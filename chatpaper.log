2025-11-09 00:54:09,371 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-09 00:54:09,374 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-09 00:54:09,376 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-09 00:54:09,380 - WARNING - root - 初始化 LLM 客户端失败: unexpected indent (llm_client.py, line 96)
2025-11-09 00:54:09,382 - INFO - root - === 运行配置 ===
2025-11-09 00:54:09,382 - INFO - root - 处理模式: 本地PDF文件
2025-11-09 00:54:09,382 - INFO - root - PDF目录: d:\ChatPaper\myPapers
2025-11-09 00:54:09,383 - INFO - root - 最大处理数量: 2
2025-11-09 00:54:09,384 - INFO - root - 保存图片: 是
2025-11-09 00:54:09,384 - INFO - root - 输出语言: 中文
2025-11-09 00:54:09,385 - INFO - root - 强制重新处理: 否
2025-11-09 00:54:09,385 - INFO - root - ====================
2025-11-09 00:54:09,386 - INFO - root - 从本地目录读取PDF文件：d:\ChatPaper\myPapers
2025-11-09 00:54:10,505 - INFO - root - 成功加载PDF文件：demo.pdf
2025-11-09 00:54:10,510 - INFO - root - 正在总结论文 1/1: “Good Robot!”: Efﬁcient Reinforcement Learning for Multi-Step Visual Tasks with Sim to Real Transfer
2025-11-09 00:54:10,510 - ERROR - root - LLM 客户端未初始化，将使用备用响应。
2025-11-09 00:54:10,510 - ERROR - root - LLM 客户端未初始化，将使用备用响应。
2025-11-09 00:54:10,510 - ERROR - root - LLM 客户端未初始化，将使用备用响应。
2025-11-09 00:54:10,513 - INFO - root - 正在提取论文图片...
2025-11-09 00:54:10,726 - INFO - root - 已保存图片 1/10：./export\images_“Good Robot!”_ Efﬁcient Reinforcement Learning for Multi-Step Visual Tasks with\figure_1_page2.jpeg
2025-11-09 00:54:10,833 - INFO - root - 已保存图片 2/10：./export\images_“Good Robot!”_ Efﬁcient Reinforcement Learning for Multi-Step Visual Tasks with\figure_2_page1.jpeg
2025-11-09 00:54:10,920 - INFO - root - 已保存图片 3/10：./export\images_“Good Robot!”_ Efﬁcient Reinforcement Learning for Multi-Step Visual Tasks with\figure_3_page7.jpeg
2025-11-09 00:54:10,982 - INFO - root - 已保存图片 4/10：./export\images_“Good Robot!”_ Efﬁcient Reinforcement Learning for Multi-Step Visual Tasks with\figure_4_page4.jpeg
2025-11-09 00:54:11,019 - INFO - root - 已保存图片 5/10：./export\images_“Good Robot!”_ Efﬁcient Reinforcement Learning for Multi-Step Visual Tasks with\figure_5_page4.png
2025-11-09 00:54:11,053 - INFO - root - 已保存图片 6/10：./export\images_“Good Robot!”_ Efﬁcient Reinforcement Learning for Multi-Step Visual Tasks with\figure_6_page7.jpeg
2025-11-09 00:54:11,069 - INFO - root - 成功添加图片 1：./export\images_“Good Robot!”_ Efﬁcient Reinforcement Learning for Multi-Step Visual Tasks with\figure_1_page2.jpeg
2025-11-09 00:54:11,069 - INFO - root - 成功添加图片 2：./export\images_“Good Robot!”_ Efﬁcient Reinforcement Learning for Multi-Step Visual Tasks with\figure_2_page1.jpeg
2025-11-09 00:54:11,070 - INFO - root - 成功添加图片 3：./export\images_“Good Robot!”_ Efﬁcient Reinforcement Learning for Multi-Step Visual Tasks with\figure_3_page7.jpeg
2025-11-09 00:54:11,071 - INFO - root - 成功添加图片 4：./export\images_“Good Robot!”_ Efﬁcient Reinforcement Learning for Multi-Step Visual Tasks with\figure_4_page4.jpeg
2025-11-09 00:54:11,071 - INFO - root - 成功添加图片 5：./export\images_“Good Robot!”_ Efﬁcient Reinforcement Learning for Multi-Step Visual Tasks with\figure_5_page4.png
2025-11-09 00:54:11,071 - INFO - root - 成功添加图片 6：./export\images_“Good Robot!”_ Efﬁcient Reinforcement Learning for Multi-Step Visual Tasks with\figure_6_page7.jpeg
2025-11-09 00:54:11,076 - INFO - root - 论文《“Good Robot!”: Efﬁcient Reinforcement Learning for Multi-Step Visual Tasks with Sim to Real Transfer》的分析已保存到 ./export\“Good Robot!”_ Efﬁcient Reinforcement Learning for Multi-Step Visual Tasks with.md
2025-11-09 00:54:11,080 - INFO - root - summary time: 1.71 seconds
2025-11-09 00:56:18,518 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-09 00:56:18,518 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-09 00:56:18,518 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-09 00:56:18,518 - WARNING - root - 初始化 LLM 客户端失败: unexpected indent (llm_client.py, line 96)
2025-11-09 00:56:18,524 - INFO - root - === 运行配置 ===
2025-11-09 00:56:18,524 - INFO - root - 处理模式: 本地PDF文件
2025-11-09 00:56:18,524 - INFO - root - PDF目录: d:\ChatPaper\myPapers
2025-11-09 00:56:18,525 - INFO - root - 最大处理数量: 2
2025-11-09 00:56:18,525 - INFO - root - 保存图片: 是
2025-11-09 00:56:18,525 - INFO - root - 输出语言: 中文
2025-11-09 00:56:18,525 - INFO - root - 强制重新处理: 否
2025-11-09 00:56:18,527 - INFO - root - ====================
2025-11-09 00:56:18,527 - INFO - root - 从本地目录读取PDF文件：d:\ChatPaper\myPapers
2025-11-09 00:56:19,108 - INFO - root - 成功加载PDF文件：demo.pdf
2025-11-09 00:56:19,108 - INFO - root - 跳过已处理论文 “Good Robot!”: Efﬁcient Reinforcement Learning for Multi-Step Visual Tasks with Sim to Real Transfer：d:\ChatPaper\myPapers\demo.pdf
2025-11-09 00:56:19,108 - INFO - root - summary time: 0.59 seconds
2025-11-09 00:56:38,605 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-09 00:56:38,606 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-09 00:56:38,607 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-09 00:56:38,610 - WARNING - root - 初始化 LLM 客户端失败: unexpected indent (llm_client.py, line 96)
2025-11-09 00:56:38,610 - INFO - root - === 运行配置 ===
2025-11-09 00:56:38,611 - INFO - root - 处理模式: 本地PDF文件
2025-11-09 00:56:38,611 - INFO - root - PDF目录: d:\ChatPaper\myPapers
2025-11-09 00:56:38,611 - INFO - root - 最大处理数量: 2
2025-11-09 00:56:38,611 - INFO - root - 保存图片: 是
2025-11-09 00:56:38,611 - INFO - root - 输出语言: 中文
2025-11-09 00:56:38,611 - INFO - root - 强制重新处理: 否
2025-11-09 00:56:38,611 - INFO - root - ====================
2025-11-09 00:56:38,611 - INFO - root - 从本地目录读取PDF文件：d:\ChatPaper\myPapers
2025-11-09 00:56:39,256 - INFO - root - 成功加载PDF文件：demo.pdf
2025-11-09 00:56:39,257 - INFO - root - 跳过已处理论文 “Good Robot!”: Efﬁcient Reinforcement Learning for Multi-Step Visual Tasks with Sim to Real Transfer：d:\ChatPaper\myPapers\demo.pdf
2025-11-09 00:56:39,257 - INFO - root - summary time: 0.65 seconds
2025-11-09 00:57:37,925 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-09 00:57:37,926 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-09 00:57:37,928 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-09 00:57:39,179 - INFO - root - LLMClient: trying model gemini-2.5-flash
2025-11-09 00:57:44,038 - INFO - root - LLMClient: initialized model gemini-2.5-flash
2025-11-09 00:57:44,039 - INFO - root - 使用 LLM 模型: gemini-2.5-flash
2025-11-09 00:57:44,040 - INFO - root - === 运行配置 ===
2025-11-09 00:57:44,041 - INFO - root - 处理模式: 本地PDF文件
2025-11-09 00:57:44,045 - INFO - root - PDF目录: d:\ChatPaper\myPapers
2025-11-09 00:57:44,049 - INFO - root - 最大处理数量: 2
2025-11-09 00:57:44,049 - INFO - root - 保存图片: 是
2025-11-09 00:57:44,051 - INFO - root - 输出语言: 中文
2025-11-09 00:57:44,052 - INFO - root - 强制重新处理: 否
2025-11-09 00:57:44,053 - INFO - root - ====================
2025-11-09 00:57:44,054 - INFO - root - 从本地目录读取PDF文件：d:\ChatPaper\myPapers
2025-11-09 00:57:45,100 - INFO - root - 成功加载PDF文件：demo.pdf
2025-11-09 00:57:45,101 - INFO - root - 跳过已处理论文 “Good Robot!”: Efﬁcient Reinforcement Learning for Multi-Step Visual Tasks with Sim to Real Transfer：d:\ChatPaper\myPapers\demo.pdf
2025-11-09 00:57:45,102 - INFO - root - summary time: 7.18 seconds
2025-11-09 00:57:54,670 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-09 00:57:54,670 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-09 00:57:54,670 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-09 00:57:55,831 - INFO - root - LLMClient: trying model gemini-2.5-flash
2025-11-09 00:57:58,715 - INFO - root - LLMClient: initialized model gemini-2.5-flash
2025-11-09 00:57:58,716 - INFO - root - 使用 LLM 模型: gemini-2.5-flash
2025-11-09 00:57:58,718 - INFO - root - === 运行配置 ===
2025-11-09 00:57:58,719 - INFO - root - 处理模式: 本地PDF文件
2025-11-09 00:57:58,720 - INFO - root - PDF目录: d:\ChatPaper\myPapers
2025-11-09 00:57:58,721 - INFO - root - 最大处理数量: 2
2025-11-09 00:57:58,722 - INFO - root - 保存图片: 是
2025-11-09 00:57:58,723 - INFO - root - 输出语言: 中文
2025-11-09 00:57:58,724 - INFO - root - 强制重新处理: 否
2025-11-09 00:57:58,726 - INFO - root - ====================
2025-11-09 00:57:58,727 - INFO - root - 从本地目录读取PDF文件：d:\ChatPaper\myPapers
2025-11-09 00:57:59,367 - INFO - root - 成功加载PDF文件：demo.pdf
2025-11-09 00:57:59,367 - INFO - root - 跳过已处理论文 “Good Robot!”: Efﬁcient Reinforcement Learning for Multi-Step Visual Tasks with Sim to Real Transfer：d:\ChatPaper\myPapers\demo.pdf
2025-11-09 00:57:59,368 - INFO - root - summary time: 4.70 seconds
2025-11-09 00:58:27,401 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-09 00:58:27,401 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-09 00:58:27,405 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-09 00:58:28,300 - INFO - root - LLMClient: trying model gemini-2.5-flash
2025-11-09 00:58:33,329 - INFO - root - LLMClient: initialized model gemini-2.5-flash
2025-11-09 00:58:33,330 - INFO - root - 使用 LLM 模型: gemini-2.5-flash
2025-11-09 00:58:33,331 - INFO - root - === 运行配置 ===
2025-11-09 00:58:33,331 - INFO - root - 处理模式: arxiv在线搜索
2025-11-09 00:58:33,332 - INFO - root - 关键词: Quant
2025-11-09 00:58:33,332 - INFO - root - 查询: block float point
2025-11-09 00:58:33,332 - INFO - root - 排序: None
2025-11-09 00:58:33,332 - INFO - root - 最近天数: 180
2025-11-09 00:58:33,332 - INFO - root - 最大处理数量: 2
2025-11-09 00:58:33,333 - INFO - root - 保存图片: 是
2025-11-09 00:58:33,333 - INFO - root - 输出语言: 中文
2025-11-09 00:58:33,334 - INFO - root - 强制重新处理: 否
2025-11-09 00:58:33,335 - INFO - root - ====================
2025-11-09 00:58:33,335 - INFO - root - 使用 arXiv 搜索模式（通过 chat_arxiv 模块获取）
2025-11-09 00:59:13,415 - INFO - root - 正在总结论文 1/2: From Uniform to Adaptive: General Skip-Block Mechanisms for Efficient PDE Neural Operators
2025-11-09 00:59:51,953 - INFO - root - LLMClient: rate limit reached, sleeping 21.5s
2025-11-09 01:00:34,660 - INFO - root - 正在提取论文图片...
2025-11-09 01:14:08,444 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-09 01:14:08,444 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-09 01:14:08,449 - WARNING - root - LLMClient: Gemini API key not provided. LLM disabled.
2025-11-09 01:14:08,449 - INFO - root - LLM 未初始化或不可用，后续生成将返回备用消息
2025-11-09 01:14:08,454 - INFO - root - 已创建目录：D:\ChatPaper\src\myPapers
2025-11-09 01:14:08,454 - INFO - root - === 运行配置 ===
2025-11-09 01:14:08,455 - INFO - root - 处理模式: arxiv在线搜索
2025-11-09 01:14:08,455 - INFO - root - 关键词: Quant
2025-11-09 01:14:08,456 - INFO - root - 查询: block float point
2025-11-09 01:14:08,456 - INFO - root - 排序: None
2025-11-09 01:14:08,457 - INFO - root - 最近天数: 180
2025-11-09 01:14:08,458 - INFO - root - 最大处理数量: 2
2025-11-09 01:14:08,458 - INFO - root - 保存图片: 是
2025-11-09 01:14:08,460 - INFO - root - 输出语言: 中文
2025-11-09 01:14:08,460 - INFO - root - 强制重新处理: 否
2025-11-09 01:14:08,461 - INFO - root - ====================
2025-11-09 01:14:08,461 - INFO - root - 使用 arXiv 搜索模式（通过 chat_arxiv 模块获取）
2025-11-09 01:14:18,810 - INFO - root - 正在总结论文 1/2: From Uniform to Adaptive: General Skip-Block Mechanisms for Efficient PDE Neural Operators
2025-11-09 01:14:18,810 - INFO - root - 正在提取论文图片...
2025-11-09 01:14:19,325 - INFO - root - 已保存图片 1/10：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_1_page3.png
2025-11-09 01:14:19,410 - INFO - root - 已保存图片 2/10：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_2_page8.png
2025-11-09 01:14:19,483 - INFO - root - 已保存图片 3/10：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_3_page8.png
2025-11-09 01:14:19,540 - INFO - root - 已保存图片 4/10：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_4_page9.png
2025-11-09 01:14:19,595 - INFO - root - 已保存图片 5/10：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_5_page9.png
2025-11-09 01:14:19,662 - INFO - root - 已保存图片 6/10：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_6_page4.png
2025-11-09 01:14:19,707 - INFO - root - 已保存图片 7/10：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_7_page4.png
2025-11-09 01:14:19,783 - INFO - root - 已保存图片 8/10：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_8_page16.png
2025-11-09 01:14:19,793 - INFO - root - 已保存图片 9/10：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_9_page4.png
2025-11-09 01:14:19,810 - INFO - root - 已保存图片 10/10：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_10_page4.png
2025-11-09 01:14:19,815 - INFO - root - 成功添加图片 1：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_1_page3.png
2025-11-09 01:14:19,815 - INFO - root - 成功添加图片 2：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_2_page8.png
2025-11-09 01:14:19,816 - INFO - root - 成功添加图片 3：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_3_page8.png
2025-11-09 01:14:19,818 - INFO - root - 成功添加图片 4：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_4_page9.png
2025-11-09 01:14:19,820 - INFO - root - 成功添加图片 5：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_5_page9.png
2025-11-09 01:14:19,820 - INFO - root - 成功添加图片 6：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_6_page4.png
2025-11-09 01:14:19,822 - INFO - root - 成功添加图片 7：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_7_page4.png
2025-11-09 01:14:19,825 - INFO - root - 成功添加图片 8：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_8_page16.png
2025-11-09 01:14:19,826 - INFO - root - 成功添加图片 9：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_9_page4.png
2025-11-09 01:14:19,827 - INFO - root - 成功添加图片 10：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_10_page4.png
2025-11-09 01:14:19,829 - INFO - root - 论文《From Uniform to Adaptive: General Skip-Block Mechanisms for Efficient PDE Neural Operators》的分析已保存到 ./export\From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural.md
2025-11-09 01:14:19,836 - INFO - root - 正在总结论文 2/2: INT v.s. FP: A Comprehensive Study of Fine-Grained Low-bit Quantization Formats
2025-11-09 01:14:19,845 - INFO - root - 正在提取论文图片...
2025-11-09 01:14:20,289 - INFO - root - 已保存图片 1/10：./export\images_INT v.s. FP_ A Comprehensive Study of Fine-Grained Low-bit Quantization Formats\figure_1_page9.png
2025-11-09 01:14:20,354 - INFO - root - 已保存图片 2/10：./export\images_INT v.s. FP_ A Comprehensive Study of Fine-Grained Low-bit Quantization Formats\figure_2_page1.png
2025-11-09 01:14:20,388 - INFO - root - 已保存图片 3/10：./export\images_INT v.s. FP_ A Comprehensive Study of Fine-Grained Low-bit Quantization Formats\figure_3_page1.jpeg
2025-11-09 01:14:20,450 - INFO - root - 已保存图片 4/10：./export\images_INT v.s. FP_ A Comprehensive Study of Fine-Grained Low-bit Quantization Formats\figure_4_page9.png
2025-11-09 01:14:20,454 - INFO - root - 成功添加图片 1：./export\images_INT v.s. FP_ A Comprehensive Study of Fine-Grained Low-bit Quantization Formats\figure_1_page9.png
2025-11-09 01:14:20,454 - INFO - root - 成功添加图片 2：./export\images_INT v.s. FP_ A Comprehensive Study of Fine-Grained Low-bit Quantization Formats\figure_2_page1.png
2025-11-09 01:14:20,455 - INFO - root - 成功添加图片 3：./export\images_INT v.s. FP_ A Comprehensive Study of Fine-Grained Low-bit Quantization Formats\figure_3_page1.jpeg
2025-11-09 01:14:20,455 - INFO - root - 成功添加图片 4：./export\images_INT v.s. FP_ A Comprehensive Study of Fine-Grained Low-bit Quantization Formats\figure_4_page9.png
2025-11-09 01:14:20,457 - INFO - root - 论文《INT v.s. FP: A Comprehensive Study of Fine-Grained Low-bit Quantization Formats》的分析已保存到 ./export\INT v.s. FP_ A Comprehensive Study of Fine-Grained Low-bit Quantization Formats.md
2025-11-09 01:14:20,461 - INFO - root - summary time: 12.02 seconds
2025-11-09 01:17:35,499 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-09 01:17:35,499 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-09 01:17:35,499 - WARNING - root - LLMClient: Gemini API key not provided. LLM disabled.
2025-11-09 01:17:35,499 - INFO - root - LLM 未初始化或不可用，后续生成将返回备用消息
2025-11-09 01:17:35,499 - INFO - root - === 运行配置 ===
2025-11-09 01:17:35,499 - INFO - root - 处理模式: arxiv在线搜索
2025-11-09 01:17:35,499 - INFO - root - 关键词: Quant
2025-11-09 01:17:35,499 - INFO - root - 查询: block float point
2025-11-09 01:17:35,499 - INFO - root - 排序: None
2025-11-09 01:17:35,499 - INFO - root - 最近天数: 180
2025-11-09 01:17:35,499 - INFO - root - 最大处理数量: 2
2025-11-09 01:17:35,499 - INFO - root - 保存图片: 是
2025-11-09 01:17:35,499 - INFO - root - 输出语言: 中文
2025-11-09 01:17:35,499 - INFO - root - 强制重新处理: 否
2025-11-09 01:17:35,499 - INFO - root - ====================
2025-11-09 01:17:35,499 - INFO - root - 使用 arXiv 搜索模式（通过 chat_arxiv 模块获取）
2025-11-09 01:17:59,345 - INFO - root - 正在总结论文 1/2: From Uniform to Adaptive: General Skip-Block Mechanisms for Efficient PDE Neural Operators
2025-11-09 01:17:59,346 - INFO - root - 正在提取论文图片...
2025-11-09 01:17:59,741 - INFO - root - 已保存图片 1/10：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_1_page3.png
2025-11-09 01:17:59,811 - INFO - root - 已保存图片 2/10：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_2_page8.png
2025-11-09 01:17:59,872 - INFO - root - 已保存图片 3/10：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_3_page8.png
2025-11-09 01:17:59,923 - INFO - root - 已保存图片 4/10：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_4_page9.png
2025-11-09 01:18:00,011 - INFO - root - 已保存图片 5/10：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_5_page9.png
2025-11-09 01:18:00,104 - INFO - root - 已保存图片 6/10：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_6_page4.png
2025-11-09 01:18:00,147 - INFO - root - 已保存图片 7/10：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_7_page4.png
2025-11-09 01:18:00,211 - INFO - root - 已保存图片 8/10：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_8_page16.png
2025-11-09 01:18:00,221 - INFO - root - 已保存图片 9/10：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_9_page4.png
2025-11-09 01:18:00,239 - INFO - root - 已保存图片 10/10：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_10_page4.png
2025-11-09 01:18:00,241 - INFO - root - 成功添加图片 1：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_1_page3.png
2025-11-09 01:18:00,246 - INFO - root - 成功添加图片 2：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_2_page8.png
2025-11-09 01:18:00,246 - INFO - root - 成功添加图片 3：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_3_page8.png
2025-11-09 01:18:00,247 - INFO - root - 成功添加图片 4：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_4_page9.png
2025-11-09 01:18:00,247 - INFO - root - 成功添加图片 5：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_5_page9.png
2025-11-09 01:18:00,249 - INFO - root - 成功添加图片 6：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_6_page4.png
2025-11-09 01:18:00,249 - INFO - root - 成功添加图片 7：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_7_page4.png
2025-11-09 01:18:00,249 - INFO - root - 成功添加图片 8：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_8_page16.png
2025-11-09 01:18:00,249 - INFO - root - 成功添加图片 9：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_9_page4.png
2025-11-09 01:18:00,250 - INFO - root - 成功添加图片 10：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_10_page4.png
2025-11-09 01:18:00,253 - INFO - root - 论文《From Uniform to Adaptive: General Skip-Block Mechanisms for Efficient PDE Neural Operators》的分析已保存到 ./export\From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural-1.md
2025-11-09 01:18:00,268 - INFO - root - 正在总结论文 2/2: INT v.s. FP: A Comprehensive Study of Fine-Grained Low-bit Quantization Formats
2025-11-09 01:18:00,272 - INFO - root - 正在提取论文图片...
2025-11-09 01:18:00,811 - INFO - root - 已保存图片 1/10：./export\images_INT v.s. FP_ A Comprehensive Study of Fine-Grained Low-bit Quantization Formats\figure_1_page9.png
2025-11-09 01:18:00,888 - INFO - root - 已保存图片 2/10：./export\images_INT v.s. FP_ A Comprehensive Study of Fine-Grained Low-bit Quantization Formats\figure_2_page1.png
2025-11-09 01:18:00,915 - INFO - root - 已保存图片 3/10：./export\images_INT v.s. FP_ A Comprehensive Study of Fine-Grained Low-bit Quantization Formats\figure_3_page1.jpeg
2025-11-09 01:18:00,974 - INFO - root - 已保存图片 4/10：./export\images_INT v.s. FP_ A Comprehensive Study of Fine-Grained Low-bit Quantization Formats\figure_4_page9.png
2025-11-09 01:18:00,980 - INFO - root - 成功添加图片 1：./export\images_INT v.s. FP_ A Comprehensive Study of Fine-Grained Low-bit Quantization Formats\figure_1_page9.png
2025-11-09 01:18:00,981 - INFO - root - 成功添加图片 2：./export\images_INT v.s. FP_ A Comprehensive Study of Fine-Grained Low-bit Quantization Formats\figure_2_page1.png
2025-11-09 01:18:00,982 - INFO - root - 成功添加图片 3：./export\images_INT v.s. FP_ A Comprehensive Study of Fine-Grained Low-bit Quantization Formats\figure_3_page1.jpeg
2025-11-09 01:18:00,983 - INFO - root - 成功添加图片 4：./export\images_INT v.s. FP_ A Comprehensive Study of Fine-Grained Low-bit Quantization Formats\figure_4_page9.png
2025-11-09 01:18:00,985 - INFO - root - 论文《INT v.s. FP: A Comprehensive Study of Fine-Grained Low-bit Quantization Formats》的分析已保存到 ./export\INT v.s. FP_ A Comprehensive Study of Fine-Grained Low-bit Quantization Formats-1.md
2025-11-09 01:18:00,999 - INFO - root - summary time: 25.50 seconds
2025-11-09 01:18:24,953 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-09 01:18:24,953 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-09 01:18:24,953 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-09 01:18:26,047 - INFO - root - LLMClient: trying model gemini-2.5-flash
2025-11-09 01:18:30,078 - INFO - root - LLMClient: initialized model gemini-2.5-flash
2025-11-09 01:18:30,079 - INFO - root - 使用 LLM 模型: gemini-2.5-flash
2025-11-09 01:18:30,080 - INFO - root - === 运行配置 ===
2025-11-09 01:18:30,081 - INFO - root - 处理模式: arxiv在线搜索
2025-11-09 01:18:30,081 - INFO - root - 关键词: Quant
2025-11-09 01:18:30,082 - INFO - root - 查询: block float point
2025-11-09 01:18:30,082 - INFO - root - 排序: None
2025-11-09 01:18:30,082 - INFO - root - 最近天数: 180
2025-11-09 01:18:30,083 - INFO - root - 最大处理数量: 2
2025-11-09 01:18:30,083 - INFO - root - 保存图片: 是
2025-11-09 01:18:30,083 - INFO - root - 输出语言: 中文
2025-11-09 01:18:30,083 - INFO - root - 强制重新处理: 否
2025-11-09 01:18:30,084 - INFO - root - ====================
2025-11-09 01:18:30,084 - INFO - root - 使用 arXiv 搜索模式（通过 chat_arxiv 模块获取）
2025-11-09 01:18:42,682 - INFO - root - 正在总结论文 1/2: From Uniform to Adaptive: General Skip-Block Mechanisms for Efficient PDE Neural Operators
2025-11-09 01:19:21,628 - INFO - root - LLMClient: rate limit reached, sleeping 21.1s
2025-11-09 01:20:03,870 - INFO - root - 正在提取论文图片...
2025-11-09 01:20:04,695 - INFO - root - 已保存图片 1/10：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_1_page3.png
2025-11-09 01:20:04,870 - INFO - root - 已保存图片 2/10：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_2_page8.png
2025-11-09 01:20:05,078 - INFO - root - 已保存图片 3/10：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_3_page8.png
2025-11-09 01:20:05,256 - INFO - root - 已保存图片 4/10：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_4_page9.png
2025-11-09 01:20:05,391 - INFO - root - 已保存图片 5/10：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_5_page9.png
2025-11-09 01:20:05,493 - INFO - root - 已保存图片 6/10：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_6_page4.png
2025-11-09 01:20:05,603 - INFO - root - 已保存图片 7/10：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_7_page4.png
2025-11-09 01:20:05,681 - INFO - root - 已保存图片 8/10：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_8_page16.png
2025-11-09 01:20:05,703 - INFO - root - 已保存图片 9/10：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_9_page4.png
2025-11-09 01:20:05,726 - INFO - root - 已保存图片 10/10：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_10_page4.png
2025-11-09 01:20:05,732 - INFO - root - 成功添加图片 1：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_1_page3.png
2025-11-09 01:20:05,732 - INFO - root - 成功添加图片 2：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_2_page8.png
2025-11-09 01:20:05,734 - INFO - root - 成功添加图片 3：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_3_page8.png
2025-11-09 01:20:05,734 - INFO - root - 成功添加图片 4：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_4_page9.png
2025-11-09 01:20:05,734 - INFO - root - 成功添加图片 5：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_5_page9.png
2025-11-09 01:20:05,737 - INFO - root - 成功添加图片 6：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_6_page4.png
2025-11-09 01:20:05,737 - INFO - root - 成功添加图片 7：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_7_page4.png
2025-11-09 01:20:05,738 - INFO - root - 成功添加图片 8：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_8_page16.png
2025-11-09 01:20:05,739 - INFO - root - 成功添加图片 9：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_9_page4.png
2025-11-09 01:20:05,741 - INFO - root - 成功添加图片 10：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_10_page4.png
2025-11-09 01:20:05,749 - INFO - root - 论文《From Uniform to Adaptive: General Skip-Block Mechanisms for Efficient PDE Neural Operators》的分析已保存到 ./export\From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural-2.md
2025-11-09 01:20:05,752 - INFO - root - 正在总结论文 2/2: INT v.s. FP: A Comprehensive Study of Fine-Grained Low-bit Quantization Formats
2025-11-09 01:20:18,101 - INFO - root - LLMClient: rate limit reached, sleeping 24.6s
2025-11-09 01:21:36,061 - INFO - root - 正在提取论文图片...
2025-11-09 01:21:36,446 - INFO - root - 已保存图片 1/10：./export\images_INT v.s. FP_ A Comprehensive Study of Fine-Grained Low-bit Quantization Formats\figure_1_page9.png
2025-11-09 01:21:36,499 - INFO - root - 已保存图片 2/10：./export\images_INT v.s. FP_ A Comprehensive Study of Fine-Grained Low-bit Quantization Formats\figure_2_page1.png
2025-11-09 01:21:36,546 - INFO - root - 已保存图片 3/10：./export\images_INT v.s. FP_ A Comprehensive Study of Fine-Grained Low-bit Quantization Formats\figure_3_page1.jpeg
2025-11-09 01:21:36,592 - INFO - root - 已保存图片 4/10：./export\images_INT v.s. FP_ A Comprehensive Study of Fine-Grained Low-bit Quantization Formats\figure_4_page9.png
2025-11-09 01:21:36,604 - INFO - root - 成功添加图片 1：./export\images_INT v.s. FP_ A Comprehensive Study of Fine-Grained Low-bit Quantization Formats\figure_1_page9.png
2025-11-09 01:21:36,604 - INFO - root - 成功添加图片 2：./export\images_INT v.s. FP_ A Comprehensive Study of Fine-Grained Low-bit Quantization Formats\figure_2_page1.png
2025-11-09 01:21:36,604 - INFO - root - 成功添加图片 3：./export\images_INT v.s. FP_ A Comprehensive Study of Fine-Grained Low-bit Quantization Formats\figure_3_page1.jpeg
2025-11-09 01:21:36,604 - INFO - root - 成功添加图片 4：./export\images_INT v.s. FP_ A Comprehensive Study of Fine-Grained Low-bit Quantization Formats\figure_4_page9.png
2025-11-09 01:21:36,613 - INFO - root - 论文《INT v.s. FP: A Comprehensive Study of Fine-Grained Low-bit Quantization Formats》的分析已保存到 ./export\INT v.s. FP_ A Comprehensive Study of Fine-Grained Low-bit Quantization Formats-2.md
2025-11-09 01:21:36,618 - INFO - root - summary time: 191.66 seconds
2025-11-09 01:26:11,351 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-09 01:26:11,351 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-09 01:26:11,351 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-09 01:26:12,198 - INFO - root - LLMClient: trying model gemini-2.5-flash
2025-11-09 01:26:14,752 - INFO - root - LLMClient: initialized model gemini-2.5-flash
2025-11-09 01:26:14,752 - INFO - root - 使用 LLM 模型: gemini-2.5-flash
2025-11-09 01:26:14,753 - INFO - root - === 运行配置 ===
2025-11-09 01:26:14,754 - INFO - root - 处理模式: arxiv在线搜索
2025-11-09 01:26:14,755 - INFO - root - 关键词: Quant
2025-11-09 01:26:14,756 - INFO - root - 查询: block float point
2025-11-09 01:26:14,757 - INFO - root - 排序: None
2025-11-09 01:26:14,757 - INFO - root - 最近天数: 180
2025-11-09 01:26:14,759 - INFO - root - 最大处理数量: 2
2025-11-09 01:26:14,760 - INFO - root - 保存图片: 是
2025-11-09 01:26:14,760 - INFO - root - 输出语言: 中文
2025-11-09 01:26:14,761 - INFO - root - 强制重新处理: 否
2025-11-09 01:26:14,762 - INFO - root - ====================
2025-11-09 01:26:14,763 - INFO - root - 使用 arXiv 搜索模式（通过 chat_arxiv 模块获取）
2025-11-09 01:26:31,982 - INFO - root - 正在总结论文 1/2: From Uniform to Adaptive: General Skip-Block Mechanisms for Efficient PDE Neural Operators
2025-11-09 01:27:10,578 - INFO - root - LLMClient: rate limit reached, sleeping 21.4s
2025-11-09 01:27:51,208 - INFO - root - 正在提取论文图片...
2025-11-09 01:27:51,587 - INFO - root - 已保存图片 1/10：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_1_page3.png
2025-11-09 01:27:51,674 - INFO - root - 已保存图片 2/10：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_2_page8.png
2025-11-09 01:27:51,738 - INFO - root - 已保存图片 3/10：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_3_page8.png
2025-11-09 01:27:51,809 - INFO - root - 已保存图片 4/10：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_4_page9.png
2025-11-09 01:27:51,866 - INFO - root - 已保存图片 5/10：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_5_page9.png
2025-11-09 01:27:51,923 - INFO - root - 已保存图片 6/10：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_6_page4.png
2025-11-09 01:27:51,979 - INFO - root - 已保存图片 7/10：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_7_page4.png
2025-11-09 01:27:52,046 - INFO - root - 已保存图片 8/10：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_8_page16.png
2025-11-09 01:27:52,057 - INFO - root - 已保存图片 9/10：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_9_page4.png
2025-11-09 01:27:52,073 - INFO - root - 已保存图片 10/10：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_10_page4.png
2025-11-09 01:27:52,081 - INFO - root - 成功添加图片 1：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_1_page3.png
2025-11-09 01:27:52,081 - INFO - root - 成功添加图片 2：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_2_page8.png
2025-11-09 01:27:52,083 - INFO - root - 成功添加图片 3：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_3_page8.png
2025-11-09 01:27:52,083 - INFO - root - 成功添加图片 4：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_4_page9.png
2025-11-09 01:27:52,083 - INFO - root - 成功添加图片 5：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_5_page9.png
2025-11-09 01:27:52,085 - INFO - root - 成功添加图片 6：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_6_page4.png
2025-11-09 01:27:52,086 - INFO - root - 成功添加图片 7：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_7_page4.png
2025-11-09 01:27:52,087 - INFO - root - 成功添加图片 8：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_8_page16.png
2025-11-09 01:27:52,088 - INFO - root - 成功添加图片 9：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_9_page4.png
2025-11-09 01:27:52,089 - INFO - root - 成功添加图片 10：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_10_page4.png
2025-11-09 01:27:52,094 - INFO - root - 论文《From Uniform to Adaptive: General Skip-Block Mechanisms for Efficient PDE Neural Operators》的分析已保存到 ./export\From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural.md
2025-11-09 01:27:52,099 - INFO - root - 正在总结论文 2/2: INT v.s. FP: A Comprehensive Study of Fine-Grained Low-bit Quantization Formats
2025-11-09 01:28:03,710 - INFO - root - LLMClient: rate limit reached, sleeping 28.3s
2025-11-09 01:29:19,818 - INFO - root - 正在提取论文图片...
2025-11-09 01:29:20,248 - INFO - root - 已保存图片 1/10：./export\images_INT v.s. FP_ A Comprehensive Study of Fine-Grained Low-bit Quantization Formats\figure_1_page9.png
2025-11-09 01:29:20,306 - INFO - root - 已保存图片 2/10：./export\images_INT v.s. FP_ A Comprehensive Study of Fine-Grained Low-bit Quantization Formats\figure_2_page1.png
2025-11-09 01:29:20,332 - INFO - root - 已保存图片 3/10：./export\images_INT v.s. FP_ A Comprehensive Study of Fine-Grained Low-bit Quantization Formats\figure_3_page1.jpeg
2025-11-09 01:29:20,412 - INFO - root - 已保存图片 4/10：./export\images_INT v.s. FP_ A Comprehensive Study of Fine-Grained Low-bit Quantization Formats\figure_4_page9.png
2025-11-09 01:29:20,416 - INFO - root - 成功添加图片 1：./export\images_INT v.s. FP_ A Comprehensive Study of Fine-Grained Low-bit Quantization Formats\figure_1_page9.png
2025-11-09 01:29:20,417 - INFO - root - 成功添加图片 2：./export\images_INT v.s. FP_ A Comprehensive Study of Fine-Grained Low-bit Quantization Formats\figure_2_page1.png
2025-11-09 01:29:20,419 - INFO - root - 成功添加图片 3：./export\images_INT v.s. FP_ A Comprehensive Study of Fine-Grained Low-bit Quantization Formats\figure_3_page1.jpeg
2025-11-09 01:29:20,419 - INFO - root - 成功添加图片 4：./export\images_INT v.s. FP_ A Comprehensive Study of Fine-Grained Low-bit Quantization Formats\figure_4_page9.png
2025-11-09 01:29:20,424 - INFO - root - 论文《INT v.s. FP: A Comprehensive Study of Fine-Grained Low-bit Quantization Formats》的分析已保存到 ./export\INT v.s. FP_ A Comprehensive Study of Fine-Grained Low-bit Quantization Formats.md
2025-11-09 01:29:20,428 - INFO - root - summary time: 189.08 seconds
2025-11-09 01:32:09,191 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-09 01:32:09,191 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-09 01:32:09,191 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-09 01:32:10,153 - INFO - root - LLMClient: trying model gemini-2.5-flash
2025-11-09 01:32:14,357 - INFO - root - LLMClient: initialized model gemini-2.5-flash
2025-11-09 01:32:14,358 - INFO - root - 使用 LLM 模型: gemini-2.5-flash
2025-11-09 01:32:14,359 - INFO - root - === 运行配置 ===
2025-11-09 01:32:14,359 - INFO - root - 处理模式: arxiv在线搜索
2025-11-09 01:32:14,359 - INFO - root - 关键词: Quant
2025-11-09 01:32:14,360 - INFO - root - 查询: block float point quant
2025-11-09 01:32:14,361 - INFO - root - 排序: None
2025-11-09 01:32:14,361 - INFO - root - 最近天数: 180
2025-11-09 01:32:14,362 - INFO - root - 最大处理数量: 50
2025-11-09 01:32:14,363 - INFO - root - 保存图片: 是
2025-11-09 01:32:14,364 - INFO - root - 输出语言: 中文
2025-11-09 01:32:14,364 - INFO - root - 强制重新处理: 否
2025-11-09 01:32:14,365 - INFO - root - ====================
2025-11-09 01:32:14,366 - INFO - root - 使用 arXiv 搜索模式（通过 chat_arxiv 模块获取）
2025-11-09 01:32:15,526 - INFO - root - 没有找到要处理的论文，程序退出
2025-11-09 01:32:15,526 - INFO - root - summary time: 6.34 seconds
2025-11-09 01:33:18,608 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-09 01:33:18,608 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-09 01:33:18,608 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-09 01:33:19,613 - INFO - root - LLMClient: trying model gemini-2.5-flash
2025-11-09 01:33:22,894 - INFO - root - LLMClient: initialized model gemini-2.5-flash
2025-11-09 01:33:22,895 - INFO - root - 使用 LLM 模型: gemini-2.5-flash
2025-11-09 01:33:22,896 - INFO - root - === 运行配置 ===
2025-11-09 01:33:22,896 - INFO - root - 处理模式: arxiv在线搜索
2025-11-09 01:33:22,897 - INFO - root - 关键词: Quant
2025-11-09 01:33:22,898 - INFO - root - 查询: block float point
2025-11-09 01:33:22,899 - INFO - root - 排序: None
2025-11-09 01:33:22,899 - INFO - root - 最近天数: 180
2025-11-09 01:33:22,900 - INFO - root - 最大处理数量: 50
2025-11-09 01:33:22,901 - INFO - root - 保存图片: 是
2025-11-09 01:33:22,902 - INFO - root - 输出语言: 中文
2025-11-09 01:33:22,903 - INFO - root - 强制重新处理: 否
2025-11-09 01:33:22,904 - INFO - root - ====================
2025-11-09 01:33:22,904 - INFO - root - 使用 arXiv 搜索模式（通过 chat_arxiv 模块获取）
2025-11-09 01:35:28,889 - INFO - root - 正在总结论文 1/30: From Uniform to Adaptive: General Skip-Block Mechanisms for Efficient PDE Neural Operators
2025-11-09 01:36:07,843 - INFO - root - LLMClient: rate limit reached, sleeping 21.0s
2025-11-09 01:36:46,512 - INFO - root - 正在提取论文图片...
2025-11-09 01:36:46,941 - INFO - root - 已保存图片 1/10：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_1_page3.png
2025-11-09 01:36:47,012 - INFO - root - 已保存图片 2/10：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_2_page8.png
2025-11-09 01:36:47,088 - INFO - root - 已保存图片 3/10：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_3_page8.png
2025-11-09 01:36:47,156 - INFO - root - 已保存图片 4/10：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_4_page9.png
2025-11-09 01:36:47,208 - INFO - root - 已保存图片 5/10：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_5_page9.png
2025-11-09 01:36:47,265 - INFO - root - 已保存图片 6/10：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_6_page4.png
2025-11-09 01:36:47,312 - INFO - root - 已保存图片 7/10：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_7_page4.png
2025-11-09 01:36:47,369 - INFO - root - 已保存图片 8/10：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_8_page16.png
2025-11-09 01:36:47,382 - INFO - root - 已保存图片 9/10：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_9_page4.png
2025-11-09 01:36:47,403 - INFO - root - 已保存图片 10/10：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_10_page4.png
2025-11-09 01:36:47,408 - INFO - root - 成功添加图片 1：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_1_page3.png
2025-11-09 01:36:47,408 - INFO - root - 成功添加图片 2：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_2_page8.png
2025-11-09 01:36:47,410 - INFO - root - 成功添加图片 3：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_3_page8.png
2025-11-09 01:36:47,410 - INFO - root - 成功添加图片 4：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_4_page9.png
2025-11-09 01:36:47,410 - INFO - root - 成功添加图片 5：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_5_page9.png
2025-11-09 01:36:47,411 - INFO - root - 成功添加图片 6：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_6_page4.png
2025-11-09 01:36:47,411 - INFO - root - 成功添加图片 7：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_7_page4.png
2025-11-09 01:36:47,411 - INFO - root - 成功添加图片 8：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_8_page16.png
2025-11-09 01:36:47,411 - INFO - root - 成功添加图片 9：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_9_page4.png
2025-11-09 01:36:47,412 - INFO - root - 成功添加图片 10：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_10_page4.png
2025-11-09 01:36:47,418 - INFO - root - 论文《From Uniform to Adaptive: General Skip-Block Mechanisms for Efficient PDE Neural Operators》的分析已保存到 ./export\From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural.md
2025-11-09 01:36:47,423 - INFO - root - 正在总结论文 2/30: INT v.s. FP: A Comprehensive Study of Fine-Grained Low-bit Quantization Formats
2025-11-09 01:36:58,155 - INFO - root - LLMClient: rate limit reached, sleeping 30.7s
2025-11-09 01:38:16,887 - INFO - root - 正在提取论文图片...
2025-11-09 01:38:17,284 - INFO - root - 已保存图片 1/10：./export\images_INT v.s. FP_ A Comprehensive Study of Fine-Grained Low-bit Quantization Formats\figure_1_page9.png
2025-11-09 01:38:17,342 - INFO - root - 已保存图片 2/10：./export\images_INT v.s. FP_ A Comprehensive Study of Fine-Grained Low-bit Quantization Formats\figure_2_page1.png
2025-11-09 01:38:17,375 - INFO - root - 已保存图片 3/10：./export\images_INT v.s. FP_ A Comprehensive Study of Fine-Grained Low-bit Quantization Formats\figure_3_page1.jpeg
2025-11-09 01:38:17,449 - INFO - root - 已保存图片 4/10：./export\images_INT v.s. FP_ A Comprehensive Study of Fine-Grained Low-bit Quantization Formats\figure_4_page9.png
2025-11-09 01:38:17,451 - INFO - root - 成功添加图片 1：./export\images_INT v.s. FP_ A Comprehensive Study of Fine-Grained Low-bit Quantization Formats\figure_1_page9.png
2025-11-09 01:38:17,452 - INFO - root - 成功添加图片 2：./export\images_INT v.s. FP_ A Comprehensive Study of Fine-Grained Low-bit Quantization Formats\figure_2_page1.png
2025-11-09 01:38:17,452 - INFO - root - 成功添加图片 3：./export\images_INT v.s. FP_ A Comprehensive Study of Fine-Grained Low-bit Quantization Formats\figure_3_page1.jpeg
2025-11-09 01:38:17,453 - INFO - root - 成功添加图片 4：./export\images_INT v.s. FP_ A Comprehensive Study of Fine-Grained Low-bit Quantization Formats\figure_4_page9.png
2025-11-09 01:38:17,459 - INFO - root - 论文《INT v.s. FP: A Comprehensive Study of Fine-Grained Low-bit Quantization Formats》的分析已保存到 ./export\INT v.s. FP_ A Comprehensive Study of Fine-Grained Low-bit Quantization Formats.md
2025-11-09 01:38:17,460 - INFO - root - 正在总结论文 3/30: MX+: Pushing the Limits of Microscaling Formats for Efficient Large Language Model Serving
2025-11-09 01:38:17,464 - INFO - root - LLMClient: rate limit reached, sleeping 11.4s
2025-11-09 01:38:39,386 - INFO - root - LLMClient: rate limit reached, sleeping 17.3s
2025-11-09 01:39:27,594 - INFO - root - LLMClient: rate limit reached, sleeping 1.3s
2025-11-09 01:39:49,790 - INFO - root - 正在提取论文图片...
2025-11-09 01:39:49,913 - INFO - root - 已保存图片 1/10：./export\images_MX+_ Pushing the Limits of Microscaling Formats for Efficient Large Language Mod\figure_1_page3.png
2025-11-09 01:39:49,913 - INFO - root - 成功添加图片 1：./export\images_MX+_ Pushing the Limits of Microscaling Formats for Efficient Large Language Mod\figure_1_page3.png
2025-11-09 01:39:49,919 - INFO - root - 论文《MX+: Pushing the Limits of Microscaling Formats for Efficient Large Language Model Serving》的分析已保存到 ./export\MX+_ Pushing the Limits of Microscaling Formats for Efficient Large Language Mod.md
2025-11-09 01:39:49,920 - INFO - root - 正在总结论文 4/30: F-BFQ: Flexible Block Floating-Point Quantization Accelerator for LLMs
2025-11-09 01:39:49,924 - INFO - root - LLMClient: rate limit reached, sleeping 6.8s
2025-11-09 01:40:08,222 - INFO - root - LLMClient: rate limit reached, sleeping 20.7s
2025-11-09 01:41:47,120 - INFO - root - 正在提取论文图片...
2025-11-09 01:41:47,964 - INFO - root - 已保存图片 1/10：./export\images_F-BFQ_ Flexible Block Floating-Point Quantization Accelerator for LLMs\figure_1_page4.png
2025-11-09 01:41:48,120 - INFO - root - 已保存图片 2/10：./export\images_F-BFQ_ Flexible Block Floating-Point Quantization Accelerator for LLMs\figure_2_page3.png
2025-11-09 01:41:48,183 - INFO - root - 已保存图片 3/10：./export\images_F-BFQ_ Flexible Block Floating-Point Quantization Accelerator for LLMs\figure_3_page2.png
2025-11-09 01:41:48,190 - INFO - root - 成功添加图片 1：./export\images_F-BFQ_ Flexible Block Floating-Point Quantization Accelerator for LLMs\figure_1_page4.png
2025-11-09 01:41:48,190 - INFO - root - 成功添加图片 2：./export\images_F-BFQ_ Flexible Block Floating-Point Quantization Accelerator for LLMs\figure_2_page3.png
2025-11-09 01:41:48,191 - INFO - root - 成功添加图片 3：./export\images_F-BFQ_ Flexible Block Floating-Point Quantization Accelerator for LLMs\figure_3_page2.png
2025-11-09 01:41:48,197 - INFO - root - 论文《F-BFQ: Flexible Block Floating-Point Quantization Accelerator for LLMs》的分析已保存到 ./export\F-BFQ_ Flexible Block Floating-Point Quantization Accelerator for LLMs.md
2025-11-09 01:41:48,204 - INFO - root - 正在总结论文 5/30: Computationally Efficient Neural Receivers via Axial Self-Attention
2025-11-09 01:41:56,029 - INFO - root - LLMClient: rate limit reached, sleeping 30.6s
2025-11-09 01:43:18,247 - INFO - root - 正在提取论文图片...
2025-11-09 01:43:19,213 - INFO - root - 已保存图片 1/10：./export\images_Computationally Efficient Neural Receivers via Axial Self-Attention\figure_1_page5.png
2025-11-09 01:43:19,215 - INFO - root - 成功添加图片 1：./export\images_Computationally Efficient Neural Receivers via Axial Self-Attention\figure_1_page5.png
2025-11-09 01:43:19,222 - INFO - root - 论文《Computationally Efficient Neural Receivers via Axial Self-Attention》的分析已保存到 ./export\Computationally Efficient Neural Receivers via Axial Self-Attention.md
2025-11-09 01:43:19,222 - INFO - root - 正在总结论文 6/30: Efficient In-Memory Acceleration of Sparse Block Diagonal LLMs
2025-11-09 01:43:19,229 - INFO - root - LLMClient: rate limit reached, sleeping 7.4s
2025-11-09 01:43:37,171 - INFO - root - LLMClient: rate limit reached, sleeping 22.5s
2025-11-09 01:44:49,455 - INFO - root - 正在提取论文图片...
2025-11-09 01:44:49,522 - INFO - root - 已保存图片 1/10：./export\images_Efficient In-Memory Acceleration of Sparse Block Diagonal LLMs\figure_1_page3.png
2025-11-09 01:44:49,560 - INFO - root - 已保存图片 2/10：./export\images_Efficient In-Memory Acceleration of Sparse Block Diagonal LLMs\figure_2_page3.png
2025-11-09 01:44:49,671 - INFO - root - 已保存图片 3/10：./export\images_Efficient In-Memory Acceleration of Sparse Block Diagonal LLMs\figure_3_page3.png
2025-11-09 01:44:49,671 - INFO - root - 成功添加图片 1：./export\images_Efficient In-Memory Acceleration of Sparse Block Diagonal LLMs\figure_1_page3.png
2025-11-09 01:44:49,671 - INFO - root - 成功添加图片 2：./export\images_Efficient In-Memory Acceleration of Sparse Block Diagonal LLMs\figure_2_page3.png
2025-11-09 01:44:49,671 - INFO - root - 成功添加图片 3：./export\images_Efficient In-Memory Acceleration of Sparse Block Diagonal LLMs\figure_3_page3.png
2025-11-09 01:44:49,671 - INFO - root - 论文《Efficient In-Memory Acceleration of Sparse Block Diagonal LLMs》的分析已保存到 ./export\Efficient In-Memory Acceleration of Sparse Block Diagonal LLMs.md
2025-11-09 01:44:49,684 - INFO - root - 正在总结论文 7/30: Dissecting Transformers: A CLEAR Perspective towards Green AI
2025-11-09 01:44:49,685 - INFO - root - LLMClient: rate limit reached, sleeping 10.0s
2025-11-09 01:45:09,772 - INFO - root - LLMClient: rate limit reached, sleeping 19.1s
2025-11-09 09:31:54,038 - ERROR - root - LLMClient: generation error: 504 Deadline Exceeded
Traceback (most recent call last):
  File "D:\ChatPaper\llm_client.py", line 117, in generate
    resp = self.model.generate_content(prompt, safety_settings=self.safety_settings)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\google\generativeai\generative_models.py", line 331, in generate_content
    response = self._client.generate_content(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\google\ai\generativelanguage_v1beta\services\generative_service\client.py", line 835, in generate_content
    response = rpc(
               ^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\google\api_core\gapic_v1\method.py", line 131, in __call__
    return wrapped_func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 294, in retry_wrapped_func
    return retry_target(
           ^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 156, in retry_target
    next_sleep = _retry_error_helper(
                 ^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\google\api_core\retry\retry_base.py", line 214, in _retry_error_helper
    raise final_exc from source_exc
  File "D:\ChatPaper\.venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 147, in retry_target
    result = target()
             ^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\google\api_core\timeout.py", line 130, in func_with_timeout
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\google\api_core\grpc_helpers.py", line 77, in error_remapped_callable
    raise exceptions.from_grpc_error(exc) from exc
google.api_core.exceptions.DeadlineExceeded: 504 Deadline Exceeded
2025-11-09 09:32:55,151 - INFO - root - LLMClient: retry attempt 2 for generation
2025-11-09 09:33:40,009 - INFO - root - 正在提取论文图片...
2025-11-09 09:33:40,070 - WARNING - root - 处理页面 19 的图片 1 时出错：Image size (360000000 pixels) exceeds limit of 178956970 pixels, could be decompression bomb DOS attack.
2025-11-09 09:33:40,180 - INFO - root - 已保存图片 1/10：./export\images_Dissecting Transformers_ A CLEAR Perspective towards Green AI\figure_1_page3.png
2025-11-09 09:33:40,254 - INFO - root - 已保存图片 2/10：./export\images_Dissecting Transformers_ A CLEAR Perspective towards Green AI\figure_2_page3.png
2025-11-09 09:33:40,317 - INFO - root - 已保存图片 3/10：./export\images_Dissecting Transformers_ A CLEAR Perspective towards Green AI\figure_3_page3.png
2025-11-09 09:33:40,398 - INFO - root - 已保存图片 4/10：./export\images_Dissecting Transformers_ A CLEAR Perspective towards Green AI\figure_4_page3.png
2025-11-09 09:33:40,475 - INFO - root - 已保存图片 5/10：./export\images_Dissecting Transformers_ A CLEAR Perspective towards Green AI\figure_5_page3.png
2025-11-09 09:33:40,475 - INFO - root - 成功添加图片 1：./export\images_Dissecting Transformers_ A CLEAR Perspective towards Green AI\figure_1_page3.png
2025-11-09 09:33:40,475 - INFO - root - 成功添加图片 2：./export\images_Dissecting Transformers_ A CLEAR Perspective towards Green AI\figure_2_page3.png
2025-11-09 09:33:40,475 - INFO - root - 成功添加图片 3：./export\images_Dissecting Transformers_ A CLEAR Perspective towards Green AI\figure_3_page3.png
2025-11-09 09:33:40,475 - INFO - root - 成功添加图片 4：./export\images_Dissecting Transformers_ A CLEAR Perspective towards Green AI\figure_4_page3.png
2025-11-09 09:33:40,475 - INFO - root - 成功添加图片 5：./export\images_Dissecting Transformers_ A CLEAR Perspective towards Green AI\figure_5_page3.png
2025-11-09 09:33:40,482 - INFO - root - 论文《Dissecting Transformers: A CLEAR Perspective towards Green AI》的分析已保存到 ./export\Dissecting Transformers_ A CLEAR Perspective towards Green AI.md
2025-11-09 09:33:40,490 - INFO - root - 正在总结论文 8/30: Microscaling Floating Point Formats for Large Language Models
2025-11-09 09:33:40,490 - INFO - root - LLMClient: rate limit reached, sleeping 14.7s
2025-11-09 09:34:05,948 - INFO - root - LLMClient: rate limit reached, sleeping 16.8s
2025-11-09 09:34:49,182 - INFO - root - LLMClient: rate limit reached, sleeping 6.0s
2025-11-09 09:35:12,373 - INFO - root - 正在提取论文图片...
2025-11-09 09:35:12,402 - INFO - root - 论文《Microscaling Floating Point Formats for Large Language Models》的分析已保存到 ./export\Microscaling Floating Point Formats for Large Language Models.md
2025-11-09 09:35:12,406 - INFO - root - 正在总结论文 9/30: Automated and Scalable SEM Image Analysis of Perovskite Solar Cell Materials via a Deep Segmentation Framework
2025-11-09 09:35:12,414 - INFO - root - LLMClient: rate limit reached, sleeping 10.4s
2025-11-09 09:35:31,867 - INFO - root - LLMClient: rate limit reached, sleeping 23.3s
2025-11-09 09:36:20,645 - INFO - root - LLMClient: rate limit reached, sleeping 2.1s
2025-11-09 09:36:42,880 - INFO - root - 正在提取论文图片...
2025-11-09 09:37:17,872 - INFO - root - 已保存图片 1/10：./export\images_Automated and Scalable SEM Image Analysis of Perovskite Solar Cell Materials via\figure_1_page8.jpeg
2025-11-09 09:37:18,126 - INFO - root - 已保存图片 2/10：./export\images_Automated and Scalable SEM Image Analysis of Perovskite Solar Cell Materials via\figure_2_page5.jpeg
2025-11-09 09:37:18,414 - INFO - root - 已保存图片 3/10：./export\images_Automated and Scalable SEM Image Analysis of Perovskite Solar Cell Materials via\figure_3_page9.jpeg
2025-11-09 09:37:18,633 - INFO - root - 已保存图片 4/10：./export\images_Automated and Scalable SEM Image Analysis of Perovskite Solar Cell Materials via\figure_4_page9.jpeg
2025-11-09 09:37:18,850 - INFO - root - 已保存图片 5/10：./export\images_Automated and Scalable SEM Image Analysis of Perovskite Solar Cell Materials via\figure_5_page9.jpeg
2025-11-09 09:37:19,059 - INFO - root - 已保存图片 6/10：./export\images_Automated and Scalable SEM Image Analysis of Perovskite Solar Cell Materials via\figure_6_page9.jpeg
2025-11-09 09:37:19,336 - INFO - root - 已保存图片 7/10：./export\images_Automated and Scalable SEM Image Analysis of Perovskite Solar Cell Materials via\figure_7_page9.jpeg
2025-11-09 09:37:19,590 - INFO - root - 已保存图片 8/10：./export\images_Automated and Scalable SEM Image Analysis of Perovskite Solar Cell Materials via\figure_8_page9.jpeg
2025-11-09 09:37:19,794 - INFO - root - 已保存图片 9/10：./export\images_Automated and Scalable SEM Image Analysis of Perovskite Solar Cell Materials via\figure_9_page9.jpeg
2025-11-09 09:37:20,022 - INFO - root - 已保存图片 10/10：./export\images_Automated and Scalable SEM Image Analysis of Perovskite Solar Cell Materials via\figure_10_page9.jpeg
2025-11-09 09:37:20,055 - INFO - root - 成功添加图片 1：./export\images_Automated and Scalable SEM Image Analysis of Perovskite Solar Cell Materials via\figure_1_page8.jpeg
2025-11-09 09:37:20,055 - INFO - root - 成功添加图片 2：./export\images_Automated and Scalable SEM Image Analysis of Perovskite Solar Cell Materials via\figure_2_page5.jpeg
2025-11-09 09:37:20,055 - INFO - root - 成功添加图片 3：./export\images_Automated and Scalable SEM Image Analysis of Perovskite Solar Cell Materials via\figure_3_page9.jpeg
2025-11-09 09:37:20,055 - INFO - root - 成功添加图片 4：./export\images_Automated and Scalable SEM Image Analysis of Perovskite Solar Cell Materials via\figure_4_page9.jpeg
2025-11-09 09:37:20,055 - INFO - root - 成功添加图片 5：./export\images_Automated and Scalable SEM Image Analysis of Perovskite Solar Cell Materials via\figure_5_page9.jpeg
2025-11-09 09:37:20,055 - INFO - root - 成功添加图片 6：./export\images_Automated and Scalable SEM Image Analysis of Perovskite Solar Cell Materials via\figure_6_page9.jpeg
2025-11-09 09:37:20,055 - INFO - root - 成功添加图片 7：./export\images_Automated and Scalable SEM Image Analysis of Perovskite Solar Cell Materials via\figure_7_page9.jpeg
2025-11-09 09:37:20,055 - INFO - root - 成功添加图片 8：./export\images_Automated and Scalable SEM Image Analysis of Perovskite Solar Cell Materials via\figure_8_page9.jpeg
2025-11-09 09:37:20,055 - INFO - root - 成功添加图片 9：./export\images_Automated and Scalable SEM Image Analysis of Perovskite Solar Cell Materials via\figure_9_page9.jpeg
2025-11-09 09:37:20,055 - INFO - root - 成功添加图片 10：./export\images_Automated and Scalable SEM Image Analysis of Perovskite Solar Cell Materials via\figure_10_page9.jpeg
2025-11-09 09:37:20,063 - INFO - root - 论文《Automated and Scalable SEM Image Analysis of Perovskite Solar Cell Materials via a Deep Segmentation Framework》的分析已保存到 ./export\Automated and Scalable SEM Image Analysis of Perovskite Solar Cell Materials via.md
2025-11-09 09:37:20,067 - INFO - root - 正在总结论文 10/30: AMLA: MUL by ADD in FlashAttention Rescaling
2025-11-09 09:38:03,534 - INFO - root - LLMClient: rate limit reached, sleeping 16.5s
2025-11-09 09:38:39,999 - INFO - root - 正在提取论文图片...
2025-11-09 09:38:40,977 - INFO - root - 已保存图片 1/10：./export\images_AMLA_ MUL by ADD in FlashAttention Rescaling\figure_1_page15.png
2025-11-09 09:38:41,030 - INFO - root - 已保存图片 2/10：./export\images_AMLA_ MUL by ADD in FlashAttention Rescaling\figure_2_page4.jpeg
2025-11-09 09:38:41,059 - INFO - root - 已保存图片 3/10：./export\images_AMLA_ MUL by ADD in FlashAttention Rescaling\figure_3_page8.jpeg
2025-11-09 09:38:41,077 - INFO - root - 成功添加图片 1：./export\images_AMLA_ MUL by ADD in FlashAttention Rescaling\figure_1_page15.png
2025-11-09 09:38:41,077 - INFO - root - 成功添加图片 2：./export\images_AMLA_ MUL by ADD in FlashAttention Rescaling\figure_2_page4.jpeg
2025-11-09 09:38:41,078 - INFO - root - 成功添加图片 3：./export\images_AMLA_ MUL by ADD in FlashAttention Rescaling\figure_3_page8.jpeg
2025-11-09 09:38:41,082 - INFO - root - 论文《AMLA: MUL by ADD in FlashAttention Rescaling》的分析已保存到 ./export\AMLA_ MUL by ADD in FlashAttention Rescaling.md
2025-11-09 09:38:41,086 - INFO - root - 正在总结论文 11/30: Pretraining Large Language Models with NVFP4
2025-11-09 09:38:51,473 - INFO - root - LLMClient: rate limit reached, sleeping 28.6s
2025-11-09 09:40:00,161 - INFO - root - 正在提取论文图片...
2025-11-09 09:40:00,308 - INFO - root - 已保存图片 1/10：./export\images_Pretraining Large Language Models with NVFP4\figure_1_page7.png
2025-11-09 09:40:00,337 - INFO - root - 已保存图片 2/10：./export\images_Pretraining Large Language Models with NVFP4\figure_2_page7.jpeg
2025-11-09 09:40:00,356 - INFO - root - 已保存图片 3/10：./export\images_Pretraining Large Language Models with NVFP4\figure_3_page1.png
2025-11-09 09:40:00,378 - INFO - root - 已保存图片 4/10：./export\images_Pretraining Large Language Models with NVFP4\figure_4_page7.jpeg
2025-11-09 09:40:00,398 - INFO - root - 已保存图片 5/10：./export\images_Pretraining Large Language Models with NVFP4\figure_5_page7.jpeg
2025-11-09 09:40:00,422 - INFO - root - 已保存图片 6/10：./export\images_Pretraining Large Language Models with NVFP4\figure_6_page7.jpeg
2025-11-09 09:40:00,440 - INFO - root - 已保存图片 7/10：./export\images_Pretraining Large Language Models with NVFP4\figure_7_page7.png
2025-11-09 09:40:00,472 - INFO - root - 已保存图片 8/10：./export\images_Pretraining Large Language Models with NVFP4\figure_8_page7.jpeg
2025-11-09 09:40:00,487 - INFO - root - 已保存图片 9/10：./export\images_Pretraining Large Language Models with NVFP4\figure_9_page7.jpeg
2025-11-09 09:40:00,532 - INFO - root - 已保存图片 10/10：./export\images_Pretraining Large Language Models with NVFP4\figure_10_page7.jpeg
2025-11-09 09:40:00,535 - INFO - root - 成功添加图片 1：./export\images_Pretraining Large Language Models with NVFP4\figure_1_page7.png
2025-11-09 09:40:00,535 - INFO - root - 成功添加图片 2：./export\images_Pretraining Large Language Models with NVFP4\figure_2_page7.jpeg
2025-11-09 09:40:00,535 - INFO - root - 成功添加图片 3：./export\images_Pretraining Large Language Models with NVFP4\figure_3_page1.png
2025-11-09 09:40:00,535 - INFO - root - 成功添加图片 4：./export\images_Pretraining Large Language Models with NVFP4\figure_4_page7.jpeg
2025-11-09 09:40:00,535 - INFO - root - 成功添加图片 5：./export\images_Pretraining Large Language Models with NVFP4\figure_5_page7.jpeg
2025-11-09 09:40:00,535 - INFO - root - 成功添加图片 6：./export\images_Pretraining Large Language Models with NVFP4\figure_6_page7.jpeg
2025-11-09 09:40:00,535 - INFO - root - 成功添加图片 7：./export\images_Pretraining Large Language Models with NVFP4\figure_7_page7.png
2025-11-09 09:40:00,535 - INFO - root - 成功添加图片 8：./export\images_Pretraining Large Language Models with NVFP4\figure_8_page7.jpeg
2025-11-09 09:40:00,535 - INFO - root - 成功添加图片 9：./export\images_Pretraining Large Language Models with NVFP4\figure_9_page7.jpeg
2025-11-09 09:40:00,535 - INFO - root - 成功添加图片 10：./export\images_Pretraining Large Language Models with NVFP4\figure_10_page7.jpeg
2025-11-09 09:40:00,543 - INFO - root - 论文《Pretraining Large Language Models with NVFP4》的分析已保存到 ./export\Pretraining Large Language Models with NVFP4.md
2025-11-09 09:40:00,543 - INFO - root - 正在总结论文 12/30: Bridging the Gap Between Promise and Performance for Microscaling FP4 Quantization
2025-11-09 09:40:00,543 - INFO - root - LLMClient: rate limit reached, sleeping 19.5s
2025-11-09 09:40:28,694 - INFO - root - LLMClient: rate limit reached, sleeping 13.9s
2025-11-09 09:41:10,576 - INFO - root - LLMClient: rate limit reached, sleeping 9.5s
2025-11-09 09:41:40,505 - INFO - root - 正在提取论文图片...
2025-11-09 09:41:40,613 - INFO - root - 已保存图片 1/10：./export\images_Bridging the Gap Between Promise and Performance for Microscaling FP4 Quantizati\figure_1_page25.png
2025-11-09 09:41:40,615 - INFO - root - 成功添加图片 1：./export\images_Bridging the Gap Between Promise and Performance for Microscaling FP4 Quantizati\figure_1_page25.png
2025-11-09 09:41:40,619 - INFO - root - 论文《Bridging the Gap Between Promise and Performance for Microscaling FP4 Quantization》的分析已保存到 ./export\Bridging the Gap Between Promise and Performance for Microscaling FP4 Quantizati.md
2025-11-09 09:41:40,631 - INFO - root - 正在总结论文 13/30: Towards Verified Compilation of Floating-point Optimization in Scientific Computing Programs
2025-11-09 09:41:40,635 - INFO - root - LLMClient: rate limit reached, sleeping 1.9s
2025-11-09 09:41:51,136 - INFO - root - LLMClient: rate limit reached, sleeping 28.9s
2025-11-09 09:43:15,225 - INFO - root - 正在提取论文图片...
2025-11-09 09:43:15,235 - INFO - root - 论文《Towards Verified Compilation of Floating-point Optimization in Scientific Computing Programs》的分析已保存到 ./export\Towards Verified Compilation of Floating-point Optimization in Scientific Comput.md
2025-11-09 09:43:15,242 - INFO - root - 正在总结论文 14/30: Green Learning for STAR-RIS mmWave Systems with Implicit CSI
2025-11-09 09:43:15,246 - INFO - root - LLMClient: rate limit reached, sleeping 4.8s
2025-11-09 09:43:29,726 - INFO - root - LLMClient: rate limit reached, sleeping 25.1s
2025-11-09 09:44:20,033 - INFO - root - LLMClient: rate limit reached, sleeping 0.0s
2025-11-09 09:44:39,745 - INFO - root - 正在提取论文图片...
2025-11-09 09:44:39,853 - INFO - root - 已保存图片 1/10：./export\images_Green Learning for STAR-RIS mmWave Systems with Implicit CSI\figure_1_page2.jpeg
2025-11-09 09:44:39,931 - INFO - root - 已保存图片 2/10：./export\images_Green Learning for STAR-RIS mmWave Systems with Implicit CSI\figure_2_page2.png
2025-11-09 09:44:39,987 - INFO - root - 已保存图片 3/10：./export\images_Green Learning for STAR-RIS mmWave Systems with Implicit CSI\figure_3_page2.png
2025-11-09 09:44:40,042 - INFO - root - 已保存图片 4/10：./export\images_Green Learning for STAR-RIS mmWave Systems with Implicit CSI\figure_4_page2.png
2025-11-09 09:44:40,044 - INFO - root - 成功添加图片 1：./export\images_Green Learning for STAR-RIS mmWave Systems with Implicit CSI\figure_1_page2.jpeg
2025-11-09 09:44:40,044 - INFO - root - 成功添加图片 2：./export\images_Green Learning for STAR-RIS mmWave Systems with Implicit CSI\figure_2_page2.png
2025-11-09 09:44:40,045 - INFO - root - 成功添加图片 3：./export\images_Green Learning for STAR-RIS mmWave Systems with Implicit CSI\figure_3_page2.png
2025-11-09 09:44:40,045 - INFO - root - 成功添加图片 4：./export\images_Green Learning for STAR-RIS mmWave Systems with Implicit CSI\figure_4_page2.png
2025-11-09 09:44:40,048 - INFO - root - 论文《Green Learning for STAR-RIS mmWave Systems with Implicit CSI》的分析已保存到 ./export\Green Learning for STAR-RIS mmWave Systems with Implicit CSI.md
2025-11-09 09:44:40,055 - INFO - root - 正在总结论文 15/30: A Compute&Memory Efficient Model-Driven Neural 5G Receiver for Edge AI-assisted RAN
2025-11-09 09:44:40,055 - INFO - root - LLMClient: rate limit reached, sleeping 14.7s
2025-11-09 09:45:05,784 - INFO - root - LLMClient: rate limit reached, sleeping 14.3s
2025-11-09 09:45:47,148 - INFO - root - LLMClient: rate limit reached, sleeping 7.6s
2025-11-09 09:46:13,321 - INFO - root - 正在提取论文图片...
2025-11-09 09:46:14,102 - INFO - root - 已保存图片 1/10：./export\images_A Compute&Memory Efficient Model-Driven Neural 5G Receiver for Edge AI-assisted\figure_1_page6.png
2025-11-09 09:46:14,216 - INFO - root - 已保存图片 2/10：./export\images_A Compute&Memory Efficient Model-Driven Neural 5G Receiver for Edge AI-assisted\figure_2_page6.png
2025-11-09 09:46:14,299 - INFO - root - 已保存图片 3/10：./export\images_A Compute&Memory Efficient Model-Driven Neural 5G Receiver for Edge AI-assisted\figure_3_page2.png
2025-11-09 09:46:14,351 - INFO - root - 已保存图片 4/10：./export\images_A Compute&Memory Efficient Model-Driven Neural 5G Receiver for Edge AI-assisted\figure_4_page2.png
2025-11-09 09:46:14,398 - INFO - root - 已保存图片 5/10：./export\images_A Compute&Memory Efficient Model-Driven Neural 5G Receiver for Edge AI-assisted\figure_5_page3.png
2025-11-09 09:46:14,401 - INFO - root - 成功添加图片 1：./export\images_A Compute&Memory Efficient Model-Driven Neural 5G Receiver for Edge AI-assisted\figure_1_page6.png
2025-11-09 09:46:14,401 - INFO - root - 成功添加图片 2：./export\images_A Compute&Memory Efficient Model-Driven Neural 5G Receiver for Edge AI-assisted\figure_2_page6.png
2025-11-09 09:46:14,401 - INFO - root - 成功添加图片 3：./export\images_A Compute&Memory Efficient Model-Driven Neural 5G Receiver for Edge AI-assisted\figure_3_page2.png
2025-11-09 09:46:14,401 - INFO - root - 成功添加图片 4：./export\images_A Compute&Memory Efficient Model-Driven Neural 5G Receiver for Edge AI-assisted\figure_4_page2.png
2025-11-09 09:46:14,401 - INFO - root - 成功添加图片 5：./export\images_A Compute&Memory Efficient Model-Driven Neural 5G Receiver for Edge AI-assisted\figure_5_page3.png
2025-11-09 09:46:14,401 - INFO - root - 论文《A Compute&Memory Efficient Model-Driven Neural 5G Receiver for Edge AI-assisted RAN》的分析已保存到 ./export\A Compute&Memory Efficient Model-Driven Neural 5G Receiver for Edge AI-assisted.md
2025-11-09 09:46:14,413 - INFO - root - 正在总结论文 16/30: SNNSIR: A Simple Spiking Neural Network for Stereo Image Restoration
2025-11-09 09:46:14,414 - INFO - root - LLMClient: rate limit reached, sleeping 5.7s
2025-11-09 09:46:28,571 - INFO - root - LLMClient: rate limit reached, sleeping 26.2s
2025-11-09 09:47:42,531 - INFO - root - 正在提取论文图片...
2025-11-09 09:47:47,298 - INFO - root - 已保存图片 1/10：./export\images_SNNSIR_ A Simple Spiking Neural Network for Stereo Image Restoration\figure_1_page8.jpeg
2025-11-09 09:47:47,342 - INFO - root - 已保存图片 2/10：./export\images_SNNSIR_ A Simple Spiking Neural Network for Stereo Image Restoration\figure_2_page7.jpeg
2025-11-09 09:47:47,388 - INFO - root - 已保存图片 3/10：./export\images_SNNSIR_ A Simple Spiking Neural Network for Stereo Image Restoration\figure_3_page7.jpeg
2025-11-09 09:47:47,418 - INFO - root - 已保存图片 4/10：./export\images_SNNSIR_ A Simple Spiking Neural Network for Stereo Image Restoration\figure_4_page7.jpeg
2025-11-09 09:47:47,447 - INFO - root - 已保存图片 5/10：./export\images_SNNSIR_ A Simple Spiking Neural Network for Stereo Image Restoration\figure_5_page7.jpeg
2025-11-09 09:47:47,576 - INFO - root - 已保存图片 6/10：./export\images_SNNSIR_ A Simple Spiking Neural Network for Stereo Image Restoration\figure_6_page8.png
2025-11-09 09:47:47,711 - INFO - root - 已保存图片 7/10：./export\images_SNNSIR_ A Simple Spiking Neural Network for Stereo Image Restoration\figure_7_page8.png
2025-11-09 09:47:47,837 - INFO - root - 已保存图片 8/10：./export\images_SNNSIR_ A Simple Spiking Neural Network for Stereo Image Restoration\figure_8_page8.png
2025-11-09 09:47:47,970 - INFO - root - 已保存图片 9/10：./export\images_SNNSIR_ A Simple Spiking Neural Network for Stereo Image Restoration\figure_9_page8.png
2025-11-09 09:47:48,087 - INFO - root - 已保存图片 10/10：./export\images_SNNSIR_ A Simple Spiking Neural Network for Stereo Image Restoration\figure_10_page8.png
2025-11-09 09:47:48,104 - INFO - root - 成功添加图片 1：./export\images_SNNSIR_ A Simple Spiking Neural Network for Stereo Image Restoration\figure_1_page8.jpeg
2025-11-09 09:47:48,104 - INFO - root - 成功添加图片 2：./export\images_SNNSIR_ A Simple Spiking Neural Network for Stereo Image Restoration\figure_2_page7.jpeg
2025-11-09 09:47:48,104 - INFO - root - 成功添加图片 3：./export\images_SNNSIR_ A Simple Spiking Neural Network for Stereo Image Restoration\figure_3_page7.jpeg
2025-11-09 09:47:48,104 - INFO - root - 成功添加图片 4：./export\images_SNNSIR_ A Simple Spiking Neural Network for Stereo Image Restoration\figure_4_page7.jpeg
2025-11-09 09:47:48,104 - INFO - root - 成功添加图片 5：./export\images_SNNSIR_ A Simple Spiking Neural Network for Stereo Image Restoration\figure_5_page7.jpeg
2025-11-09 09:47:48,104 - INFO - root - 成功添加图片 6：./export\images_SNNSIR_ A Simple Spiking Neural Network for Stereo Image Restoration\figure_6_page8.png
2025-11-09 09:47:48,104 - INFO - root - 成功添加图片 7：./export\images_SNNSIR_ A Simple Spiking Neural Network for Stereo Image Restoration\figure_7_page8.png
2025-11-09 09:47:48,104 - INFO - root - 成功添加图片 8：./export\images_SNNSIR_ A Simple Spiking Neural Network for Stereo Image Restoration\figure_8_page8.png
2025-11-09 09:47:48,104 - INFO - root - 成功添加图片 9：./export\images_SNNSIR_ A Simple Spiking Neural Network for Stereo Image Restoration\figure_9_page8.png
2025-11-09 09:47:48,104 - INFO - root - 成功添加图片 10：./export\images_SNNSIR_ A Simple Spiking Neural Network for Stereo Image Restoration\figure_10_page8.png
2025-11-09 09:47:48,112 - INFO - root - 论文《SNNSIR: A Simple Spiking Neural Network for Stereo Image Restoration》的分析已保存到 ./export\SNNSIR_ A Simple Spiking Neural Network for Stereo Image Restoration.md
2025-11-09 09:47:48,121 - INFO - root - 正在总结论文 17/30: SpikeSTAG: Spatial-Temporal Forecasting via GNN-SNN Collaboration
2025-11-09 09:47:48,121 - INFO - root - LLMClient: rate limit reached, sleeping 6.7s
2025-11-09 09:48:05,407 - INFO - root - LLMClient: rate limit reached, sleeping 17.7s
2025-11-09 09:48:48,016 - INFO - root - LLMClient: rate limit reached, sleeping 6.8s
2025-11-09 09:49:14,621 - INFO - root - 正在提取论文图片...
2025-11-09 09:49:15,026 - INFO - root - 已保存图片 1/10：./export\images_SpikeSTAG_ Spatial-Temporal Forecasting via GNN-SNN Collaboration\figure_1_page4.png
2025-11-09 09:49:15,087 - INFO - root - 已保存图片 2/10：./export\images_SpikeSTAG_ Spatial-Temporal Forecasting via GNN-SNN Collaboration\figure_2_page2.png
2025-11-09 09:49:15,163 - INFO - root - 已保存图片 3/10：./export\images_SpikeSTAG_ Spatial-Temporal Forecasting via GNN-SNN Collaboration\figure_3_page7.png
2025-11-09 09:49:15,233 - INFO - root - 已保存图片 4/10：./export\images_SpikeSTAG_ Spatial-Temporal Forecasting via GNN-SNN Collaboration\figure_4_page4.png
2025-11-09 09:49:15,237 - INFO - root - 成功添加图片 1：./export\images_SpikeSTAG_ Spatial-Temporal Forecasting via GNN-SNN Collaboration\figure_1_page4.png
2025-11-09 09:49:15,237 - INFO - root - 成功添加图片 2：./export\images_SpikeSTAG_ Spatial-Temporal Forecasting via GNN-SNN Collaboration\figure_2_page2.png
2025-11-09 09:49:15,237 - INFO - root - 成功添加图片 3：./export\images_SpikeSTAG_ Spatial-Temporal Forecasting via GNN-SNN Collaboration\figure_3_page7.png
2025-11-09 09:49:15,237 - INFO - root - 成功添加图片 4：./export\images_SpikeSTAG_ Spatial-Temporal Forecasting via GNN-SNN Collaboration\figure_4_page4.png
2025-11-09 09:49:15,243 - INFO - root - 论文《SpikeSTAG: Spatial-Temporal Forecasting via GNN-SNN Collaboration》的分析已保存到 ./export\SpikeSTAG_ Spatial-Temporal Forecasting via GNN-SNN Collaboration.md
2025-11-09 09:49:15,254 - INFO - root - 正在总结论文 18/30: DGEMM without FP64 Arithmetic - Using FP64 Emulation and FP8 Tensor Cores with Ozaki Scheme
2025-11-09 09:49:15,257 - INFO - root - LLMClient: rate limit reached, sleeping 7.8s
2025-11-09 09:49:32,140 - INFO - root - LLMClient: rate limit reached, sleeping 22.6s
2025-11-09 09:50:22,400 - INFO - root - LLMClient: rate limit reached, sleeping 0.7s
2025-11-09 09:50:42,963 - INFO - root - 正在提取论文图片...
2025-11-09 09:50:42,976 - INFO - root - 论文《DGEMM without FP64 Arithmetic - Using FP64 Emulation and FP8 Tensor Cores with Ozaki Scheme》的分析已保存到 ./export\DGEMM without FP64 Arithmetic - Using FP64 Emulation and FP8 Tensor Cores with O.md
2025-11-09 09:50:42,979 - INFO - root - 正在总结论文 19/30: Scaling Probabilistic Circuits via Monarch Matrices
2025-11-09 09:50:42,985 - INFO - root - LLMClient: rate limit reached, sleeping 11.8s
2025-11-09 09:51:03,291 - INFO - root - LLMClient: rate limit reached, sleeping 19.8s
2025-11-09 09:51:48,985 - INFO - root - LLMClient: rate limit reached, sleeping 5.8s
2025-11-09 09:52:13,915 - INFO - root - 正在提取论文图片...
2025-11-09 09:52:14,011 - INFO - root - 已保存图片 1/10：./export\images_Scaling Probabilistic Circuits via Monarch Matrices\figure_1_page5.png
2025-11-09 09:52:14,075 - INFO - root - 已保存图片 2/10：./export\images_Scaling Probabilistic Circuits via Monarch Matrices\figure_2_page5.png
2025-11-09 09:52:14,132 - INFO - root - 已保存图片 3/10：./export\images_Scaling Probabilistic Circuits via Monarch Matrices\figure_3_page5.png
2025-11-09 09:52:14,193 - INFO - root - 已保存图片 4/10：./export\images_Scaling Probabilistic Circuits via Monarch Matrices\figure_4_page5.png
2025-11-09 09:52:14,253 - INFO - root - 已保存图片 5/10：./export\images_Scaling Probabilistic Circuits via Monarch Matrices\figure_5_page13.png
2025-11-09 09:52:14,319 - INFO - root - 已保存图片 6/10：./export\images_Scaling Probabilistic Circuits via Monarch Matrices\figure_6_page13.png
2025-11-09 09:52:14,379 - INFO - root - 已保存图片 7/10：./export\images_Scaling Probabilistic Circuits via Monarch Matrices\figure_7_page13.png
2025-11-09 09:52:14,429 - INFO - root - 已保存图片 8/10：./export\images_Scaling Probabilistic Circuits via Monarch Matrices\figure_8_page13.png
2025-11-09 09:52:14,429 - INFO - root - 成功添加图片 1：./export\images_Scaling Probabilistic Circuits via Monarch Matrices\figure_1_page5.png
2025-11-09 09:52:14,429 - INFO - root - 成功添加图片 2：./export\images_Scaling Probabilistic Circuits via Monarch Matrices\figure_2_page5.png
2025-11-09 09:52:14,429 - INFO - root - 成功添加图片 3：./export\images_Scaling Probabilistic Circuits via Monarch Matrices\figure_3_page5.png
2025-11-09 09:52:14,429 - INFO - root - 成功添加图片 4：./export\images_Scaling Probabilistic Circuits via Monarch Matrices\figure_4_page5.png
2025-11-09 09:52:14,442 - INFO - root - 成功添加图片 5：./export\images_Scaling Probabilistic Circuits via Monarch Matrices\figure_5_page13.png
2025-11-09 09:52:14,442 - INFO - root - 成功添加图片 6：./export\images_Scaling Probabilistic Circuits via Monarch Matrices\figure_6_page13.png
2025-11-09 09:52:14,442 - INFO - root - 成功添加图片 7：./export\images_Scaling Probabilistic Circuits via Monarch Matrices\figure_7_page13.png
2025-11-09 09:52:14,442 - INFO - root - 成功添加图片 8：./export\images_Scaling Probabilistic Circuits via Monarch Matrices\figure_8_page13.png
2025-11-09 09:52:14,447 - INFO - root - 论文《Scaling Probabilistic Circuits via Monarch Matrices》的分析已保存到 ./export\Scaling Probabilistic Circuits via Monarch Matrices.md
2025-11-09 09:52:14,458 - INFO - root - 正在总结论文 20/30: Starting Positions Matter: A Study on Better Weight Initialization for Neural Network Quantization
2025-11-09 09:52:14,461 - INFO - root - LLMClient: rate limit reached, sleeping 8.6s
2025-11-09 09:52:32,733 - INFO - root - LLMClient: rate limit reached, sleeping 22.1s
2025-11-09 09:53:43,563 - INFO - root - 正在提取论文图片...
2025-11-09 09:53:44,074 - INFO - root - 已保存图片 1/10：./export\images_Starting Positions Matter_ A Study on Better Weight Initialization for Neural Ne\figure_1_page10.png
2025-11-09 09:53:44,111 - INFO - root - 已保存图片 2/10：./export\images_Starting Positions Matter_ A Study on Better Weight Initialization for Neural Ne\figure_2_page5.png
2025-11-09 09:53:44,215 - INFO - root - 已保存图片 3/10：./export\images_Starting Positions Matter_ A Study on Better Weight Initialization for Neural Ne\figure_3_page7.png
2025-11-09 09:53:44,295 - INFO - root - 已保存图片 4/10：./export\images_Starting Positions Matter_ A Study on Better Weight Initialization for Neural Ne\figure_4_page7.png
2025-11-09 09:53:44,362 - INFO - root - 已保存图片 5/10：./export\images_Starting Positions Matter_ A Study on Better Weight Initialization for Neural Ne\figure_5_page7.png
2025-11-09 09:53:44,433 - INFO - root - 已保存图片 6/10：./export\images_Starting Positions Matter_ A Study on Better Weight Initialization for Neural Ne\figure_6_page7.png
2025-11-09 09:53:44,500 - INFO - root - 已保存图片 7/10：./export\images_Starting Positions Matter_ A Study on Better Weight Initialization for Neural Ne\figure_7_page9.png
2025-11-09 09:53:44,567 - INFO - root - 已保存图片 8/10：./export\images_Starting Positions Matter_ A Study on Better Weight Initialization for Neural Ne\figure_8_page9.png
2025-11-09 09:53:44,634 - INFO - root - 已保存图片 9/10：./export\images_Starting Positions Matter_ A Study on Better Weight Initialization for Neural Ne\figure_9_page8.png
2025-11-09 09:53:44,701 - INFO - root - 已保存图片 10/10：./export\images_Starting Positions Matter_ A Study on Better Weight Initialization for Neural Ne\figure_10_page8.png
2025-11-09 09:53:44,703 - INFO - root - 成功添加图片 1：./export\images_Starting Positions Matter_ A Study on Better Weight Initialization for Neural Ne\figure_1_page10.png
2025-11-09 09:53:44,703 - INFO - root - 成功添加图片 2：./export\images_Starting Positions Matter_ A Study on Better Weight Initialization for Neural Ne\figure_2_page5.png
2025-11-09 09:53:44,703 - INFO - root - 成功添加图片 3：./export\images_Starting Positions Matter_ A Study on Better Weight Initialization for Neural Ne\figure_3_page7.png
2025-11-09 09:53:44,703 - INFO - root - 成功添加图片 4：./export\images_Starting Positions Matter_ A Study on Better Weight Initialization for Neural Ne\figure_4_page7.png
2025-11-09 09:53:44,703 - INFO - root - 成功添加图片 5：./export\images_Starting Positions Matter_ A Study on Better Weight Initialization for Neural Ne\figure_5_page7.png
2025-11-09 09:53:44,703 - INFO - root - 成功添加图片 6：./export\images_Starting Positions Matter_ A Study on Better Weight Initialization for Neural Ne\figure_6_page7.png
2025-11-09 09:53:44,703 - INFO - root - 成功添加图片 7：./export\images_Starting Positions Matter_ A Study on Better Weight Initialization for Neural Ne\figure_7_page9.png
2025-11-09 09:53:44,703 - INFO - root - 成功添加图片 8：./export\images_Starting Positions Matter_ A Study on Better Weight Initialization for Neural Ne\figure_8_page9.png
2025-11-09 09:53:44,703 - INFO - root - 成功添加图片 9：./export\images_Starting Positions Matter_ A Study on Better Weight Initialization for Neural Ne\figure_9_page8.png
2025-11-09 09:53:44,703 - INFO - root - 成功添加图片 10：./export\images_Starting Positions Matter_ A Study on Better Weight Initialization for Neural Ne\figure_10_page8.png
2025-11-09 09:53:44,710 - INFO - root - 论文《Starting Positions Matter: A Study on Better Weight Initialization for Neural Network Quantization》的分析已保存到 ./export\Starting Positions Matter_ A Study on Better Weight Initialization for Neural Ne.md
2025-11-09 09:53:44,717 - INFO - root - 正在总结论文 21/30: Recipes for Pre-training LLMs with MXFP8
2025-11-09 09:53:44,719 - INFO - root - LLMClient: rate limit reached, sleeping 10.1s
2025-11-09 09:54:05,661 - INFO - root - LLMClient: rate limit reached, sleeping 18.6s
2025-11-09 09:54:50,756 - INFO - root - LLMClient: rate limit reached, sleeping 4.0s
2025-11-09 09:55:13,138 - INFO - root - 正在提取论文图片...
2025-11-09 09:55:13,159 - INFO - root - 论文《Recipes for Pre-training LLMs with MXFP8》的分析已保存到 ./export\Recipes for Pre-training LLMs with MXFP8.md
2025-11-09 09:55:13,166 - INFO - root - 正在总结论文 22/30: FP4 All the Way: Fully Quantized Training of LLMs
2025-11-09 09:55:13,166 - INFO - root - LLMClient: rate limit reached, sleeping 11.1s
2025-11-09 09:55:32,581 - INFO - root - LLMClient: rate limit reached, sleeping 22.2s
2025-11-09 09:56:22,886 - INFO - root - LLMClient: rate limit reached, sleeping 1.3s
2025-11-09 09:56:41,959 - INFO - root - 正在提取论文图片...
2025-11-09 09:56:41,981 - INFO - root - 论文《FP4 All the Way: Fully Quantized Training of LLMs》的分析已保存到 ./export\FP4 All the Way_ Fully Quantized Training of LLMs.md
2025-11-09 09:56:41,981 - INFO - root - 正在总结论文 23/30: Automatic Verification of Floating-Point Accumulation Networks
2025-11-09 09:56:41,981 - INFO - root - LLMClient: rate limit reached, sleeping 12.8s
2025-11-09 09:57:05,462 - INFO - root - LLMClient: rate limit reached, sleeping 18.8s
2025-11-09 09:57:52,739 - INFO - root - LLMClient: rate limit reached, sleeping 2.1s
2025-11-09 09:58:13,141 - INFO - root - 正在提取论文图片...
2025-11-09 09:58:13,169 - INFO - root - 论文《Automatic Verification of Floating-Point Accumulation Networks》的分析已保存到 ./export\Automatic Verification of Floating-Point Accumulation Networks.md
2025-11-09 09:58:13,174 - INFO - root - 正在总结论文 24/30: MXDOTP: A RISC-V ISA Extension for Enabling Microscaling (MX) Floating-Point Dot Products
2025-11-09 09:58:13,176 - INFO - root - LLMClient: rate limit reached, sleeping 11.0s
2025-11-09 09:58:33,881 - INFO - root - LLMClient: rate limit reached, sleeping 20.9s
2025-11-09 09:59:21,837 - INFO - root - LLMClient: rate limit reached, sleeping 2.4s
2025-11-09 09:59:44,166 - INFO - root - 正在提取论文图片...
2025-11-09 09:59:44,188 - INFO - root - 论文《MXDOTP: A RISC-V ISA Extension for Enabling Microscaling (MX) Floating-Point Dot Products》的分析已保存到 ./export\MXDOTP_ A RISC-V ISA Extension for Enabling Microscaling (MX) Floating-Point Dot.md
2025-11-09 09:59:44,195 - INFO - root - 正在总结论文 25/30: Parameter-Efficient Fine-Tuning with Circulant and Diagonal Vectors
2025-11-09 09:59:44,197 - INFO - root - LLMClient: rate limit reached, sleeping 10.6s
2025-11-09 10:00:04,187 - INFO - root - LLMClient: rate limit reached, sleeping 20.1s
2025-11-09 10:01:54,954 - INFO - root - 正在提取论文图片...
2025-11-09 10:01:54,964 - INFO - root - 论文《Parameter-Efficient Fine-Tuning with Circulant and Diagonal Vectors》的分析已保存到 ./export\Parameter-Efficient Fine-Tuning with Circulant and Diagonal Vectors.md
2025-11-09 10:01:54,969 - INFO - root - 正在总结论文 26/30: Silenzio: Secure Non-Interactive Outsourced MLP Training
2025-11-09 10:02:07,552 - INFO - root - LLMClient: rate limit reached, sleeping 29.5s
2025-11-09 10:03:31,905 - INFO - root - 正在提取论文图片...
2025-11-09 10:03:32,162 - INFO - root - 已保存图片 1/10：./export\images_Silenzio_ Secure Non-Interactive Outsourced MLP Training\figure_1_page11.png
2025-11-09 10:03:32,162 - INFO - root - 成功添加图片 1：./export\images_Silenzio_ Secure Non-Interactive Outsourced MLP Training\figure_1_page11.png
2025-11-09 10:03:32,167 - INFO - root - 论文《Silenzio: Secure Non-Interactive Outsourced MLP Training》的分析已保存到 ./export\Silenzio_ Secure Non-Interactive Outsourced MLP Training.md
2025-11-09 10:03:32,175 - INFO - root - 正在总结论文 27/30: Involution and BSConv Multi-Depth Distillation Network for Lightweight Image Super-Resolution
2025-11-09 10:03:32,175 - INFO - root - LLMClient: rate limit reached, sleeping 4.8s
2025-11-09 10:03:48,557 - INFO - root - LLMClient: rate limit reached, sleeping 22.9s
2025-11-09 10:04:58,538 - INFO - root - 正在提取论文图片...
2025-11-09 10:04:58,608 - INFO - root - 已保存图片 1/10：./export\images_Involution and BSConv Multi-Depth Distillation Network for Lightweight Image Sup\figure_1_page4.jpeg
2025-11-09 10:04:58,624 - INFO - root - 已保存图片 2/10：./export\images_Involution and BSConv Multi-Depth Distillation Network for Lightweight Image Sup\figure_2_page3.jpeg
2025-11-09 10:04:58,688 - INFO - root - 已保存图片 3/10：./export\images_Involution and BSConv Multi-Depth Distillation Network for Lightweight Image Sup\figure_3_page1.png
2025-11-09 10:04:58,764 - INFO - root - 已保存图片 4/10：./export\images_Involution and BSConv Multi-Depth Distillation Network for Lightweight Image Sup\figure_4_page5.png
2025-11-09 10:04:58,797 - INFO - root - 已保存图片 5/10：./export\images_Involution and BSConv Multi-Depth Distillation Network for Lightweight Image Sup\figure_5_page7.jpeg
2025-11-09 10:04:58,842 - INFO - root - 已保存图片 6/10：./export\images_Involution and BSConv Multi-Depth Distillation Network for Lightweight Image Sup\figure_6_page7.jpeg
2025-11-09 10:04:58,876 - INFO - root - 已保存图片 7/10：./export\images_Involution and BSConv Multi-Depth Distillation Network for Lightweight Image Sup\figure_7_page7.jpeg
2025-11-09 10:04:58,912 - INFO - root - 已保存图片 8/10：./export\images_Involution and BSConv Multi-Depth Distillation Network for Lightweight Image Sup\figure_8_page7.jpeg
2025-11-09 10:04:58,940 - INFO - root - 已保存图片 9/10：./export\images_Involution and BSConv Multi-Depth Distillation Network for Lightweight Image Sup\figure_9_page7.jpeg
2025-11-09 10:04:58,977 - INFO - root - 已保存图片 10/10：./export\images_Involution and BSConv Multi-Depth Distillation Network for Lightweight Image Sup\figure_10_page7.jpeg
2025-11-09 10:04:58,983 - INFO - root - 成功添加图片 1：./export\images_Involution and BSConv Multi-Depth Distillation Network for Lightweight Image Sup\figure_1_page4.jpeg
2025-11-09 10:04:58,984 - INFO - root - 成功添加图片 2：./export\images_Involution and BSConv Multi-Depth Distillation Network for Lightweight Image Sup\figure_2_page3.jpeg
2025-11-09 10:04:58,984 - INFO - root - 成功添加图片 3：./export\images_Involution and BSConv Multi-Depth Distillation Network for Lightweight Image Sup\figure_3_page1.png
2025-11-09 10:04:58,985 - INFO - root - 成功添加图片 4：./export\images_Involution and BSConv Multi-Depth Distillation Network for Lightweight Image Sup\figure_4_page5.png
2025-11-09 10:04:58,985 - INFO - root - 成功添加图片 5：./export\images_Involution and BSConv Multi-Depth Distillation Network for Lightweight Image Sup\figure_5_page7.jpeg
2025-11-09 10:04:58,985 - INFO - root - 成功添加图片 6：./export\images_Involution and BSConv Multi-Depth Distillation Network for Lightweight Image Sup\figure_6_page7.jpeg
2025-11-09 10:04:58,986 - INFO - root - 成功添加图片 7：./export\images_Involution and BSConv Multi-Depth Distillation Network for Lightweight Image Sup\figure_7_page7.jpeg
2025-11-09 10:04:58,986 - INFO - root - 成功添加图片 8：./export\images_Involution and BSConv Multi-Depth Distillation Network for Lightweight Image Sup\figure_8_page7.jpeg
2025-11-09 10:04:58,987 - INFO - root - 成功添加图片 9：./export\images_Involution and BSConv Multi-Depth Distillation Network for Lightweight Image Sup\figure_9_page7.jpeg
2025-11-09 10:04:58,987 - INFO - root - 成功添加图片 10：./export\images_Involution and BSConv Multi-Depth Distillation Network for Lightweight Image Sup\figure_10_page7.jpeg
2025-11-09 10:04:58,994 - INFO - root - 论文《Involution and BSConv Multi-Depth Distillation Network for Lightweight Image Super-Resolution》的分析已保存到 ./export\Involution and BSConv Multi-Depth Distillation Network for Lightweight Image Sup.md
2025-11-09 10:04:59,001 - INFO - root - 正在总结论文 28/30: Flopping for FLOPs: Leveraging equivariance for computational efficiency
2025-11-09 10:04:59,002 - INFO - root - LLMClient: rate limit reached, sleeping 12.5s
2025-11-09 10:05:22,017 - INFO - root - LLMClient: rate limit reached, sleeping 18.0s
2025-11-09 10:06:03,248 - INFO - root - LLMClient: rate limit reached, sleeping 8.2s
2025-11-09 10:06:27,546 - INFO - root - 正在提取论文图片...
2025-11-09 10:06:27,990 - INFO - root - 已保存图片 1/10：./export\images_Flopping for FLOPs_ Leveraging equivariance for computational efficiency\figure_1_page3.png
2025-11-09 10:06:28,075 - INFO - root - 已保存图片 2/10：./export\images_Flopping for FLOPs_ Leveraging equivariance for computational efficiency\figure_2_page5.png
2025-11-09 10:06:28,170 - INFO - root - 已保存图片 3/10：./export\images_Flopping for FLOPs_ Leveraging equivariance for computational efficiency\figure_3_page1.png
2025-11-09 10:06:28,170 - INFO - root - 成功添加图片 1：./export\images_Flopping for FLOPs_ Leveraging equivariance for computational efficiency\figure_1_page3.png
2025-11-09 10:06:28,170 - INFO - root - 成功添加图片 2：./export\images_Flopping for FLOPs_ Leveraging equivariance for computational efficiency\figure_2_page5.png
2025-11-09 10:06:28,170 - INFO - root - 成功添加图片 3：./export\images_Flopping for FLOPs_ Leveraging equivariance for computational efficiency\figure_3_page1.png
2025-11-09 10:06:28,185 - INFO - root - 论文《Flopping for FLOPs: Leveraging equivariance for computational efficiency》的分析已保存到 ./export\Flopping for FLOPs_ Leveraging equivariance for computational efficiency.md
2025-11-09 10:06:28,191 - INFO - root - 正在总结论文 29/30: An Effective UNet Using Feature Interaction and Fusion for Organ Segmentation in Medical Image
2025-11-09 10:06:28,191 - INFO - root - LLMClient: rate limit reached, sleeping 11.8s
2025-11-09 10:06:49,350 - INFO - root - LLMClient: rate limit reached, sleeping 22.1s
2025-11-09 10:07:35,800 - INFO - root - LLMClient: rate limit reached, sleeping 4.2s
2025-11-09 10:07:58,300 - INFO - root - 正在提取论文图片...
2025-11-09 10:07:58,489 - INFO - root - 已保存图片 1/10：./export\images_An Effective UNet Using Feature Interaction and Fusion for Organ Segmentation in\figure_1_page14.png
2025-11-09 10:07:58,531 - INFO - root - 已保存图片 2/10：./export\images_An Effective UNet Using Feature Interaction and Fusion for Organ Segmentation in\figure_2_page19.jpeg
2025-11-09 10:07:58,577 - INFO - root - 已保存图片 3/10：./export\images_An Effective UNet Using Feature Interaction and Fusion for Organ Segmentation in\figure_3_page19.jpeg
2025-11-09 10:07:58,672 - INFO - root - 已保存图片 4/10：./export\images_An Effective UNet Using Feature Interaction and Fusion for Organ Segmentation in\figure_4_page19.jpeg
2025-11-09 10:07:58,764 - INFO - root - 已保存图片 5/10：./export\images_An Effective UNet Using Feature Interaction and Fusion for Organ Segmentation in\figure_5_page19.jpeg
2025-11-09 10:07:58,822 - INFO - root - 已保存图片 6/10：./export\images_An Effective UNet Using Feature Interaction and Fusion for Organ Segmentation in\figure_6_page19.jpeg
2025-11-09 10:07:58,889 - INFO - root - 已保存图片 7/10：./export\images_An Effective UNet Using Feature Interaction and Fusion for Organ Segmentation in\figure_7_page19.jpeg
2025-11-09 10:07:58,992 - INFO - root - 已保存图片 8/10：./export\images_An Effective UNet Using Feature Interaction and Fusion for Organ Segmentation in\figure_8_page19.jpeg
2025-11-09 10:07:59,073 - INFO - root - 已保存图片 9/10：./export\images_An Effective UNet Using Feature Interaction and Fusion for Organ Segmentation in\figure_9_page19.jpeg
2025-11-09 10:07:59,146 - INFO - root - 已保存图片 10/10：./export\images_An Effective UNet Using Feature Interaction and Fusion for Organ Segmentation in\figure_10_page19.jpeg
2025-11-09 10:07:59,241 - INFO - root - 成功添加图片 1：./export\images_An Effective UNet Using Feature Interaction and Fusion for Organ Segmentation in\figure_1_page14.png
2025-11-09 10:07:59,253 - INFO - root - 成功添加图片 2：./export\images_An Effective UNet Using Feature Interaction and Fusion for Organ Segmentation in\figure_2_page19.jpeg
2025-11-09 10:07:59,255 - INFO - root - 成功添加图片 3：./export\images_An Effective UNet Using Feature Interaction and Fusion for Organ Segmentation in\figure_3_page19.jpeg
2025-11-09 10:07:59,258 - INFO - root - 成功添加图片 4：./export\images_An Effective UNet Using Feature Interaction and Fusion for Organ Segmentation in\figure_4_page19.jpeg
2025-11-09 10:07:59,263 - INFO - root - 成功添加图片 5：./export\images_An Effective UNet Using Feature Interaction and Fusion for Organ Segmentation in\figure_5_page19.jpeg
2025-11-09 10:07:59,285 - INFO - root - 成功添加图片 6：./export\images_An Effective UNet Using Feature Interaction and Fusion for Organ Segmentation in\figure_6_page19.jpeg
2025-11-09 10:07:59,297 - INFO - root - 成功添加图片 7：./export\images_An Effective UNet Using Feature Interaction and Fusion for Organ Segmentation in\figure_7_page19.jpeg
2025-11-09 10:07:59,321 - INFO - root - 成功添加图片 8：./export\images_An Effective UNet Using Feature Interaction and Fusion for Organ Segmentation in\figure_8_page19.jpeg
2025-11-09 10:07:59,321 - INFO - root - 成功添加图片 9：./export\images_An Effective UNet Using Feature Interaction and Fusion for Organ Segmentation in\figure_9_page19.jpeg
2025-11-09 10:07:59,323 - INFO - root - 成功添加图片 10：./export\images_An Effective UNet Using Feature Interaction and Fusion for Organ Segmentation in\figure_10_page19.jpeg
2025-11-09 10:07:59,333 - INFO - root - 论文《An Effective UNet Using Feature Interaction and Fusion for Organ Segmentation in Medical Image》的分析已保存到 ./export\An Effective UNet Using Feature Interaction and Fusion for Organ Segmentation in.md
2025-11-09 10:07:59,343 - INFO - root - 正在总结论文 30/30: TwinLiteNet+: An Enhanced Multi-Task Segmentation Model for Autonomous Driving
2025-11-09 10:07:59,345 - INFO - root - LLMClient: rate limit reached, sleeping 12.1s
2025-11-09 10:08:22,814 - INFO - root - LLMClient: rate limit reached, sleeping 17.2s
2025-11-09 10:09:04,202 - INFO - root - LLMClient: rate limit reached, sleeping 7.3s
2025-11-09 10:09:11,822 - ERROR - root - LLMClient: generation error: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. 
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 250
Please retry in 47.09277372s. [links {
  description: "Learn more about Gemini API quotas"
  url: "https://ai.google.dev/gemini-api/docs/rate-limits"
}
, violations {
  quota_metric: "generativelanguage.googleapis.com/generate_content_free_tier_requests"
  quota_id: "GenerateRequestsPerDayPerProjectPerModel-FreeTier"
  quota_dimensions {
    key: "model"
    value: "gemini-2.5-flash"
  }
  quota_dimensions {
    key: "location"
    value: "global"
  }
  quota_value: 250
}
, retry_delay {
  seconds: 47
}
]
Traceback (most recent call last):
  File "D:\ChatPaper\llm_client.py", line 117, in generate
    resp = self.model.generate_content(prompt, safety_settings=self.safety_settings)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\google\generativeai\generative_models.py", line 331, in generate_content
    response = self._client.generate_content(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\google\ai\generativelanguage_v1beta\services\generative_service\client.py", line 835, in generate_content
    response = rpc(
               ^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\google\api_core\gapic_v1\method.py", line 131, in __call__
    return wrapped_func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 294, in retry_wrapped_func
    return retry_target(
           ^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 156, in retry_target
    next_sleep = _retry_error_helper(
                 ^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\google\api_core\retry\retry_base.py", line 214, in _retry_error_helper
    raise final_exc from source_exc
  File "D:\ChatPaper\.venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 147, in retry_target
    result = target()
             ^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\google\api_core\timeout.py", line 130, in func_with_timeout
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\google\api_core\grpc_helpers.py", line 77, in error_remapped_callable
    raise exceptions.from_grpc_error(exc) from exc
google.api_core.exceptions.ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. 
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 250
Please retry in 47.09277372s. [links {
  description: "Learn more about Gemini API quotas"
  url: "https://ai.google.dev/gemini-api/docs/rate-limits"
}
, violations {
  quota_metric: "generativelanguage.googleapis.com/generate_content_free_tier_requests"
  quota_id: "GenerateRequestsPerDayPerProjectPerModel-FreeTier"
  quota_dimensions {
    key: "model"
    value: "gemini-2.5-flash"
  }
  quota_dimensions {
    key: "location"
    value: "global"
  }
  quota_value: 250
}
, retry_delay {
  seconds: 47
}
]
2025-11-09 10:09:11,825 - WARNING - root - LLMClient: quota/rate detected, sleeping 60 s then retrying
2025-11-09 10:10:11,826 - INFO - root - LLMClient: retry attempt 2 for generation
2025-11-09 10:10:12,768 - ERROR - root - LLMClient: generation error: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. 
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 250
Please retry in 46.154652662s. [links {
  description: "Learn more about Gemini API quotas"
  url: "https://ai.google.dev/gemini-api/docs/rate-limits"
}
, violations {
  quota_metric: "generativelanguage.googleapis.com/generate_content_free_tier_requests"
  quota_id: "GenerateRequestsPerDayPerProjectPerModel-FreeTier"
  quota_dimensions {
    key: "model"
    value: "gemini-2.5-flash"
  }
  quota_dimensions {
    key: "location"
    value: "global"
  }
  quota_value: 250
}
, retry_delay {
  seconds: 46
}
]
Traceback (most recent call last):
  File "D:\ChatPaper\llm_client.py", line 117, in generate
    resp = self.model.generate_content(prompt, safety_settings=self.safety_settings)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\google\generativeai\generative_models.py", line 331, in generate_content
    response = self._client.generate_content(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\google\ai\generativelanguage_v1beta\services\generative_service\client.py", line 835, in generate_content
    response = rpc(
               ^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\google\api_core\gapic_v1\method.py", line 131, in __call__
    return wrapped_func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 294, in retry_wrapped_func
    return retry_target(
           ^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 156, in retry_target
    next_sleep = _retry_error_helper(
                 ^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\google\api_core\retry\retry_base.py", line 214, in _retry_error_helper
    raise final_exc from source_exc
  File "D:\ChatPaper\.venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 147, in retry_target
    result = target()
             ^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\google\api_core\timeout.py", line 130, in func_with_timeout
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\google\api_core\grpc_helpers.py", line 77, in error_remapped_callable
    raise exceptions.from_grpc_error(exc) from exc
google.api_core.exceptions.ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. 
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 250
Please retry in 46.154652662s. [links {
  description: "Learn more about Gemini API quotas"
  url: "https://ai.google.dev/gemini-api/docs/rate-limits"
}
, violations {
  quota_metric: "generativelanguage.googleapis.com/generate_content_free_tier_requests"
  quota_id: "GenerateRequestsPerDayPerProjectPerModel-FreeTier"
  quota_dimensions {
    key: "model"
    value: "gemini-2.5-flash"
  }
  quota_dimensions {
    key: "location"
    value: "global"
  }
  quota_value: 250
}
, retry_delay {
  seconds: 46
}
]
2025-11-09 10:10:12,770 - WARNING - root - LLMClient: quota/rate detected, sleeping 60 s then retrying
2025-11-09 10:11:12,771 - INFO - root - LLMClient: retry attempt 3 for generation
2025-11-09 10:11:14,264 - ERROR - root - LLMClient: generation error: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. 
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 250
Please retry in 44.666304166s. [links {
  description: "Learn more about Gemini API quotas"
  url: "https://ai.google.dev/gemini-api/docs/rate-limits"
}
, violations {
  quota_metric: "generativelanguage.googleapis.com/generate_content_free_tier_requests"
  quota_id: "GenerateRequestsPerDayPerProjectPerModel-FreeTier"
  quota_dimensions {
    key: "model"
    value: "gemini-2.5-flash"
  }
  quota_dimensions {
    key: "location"
    value: "global"
  }
  quota_value: 250
}
, retry_delay {
  seconds: 44
}
]
Traceback (most recent call last):
  File "D:\ChatPaper\llm_client.py", line 117, in generate
    resp = self.model.generate_content(prompt, safety_settings=self.safety_settings)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\google\generativeai\generative_models.py", line 331, in generate_content
    response = self._client.generate_content(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\google\ai\generativelanguage_v1beta\services\generative_service\client.py", line 835, in generate_content
    response = rpc(
               ^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\google\api_core\gapic_v1\method.py", line 131, in __call__
    return wrapped_func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 294, in retry_wrapped_func
    return retry_target(
           ^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 156, in retry_target
    next_sleep = _retry_error_helper(
                 ^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\google\api_core\retry\retry_base.py", line 214, in _retry_error_helper
    raise final_exc from source_exc
  File "D:\ChatPaper\.venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 147, in retry_target
    result = target()
             ^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\google\api_core\timeout.py", line 130, in func_with_timeout
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\google\api_core\grpc_helpers.py", line 77, in error_remapped_callable
    raise exceptions.from_grpc_error(exc) from exc
google.api_core.exceptions.ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. 
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 250
Please retry in 44.666304166s. [links {
  description: "Learn more about Gemini API quotas"
  url: "https://ai.google.dev/gemini-api/docs/rate-limits"
}
, violations {
  quota_metric: "generativelanguage.googleapis.com/generate_content_free_tier_requests"
  quota_id: "GenerateRequestsPerDayPerProjectPerModel-FreeTier"
  quota_dimensions {
    key: "model"
    value: "gemini-2.5-flash"
  }
  quota_dimensions {
    key: "location"
    value: "global"
  }
  quota_value: 250
}
, retry_delay {
  seconds: 44
}
]
2025-11-09 10:11:14,267 - INFO - root - 正在提取论文图片...
2025-11-09 10:11:14,617 - INFO - root - 已保存图片 1/10：./export\images_TwinLiteNet+_ An Enhanced Multi-Task Segmentation Model for Autonomous Driving\figure_1_page23.jpeg
2025-11-09 10:11:14,653 - INFO - root - 已保存图片 2/10：./export\images_TwinLiteNet+_ An Enhanced Multi-Task Segmentation Model for Autonomous Driving\figure_2_page6.jpeg
2025-11-09 10:11:14,696 - INFO - root - 已保存图片 3/10：./export\images_TwinLiteNet+_ An Enhanced Multi-Task Segmentation Model for Autonomous Driving\figure_3_page6.png
2025-11-09 10:11:14,750 - INFO - root - 已保存图片 4/10：./export\images_TwinLiteNet+_ An Enhanced Multi-Task Segmentation Model for Autonomous Driving\figure_4_page6.png
2025-11-09 10:11:14,794 - INFO - root - 已保存图片 5/10：./export\images_TwinLiteNet+_ An Enhanced Multi-Task Segmentation Model for Autonomous Driving\figure_5_page8.jpeg
2025-11-09 10:11:14,835 - INFO - root - 已保存图片 6/10：./export\images_TwinLiteNet+_ An Enhanced Multi-Task Segmentation Model for Autonomous Driving\figure_6_page17.jpeg
2025-11-09 10:11:14,883 - INFO - root - 已保存图片 7/10：./export\images_TwinLiteNet+_ An Enhanced Multi-Task Segmentation Model for Autonomous Driving\figure_7_page17.jpeg
2025-11-09 10:11:14,919 - INFO - root - 已保存图片 8/10：./export\images_TwinLiteNet+_ An Enhanced Multi-Task Segmentation Model for Autonomous Driving\figure_8_page17.jpeg
2025-11-09 10:11:14,961 - INFO - root - 已保存图片 9/10：./export\images_TwinLiteNet+_ An Enhanced Multi-Task Segmentation Model for Autonomous Driving\figure_9_page17.jpeg
2025-11-09 10:11:15,005 - INFO - root - 已保存图片 10/10：./export\images_TwinLiteNet+_ An Enhanced Multi-Task Segmentation Model for Autonomous Driving\figure_10_page17.jpeg
2025-11-09 10:11:15,011 - INFO - root - 成功添加图片 1：./export\images_TwinLiteNet+_ An Enhanced Multi-Task Segmentation Model for Autonomous Driving\figure_1_page23.jpeg
2025-11-09 10:11:15,011 - INFO - root - 成功添加图片 2：./export\images_TwinLiteNet+_ An Enhanced Multi-Task Segmentation Model for Autonomous Driving\figure_2_page6.jpeg
2025-11-09 10:11:15,011 - INFO - root - 成功添加图片 3：./export\images_TwinLiteNet+_ An Enhanced Multi-Task Segmentation Model for Autonomous Driving\figure_3_page6.png
2025-11-09 10:11:15,011 - INFO - root - 成功添加图片 4：./export\images_TwinLiteNet+_ An Enhanced Multi-Task Segmentation Model for Autonomous Driving\figure_4_page6.png
2025-11-09 10:11:15,011 - INFO - root - 成功添加图片 5：./export\images_TwinLiteNet+_ An Enhanced Multi-Task Segmentation Model for Autonomous Driving\figure_5_page8.jpeg
2025-11-09 10:11:15,011 - INFO - root - 成功添加图片 6：./export\images_TwinLiteNet+_ An Enhanced Multi-Task Segmentation Model for Autonomous Driving\figure_6_page17.jpeg
2025-11-09 10:11:15,017 - INFO - root - 成功添加图片 7：./export\images_TwinLiteNet+_ An Enhanced Multi-Task Segmentation Model for Autonomous Driving\figure_7_page17.jpeg
2025-11-09 10:11:15,017 - INFO - root - 成功添加图片 8：./export\images_TwinLiteNet+_ An Enhanced Multi-Task Segmentation Model for Autonomous Driving\figure_8_page17.jpeg
2025-11-09 10:11:15,017 - INFO - root - 成功添加图片 9：./export\images_TwinLiteNet+_ An Enhanced Multi-Task Segmentation Model for Autonomous Driving\figure_9_page17.jpeg
2025-11-09 10:11:15,017 - INFO - root - 成功添加图片 10：./export\images_TwinLiteNet+_ An Enhanced Multi-Task Segmentation Model for Autonomous Driving\figure_10_page17.jpeg
2025-11-09 10:11:15,028 - INFO - root - 论文《TwinLiteNet+: An Enhanced Multi-Task Segmentation Model for Autonomous Driving》的分析已保存到 ./export\TwinLiteNet+_ An Enhanced Multi-Task Segmentation Model for Autonomous Driving.md
2025-11-09 10:11:15,034 - INFO - root - summary time: 31076.43 seconds
2025-11-09 10:23:21,960 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-09 10:23:21,960 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-09 10:23:21,960 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-09 10:23:22,718 - INFO - root - LLMClient: trying model gemini-2.5-flash
2025-11-09 10:23:23,714 - INFO - root - LLMClient: trying model gemini-2.5-pro
2025-11-09 10:23:34,497 - INFO - root - LLMClient: initialized model gemini-2.5-pro
2025-11-09 10:23:34,497 - INFO - root - 使用 LLM 模型: gemini-2.5-pro
2025-11-09 10:23:34,498 - INFO - root - === 运行配置 ===
2025-11-09 10:23:34,498 - INFO - root - 处理模式: arxiv在线搜索
2025-11-09 10:23:34,499 - INFO - root - 关键词: Quant
2025-11-09 10:23:34,499 - INFO - root - 查询: block float point
2025-11-09 10:23:34,499 - INFO - root - 排序: None
2025-11-09 10:23:34,500 - INFO - root - 最近天数: 180
2025-11-09 10:23:34,500 - INFO - root - 最大处理数量: 50
2025-11-09 10:23:34,500 - INFO - root - 保存图片: 是
2025-11-09 10:23:34,501 - INFO - root - 输出语言: 中文
2025-11-09 10:23:34,501 - INFO - root - 强制重新处理: 否
2025-11-09 10:23:34,501 - INFO - root - ====================
2025-11-09 10:23:34,501 - INFO - root - 使用 arXiv 搜索模式（通过 chat_arxiv 模块获取）
2025-11-09 10:24:22,578 - INFO - root - 正在总结论文 1/30: From Uniform to Adaptive: General Skip-Block Mechanisms for Efficient PDE Neural Operators
2025-11-09 10:24:22,751 - ERROR - root - LLMClient: generation error: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. 
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 50
Please retry in 35.947403049s. [links {
  description: "Learn more about Gemini API quotas"
  url: "https://ai.google.dev/gemini-api/docs/rate-limits"
}
, violations {
  quota_metric: "generativelanguage.googleapis.com/generate_content_free_tier_requests"
  quota_id: "GenerateRequestsPerDayPerProjectPerModel-FreeTier"
  quota_dimensions {
    key: "model"
    value: "gemini-2.5-pro"
  }
  quota_dimensions {
    key: "location"
    value: "global"
  }
  quota_value: 50
}
, retry_delay {
  seconds: 35
}
]
Traceback (most recent call last):
  File "D:\ChatPaper\llm_client.py", line 117, in generate
    resp = self.model.generate_content(prompt, safety_settings=self.safety_settings)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\google\generativeai\generative_models.py", line 331, in generate_content
    response = self._client.generate_content(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\google\ai\generativelanguage_v1beta\services\generative_service\client.py", line 835, in generate_content
    response = rpc(
               ^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\google\api_core\gapic_v1\method.py", line 131, in __call__
    return wrapped_func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 294, in retry_wrapped_func
    return retry_target(
           ^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 156, in retry_target
    next_sleep = _retry_error_helper(
                 ^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\google\api_core\retry\retry_base.py", line 214, in _retry_error_helper
    raise final_exc from source_exc
  File "D:\ChatPaper\.venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 147, in retry_target
    result = target()
             ^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\google\api_core\timeout.py", line 130, in func_with_timeout
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\google\api_core\grpc_helpers.py", line 77, in error_remapped_callable
    raise exceptions.from_grpc_error(exc) from exc
google.api_core.exceptions.ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. 
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 50
Please retry in 35.947403049s. [links {
  description: "Learn more about Gemini API quotas"
  url: "https://ai.google.dev/gemini-api/docs/rate-limits"
}
, violations {
  quota_metric: "generativelanguage.googleapis.com/generate_content_free_tier_requests"
  quota_id: "GenerateRequestsPerDayPerProjectPerModel-FreeTier"
  quota_dimensions {
    key: "model"
    value: "gemini-2.5-pro"
  }
  quota_dimensions {
    key: "location"
    value: "global"
  }
  quota_value: 50
}
, retry_delay {
  seconds: 35
}
]
2025-11-09 10:24:22,758 - WARNING - root - LLMClient: quota/rate detected, sleeping 60 s then retrying
2025-11-09 10:25:22,762 - INFO - root - LLMClient: retry attempt 2 for generation
2025-11-09 10:25:23,508 - ERROR - root - LLMClient: generation error: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. 
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 50
Please retry in 35.205752668s. [links {
  description: "Learn more about Gemini API quotas"
  url: "https://ai.google.dev/gemini-api/docs/rate-limits"
}
, violations {
  quota_metric: "generativelanguage.googleapis.com/generate_content_free_tier_requests"
  quota_id: "GenerateRequestsPerDayPerProjectPerModel-FreeTier"
  quota_dimensions {
    key: "model"
    value: "gemini-2.5-pro"
  }
  quota_dimensions {
    key: "location"
    value: "global"
  }
  quota_value: 50
}
, retry_delay {
  seconds: 35
}
]
Traceback (most recent call last):
  File "D:\ChatPaper\llm_client.py", line 117, in generate
    resp = self.model.generate_content(prompt, safety_settings=self.safety_settings)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\google\generativeai\generative_models.py", line 331, in generate_content
    response = self._client.generate_content(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\google\ai\generativelanguage_v1beta\services\generative_service\client.py", line 835, in generate_content
    response = rpc(
               ^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\google\api_core\gapic_v1\method.py", line 131, in __call__
    return wrapped_func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 294, in retry_wrapped_func
    return retry_target(
           ^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 156, in retry_target
    next_sleep = _retry_error_helper(
                 ^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\google\api_core\retry\retry_base.py", line 214, in _retry_error_helper
    raise final_exc from source_exc
  File "D:\ChatPaper\.venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 147, in retry_target
    result = target()
             ^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\google\api_core\timeout.py", line 130, in func_with_timeout
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\google\api_core\grpc_helpers.py", line 77, in error_remapped_callable
    raise exceptions.from_grpc_error(exc) from exc
google.api_core.exceptions.ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. 
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 50
Please retry in 35.205752668s. [links {
  description: "Learn more about Gemini API quotas"
  url: "https://ai.google.dev/gemini-api/docs/rate-limits"
}
, violations {
  quota_metric: "generativelanguage.googleapis.com/generate_content_free_tier_requests"
  quota_id: "GenerateRequestsPerDayPerProjectPerModel-FreeTier"
  quota_dimensions {
    key: "model"
    value: "gemini-2.5-pro"
  }
  quota_dimensions {
    key: "location"
    value: "global"
  }
  quota_value: 50
}
, retry_delay {
  seconds: 35
}
]
2025-11-09 10:25:23,511 - WARNING - root - LLMClient: quota/rate detected, sleeping 60 s then retrying
2025-11-09 10:26:23,511 - INFO - root - LLMClient: retry attempt 3 for generation
2025-11-09 10:26:24,694 - ERROR - root - LLMClient: generation error: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. 
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 50
Please retry in 34.01837253s. [links {
  description: "Learn more about Gemini API quotas"
  url: "https://ai.google.dev/gemini-api/docs/rate-limits"
}
, violations {
  quota_metric: "generativelanguage.googleapis.com/generate_content_free_tier_requests"
  quota_id: "GenerateRequestsPerDayPerProjectPerModel-FreeTier"
  quota_dimensions {
    key: "model"
    value: "gemini-2.5-pro"
  }
  quota_dimensions {
    key: "location"
    value: "global"
  }
  quota_value: 50
}
, retry_delay {
  seconds: 34
}
]
Traceback (most recent call last):
  File "D:\ChatPaper\llm_client.py", line 117, in generate
    resp = self.model.generate_content(prompt, safety_settings=self.safety_settings)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\google\generativeai\generative_models.py", line 331, in generate_content
    response = self._client.generate_content(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\google\ai\generativelanguage_v1beta\services\generative_service\client.py", line 835, in generate_content
    response = rpc(
               ^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\google\api_core\gapic_v1\method.py", line 131, in __call__
    return wrapped_func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 294, in retry_wrapped_func
    return retry_target(
           ^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 156, in retry_target
    next_sleep = _retry_error_helper(
                 ^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\google\api_core\retry\retry_base.py", line 214, in _retry_error_helper
    raise final_exc from source_exc
  File "D:\ChatPaper\.venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 147, in retry_target
    result = target()
             ^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\google\api_core\timeout.py", line 130, in func_with_timeout
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\google\api_core\grpc_helpers.py", line 77, in error_remapped_callable
    raise exceptions.from_grpc_error(exc) from exc
google.api_core.exceptions.ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. 
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 50
Please retry in 34.01837253s. [links {
  description: "Learn more about Gemini API quotas"
  url: "https://ai.google.dev/gemini-api/docs/rate-limits"
}
, violations {
  quota_metric: "generativelanguage.googleapis.com/generate_content_free_tier_requests"
  quota_id: "GenerateRequestsPerDayPerProjectPerModel-FreeTier"
  quota_dimensions {
    key: "model"
    value: "gemini-2.5-pro"
  }
  quota_dimensions {
    key: "location"
    value: "global"
  }
  quota_value: 50
}
, retry_delay {
  seconds: 34
}
]
2025-11-09 10:26:24,828 - ERROR - root - LLMClient: generation error: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. 
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 50
Please retry in 33.879301367s. [links {
  description: "Learn more about Gemini API quotas"
  url: "https://ai.google.dev/gemini-api/docs/rate-limits"
}
, violations {
  quota_metric: "generativelanguage.googleapis.com/generate_content_free_tier_requests"
  quota_id: "GenerateRequestsPerDayPerProjectPerModel-FreeTier"
  quota_dimensions {
    key: "model"
    value: "gemini-2.5-pro"
  }
  quota_dimensions {
    key: "location"
    value: "global"
  }
  quota_value: 50
}
, retry_delay {
  seconds: 33
}
]
Traceback (most recent call last):
  File "D:\ChatPaper\llm_client.py", line 117, in generate
    resp = self.model.generate_content(prompt, safety_settings=self.safety_settings)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\google\generativeai\generative_models.py", line 331, in generate_content
    response = self._client.generate_content(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\google\ai\generativelanguage_v1beta\services\generative_service\client.py", line 835, in generate_content
    response = rpc(
               ^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\google\api_core\gapic_v1\method.py", line 131, in __call__
    return wrapped_func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 294, in retry_wrapped_func
    return retry_target(
           ^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 156, in retry_target
    next_sleep = _retry_error_helper(
                 ^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\google\api_core\retry\retry_base.py", line 214, in _retry_error_helper
    raise final_exc from source_exc
  File "D:\ChatPaper\.venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 147, in retry_target
    result = target()
             ^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\google\api_core\timeout.py", line 130, in func_with_timeout
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\google\api_core\grpc_helpers.py", line 77, in error_remapped_callable
    raise exceptions.from_grpc_error(exc) from exc
google.api_core.exceptions.ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. 
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 50
Please retry in 33.879301367s. [links {
  description: "Learn more about Gemini API quotas"
  url: "https://ai.google.dev/gemini-api/docs/rate-limits"
}
, violations {
  quota_metric: "generativelanguage.googleapis.com/generate_content_free_tier_requests"
  quota_id: "GenerateRequestsPerDayPerProjectPerModel-FreeTier"
  quota_dimensions {
    key: "model"
    value: "gemini-2.5-pro"
  }
  quota_dimensions {
    key: "location"
    value: "global"
  }
  quota_value: 50
}
, retry_delay {
  seconds: 33
}
]
2025-11-09 10:26:24,830 - WARNING - root - LLMClient: quota/rate detected, sleeping 60 s then retrying
2025-11-09 10:27:24,831 - INFO - root - LLMClient: retry attempt 2 for generation
2025-11-09 10:27:25,705 - ERROR - root - LLMClient: generation error: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. 
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 50
Please retry in 32.998956656s. [links {
  description: "Learn more about Gemini API quotas"
  url: "https://ai.google.dev/gemini-api/docs/rate-limits"
}
, violations {
  quota_metric: "generativelanguage.googleapis.com/generate_content_free_tier_requests"
  quota_id: "GenerateRequestsPerDayPerProjectPerModel-FreeTier"
  quota_dimensions {
    key: "model"
    value: "gemini-2.5-pro"
  }
  quota_dimensions {
    key: "location"
    value: "global"
  }
  quota_value: 50
}
, retry_delay {
  seconds: 32
}
]
Traceback (most recent call last):
  File "D:\ChatPaper\llm_client.py", line 117, in generate
    resp = self.model.generate_content(prompt, safety_settings=self.safety_settings)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\google\generativeai\generative_models.py", line 331, in generate_content
    response = self._client.generate_content(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\google\ai\generativelanguage_v1beta\services\generative_service\client.py", line 835, in generate_content
    response = rpc(
               ^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\google\api_core\gapic_v1\method.py", line 131, in __call__
    return wrapped_func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 294, in retry_wrapped_func
    return retry_target(
           ^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 156, in retry_target
    next_sleep = _retry_error_helper(
                 ^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\google\api_core\retry\retry_base.py", line 214, in _retry_error_helper
    raise final_exc from source_exc
  File "D:\ChatPaper\.venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 147, in retry_target
    result = target()
             ^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\google\api_core\timeout.py", line 130, in func_with_timeout
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\google\api_core\grpc_helpers.py", line 77, in error_remapped_callable
    raise exceptions.from_grpc_error(exc) from exc
google.api_core.exceptions.ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. 
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 50
Please retry in 32.998956656s. [links {
  description: "Learn more about Gemini API quotas"
  url: "https://ai.google.dev/gemini-api/docs/rate-limits"
}
, violations {
  quota_metric: "generativelanguage.googleapis.com/generate_content_free_tier_requests"
  quota_id: "GenerateRequestsPerDayPerProjectPerModel-FreeTier"
  quota_dimensions {
    key: "model"
    value: "gemini-2.5-pro"
  }
  quota_dimensions {
    key: "location"
    value: "global"
  }
  quota_value: 50
}
, retry_delay {
  seconds: 32
}
]
2025-11-09 10:27:25,707 - WARNING - root - LLMClient: quota/rate detected, sleeping 60 s then retrying
2025-11-09 10:28:25,708 - INFO - root - LLMClient: retry attempt 3 for generation
2025-11-09 10:28:26,444 - ERROR - root - LLMClient: generation error: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. 
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 50
Please retry in 32.258710193s. [links {
  description: "Learn more about Gemini API quotas"
  url: "https://ai.google.dev/gemini-api/docs/rate-limits"
}
, violations {
  quota_metric: "generativelanguage.googleapis.com/generate_content_free_tier_requests"
  quota_id: "GenerateRequestsPerDayPerProjectPerModel-FreeTier"
  quota_dimensions {
    key: "model"
    value: "gemini-2.5-pro"
  }
  quota_dimensions {
    key: "location"
    value: "global"
  }
  quota_value: 50
}
, retry_delay {
  seconds: 32
}
]
Traceback (most recent call last):
  File "D:\ChatPaper\llm_client.py", line 117, in generate
    resp = self.model.generate_content(prompt, safety_settings=self.safety_settings)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\google\generativeai\generative_models.py", line 331, in generate_content
    response = self._client.generate_content(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\google\ai\generativelanguage_v1beta\services\generative_service\client.py", line 835, in generate_content
    response = rpc(
               ^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\google\api_core\gapic_v1\method.py", line 131, in __call__
    return wrapped_func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 294, in retry_wrapped_func
    return retry_target(
           ^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 156, in retry_target
    next_sleep = _retry_error_helper(
                 ^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\google\api_core\retry\retry_base.py", line 214, in _retry_error_helper
    raise final_exc from source_exc
  File "D:\ChatPaper\.venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 147, in retry_target
    result = target()
             ^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\google\api_core\timeout.py", line 130, in func_with_timeout
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\google\api_core\grpc_helpers.py", line 77, in error_remapped_callable
    raise exceptions.from_grpc_error(exc) from exc
google.api_core.exceptions.ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. 
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 50
Please retry in 32.258710193s. [links {
  description: "Learn more about Gemini API quotas"
  url: "https://ai.google.dev/gemini-api/docs/rate-limits"
}
, violations {
  quota_metric: "generativelanguage.googleapis.com/generate_content_free_tier_requests"
  quota_id: "GenerateRequestsPerDayPerProjectPerModel-FreeTier"
  quota_dimensions {
    key: "model"
    value: "gemini-2.5-pro"
  }
  quota_dimensions {
    key: "location"
    value: "global"
  }
  quota_value: 50
}
, retry_delay {
  seconds: 32
}
]
2025-11-09 10:28:26,558 - ERROR - root - LLMClient: generation error: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. 
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 50
Please retry in 32.138240581s. [links {
  description: "Learn more about Gemini API quotas"
  url: "https://ai.google.dev/gemini-api/docs/rate-limits"
}
, violations {
  quota_metric: "generativelanguage.googleapis.com/generate_content_free_tier_requests"
  quota_id: "GenerateRequestsPerDayPerProjectPerModel-FreeTier"
  quota_dimensions {
    key: "model"
    value: "gemini-2.5-pro"
  }
  quota_dimensions {
    key: "location"
    value: "global"
  }
  quota_value: 50
}
, retry_delay {
  seconds: 32
}
]
Traceback (most recent call last):
  File "D:\ChatPaper\llm_client.py", line 117, in generate
    resp = self.model.generate_content(prompt, safety_settings=self.safety_settings)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\google\generativeai\generative_models.py", line 331, in generate_content
    response = self._client.generate_content(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\google\ai\generativelanguage_v1beta\services\generative_service\client.py", line 835, in generate_content
    response = rpc(
               ^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\google\api_core\gapic_v1\method.py", line 131, in __call__
    return wrapped_func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 294, in retry_wrapped_func
    return retry_target(
           ^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 156, in retry_target
    next_sleep = _retry_error_helper(
                 ^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\google\api_core\retry\retry_base.py", line 214, in _retry_error_helper
    raise final_exc from source_exc
  File "D:\ChatPaper\.venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 147, in retry_target
    result = target()
             ^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\google\api_core\timeout.py", line 130, in func_with_timeout
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\google\api_core\grpc_helpers.py", line 77, in error_remapped_callable
    raise exceptions.from_grpc_error(exc) from exc
google.api_core.exceptions.ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. 
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 50
Please retry in 32.138240581s. [links {
  description: "Learn more about Gemini API quotas"
  url: "https://ai.google.dev/gemini-api/docs/rate-limits"
}
, violations {
  quota_metric: "generativelanguage.googleapis.com/generate_content_free_tier_requests"
  quota_id: "GenerateRequestsPerDayPerProjectPerModel-FreeTier"
  quota_dimensions {
    key: "model"
    value: "gemini-2.5-pro"
  }
  quota_dimensions {
    key: "location"
    value: "global"
  }
  quota_value: 50
}
, retry_delay {
  seconds: 32
}
]
2025-11-09 10:28:26,561 - WARNING - root - LLMClient: quota/rate detected, sleeping 60 s then retrying
2025-11-09 10:34:14,529 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-09 10:34:14,529 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-09 10:34:14,529 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-09 10:34:15,175 - INFO - root - LLMClient: trying model gemini-2.5-flash
2025-11-09 10:34:16,017 - INFO - root - LLMClient: trying model gemini-2.5-pro
2025-11-09 10:34:16,375 - WARNING - root - LLMClient: no usable model found, LLM disabled
2025-11-09 10:34:16,375 - INFO - root - LLM 未初始化或不可用，后续生成将返回备用消息
2025-11-09 10:34:16,375 - INFO - root - === 运行配置 ===
2025-11-09 10:34:16,376 - INFO - root - 处理模式: arxiv在线搜索
2025-11-09 10:34:16,376 - INFO - root - 关键词: Quant
2025-11-09 10:34:16,376 - INFO - root - 查询: block float point
2025-11-09 10:34:16,376 - INFO - root - 排序: None
2025-11-09 10:34:16,377 - INFO - root - 最近天数: 180
2025-11-09 10:34:16,377 - INFO - root - 最大处理数量: 50
2025-11-09 10:34:16,377 - INFO - root - 保存图片: 是
2025-11-09 10:34:16,378 - INFO - root - 输出语言: 中文
2025-11-09 10:34:16,378 - INFO - root - 强制重新处理: 否
2025-11-09 10:34:16,379 - INFO - root - ====================
2025-11-09 10:34:16,379 - INFO - root - 使用 arXiv 搜索模式（通过 chat_arxiv 模块获取）
2025-11-09 10:34:16,380 - ERROR - root - 从 chat_arxiv 获取论文列表失败: name 'get_all_titles_from_web' is not defined
2025-11-09 10:34:16,384 - INFO - root - 没有找到要处理的论文，程序退出
2025-11-09 10:34:16,384 - INFO - root - summary time: 1.85 seconds
2025-11-09 10:40:38,168 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-09 10:40:38,176 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-09 10:40:38,176 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-09 10:40:38,993 - INFO - root - LLMClient: trying model gemini-2.5-flash
2025-11-09 10:40:39,838 - INFO - root - LLMClient: trying model gemini-2.5-pro
2025-11-09 10:40:40,189 - WARNING - root - LLMClient: no usable model found, LLM disabled
2025-11-09 10:40:40,190 - INFO - root - LLM 未初始化或不可用，后续生成将返回备用消息
2025-11-09 10:40:40,190 - INFO - root - === 运行配置 ===
2025-11-09 10:40:40,190 - INFO - root - 处理模式: arxiv在线搜索
2025-11-09 10:40:40,190 - INFO - root - 关键词: Quant
2025-11-09 10:40:40,191 - INFO - root - 查询: block float point
2025-11-09 10:40:40,191 - INFO - root - 排序: None
2025-11-09 10:40:40,191 - INFO - root - 最近天数: 180
2025-11-09 10:40:40,192 - INFO - root - 最大处理数量: 50
2025-11-09 10:40:40,192 - INFO - root - 保存图片: 是
2025-11-09 10:40:40,192 - INFO - root - 输出语言: 中文
2025-11-09 10:40:40,193 - INFO - root - 强制重新处理: 否
2025-11-09 10:40:40,193 - INFO - root - ====================
2025-11-09 10:40:40,193 - INFO - root - 使用 arXiv 搜索模式（通过 chat_arxiv 模块获取）
2025-11-09 10:40:40,193 - ERROR - root - 从 chat_arxiv 获取论文列表失败: get_all_titles_from_web() missing 1 required positional argument: 'keyword'
2025-11-09 10:40:40,195 - INFO - root - 没有找到要处理的论文，程序退出
2025-11-09 10:40:40,195 - INFO - root - summary time: 2.03 seconds
2025-11-09 10:43:10,381 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-09 10:43:10,381 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-09 10:43:10,381 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-09 10:43:10,983 - INFO - root - LLMClient: trying model gemini-2.5-flash
2025-11-09 10:43:11,896 - INFO - root - LLMClient: trying model gemini-2.5-pro
2025-11-09 10:43:12,334 - WARNING - root - LLMClient: no usable model found, LLM disabled
2025-11-09 10:43:12,335 - INFO - root - LLM 未初始化或不可用，后续生成将返回备用消息
2025-11-09 10:43:12,335 - INFO - root - === 运行配置 ===
2025-11-09 10:43:12,335 - INFO - root - 处理模式: arxiv在线搜索
2025-11-09 10:43:12,335 - INFO - root - 关键词: Quant
2025-11-09 10:43:12,336 - INFO - root - 查询: block float point
2025-11-09 10:43:12,336 - INFO - root - 排序: None
2025-11-09 10:43:12,336 - INFO - root - 最近天数: 180
2025-11-09 10:43:12,336 - INFO - root - 最大处理数量: 50
2025-11-09 10:43:12,337 - INFO - root - 保存图片: 是
2025-11-09 10:43:12,337 - INFO - root - 输出语言: 中文
2025-11-09 10:43:12,338 - INFO - root - 强制重新处理: 否
2025-11-09 10:43:12,338 - INFO - root - ====================
2025-11-09 10:43:12,338 - INFO - root - 使用 arXiv 搜索模式（通过 chat_arxiv 模块获取）
2025-11-09 10:43:12,338 - INFO - root - Fetching page 1 with URL: https://arxiv.org/search/?query=block+float+point&searchtype=all&abstracts=show&order=-announced_date_first&size=50
2025-11-09 10:43:14,471 - INFO - root - get_all_titles_from_web 
2025-11-09 10:43:14,471 - INFO - root - Page:0, Index:0, From Uniform to Adaptive: General Skip-Block Mechanisms for Efficient PDE Neural Operators, https://arxiv.org/pdf/2511.00032, 2025-11-04
2025-11-09 10:43:14,471 - INFO - root - Page:0, Index:1, INT v.s. FP: A Comprehensive Study of Fine-Grained Low-bit Quantization Formats, https://arxiv.org/pdf/2510.25602, 2025-10-29
2025-11-09 10:43:14,471 - INFO - root - Page:0, Index:2, MX+: Pushing the Limits of Microscaling Formats for Efficient Large Language Model Serving, https://arxiv.org/pdf/2510.14557, 2025-10-16
2025-11-09 10:43:14,471 - INFO - root - Page:0, Index:3, F-BFQ: Flexible Block Floating-Point Quantization Accelerator for LLMs, https://arxiv.org/pdf/2510.13401, 2025-10-15
2025-11-09 10:43:14,471 - INFO - root - Page:0, Index:4, Computationally Efficient Neural Receivers via Axial Self-Attention, https://arxiv.org/pdf/2510.12941, 2025-10-14
2025-11-09 10:43:14,471 - INFO - root - Page:0, Index:5, Efficient In-Memory Acceleration of Sparse Block Diagonal LLMs, https://arxiv.org/pdf/2510.11192, 2025-10-13
2025-11-09 10:43:14,471 - INFO - root - Page:0, Index:6, Dissecting Transformers: A CLEAR Perspective towards Green AI, https://arxiv.org/pdf/2510.02810, 2025-10-03
2025-11-09 10:43:14,471 - INFO - root - Page:0, Index:7, Microscaling Floating Point Formats for Large Language Models, https://arxiv.org/pdf/2510.01863, 2025-10-02
2025-11-09 10:43:14,471 - INFO - root - Page:0, Index:8, Automated and Scalable SEM Image Analysis of Perovskite Solar Cell Materials via a Deep Segmentation Framework, https://arxiv.org/pdf/2509.26548, 2025-09-30
2025-11-09 10:43:14,471 - INFO - root - Page:0, Index:9, AMLA: MUL by ADD in FlashAttention Rescaling, https://arxiv.org/pdf/2509.25224, 2025-09-24
2025-11-09 10:43:14,471 - INFO - root - Page:0, Index:10, Pretraining Large Language Models with NVFP4, https://arxiv.org/pdf/2509.25149, 2025-09-29
2025-11-09 10:43:14,471 - INFO - root - Page:0, Index:11, Bridging the Gap Between Promise and Performance for Microscaling FP4 Quantization, https://arxiv.org/pdf/2509.23202, 2025-10-16
2025-11-09 10:43:14,471 - INFO - root - Page:0, Index:12, Towards Verified Compilation of Floating-point Optimization in Scientific Computing Programs, https://arxiv.org/pdf/2509.09019, 2025-09-10
2025-11-09 10:43:14,471 - INFO - root - Page:0, Index:13, Green Learning for STAR-RIS mmWave Systems with Implicit CSI, https://arxiv.org/pdf/2509.06820, 2025-09-08
2025-11-09 10:43:14,476 - INFO - root - Page:0, Index:14, A Compute&Memory Efficient Model-Driven Neural 5G Receiver for Edge AI-assisted RAN, https://arxiv.org/pdf/2508.12892, 2025-10-22
2025-11-09 10:43:14,476 - INFO - root - Page:0, Index:15, SNNSIR: A Simple Spiking Neural Network for Stereo Image Restoration, https://arxiv.org/pdf/2508.12271, 2025-08-17
2025-11-09 10:43:14,476 - INFO - root - Page:0, Index:16, SpikeSTAG: Spatial-Temporal Forecasting via GNN-SNN Collaboration, https://arxiv.org/pdf/2508.02069, 2025-08-18
2025-11-09 10:43:14,476 - INFO - root - Page:0, Index:17, DGEMM without FP64 Arithmetic - Using FP64 Emulation and FP8 Tensor Cores with Ozaki Scheme, https://arxiv.org/pdf/2508.00441, 2025-09-25
2025-11-09 10:43:14,477 - INFO - root - Page:0, Index:18, Scaling Probabilistic Circuits via Monarch Matrices, https://arxiv.org/pdf/2506.12383, 2025-06-14
2025-11-09 10:43:14,477 - INFO - root - Page:0, Index:19, Starting Positions Matter: A Study on Better Weight Initialization for Neural Network Quantization, https://arxiv.org/pdf/2506.10463, 2025-06-12
2025-11-09 10:43:14,477 - INFO - root - Page:0, Index:20, Recipes for Pre-training LLMs with MXFP8, https://arxiv.org/pdf/2506.08027, 2025-08-18
2025-11-09 10:43:14,477 - INFO - root - Page:0, Index:21, FP4 All the Way: Fully Quantized Training of LLMs, https://arxiv.org/pdf/2505.19115, 2025-08-10
2025-11-09 10:43:14,478 - INFO - root - Page:0, Index:22, Automatic Verification of Floating-Point Accumulation Networks, https://arxiv.org/pdf/2505.18791, 2025-05-24
2025-11-09 10:43:14,478 - INFO - root - Page:0, Index:23, MXDOTP: A RISC-V ISA Extension for Enabling Microscaling (MX) Floating-Point Dot Products, https://arxiv.org/pdf/2505.13159, 2025-05-19
2025-11-09 10:43:14,478 - INFO - root - Page:0, Index:24, Parameter-Efficient Fine-Tuning with Circulant and Diagonal Vectors, https://arxiv.org/pdf/2505.00580, 2025-07-15
2025-11-09 10:43:14,480 - INFO - root - Page:0, Index:25, Silenzio: Secure Non-Interactive Outsourced MLP Training, https://arxiv.org/pdf/2504.17785, 2025-09-18
2025-11-09 10:43:14,480 - INFO - root - Page:0, Index:26, Involution and BSConv Multi-Depth Distillation Network for Lightweight Image Super-Resolution, https://arxiv.org/pdf/2503.14779, 2025-09-08
2025-11-09 10:43:14,480 - INFO - root - Page:0, Index:27, Flopping for FLOPs: Leveraging equivariance for computational efficiency, https://arxiv.org/pdf/2502.05169, 2025-06-24
2025-11-09 10:43:14,481 - INFO - root - Page:0, Index:28, An Effective UNet Using Feature Interaction and Fusion for Organ Segmentation in Medical Image, https://arxiv.org/pdf/2409.05324, 2025-07-26
2025-11-09 10:43:14,481 - INFO - root - Fetching page 2 with URL: https://arxiv.org/search/?query=block+float+point&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=50
2025-11-09 10:43:15,874 - INFO - root - get_all_titles_from_web 
2025-11-09 10:43:15,874 - INFO - root - Page:1, Index:0, TwinLiteNet+: An Enhanced Multi-Task Segmentation Model for Autonomous Driving, https://arxiv.org/pdf/2403.16958, 2025-08-30
2025-11-09 10:43:15,874 - INFO - root - Fetching page 3 with URL: https://arxiv.org/search/?query=block+float+point&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=100
2025-11-09 10:43:17,159 - INFO - root - ------------------------------------------------------------------------------------------------------------------------
2025-11-09 10:43:57,319 - INFO - root - 正在总结论文 1/30: From Uniform to Adaptive: General Skip-Block Mechanisms for Efficient PDE Neural Operators
2025-11-09 10:43:57,319 - INFO - root - 正在提取论文图片...
2025-11-09 10:43:57,752 - INFO - root - 已保存图片 1/10：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_1_page3.png
2025-11-09 10:43:57,814 - INFO - root - 已保存图片 2/10：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_2_page8.png
2025-11-09 10:43:57,914 - INFO - root - 已保存图片 3/10：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_3_page8.png
2025-11-09 10:43:57,978 - INFO - root - 已保存图片 4/10：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_4_page9.png
2025-11-09 10:43:58,046 - INFO - root - 已保存图片 5/10：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_5_page9.png
2025-11-09 10:43:58,121 - INFO - root - 已保存图片 6/10：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_6_page4.png
2025-11-09 10:43:58,206 - INFO - root - 已保存图片 7/10：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_7_page4.png
2025-11-09 10:43:58,277 - INFO - root - 已保存图片 8/10：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_8_page16.png
2025-11-09 10:43:58,296 - INFO - root - 已保存图片 9/10：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_9_page4.png
2025-11-09 10:43:58,307 - INFO - root - 已保存图片 10/10：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_10_page4.png
2025-11-09 10:43:58,313 - INFO - root - 成功添加图片 1：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_1_page3.png
2025-11-09 10:43:58,313 - INFO - root - 成功添加图片 2：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_2_page8.png
2025-11-09 10:43:58,313 - INFO - root - 成功添加图片 3：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_3_page8.png
2025-11-09 10:43:58,313 - INFO - root - 成功添加图片 4：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_4_page9.png
2025-11-09 10:43:58,315 - INFO - root - 成功添加图片 5：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_5_page9.png
2025-11-09 10:43:58,315 - INFO - root - 成功添加图片 6：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_6_page4.png
2025-11-09 10:43:58,315 - INFO - root - 成功添加图片 7：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_7_page4.png
2025-11-09 10:43:58,317 - INFO - root - 成功添加图片 8：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_8_page16.png
2025-11-09 10:43:58,317 - INFO - root - 成功添加图片 9：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_9_page4.png
2025-11-09 10:43:58,317 - INFO - root - 成功添加图片 10：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_10_page4.png
2025-11-09 10:43:58,321 - INFO - root - 论文《From Uniform to Adaptive: General Skip-Block Mechanisms for Efficient PDE Neural Operators》的分析已保存到 ./export\From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural-1.md
2025-11-09 10:43:58,335 - INFO - root - 正在总结论文 2/30: INT v.s. FP: A Comprehensive Study of Fine-Grained Low-bit Quantization Formats
2025-11-09 10:43:58,336 - INFO - root - 正在提取论文图片...
2025-11-09 10:43:58,817 - INFO - root - 已保存图片 1/10：./export\images_INT v.s. FP_ A Comprehensive Study of Fine-Grained Low-bit Quantization Formats\figure_1_page9.png
2025-11-09 10:43:58,884 - INFO - root - 已保存图片 2/10：./export\images_INT v.s. FP_ A Comprehensive Study of Fine-Grained Low-bit Quantization Formats\figure_2_page1.png
2025-11-09 10:43:58,918 - INFO - root - 已保存图片 3/10：./export\images_INT v.s. FP_ A Comprehensive Study of Fine-Grained Low-bit Quantization Formats\figure_3_page1.jpeg
2025-11-09 10:43:58,989 - INFO - root - 已保存图片 4/10：./export\images_INT v.s. FP_ A Comprehensive Study of Fine-Grained Low-bit Quantization Formats\figure_4_page9.png
2025-11-09 10:43:58,995 - INFO - root - 成功添加图片 1：./export\images_INT v.s. FP_ A Comprehensive Study of Fine-Grained Low-bit Quantization Formats\figure_1_page9.png
2025-11-09 10:43:58,995 - INFO - root - 成功添加图片 2：./export\images_INT v.s. FP_ A Comprehensive Study of Fine-Grained Low-bit Quantization Formats\figure_2_page1.png
2025-11-09 10:43:58,997 - INFO - root - 成功添加图片 3：./export\images_INT v.s. FP_ A Comprehensive Study of Fine-Grained Low-bit Quantization Formats\figure_3_page1.jpeg
2025-11-09 10:43:58,997 - INFO - root - 成功添加图片 4：./export\images_INT v.s. FP_ A Comprehensive Study of Fine-Grained Low-bit Quantization Formats\figure_4_page9.png
2025-11-09 10:43:59,009 - INFO - root - 论文《INT v.s. FP: A Comprehensive Study of Fine-Grained Low-bit Quantization Formats》的分析已保存到 ./export\INT v.s. FP_ A Comprehensive Study of Fine-Grained Low-bit Quantization Formats-1.md
2025-11-09 10:43:59,018 - INFO - root - 正在总结论文 3/30: MX+: Pushing the Limits of Microscaling Formats for Efficient Large Language Model Serving
2025-11-09 10:43:59,020 - INFO - root - 正在提取论文图片...
2025-11-09 10:43:59,133 - INFO - root - 已保存图片 1/10：./export\images_MX+_ Pushing the Limits of Microscaling Formats for Efficient Large Language Mod\figure_1_page3.png
2025-11-09 10:43:59,133 - INFO - root - 成功添加图片 1：./export\images_MX+_ Pushing the Limits of Microscaling Formats for Efficient Large Language Mod\figure_1_page3.png
2025-11-09 10:43:59,137 - INFO - root - 论文《MX+: Pushing the Limits of Microscaling Formats for Efficient Large Language Model Serving》的分析已保存到 ./export\MX+_ Pushing the Limits of Microscaling Formats for Efficient Large Language Mod-1.md
2025-11-09 10:43:59,150 - INFO - root - 正在总结论文 4/30: F-BFQ: Flexible Block Floating-Point Quantization Accelerator for LLMs
2025-11-09 10:43:59,151 - INFO - root - 正在提取论文图片...
2025-11-09 10:44:00,097 - INFO - root - 已保存图片 1/10：./export\images_F-BFQ_ Flexible Block Floating-Point Quantization Accelerator for LLMs\figure_1_page4.png
2025-11-09 10:44:00,242 - INFO - root - 已保存图片 2/10：./export\images_F-BFQ_ Flexible Block Floating-Point Quantization Accelerator for LLMs\figure_2_page3.png
2025-11-09 10:44:00,286 - INFO - root - 已保存图片 3/10：./export\images_F-BFQ_ Flexible Block Floating-Point Quantization Accelerator for LLMs\figure_3_page2.png
2025-11-09 10:44:00,298 - INFO - root - 成功添加图片 1：./export\images_F-BFQ_ Flexible Block Floating-Point Quantization Accelerator for LLMs\figure_1_page4.png
2025-11-09 10:44:00,298 - INFO - root - 成功添加图片 2：./export\images_F-BFQ_ Flexible Block Floating-Point Quantization Accelerator for LLMs\figure_2_page3.png
2025-11-09 10:44:00,299 - INFO - root - 成功添加图片 3：./export\images_F-BFQ_ Flexible Block Floating-Point Quantization Accelerator for LLMs\figure_3_page2.png
2025-11-09 10:44:00,304 - INFO - root - 论文《F-BFQ: Flexible Block Floating-Point Quantization Accelerator for LLMs》的分析已保存到 ./export\F-BFQ_ Flexible Block Floating-Point Quantization Accelerator for LLMs-1.md
2025-11-09 10:44:00,310 - INFO - root - 正在总结论文 5/30: Computationally Efficient Neural Receivers via Axial Self-Attention
2025-11-09 10:44:00,314 - INFO - root - 正在提取论文图片...
2025-11-09 10:44:01,593 - INFO - root - 已保存图片 1/10：./export\images_Computationally Efficient Neural Receivers via Axial Self-Attention\figure_1_page5.png
2025-11-09 10:44:01,601 - INFO - root - 成功添加图片 1：./export\images_Computationally Efficient Neural Receivers via Axial Self-Attention\figure_1_page5.png
2025-11-09 10:44:01,608 - INFO - root - 论文《Computationally Efficient Neural Receivers via Axial Self-Attention》的分析已保存到 ./export\Computationally Efficient Neural Receivers via Axial Self-Attention-1.md
2025-11-09 10:44:01,617 - INFO - root - 正在总结论文 6/30: Efficient In-Memory Acceleration of Sparse Block Diagonal LLMs
2025-11-09 10:44:01,619 - INFO - root - 正在提取论文图片...
2025-11-09 10:44:01,703 - INFO - root - 已保存图片 1/10：./export\images_Efficient In-Memory Acceleration of Sparse Block Diagonal LLMs\figure_1_page3.png
2025-11-09 10:44:01,769 - INFO - root - 已保存图片 2/10：./export\images_Efficient In-Memory Acceleration of Sparse Block Diagonal LLMs\figure_2_page3.png
2025-11-09 10:44:01,909 - INFO - root - 已保存图片 3/10：./export\images_Efficient In-Memory Acceleration of Sparse Block Diagonal LLMs\figure_3_page3.png
2025-11-09 10:44:01,910 - INFO - root - 成功添加图片 1：./export\images_Efficient In-Memory Acceleration of Sparse Block Diagonal LLMs\figure_1_page3.png
2025-11-09 10:44:01,910 - INFO - root - 成功添加图片 2：./export\images_Efficient In-Memory Acceleration of Sparse Block Diagonal LLMs\figure_2_page3.png
2025-11-09 10:44:01,912 - INFO - root - 成功添加图片 3：./export\images_Efficient In-Memory Acceleration of Sparse Block Diagonal LLMs\figure_3_page3.png
2025-11-09 10:44:01,921 - INFO - root - 论文《Efficient In-Memory Acceleration of Sparse Block Diagonal LLMs》的分析已保存到 ./export\Efficient In-Memory Acceleration of Sparse Block Diagonal LLMs-1.md
2025-11-09 10:44:01,932 - INFO - root - 正在总结论文 7/30: Dissecting Transformers: A CLEAR Perspective towards Green AI
2025-11-09 10:44:01,934 - INFO - root - 正在提取论文图片...
2025-11-09 10:44:02,051 - WARNING - root - 处理页面 19 的图片 1 时出错：Image size (360000000 pixels) exceeds limit of 178956970 pixels, could be decompression bomb DOS attack.
2025-11-09 10:44:02,223 - INFO - root - 已保存图片 1/10：./export\images_Dissecting Transformers_ A CLEAR Perspective towards Green AI\figure_1_page3.png
2025-11-09 10:44:02,317 - INFO - root - 已保存图片 2/10：./export\images_Dissecting Transformers_ A CLEAR Perspective towards Green AI\figure_2_page3.png
2025-11-09 10:44:02,443 - INFO - root - 已保存图片 3/10：./export\images_Dissecting Transformers_ A CLEAR Perspective towards Green AI\figure_3_page3.png
2025-11-09 10:44:02,555 - INFO - root - 已保存图片 4/10：./export\images_Dissecting Transformers_ A CLEAR Perspective towards Green AI\figure_4_page3.png
2025-11-09 10:44:02,691 - INFO - root - 已保存图片 5/10：./export\images_Dissecting Transformers_ A CLEAR Perspective towards Green AI\figure_5_page3.png
2025-11-09 10:44:02,691 - INFO - root - 成功添加图片 1：./export\images_Dissecting Transformers_ A CLEAR Perspective towards Green AI\figure_1_page3.png
2025-11-09 10:44:02,691 - INFO - root - 成功添加图片 2：./export\images_Dissecting Transformers_ A CLEAR Perspective towards Green AI\figure_2_page3.png
2025-11-09 10:44:02,691 - INFO - root - 成功添加图片 3：./export\images_Dissecting Transformers_ A CLEAR Perspective towards Green AI\figure_3_page3.png
2025-11-09 10:44:02,691 - INFO - root - 成功添加图片 4：./export\images_Dissecting Transformers_ A CLEAR Perspective towards Green AI\figure_4_page3.png
2025-11-09 10:44:02,691 - INFO - root - 成功添加图片 5：./export\images_Dissecting Transformers_ A CLEAR Perspective towards Green AI\figure_5_page3.png
2025-11-09 10:44:02,699 - INFO - root - 论文《Dissecting Transformers: A CLEAR Perspective towards Green AI》的分析已保存到 ./export\Dissecting Transformers_ A CLEAR Perspective towards Green AI-1.md
2025-11-09 10:44:02,711 - INFO - root - 正在总结论文 8/30: Microscaling Floating Point Formats for Large Language Models
2025-11-09 10:44:02,718 - INFO - root - 正在提取论文图片...
2025-11-09 10:44:02,737 - INFO - root - 论文《Microscaling Floating Point Formats for Large Language Models》的分析已保存到 ./export\Microscaling Floating Point Formats for Large Language Models-1.md
2025-11-09 10:44:02,760 - INFO - root - 正在总结论文 9/30: Automated and Scalable SEM Image Analysis of Perovskite Solar Cell Materials via a Deep Segmentation Framework
2025-11-09 10:44:02,762 - INFO - root - 正在提取论文图片...
2025-11-09 10:44:32,563 - INFO - root - 已保存图片 1/10：./export\images_Automated and Scalable SEM Image Analysis of Perovskite Solar Cell Materials via\figure_1_page8.jpeg
2025-11-09 10:44:32,843 - INFO - root - 已保存图片 2/10：./export\images_Automated and Scalable SEM Image Analysis of Perovskite Solar Cell Materials via\figure_2_page5.jpeg
2025-11-09 10:44:33,156 - INFO - root - 已保存图片 3/10：./export\images_Automated and Scalable SEM Image Analysis of Perovskite Solar Cell Materials via\figure_3_page9.jpeg
2025-11-09 10:44:33,411 - INFO - root - 已保存图片 4/10：./export\images_Automated and Scalable SEM Image Analysis of Perovskite Solar Cell Materials via\figure_4_page9.jpeg
2025-11-09 10:44:33,641 - INFO - root - 已保存图片 5/10：./export\images_Automated and Scalable SEM Image Analysis of Perovskite Solar Cell Materials via\figure_5_page9.jpeg
2025-11-09 10:44:33,837 - INFO - root - 已保存图片 6/10：./export\images_Automated and Scalable SEM Image Analysis of Perovskite Solar Cell Materials via\figure_6_page9.jpeg
2025-11-09 10:44:34,057 - INFO - root - 已保存图片 7/10：./export\images_Automated and Scalable SEM Image Analysis of Perovskite Solar Cell Materials via\figure_7_page9.jpeg
2025-11-09 10:44:34,251 - INFO - root - 已保存图片 8/10：./export\images_Automated and Scalable SEM Image Analysis of Perovskite Solar Cell Materials via\figure_8_page9.jpeg
2025-11-09 10:44:34,453 - INFO - root - 已保存图片 9/10：./export\images_Automated and Scalable SEM Image Analysis of Perovskite Solar Cell Materials via\figure_9_page9.jpeg
2025-11-09 10:44:34,645 - INFO - root - 已保存图片 10/10：./export\images_Automated and Scalable SEM Image Analysis of Perovskite Solar Cell Materials via\figure_10_page9.jpeg
2025-11-09 10:44:34,678 - INFO - root - 成功添加图片 1：./export\images_Automated and Scalable SEM Image Analysis of Perovskite Solar Cell Materials via\figure_1_page8.jpeg
2025-11-09 10:44:34,679 - INFO - root - 成功添加图片 2：./export\images_Automated and Scalable SEM Image Analysis of Perovskite Solar Cell Materials via\figure_2_page5.jpeg
2025-11-09 10:44:34,680 - INFO - root - 成功添加图片 3：./export\images_Automated and Scalable SEM Image Analysis of Perovskite Solar Cell Materials via\figure_3_page9.jpeg
2025-11-09 10:44:34,680 - INFO - root - 成功添加图片 4：./export\images_Automated and Scalable SEM Image Analysis of Perovskite Solar Cell Materials via\figure_4_page9.jpeg
2025-11-09 10:44:34,680 - INFO - root - 成功添加图片 5：./export\images_Automated and Scalable SEM Image Analysis of Perovskite Solar Cell Materials via\figure_5_page9.jpeg
2025-11-09 10:44:34,680 - INFO - root - 成功添加图片 6：./export\images_Automated and Scalable SEM Image Analysis of Perovskite Solar Cell Materials via\figure_6_page9.jpeg
2025-11-09 10:44:34,680 - INFO - root - 成功添加图片 7：./export\images_Automated and Scalable SEM Image Analysis of Perovskite Solar Cell Materials via\figure_7_page9.jpeg
2025-11-09 10:44:34,680 - INFO - root - 成功添加图片 8：./export\images_Automated and Scalable SEM Image Analysis of Perovskite Solar Cell Materials via\figure_8_page9.jpeg
2025-11-09 10:44:34,680 - INFO - root - 成功添加图片 9：./export\images_Automated and Scalable SEM Image Analysis of Perovskite Solar Cell Materials via\figure_9_page9.jpeg
2025-11-09 10:44:34,680 - INFO - root - 成功添加图片 10：./export\images_Automated and Scalable SEM Image Analysis of Perovskite Solar Cell Materials via\figure_10_page9.jpeg
2025-11-09 10:44:34,689 - INFO - root - 论文《Automated and Scalable SEM Image Analysis of Perovskite Solar Cell Materials via a Deep Segmentation Framework》的分析已保存到 ./export\Automated and Scalable SEM Image Analysis of Perovskite Solar Cell Materials via-1.md
2025-11-09 10:44:34,695 - INFO - root - 正在总结论文 10/30: AMLA: MUL by ADD in FlashAttention Rescaling
2025-11-09 10:44:34,698 - INFO - root - 正在提取论文图片...
2025-11-09 10:44:35,653 - INFO - root - 已保存图片 1/10：./export\images_AMLA_ MUL by ADD in FlashAttention Rescaling\figure_1_page15.png
2025-11-09 10:44:35,705 - INFO - root - 已保存图片 2/10：./export\images_AMLA_ MUL by ADD in FlashAttention Rescaling\figure_2_page4.jpeg
2025-11-09 10:44:35,752 - INFO - root - 已保存图片 3/10：./export\images_AMLA_ MUL by ADD in FlashAttention Rescaling\figure_3_page8.jpeg
2025-11-09 10:44:35,752 - INFO - root - 成功添加图片 1：./export\images_AMLA_ MUL by ADD in FlashAttention Rescaling\figure_1_page15.png
2025-11-09 10:44:35,752 - INFO - root - 成功添加图片 2：./export\images_AMLA_ MUL by ADD in FlashAttention Rescaling\figure_2_page4.jpeg
2025-11-09 10:44:35,752 - INFO - root - 成功添加图片 3：./export\images_AMLA_ MUL by ADD in FlashAttention Rescaling\figure_3_page8.jpeg
2025-11-09 10:44:35,766 - INFO - root - 论文《AMLA: MUL by ADD in FlashAttention Rescaling》的分析已保存到 ./export\AMLA_ MUL by ADD in FlashAttention Rescaling-1.md
2025-11-09 10:44:35,774 - INFO - root - 正在总结论文 11/30: Pretraining Large Language Models with NVFP4
2025-11-09 10:44:35,774 - INFO - root - 正在提取论文图片...
2025-11-09 10:44:35,975 - INFO - root - 已保存图片 1/10：./export\images_Pretraining Large Language Models with NVFP4\figure_1_page7.png
2025-11-09 10:44:36,036 - INFO - root - 已保存图片 2/10：./export\images_Pretraining Large Language Models with NVFP4\figure_2_page7.jpeg
2025-11-09 10:44:36,072 - INFO - root - 已保存图片 3/10：./export\images_Pretraining Large Language Models with NVFP4\figure_3_page1.png
2025-11-09 10:44:36,097 - INFO - root - 已保存图片 4/10：./export\images_Pretraining Large Language Models with NVFP4\figure_4_page7.jpeg
2025-11-09 10:44:36,128 - INFO - root - 已保存图片 5/10：./export\images_Pretraining Large Language Models with NVFP4\figure_5_page7.jpeg
2025-11-09 10:44:36,220 - INFO - root - 已保存图片 6/10：./export\images_Pretraining Large Language Models with NVFP4\figure_6_page7.jpeg
2025-11-09 10:44:36,277 - INFO - root - 已保存图片 7/10：./export\images_Pretraining Large Language Models with NVFP4\figure_7_page7.png
2025-11-09 10:44:36,307 - INFO - root - 已保存图片 8/10：./export\images_Pretraining Large Language Models with NVFP4\figure_8_page7.jpeg
2025-11-09 10:44:36,340 - INFO - root - 已保存图片 9/10：./export\images_Pretraining Large Language Models with NVFP4\figure_9_page7.jpeg
2025-11-09 10:44:36,387 - INFO - root - 已保存图片 10/10：./export\images_Pretraining Large Language Models with NVFP4\figure_10_page7.jpeg
2025-11-09 10:44:36,389 - INFO - root - 成功添加图片 1：./export\images_Pretraining Large Language Models with NVFP4\figure_1_page7.png
2025-11-09 10:44:36,389 - INFO - root - 成功添加图片 2：./export\images_Pretraining Large Language Models with NVFP4\figure_2_page7.jpeg
2025-11-09 10:44:36,389 - INFO - root - 成功添加图片 3：./export\images_Pretraining Large Language Models with NVFP4\figure_3_page1.png
2025-11-09 10:44:36,389 - INFO - root - 成功添加图片 4：./export\images_Pretraining Large Language Models with NVFP4\figure_4_page7.jpeg
2025-11-09 10:44:36,389 - INFO - root - 成功添加图片 5：./export\images_Pretraining Large Language Models with NVFP4\figure_5_page7.jpeg
2025-11-09 10:44:36,389 - INFO - root - 成功添加图片 6：./export\images_Pretraining Large Language Models with NVFP4\figure_6_page7.jpeg
2025-11-09 10:44:36,389 - INFO - root - 成功添加图片 7：./export\images_Pretraining Large Language Models with NVFP4\figure_7_page7.png
2025-11-09 10:44:36,389 - INFO - root - 成功添加图片 8：./export\images_Pretraining Large Language Models with NVFP4\figure_8_page7.jpeg
2025-11-09 10:44:36,397 - INFO - root - 成功添加图片 9：./export\images_Pretraining Large Language Models with NVFP4\figure_9_page7.jpeg
2025-11-09 10:44:36,397 - INFO - root - 成功添加图片 10：./export\images_Pretraining Large Language Models with NVFP4\figure_10_page7.jpeg
2025-11-09 10:44:36,406 - INFO - root - 论文《Pretraining Large Language Models with NVFP4》的分析已保存到 ./export\Pretraining Large Language Models with NVFP4-1.md
2025-11-09 10:44:36,416 - INFO - root - 正在总结论文 12/30: Bridging the Gap Between Promise and Performance for Microscaling FP4 Quantization
2025-11-09 10:44:36,418 - INFO - root - 正在提取论文图片...
2025-11-09 10:44:36,558 - INFO - root - 已保存图片 1/10：./export\images_Bridging the Gap Between Promise and Performance for Microscaling FP4 Quantizati\figure_1_page25.png
2025-11-09 10:44:36,559 - INFO - root - 成功添加图片 1：./export\images_Bridging the Gap Between Promise and Performance for Microscaling FP4 Quantizati\figure_1_page25.png
2025-11-09 10:44:36,577 - INFO - root - 论文《Bridging the Gap Between Promise and Performance for Microscaling FP4 Quantization》的分析已保存到 ./export\Bridging the Gap Between Promise and Performance for Microscaling FP4 Quantizati-1.md
2025-11-09 10:44:36,589 - INFO - root - 正在总结论文 13/30: Towards Verified Compilation of Floating-point Optimization in Scientific Computing Programs
2025-11-09 10:44:36,591 - INFO - root - 正在提取论文图片...
2025-11-09 10:44:36,597 - INFO - root - 论文《Towards Verified Compilation of Floating-point Optimization in Scientific Computing Programs》的分析已保存到 ./export\Towards Verified Compilation of Floating-point Optimization in Scientific Comput-1.md
2025-11-09 10:44:36,608 - INFO - root - 正在总结论文 14/30: Green Learning for STAR-RIS mmWave Systems with Implicit CSI
2025-11-09 10:44:36,609 - INFO - root - 正在提取论文图片...
2025-11-09 10:44:36,795 - INFO - root - 已保存图片 1/10：./export\images_Green Learning for STAR-RIS mmWave Systems with Implicit CSI\figure_1_page2.jpeg
2025-11-09 10:44:36,926 - INFO - root - 已保存图片 2/10：./export\images_Green Learning for STAR-RIS mmWave Systems with Implicit CSI\figure_2_page2.png
2025-11-09 10:44:36,977 - INFO - root - 已保存图片 3/10：./export\images_Green Learning for STAR-RIS mmWave Systems with Implicit CSI\figure_3_page2.png
2025-11-09 10:44:37,035 - INFO - root - 已保存图片 4/10：./export\images_Green Learning for STAR-RIS mmWave Systems with Implicit CSI\figure_4_page2.png
2025-11-09 10:44:37,037 - INFO - root - 成功添加图片 1：./export\images_Green Learning for STAR-RIS mmWave Systems with Implicit CSI\figure_1_page2.jpeg
2025-11-09 10:44:37,039 - INFO - root - 成功添加图片 2：./export\images_Green Learning for STAR-RIS mmWave Systems with Implicit CSI\figure_2_page2.png
2025-11-09 10:44:37,039 - INFO - root - 成功添加图片 3：./export\images_Green Learning for STAR-RIS mmWave Systems with Implicit CSI\figure_3_page2.png
2025-11-09 10:44:37,041 - INFO - root - 成功添加图片 4：./export\images_Green Learning for STAR-RIS mmWave Systems with Implicit CSI\figure_4_page2.png
2025-11-09 10:44:37,055 - INFO - root - 论文《Green Learning for STAR-RIS mmWave Systems with Implicit CSI》的分析已保存到 ./export\Green Learning for STAR-RIS mmWave Systems with Implicit CSI-1.md
2025-11-09 10:44:37,064 - INFO - root - 正在总结论文 15/30: A Compute&Memory Efficient Model-Driven Neural 5G Receiver for Edge AI-assisted RAN
2025-11-09 10:44:37,065 - INFO - root - 正在提取论文图片...
2025-11-09 10:44:37,775 - INFO - root - 已保存图片 1/10：./export\images_A Compute&Memory Efficient Model-Driven Neural 5G Receiver for Edge AI-assisted\figure_1_page6.png
2025-11-09 10:44:37,872 - INFO - root - 已保存图片 2/10：./export\images_A Compute&Memory Efficient Model-Driven Neural 5G Receiver for Edge AI-assisted\figure_2_page6.png
2025-11-09 10:44:37,969 - INFO - root - 已保存图片 3/10：./export\images_A Compute&Memory Efficient Model-Driven Neural 5G Receiver for Edge AI-assisted\figure_3_page2.png
2025-11-09 10:54:15,017 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-09 10:54:15,033 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-09 10:54:15,033 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-09 10:55:08,572 - ERROR - root - LLMClient: error during initialization: Timeout of 60.0s exceeded, last exception: 503 failed to connect to all addresses; last error: UNKNOWN: ipv4:142.251.34.202:443: socket is null
2025-11-09 10:55:08,574 - INFO - root - LLM 未初始化或不可用，后续生成将返回备用消息
2025-11-09 10:55:08,574 - INFO - root - === 运行配置 ===
2025-11-09 10:55:08,575 - INFO - root - 处理模式: arxiv在线搜索
2025-11-09 10:55:08,576 - INFO - root - 关键词: Quant
2025-11-09 10:55:08,576 - INFO - root - 查询: block float point
2025-11-09 10:55:08,578 - INFO - root - 排序: None
2025-11-09 10:55:08,578 - INFO - root - 最近天数: 180
2025-11-09 10:55:08,578 - INFO - root - 最大处理数量: 50
2025-11-09 10:55:08,578 - INFO - root - 保存图片: 是
2025-11-09 10:55:08,578 - INFO - root - 输出语言: 中文
2025-11-09 10:55:08,578 - INFO - root - 强制重新处理: 否
2025-11-09 10:55:08,578 - INFO - root - ====================
2025-11-09 10:55:08,590 - INFO - root - 使用 arXiv 搜索模式（通过 chat_arxiv 模块获取）
2025-11-09 10:55:08,590 - INFO - root - Fetching page 1 with URL: https://arxiv.org/search/?query=block+float+point&searchtype=all&abstracts=show&order=-announced_date_first&size=50
2025-11-09 10:55:39,943 - INFO - root - get_all_titles_from_web 
2025-11-09 10:55:39,943 - INFO - root - Page:0, Index:0, From Uniform to Adaptive: General Skip-Block Mechanisms for Efficient PDE Neural Operators, https://arxiv.org/pdf/2511.00032, 2025-11-04
2025-11-09 10:55:39,943 - INFO - root - Page:0, Index:1, INT v.s. FP: A Comprehensive Study of Fine-Grained Low-bit Quantization Formats, https://arxiv.org/pdf/2510.25602, 2025-10-29
2025-11-09 10:55:39,943 - INFO - root - Page:0, Index:2, MX+: Pushing the Limits of Microscaling Formats for Efficient Large Language Model Serving, https://arxiv.org/pdf/2510.14557, 2025-10-16
2025-11-09 10:55:39,943 - INFO - root - Page:0, Index:3, F-BFQ: Flexible Block Floating-Point Quantization Accelerator for LLMs, https://arxiv.org/pdf/2510.13401, 2025-10-15
2025-11-09 10:55:39,943 - INFO - root - Page:0, Index:4, Computationally Efficient Neural Receivers via Axial Self-Attention, https://arxiv.org/pdf/2510.12941, 2025-10-14
2025-11-09 10:55:39,943 - INFO - root - Page:0, Index:5, Efficient In-Memory Acceleration of Sparse Block Diagonal LLMs, https://arxiv.org/pdf/2510.11192, 2025-10-13
2025-11-09 10:55:39,943 - INFO - root - Page:0, Index:6, Dissecting Transformers: A CLEAR Perspective towards Green AI, https://arxiv.org/pdf/2510.02810, 2025-10-03
2025-11-09 10:55:39,943 - INFO - root - Page:0, Index:7, Microscaling Floating Point Formats for Large Language Models, https://arxiv.org/pdf/2510.01863, 2025-10-02
2025-11-09 10:55:39,943 - INFO - root - Page:0, Index:8, Automated and Scalable SEM Image Analysis of Perovskite Solar Cell Materials via a Deep Segmentation Framework, https://arxiv.org/pdf/2509.26548, 2025-09-30
2025-11-09 10:55:39,943 - INFO - root - Page:0, Index:9, AMLA: MUL by ADD in FlashAttention Rescaling, https://arxiv.org/pdf/2509.25224, 2025-09-24
2025-11-09 10:55:39,949 - INFO - root - Page:0, Index:10, Pretraining Large Language Models with NVFP4, https://arxiv.org/pdf/2509.25149, 2025-09-29
2025-11-09 10:55:39,949 - INFO - root - Page:0, Index:11, Bridging the Gap Between Promise and Performance for Microscaling FP4 Quantization, https://arxiv.org/pdf/2509.23202, 2025-10-16
2025-11-09 10:55:39,949 - INFO - root - Page:0, Index:12, Towards Verified Compilation of Floating-point Optimization in Scientific Computing Programs, https://arxiv.org/pdf/2509.09019, 2025-09-10
2025-11-09 10:55:39,949 - INFO - root - Page:0, Index:13, Green Learning for STAR-RIS mmWave Systems with Implicit CSI, https://arxiv.org/pdf/2509.06820, 2025-09-08
2025-11-09 10:55:39,949 - INFO - root - Page:0, Index:14, A Compute&Memory Efficient Model-Driven Neural 5G Receiver for Edge AI-assisted RAN, https://arxiv.org/pdf/2508.12892, 2025-10-22
2025-11-09 10:55:39,949 - INFO - root - Page:0, Index:15, SNNSIR: A Simple Spiking Neural Network for Stereo Image Restoration, https://arxiv.org/pdf/2508.12271, 2025-08-17
2025-11-09 10:55:39,949 - INFO - root - Page:0, Index:16, SpikeSTAG: Spatial-Temporal Forecasting via GNN-SNN Collaboration, https://arxiv.org/pdf/2508.02069, 2025-08-18
2025-11-09 10:55:39,949 - INFO - root - Page:0, Index:17, DGEMM without FP64 Arithmetic - Using FP64 Emulation and FP8 Tensor Cores with Ozaki Scheme, https://arxiv.org/pdf/2508.00441, 2025-09-25
2025-11-09 10:55:39,949 - INFO - root - Page:0, Index:18, Scaling Probabilistic Circuits via Monarch Matrices, https://arxiv.org/pdf/2506.12383, 2025-06-14
2025-11-09 10:55:39,949 - INFO - root - Page:0, Index:19, Starting Positions Matter: A Study on Better Weight Initialization for Neural Network Quantization, https://arxiv.org/pdf/2506.10463, 2025-06-12
2025-11-09 10:55:39,949 - INFO - root - Page:0, Index:20, Recipes for Pre-training LLMs with MXFP8, https://arxiv.org/pdf/2506.08027, 2025-08-18
2025-11-09 10:55:39,949 - INFO - root - Page:0, Index:21, FP4 All the Way: Fully Quantized Training of LLMs, https://arxiv.org/pdf/2505.19115, 2025-08-10
2025-11-09 10:55:39,949 - INFO - root - Page:0, Index:22, Automatic Verification of Floating-Point Accumulation Networks, https://arxiv.org/pdf/2505.18791, 2025-05-24
2025-11-09 10:55:39,949 - INFO - root - Page:0, Index:23, MXDOTP: A RISC-V ISA Extension for Enabling Microscaling (MX) Floating-Point Dot Products, https://arxiv.org/pdf/2505.13159, 2025-05-19
2025-11-09 10:55:39,949 - INFO - root - Page:0, Index:24, Parameter-Efficient Fine-Tuning with Circulant and Diagonal Vectors, https://arxiv.org/pdf/2505.00580, 2025-07-15
2025-11-09 10:55:39,949 - INFO - root - Page:0, Index:25, Silenzio: Secure Non-Interactive Outsourced MLP Training, https://arxiv.org/pdf/2504.17785, 2025-09-18
2025-11-09 10:55:39,949 - INFO - root - Page:0, Index:26, Involution and BSConv Multi-Depth Distillation Network for Lightweight Image Super-Resolution, https://arxiv.org/pdf/2503.14779, 2025-09-08
2025-11-09 10:55:39,949 - INFO - root - Page:0, Index:27, Flopping for FLOPs: Leveraging equivariance for computational efficiency, https://arxiv.org/pdf/2502.05169, 2025-06-24
2025-11-09 10:55:39,949 - INFO - root - Page:0, Index:28, An Effective UNet Using Feature Interaction and Fusion for Organ Segmentation in Medical Image, https://arxiv.org/pdf/2409.05324, 2025-07-26
2025-11-09 10:55:39,949 - INFO - root - Fetching page 2 with URL: https://arxiv.org/search/?query=block+float+point&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=50
2025-11-09 10:59:20,251 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-09 10:59:20,252 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-09 10:59:20,254 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-09 10:59:21,780 - INFO - root - LLMClient: trying model gemini-2.5-flash
2025-11-09 10:59:22,916 - INFO - root - LLMClient: trying model gemini-2.5-pro
2025-11-09 10:59:23,284 - WARNING - root - LLMClient: no usable model found, LLM disabled
2025-11-09 10:59:23,284 - INFO - root - LLM 未初始化或不可用，后续生成将返回备用消息
2025-11-09 10:59:23,285 - INFO - root - === 运行配置 ===
2025-11-09 10:59:23,285 - INFO - root - 处理模式: arxiv在线搜索
2025-11-09 10:59:23,286 - INFO - root - 关键词: Quant
2025-11-09 10:59:23,286 - INFO - root - 查询: block float point
2025-11-09 10:59:23,286 - INFO - root - 排序: None
2025-11-09 10:59:23,287 - INFO - root - 最近天数: 180
2025-11-09 10:59:23,287 - INFO - root - 最大处理数量: 50
2025-11-09 10:59:23,288 - INFO - root - 保存图片: 是
2025-11-09 10:59:23,288 - INFO - root - 输出语言: 中文
2025-11-09 10:59:23,288 - INFO - root - 强制重新处理: 否
2025-11-09 10:59:23,288 - INFO - root - ====================
2025-11-09 10:59:23,289 - INFO - root - 使用 arXiv 搜索模式（通过 chat_arxiv 模块获取）
2025-11-09 10:59:23,290 - INFO - root - Fetching page 1 with URL: https://arxiv.org/search/?query=block+float+point&searchtype=all&abstracts=show&order=-announced_date_first&size=50
2025-11-09 10:59:29,441 - INFO - root - get_all_titles_from_web 
2025-11-09 10:59:29,441 - INFO - root - Page:0, Index:0, From Uniform to Adaptive: General Skip-Block Mechanisms for Efficient PDE Neural Operators, https://arxiv.org/pdf/2511.00032, 2025-11-04
2025-11-09 10:59:29,442 - INFO - root - Page:0, Index:1, INT v.s. FP: A Comprehensive Study of Fine-Grained Low-bit Quantization Formats, https://arxiv.org/pdf/2510.25602, 2025-10-29
2025-11-09 10:59:29,442 - INFO - root - Page:0, Index:2, MX+: Pushing the Limits of Microscaling Formats for Efficient Large Language Model Serving, https://arxiv.org/pdf/2510.14557, 2025-10-16
2025-11-09 10:59:29,442 - INFO - root - Page:0, Index:3, F-BFQ: Flexible Block Floating-Point Quantization Accelerator for LLMs, https://arxiv.org/pdf/2510.13401, 2025-10-15
2025-11-09 10:59:29,442 - INFO - root - Page:0, Index:4, Computationally Efficient Neural Receivers via Axial Self-Attention, https://arxiv.org/pdf/2510.12941, 2025-10-14
2025-11-09 10:59:29,444 - INFO - root - Page:0, Index:5, Efficient In-Memory Acceleration of Sparse Block Diagonal LLMs, https://arxiv.org/pdf/2510.11192, 2025-10-13
2025-11-09 10:59:29,444 - INFO - root - Page:0, Index:6, Dissecting Transformers: A CLEAR Perspective towards Green AI, https://arxiv.org/pdf/2510.02810, 2025-10-03
2025-11-09 10:59:29,444 - INFO - root - Page:0, Index:7, Microscaling Floating Point Formats for Large Language Models, https://arxiv.org/pdf/2510.01863, 2025-10-02
2025-11-09 10:59:29,444 - INFO - root - Page:0, Index:8, Automated and Scalable SEM Image Analysis of Perovskite Solar Cell Materials via a Deep Segmentation Framework, https://arxiv.org/pdf/2509.26548, 2025-09-30
2025-11-09 10:59:29,445 - INFO - root - Page:0, Index:9, AMLA: MUL by ADD in FlashAttention Rescaling, https://arxiv.org/pdf/2509.25224, 2025-09-24
2025-11-09 10:59:29,445 - INFO - root - Page:0, Index:10, Pretraining Large Language Models with NVFP4, https://arxiv.org/pdf/2509.25149, 2025-09-29
2025-11-09 10:59:29,445 - INFO - root - Page:0, Index:11, Bridging the Gap Between Promise and Performance for Microscaling FP4 Quantization, https://arxiv.org/pdf/2509.23202, 2025-10-16
2025-11-09 10:59:29,446 - INFO - root - Page:0, Index:12, Towards Verified Compilation of Floating-point Optimization in Scientific Computing Programs, https://arxiv.org/pdf/2509.09019, 2025-09-10
2025-11-09 10:59:29,446 - INFO - root - Page:0, Index:13, Green Learning for STAR-RIS mmWave Systems with Implicit CSI, https://arxiv.org/pdf/2509.06820, 2025-09-08
2025-11-09 10:59:29,446 - INFO - root - Page:0, Index:14, A Compute&Memory Efficient Model-Driven Neural 5G Receiver for Edge AI-assisted RAN, https://arxiv.org/pdf/2508.12892, 2025-10-22
2025-11-09 10:59:29,447 - INFO - root - Page:0, Index:15, SNNSIR: A Simple Spiking Neural Network for Stereo Image Restoration, https://arxiv.org/pdf/2508.12271, 2025-08-17
2025-11-09 10:59:29,447 - INFO - root - Page:0, Index:16, SpikeSTAG: Spatial-Temporal Forecasting via GNN-SNN Collaboration, https://arxiv.org/pdf/2508.02069, 2025-08-18
2025-11-09 10:59:29,450 - INFO - root - Page:0, Index:17, DGEMM without FP64 Arithmetic - Using FP64 Emulation and FP8 Tensor Cores with Ozaki Scheme, https://arxiv.org/pdf/2508.00441, 2025-09-25
2025-11-09 10:59:29,451 - INFO - root - Page:0, Index:18, Scaling Probabilistic Circuits via Monarch Matrices, https://arxiv.org/pdf/2506.12383, 2025-06-14
2025-11-09 10:59:29,452 - INFO - root - Page:0, Index:19, Starting Positions Matter: A Study on Better Weight Initialization for Neural Network Quantization, https://arxiv.org/pdf/2506.10463, 2025-06-12
2025-11-09 10:59:29,452 - INFO - root - Page:0, Index:20, Recipes for Pre-training LLMs with MXFP8, https://arxiv.org/pdf/2506.08027, 2025-08-18
2025-11-09 10:59:29,452 - INFO - root - Page:0, Index:21, FP4 All the Way: Fully Quantized Training of LLMs, https://arxiv.org/pdf/2505.19115, 2025-08-10
2025-11-09 10:59:29,453 - INFO - root - Page:0, Index:22, Automatic Verification of Floating-Point Accumulation Networks, https://arxiv.org/pdf/2505.18791, 2025-05-24
2025-11-09 10:59:29,454 - INFO - root - Page:0, Index:23, MXDOTP: A RISC-V ISA Extension for Enabling Microscaling (MX) Floating-Point Dot Products, https://arxiv.org/pdf/2505.13159, 2025-05-19
2025-11-09 10:59:29,455 - INFO - root - Page:0, Index:24, Parameter-Efficient Fine-Tuning with Circulant and Diagonal Vectors, https://arxiv.org/pdf/2505.00580, 2025-07-15
2025-11-09 10:59:29,455 - INFO - root - Page:0, Index:25, Silenzio: Secure Non-Interactive Outsourced MLP Training, https://arxiv.org/pdf/2504.17785, 2025-09-18
2025-11-09 10:59:29,455 - INFO - root - Page:0, Index:26, Involution and BSConv Multi-Depth Distillation Network for Lightweight Image Super-Resolution, https://arxiv.org/pdf/2503.14779, 2025-09-08
2025-11-09 10:59:29,456 - INFO - root - Page:0, Index:27, Flopping for FLOPs: Leveraging equivariance for computational efficiency, https://arxiv.org/pdf/2502.05169, 2025-06-24
2025-11-09 10:59:29,457 - INFO - root - Page:0, Index:28, An Effective UNet Using Feature Interaction and Fusion for Organ Segmentation in Medical Image, https://arxiv.org/pdf/2409.05324, 2025-07-26
2025-11-09 10:59:29,458 - INFO - root - Fetching page 2 with URL: https://arxiv.org/search/?query=block+float+point&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=50
2025-11-09 10:59:35,891 - INFO - root - get_all_titles_from_web 
2025-11-09 10:59:35,892 - INFO - root - Page:1, Index:0, TwinLiteNet+: An Enhanced Multi-Task Segmentation Model for Autonomous Driving, https://arxiv.org/pdf/2403.16958, 2025-08-30
2025-11-09 10:59:35,892 - INFO - root - Fetching page 3 with URL: https://arxiv.org/search/?query=block+float+point&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=100
2025-11-09 10:59:42,083 - INFO - root - ------------------------------------------------------------------------------------------------------------------------
2025-11-09 11:02:42,840 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-09 11:02:42,841 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-09 11:02:42,846 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-09 11:02:43,393 - INFO - root - LLMClient: trying model gemini-2.5-flash
2025-11-09 11:02:44,233 - INFO - root - LLMClient: trying model gemini-2.5-pro
2025-11-09 11:02:44,596 - WARNING - root - LLMClient: no usable model found, LLM disabled
2025-11-09 11:02:44,596 - INFO - root - LLM 未初始化或不可用，后续生成将返回备用消息
2025-11-09 11:02:44,596 - INFO - root - === 运行配置 ===
2025-11-09 11:02:44,597 - INFO - root - 处理模式: arxiv在线搜索
2025-11-09 11:02:44,597 - INFO - root - 关键词: Quant
2025-11-09 11:02:44,598 - INFO - root - 查询: block float point
2025-11-09 11:02:44,598 - INFO - root - 排序: None
2025-11-09 11:02:44,598 - INFO - root - 最近天数: 180
2025-11-09 11:02:44,599 - INFO - root - 最大处理数量: 50
2025-11-09 11:02:44,599 - INFO - root - 保存图片: 是
2025-11-09 11:02:44,600 - INFO - root - 输出语言: 中文
2025-11-09 11:02:44,600 - INFO - root - 强制重新处理: 否
2025-11-09 11:02:44,600 - INFO - root - ====================
2025-11-09 11:02:44,600 - INFO - root - 使用 arXiv 搜索模式（通过 chat_arxiv 模块获取）
2025-11-09 11:02:44,601 - INFO - root - Fetching page 1 with URL: https://arxiv.org/search/?query=block+float+point&searchtype=all&abstracts=show&order=-announced_date_first&size=50
2025-11-09 11:02:50,748 - INFO - root - get_all_titles_from_web 
2025-11-09 11:02:50,750 - INFO - root - Page:0, Index:0, From Uniform to Adaptive: General Skip-Block Mechanisms for Efficient PDE Neural Operators, https://arxiv.org/pdf/2511.00032, 2025-11-04
2025-11-09 11:02:50,750 - INFO - root - Page:0, Index:1, INT v.s. FP: A Comprehensive Study of Fine-Grained Low-bit Quantization Formats, https://arxiv.org/pdf/2510.25602, 2025-10-29
2025-11-09 11:02:50,751 - INFO - root - Page:0, Index:2, MX+: Pushing the Limits of Microscaling Formats for Efficient Large Language Model Serving, https://arxiv.org/pdf/2510.14557, 2025-10-16
2025-11-09 11:02:50,751 - INFO - root - Page:0, Index:3, F-BFQ: Flexible Block Floating-Point Quantization Accelerator for LLMs, https://arxiv.org/pdf/2510.13401, 2025-10-15
2025-11-09 11:02:50,751 - INFO - root - Page:0, Index:4, Computationally Efficient Neural Receivers via Axial Self-Attention, https://arxiv.org/pdf/2510.12941, 2025-10-14
2025-11-09 11:02:50,751 - INFO - root - Page:0, Index:5, Efficient In-Memory Acceleration of Sparse Block Diagonal LLMs, https://arxiv.org/pdf/2510.11192, 2025-10-13
2025-11-09 11:02:50,751 - INFO - root - Page:0, Index:6, Dissecting Transformers: A CLEAR Perspective towards Green AI, https://arxiv.org/pdf/2510.02810, 2025-10-03
2025-11-09 11:02:50,751 - INFO - root - Page:0, Index:7, Microscaling Floating Point Formats for Large Language Models, https://arxiv.org/pdf/2510.01863, 2025-10-02
2025-11-09 11:02:50,751 - INFO - root - Page:0, Index:8, Automated and Scalable SEM Image Analysis of Perovskite Solar Cell Materials via a Deep Segmentation Framework, https://arxiv.org/pdf/2509.26548, 2025-09-30
2025-11-09 11:02:50,751 - INFO - root - Page:0, Index:9, AMLA: MUL by ADD in FlashAttention Rescaling, https://arxiv.org/pdf/2509.25224, 2025-09-24
2025-11-09 11:02:50,751 - INFO - root - Page:0, Index:10, Pretraining Large Language Models with NVFP4, https://arxiv.org/pdf/2509.25149, 2025-09-29
2025-11-09 11:02:50,751 - INFO - root - Page:0, Index:11, Bridging the Gap Between Promise and Performance for Microscaling FP4 Quantization, https://arxiv.org/pdf/2509.23202, 2025-10-16
2025-11-09 11:02:50,755 - INFO - root - Page:0, Index:12, Towards Verified Compilation of Floating-point Optimization in Scientific Computing Programs, https://arxiv.org/pdf/2509.09019, 2025-09-10
2025-11-09 11:02:50,755 - INFO - root - Page:0, Index:13, Green Learning for STAR-RIS mmWave Systems with Implicit CSI, https://arxiv.org/pdf/2509.06820, 2025-09-08
2025-11-09 11:02:50,755 - INFO - root - Page:0, Index:14, A Compute&Memory Efficient Model-Driven Neural 5G Receiver for Edge AI-assisted RAN, https://arxiv.org/pdf/2508.12892, 2025-10-22
2025-11-09 11:02:50,756 - INFO - root - Page:0, Index:15, SNNSIR: A Simple Spiking Neural Network for Stereo Image Restoration, https://arxiv.org/pdf/2508.12271, 2025-08-17
2025-11-09 11:02:50,758 - INFO - root - Page:0, Index:16, SpikeSTAG: Spatial-Temporal Forecasting via GNN-SNN Collaboration, https://arxiv.org/pdf/2508.02069, 2025-08-18
2025-11-09 11:02:50,758 - INFO - root - Page:0, Index:17, DGEMM without FP64 Arithmetic - Using FP64 Emulation and FP8 Tensor Cores with Ozaki Scheme, https://arxiv.org/pdf/2508.00441, 2025-09-25
2025-11-09 11:02:50,758 - INFO - root - Page:0, Index:18, Scaling Probabilistic Circuits via Monarch Matrices, https://arxiv.org/pdf/2506.12383, 2025-06-14
2025-11-09 11:02:50,758 - INFO - root - Page:0, Index:19, Starting Positions Matter: A Study on Better Weight Initialization for Neural Network Quantization, https://arxiv.org/pdf/2506.10463, 2025-06-12
2025-11-09 11:02:50,758 - INFO - root - Page:0, Index:20, Recipes for Pre-training LLMs with MXFP8, https://arxiv.org/pdf/2506.08027, 2025-08-18
2025-11-09 11:02:50,758 - INFO - root - Page:0, Index:21, FP4 All the Way: Fully Quantized Training of LLMs, https://arxiv.org/pdf/2505.19115, 2025-08-10
2025-11-09 11:02:50,759 - INFO - root - Page:0, Index:22, Automatic Verification of Floating-Point Accumulation Networks, https://arxiv.org/pdf/2505.18791, 2025-05-24
2025-11-09 11:02:50,759 - INFO - root - Page:0, Index:23, MXDOTP: A RISC-V ISA Extension for Enabling Microscaling (MX) Floating-Point Dot Products, https://arxiv.org/pdf/2505.13159, 2025-05-19
2025-11-09 11:02:50,760 - INFO - root - Page:0, Index:24, Parameter-Efficient Fine-Tuning with Circulant and Diagonal Vectors, https://arxiv.org/pdf/2505.00580, 2025-07-15
2025-11-09 11:02:50,760 - INFO - root - Page:0, Index:25, Silenzio: Secure Non-Interactive Outsourced MLP Training, https://arxiv.org/pdf/2504.17785, 2025-09-18
2025-11-09 11:02:50,760 - INFO - root - Page:0, Index:26, Involution and BSConv Multi-Depth Distillation Network for Lightweight Image Super-Resolution, https://arxiv.org/pdf/2503.14779, 2025-09-08
2025-11-09 11:02:50,762 - INFO - root - Page:0, Index:27, Flopping for FLOPs: Leveraging equivariance for computational efficiency, https://arxiv.org/pdf/2502.05169, 2025-06-24
2025-11-09 11:02:50,762 - INFO - root - Page:0, Index:28, An Effective UNet Using Feature Interaction and Fusion for Organ Segmentation in Medical Image, https://arxiv.org/pdf/2409.05324, 2025-07-26
2025-11-09 11:02:50,762 - INFO - root - Fetching page 2 with URL: https://arxiv.org/search/?query=block+float+point&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=50
2025-11-09 11:14:07,152 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-09 11:14:07,154 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-09 11:14:07,155 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-09 11:14:07,953 - INFO - root - LLMClient: trying model gemini-2.5-flash
2025-11-09 11:14:08,826 - INFO - root - LLMClient: trying model gemini-2.5-pro
2025-11-09 11:14:09,206 - WARNING - root - LLMClient: no usable model found, LLM disabled
2025-11-09 11:14:09,206 - INFO - root - LLM 未初始化或不可用，后续生成将返回备用消息
2025-11-09 11:14:09,207 - INFO - root - === 运行配置 ===
2025-11-09 11:14:09,207 - INFO - root - 处理模式: arxiv在线搜索
2025-11-09 11:14:09,207 - INFO - root - 关键词: Quant
2025-11-09 11:14:09,207 - INFO - root - 查询: block float point
2025-11-09 11:14:09,208 - INFO - root - 排序: None
2025-11-09 11:14:09,208 - INFO - root - 最近天数: 180
2025-11-09 11:14:09,208 - INFO - root - 最大处理数量: 50
2025-11-09 11:14:09,209 - INFO - root - 保存图片: 是
2025-11-09 11:14:09,209 - INFO - root - 输出语言: 中文
2025-11-09 11:14:09,209 - INFO - root - 强制重新处理: 否
2025-11-09 11:14:09,209 - INFO - root - ====================
2025-11-09 11:14:09,210 - INFO - root - 使用 arXiv 搜索模式（通过 chat_arxiv 模块获取）
2025-11-09 11:14:09,210 - INFO - root - Fetching page 1 with URL: https://arxiv.org/search/?query=block+float+point&searchtype=all&abstracts=show&order=-announced_date_first&size=50
2025-11-09 11:14:15,463 - INFO - root - get_all_titles_from_web 
2025-11-09 11:14:15,463 - INFO - root - Page:0, Index:0, From Uniform to Adaptive: General Skip-Block Mechanisms for Efficient PDE Neural Operators, https://arxiv.org/pdf/2511.00032, 2025-11-04
2025-11-09 11:14:15,463 - INFO - root - Page:0, Index:1, INT v.s. FP: A Comprehensive Study of Fine-Grained Low-bit Quantization Formats, https://arxiv.org/pdf/2510.25602, 2025-10-29
2025-11-09 11:14:15,463 - INFO - root - Page:0, Index:2, MX+: Pushing the Limits of Microscaling Formats for Efficient Large Language Model Serving, https://arxiv.org/pdf/2510.14557, 2025-10-16
2025-11-09 11:14:15,463 - INFO - root - Page:0, Index:3, F-BFQ: Flexible Block Floating-Point Quantization Accelerator for LLMs, https://arxiv.org/pdf/2510.13401, 2025-10-15
2025-11-09 11:14:15,463 - INFO - root - Page:0, Index:4, Computationally Efficient Neural Receivers via Axial Self-Attention, https://arxiv.org/pdf/2510.12941, 2025-10-14
2025-11-09 11:14:15,463 - INFO - root - Page:0, Index:5, Efficient In-Memory Acceleration of Sparse Block Diagonal LLMs, https://arxiv.org/pdf/2510.11192, 2025-10-13
2025-11-09 11:14:15,463 - INFO - root - Page:0, Index:6, Dissecting Transformers: A CLEAR Perspective towards Green AI, https://arxiv.org/pdf/2510.02810, 2025-10-03
2025-11-09 11:14:15,463 - INFO - root - Page:0, Index:7, Microscaling Floating Point Formats for Large Language Models, https://arxiv.org/pdf/2510.01863, 2025-10-02
2025-11-09 11:14:15,463 - INFO - root - Page:0, Index:8, Automated and Scalable SEM Image Analysis of Perovskite Solar Cell Materials via a Deep Segmentation Framework, https://arxiv.org/pdf/2509.26548, 2025-09-30
2025-11-09 11:14:15,463 - INFO - root - Page:0, Index:9, AMLA: MUL by ADD in FlashAttention Rescaling, https://arxiv.org/pdf/2509.25224, 2025-09-24
2025-11-09 11:14:15,463 - INFO - root - Page:0, Index:10, Pretraining Large Language Models with NVFP4, https://arxiv.org/pdf/2509.25149, 2025-09-29
2025-11-09 11:14:15,463 - INFO - root - Page:0, Index:11, Bridging the Gap Between Promise and Performance for Microscaling FP4 Quantization, https://arxiv.org/pdf/2509.23202, 2025-10-16
2025-11-09 11:14:15,463 - INFO - root - Page:0, Index:12, Towards Verified Compilation of Floating-point Optimization in Scientific Computing Programs, https://arxiv.org/pdf/2509.09019, 2025-09-10
2025-11-09 11:14:15,463 - INFO - root - Page:0, Index:13, Green Learning for STAR-RIS mmWave Systems with Implicit CSI, https://arxiv.org/pdf/2509.06820, 2025-09-08
2025-11-09 11:14:15,463 - INFO - root - Page:0, Index:14, A Compute&Memory Efficient Model-Driven Neural 5G Receiver for Edge AI-assisted RAN, https://arxiv.org/pdf/2508.12892, 2025-10-22
2025-11-09 11:14:15,463 - INFO - root - Page:0, Index:15, SNNSIR: A Simple Spiking Neural Network for Stereo Image Restoration, https://arxiv.org/pdf/2508.12271, 2025-08-17
2025-11-09 11:14:15,463 - INFO - root - Page:0, Index:16, SpikeSTAG: Spatial-Temporal Forecasting via GNN-SNN Collaboration, https://arxiv.org/pdf/2508.02069, 2025-08-18
2025-11-09 11:14:15,463 - INFO - root - Page:0, Index:17, DGEMM without FP64 Arithmetic - Using FP64 Emulation and FP8 Tensor Cores with Ozaki Scheme, https://arxiv.org/pdf/2508.00441, 2025-09-25
2025-11-09 11:14:15,463 - INFO - root - Page:0, Index:18, Scaling Probabilistic Circuits via Monarch Matrices, https://arxiv.org/pdf/2506.12383, 2025-06-14
2025-11-09 11:14:15,463 - INFO - root - Page:0, Index:19, Starting Positions Matter: A Study on Better Weight Initialization for Neural Network Quantization, https://arxiv.org/pdf/2506.10463, 2025-06-12
2025-11-09 11:14:15,463 - INFO - root - Page:0, Index:20, Recipes for Pre-training LLMs with MXFP8, https://arxiv.org/pdf/2506.08027, 2025-08-18
2025-11-09 11:14:15,463 - INFO - root - Page:0, Index:21, FP4 All the Way: Fully Quantized Training of LLMs, https://arxiv.org/pdf/2505.19115, 2025-08-10
2025-11-09 11:14:15,463 - INFO - root - Page:0, Index:22, Automatic Verification of Floating-Point Accumulation Networks, https://arxiv.org/pdf/2505.18791, 2025-05-24
2025-11-09 11:14:15,463 - INFO - root - Page:0, Index:23, MXDOTP: A RISC-V ISA Extension for Enabling Microscaling (MX) Floating-Point Dot Products, https://arxiv.org/pdf/2505.13159, 2025-05-19
2025-11-09 11:14:15,463 - INFO - root - Page:0, Index:24, Parameter-Efficient Fine-Tuning with Circulant and Diagonal Vectors, https://arxiv.org/pdf/2505.00580, 2025-07-15
2025-11-09 11:14:15,473 - INFO - root - Page:0, Index:25, Silenzio: Secure Non-Interactive Outsourced MLP Training, https://arxiv.org/pdf/2504.17785, 2025-09-18
2025-11-09 11:14:15,475 - INFO - root - Page:0, Index:26, Involution and BSConv Multi-Depth Distillation Network for Lightweight Image Super-Resolution, https://arxiv.org/pdf/2503.14779, 2025-09-08
2025-11-09 11:14:15,475 - INFO - root - Page:0, Index:27, Flopping for FLOPs: Leveraging equivariance for computational efficiency, https://arxiv.org/pdf/2502.05169, 2025-06-24
2025-11-09 11:14:15,477 - INFO - root - Page:0, Index:28, An Effective UNet Using Feature Interaction and Fusion for Organ Segmentation in Medical Image, https://arxiv.org/pdf/2409.05324, 2025-07-26
2025-11-09 11:14:15,477 - INFO - root - Fetching page 2 with URL: https://arxiv.org/search/?query=block+float+point&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=50
2025-11-09 11:14:21,869 - INFO - root - get_all_titles_from_web 
2025-11-09 11:14:21,869 - INFO - root - Page:1, Index:0, TwinLiteNet+: An Enhanced Multi-Task Segmentation Model for Autonomous Driving, https://arxiv.org/pdf/2403.16958, 2025-08-30
2025-11-09 11:14:21,869 - INFO - root - Fetching page 3 with URL: https://arxiv.org/search/?query=block+float+point&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=100
2025-11-09 11:14:28,257 - INFO - root - ------------------------------------------------------------------------------------------------------------------------
2025-11-09 11:18:03,978 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-09 11:18:03,979 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-09 11:18:03,981 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-09 11:18:04,669 - INFO - root - LLMClient: trying model gemini-2.5-flash
2025-11-09 11:18:05,549 - INFO - root - LLMClient: trying model gemini-2.5-pro
2025-11-09 11:18:05,899 - WARNING - root - LLMClient: no usable model found, LLM disabled
2025-11-09 11:18:05,899 - INFO - root - LLM 未初始化或不可用，后续生成将返回备用消息
2025-11-09 11:18:05,900 - INFO - root - === 运行配置 ===
2025-11-09 11:18:05,901 - INFO - root - 处理模式: arxiv在线搜索
2025-11-09 11:18:05,901 - INFO - root - 关键词: Quant
2025-11-09 11:18:05,901 - INFO - root - 查询: block float point
2025-11-09 11:18:05,901 - INFO - root - 排序: None
2025-11-09 11:18:05,902 - INFO - root - 最近天数: 180
2025-11-09 11:18:05,902 - INFO - root - 最大处理数量: 2
2025-11-09 11:18:05,903 - INFO - root - 保存图片: 是
2025-11-09 11:18:05,903 - INFO - root - 输出语言: 中文
2025-11-09 11:18:05,903 - INFO - root - 强制重新处理: 否
2025-11-09 11:18:05,903 - INFO - root - ====================
2025-11-09 11:18:05,904 - INFO - root - 使用 arXiv 搜索模式（通过 chat_arxiv 模块获取）
2025-11-09 11:18:05,904 - INFO - root - Fetching page 1 with URL: https://arxiv.org/search/?query=block+float+point&searchtype=all&abstracts=show&order=-announced_date_first&size=50
2025-11-09 11:18:12,193 - INFO - root - get_all_titles_from_web 
2025-11-09 11:18:12,193 - INFO - root - Page:0, Index:0, From Uniform to Adaptive: General Skip-Block Mechanisms for Efficient PDE Neural Operators, https://arxiv.org/pdf/2511.00032, 2025-11-04
2025-11-09 11:18:12,194 - INFO - root - Page:0, Index:1, INT v.s. FP: A Comprehensive Study of Fine-Grained Low-bit Quantization Formats, https://arxiv.org/pdf/2510.25602, 2025-10-29
2025-11-09 11:18:12,194 - INFO - root - Page:0, Index:2, MX+: Pushing the Limits of Microscaling Formats for Efficient Large Language Model Serving, https://arxiv.org/pdf/2510.14557, 2025-10-16
2025-11-09 11:18:12,194 - INFO - root - Page:0, Index:3, F-BFQ: Flexible Block Floating-Point Quantization Accelerator for LLMs, https://arxiv.org/pdf/2510.13401, 2025-10-15
2025-11-09 11:18:12,194 - INFO - root - Page:0, Index:4, Computationally Efficient Neural Receivers via Axial Self-Attention, https://arxiv.org/pdf/2510.12941, 2025-10-14
2025-11-09 11:18:12,196 - INFO - root - Page:0, Index:5, Efficient In-Memory Acceleration of Sparse Block Diagonal LLMs, https://arxiv.org/pdf/2510.11192, 2025-10-13
2025-11-09 11:18:12,196 - INFO - root - Page:0, Index:6, Dissecting Transformers: A CLEAR Perspective towards Green AI, https://arxiv.org/pdf/2510.02810, 2025-10-03
2025-11-09 11:18:12,196 - INFO - root - Page:0, Index:7, Microscaling Floating Point Formats for Large Language Models, https://arxiv.org/pdf/2510.01863, 2025-10-02
2025-11-09 11:18:12,196 - INFO - root - Page:0, Index:8, Automated and Scalable SEM Image Analysis of Perovskite Solar Cell Materials via a Deep Segmentation Framework, https://arxiv.org/pdf/2509.26548, 2025-09-30
2025-11-09 11:18:12,196 - INFO - root - Page:0, Index:9, AMLA: MUL by ADD in FlashAttention Rescaling, https://arxiv.org/pdf/2509.25224, 2025-09-24
2025-11-09 11:18:12,196 - INFO - root - Page:0, Index:10, Pretraining Large Language Models with NVFP4, https://arxiv.org/pdf/2509.25149, 2025-09-29
2025-11-09 11:18:12,196 - INFO - root - Page:0, Index:11, Bridging the Gap Between Promise and Performance for Microscaling FP4 Quantization, https://arxiv.org/pdf/2509.23202, 2025-10-16
2025-11-09 11:18:12,196 - INFO - root - Page:0, Index:12, Towards Verified Compilation of Floating-point Optimization in Scientific Computing Programs, https://arxiv.org/pdf/2509.09019, 2025-09-10
2025-11-09 11:18:12,196 - INFO - root - Page:0, Index:13, Green Learning for STAR-RIS mmWave Systems with Implicit CSI, https://arxiv.org/pdf/2509.06820, 2025-09-08
2025-11-09 11:18:12,196 - INFO - root - Page:0, Index:14, A Compute&Memory Efficient Model-Driven Neural 5G Receiver for Edge AI-assisted RAN, https://arxiv.org/pdf/2508.12892, 2025-10-22
2025-11-09 11:18:12,196 - INFO - root - Page:0, Index:15, SNNSIR: A Simple Spiking Neural Network for Stereo Image Restoration, https://arxiv.org/pdf/2508.12271, 2025-08-17
2025-11-09 11:18:12,196 - INFO - root - Page:0, Index:16, SpikeSTAG: Spatial-Temporal Forecasting via GNN-SNN Collaboration, https://arxiv.org/pdf/2508.02069, 2025-08-18
2025-11-09 11:18:12,196 - INFO - root - Page:0, Index:17, DGEMM without FP64 Arithmetic - Using FP64 Emulation and FP8 Tensor Cores with Ozaki Scheme, https://arxiv.org/pdf/2508.00441, 2025-09-25
2025-11-09 11:18:12,196 - INFO - root - Page:0, Index:18, Scaling Probabilistic Circuits via Monarch Matrices, https://arxiv.org/pdf/2506.12383, 2025-06-14
2025-11-09 11:18:12,196 - INFO - root - Page:0, Index:19, Starting Positions Matter: A Study on Better Weight Initialization for Neural Network Quantization, https://arxiv.org/pdf/2506.10463, 2025-06-12
2025-11-09 11:18:12,196 - INFO - root - Page:0, Index:20, Recipes for Pre-training LLMs with MXFP8, https://arxiv.org/pdf/2506.08027, 2025-08-18
2025-11-09 11:18:12,196 - INFO - root - Page:0, Index:21, FP4 All the Way: Fully Quantized Training of LLMs, https://arxiv.org/pdf/2505.19115, 2025-08-10
2025-11-09 11:18:12,196 - INFO - root - Page:0, Index:22, Automatic Verification of Floating-Point Accumulation Networks, https://arxiv.org/pdf/2505.18791, 2025-05-24
2025-11-09 11:18:12,196 - INFO - root - Page:0, Index:23, MXDOTP: A RISC-V ISA Extension for Enabling Microscaling (MX) Floating-Point Dot Products, https://arxiv.org/pdf/2505.13159, 2025-05-19
2025-11-09 11:18:12,196 - INFO - root - Page:0, Index:24, Parameter-Efficient Fine-Tuning with Circulant and Diagonal Vectors, https://arxiv.org/pdf/2505.00580, 2025-07-15
2025-11-09 11:18:12,196 - INFO - root - Page:0, Index:25, Silenzio: Secure Non-Interactive Outsourced MLP Training, https://arxiv.org/pdf/2504.17785, 2025-09-18
2025-11-09 11:18:12,196 - INFO - root - Page:0, Index:26, Involution and BSConv Multi-Depth Distillation Network for Lightweight Image Super-Resolution, https://arxiv.org/pdf/2503.14779, 2025-09-08
2025-11-09 11:18:12,196 - INFO - root - Page:0, Index:27, Flopping for FLOPs: Leveraging equivariance for computational efficiency, https://arxiv.org/pdf/2502.05169, 2025-06-24
2025-11-09 11:18:12,204 - INFO - root - Page:0, Index:28, An Effective UNet Using Feature Interaction and Fusion for Organ Segmentation in Medical Image, https://arxiv.org/pdf/2409.05324, 2025-07-26
2025-11-09 11:18:12,204 - INFO - root - Fetching page 2 with URL: https://arxiv.org/search/?query=block+float+point&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=50
2025-11-09 11:18:18,346 - INFO - root - get_all_titles_from_web 
2025-11-09 11:18:18,347 - INFO - root - Page:1, Index:0, TwinLiteNet+: An Enhanced Multi-Task Segmentation Model for Autonomous Driving, https://arxiv.org/pdf/2403.16958, 2025-08-30
2025-11-09 11:18:18,347 - INFO - root - Fetching page 3 with URL: https://arxiv.org/search/?query=block+float+point&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=100
2025-11-09 11:18:24,765 - INFO - root - ------------------------------------------------------------------------------------------------------------------------
2025-11-09 11:18:36,427 - INFO - root - 正在总结论文 1/2: From Uniform to Adaptive: General Skip-Block Mechanisms for Efficient PDE Neural Operators
2025-11-09 11:18:36,429 - INFO - root - 正在提取论文图片...
2025-11-09 11:18:36,905 - INFO - root - 已保存图片 1/10：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_1_page3.png
2025-11-09 11:18:36,981 - INFO - root - 已保存图片 2/10：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_2_page8.png
2025-11-09 11:18:37,084 - INFO - root - 已保存图片 3/10：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_3_page8.png
2025-11-09 11:18:37,161 - INFO - root - 已保存图片 4/10：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_4_page9.png
2025-11-09 11:18:37,262 - INFO - root - 已保存图片 5/10：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_5_page9.png
2025-11-09 11:18:37,350 - INFO - root - 已保存图片 6/10：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_6_page4.png
2025-11-09 11:18:37,428 - INFO - root - 已保存图片 7/10：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_7_page4.png
2025-11-09 11:18:37,564 - INFO - root - 已保存图片 8/10：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_8_page16.png
2025-11-09 11:18:37,585 - INFO - root - 已保存图片 9/10：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_9_page4.png
2025-11-09 11:18:37,612 - INFO - root - 已保存图片 10/10：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_10_page4.png
2025-11-09 11:18:37,619 - INFO - root - 成功添加图片 1：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_1_page3.png
2025-11-09 11:18:37,621 - INFO - root - 成功添加图片 2：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_2_page8.png
2025-11-09 11:18:37,625 - INFO - root - 成功添加图片 3：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_3_page8.png
2025-11-09 11:18:37,626 - INFO - root - 成功添加图片 4：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_4_page9.png
2025-11-09 11:18:37,627 - INFO - root - 成功添加图片 5：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_5_page9.png
2025-11-09 11:18:37,627 - INFO - root - 成功添加图片 6：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_6_page4.png
2025-11-09 11:18:37,628 - INFO - root - 成功添加图片 7：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_7_page4.png
2025-11-09 11:18:37,629 - INFO - root - 成功添加图片 8：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_8_page16.png
2025-11-09 11:18:37,630 - INFO - root - 成功添加图片 9：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_9_page4.png
2025-11-09 11:18:37,631 - INFO - root - 成功添加图片 10：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_10_page4.png
2025-11-09 11:18:37,634 - INFO - root - 论文《From Uniform to Adaptive: General Skip-Block Mechanisms for Efficient PDE Neural Operators》的分析已保存到 ./export\From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural-2.md
2025-11-09 11:18:37,645 - INFO - root - 正在总结论文 2/2: INT v.s. FP: A Comprehensive Study of Fine-Grained Low-bit Quantization Formats
2025-11-09 11:18:37,646 - INFO - root - 正在提取论文图片...
2025-11-09 11:18:38,452 - INFO - root - 已保存图片 1/10：./export\images_INT v.s. FP_ A Comprehensive Study of Fine-Grained Low-bit Quantization Formats\figure_1_page9.png
2025-11-09 11:18:38,533 - INFO - root - 已保存图片 2/10：./export\images_INT v.s. FP_ A Comprehensive Study of Fine-Grained Low-bit Quantization Formats\figure_2_page1.png
2025-11-09 11:18:38,563 - INFO - root - 已保存图片 3/10：./export\images_INT v.s. FP_ A Comprehensive Study of Fine-Grained Low-bit Quantization Formats\figure_3_page1.jpeg
2025-11-09 11:18:38,638 - INFO - root - 已保存图片 4/10：./export\images_INT v.s. FP_ A Comprehensive Study of Fine-Grained Low-bit Quantization Formats\figure_4_page9.png
2025-11-09 11:18:38,648 - INFO - root - 成功添加图片 1：./export\images_INT v.s. FP_ A Comprehensive Study of Fine-Grained Low-bit Quantization Formats\figure_1_page9.png
2025-11-09 11:18:38,648 - INFO - root - 成功添加图片 2：./export\images_INT v.s. FP_ A Comprehensive Study of Fine-Grained Low-bit Quantization Formats\figure_2_page1.png
2025-11-09 11:18:38,650 - INFO - root - 成功添加图片 3：./export\images_INT v.s. FP_ A Comprehensive Study of Fine-Grained Low-bit Quantization Formats\figure_3_page1.jpeg
2025-11-09 11:18:38,650 - INFO - root - 成功添加图片 4：./export\images_INT v.s. FP_ A Comprehensive Study of Fine-Grained Low-bit Quantization Formats\figure_4_page9.png
2025-11-09 11:18:38,652 - INFO - root - 论文《INT v.s. FP: A Comprehensive Study of Fine-Grained Low-bit Quantization Formats》的分析已保存到 ./export\INT v.s. FP_ A Comprehensive Study of Fine-Grained Low-bit Quantization Formats-2.md
2025-11-09 11:18:38,667 - INFO - root - summary time: 34.69 seconds
2025-11-09 11:29:36,716 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-09 11:29:36,721 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-09 11:29:36,737 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-09 11:30:37,916 - ERROR - root - LLMClient: error during initialization: Timeout of 60.0s exceeded, last exception: 503 failed to connect to all addresses; last error: UNKNOWN: ipv4:142.250.73.138:443: tcp handshaker shutdown
2025-11-09 11:30:37,917 - INFO - root - LLM 未初始化或不可用，后续生成将返回备用消息
2025-11-09 11:30:37,917 - INFO - root - === 运行配置 ===
2025-11-09 11:30:37,918 - INFO - root - 处理模式: arxiv在线搜索
2025-11-09 11:30:37,918 - INFO - root - 关键词: Quant
2025-11-09 11:30:37,918 - INFO - root - 查询: block float point
2025-11-09 11:30:37,919 - INFO - root - 排序: None
2025-11-09 11:30:37,919 - INFO - root - 最近天数: 180
2025-11-09 11:30:37,919 - INFO - root - 最大处理数量: 2
2025-11-09 11:30:37,919 - INFO - root - 保存图片: 是
2025-11-09 11:30:37,920 - INFO - root - 输出语言: 中文
2025-11-09 11:30:37,920 - INFO - root - 强制重新处理: 否
2025-11-09 11:30:37,920 - INFO - root - ====================
2025-11-09 11:30:37,921 - INFO - root - 使用 arXiv 搜索模式（通过 chat_arxiv 模块获取）
2025-11-09 11:30:37,921 - INFO - root - Fetching page 1 with URL: https://arxiv.org/search/?query=block+float+point&searchtype=all&abstracts=show&order=-announced_date_first&size=50
2025-11-09 11:31:05,549 - INFO - root - get_all_titles_from_web 
2025-11-09 11:31:05,549 - INFO - root - Page:0, Index:0, From Uniform to Adaptive: General Skip-Block Mechanisms for Efficient PDE Neural Operators, https://arxiv.org/pdf/2511.00032, 2025-11-04
2025-11-09 11:31:05,549 - INFO - root - Page:0, Index:1, INT v.s. FP: A Comprehensive Study of Fine-Grained Low-bit Quantization Formats, https://arxiv.org/pdf/2510.25602, 2025-10-29
2025-11-09 11:31:05,549 - INFO - root - Page:0, Index:2, MX+: Pushing the Limits of Microscaling Formats for Efficient Large Language Model Serving, https://arxiv.org/pdf/2510.14557, 2025-10-16
2025-11-09 11:31:05,549 - INFO - root - Page:0, Index:3, F-BFQ: Flexible Block Floating-Point Quantization Accelerator for LLMs, https://arxiv.org/pdf/2510.13401, 2025-10-15
2025-11-09 11:31:05,549 - INFO - root - Page:0, Index:4, Computationally Efficient Neural Receivers via Axial Self-Attention, https://arxiv.org/pdf/2510.12941, 2025-10-14
2025-11-09 11:31:05,549 - INFO - root - Page:0, Index:5, Efficient In-Memory Acceleration of Sparse Block Diagonal LLMs, https://arxiv.org/pdf/2510.11192, 2025-10-13
2025-11-09 11:31:05,549 - INFO - root - Page:0, Index:6, Dissecting Transformers: A CLEAR Perspective towards Green AI, https://arxiv.org/pdf/2510.02810, 2025-10-03
2025-11-09 11:31:05,549 - INFO - root - Page:0, Index:7, Microscaling Floating Point Formats for Large Language Models, https://arxiv.org/pdf/2510.01863, 2025-10-02
2025-11-09 11:31:05,549 - INFO - root - Page:0, Index:8, Automated and Scalable SEM Image Analysis of Perovskite Solar Cell Materials via a Deep Segmentation Framework, https://arxiv.org/pdf/2509.26548, 2025-09-30
2025-11-09 11:31:05,549 - INFO - root - Page:0, Index:9, AMLA: MUL by ADD in FlashAttention Rescaling, https://arxiv.org/pdf/2509.25224, 2025-09-24
2025-11-09 11:31:05,549 - INFO - root - Page:0, Index:10, Pretraining Large Language Models with NVFP4, https://arxiv.org/pdf/2509.25149, 2025-09-29
2025-11-09 11:31:05,549 - INFO - root - Page:0, Index:11, Bridging the Gap Between Promise and Performance for Microscaling FP4 Quantization, https://arxiv.org/pdf/2509.23202, 2025-10-16
2025-11-09 11:31:05,549 - INFO - root - Page:0, Index:12, Towards Verified Compilation of Floating-point Optimization in Scientific Computing Programs, https://arxiv.org/pdf/2509.09019, 2025-09-10
2025-11-09 11:31:05,549 - INFO - root - Page:0, Index:13, Green Learning for STAR-RIS mmWave Systems with Implicit CSI, https://arxiv.org/pdf/2509.06820, 2025-09-08
2025-11-09 11:31:05,549 - INFO - root - Page:0, Index:14, A Compute&Memory Efficient Model-Driven Neural 5G Receiver for Edge AI-assisted RAN, https://arxiv.org/pdf/2508.12892, 2025-10-22
2025-11-09 11:31:05,549 - INFO - root - Page:0, Index:15, SNNSIR: A Simple Spiking Neural Network for Stereo Image Restoration, https://arxiv.org/pdf/2508.12271, 2025-08-17
2025-11-09 11:31:05,549 - INFO - root - Page:0, Index:16, SpikeSTAG: Spatial-Temporal Forecasting via GNN-SNN Collaboration, https://arxiv.org/pdf/2508.02069, 2025-08-18
2025-11-09 11:31:05,549 - INFO - root - Page:0, Index:17, DGEMM without FP64 Arithmetic - Using FP64 Emulation and FP8 Tensor Cores with Ozaki Scheme, https://arxiv.org/pdf/2508.00441, 2025-09-25
2025-11-09 11:31:05,556 - INFO - root - Page:0, Index:18, Scaling Probabilistic Circuits via Monarch Matrices, https://arxiv.org/pdf/2506.12383, 2025-06-14
2025-11-09 11:31:05,557 - INFO - root - Page:0, Index:19, Starting Positions Matter: A Study on Better Weight Initialization for Neural Network Quantization, https://arxiv.org/pdf/2506.10463, 2025-06-12
2025-11-09 11:31:05,559 - INFO - root - Page:0, Index:20, Recipes for Pre-training LLMs with MXFP8, https://arxiv.org/pdf/2506.08027, 2025-08-18
2025-11-09 11:31:05,560 - INFO - root - Page:0, Index:21, FP4 All the Way: Fully Quantized Training of LLMs, https://arxiv.org/pdf/2505.19115, 2025-08-10
2025-11-09 11:31:05,560 - INFO - root - Page:0, Index:22, Automatic Verification of Floating-Point Accumulation Networks, https://arxiv.org/pdf/2505.18791, 2025-05-24
2025-11-09 11:31:05,560 - INFO - root - Page:0, Index:23, MXDOTP: A RISC-V ISA Extension for Enabling Microscaling (MX) Floating-Point Dot Products, https://arxiv.org/pdf/2505.13159, 2025-05-19
2025-11-09 11:31:05,561 - INFO - root - Page:0, Index:24, Parameter-Efficient Fine-Tuning with Circulant and Diagonal Vectors, https://arxiv.org/pdf/2505.00580, 2025-07-15
2025-11-09 11:31:05,561 - INFO - root - Page:0, Index:25, Silenzio: Secure Non-Interactive Outsourced MLP Training, https://arxiv.org/pdf/2504.17785, 2025-09-18
2025-11-09 11:31:05,561 - INFO - root - Page:0, Index:26, Involution and BSConv Multi-Depth Distillation Network for Lightweight Image Super-Resolution, https://arxiv.org/pdf/2503.14779, 2025-09-08
2025-11-09 11:31:05,562 - INFO - root - Page:0, Index:27, Flopping for FLOPs: Leveraging equivariance for computational efficiency, https://arxiv.org/pdf/2502.05169, 2025-06-24
2025-11-09 11:31:05,562 - INFO - root - Page:0, Index:28, An Effective UNet Using Feature Interaction and Fusion for Organ Segmentation in Medical Image, https://arxiv.org/pdf/2409.05324, 2025-07-26
2025-11-09 11:31:05,563 - INFO - root - Fetching page 2 with URL: https://arxiv.org/search/?query=block+float+point&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=50
2025-11-09 11:31:30,452 - INFO - root - get_all_titles_from_web 
2025-11-09 11:31:30,453 - INFO - root - Page:1, Index:0, TwinLiteNet+: An Enhanced Multi-Task Segmentation Model for Autonomous Driving, https://arxiv.org/pdf/2403.16958, 2025-08-30
2025-11-09 11:31:30,453 - INFO - root - Fetching page 3 with URL: https://arxiv.org/search/?query=block+float+point&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=100
2025-11-09 11:32:32,097 - INFO - root - ------------------------------------------------------------------------------------------------------------------------
2025-11-09 11:33:32,864 - INFO - root - 跳过已处理论文 From Uniform to Adaptive: General Skip-Block Mechanisms for Efficient PDE Neural Operators：D:\ChatPaper\academic Papers\block float point\From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural-1.pdf
2025-11-09 11:33:32,864 - INFO - root - 跳过已处理论文 INT v.s. FP: A Comprehensive Study of Fine-Grained Low-bit Quantization Formats：D:\ChatPaper\academic Papers\block float point\INT v.s. FP_ A Comprehensive Study of Fine-Grained Low-bit Quantization Formats-1.pdf
2025-11-09 11:33:32,864 - INFO - root - summary time: 236.15 seconds
2025-11-09 12:02:26,323 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-09 12:02:26,323 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-09 12:02:26,323 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-09 12:02:27,086 - INFO - root - GeminiClient: trying model gemini-2.5-flash
2025-11-09 12:02:27,922 - INFO - root - GeminiClient: trying model gemini-2.5-pro
2025-11-09 12:02:28,280 - WARNING - root - GeminiClient: no usable model found
2025-11-09 12:02:28,280 - WARNING - root - LLMClientManager: Gemini client initialization failed
2025-11-09 12:02:28,281 - WARNING - root - DeepSeekClient: API key not provided. LLM disabled.
2025-11-09 12:02:28,281 - WARNING - root - LLMClientManager: DeepSeek client initialization failed
2025-11-09 12:02:28,281 - WARNING - root - KimiClient: API key not provided. LLM disabled.
2025-11-09 12:02:28,281 - WARNING - root - LLMClientManager: Kimi client initialization failed
2025-11-09 12:02:28,282 - WARNING - root - QwenClient: API key not provided. LLM disabled.
2025-11-09 12:02:28,282 - WARNING - root - LLMClientManager: Qwen client initialization failed
2025-11-09 12:02:28,282 - WARNING - root - DoubaoClient: API key not provided. LLM disabled.
2025-11-09 12:02:28,282 - WARNING - root - LLMClientManager: Doubao client initialization failed
2025-11-09 12:02:28,283 - WARNING - root - LLMClientManager: no LLM client available
2025-11-09 12:02:28,283 - INFO - root - LLM 未初始化或不可用，后续生成将返回备用消息
2025-11-09 12:02:28,284 - INFO - root - === 运行配置 ===
2025-11-09 12:02:28,284 - INFO - root - 处理模式: arxiv在线搜索
2025-11-09 12:02:28,285 - INFO - root - 关键词: Quant
2025-11-09 12:02:28,285 - INFO - root - 查询: block float point
2025-11-09 12:02:28,287 - INFO - root - 排序: None
2025-11-09 12:02:28,287 - INFO - root - 最近天数: 180
2025-11-09 12:02:28,288 - INFO - root - 最大处理数量: 2
2025-11-09 12:02:28,289 - INFO - root - 保存图片: 是
2025-11-09 12:02:28,289 - INFO - root - 输出语言: 中文
2025-11-09 12:02:28,289 - INFO - root - 强制重新处理: 否
2025-11-09 12:02:28,290 - INFO - root - ====================
2025-11-09 12:02:28,290 - INFO - root - 使用 arXiv 搜索模式（通过 chat_arxiv 模块获取）
2025-11-09 12:02:28,290 - INFO - root - Fetching page 1 with URL: https://arxiv.org/search/?query=block+float+point&searchtype=all&abstracts=show&order=-announced_date_first&size=50
2025-11-09 12:02:34,854 - INFO - root - get_all_titles_from_web 
2025-11-09 12:02:34,854 - INFO - root - Page:0, Index:0, From Uniform to Adaptive: General Skip-Block Mechanisms for Efficient PDE Neural Operators, https://arxiv.org/pdf/2511.00032, 2025-11-04
2025-11-09 12:02:34,854 - INFO - root - Page:0, Index:1, INT v.s. FP: A Comprehensive Study of Fine-Grained Low-bit Quantization Formats, https://arxiv.org/pdf/2510.25602, 2025-10-29
2025-11-09 12:02:34,854 - INFO - root - Page:0, Index:2, MX+: Pushing the Limits of Microscaling Formats for Efficient Large Language Model Serving, https://arxiv.org/pdf/2510.14557, 2025-10-16
2025-11-09 12:02:34,854 - INFO - root - Page:0, Index:3, F-BFQ: Flexible Block Floating-Point Quantization Accelerator for LLMs, https://arxiv.org/pdf/2510.13401, 2025-10-15
2025-11-09 12:02:34,854 - INFO - root - Page:0, Index:4, Computationally Efficient Neural Receivers via Axial Self-Attention, https://arxiv.org/pdf/2510.12941, 2025-10-14
2025-11-09 12:02:34,854 - INFO - root - Page:0, Index:5, Efficient In-Memory Acceleration of Sparse Block Diagonal LLMs, https://arxiv.org/pdf/2510.11192, 2025-10-13
2025-11-09 12:02:34,854 - INFO - root - Page:0, Index:6, Dissecting Transformers: A CLEAR Perspective towards Green AI, https://arxiv.org/pdf/2510.02810, 2025-10-03
2025-11-09 12:02:34,857 - INFO - root - Page:0, Index:7, Microscaling Floating Point Formats for Large Language Models, https://arxiv.org/pdf/2510.01863, 2025-10-02
2025-11-09 12:02:34,857 - INFO - root - Page:0, Index:8, Automated and Scalable SEM Image Analysis of Perovskite Solar Cell Materials via a Deep Segmentation Framework, https://arxiv.org/pdf/2509.26548, 2025-09-30
2025-11-09 12:02:34,858 - INFO - root - Page:0, Index:9, AMLA: MUL by ADD in FlashAttention Rescaling, https://arxiv.org/pdf/2509.25224, 2025-09-24
2025-11-09 12:02:34,858 - INFO - root - Page:0, Index:10, Pretraining Large Language Models with NVFP4, https://arxiv.org/pdf/2509.25149, 2025-09-29
2025-11-09 12:02:34,858 - INFO - root - Page:0, Index:11, Bridging the Gap Between Promise and Performance for Microscaling FP4 Quantization, https://arxiv.org/pdf/2509.23202, 2025-10-16
2025-11-09 12:02:34,858 - INFO - root - Page:0, Index:12, Towards Verified Compilation of Floating-point Optimization in Scientific Computing Programs, https://arxiv.org/pdf/2509.09019, 2025-09-10
2025-11-09 12:02:34,859 - INFO - root - Page:0, Index:13, Green Learning for STAR-RIS mmWave Systems with Implicit CSI, https://arxiv.org/pdf/2509.06820, 2025-09-08
2025-11-09 12:02:34,859 - INFO - root - Page:0, Index:14, A Compute&Memory Efficient Model-Driven Neural 5G Receiver for Edge AI-assisted RAN, https://arxiv.org/pdf/2508.12892, 2025-10-22
2025-11-09 12:02:34,859 - INFO - root - Page:0, Index:15, SNNSIR: A Simple Spiking Neural Network for Stereo Image Restoration, https://arxiv.org/pdf/2508.12271, 2025-08-17
2025-11-09 12:02:34,860 - INFO - root - Page:0, Index:16, SpikeSTAG: Spatial-Temporal Forecasting via GNN-SNN Collaboration, https://arxiv.org/pdf/2508.02069, 2025-08-18
2025-11-09 12:02:34,860 - INFO - root - Page:0, Index:17, DGEMM without FP64 Arithmetic - Using FP64 Emulation and FP8 Tensor Cores with Ozaki Scheme, https://arxiv.org/pdf/2508.00441, 2025-09-25
2025-11-09 12:02:34,860 - INFO - root - Page:0, Index:18, Scaling Probabilistic Circuits via Monarch Matrices, https://arxiv.org/pdf/2506.12383, 2025-06-14
2025-11-09 12:02:34,861 - INFO - root - Page:0, Index:19, Starting Positions Matter: A Study on Better Weight Initialization for Neural Network Quantization, https://arxiv.org/pdf/2506.10463, 2025-06-12
2025-11-09 12:02:34,861 - INFO - root - Page:0, Index:20, Recipes for Pre-training LLMs with MXFP8, https://arxiv.org/pdf/2506.08027, 2025-08-18
2025-11-09 12:02:34,862 - INFO - root - Page:0, Index:21, FP4 All the Way: Fully Quantized Training of LLMs, https://arxiv.org/pdf/2505.19115, 2025-08-10
2025-11-09 12:02:34,862 - INFO - root - Page:0, Index:22, Automatic Verification of Floating-Point Accumulation Networks, https://arxiv.org/pdf/2505.18791, 2025-05-24
2025-11-09 12:02:34,862 - INFO - root - Page:0, Index:23, MXDOTP: A RISC-V ISA Extension for Enabling Microscaling (MX) Floating-Point Dot Products, https://arxiv.org/pdf/2505.13159, 2025-05-19
2025-11-09 12:02:34,862 - INFO - root - Page:0, Index:24, Parameter-Efficient Fine-Tuning with Circulant and Diagonal Vectors, https://arxiv.org/pdf/2505.00580, 2025-07-15
2025-11-09 12:02:34,863 - INFO - root - Page:0, Index:25, Silenzio: Secure Non-Interactive Outsourced MLP Training, https://arxiv.org/pdf/2504.17785, 2025-09-18
2025-11-09 12:02:34,863 - INFO - root - Page:0, Index:26, Involution and BSConv Multi-Depth Distillation Network for Lightweight Image Super-Resolution, https://arxiv.org/pdf/2503.14779, 2025-09-08
2025-11-09 12:02:34,863 - INFO - root - Page:0, Index:27, Flopping for FLOPs: Leveraging equivariance for computational efficiency, https://arxiv.org/pdf/2502.05169, 2025-06-24
2025-11-09 12:02:34,863 - INFO - root - Page:0, Index:28, An Effective UNet Using Feature Interaction and Fusion for Organ Segmentation in Medical Image, https://arxiv.org/pdf/2409.05324, 2025-07-26
2025-11-09 12:02:34,864 - INFO - root - Fetching page 2 with URL: https://arxiv.org/search/?query=block+float+point&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=50
2025-11-09 12:02:41,042 - INFO - root - get_all_titles_from_web 
2025-11-09 12:02:41,042 - INFO - root - Page:1, Index:0, TwinLiteNet+: An Enhanced Multi-Task Segmentation Model for Autonomous Driving, https://arxiv.org/pdf/2403.16958, 2025-08-30
2025-11-09 12:02:41,043 - INFO - root - Fetching page 3 with URL: https://arxiv.org/search/?query=block+float+point&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=100
2025-11-09 12:02:47,533 - INFO - root - ------------------------------------------------------------------------------------------------------------------------
2025-11-09 12:02:59,831 - INFO - root - 正在总结论文 1/2: From Uniform to Adaptive: General Skip-Block Mechanisms for Efficient PDE Neural Operators
2025-11-09 12:02:59,835 - INFO - root - 正在提取论文图片...
2025-11-09 12:03:00,382 - INFO - root - 已保存图片 1/10：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_1_page3.png
2025-11-09 12:03:00,553 - INFO - root - 已保存图片 2/10：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_2_page8.png
2025-11-09 12:03:00,645 - INFO - root - 已保存图片 3/10：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_3_page8.png
2025-11-09 12:03:00,721 - INFO - root - 已保存图片 4/10：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_4_page9.png
2025-11-09 12:03:00,827 - INFO - root - 已保存图片 5/10：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_5_page9.png
2025-11-09 12:03:00,943 - INFO - root - 已保存图片 6/10：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_6_page4.png
2025-11-09 12:03:01,103 - INFO - root - 已保存图片 7/10：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_7_page4.png
2025-11-09 12:03:01,219 - INFO - root - 已保存图片 8/10：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_8_page16.png
2025-11-09 12:03:01,246 - INFO - root - 已保存图片 9/10：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_9_page4.png
2025-11-09 12:03:01,272 - INFO - root - 已保存图片 10/10：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_10_page4.png
2025-11-09 12:03:01,284 - INFO - root - 输出文件已存在，跳过论文 From Uniform to Adaptive: General Skip-Block Mechanisms for Efficient PDE Neural Operators 的处理
2025-11-09 12:03:01,286 - INFO - root - 正在总结论文 2/2: INT v.s. FP: A Comprehensive Study of Fine-Grained Low-bit Quantization Formats
2025-11-09 12:03:01,287 - INFO - root - 正在提取论文图片...
2025-11-09 12:03:02,061 - INFO - root - 已保存图片 1/10：./export\images_INT v.s. FP_ A Comprehensive Study of Fine-Grained Low-bit Quantization Formats\figure_1_page9.png
2025-11-09 12:03:02,238 - INFO - root - 已保存图片 2/10：./export\images_INT v.s. FP_ A Comprehensive Study of Fine-Grained Low-bit Quantization Formats\figure_2_page1.png
2025-11-09 12:03:02,291 - INFO - root - 已保存图片 3/10：./export\images_INT v.s. FP_ A Comprehensive Study of Fine-Grained Low-bit Quantization Formats\figure_3_page1.jpeg
2025-11-09 12:03:02,361 - INFO - root - 已保存图片 4/10：./export\images_INT v.s. FP_ A Comprehensive Study of Fine-Grained Low-bit Quantization Formats\figure_4_page9.png
2025-11-09 12:03:02,364 - INFO - root - 输出文件已存在，跳过论文 INT v.s. FP: A Comprehensive Study of Fine-Grained Low-bit Quantization Formats 的处理
2025-11-09 12:03:02,364 - INFO - root - summary time: 36.04 seconds
2025-11-09 12:40:27,534 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-09 12:40:27,541 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-09 12:40:27,546 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-09 12:40:28,502 - INFO - root - GeminiClient: trying model gemini-2.5-flash
2025-11-09 12:40:29,436 - INFO - root - GeminiClient: trying model gemini-2.5-pro
2025-11-09 12:40:29,790 - WARNING - root - GeminiClient: no usable model found
2025-11-09 12:40:29,791 - WARNING - root - LLMClientManager: Gemini client initialization failed
2025-11-09 12:40:29,791 - WARNING - root - DeepSeekClient: API key not provided. LLM disabled.
2025-11-09 12:40:29,791 - WARNING - root - LLMClientManager: DeepSeek client initialization failed
2025-11-09 12:40:29,791 - WARNING - root - KimiClient: API key not provided. LLM disabled.
2025-11-09 12:40:29,792 - WARNING - root - LLMClientManager: Kimi client initialization failed
2025-11-09 12:40:29,792 - WARNING - root - QwenClient: API key not provided. LLM disabled.
2025-11-09 12:40:29,792 - WARNING - root - LLMClientManager: Qwen client initialization failed
2025-11-09 12:40:29,792 - WARNING - root - DoubaoClient: API key not provided. LLM disabled.
2025-11-09 12:40:29,793 - WARNING - root - LLMClientManager: Doubao client initialization failed
2025-11-09 12:40:29,793 - WARNING - root - LLMClientManager: no LLM client available
2025-11-09 12:40:29,793 - WARNING - root - LLMClientManager: client Gemini not available
2025-11-09 12:40:29,794 - WARNING - root - 无法切换到指定的客户端 Gemini，将使用默认客户端
2025-11-09 12:40:29,794 - INFO - root - 可用客户端: []
2025-11-09 12:40:29,795 - INFO - root - LLM 未初始化或不可用，后续生成将返回备用消息
2025-11-09 12:40:29,795 - INFO - root - === 运行配置 ===
2025-11-09 12:40:29,795 - INFO - root - 处理模式: 本地PDF文件
2025-11-09 12:40:29,796 - INFO - root - PDF目录: ./myPapers
2025-11-09 12:40:29,796 - INFO - root - 最大处理数量: 2
2025-11-09 12:40:29,797 - INFO - root - 保存图片: 是
2025-11-09 12:40:29,799 - INFO - root - 输出语言: 中文
2025-11-09 12:40:29,799 - INFO - root - 强制重新处理: 否
2025-11-09 12:40:29,800 - INFO - root - ====================
2025-11-09 12:40:29,800 - INFO - root - 从本地目录读取PDF文件：./myPapers
2025-11-09 12:40:32,678 - INFO - root - 成功加载PDF文件：A Compute&Memory Efficient Model-Driven Neural 5G Receiver for Edge AI-assisted.pdf
2025-11-09 12:40:35,064 - INFO - root - 成功加载PDF文件：AMLA_ MUL by ADD in FlashAttention Rescaling.pdf
2025-11-09 12:40:35,890 - INFO - root - 成功加载PDF文件：An Effective UNet Using Feature Interaction and Fusion for Organ Segmentation in.pdf
2025-11-09 12:42:15,377 - INFO - root - 成功加载PDF文件：Automated and Scalable SEM Image Analysis of Perovskite Solar Cell Materials via.pdf
2025-11-09 12:42:16,352 - INFO - root - 成功加载PDF文件：Automatic Verification of Floating-Point Accumulation Networks.pdf
2025-11-09 12:42:17,772 - INFO - root - 成功加载PDF文件：Bridging the Gap Between Promise and Performance for Microscaling FP4 Quantizati.pdf
2025-11-09 12:42:20,130 - INFO - root - 成功加载PDF文件：Computationally Efficient Neural Receivers via Axial Self-Attention.pdf
2025-11-09 12:42:21,023 - INFO - root - 成功加载PDF文件：DGEMM without FP64 Arithmetic - Using FP64 Emulation and FP8 Tensor Cores with O.pdf
2025-11-09 12:42:23,369 - INFO - root - 成功加载PDF文件：Dissecting Transformers_ A CLEAR Perspective towards Green AI.pdf
2025-11-09 12:42:23,819 - INFO - root - 成功加载PDF文件：Efficient In-Memory Acceleration of Sparse Block Diagonal LLMs.pdf
2025-11-09 12:42:26,826 - INFO - root - 成功加载PDF文件：F-BFQ_ Flexible Block Floating-Point Quantization Accelerator for LLMs.pdf
2025-11-09 12:42:28,662 - INFO - root - 成功加载PDF文件：Flopping for FLOPs_ Leveraging equivariance for computational efficiency.pdf
2025-11-09 12:42:29,354 - INFO - root - 成功加载PDF文件：FP4 All the Way_ Fully Quantized Training of LLMs.pdf
2025-11-09 12:42:30,794 - INFO - root - 成功加载PDF文件：From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural.pdf
2025-11-09 12:42:31,478 - INFO - root - 成功加载PDF文件：Green Learning for STAR-RIS mmWave Systems with Implicit CSI.pdf
2025-11-09 12:42:38,123 - INFO - root - 成功加载PDF文件：INT v.s. FP_ A Comprehensive Study of Fine-Grained Low-bit Quantization Formats.pdf
2025-11-09 12:42:38,686 - INFO - root - 成功加载PDF文件：Involution and BSConv Multi-Depth Distillation Network for Lightweight Image Sup.pdf
2025-11-09 12:42:39,128 - INFO - root - 成功加载PDF文件：Microscaling Floating Point Formats for Large Language Models.pdf
2025-11-09 12:42:39,967 - INFO - root - 成功加载PDF文件：MX+_ Pushing the Limits of Microscaling Formats for Efficient Large Language Mod.pdf
2025-11-09 12:42:40,332 - INFO - root - 成功加载PDF文件：MXDOTP_ A RISC-V ISA Extension for Enabling Microscaling (MX) Floating-Point Dot.pdf
2025-11-09 12:42:40,665 - INFO - root - 成功加载PDF文件：Parameter-Efficient Fine-Tuning with Circulant and Diagonal Vectors.pdf
2025-11-09 12:42:42,370 - INFO - root - 成功加载PDF文件：Pretraining Large Language Models with NVFP4.pdf
2025-11-09 12:42:42,773 - INFO - root - 成功加载PDF文件：Recipes for Pre-training LLMs with MXFP8.pdf
2025-11-09 12:42:44,763 - INFO - root - 成功加载PDF文件：Scaling Probabilistic Circuits via Monarch Matrices.pdf
2025-11-09 12:42:44,776 - ERROR - root - 处理PDF文件 Silenzio_ Secure Non-Interactive Outsourced MLP Training.pdf 时出错：no such file: './myPapers\Silenzio_ Secure Non-Interactive Outsourced MLP Training.pdf'
2025-11-09 12:42:44,778 - ERROR - root - 处理PDF文件 SNNSIR_ A Simple Spiking Neural Network for Stereo Image Restoration.pdf 时出错：no such file: './myPapers\SNNSIR_ A Simple Spiking Neural Network for Stereo Image Restoration.pdf'
2025-11-09 12:42:44,909 - ERROR - root - 处理PDF文件 SpikeSTAG_ Spatial-Temporal Forecasting via GNN-SNN Collaboration.pdf 时出错：no such file: './myPapers\SpikeSTAG_ Spatial-Temporal Forecasting via GNN-SNN Collaboration.pdf'
2025-11-09 12:42:44,940 - ERROR - root - 处理PDF文件 Starting Positions Matter_ A Study on Better Weight Initialization for Neural Ne.pdf 时出错：no such file: './myPapers\Starting Positions Matter_ A Study on Better Weight Initialization for Neural Ne.pdf'
2025-11-09 12:42:44,984 - ERROR - root - 处理PDF文件 Towards Verified Compilation of Floating-point Optimization in Scientific Comput.pdf 时出错：no such file: './myPapers\Towards Verified Compilation of Floating-point Optimization in Scientific Comput.pdf'
2025-11-09 12:42:44,994 - ERROR - root - 处理PDF文件 TwinLiteNet+_ An Enhanced Multi-Task Segmentation Model for Autonomous Driving.pdf 时出错：no such file: './myPapers\TwinLiteNet+_ An Enhanced Multi-Task Segmentation Model for Autonomous Driving.pdf'
2025-11-09 12:42:45,008 - INFO - root - 正在总结论文 1/24: A Compute&Memory Efficient Model-Driven Neural
2025-11-09 12:42:45,010 - INFO - root - 正在提取论文图片...
2025-11-09 12:42:46,858 - INFO - root - 已保存图片 1/10：./export\images_A Compute&Memory Efficient Model-Driven Neural\figure_1_page6.png
2025-11-09 12:42:47,327 - INFO - root - 已保存图片 2/10：./export\images_A Compute&Memory Efficient Model-Driven Neural\figure_2_page6.png
2025-11-09 12:42:47,562 - INFO - root - 已保存图片 3/10：./export\images_A Compute&Memory Efficient Model-Driven Neural\figure_3_page2.png
2025-11-09 12:42:47,639 - INFO - root - 已保存图片 4/10：./export\images_A Compute&Memory Efficient Model-Driven Neural\figure_4_page2.png
2025-11-09 12:42:47,689 - INFO - root - 已保存图片 5/10：./export\images_A Compute&Memory Efficient Model-Driven Neural\figure_5_page3.png
2025-11-09 12:42:47,702 - INFO - root - 成功添加图片 1：./export\images_A Compute&Memory Efficient Model-Driven Neural\figure_1_page6.png
2025-11-09 12:42:47,702 - INFO - root - 成功添加图片 2：./export\images_A Compute&Memory Efficient Model-Driven Neural\figure_2_page6.png
2025-11-09 12:42:47,703 - INFO - root - 成功添加图片 3：./export\images_A Compute&Memory Efficient Model-Driven Neural\figure_3_page2.png
2025-11-09 12:42:47,703 - INFO - root - 成功添加图片 4：./export\images_A Compute&Memory Efficient Model-Driven Neural\figure_4_page2.png
2025-11-09 12:42:47,703 - INFO - root - 成功添加图片 5：./export\images_A Compute&Memory Efficient Model-Driven Neural\figure_5_page3.png
2025-11-09 12:42:47,711 - INFO - root - 论文《A Compute&Memory Efficient Model-Driven Neural》的分析已保存到 ./export\A Compute&Memory Efficient Model-Driven Neural.md
2025-11-09 12:42:47,729 - INFO - root - 跳过已处理论文 AMLA: MUL by ADD in FlashAttention Rescaling：./myPapers\AMLA_ MUL by ADD in FlashAttention Rescaling.pdf
2025-11-09 12:42:47,730 - INFO - root - 正在总结论文 3/24: An Effective UNet Using Feature Interaction and Fusion for Organ
2025-11-09 12:42:47,737 - INFO - root - 正在提取论文图片...
2025-11-09 12:42:48,558 - INFO - root - 已保存图片 1/10：./export\images_An Effective UNet Using Feature Interaction and Fusion for Organ\figure_1_page14.png
2025-11-09 12:42:48,712 - INFO - root - 已保存图片 2/10：./export\images_An Effective UNet Using Feature Interaction and Fusion for Organ\figure_2_page19.jpeg
2025-11-09 12:42:48,812 - INFO - root - 已保存图片 3/10：./export\images_An Effective UNet Using Feature Interaction and Fusion for Organ\figure_3_page19.jpeg
2025-11-09 12:42:48,931 - INFO - root - 已保存图片 4/10：./export\images_An Effective UNet Using Feature Interaction and Fusion for Organ\figure_4_page19.jpeg
2025-11-09 12:42:49,105 - INFO - root - 已保存图片 5/10：./export\images_An Effective UNet Using Feature Interaction and Fusion for Organ\figure_5_page19.jpeg
2025-11-09 12:42:49,209 - INFO - root - 已保存图片 6/10：./export\images_An Effective UNet Using Feature Interaction and Fusion for Organ\figure_6_page19.jpeg
2025-11-09 12:42:49,478 - INFO - root - 已保存图片 7/10：./export\images_An Effective UNet Using Feature Interaction and Fusion for Organ\figure_7_page19.jpeg
2025-11-09 12:42:49,706 - INFO - root - 已保存图片 8/10：./export\images_An Effective UNet Using Feature Interaction and Fusion for Organ\figure_8_page19.jpeg
2025-11-09 12:42:49,794 - INFO - root - 已保存图片 9/10：./export\images_An Effective UNet Using Feature Interaction and Fusion for Organ\figure_9_page19.jpeg
2025-11-09 12:42:49,961 - INFO - root - 已保存图片 10/10：./export\images_An Effective UNet Using Feature Interaction and Fusion for Organ\figure_10_page19.jpeg
2025-11-09 12:42:49,966 - INFO - root - 成功添加图片 1：./export\images_An Effective UNet Using Feature Interaction and Fusion for Organ\figure_1_page14.png
2025-11-09 12:42:49,967 - INFO - root - 成功添加图片 2：./export\images_An Effective UNet Using Feature Interaction and Fusion for Organ\figure_2_page19.jpeg
2025-11-09 12:42:49,969 - INFO - root - 成功添加图片 3：./export\images_An Effective UNet Using Feature Interaction and Fusion for Organ\figure_3_page19.jpeg
2025-11-09 12:42:49,977 - INFO - root - 成功添加图片 4：./export\images_An Effective UNet Using Feature Interaction and Fusion for Organ\figure_4_page19.jpeg
2025-11-09 12:42:49,979 - INFO - root - 成功添加图片 5：./export\images_An Effective UNet Using Feature Interaction and Fusion for Organ\figure_5_page19.jpeg
2025-11-09 12:42:49,982 - INFO - root - 成功添加图片 6：./export\images_An Effective UNet Using Feature Interaction and Fusion for Organ\figure_6_page19.jpeg
2025-11-09 12:42:49,985 - INFO - root - 成功添加图片 7：./export\images_An Effective UNet Using Feature Interaction and Fusion for Organ\figure_7_page19.jpeg
2025-11-09 12:42:49,993 - INFO - root - 成功添加图片 8：./export\images_An Effective UNet Using Feature Interaction and Fusion for Organ\figure_8_page19.jpeg
2025-11-09 12:42:49,996 - INFO - root - 成功添加图片 9：./export\images_An Effective UNet Using Feature Interaction and Fusion for Organ\figure_9_page19.jpeg
2025-11-09 12:42:50,011 - INFO - root - 成功添加图片 10：./export\images_An Effective UNet Using Feature Interaction and Fusion for Organ\figure_10_page19.jpeg
2025-11-09 12:42:50,030 - INFO - root - 论文《An Effective UNet Using Feature Interaction and Fusion for Organ》的分析已保存到 ./export\An Effective UNet Using Feature Interaction and Fusion for Organ.md
2025-11-09 12:42:50,076 - INFO - root - 正在总结论文 4/24: Automated and Scalable SEM Image Analysis of Perovskite Solar Cell
2025-11-09 12:42:50,095 - INFO - root - 正在提取论文图片...
2025-11-09 12:43:28,803 - INFO - root - 已保存图片 1/10：./export\images_Automated and Scalable SEM Image Analysis of Perovskite Solar Cell\figure_1_page8.jpeg
2025-11-09 12:43:29,124 - INFO - root - 已保存图片 2/10：./export\images_Automated and Scalable SEM Image Analysis of Perovskite Solar Cell\figure_2_page5.jpeg
2025-11-09 12:43:29,434 - INFO - root - 已保存图片 3/10：./export\images_Automated and Scalable SEM Image Analysis of Perovskite Solar Cell\figure_3_page9.jpeg
2025-11-09 12:43:29,639 - INFO - root - 已保存图片 4/10：./export\images_Automated and Scalable SEM Image Analysis of Perovskite Solar Cell\figure_4_page9.jpeg
2025-11-09 12:43:29,842 - INFO - root - 已保存图片 5/10：./export\images_Automated and Scalable SEM Image Analysis of Perovskite Solar Cell\figure_5_page9.jpeg
2025-11-09 12:43:30,072 - INFO - root - 已保存图片 6/10：./export\images_Automated and Scalable SEM Image Analysis of Perovskite Solar Cell\figure_6_page9.jpeg
2025-11-09 12:43:30,284 - INFO - root - 已保存图片 7/10：./export\images_Automated and Scalable SEM Image Analysis of Perovskite Solar Cell\figure_7_page9.jpeg
2025-11-09 12:43:30,485 - INFO - root - 已保存图片 8/10：./export\images_Automated and Scalable SEM Image Analysis of Perovskite Solar Cell\figure_8_page9.jpeg
2025-11-09 12:43:30,688 - INFO - root - 已保存图片 9/10：./export\images_Automated and Scalable SEM Image Analysis of Perovskite Solar Cell\figure_9_page9.jpeg
2025-11-09 12:43:30,896 - INFO - root - 已保存图片 10/10：./export\images_Automated and Scalable SEM Image Analysis of Perovskite Solar Cell\figure_10_page9.jpeg
2025-11-09 12:43:30,919 - INFO - root - 成功添加图片 1：./export\images_Automated and Scalable SEM Image Analysis of Perovskite Solar Cell\figure_1_page8.jpeg
2025-11-09 12:43:30,920 - INFO - root - 成功添加图片 2：./export\images_Automated and Scalable SEM Image Analysis of Perovskite Solar Cell\figure_2_page5.jpeg
2025-11-09 12:43:30,921 - INFO - root - 成功添加图片 3：./export\images_Automated and Scalable SEM Image Analysis of Perovskite Solar Cell\figure_3_page9.jpeg
2025-11-09 12:43:30,921 - INFO - root - 成功添加图片 4：./export\images_Automated and Scalable SEM Image Analysis of Perovskite Solar Cell\figure_4_page9.jpeg
2025-11-09 12:43:30,922 - INFO - root - 成功添加图片 5：./export\images_Automated and Scalable SEM Image Analysis of Perovskite Solar Cell\figure_5_page9.jpeg
2025-11-09 12:43:30,922 - INFO - root - 成功添加图片 6：./export\images_Automated and Scalable SEM Image Analysis of Perovskite Solar Cell\figure_6_page9.jpeg
2025-11-09 12:43:30,922 - INFO - root - 成功添加图片 7：./export\images_Automated and Scalable SEM Image Analysis of Perovskite Solar Cell\figure_7_page9.jpeg
2025-11-09 12:43:30,923 - INFO - root - 成功添加图片 8：./export\images_Automated and Scalable SEM Image Analysis of Perovskite Solar Cell\figure_8_page9.jpeg
2025-11-09 12:43:30,923 - INFO - root - 成功添加图片 9：./export\images_Automated and Scalable SEM Image Analysis of Perovskite Solar Cell\figure_9_page9.jpeg
2025-11-09 12:43:30,925 - INFO - root - 成功添加图片 10：./export\images_Automated and Scalable SEM Image Analysis of Perovskite Solar Cell\figure_10_page9.jpeg
2025-11-09 12:43:30,932 - INFO - root - 论文《Automated and Scalable SEM Image Analysis of Perovskite Solar Cell》的分析已保存到 ./export\Automated and Scalable SEM Image Analysis of Perovskite Solar Cell.md
2025-11-09 12:43:30,948 - INFO - root - 正在总结论文 5/24: Automatic Verification of
2025-11-09 12:43:30,950 - INFO - root - 正在提取论文图片...
2025-11-09 12:43:30,989 - INFO - root - 论文《Automatic Verification of》的分析已保存到 ./export\Automatic Verification of.md
2025-11-09 12:43:31,005 - INFO - root - 正在总结论文 6/24: 
2025-11-09 12:43:31,014 - INFO - root - 正在提取论文图片...
2025-11-09 12:43:31,371 - INFO - root - 已保存图片 1/10：./export\images_untitled\figure_1_page25.png
2025-11-09 12:43:31,371 - INFO - root - 成功添加图片 1：./export\images_untitled\figure_1_page25.png
2025-11-09 12:43:31,386 - INFO - root - 论文《》的分析已保存到 ./export\traffic flow prediction.md
2025-11-09 12:43:31,402 - INFO - root - 正在总结论文 7/24: Computationally Efficient Neural Receivers via
2025-11-09 12:43:31,409 - INFO - root - 正在提取论文图片...
2025-11-09 12:43:32,644 - INFO - root - 已保存图片 1/10：./export\images_Computationally Efficient Neural Receivers via\figure_1_page5.png
2025-11-09 12:43:32,650 - INFO - root - 成功添加图片 1：./export\images_Computationally Efficient Neural Receivers via\figure_1_page5.png
2025-11-09 12:43:32,655 - INFO - root - 论文《Computationally Efficient Neural Receivers via》的分析已保存到 ./export\Computationally Efficient Neural Receivers via.md
2025-11-09 12:43:32,660 - INFO - root - 正在总结论文 8/24: DGEMM without FP64 Arithmetic – Using FP64 Emulation and
2025-11-09 12:43:32,666 - INFO - root - 正在提取论文图片...
2025-11-09 12:45:56,822 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-09 12:45:56,824 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-09 12:45:56,826 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-09 12:45:57,544 - INFO - root - GeminiClient: trying model gemini-2.5-flash
2025-11-09 12:45:58,503 - INFO - root - GeminiClient: trying model gemini-2.5-pro
2025-11-09 12:45:58,863 - WARNING - root - GeminiClient: no usable model found
2025-11-09 12:45:58,863 - WARNING - root - LLMClientManager: Gemini client initialization failed
2025-11-09 12:45:58,864 - WARNING - root - DeepSeekClient: API key not provided. LLM disabled.
2025-11-09 12:45:58,864 - WARNING - root - LLMClientManager: DeepSeek client initialization failed
2025-11-09 12:45:58,864 - WARNING - root - KimiClient: API key not provided. LLM disabled.
2025-11-09 12:45:58,865 - WARNING - root - LLMClientManager: Kimi client initialization failed
2025-11-09 12:45:58,865 - WARNING - root - QwenClient: API key not provided. LLM disabled.
2025-11-09 12:45:58,866 - WARNING - root - LLMClientManager: Qwen client initialization failed
2025-11-09 12:45:58,866 - WARNING - root - DoubaoClient: API key not provided. LLM disabled.
2025-11-09 12:45:58,866 - WARNING - root - LLMClientManager: Doubao client initialization failed
2025-11-09 12:45:58,867 - WARNING - root - LLMClientManager: no LLM client available
2025-11-09 12:45:58,867 - INFO - root - LLM 未初始化或不可用，后续生成将返回备用消息
2025-11-09 12:45:58,867 - INFO - root - === 运行配置 ===
2025-11-09 12:45:58,867 - INFO - root - 处理模式: 本地PDF文件
2025-11-09 12:45:58,868 - INFO - root - PDF目录: ./myPapers
2025-11-09 12:45:58,869 - INFO - root - 最大处理数量: 2
2025-11-09 12:45:58,869 - INFO - root - 保存图片: 是
2025-11-09 12:45:58,869 - INFO - root - 输出语言: 中文
2025-11-09 12:45:58,870 - INFO - root - 强制重新处理: 否
2025-11-09 12:45:58,870 - INFO - root - ====================
2025-11-09 12:45:58,870 - INFO - root - 从本地目录读取PDF文件：./myPapers
2025-11-09 12:46:00,328 - INFO - root - 成功加载PDF文件：A Compute&Memory Efficient Model-Driven Neural 5G Receiver for Edge AI-assisted.pdf
2025-11-09 12:46:02,886 - INFO - root - 成功加载PDF文件：AMLA_ MUL by ADD in FlashAttention Rescaling.pdf
2025-11-09 12:46:02,886 - INFO - root - 已达到最大处理数量限制 (2)，停止加载更多PDF文件
2025-11-09 12:46:02,887 - INFO - root - 跳过已处理论文 A Compute&Memory Efficient Model-Driven Neural：./myPapers\A Compute&Memory Efficient Model-Driven Neural 5G Receiver for Edge AI-assisted.pdf
2025-11-09 12:46:02,889 - INFO - root - 跳过已处理论文 AMLA: MUL by ADD in FlashAttention Rescaling：./myPapers\AMLA_ MUL by ADD in FlashAttention Rescaling.pdf
2025-11-09 12:46:02,890 - INFO - root - summary time: 6.07 seconds
2025-11-09 12:46:38,191 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-09 12:46:38,192 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-09 12:46:38,194 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-09 12:46:38,778 - INFO - root - GeminiClient: trying model gemini-2.5-flash
2025-11-09 12:46:39,436 - INFO - root - GeminiClient: trying model gemini-2.5-pro
2025-11-09 12:46:39,558 - WARNING - root - GeminiClient: no usable model found
2025-11-09 12:46:39,560 - WARNING - root - LLMClientManager: Gemini client initialization failed
2025-11-09 12:46:39,560 - WARNING - root - DeepSeekClient: API key not provided. LLM disabled.
2025-11-09 12:46:39,561 - WARNING - root - LLMClientManager: DeepSeek client initialization failed
2025-11-09 12:46:39,562 - WARNING - root - KimiClient: API key not provided. LLM disabled.
2025-11-09 12:46:39,562 - WARNING - root - LLMClientManager: Kimi client initialization failed
2025-11-09 12:46:39,563 - WARNING - root - QwenClient: API key not provided. LLM disabled.
2025-11-09 12:46:39,563 - WARNING - root - LLMClientManager: Qwen client initialization failed
2025-11-09 12:46:40,213 - ERROR - root - DoubaoClient: API test failed with status 404
2025-11-09 12:46:40,215 - WARNING - root - LLMClientManager: Doubao client initialization failed
2025-11-09 12:46:40,215 - WARNING - root - LLMClientManager: no LLM client available
2025-11-09 12:46:40,215 - WARNING - root - LLMClientManager: client Doubao not available
2025-11-09 12:46:40,215 - WARNING - root - 无法切换到指定的客户端 Doubao，将使用默认客户端
2025-11-09 12:46:40,217 - INFO - root - 可用客户端: []
2025-11-09 12:46:40,217 - INFO - root - LLM 未初始化或不可用，后续生成将返回备用消息
2025-11-09 12:46:40,218 - INFO - root - === 运行配置 ===
2025-11-09 12:46:40,218 - INFO - root - 处理模式: 本地PDF文件
2025-11-09 12:46:40,221 - INFO - root - PDF目录: ./myPapers
2025-11-09 12:46:40,222 - INFO - root - 最大处理数量: 2
2025-11-09 12:46:40,223 - INFO - root - 保存图片: 是
2025-11-09 12:46:40,224 - INFO - root - 输出语言: 中文
2025-11-09 12:46:40,224 - INFO - root - 强制重新处理: 否
2025-11-09 12:46:40,224 - INFO - root - ====================
2025-11-09 12:46:40,226 - INFO - root - 从本地目录读取PDF文件：./myPapers
2025-11-09 12:46:41,906 - INFO - root - 成功加载PDF文件：A Compute&Memory Efficient Model-Driven Neural 5G Receiver for Edge AI-assisted.pdf
2025-11-09 12:46:45,400 - INFO - root - 成功加载PDF文件：AMLA_ MUL by ADD in FlashAttention Rescaling.pdf
2025-11-09 12:46:45,400 - INFO - root - 已达到最大处理数量限制 (2)，停止加载更多PDF文件
2025-11-09 12:46:45,401 - INFO - root - 跳过已处理论文 A Compute&Memory Efficient Model-Driven Neural：./myPapers\A Compute&Memory Efficient Model-Driven Neural 5G Receiver for Edge AI-assisted.pdf
2025-11-09 12:46:45,402 - INFO - root - 跳过已处理论文 AMLA: MUL by ADD in FlashAttention Rescaling：./myPapers\AMLA_ MUL by ADD in FlashAttention Rescaling.pdf
2025-11-09 12:46:45,402 - INFO - root - summary time: 7.21 seconds
2025-11-09 12:49:23,218 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-09 12:49:23,219 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-09 12:49:23,221 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-09 12:49:23,805 - INFO - root - GeminiClient: trying model gemini-2.5-flash
2025-11-09 12:49:24,666 - INFO - root - GeminiClient: trying model gemini-2.5-pro
2025-11-09 12:49:25,022 - WARNING - root - GeminiClient: no usable model found
2025-11-09 12:49:25,022 - WARNING - root - LLMClientManager: Gemini client initialization failed
2025-11-09 12:49:25,022 - WARNING - root - DeepSeekClient: API key not provided. LLM disabled.
2025-11-09 12:49:25,022 - WARNING - root - LLMClientManager: DeepSeek client initialization failed
2025-11-09 12:49:25,023 - WARNING - root - KimiClient: API key not provided. LLM disabled.
2025-11-09 12:49:25,023 - WARNING - root - LLMClientManager: Kimi client initialization failed
2025-11-09 12:49:25,023 - WARNING - root - QwenClient: API key not provided. LLM disabled.
2025-11-09 12:49:25,024 - WARNING - root - LLMClientManager: Qwen client initialization failed
2025-11-09 12:49:25,491 - ERROR - root - DoubaoClient: API test failed with status 404
2025-11-09 12:49:25,493 - WARNING - root - LLMClientManager: Doubao client initialization failed
2025-11-09 12:49:25,493 - WARNING - root - LLMClientManager: no LLM client available
2025-11-09 12:49:25,494 - WARNING - root - LLMClientManager: client Doubao not available
2025-11-09 12:49:25,494 - WARNING - root - 无法切换到指定的客户端 Doubao，将使用默认客户端
2025-11-09 12:49:25,494 - INFO - root - 可用客户端: []
2025-11-09 12:49:25,495 - INFO - root - LLM 未初始化或不可用，后续生成将返回备用消息
2025-11-09 12:49:25,495 - INFO - root - === 运行配置 ===
2025-11-09 12:49:25,495 - INFO - root - 处理模式: 本地PDF文件
2025-11-09 12:49:25,495 - INFO - root - PDF目录: ./myPapers
2025-11-09 12:49:25,495 - INFO - root - 最大处理数量: 2
2025-11-09 12:49:25,496 - INFO - root - 保存图片: 是
2025-11-09 12:49:25,497 - INFO - root - 输出语言: 中文
2025-11-09 12:49:25,497 - INFO - root - 强制重新处理: 否
2025-11-09 12:49:25,497 - INFO - root - ====================
2025-11-09 12:49:25,497 - INFO - root - 从本地目录读取PDF文件：./myPapers
2025-11-09 12:49:26,935 - INFO - root - 成功加载PDF文件：A Compute&Memory Efficient Model-Driven Neural 5G Receiver for Edge AI-assisted.pdf
2025-11-09 12:49:28,995 - INFO - root - 成功加载PDF文件：AMLA_ MUL by ADD in FlashAttention Rescaling.pdf
2025-11-09 12:49:28,996 - INFO - root - 已达到最大处理数量限制 (2)，停止加载更多PDF文件
2025-11-09 12:49:28,997 - INFO - root - 跳过已处理论文 A Compute&Memory Efficient Model-Driven Neural：./myPapers\A Compute&Memory Efficient Model-Driven Neural 5G Receiver for Edge AI-assisted.pdf
2025-11-09 12:49:28,997 - INFO - root - 跳过已处理论文 AMLA: MUL by ADD in FlashAttention Rescaling：./myPapers\AMLA_ MUL by ADD in FlashAttention Rescaling.pdf
2025-11-09 12:49:28,999 - INFO - root - summary time: 5.78 seconds
2025-11-09 12:58:12,607 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-09 12:58:12,611 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-09 12:58:12,613 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-09 12:58:13,285 - INFO - root - GeminiClient: trying model gemini-2.5-flash
2025-11-09 12:58:14,129 - INFO - root - GeminiClient: trying model gemini-2.5-pro
2025-11-09 12:58:14,477 - WARNING - root - GeminiClient: no usable model found
2025-11-09 12:58:14,478 - WARNING - root - LLMClientManager: Gemini client initialization failed
2025-11-09 12:58:14,478 - WARNING - root - DeepSeekClient: API key not provided. LLM disabled.
2025-11-09 12:58:14,478 - WARNING - root - LLMClientManager: DeepSeek client initialization failed
2025-11-09 12:58:14,479 - WARNING - root - KimiClient: API key not provided. LLM disabled.
2025-11-09 12:58:14,479 - WARNING - root - LLMClientManager: Kimi client initialization failed
2025-11-09 12:58:14,480 - WARNING - root - QwenClient: API key not provided. LLM disabled.
2025-11-09 12:58:14,480 - WARNING - root - LLMClientManager: Qwen client initialization failed
2025-11-09 12:58:15,026 - ERROR - root - DoubaoClient: API test failed with status 404
2025-11-09 12:58:15,030 - WARNING - root - LLMClientManager: Doubao client initialization failed
2025-11-09 12:58:15,031 - WARNING - root - LLMClientManager: no LLM client available
2025-11-09 12:58:15,031 - WARNING - root - LLMClientManager: client Doubao not available
2025-11-09 12:58:15,031 - WARNING - root - 无法切换到指定的客户端 Doubao，将使用默认客户端
2025-11-09 12:58:15,033 - INFO - root - 可用客户端: []
2025-11-09 12:58:15,033 - INFO - root - LLM 未初始化或不可用，后续生成将返回备用消息
2025-11-09 12:58:15,034 - INFO - root - === 运行配置 ===
2025-11-09 12:58:15,034 - INFO - root - 处理模式: 本地PDF文件
2025-11-09 12:58:15,034 - INFO - root - PDF目录: ./myPapers
2025-11-09 12:58:15,035 - INFO - root - 最大处理数量: 2
2025-11-09 12:58:15,035 - INFO - root - 保存图片: 是
2025-11-09 12:58:15,035 - INFO - root - 输出语言: 中文
2025-11-09 12:58:15,036 - INFO - root - 强制重新处理: 否
2025-11-09 12:58:15,036 - INFO - root - ====================
2025-11-09 12:58:15,036 - INFO - root - 从本地目录读取PDF文件：./myPapers
2025-11-09 12:58:16,829 - INFO - root - 成功加载PDF文件：A Compute&Memory Efficient Model-Driven Neural 5G Receiver for Edge AI-assisted.pdf
2025-11-09 12:58:19,740 - INFO - root - 成功加载PDF文件：AMLA_ MUL by ADD in FlashAttention Rescaling.pdf
2025-11-09 12:58:19,741 - INFO - root - 已达到最大处理数量限制 (2)，停止加载更多PDF文件
2025-11-09 12:58:19,747 - INFO - root - 跳过已处理论文 A Compute&Memory Efficient Model-Driven Neural：./myPapers\A Compute&Memory Efficient Model-Driven Neural 5G Receiver for Edge AI-assisted.pdf
2025-11-09 12:58:19,747 - INFO - root - 跳过已处理论文 AMLA: MUL by ADD in FlashAttention Rescaling：./myPapers\AMLA_ MUL by ADD in FlashAttention Rescaling.pdf
2025-11-09 12:58:19,748 - INFO - root - summary time: 7.14 seconds
2025-11-09 13:05:28,941 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-09 13:05:28,942 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-09 13:05:28,944 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-09 13:05:28,970 - INFO - root - LLMClientManager: 指定使用客户端: Doubao
2025-11-09 13:05:29,528 - ERROR - root - DoubaoClient: API test failed with status 404
2025-11-09 13:05:29,529 - ERROR - root - LLMClientManager: 指定的客户端 Doubao 初始化失败
2025-11-09 13:05:29,529 - WARNING - root - LLMClientManager: 指定的客户端 Doubao 不可用，将尝试其他客户端
2025-11-09 13:05:30,291 - INFO - root - GeminiClient: trying model gemini-2.5-flash
2025-11-09 13:05:31,203 - INFO - root - GeminiClient: trying model gemini-2.5-pro
2025-11-09 13:05:31,564 - WARNING - root - GeminiClient: no usable model found
2025-11-09 13:05:31,565 - WARNING - root - LLMClientManager: Gemini client initialization failed
2025-11-09 13:05:31,565 - WARNING - root - DeepSeekClient: API key not provided. LLM disabled.
2025-11-09 13:05:31,565 - WARNING - root - LLMClientManager: DeepSeek client initialization failed
2025-11-09 13:05:31,566 - WARNING - root - KimiClient: API key not provided. LLM disabled.
2025-11-09 13:05:31,566 - WARNING - root - LLMClientManager: Kimi client initialization failed
2025-11-09 13:05:31,566 - WARNING - root - QwenClient: API key not provided. LLM disabled.
2025-11-09 13:05:31,566 - WARNING - root - LLMClientManager: Qwen client initialization failed
2025-11-09 13:05:31,567 - WARNING - root - LLMClientManager: no LLM client available
2025-11-09 13:05:31,567 - WARNING - root - LLMClientManager: client Doubao not available
2025-11-09 13:05:31,568 - WARNING - root - 无法切换到指定的客户端 Doubao，将使用默认客户端
2025-11-09 13:05:31,568 - INFO - root - 可用客户端: []
2025-11-09 13:05:31,568 - INFO - root - LLM 未初始化或不可用，后续生成将返回备用消息
2025-11-09 13:05:31,568 - INFO - root - === 运行配置 ===
2025-11-09 13:05:31,569 - INFO - root - 处理模式: 本地PDF文件
2025-11-09 13:05:31,569 - INFO - root - PDF目录: ./myPapers
2025-11-09 13:05:31,569 - INFO - root - 最大处理数量: 2
2025-11-09 13:05:31,569 - INFO - root - 保存图片: 是
2025-11-09 13:05:31,570 - INFO - root - 输出语言: 中文
2025-11-09 13:05:31,570 - INFO - root - 强制重新处理: 否
2025-11-09 13:05:31,571 - INFO - root - ====================
2025-11-09 13:05:31,572 - INFO - root - 从本地目录读取PDF文件：./myPapers
2025-11-09 13:05:33,240 - INFO - root - 成功加载PDF文件：A Compute&Memory Efficient Model-Driven Neural 5G Receiver for Edge AI-assisted.pdf
2025-11-09 13:05:35,435 - INFO - root - 成功加载PDF文件：AMLA_ MUL by ADD in FlashAttention Rescaling.pdf
2025-11-09 13:05:35,435 - INFO - root - 已达到最大处理数量限制 (2)，停止加载更多PDF文件
2025-11-09 13:05:35,436 - INFO - root - 跳过已处理论文 A Compute&Memory Efficient Model-Driven Neural：./myPapers\A Compute&Memory Efficient Model-Driven Neural 5G Receiver for Edge AI-assisted.pdf
2025-11-09 13:05:35,437 - INFO - root - 跳过已处理论文 AMLA: MUL by ADD in FlashAttention Rescaling：./myPapers\AMLA_ MUL by ADD in FlashAttention Rescaling.pdf
2025-11-09 13:05:35,438 - INFO - root - summary time: 6.50 seconds
2025-11-09 13:09:04,133 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-09 13:09:04,152 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-09 13:09:04,154 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-09 13:09:04,321 - INFO - root - LLMClientManager: 指定使用客户端: Doubao
2025-11-09 13:09:06,618 - ERROR - root - DoubaoClient: API test failed with status 404
2025-11-09 13:09:06,631 - ERROR - root - LLMClientManager: 指定的客户端 Doubao 初始化失败
2025-11-09 13:09:06,644 - WARNING - root - LLMClientManager: 指定的客户端 Doubao 不可用，将尝试其他客户端
2025-11-09 13:09:08,688 - INFO - root - GeminiClient: trying model gemini-2.5-flash
2025-11-09 13:09:09,712 - INFO - root - GeminiClient: trying model gemini-2.5-pro
2025-11-09 13:09:10,067 - WARNING - root - GeminiClient: no usable model found
2025-11-09 13:09:10,075 - WARNING - root - LLMClientManager: Gemini client initialization failed
2025-11-09 13:09:10,076 - WARNING - root - DeepSeekClient: API key not provided. LLM disabled.
2025-11-09 13:09:10,077 - WARNING - root - LLMClientManager: DeepSeek client initialization failed
2025-11-09 13:09:10,079 - WARNING - root - KimiClient: API key not provided. LLM disabled.
2025-11-09 13:09:10,080 - WARNING - root - LLMClientManager: Kimi client initialization failed
2025-11-09 13:09:10,080 - WARNING - root - QwenClient: API key not provided. LLM disabled.
2025-11-09 13:09:10,081 - WARNING - root - LLMClientManager: Qwen client initialization failed
2025-11-09 13:09:10,082 - WARNING - root - LLMClientManager: no LLM client available
2025-11-09 13:09:10,082 - WARNING - root - LLMClientManager: client Doubao not available
2025-11-09 13:09:10,098 - WARNING - root - 无法切换到指定的客户端 Doubao，将使用默认客户端
2025-11-09 13:09:10,101 - INFO - root - 可用客户端: []
2025-11-09 13:09:10,107 - INFO - root - LLM 未初始化或不可用，后续生成将返回备用消息
2025-11-09 13:09:10,117 - INFO - root - === 运行配置 ===
2025-11-09 13:09:10,123 - INFO - root - 处理模式: 本地PDF文件
2025-11-09 13:09:10,126 - INFO - root - PDF目录: ./myPapers
2025-11-09 13:09:10,135 - INFO - root - 最大处理数量: 2
2025-11-09 13:09:10,143 - INFO - root - 保存图片: 是
2025-11-09 13:09:10,146 - INFO - root - 输出语言: 中文
2025-11-09 13:09:10,149 - INFO - root - 强制重新处理: 否
2025-11-09 13:09:10,151 - INFO - root - ====================
2025-11-09 13:09:10,158 - INFO - root - 从本地目录读取PDF文件：./myPapers
2025-11-09 13:09:15,684 - INFO - root - 成功加载PDF文件：A Compute&Memory Efficient Model-Driven Neural 5G Receiver for Edge AI-assisted.pdf
2025-11-09 13:09:19,567 - INFO - root - 成功加载PDF文件：AMLA_ MUL by ADD in FlashAttention Rescaling.pdf
2025-11-09 13:09:19,568 - INFO - root - 已达到最大处理数量限制 (2)，停止加载更多PDF文件
2025-11-09 13:09:19,572 - INFO - root - 跳过已处理论文 A Compute&Memory Efficient Model-Driven Neural：./myPapers\A Compute&Memory Efficient Model-Driven Neural 5G Receiver for Edge AI-assisted.pdf
2025-11-09 13:09:19,573 - INFO - root - 跳过已处理论文 AMLA: MUL by ADD in FlashAttention Rescaling：./myPapers\AMLA_ MUL by ADD in FlashAttention Rescaling.pdf
2025-11-09 13:09:19,574 - INFO - root - summary time: 15.44 seconds
2025-11-09 13:14:46,332 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-09 13:14:46,334 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-09 13:14:46,337 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-09 13:14:49,446 - INFO - root - LLMClientManager: 指定使用客户端: Doubao
2025-11-09 13:14:49,446 - WARNING - root - DoubaoClient: API key not provided. LLM disabled.
2025-11-09 13:14:49,446 - ERROR - root - LLMClientManager: 指定的客户端 Doubao 初始化失败
2025-11-09 13:14:49,446 - WARNING - root - LLMClientManager: 指定的客户端 Doubao 不可用，将尝试其他客户端
2025-11-09 13:14:50,249 - INFO - root - GeminiClient: trying model gemini-2.5-flash
2025-11-09 13:14:51,097 - INFO - root - GeminiClient: trying model gemini-2.5-pro
2025-11-09 13:14:51,453 - WARNING - root - GeminiClient: no usable model found
2025-11-09 13:14:51,454 - WARNING - root - LLMClientManager: Gemini client initialization failed
2025-11-09 13:14:51,455 - WARNING - root - DeepSeekClient: API key not provided. LLM disabled.
2025-11-09 13:14:51,455 - WARNING - root - LLMClientManager: DeepSeek client initialization failed
2025-11-09 13:14:51,456 - WARNING - root - KimiClient: API key not provided. LLM disabled.
2025-11-09 13:14:51,456 - WARNING - root - LLMClientManager: Kimi client initialization failed
2025-11-09 13:14:51,456 - WARNING - root - QwenClient: API key not provided. LLM disabled.
2025-11-09 13:14:51,457 - WARNING - root - LLMClientManager: Qwen client initialization failed
2025-11-09 13:14:51,457 - WARNING - root - LLMClientManager: no LLM client available
2025-11-09 13:14:51,458 - WARNING - root - LLMClientManager: client Doubao not available
2025-11-09 13:14:51,458 - WARNING - root - 无法切换到指定的客户端 Doubao，将使用默认客户端
2025-11-09 13:14:51,458 - INFO - root - 可用客户端: []
2025-11-09 13:14:51,459 - INFO - root - LLM 未初始化或不可用，后续生成将返回备用消息
2025-11-09 13:14:51,459 - INFO - root - === 运行配置 ===
2025-11-09 13:14:51,460 - INFO - root - 处理模式: 本地PDF文件
2025-11-09 13:14:51,461 - INFO - root - PDF目录: ./myPapers
2025-11-09 13:14:51,461 - INFO - root - 最大处理数量: 2
2025-11-09 13:14:51,463 - INFO - root - 保存图片: 是
2025-11-09 13:14:51,463 - INFO - root - 输出语言: 中文
2025-11-09 13:14:51,464 - INFO - root - 强制重新处理: 否
2025-11-09 13:14:51,465 - INFO - root - ====================
2025-11-09 13:14:51,466 - INFO - root - 从本地目录读取PDF文件：./myPapers
2025-11-09 13:14:53,801 - INFO - root - 成功加载PDF文件：A Compute&Memory Efficient Model-Driven Neural 5G Receiver for Edge AI-assisted.pdf
2025-11-09 13:14:57,267 - INFO - root - 成功加载PDF文件：AMLA_ MUL by ADD in FlashAttention Rescaling.pdf
2025-11-09 13:14:57,268 - INFO - root - 已达到最大处理数量限制 (2)，停止加载更多PDF文件
2025-11-09 13:14:57,277 - INFO - root - 跳过已处理论文 A Compute&Memory Efficient Model-Driven Neural：./myPapers\A Compute&Memory Efficient Model-Driven Neural 5G Receiver for Edge AI-assisted.pdf
2025-11-09 13:14:57,279 - INFO - root - 跳过已处理论文 AMLA: MUL by ADD in FlashAttention Rescaling：./myPapers\AMLA_ MUL by ADD in FlashAttention Rescaling.pdf
2025-11-09 13:14:57,279 - INFO - root - summary time: 10.95 seconds
2025-11-09 13:15:29,541 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-09 13:15:29,543 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-09 13:15:29,543 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-09 13:15:30,631 - INFO - root - LLMClientManager: 指定使用客户端: Doubao
2025-11-09 13:15:30,636 - WARNING - root - DoubaoClient: API key not provided. LLM disabled.
2025-11-09 13:15:30,636 - ERROR - root - LLMClientManager: 指定的客户端 Doubao 初始化失败
2025-11-09 13:15:30,636 - WARNING - root - LLMClientManager: 指定的客户端 Doubao 不可用，将尝试其他客户端
2025-11-09 13:15:31,714 - INFO - root - GeminiClient: trying model gemini-2.5-flash
2025-11-09 13:15:32,394 - INFO - root - GeminiClient: trying model gemini-2.5-pro
2025-11-09 13:15:32,518 - WARNING - root - GeminiClient: no usable model found
2025-11-09 13:15:32,519 - WARNING - root - LLMClientManager: Gemini client initialization failed
2025-11-09 13:15:32,520 - WARNING - root - DeepSeekClient: API key not provided. LLM disabled.
2025-11-09 13:15:32,521 - WARNING - root - LLMClientManager: DeepSeek client initialization failed
2025-11-09 13:15:32,522 - WARNING - root - KimiClient: API key not provided. LLM disabled.
2025-11-09 13:15:32,522 - WARNING - root - LLMClientManager: Kimi client initialization failed
2025-11-09 13:15:32,523 - WARNING - root - QwenClient: API key not provided. LLM disabled.
2025-11-09 13:15:32,523 - WARNING - root - LLMClientManager: Qwen client initialization failed
2025-11-09 13:15:32,523 - WARNING - root - LLMClientManager: no LLM client available
2025-11-09 13:15:32,524 - WARNING - root - LLMClientManager: client Doubao not available
2025-11-09 13:15:32,524 - WARNING - root - 无法切换到指定的客户端 Doubao，将使用默认客户端
2025-11-09 13:15:32,524 - INFO - root - 可用客户端: []
2025-11-09 13:15:32,525 - INFO - root - LLM 未初始化或不可用，后续生成将返回备用消息
2025-11-09 13:15:32,525 - INFO - root - === 运行配置 ===
2025-11-09 13:15:32,525 - INFO - root - 处理模式: 本地PDF文件
2025-11-09 13:15:32,526 - INFO - root - PDF目录: ./myPapers
2025-11-09 13:15:32,526 - INFO - root - 最大处理数量: 2
2025-11-09 13:15:32,527 - INFO - root - 保存图片: 是
2025-11-09 13:15:32,527 - INFO - root - 输出语言: 中文
2025-11-09 13:15:32,528 - INFO - root - 强制重新处理: 否
2025-11-09 13:15:32,528 - INFO - root - ====================
2025-11-09 13:15:32,529 - INFO - root - 从本地目录读取PDF文件：./myPapers
2025-11-09 13:15:34,692 - INFO - root - 成功加载PDF文件：A Compute&Memory Efficient Model-Driven Neural 5G Receiver for Edge AI-assisted.pdf
2025-11-09 13:15:37,219 - INFO - root - 成功加载PDF文件：AMLA_ MUL by ADD in FlashAttention Rescaling.pdf
2025-11-09 13:15:37,219 - INFO - root - 已达到最大处理数量限制 (2)，停止加载更多PDF文件
2025-11-09 13:15:37,220 - INFO - root - 跳过已处理论文 A Compute&Memory Efficient Model-Driven Neural：./myPapers\A Compute&Memory Efficient Model-Driven Neural 5G Receiver for Edge AI-assisted.pdf
2025-11-09 13:15:37,220 - INFO - root - 跳过已处理论文 AMLA: MUL by ADD in FlashAttention Rescaling：./myPapers\AMLA_ MUL by ADD in FlashAttention Rescaling.pdf
2025-11-09 13:15:37,222 - INFO - root - summary time: 7.68 seconds
2025-11-09 13:17:34,011 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-09 13:17:34,012 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-09 13:17:34,014 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-09 13:17:35,164 - INFO - root - LLMClientManager: 指定使用客户端: Doubao
2025-11-09 13:17:35,164 - ERROR - root - DoubaoClient: error reading config: RawConfigParser.get() takes 3 positional arguments but 4 were given
2025-11-09 13:17:35,165 - WARNING - root - DoubaoClient: API key not provided or using placeholder. LLM disabled.
2025-11-09 13:17:35,165 - ERROR - root - LLMClientManager: 指定的客户端 Doubao 初始化失败
2025-11-09 13:17:35,165 - WARNING - root - LLMClientManager: 指定的客户端 Doubao 不可用，将尝试其他客户端
2025-11-09 13:17:35,805 - INFO - root - GeminiClient: trying model gemini-2.5-flash
2025-11-09 13:17:36,828 - INFO - root - GeminiClient: trying model gemini-2.5-pro
2025-11-09 13:17:37,191 - WARNING - root - GeminiClient: no usable model found
2025-11-09 13:17:37,191 - WARNING - root - LLMClientManager: Gemini client initialization failed
2025-11-09 13:17:37,192 - WARNING - root - DeepSeekClient: API key not provided. LLM disabled.
2025-11-09 13:17:37,192 - WARNING - root - LLMClientManager: DeepSeek client initialization failed
2025-11-09 13:17:37,193 - WARNING - root - KimiClient: API key not provided. LLM disabled.
2025-11-09 13:17:37,193 - WARNING - root - LLMClientManager: Kimi client initialization failed
2025-11-09 13:17:37,193 - WARNING - root - QwenClient: API key not provided. LLM disabled.
2025-11-09 13:17:37,194 - WARNING - root - LLMClientManager: Qwen client initialization failed
2025-11-09 13:17:37,194 - WARNING - root - LLMClientManager: no LLM client available
2025-11-09 13:17:37,194 - WARNING - root - LLMClientManager: client Doubao not available
2025-11-09 13:17:37,195 - WARNING - root - 无法切换到指定的客户端 Doubao，将使用默认客户端
2025-11-09 13:17:37,195 - INFO - root - 可用客户端: []
2025-11-09 13:17:37,196 - INFO - root - LLM 未初始化或不可用，后续生成将返回备用消息
2025-11-09 13:17:37,196 - INFO - root - === 运行配置 ===
2025-11-09 13:17:37,203 - INFO - root - 处理模式: 本地PDF文件
2025-11-09 13:17:37,213 - INFO - root - PDF目录: ./myPapers
2025-11-09 13:17:37,219 - INFO - root - 最大处理数量: 2
2025-11-09 13:17:37,220 - INFO - root - 保存图片: 是
2025-11-09 13:17:37,224 - INFO - root - 输出语言: 中文
2025-11-09 13:17:37,225 - INFO - root - 强制重新处理: 否
2025-11-09 13:17:37,228 - INFO - root - ====================
2025-11-09 13:17:37,230 - INFO - root - 从本地目录读取PDF文件：./myPapers
2025-11-09 13:17:39,662 - INFO - root - 成功加载PDF文件：A Compute&Memory Efficient Model-Driven Neural 5G Receiver for Edge AI-assisted.pdf
2025-11-09 13:17:42,426 - INFO - root - 成功加载PDF文件：AMLA_ MUL by ADD in FlashAttention Rescaling.pdf
2025-11-09 13:17:42,426 - INFO - root - 已达到最大处理数量限制 (2)，停止加载更多PDF文件
2025-11-09 13:17:42,426 - INFO - root - 跳过已处理论文 A Compute&Memory Efficient Model-Driven Neural：./myPapers\A Compute&Memory Efficient Model-Driven Neural 5G Receiver for Edge AI-assisted.pdf
2025-11-09 13:17:42,426 - INFO - root - 跳过已处理论文 AMLA: MUL by ADD in FlashAttention Rescaling：./myPapers\AMLA_ MUL by ADD in FlashAttention Rescaling.pdf
2025-11-09 13:17:42,426 - INFO - root - summary time: 8.42 seconds
2025-11-09 13:19:00,129 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-09 13:19:00,131 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-09 13:19:00,135 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-09 13:19:01,214 - INFO - root - LLMClientManager: 指定使用客户端: Doubao
2025-11-09 13:19:01,214 - INFO - root - DoubaoClient: API key found: 9f9e270e-b...
2025-11-09 13:19:07,220 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 13:19:07,240 - INFO - root - DoubaoClient: initialized successfully with model doubao-seed-1-6-lite-251015
2025-11-09 13:19:07,241 - INFO - root - LLMClientManager: Doubao 客户端初始化成功
2025-11-09 13:19:07,241 - INFO - root - LLMClientManager: switched to Doubao client
2025-11-09 13:19:07,241 - INFO - root - 已手动切换到 LLM 客户端: Doubao
2025-11-09 13:19:07,242 - INFO - root - 使用 LLM 模型: doubao-seed-1-6-lite-251015
2025-11-09 13:19:07,242 - INFO - root - 可用客户端: ['Doubao']
2025-11-09 13:19:07,242 - INFO - root - === 运行配置 ===
2025-11-09 13:19:07,243 - INFO - root - 处理模式: 本地PDF文件
2025-11-09 13:19:07,245 - INFO - root - PDF目录: ./myPapers
2025-11-09 13:19:07,246 - INFO - root - 最大处理数量: 2
2025-11-09 13:19:07,249 - INFO - root - 保存图片: 是
2025-11-09 13:19:07,252 - INFO - root - 输出语言: 中文
2025-11-09 13:19:07,253 - INFO - root - 强制重新处理: 否
2025-11-09 13:19:07,260 - INFO - root - ====================
2025-11-09 13:19:07,263 - INFO - root - 从本地目录读取PDF文件：./myPapers
2025-11-09 13:19:09,141 - INFO - root - 成功加载PDF文件：A Compute&Memory Efficient Model-Driven Neural 5G Receiver for Edge AI-assisted.pdf
2025-11-09 13:19:11,769 - INFO - root - 成功加载PDF文件：AMLA_ MUL by ADD in FlashAttention Rescaling.pdf
2025-11-09 13:19:11,769 - INFO - root - 已达到最大处理数量限制 (2)，停止加载更多PDF文件
2025-11-09 13:19:11,772 - INFO - root - 跳过已处理论文 A Compute&Memory Efficient Model-Driven Neural：./myPapers\A Compute&Memory Efficient Model-Driven Neural 5G Receiver for Edge AI-assisted.pdf
2025-11-09 13:19:11,772 - INFO - root - 跳过已处理论文 AMLA: MUL by ADD in FlashAttention Rescaling：./myPapers\AMLA_ MUL by ADD in FlashAttention Rescaling.pdf
2025-11-09 13:19:11,773 - INFO - root - summary time: 11.65 seconds
2025-11-09 13:21:37,150 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-09 13:21:37,176 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-09 13:21:37,179 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-09 13:21:38,652 - INFO - root - LLMClientManager: 指定使用客户端: Doubao
2025-11-09 13:21:38,653 - INFO - root - DoubaoClient: API key found: 9f9e270e-b...
2025-11-09 13:21:43,494 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 13:21:43,681 - INFO - root - DoubaoClient: initialized successfully with model doubao-seed-1-6-lite-251015
2025-11-09 13:21:43,821 - INFO - root - LLMClientManager: Doubao 客户端初始化成功
2025-11-09 13:21:43,871 - INFO - root - LLMClientManager: switched to Doubao client
2025-11-09 13:21:43,897 - INFO - root - 已手动切换到 LLM 客户端: Doubao
2025-11-09 13:21:43,971 - INFO - root - 使用 LLM 模型: doubao-seed-1-6-lite-251015
2025-11-09 13:21:43,993 - INFO - root - 可用客户端: ['Doubao']
2025-11-09 13:21:44,032 - INFO - root - === 运行配置 ===
2025-11-09 13:21:44,100 - INFO - root - 处理模式: 本地PDF文件
2025-11-09 13:21:44,117 - INFO - root - PDF目录: ./myPapers
2025-11-09 13:21:44,147 - INFO - root - 最大处理数量: 2
2025-11-09 13:21:44,186 - INFO - root - 保存图片: 是
2025-11-09 13:21:44,233 - INFO - root - 输出语言: 中文
2025-11-09 13:21:44,238 - INFO - root - 强制重新处理: 否
2025-11-09 13:21:44,244 - INFO - root - ====================
2025-11-09 13:21:44,250 - INFO - root - 从本地目录读取PDF文件：./myPapers
2025-11-09 13:21:46,096 - INFO - root - 成功加载PDF文件：A Compute&Memory Efficient Model-Driven Neural 5G Receiver for Edge AI-assisted.pdf
2025-11-09 13:21:49,176 - INFO - root - 成功加载PDF文件：AMLA_ MUL by ADD in FlashAttention Rescaling.pdf
2025-11-09 13:21:49,178 - INFO - root - 已达到最大处理数量限制 (2)，停止加载更多PDF文件
2025-11-09 13:21:49,179 - INFO - root - 跳过已处理论文 A Compute&Memory Efficient Model-Driven Neural：./myPapers\A Compute&Memory Efficient Model-Driven Neural 5G Receiver for Edge AI-assisted.pdf
2025-11-09 13:21:49,179 - INFO - root - 跳过已处理论文 AMLA: MUL by ADD in FlashAttention Rescaling：./myPapers\AMLA_ MUL by ADD in FlashAttention Rescaling.pdf
2025-11-09 13:21:49,179 - INFO - root - summary time: 12.03 seconds
2025-11-09 13:22:41,686 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-09 13:22:41,687 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-09 13:22:41,688 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-09 13:22:43,552 - INFO - root - LLMClientManager: 指定使用客户端: Doubao
2025-11-09 13:22:43,552 - INFO - root - DoubaoClient: API key found: 9f9e270e-b...
2025-11-09 13:22:48,878 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 13:22:48,886 - INFO - root - DoubaoClient: initialized successfully with model doubao-seed-1-6-lite-251015
2025-11-09 13:22:48,886 - INFO - root - LLMClientManager: Doubao 客户端初始化成功
2025-11-09 13:22:48,887 - INFO - root - LLMClientManager: switched to Doubao client
2025-11-09 13:22:48,887 - INFO - root - 已手动切换到 LLM 客户端: Doubao
2025-11-09 13:22:48,888 - INFO - root - 使用 LLM 模型: doubao-seed-1-6-lite-251015
2025-11-09 13:22:48,889 - INFO - root - 可用客户端: ['Doubao']
2025-11-09 13:22:48,889 - INFO - root - === 运行配置 ===
2025-11-09 13:22:48,890 - INFO - root - 处理模式: 本地PDF文件
2025-11-09 13:22:48,891 - INFO - root - PDF目录: ./myPapers
2025-11-09 13:22:48,891 - INFO - root - 最大处理数量: 2
2025-11-09 13:22:48,892 - INFO - root - 保存图片: 是
2025-11-09 13:22:48,892 - INFO - root - 输出语言: 中文
2025-11-09 13:22:48,892 - INFO - root - 强制重新处理: 否
2025-11-09 13:22:48,892 - INFO - root - ====================
2025-11-09 13:22:48,894 - INFO - root - 从本地目录读取PDF文件：./myPapers
2025-11-09 13:22:50,256 - INFO - root - 成功加载PDF文件：A Compute&Memory Efficient Model-Driven Neural 5G Receiver for Edge AI-assisted.pdf
2025-11-09 13:22:52,443 - INFO - root - 成功加载PDF文件：AMLA_ MUL by ADD in FlashAttention Rescaling.pdf
2025-11-09 13:22:52,443 - INFO - root - 已达到最大处理数量限制 (2)，停止加载更多PDF文件
2025-11-09 13:22:52,443 - INFO - root - 正在总结论文 1/2: A Compute&Memory Efficient Model-Driven Neural
2025-11-09 13:23:18,467 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 13:24:47,003 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 13:25:29,784 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 13:25:29,788 - INFO - root - 正在提取论文图片...
2025-11-09 13:25:31,327 - INFO - root - 已保存图片 1/10：./export\images_A Compute&Memory Efficient Model-Driven Neural\figure_1_page6.png
2025-11-09 13:25:31,422 - INFO - root - 已保存图片 2/10：./export\images_A Compute&Memory Efficient Model-Driven Neural\figure_2_page6.png
2025-11-09 13:25:31,518 - INFO - root - 已保存图片 3/10：./export\images_A Compute&Memory Efficient Model-Driven Neural\figure_3_page2.png
2025-11-09 13:25:31,575 - INFO - root - 已保存图片 4/10：./export\images_A Compute&Memory Efficient Model-Driven Neural\figure_4_page2.png
2025-11-09 13:25:31,625 - INFO - root - 已保存图片 5/10：./export\images_A Compute&Memory Efficient Model-Driven Neural\figure_5_page3.png
2025-11-09 13:25:31,628 - INFO - root - 成功添加图片 1：./export\images_A Compute&Memory Efficient Model-Driven Neural\figure_1_page6.png
2025-11-09 13:25:31,628 - INFO - root - 成功添加图片 2：./export\images_A Compute&Memory Efficient Model-Driven Neural\figure_2_page6.png
2025-11-09 13:25:31,628 - INFO - root - 成功添加图片 3：./export\images_A Compute&Memory Efficient Model-Driven Neural\figure_3_page2.png
2025-11-09 13:25:31,629 - INFO - root - 成功添加图片 4：./export\images_A Compute&Memory Efficient Model-Driven Neural\figure_4_page2.png
2025-11-09 13:25:31,629 - INFO - root - 成功添加图片 5：./export\images_A Compute&Memory Efficient Model-Driven Neural\figure_5_page3.png
2025-11-09 13:25:31,631 - INFO - root - 论文《A Compute&Memory Efficient Model-Driven Neural》的分析已保存到 ./export\A Compute&Memory Efficient Model-Driven Neural.md
2025-11-09 13:25:31,639 - INFO - root - 跳过已处理论文 AMLA: MUL by ADD in FlashAttention Rescaling：./myPapers\AMLA_ MUL by ADD in FlashAttention Rescaling.pdf
2025-11-09 13:25:31,644 - INFO - root - summary time: 169.96 seconds
2025-11-09 13:41:09,766 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-09 13:41:09,768 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-09 13:41:09,770 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-09 13:41:10,997 - INFO - root - LLMClientManager: 指定使用客户端: Doubao
2025-11-09 13:41:10,998 - INFO - root - DoubaoClient: API key found: 9f9e270e-b...
2025-11-09 13:41:16,132 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 13:41:16,144 - INFO - root - DoubaoClient: initialized successfully with model doubao-seed-1-6-lite-251015
2025-11-09 13:41:16,144 - INFO - root - LLMClientManager: Doubao 客户端初始化成功
2025-11-09 13:41:16,144 - INFO - root - LLMClientManager: switched to Doubao client
2025-11-09 13:41:16,145 - INFO - root - 已手动切换到 LLM 客户端: Doubao
2025-11-09 13:41:16,145 - INFO - root - 使用 LLM 模型: doubao-seed-1-6-lite-251015
2025-11-09 13:41:16,146 - INFO - root - 可用客户端: ['Doubao']
2025-11-09 13:41:16,146 - INFO - root - === 运行配置 ===
2025-11-09 13:41:16,147 - INFO - root - 处理模式: 本地PDF文件
2025-11-09 13:41:16,147 - INFO - root - PDF目录: ./myPapers
2025-11-09 13:41:16,147 - INFO - root - 最大处理数量: 2
2025-11-09 13:41:16,148 - INFO - root - 保存图片: 是
2025-11-09 13:41:16,150 - INFO - root - 输出语言: 中文
2025-11-09 13:41:16,151 - INFO - root - 强制重新处理: 否
2025-11-09 13:41:16,152 - INFO - root - ====================
2025-11-09 13:41:16,153 - INFO - root - 从本地目录读取PDF文件：./myPapers
2025-11-09 13:41:18,769 - INFO - root - 成功加载PDF文件：A Compute&Memory Efficient Model-Driven Neural 5G Receiver for Edge AI-assisted.pdf
2025-11-09 13:41:22,435 - INFO - root - 成功加载PDF文件：AMLA_ MUL by ADD in FlashAttention Rescaling.pdf
2025-11-09 13:41:22,435 - INFO - root - 已达到最大处理数量限制 (2)，停止加载更多PDF文件
2025-11-09 13:41:22,437 - INFO - root - 跳过已处理论文 A Compute&Memory Efficient Model-Driven Neural：./myPapers\A Compute&Memory Efficient Model-Driven Neural 5G Receiver for Edge AI-assisted.pdf
2025-11-09 13:41:22,437 - INFO - root - 跳过已处理论文 AMLA: MUL by ADD in FlashAttention Rescaling：./myPapers\AMLA_ MUL by ADD in FlashAttention Rescaling.pdf
2025-11-09 13:41:22,437 - INFO - root - summary time: 12.67 seconds
2025-11-09 13:42:09,313 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-09 13:42:09,314 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-09 13:42:09,317 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-09 13:42:10,708 - INFO - root - LLMClientManager: 指定使用客户端: Doubao
2025-11-09 13:42:10,709 - INFO - root - DoubaoClient: API key found: 9f9e270e-b...
2025-11-09 13:42:15,602 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 13:42:15,620 - INFO - root - DoubaoClient: initialized successfully with model doubao-seed-1-6-lite-251015
2025-11-09 13:42:15,620 - INFO - root - LLMClientManager: Doubao 客户端初始化成功
2025-11-09 13:42:15,621 - INFO - root - LLMClientManager: switched to Doubao client
2025-11-09 13:42:15,623 - INFO - root - 已手动切换到 LLM 客户端: Doubao
2025-11-09 13:42:15,624 - INFO - root - 使用 LLM 模型: doubao-seed-1-6-lite-251015
2025-11-09 13:42:15,625 - INFO - root - 可用客户端: ['Doubao']
2025-11-09 13:42:15,627 - INFO - root - === 运行配置 ===
2025-11-09 13:42:15,628 - INFO - root - 处理模式: 本地PDF文件
2025-11-09 13:42:15,629 - INFO - root - PDF目录: ./myPapers
2025-11-09 13:42:15,629 - INFO - root - 最大处理数量: 2
2025-11-09 13:42:15,630 - INFO - root - 保存图片: 是
2025-11-09 13:42:15,630 - INFO - root - 输出语言: 中文
2025-11-09 13:42:15,631 - INFO - root - 强制重新处理: 否
2025-11-09 13:42:15,631 - INFO - root - ====================
2025-11-09 13:42:15,631 - INFO - root - 从本地目录读取PDF文件：./myPapers
2025-11-09 13:42:17,181 - INFO - root - 成功加载PDF文件：A Compute&Memory Efficient Model-Driven Neural 5G Receiver for Edge AI-assisted.pdf
2025-11-09 13:42:19,842 - INFO - root - 成功加载PDF文件：AMLA_ MUL by ADD in FlashAttention Rescaling.pdf
2025-11-09 13:42:19,843 - INFO - root - 已达到最大处理数量限制 (2)，停止加载更多PDF文件
2025-11-09 13:42:19,844 - INFO - root - 正在总结论文 1/2: A Compute&Memory Efficient Model-Driven Neural
2025-11-09 13:42:52,518 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 13:44:31,832 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 13:45:09,321 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 13:45:09,322 - INFO - root - 正在提取论文图片...
2025-11-09 13:45:10,094 - INFO - root - 已保存图片 1/10：./export\images_A Compute&Memory Efficient Model-Driven Neural\figure_1_page6.png
2025-11-09 13:45:10,255 - INFO - root - 已保存图片 2/10：./export\images_A Compute&Memory Efficient Model-Driven Neural\figure_2_page6.png
2025-11-09 13:45:10,346 - INFO - root - 已保存图片 3/10：./export\images_A Compute&Memory Efficient Model-Driven Neural\figure_3_page2.png
2025-11-09 13:45:10,394 - INFO - root - 已保存图片 4/10：./export\images_A Compute&Memory Efficient Model-Driven Neural\figure_4_page2.png
2025-11-09 13:45:10,451 - INFO - root - 已保存图片 5/10：./export\images_A Compute&Memory Efficient Model-Driven Neural\figure_5_page3.png
2025-11-09 13:45:10,457 - INFO - root - 成功添加图片 1：./export\images_A Compute&Memory Efficient Model-Driven Neural\figure_1_page6.png
2025-11-09 13:45:10,457 - INFO - root - 成功添加图片 2：./export\images_A Compute&Memory Efficient Model-Driven Neural\figure_2_page6.png
2025-11-09 13:45:10,458 - INFO - root - 成功添加图片 3：./export\images_A Compute&Memory Efficient Model-Driven Neural\figure_3_page2.png
2025-11-09 13:45:10,458 - INFO - root - 成功添加图片 4：./export\images_A Compute&Memory Efficient Model-Driven Neural\figure_4_page2.png
2025-11-09 13:45:10,458 - INFO - root - 成功添加图片 5：./export\images_A Compute&Memory Efficient Model-Driven Neural\figure_5_page3.png
2025-11-09 13:45:10,460 - INFO - root - 论文《A Compute&Memory Efficient Model-Driven Neural》的分析已保存到 ./export\A Compute&Memory Efficient Model-Driven Neural.md
2025-11-09 13:45:10,473 - INFO - root - 跳过已处理论文 AMLA: MUL by ADD in FlashAttention Rescaling：./myPapers\AMLA_ MUL by ADD in FlashAttention Rescaling.pdf
2025-11-09 13:45:10,479 - INFO - root - summary time: 181.17 seconds
2025-11-09 14:04:17,111 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-09 14:04:17,111 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-09 14:04:17,111 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-09 14:04:19,141 - INFO - root - GeminiClient: trying model gemini-2.5-flash
2025-11-09 14:04:20,107 - INFO - root - GeminiClient: trying model gemini-2.5-pro
2025-11-09 14:04:20,489 - WARNING - root - GeminiClient: no usable model found
2025-11-09 14:04:20,491 - WARNING - root - LLMClientManager: Gemini client initialization failed
2025-11-09 14:04:20,492 - WARNING - root - DeepSeekClient: API key not provided. LLM disabled.
2025-11-09 14:04:20,492 - WARNING - root - LLMClientManager: DeepSeek client initialization failed
2025-11-09 14:04:20,493 - WARNING - root - KimiClient: API key not provided. LLM disabled.
2025-11-09 14:04:20,493 - WARNING - root - LLMClientManager: Kimi client initialization failed
2025-11-09 14:04:20,493 - WARNING - root - QwenClient: API key not provided. LLM disabled.
2025-11-09 14:04:20,494 - WARNING - root - LLMClientManager: Qwen client initialization failed
2025-11-09 14:04:20,494 - INFO - root - DoubaoClient: API key found: 9f9e270e-b...
2025-11-09 14:04:26,872 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 14:04:26,893 - INFO - root - DoubaoClient: initialized successfully with model doubao-seed-1-6-lite-251015
2025-11-09 14:04:26,894 - INFO - root - LLMClientManager: Doubao client initialized successfully
2025-11-09 14:04:26,894 - INFO - root - LLMClientManager: using Doubao as default client
2025-11-09 14:04:26,895 - INFO - root - 使用 LLM 模型: doubao-seed-1-6-lite-251015
2025-11-09 14:04:26,896 - INFO - root - 可用客户端: ['Doubao']
2025-11-09 14:04:26,896 - INFO - root - === 运行配置 ===
2025-11-09 14:04:26,896 - INFO - root - 处理模式: 本地PDF文件
2025-11-09 14:04:26,897 - INFO - root - PDF目录: ./myPapers
2025-11-09 14:04:26,897 - INFO - root - 最大处理数量: 2
2025-11-09 14:04:26,897 - INFO - root - 保存图片: 是
2025-11-09 14:04:26,898 - INFO - root - 输出语言: 中文
2025-11-09 14:04:26,898 - INFO - root - 强制重新处理: 否
2025-11-09 14:04:26,899 - INFO - root - ====================
2025-11-09 14:04:26,900 - INFO - root - 从本地目录读取PDF文件：./myPapers
2025-11-09 14:04:28,787 - INFO - root - 成功加载PDF文件：A Compute&Memory Efficient Model-Driven Neural 5G Receiver for Edge AI-assisted.pdf
2025-11-09 14:04:31,792 - INFO - root - 成功加载PDF文件：AMLA_ MUL by ADD in FlashAttention Rescaling.pdf
2025-11-09 14:04:31,794 - INFO - root - 已达到最大处理数量限制 (2)，停止加载更多PDF文件
2025-11-09 14:04:31,795 - INFO - root - 跳过已处理论文 A Compute&Memory Efficient Model-Driven Neural：./myPapers\A Compute&Memory Efficient Model-Driven Neural 5G Receiver for Edge AI-assisted.pdf
2025-11-09 14:04:31,796 - INFO - root - 跳过已处理论文 AMLA: MUL by ADD in FlashAttention Rescaling：./myPapers\AMLA_ MUL by ADD in FlashAttention Rescaling.pdf
2025-11-09 14:04:31,796 - INFO - root - summary time: 14.68 seconds
2025-11-09 14:12:56,035 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-09 14:12:56,035 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-09 14:12:56,049 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-09 14:12:57,528 - INFO - root - GeminiClient: trying model gemini-2.5-flash
2025-11-09 14:12:58,374 - INFO - root - GeminiClient: trying model gemini-2.5-pro
2025-11-09 14:12:58,745 - WARNING - root - GeminiClient: no usable model found
2025-11-09 14:12:58,746 - WARNING - root - LLMClientManager: Gemini client initialization failed
2025-11-09 14:12:58,746 - WARNING - root - DeepSeekClient: API key not provided. LLM disabled.
2025-11-09 14:12:58,746 - WARNING - root - LLMClientManager: DeepSeek client initialization failed
2025-11-09 14:12:58,747 - WARNING - root - KimiClient: API key not provided. LLM disabled.
2025-11-09 14:12:58,748 - WARNING - root - LLMClientManager: Kimi client initialization failed
2025-11-09 14:12:58,748 - WARNING - root - QwenClient: API key not provided. LLM disabled.
2025-11-09 14:12:58,748 - WARNING - root - LLMClientManager: Qwen client initialization failed
2025-11-09 14:12:58,748 - INFO - root - DoubaoClient: API key found: 9f9e270e-b...
2025-11-09 14:13:02,872 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 14:13:02,877 - INFO - root - DoubaoClient: initialized successfully with model doubao-seed-1-6-lite-251015
2025-11-09 14:13:02,877 - INFO - root - LLMClientManager: Doubao client initialized successfully
2025-11-09 14:13:02,877 - INFO - root - LLMClientManager: using Doubao as default client
2025-11-09 14:13:02,885 - INFO - root - 使用 LLM 模型: doubao-seed-1-6-lite-251015
2025-11-09 14:13:02,885 - INFO - root - 可用客户端: ['Doubao']
2025-11-09 14:13:02,886 - INFO - root - === 运行配置 ===
2025-11-09 14:13:02,886 - INFO - root - 处理模式: 本地PDF文件
2025-11-09 14:13:02,887 - INFO - root - PDF目录: ./myPapers
2025-11-09 14:13:02,887 - INFO - root - 最大处理数量: 2
2025-11-09 14:13:02,890 - INFO - root - 保存图片: 是
2025-11-09 14:13:02,890 - INFO - root - 输出语言: 中文
2025-11-09 14:13:02,891 - INFO - root - 强制重新处理: 否
2025-11-09 14:13:02,891 - INFO - root - ====================
2025-11-09 14:13:02,891 - INFO - root - 从本地目录读取PDF文件：./myPapers
2025-11-09 14:13:04,457 - INFO - root - 成功加载PDF文件：A Compute&Memory Efficient Model-Driven Neural 5G Receiver for Edge AI-assisted.pdf
2025-11-09 14:13:06,450 - INFO - root - 成功加载PDF文件：AMLA_ MUL by ADD in FlashAttention Rescaling.pdf
2025-11-09 14:13:06,450 - INFO - root - 已达到最大处理数量限制 (2)，停止加载更多PDF文件
2025-11-09 14:13:06,450 - INFO - root - 跳过已处理论文 A Compute&Memory Efficient Model-Driven Neural：./myPapers\A Compute&Memory Efficient Model-Driven Neural 5G Receiver for Edge AI-assisted.pdf
2025-11-09 14:13:06,450 - INFO - root - 跳过已处理论文 AMLA: MUL by ADD in FlashAttention Rescaling：./myPapers\AMLA_ MUL by ADD in FlashAttention Rescaling.pdf
2025-11-09 14:13:06,450 - INFO - root - summary time: 10.42 seconds
2025-11-09 14:13:27,922 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-09 14:13:27,924 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-09 14:13:27,926 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-09 14:13:29,624 - INFO - root - GeminiClient: trying model gemini-2.5-flash
2025-11-09 14:13:30,568 - INFO - root - GeminiClient: trying model gemini-2.5-pro
2025-11-09 14:13:30,695 - WARNING - root - GeminiClient: no usable model found
2025-11-09 14:13:30,696 - WARNING - root - LLMClientManager: Gemini client initialization failed
2025-11-09 14:13:30,696 - WARNING - root - DeepSeekClient: API key not provided. LLM disabled.
2025-11-09 14:13:30,696 - WARNING - root - LLMClientManager: DeepSeek client initialization failed
2025-11-09 14:13:30,697 - WARNING - root - KimiClient: API key not provided. LLM disabled.
2025-11-09 14:13:30,697 - WARNING - root - LLMClientManager: Kimi client initialization failed
2025-11-09 14:13:30,697 - WARNING - root - QwenClient: API key not provided. LLM disabled.
2025-11-09 14:13:30,697 - WARNING - root - LLMClientManager: Qwen client initialization failed
2025-11-09 14:13:30,698 - INFO - root - DoubaoClient: API key found: 9f9e270e-b...
2025-11-09 14:13:35,993 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 14:13:36,003 - INFO - root - DoubaoClient: initialized successfully with model doubao-seed-1-6-lite-251015
2025-11-09 14:13:36,003 - INFO - root - LLMClientManager: Doubao client initialized successfully
2025-11-09 14:13:36,003 - INFO - root - LLMClientManager: using Doubao as default client
2025-11-09 14:13:36,003 - INFO - root - 使用 LLM 模型: doubao-seed-1-6-lite-251015
2025-11-09 14:13:36,004 - INFO - root - 可用客户端: ['Doubao']
2025-11-09 14:13:36,006 - INFO - root - === 运行配置 ===
2025-11-09 14:13:36,008 - INFO - root - 处理模式: 本地PDF文件
2025-11-09 14:13:36,009 - INFO - root - PDF目录: ./myPapers
2025-11-09 14:13:36,010 - INFO - root - 最大处理数量: 2
2025-11-09 14:13:36,010 - INFO - root - 保存图片: 是
2025-11-09 14:13:36,011 - INFO - root - 输出语言: 中文
2025-11-09 14:13:36,011 - INFO - root - 强制重新处理: 否
2025-11-09 14:13:36,011 - INFO - root - ====================
2025-11-09 14:13:36,011 - INFO - root - 从本地目录读取PDF文件：./myPapers
2025-11-09 14:13:37,419 - INFO - root - 成功加载PDF文件：A Compute&Memory Efficient Model-Driven Neural 5G Receiver for Edge AI-assisted.pdf
2025-11-09 14:13:39,410 - INFO - root - 成功加载PDF文件：AMLA_ MUL by ADD in FlashAttention Rescaling.pdf
2025-11-09 14:13:39,410 - INFO - root - 已达到最大处理数量限制 (2)，停止加载更多PDF文件
2025-11-09 14:13:39,410 - INFO - root - 跳过已处理论文 A Compute&Memory Efficient Model-Driven Neural：./myPapers\A Compute&Memory Efficient Model-Driven Neural 5G Receiver for Edge AI-assisted.pdf
2025-11-09 14:13:39,410 - INFO - root - 跳过已处理论文 AMLA: MUL by ADD in FlashAttention Rescaling：./myPapers\AMLA_ MUL by ADD in FlashAttention Rescaling.pdf
2025-11-09 14:13:39,410 - INFO - root - summary time: 11.49 seconds
2025-11-09 14:14:39,048 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-09 14:14:39,052 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-09 14:14:39,054 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-09 14:14:40,444 - INFO - root - GeminiClient: trying model gemini-2.5-flash
2025-11-09 14:14:41,291 - INFO - root - GeminiClient: trying model gemini-2.5-pro
2025-11-09 14:14:41,648 - WARNING - root - GeminiClient: no usable model found
2025-11-09 14:14:41,648 - WARNING - root - LLMClientManager: Gemini client initialization failed
2025-11-09 14:14:41,648 - WARNING - root - DeepSeekClient: API key not provided. LLM disabled.
2025-11-09 14:14:41,649 - WARNING - root - LLMClientManager: DeepSeek client initialization failed
2025-11-09 14:14:41,649 - WARNING - root - KimiClient: API key not provided. LLM disabled.
2025-11-09 14:14:41,649 - WARNING - root - LLMClientManager: Kimi client initialization failed
2025-11-09 14:14:41,650 - WARNING - root - QwenClient: API key not provided. LLM disabled.
2025-11-09 14:14:41,650 - WARNING - root - LLMClientManager: Qwen client initialization failed
2025-11-09 14:14:41,650 - INFO - root - DoubaoClient: API key found: 9f9e270e-b...
2025-11-09 14:14:46,605 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 14:14:46,616 - INFO - root - DoubaoClient: initialized successfully with model doubao-seed-1-6-lite-251015
2025-11-09 14:14:46,616 - INFO - root - LLMClientManager: Doubao client initialized successfully
2025-11-09 14:14:46,616 - INFO - root - LLMClientManager: using Doubao as default client
2025-11-09 14:14:46,616 - INFO - root - 使用 LLM 模型: doubao-seed-1-6-lite-251015
2025-11-09 14:14:46,616 - INFO - root - 可用客户端: ['Doubao']
2025-11-09 14:14:46,619 - INFO - root - === 运行配置 ===
2025-11-09 14:14:46,619 - INFO - root - 处理模式: 本地PDF文件
2025-11-09 14:14:46,620 - INFO - root - PDF目录: ./myPapers
2025-11-09 14:14:46,620 - INFO - root - 最大处理数量: 2
2025-11-09 14:14:46,620 - INFO - root - 保存图片: 是
2025-11-09 14:14:46,620 - INFO - root - 输出语言: 中文
2025-11-09 14:14:46,621 - INFO - root - 强制重新处理: 否
2025-11-09 14:14:46,622 - INFO - root - ====================
2025-11-09 14:14:46,622 - INFO - root - 从本地目录读取PDF文件：./myPapers
2025-11-09 14:14:47,983 - INFO - root - 成功加载PDF文件：A Compute&Memory Efficient Model-Driven Neural 5G Receiver for Edge AI-assisted.pdf
2025-11-09 14:14:49,898 - INFO - root - 成功加载PDF文件：AMLA_ MUL by ADD in FlashAttention Rescaling.pdf
2025-11-09 14:14:49,898 - INFO - root - 已达到最大处理数量限制 (2)，停止加载更多PDF文件
2025-11-09 14:14:49,898 - INFO - root - 正在总结论文 1/2: A Compute&Memory Efficient Model-Driven Neural
2025-11-09 14:15:32,728 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 14:16:45,454 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 14:17:33,055 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 14:17:33,058 - INFO - root - 正在提取论文图片...
2025-11-09 14:17:33,812 - INFO - root - 已保存图片 1/10：./export\images_A Compute&Memory Efficient Model-Driven Neural\figure_1_page6.png
2025-11-09 14:17:33,915 - INFO - root - 已保存图片 2/10：./export\images_A Compute&Memory Efficient Model-Driven Neural\figure_2_page6.png
2025-11-09 14:17:34,007 - INFO - root - 已保存图片 3/10：./export\images_A Compute&Memory Efficient Model-Driven Neural\figure_3_page2.png
2025-11-09 14:17:34,056 - INFO - root - 已保存图片 4/10：./export\images_A Compute&Memory Efficient Model-Driven Neural\figure_4_page2.png
2025-11-09 14:17:34,127 - INFO - root - 已保存图片 5/10：./export\images_A Compute&Memory Efficient Model-Driven Neural\figure_5_page3.png
2025-11-09 14:17:34,132 - INFO - root - 成功添加图片 1：./export\images_A Compute&Memory Efficient Model-Driven Neural\figure_1_page6.png
2025-11-09 14:17:34,132 - INFO - root - 成功添加图片 2：./export\images_A Compute&Memory Efficient Model-Driven Neural\figure_2_page6.png
2025-11-09 14:17:34,132 - INFO - root - 成功添加图片 3：./export\images_A Compute&Memory Efficient Model-Driven Neural\figure_3_page2.png
2025-11-09 14:17:34,133 - INFO - root - 成功添加图片 4：./export\images_A Compute&Memory Efficient Model-Driven Neural\figure_4_page2.png
2025-11-09 14:17:34,133 - INFO - root - 成功添加图片 5：./export\images_A Compute&Memory Efficient Model-Driven Neural\figure_5_page3.png
2025-11-09 14:17:34,138 - INFO - root - 论文《A Compute&Memory Efficient Model-Driven Neural》的分析已保存到 ./export\A Compute&Memory Efficient Model-Driven Neural.md
2025-11-09 14:17:34,145 - INFO - root - 跳过已处理论文 AMLA: MUL by ADD in FlashAttention Rescaling：./myPapers\AMLA_ MUL by ADD in FlashAttention Rescaling.pdf
2025-11-09 14:17:34,153 - INFO - root - summary time: 175.10 seconds
2025-11-09 16:42:33,744 - INFO - root - Fetching page 1 with URL: https://arxiv.org/search/?query=traffic+flow+prediction&searchtype=all&abstracts=show&order=-announced_date_first&size=50
2025-11-09 16:42:35,196 - INFO - root - get_all_titles_from_web 
2025-11-09 16:42:35,196 - INFO - root - Page:0, Index:0, A Theoretical Framework for Environmental Similarity and Vessel Mobility as Coupled Predictors of Marine Invasive Species Pathways, https://arxiv.org/pdf/2511.03499, 2025-11-06
2025-11-09 16:42:35,196 - INFO - root - Page:0, Index:1, Towards Sub-millisecond Latency and Guaranteed Bit Rates in 5G User Plane, https://arxiv.org/pdf/2511.00196, 2025-10-31
2025-11-09 16:42:35,196 - INFO - root - Page:0, Index:2, A Cloud-Based Spatio-Temporal GNN-Transformer Hybrid Model for Traffic Flow Forecasting with External Feature Integration, https://arxiv.org/pdf/2510.27039, 2025-10-30
2025-11-09 16:42:35,196 - INFO - root - Page:0, Index:3, Research on Expressway Congestion Warning Technology Based on YOLOv11-DIoU and GRU-Attention, https://arxiv.org/pdf/2509.13361, 2025-11-04
2025-11-09 16:42:35,196 - INFO - root - Fetching page 2 with URL: https://arxiv.org/search/?query=traffic+flow+prediction&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=50
2025-11-09 16:42:36,837 - INFO - root - ------------------------------------------------------------------------------------------------------------------------
2025-11-09 16:42:46,124 - INFO - root - Downloaded 3 papers in 12.4s
2025-11-09 16:43:48,497 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-09 16:43:48,502 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-09 16:43:48,502 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-09 16:47:07,981 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-09 16:47:07,981 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-09 16:47:07,985 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-09 16:47:09,033 - INFO - root - LLMClientManager: 指定使用客户端: Deepseek
2025-11-09 16:47:09,034 - INFO - root - DeepSeekClient: API key found: your_deeps...
2025-11-09 16:47:09,034 - WARNING - root - DeepSeekClient: API key not provided or using placeholder. LLM disabled.
2025-11-09 16:47:09,034 - ERROR - root - LLMClientManager: 指定的客户端 DeepSeek 初始化失败
2025-11-09 16:47:09,034 - WARNING - root - LLMClientManager: 指定的客户端 Deepseek 不可用，将尝试其他客户端
2025-11-09 16:51:57,471 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-09 16:51:57,472 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-09 16:51:57,477 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-09 16:51:59,021 - INFO - root - LLMClientManager: 指定使用客户端: Deepseek
2025-11-09 16:51:59,021 - INFO - root - DeepSeekClient: API key found: 9f9e270e-b...
2025-11-09 16:52:01,342 - INFO - httpx - HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 401 Unauthorized"
2025-11-09 16:52:01,345 - ERROR - root - DeepSeekClient: error during initialization: Error code: 401 - {'error': {'message': 'Authentication Fails, Your api key: ****24c9 is invalid', 'type': 'authentication_error', 'param': None, 'code': 'invalid_request_error'}}
2025-11-09 16:52:01,346 - ERROR - root - LLMClientManager: 指定的客户端 DeepSeek 初始化失败
2025-11-09 16:52:01,347 - WARNING - root - LLMClientManager: 指定的客户端 Deepseek 不可用，将尝试其他客户端
2025-11-09 16:53:00,258 - ERROR - root - GeminiClient: error during initialization: Timeout of 60.0s exceeded, last exception: 503 failed to connect to all addresses; last error: UNKNOWN: ipv4:142.250.73.138:443: socket is null
2025-11-09 16:53:00,260 - WARNING - root - LLMClientManager: Gemini client initialization failed
2025-11-09 16:53:00,261 - WARNING - root - KimiClient: API key not provided. LLM disabled.
2025-11-09 16:53:00,261 - WARNING - root - LLMClientManager: Kimi client initialization failed
2025-11-09 16:53:00,261 - WARNING - root - QwenClient: API key not provided. LLM disabled.
2025-11-09 16:53:00,263 - WARNING - root - LLMClientManager: Qwen client initialization failed
2025-11-09 16:53:00,263 - INFO - root - DoubaoClient: API key found: 9f9e270e-b...
2025-11-09 16:53:04,463 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 16:53:04,488 - INFO - root - DoubaoClient: initialized successfully with model doubao-seed-1-6-lite-251015
2025-11-09 16:53:04,489 - INFO - root - LLMClientManager: Doubao client initialized successfully
2025-11-09 16:53:04,491 - INFO - root - LLMClientManager: using Doubao as default client
2025-11-09 16:53:04,492 - WARNING - root - LLMClientManager: client Deepseek not available
2025-11-09 16:53:04,493 - WARNING - root - 无法切换到指定的客户端 Deepseek，将使用默认客户端
2025-11-09 16:53:04,497 - INFO - root - 可用客户端: ['Doubao']
2025-11-09 16:53:04,497 - INFO - root - 使用 LLM 模型: doubao-seed-1-6-lite-251015
2025-11-09 16:53:04,498 - INFO - root - 可用客户端: ['Doubao']
2025-11-09 16:53:04,501 - INFO - root - === 运行配置 ===
2025-11-09 16:53:04,502 - INFO - root - 处理模式: arxiv在线搜索
2025-11-09 16:53:04,503 - INFO - root - 关键词: Quant
2025-11-09 16:53:04,506 - INFO - root - 查询: Quantization-Aware-Training
2025-11-09 16:53:04,507 - INFO - root - 排序: None
2025-11-09 16:53:04,507 - INFO - root - 最近天数: 180
2025-11-09 16:53:04,544 - INFO - root - 最大处理数量: 10
2025-11-09 16:53:04,544 - INFO - root - 保存图片: 是
2025-11-09 16:53:04,546 - INFO - root - 输出语言: 中文
2025-11-09 16:53:04,547 - INFO - root - 强制重新处理: 否
2025-11-09 16:53:04,551 - INFO - root - ====================
2025-11-09 16:53:04,557 - INFO - root - 使用 arXiv 搜索模式（通过 chat_arxiv 模块获取）
2025-11-09 16:53:04,557 - INFO - root - Fetching page 1 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50
2025-11-09 16:53:06,532 - INFO - root - get_all_titles_from_web 
2025-11-09 16:53:06,533 - INFO - root - Page:0, Index:0, A Quantized VAE-MLP Botnet Detection Model: A Systematic Evaluation of Quantization-Aware Training and Post-Training Quantization Strategies, https://arxiv.org/pdf/2511.03201, 2025-11-05
2025-11-09 16:53:06,533 - INFO - root - Page:0, Index:1, FP8-Flow-MoE: A Casting-Free FP8 Recipe without Double Quantization Error, https://arxiv.org/pdf/2511.02302, 2025-11-04
2025-11-09 16:53:06,533 - INFO - root - Page:0, Index:2, Outlier-Aware Post-Training Quantization for Image Super-Resolution, https://arxiv.org/pdf/2511.00682, 2025-11-01
2025-11-09 16:53:06,534 - INFO - root - Page:0, Index:3, Evaluation of Wafer-Scale SOT-MRAM for Analog Crossbar Array Applications, https://arxiv.org/pdf/2510.25853, 2025-11-03
2025-11-09 16:53:06,534 - INFO - root - Page:0, Index:4, Improving the Straight-Through Estimator with Zeroth-Order Information, https://arxiv.org/pdf/2510.23926, 2025-10-27
2025-11-09 16:53:06,534 - INFO - root - Page:0, Index:5, Real-Time Semantic Segmentation on FPGA for Autonomous Vehicles Using LMIINet with the CGRA4ML Framework, https://arxiv.org/pdf/2510.22243, 2025-10-25
2025-11-09 16:53:06,534 - INFO - root - Page:0, Index:6, TernaryCLIP: Efficiently Compressing Vision-Language Models with Ternary Weights and Distilled Knowledge, https://arxiv.org/pdf/2510.21879, 2025-10-23
2025-11-09 16:53:06,535 - INFO - root - Page:0, Index:7, KARIPAP: Quantum-Inspired Tensor Network Compression of Large Language Models Using Infinite Projected Entangled Pair States and Tensor Renormalization Group, https://arxiv.org/pdf/2510.21844, 2025-10-22
2025-11-09 16:53:06,535 - INFO - root - Page:0, Index:8, A Convergence Analysis of Adaptive Optimizers under Floating-point Quantization, https://arxiv.org/pdf/2510.21314, 2025-10-24
2025-11-09 16:53:06,535 - INFO - root - Page:0, Index:9, Adaptive Distribution-aware Quantization for Mixed-Precision Neural Networks, https://arxiv.org/pdf/2510.19760, 2025-10-22
2025-11-09 16:53:06,536 - INFO - root - Page:0, Index:10, CAGE: Curvature-Aware Gradient Estimation For Accurate Quantization-Aware Training, https://arxiv.org/pdf/2510.18784, 2025-10-21
2025-11-09 16:53:06,536 - INFO - root - Page:0, Index:11, Mixed-Precision Quantization for Language Models: Techniques and Prospects, https://arxiv.org/pdf/2510.16805, 2025-10-19
2025-11-09 16:53:06,536 - INFO - root - Page:0, Index:12, SPLite Hand: Sparsity-Aware Lightweight 3D Hand Pose Estimation, https://arxiv.org/pdf/2510.16396, 2025-10-30
2025-11-09 16:53:06,536 - INFO - root - Page:0, Index:13, CTR-LoRA: Curvature-Aware and Trust-Region Guided Low-Rank Adaptation for Large Language Models, https://arxiv.org/pdf/2510.15962, 2025-10-11
2025-11-09 16:53:06,537 - INFO - root - Page:0, Index:14, SANR: Scene-Aware Neural Representation for Light Field Image Compression with Rate-Distortion Optimization, https://arxiv.org/pdf/2510.15775, 2025-10-17
2025-11-09 16:53:06,537 - INFO - root - Page:0, Index:15, SpikeFit: Towards Optimal Deployment of Spiking Networks on Neuromorphic Hardware, https://arxiv.org/pdf/2510.15542, 2025-10-31
2025-11-09 16:53:06,537 - INFO - root - Page:0, Index:16, GRank: Towards Target-Aware and Streamlined Industrial Retrieval with a Generate-Rank Framework, https://arxiv.org/pdf/2510.15299, 2025-10-17
2025-11-09 16:53:06,538 - INFO - root - Page:0, Index:17, SaLon3R: Structure-aware Long-term Generalizable 3D Reconstruction from Unposed Images, https://arxiv.org/pdf/2510.15072, 2025-10-16
2025-11-09 16:53:06,538 - INFO - root - Page:0, Index:18, FraQAT: Quantization Aware Training with Fractional bits, https://arxiv.org/pdf/2510.14823, 2025-10-16
2025-11-09 16:53:06,540 - INFO - root - Page:0, Index:19, Computing-In-Memory Aware Model Adaption For Edge Devices, https://arxiv.org/pdf/2510.14379, 2025-10-16
2025-11-09 16:53:06,540 - INFO - root - Page:0, Index:20, Invited Paper: BitMedViT: Ternary-Quantized Vision Transformer for Medical AI Assistants on the Edge, https://arxiv.org/pdf/2510.13760, 2025-11-04
2025-11-09 16:53:06,540 - INFO - root - Page:0, Index:21, NeuroRVQ: Multi-Scale EEG Tokenization for Generative Large Brainwave Models, https://arxiv.org/pdf/2510.13068, 2025-10-14
2025-11-09 16:53:06,543 - INFO - root - Page:0, Index:22, Detect Anything via Next Point Prediction, https://arxiv.org/pdf/2510.12798, 2025-10-14
2025-11-09 16:53:06,546 - INFO - root - Page:0, Index:23, AndesVL Technical Report: An Efficient Mobile-side Multimodal Large Language Model, https://arxiv.org/pdf/2510.11496, 2025-10-14
2025-11-09 16:53:06,548 - INFO - root - Page:0, Index:24, Rescaling-Aware Training for Efficient Deployment of Deep Learning Models on Full-Integer Hardware, https://arxiv.org/pdf/2510.11484, 2025-10-13
2025-11-09 16:53:06,549 - INFO - root - Page:0, Index:25, SASER: Stego attacks on open-source LLMs, https://arxiv.org/pdf/2510.10486, 2025-10-12
2025-11-09 16:53:06,550 - INFO - root - Page:0, Index:26, Ultralytics YOLO Evolution: An Overview of YOLO26, YOLO11, YOLOv8 and YOLOv5 Object Detectors for Computer Vision and Pattern Recognition, https://arxiv.org/pdf/2510.09653, 2025-10-15
2025-11-09 16:53:06,550 - INFO - root - Page:0, Index:27, A Theoretically-Grounded Codebook for Digital Semantic Communications, https://arxiv.org/pdf/2510.07108, 2025-10-14
2025-11-09 16:53:06,551 - INFO - root - Page:0, Index:28, QuantDemoire: Quantization with Outlier Aware for Image Demoiréing, https://arxiv.org/pdf/2510.04066, 2025-10-05
2025-11-09 16:53:06,552 - INFO - root - Page:0, Index:29, Adaptively Sampling-Reusing-Mixing Decomposed Gradients to Speed Up Sharpness Aware Minimization, https://arxiv.org/pdf/2510.03763, 2025-10-04
2025-11-09 16:53:06,552 - INFO - root - Page:0, Index:30, Quant-dLLM: Post-Training Extreme Low-Bit Quantization for Diffusion Large Language Models, https://arxiv.org/pdf/2510.03274, 2025-09-27
2025-11-09 16:53:06,554 - INFO - root - Page:0, Index:31, PT$^2$-LLM: Post-Training Ternarization for Large Language Models, https://arxiv.org/pdf/2510.03267, 2025-09-26
2025-11-09 16:53:06,554 - INFO - root - Page:0, Index:32, Purrception: Variational Flow Matching for Vector-Quantized Image Generation, https://arxiv.org/pdf/2510.01478, 2025-10-01
2025-11-09 16:53:06,555 - INFO - root - Page:0, Index:33, Post-Training Quantization for Audio Diffusion Transformers, https://arxiv.org/pdf/2510.00313, 2025-09-30
2025-11-09 16:53:06,556 - INFO - root - Page:0, Index:34, Rethinking RoPE Scaling in Quantized LLM: Theory, Outlier, and Channel-Band Analysis with Weight Rescaling, https://arxiv.org/pdf/2510.00028, 2025-09-25
2025-11-09 16:53:06,557 - INFO - root - Page:0, Index:35, Post-Training Quantization via Residual Truncation and Zero Suppression for Diffusion Models, https://arxiv.org/pdf/2509.26436, 2025-09-30
2025-11-09 16:53:06,558 - INFO - root - Page:0, Index:36, Cat: Post-Training Quantization Error Reduction via Cluster-based Affine Transformation, https://arxiv.org/pdf/2509.26277, 2025-10-07
2025-11-09 16:53:06,558 - INFO - root - Page:0, Index:37, CAST: Continuous and Differentiable Semi-Structured Sparsity-Aware Training for Large Language Models, https://arxiv.org/pdf/2509.25996, 2025-09-30
2025-11-09 16:53:06,559 - INFO - root - Page:0, Index:38, Norm-Q: Effective Compression Method for Hidden Markov Models in Neuro-Symbolic Applications, https://arxiv.org/pdf/2509.25439, 2025-09-29
2025-11-09 16:53:06,561 - INFO - root - Page:0, Index:39, On-the-Fly Adaptation to Quantization: Configuration-Aware LoRA for Efficient Fine-Tuning of Quantized LLMs, https://arxiv.org/pdf/2509.25214, 2025-09-22
2025-11-09 16:53:06,566 - INFO - root - Page:0, Index:40, VoxCPM: Tokenizer-Free TTS for Context-Aware Speech Generation and True-to-Life Voice Cloning, https://arxiv.org/pdf/2509.24650, 2025-09-29
2025-11-09 16:53:06,567 - INFO - root - Page:0, Index:41, S$^2$NN: Sub-bit Spiking Neural Networks, https://arxiv.org/pdf/2509.24266, 2025-10-24
2025-11-09 16:53:06,568 - INFO - root - Page:0, Index:42, Tequila: Trapping-free Ternary Quantization for Large Language Models, https://arxiv.org/pdf/2509.23809, 2025-10-17
2025-11-09 16:53:06,568 - INFO - root - Page:0, Index:43, Texture Vector-Quantization and Reconstruction Aware Prediction for Generative Super-Resolution, https://arxiv.org/pdf/2509.23774, 2025-09-30
2025-11-09 16:53:06,568 - INFO - root - Page:0, Index:44, RobuQ: Pushing DiTs to W1.58A2 via Robust Activation Quantization, https://arxiv.org/pdf/2509.23582, 2025-09-27
2025-11-09 16:53:06,568 - INFO - root - Page:0, Index:45, Beyond Outliers: A Study of Optimizers Under Quantization, https://arxiv.org/pdf/2509.23500, 2025-10-02
2025-11-09 16:53:06,569 - INFO - root - Page:0, Index:46, Compute-Optimal Quantization-Aware Training, https://arxiv.org/pdf/2509.22935, 2025-09-26
2025-11-09 16:53:06,569 - INFO - root - Page:0, Index:47, COSPADI: Compressing LLMs via Calibration-Guided Sparse Dictionary Learning, https://arxiv.org/pdf/2509.22075, 2025-10-06
2025-11-09 16:53:06,569 - INFO - root - Page:0, Index:48, SlimDiff: Training-Free, Activation-Guided Hands-free Slimming of Diffusion Models, https://arxiv.org/pdf/2509.21498, 2025-09-25
2025-11-09 16:53:06,571 - INFO - root - Page:0, Index:49, Quantized Visual Geometry Grounded Transformer, https://arxiv.org/pdf/2509.21302, 2025-09-29
2025-11-09 16:53:06,584 - INFO - root - Fetching page 2 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=50
2025-11-09 16:53:08,300 - INFO - root - get_all_titles_from_web 
2025-11-09 16:53:08,300 - INFO - root - Page:1, Index:0, Can Less Precise Be More Reliable? A Systematic Evaluation of Quantization's Impact on CLIP Beyond Accuracy, https://arxiv.org/pdf/2509.21173, 2025-10-27
2025-11-09 16:53:08,300 - INFO - root - Page:1, Index:1, Punching Above Precision: Small Quantized Model Distillation with Learnable Regularizer, https://arxiv.org/pdf/2509.20854, 2025-09-25
2025-11-09 16:53:08,301 - INFO - root - Page:1, Index:2, TinyEcoWeedNet: Edge Efficient Real-Time Aerial Agricultural Weed Detection, https://arxiv.org/pdf/2509.18193, 2025-09-19
2025-11-09 16:53:08,301 - INFO - root - Page:1, Index:3, SBVR: Summation of BitVector Representation for Efficient LLM Quantization, https://arxiv.org/pdf/2509.18172, 2025-09-17
2025-11-09 16:53:08,301 - INFO - root - Page:1, Index:4, QWHA: Quantization-Aware Walsh-Hadamard Adaptation for Parameter-Efficient Fine-Tuning on Large Language Models, https://arxiv.org/pdf/2509.17428, 2025-09-26
2025-11-09 16:53:08,302 - INFO - root - Page:1, Index:5, PTQTP: Post-Training Quantization to Trit-Planes for Large Language Models, https://arxiv.org/pdf/2509.16989, 2025-10-28
2025-11-09 16:53:08,302 - INFO - root - Page:1, Index:6, MEC-Quant: Maximum Entropy Coding for Extremely Low Bit Quantization-Aware Training, https://arxiv.org/pdf/2509.15514, 2025-09-18
2025-11-09 16:53:08,302 - INFO - root - Page:1, Index:7, Q-ROAR: Outlier-Aware Rescaling for RoPE Position Interpolation in Quantized Long-Context LLMs, https://arxiv.org/pdf/2509.14391, 2025-09-17
2025-11-09 16:53:08,303 - INFO - root - Page:1, Index:8, Efficient Quantization-Aware Neural Receivers: Beyond Post-Training Quantization, https://arxiv.org/pdf/2509.13786, 2025-09-19
2025-11-09 16:53:08,303 - INFO - root - Page:1, Index:9, Rate-Distortion Limits for Multimodal Retrieval: Theory, Optimal Codes, and Finite-Sample Guarantees, https://arxiv.org/pdf/2509.11054, 2025-09-13
2025-11-09 16:53:08,303 - INFO - root - Page:1, Index:10, SQAP-VLA: A Synergistic Quantization-Aware Pruning Framework for High-Performance Vision-Language-Action Models, https://arxiv.org/pdf/2509.09090, 2025-09-10
2025-11-09 16:53:08,304 - INFO - root - Page:1, Index:11, CSI Compression Beyond Latents: End-to-End Hybrid Attention-CNN Networks with Entropy Regularization, https://arxiv.org/pdf/2509.08776, 2025-09-10
2025-11-09 16:53:08,304 - INFO - root - Page:1, Index:12, Explaining How Quantization Disparately Skews a Model, https://arxiv.org/pdf/2509.07222, 2025-09-08
2025-11-09 16:53:08,304 - INFO - root - Page:1, Index:13, LoaQ: Layer-wise Output Approximation Quantization, https://arxiv.org/pdf/2509.06297, 2025-09-07
2025-11-09 16:53:08,304 - INFO - root - Page:1, Index:14, FineServe: Precision-Aware KV Slab and Two-Level Scheduling for Heterogeneous Precision LLM Serving, https://arxiv.org/pdf/2509.06261, 2025-09-14
2025-11-09 16:53:08,305 - INFO - root - Page:1, Index:15, Sensitivity-Aware Post-Training Quantization for Deep Neural Networks, https://arxiv.org/pdf/2509.05576, 2025-09-05
2025-11-09 16:53:08,306 - INFO - root - Page:1, Index:16, SuperSNN: A Hardware-Aware Framework for Physically Realizable, High-Performance Superconducting Spiking Neural Network Chips, https://arxiv.org/pdf/2509.05532, 2025-09-05
2025-11-09 16:53:08,306 - INFO - root - Page:1, Index:17, Data-Augmented Quantization-Aware Knowledge Distillation, https://arxiv.org/pdf/2509.03850, 2025-09-03
2025-11-09 16:53:08,308 - INFO - root - Page:1, Index:18, DPQuant: Efficient and Differentially-Private Model Training via Dynamic Quantization Scheduling, https://arxiv.org/pdf/2509.03472, 2025-09-03
2025-11-09 16:53:08,309 - INFO - root - Page:1, Index:19, Empowering Large Language Model for Sequential Recommendation via Multimodal Embeddings and Semantic IDs, https://arxiv.org/pdf/2509.02017, 2025-09-02
2025-11-09 16:53:08,309 - INFO - root - Page:1, Index:20, Q-Sched: Pushing the Boundaries of Few-Step Diffusion Models with Quantization-Aware Scheduling, https://arxiv.org/pdf/2509.01624, 2025-09-01
2025-11-09 16:53:08,310 - INFO - root - Page:1, Index:21, Quantization Meets OOD: Generalizable Quantization-aware Training from a Flatness Perspective, https://arxiv.org/pdf/2509.00859, 2025-08-31
2025-11-09 16:53:08,311 - INFO - root - Page:1, Index:22, Progressive Element-wise Gradient Estimation for Neural Network Quantization, https://arxiv.org/pdf/2509.00097, 2025-08-27
2025-11-09 16:53:08,312 - INFO - root - Page:1, Index:23, End-to-End On-Device Quantization-Aware Training for LLMs at Inference Cost, https://arxiv.org/pdf/2509.00031, 2025-09-29
2025-11-09 16:53:08,318 - INFO - root - Page:1, Index:24, Quantization Robustness to Input Degradations for Object Detection, https://arxiv.org/pdf/2508.19600, 2025-08-27
2025-11-09 16:53:08,322 - INFO - root - Page:1, Index:25, Scaling Laws for Task-Stratified Knowledge in Post-Training Quantized Large Language Models, https://arxiv.org/pdf/2508.18609, 2025-08-27
2025-11-09 16:53:08,323 - INFO - root - Page:1, Index:26, AQ-PCDSys: An Adaptive Quantized Planetary Crater Detection System for Autonomous Space Exploration, https://arxiv.org/pdf/2508.18025, 2025-08-25
2025-11-09 16:53:08,323 - INFO - root - Page:1, Index:27, TaDiCodec: Text-aware Diffusion Speech Tokenizer for Speech Language Modeling, https://arxiv.org/pdf/2508.16790, 2025-08-22
2025-11-09 16:53:08,323 - INFO - root - Page:1, Index:28, A Node-Aware Dynamic Quantization Approach for Graph Collaborative Filtering, https://arxiv.org/pdf/2508.16516, 2025-08-22
2025-11-09 16:53:08,325 - INFO - root - Page:1, Index:29, JEDI-linear: Fast and Efficient Graph Neural Networks for Jet Tagging on FPGAs, https://arxiv.org/pdf/2508.15468, 2025-08-21
2025-11-09 16:53:08,325 - INFO - root - Page:1, Index:30, MMQ: Multimodal Mixture-of-Quantization Tokenization for Semantic ID Generation and User Behavioral Adaptation, https://arxiv.org/pdf/2508.15281, 2025-08-21
2025-11-09 16:53:08,325 - INFO - root - Page:1, Index:31, DLLMQuant: Quantizing Diffusion-based Large Language Models, https://arxiv.org/pdf/2508.14090, 2025-08-25
2025-11-09 16:53:08,326 - INFO - root - Page:1, Index:32, Automated Energy-Aware Time-Series Model Deployment on Embedded FPGAs for Resilient Combined Sewer Overflow Management, https://arxiv.org/pdf/2508.13905, 2025-08-19
2025-11-09 16:53:08,333 - INFO - root - Page:1, Index:33, XR-NPE: High-Throughput Mixed-precision SIMD Neural Processing Engine for Extended Reality Perception Workloads, https://arxiv.org/pdf/2508.13049, 2025-08-18
2025-11-09 16:53:08,334 - INFO - root - Page:1, Index:34, Exploring Self-Supervised Audio Models for Generalized Anomalous Sound Detection, https://arxiv.org/pdf/2508.12230, 2025-08-17
2025-11-09 16:53:08,336 - INFO - root - Page:1, Index:35, TriQDef: Disrupting Semantic and Gradient Alignment to Prevent Adversarial Patch Transferability in Quantized Neural Networks, https://arxiv.org/pdf/2508.12132, 2025-08-16
2025-11-09 16:53:08,336 - INFO - root - Page:1, Index:36, Error Propagation Mechanisms and Compensation Strategies for Quantized Diffusion, https://arxiv.org/pdf/2508.12094, 2025-10-13
2025-11-09 16:53:08,338 - INFO - root - Page:1, Index:37, Extending Straight-Through Estimation for Robust Neural Networks on Analog CIM Hardware, https://arxiv.org/pdf/2508.11940, 2025-08-16
2025-11-09 16:53:08,339 - INFO - root - Page:1, Index:38, PTQAT: A Hybrid Parameter-Efficient Quantization Algorithm for 3D Perception Tasks, https://arxiv.org/pdf/2508.10557, 2025-08-15
2025-11-09 16:53:08,356 - INFO - root - Page:1, Index:39, MiCo: End-to-End Mixed Precision Neural Network Co-Exploration Framework for Edge AI, https://arxiv.org/pdf/2508.09500, 2025-08-13
2025-11-09 16:53:08,356 - INFO - root - Page:1, Index:40, SPARC: Soft Probabilistic Adaptive multi-interest Retrieval Model via Codebooks for recommender system, https://arxiv.org/pdf/2508.09090, 2025-08-12
2025-11-09 16:53:08,357 - INFO - root - Page:1, Index:41, Rethinking 1-bit Optimization Leveraging Pre-trained Large Language Models, https://arxiv.org/pdf/2508.06974, 2025-08-09
2025-11-09 16:53:08,357 - INFO - root - Page:1, Index:42, Efficient Deep Neural Receiver with Post-Training Quantization, https://arxiv.org/pdf/2508.06275, 2025-08-08
2025-11-09 16:53:08,357 - INFO - root - Page:1, Index:43, iFairy: the First 2-bit Complex LLM with All Parameters in $\{\pm1, \pm i\}$, https://arxiv.org/pdf/2508.05571, 2025-08-16
2025-11-09 16:53:08,358 - INFO - root - Page:1, Index:44, S$^2$Q-VDiT: Accurate Quantized Video Diffusion Transformer with Salient Data and Sparse Token Distillation, https://arxiv.org/pdf/2508.04016, 2025-10-27
2025-11-09 16:53:08,360 - INFO - root - Page:1, Index:45, LRQ-DiT: Log-Rotation Post-Training Quantization of Diffusion Transformers for Image and Video Generation, https://arxiv.org/pdf/2508.03485, 2025-09-23
2025-11-09 16:53:08,361 - INFO - root - Page:1, Index:46, VLMQ: Efficient Post-Training Quantization for Large Vision-Language Models via Hessian Augmentation, https://arxiv.org/pdf/2508.03351, 2025-08-05
2025-11-09 16:53:08,361 - INFO - root - Page:1, Index:47, TF-MLPNet: Tiny Real-Time Neural Speech Separation, https://arxiv.org/pdf/2508.03047, 2025-08-04
2025-11-09 16:53:08,361 - INFO - root - Page:1, Index:48, SaviorRec: Semantic-Behavior Alignment for Cold-Start Recommendation, https://arxiv.org/pdf/2508.01375, 2025-08-02
2025-11-09 16:53:08,363 - INFO - root - Page:1, Index:49, MixA-Q: Revisiting Activation Sparsity for Vision Transformers from a Mixed-Precision Quantization Perspective, https://arxiv.org/pdf/2507.19131, 2025-07-25
2025-11-09 16:53:08,363 - INFO - root - Fetching page 3 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=100
2025-11-09 16:53:10,328 - INFO - root - get_all_titles_from_web 
2025-11-09 16:53:10,329 - INFO - root - Page:2, Index:0, Enhancing Quantization-Aware Training on Edge Devices via Relative Entropy Coreset Selection and Cascaded Layer Correction, https://arxiv.org/pdf/2507.17768, 2025-07-16
2025-11-09 16:53:10,329 - INFO - root - Page:2, Index:1, SiLQ: Simple Large Language Model Quantization-Aware Training, https://arxiv.org/pdf/2507.16933, 2025-07-22
2025-11-09 16:53:10,330 - INFO - root - Page:2, Index:2, Task-Specific Zero-shot Quantization-Aware Training for Object Detection, https://arxiv.org/pdf/2507.16782, 2025-07-22
2025-11-09 16:53:10,330 - INFO - root - Page:2, Index:3, TorchAO: PyTorch-Native Training-to-Serving Model Optimization, https://arxiv.org/pdf/2507.16099, 2025-07-21
2025-11-09 16:53:10,331 - INFO - root - Page:2, Index:4, SegQuant: A Semantics-Aware and Generalizable Quantization Framework for Diffusion Models, https://arxiv.org/pdf/2507.14811, 2025-08-27
2025-11-09 16:53:10,332 - INFO - root - Page:2, Index:5, Apple Intelligence Foundation Language Models: Tech Report 2025, https://arxiv.org/pdf/2507.13575, 2025-08-27
2025-11-09 16:53:10,333 - INFO - root - Page:2, Index:6, Generative Multi-Target Cross-Domain Recommendation, https://arxiv.org/pdf/2507.12871, 2025-08-07
2025-11-09 16:53:10,334 - INFO - root - Page:2, Index:7, DAF: An Efficient End-to-End Dynamic Activation Framework for on-Device DNN Training, https://arxiv.org/pdf/2507.07149, 2025-07-09
2025-11-09 16:53:10,335 - INFO - root - Page:2, Index:8, Opto-ViT: Architecting a Near-Sensor Region of Interest-Aware Vision Transformer Accelerator with Silicon Photonics, https://arxiv.org/pdf/2507.07044, 2025-07-15
2025-11-09 16:53:10,336 - INFO - root - Page:2, Index:9, QS4D: Quantization-aware training for efficient hardware deployment of structured state-space sequential models, https://arxiv.org/pdf/2507.06079, 2025-07-08
2025-11-09 16:53:10,336 - INFO - root - Page:2, Index:10, GSVR: 2D Gaussian-based Video Representation for 800+ FPS with Hybrid Deformation Field, https://arxiv.org/pdf/2507.05594, 2025-07-07
2025-11-09 16:53:10,340 - INFO - root - Page:2, Index:11, Hita: Holistic Tokenizer for Autoregressive Image Generation, https://arxiv.org/pdf/2507.02358, 2025-07-11
2025-11-09 16:53:10,341 - INFO - root - Page:2, Index:12, QPART: Adaptive Model Quantization and Dynamic Workload Balancing for Accuracy-aware Edge Inference, https://arxiv.org/pdf/2506.23934, 2025-06-30
2025-11-09 16:53:10,342 - INFO - root - Page:2, Index:13, FedWSQ: Efficient Federated Learning with Weight Standardization and Distribution-Aware Non-Uniform Quantization, https://arxiv.org/pdf/2506.23516, 2025-07-21
2025-11-09 16:53:10,347 - INFO - root - Page:2, Index:14, Spectra 1.1: Scaling Laws and Efficient Inference for Ternary Language Models, https://arxiv.org/pdf/2506.23025, 2025-06-28
2025-11-09 16:53:10,349 - INFO - root - Page:2, Index:15, Joint Quantization and Pruning Neural Networks Approach: A Case Study on FSO Receivers, https://arxiv.org/pdf/2506.20084, 2025-06-24
2025-11-09 16:53:10,374 - INFO - root - Page:2, Index:16, Single-step Diffusion for Image Compression at Ultra-Low Bitrates, https://arxiv.org/pdf/2506.16572, 2025-09-22
2025-11-09 16:53:10,389 - INFO - root - Page:2, Index:17, LittleBit: Ultra Low-Bit Quantization via Latent Factorization, https://arxiv.org/pdf/2506.13771, 2025-10-28
2025-11-09 16:53:10,394 - INFO - root - Page:2, Index:18, MARCO: Hardware-Aware Neural Architecture Search for Edge Devices with Multi-Agent Reinforcement Learning and Conformal Prediction Filtering, https://arxiv.org/pdf/2506.13755, 2025-06-16
2025-11-09 16:53:10,396 - INFO - root - Page:2, Index:19, EAQuant: Enhancing Post-Training Quantization for MoE Models via Expert-Aware Optimization, https://arxiv.org/pdf/2506.13329, 2025-07-04
2025-11-09 16:53:10,397 - INFO - root - Page:2, Index:20, Towards Neural Audio Codec Source Parsing, https://arxiv.org/pdf/2506.12627, 2025-06-14
2025-11-09 16:53:10,397 - INFO - root - Page:2, Index:21, Quantizing Small-Scale State-Space Models for Edge AI, https://arxiv.org/pdf/2506.12480, 2025-06-14
2025-11-09 16:53:10,398 - INFO - root - Page:2, Index:22, EMLoC: Emulator-based Memory-efficient Fine-tuning with LoRA Correction, https://arxiv.org/pdf/2506.12015, 2025-06-13
2025-11-09 16:53:10,399 - INFO - root - Page:2, Index:23, Compression Aware Certified Training, https://arxiv.org/pdf/2506.11992, 2025-06-13
2025-11-09 16:53:10,404 - INFO - root - Page:2, Index:24, GPLQ: A General, Practical, and Lightning QAT Method for Vision Transformers, https://arxiv.org/pdf/2506.11784, 2025-06-13
2025-11-09 16:53:10,414 - INFO - root - Page:2, Index:25, TruncQuant: Truncation-Ready Quantization for DNNs with Flexible Weight Bit Precision, https://arxiv.org/pdf/2506.11431, 2025-06-12
2025-11-09 16:53:10,415 - INFO - root - Page:2, Index:26, EfficientQuant: An Efficient Post-Training Quantization for CNN-Transformer Hybrid Models on Edge Devices, https://arxiv.org/pdf/2506.11093, 2025-06-05
2025-11-09 16:53:10,415 - INFO - root - Page:2, Index:27, Starting Positions Matter: A Study on Better Weight Initialization for Neural Network Quantization, https://arxiv.org/pdf/2506.10463, 2025-06-12
2025-11-09 16:53:10,419 - INFO - root - Page:2, Index:28, AWP: Activation-Aware Weight Pruning and Quantization with Projected Gradient Descent, https://arxiv.org/pdf/2506.10205, 2025-06-11
2025-11-09 16:53:10,420 - INFO - root - Page:2, Index:29, Q-SAM2: Accurate Quantization for Segment Anything Model 2, https://arxiv.org/pdf/2506.09782, 2025-06-11
2025-11-09 16:53:10,421 - INFO - root - Page:2, Index:30, Unifying Block-wise PTQ and Distillation-based QAT for Progressive Quantization toward 2-bit Instruction-Tuned LLMs, https://arxiv.org/pdf/2506.09104, 2025-06-10
2025-11-09 16:53:10,422 - INFO - root - Page:2, Index:31, Implementing Keyword Spotting on the MCUX947 Microcontroller with Integrated NPU, https://arxiv.org/pdf/2506.08911, 2025-06-10
2025-11-09 16:53:10,422 - INFO - root - Page:2, Index:32, POLARON: Precision-aware On-device Learning and Adaptive Runtime-cONfigurable AI acceleration, https://arxiv.org/pdf/2506.08785, 2025-06-10
2025-11-09 16:53:10,424 - INFO - root - Page:2, Index:33, MoQAE: Mixed-Precision Quantization for Long-Context LLM Inference via Mixture of Quantization-Aware Experts, https://arxiv.org/pdf/2506.07533, 2025-06-09
2025-11-09 16:53:10,425 - INFO - root - Page:2, Index:34, BitVLA: 1-bit Vision-Language-Action Models for Robotics Manipulation, https://arxiv.org/pdf/2506.07530, 2025-06-09
2025-11-09 16:53:10,425 - INFO - root - Page:2, Index:35, RecGPT: A Foundation Model for Sequential Recommendation, https://arxiv.org/pdf/2506.06270, 2025-06-12
2025-11-09 16:53:10,428 - INFO - root - Page:2, Index:36, FPSAttention: Training-Aware FP8 and Sparsity Co-Design for Fast Video Diffusion, https://arxiv.org/pdf/2506.04648, 2025-06-05
2025-11-09 16:53:10,429 - INFO - root - Page:2, Index:37, BitTTS: Highly Compact Text-to-Speech Using 1.58-bit Quantization and Weight Indexing, https://arxiv.org/pdf/2506.03515, 2025-06-03
2025-11-09 16:53:10,438 - INFO - root - Page:2, Index:38, ShapeLLM-Omni: A Native Multimodal LLM for 3D Generation and Understanding, https://arxiv.org/pdf/2506.01853, 2025-06-02
2025-11-09 16:53:10,440 - INFO - root - Page:2, Index:39, Movable Antenna Enhanced Federated Fine-Tuning of Large Language Models via Hybrid Client Selection Optimization, https://arxiv.org/pdf/2506.00011, 2025-10-26
2025-11-09 16:53:10,441 - INFO - root - Page:2, Index:40, Running Conventional Automatic Speech Recognition on Memristor Hardware: A Simulated Approach, https://arxiv.org/pdf/2505.24721, 2025-05-30
2025-11-09 16:53:10,441 - INFO - root - Page:2, Index:41, GARLIC: GAussian Representation LearnIng for spaCe partitioning, https://arxiv.org/pdf/2505.24608, 2025-10-02
2025-11-09 16:53:10,442 - INFO - root - Page:2, Index:42, AutoChemSchematic AI: Agentic Physics-Aware Automation for Chemical Manufacturing Scale-Up, https://arxiv.org/pdf/2505.24584, 2025-08-18
2025-11-09 16:53:10,446 - INFO - root - Page:2, Index:43, Model-Preserving Adaptive Rounding, https://arxiv.org/pdf/2505.22988, 2025-09-25
2025-11-09 16:53:10,452 - INFO - root - Page:2, Index:44, Highly Efficient and Effective LLMs with Multi-Boolean Architectures, https://arxiv.org/pdf/2505.22811, 2025-10-03
2025-11-09 16:53:10,458 - INFO - root - Page:2, Index:45, Pioneering 4-Bit FP Quantization for Diffusion Models: Mixup-Sign Quantization and Timestep-Aware Fine-Tuning, https://arxiv.org/pdf/2505.21591, 2025-05-27
2025-11-09 16:53:10,460 - INFO - root - Page:2, Index:46, Frequency Composition for Compressed and Domain-Adaptive Neural Networks, https://arxiv.org/pdf/2505.20890, 2025-05-27
2025-11-09 16:53:10,475 - INFO - root - Page:2, Index:47, MoPFormer: Motion-Primitive Transformer for Wearable-Sensor Activity Recognition, https://arxiv.org/pdf/2505.20744, 2025-10-27
2025-11-09 16:53:10,476 - INFO - root - Page:2, Index:48, Optimizing edge AI models on HPC systems with the edge in the loop, https://arxiv.org/pdf/2505.19995, 2025-05-26
2025-11-09 16:53:10,480 - INFO - root - Fetching page 4 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=150
2025-11-09 16:53:12,568 - INFO - root - get_all_titles_from_web 
2025-11-09 16:53:12,569 - INFO - root - Page:3, Index:0, DPASyn: Mechanism-Aware Drug Synergy Prediction via Dual Attention and Precision-Aware Quantization, https://arxiv.org/pdf/2505.19144, 2025-09-20
2025-11-09 16:53:12,569 - INFO - root - Page:3, Index:1, Reducing Storage of Pretrained Neural Networks by Rate-Constrained Quantization and Entropy Coding, https://arxiv.org/pdf/2505.18758, 2025-05-24
2025-11-09 16:53:12,570 - INFO - root - Page:3, Index:2, Beyond Discreteness: Finite-Sample Analysis of Straight-Through Estimator for Quantization, https://arxiv.org/pdf/2505.18113, 2025-05-23
2025-11-09 16:53:12,570 - INFO - root - Page:3, Index:3, Automating Versatile Time-Series Analysis with Tiny Transformers on Embedded FPGAs, https://arxiv.org/pdf/2505.17662, 2025-09-19
2025-11-09 16:53:12,571 - INFO - root - Page:3, Index:4, FPQVAR: Floating Point Quantization for Visual Autoregressive Model with FPGA Hardware Co-design, https://arxiv.org/pdf/2505.16335, 2025-05-22
2025-11-09 16:53:12,573 - INFO - root - Page:3, Index:5, Saliency-Aware Quantized Imitation Learning for Efficient Robotic Control, https://arxiv.org/pdf/2505.15304, 2025-05-30
2025-11-09 16:53:12,575 - INFO - root - Page:3, Index:6, Scaling Law for Quantization-Aware Training, https://arxiv.org/pdf/2505.14302, 2025-05-20
2025-11-09 16:53:12,579 - INFO - root - Page:3, Index:7, Automatic mixed precision for optimizing gained time with constrained loss mean-squared-error based on model partition to sequential sub-graphs, https://arxiv.org/pdf/2505.13060, 2025-05-19
2025-11-09 16:53:12,580 - INFO - root - Page:3, Index:8, Deep Unfolding with Kernel-based Quantization in MIMO Detection, https://arxiv.org/pdf/2505.12736, 2025-05-19
2025-11-09 16:53:12,580 - INFO - root - Page:3, Index:9, FedHQ: Hybrid Runtime Quantization for Federated Learning, https://arxiv.org/pdf/2505.11982, 2025-05-17
2025-11-09 16:53:12,581 - INFO - root - Page:3, Index:10, QVGen: Pushing the Limit of Quantized Video Generative Models, https://arxiv.org/pdf/2505.11497, 2025-09-27
2025-11-09 16:53:12,582 - INFO - root - Page:3, Index:11, EA-3DGS: Efficient and Adaptive 3D Gaussians with Highly Enhanced Quality for outdoor scenes, https://arxiv.org/pdf/2505.10787, 2025-05-15
2025-11-09 16:53:12,583 - INFO - root - Page:3, Index:12, ITERA-LLM: Boosting Sub-8-Bit Large Language Model Inference via Iterative Tensor Decomposition, https://arxiv.org/pdf/2505.08981, 2025-05-13
2025-11-09 16:53:12,595 - INFO - root - Page:3, Index:13, PROM: Prioritize Reduction of Multiplications Over Lower Bit-Widths for Efficient CNNs, https://arxiv.org/pdf/2505.03254, 2025-08-06
2025-11-09 16:53:12,599 - INFO - root - Page:3, Index:14, ICQuant: Index Coding enables Low-bit LLM Quantization, https://arxiv.org/pdf/2505.00850, 2025-08-24
2025-11-09 16:53:12,606 - INFO - root - Page:3, Index:15, Enhancing Ultra-Low-Bit Quantization of Large Language Models Through Saliency-Aware Partial Retraining, https://arxiv.org/pdf/2504.13932, 2025-07-30
2025-11-09 16:53:12,609 - INFO - root - Page:3, Index:16, Achieving binary weight and activation for LLMs using Post-Training Quantization, https://arxiv.org/pdf/2504.05352, 2025-06-30
2025-11-09 16:53:12,610 - INFO - root - Page:3, Index:17, Wireless Hearables With Programmable Speech AI Accelerators, https://arxiv.org/pdf/2503.18698, 2025-10-21
2025-11-09 16:53:12,611 - INFO - root - Page:3, Index:18, GranQ: Efficient Channel-wise Quantization via Vectorized Pre-Scaling for Zero-Shot QAT, https://arxiv.org/pdf/2503.18339, 2025-10-15
2025-11-09 16:53:12,611 - INFO - root - Page:3, Index:19, CompMarkGS: Robust Watermarking for Compressed 3D Gaussian Splatting, https://arxiv.org/pdf/2503.12836, 2025-09-29
2025-11-09 16:53:12,612 - INFO - root - Page:3, Index:20, AHCPTQ: Accurate and Hardware-Compatible Post-Training Quantization for Segment Anything Model, https://arxiv.org/pdf/2503.03088, 2025-07-11
2025-11-09 16:53:12,612 - INFO - root - Page:3, Index:21, Teaching Metric Distance to Discrete Autoregressive Language Models, https://arxiv.org/pdf/2503.02379, 2025-10-07
2025-11-09 16:53:12,615 - INFO - root - Page:3, Index:22, Regularization-based Framework for Quantization-, Fault- and Variability-Aware Training, https://arxiv.org/pdf/2503.01297, 2025-07-12
2025-11-09 16:53:12,616 - INFO - root - Fetching page 5 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=200
2025-11-09 16:53:14,317 - INFO - root - get_all_titles_from_web 
2025-11-09 16:53:14,317 - INFO - root - Page:4, Index:0, Investigating the Impact of Quantization Methods on the Safety and Reliability of Large Language Models, https://arxiv.org/pdf/2502.15799, 2025-06-29
2025-11-09 16:53:14,318 - INFO - root - Page:4, Index:1, Rotate, Clip, and Partition: Towards W2A4KV4 Quantization by Integrating Rotation and Learnable Non-uniform Quantizer, https://arxiv.org/pdf/2502.15779, 2025-09-01
2025-11-09 16:53:14,318 - INFO - root - Page:4, Index:2, RoSTE: An Efficient Quantization-Aware Supervised Fine-Tuning Approach for Large Language Models, https://arxiv.org/pdf/2502.09003, 2025-06-05
2025-11-09 16:53:14,318 - INFO - root - Page:4, Index:3, Spatial Degradation-Aware and Temporal Consistent Diffusion Model for Compressed Video Super-Resolution, https://arxiv.org/pdf/2502.07381, 2025-06-27
2025-11-09 16:53:14,319 - INFO - root - Page:4, Index:4, QuEST: Stable Training of LLMs with 1-Bit Weights and Activations, https://arxiv.org/pdf/2502.05003, 2025-06-10
2025-11-09 16:53:14,319 - INFO - root - Page:4, Index:5, HALO: Hadamard-Assisted Lower-Precision Optimization for LLMs, https://arxiv.org/pdf/2501.02625, 2025-11-05
2025-11-09 16:53:14,320 - INFO - root - Page:4, Index:6, TAR3D: Creating High-Quality 3D Assets via Next-Part Prediction, https://arxiv.org/pdf/2412.16919, 2025-08-08
2025-11-09 16:53:14,321 - INFO - root - Page:4, Index:7, Training Multi-Layer Binary Neural Networks With Local Binary Error Signals, https://arxiv.org/pdf/2412.00119, 2025-08-05
2025-11-09 16:53:14,321 - INFO - root - Page:4, Index:8, Scaling Large-scale GNN Training to Thousands of Processors on CPU-based Supercomputers, https://arxiv.org/pdf/2411.16025, 2025-05-26
2025-11-09 16:53:14,321 - INFO - root - Page:4, Index:9, HAFLQ: Heterogeneous Adaptive Federated LoRA Fine-tuned LLM with Quantization, https://arxiv.org/pdf/2411.06581, 2025-05-16
2025-11-09 16:53:14,322 - INFO - root - Fetching page 6 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=250
2025-11-09 16:53:16,346 - INFO - root - get_all_titles_from_web 
2025-11-09 16:53:16,346 - INFO - root - Page:5, Index:0, Gradient-Free Training of Quantized Neural Networks, https://arxiv.org/pdf/2410.09734, 2025-09-29
2025-11-09 16:53:16,347 - INFO - root - Page:5, Index:1, QT-DoG: Quantization-aware Training for Domain Generalization, https://arxiv.org/pdf/2410.06020, 2025-06-26
2025-11-09 16:53:16,347 - INFO - root - Page:5, Index:2, Constraint Guided Model Quantization of Neural Networks, https://arxiv.org/pdf/2409.20138, 2025-09-12
2025-11-09 16:53:16,347 - INFO - root - Page:5, Index:3, Accumulator-Aware Post-Training Quantization for Large Language Models, https://arxiv.org/pdf/2409.17092, 2025-07-30
2025-11-09 16:53:16,348 - INFO - root - Page:5, Index:4, DilateQuant: Accurate and Efficient Diffusion Quantization via Weight Dilation, https://arxiv.org/pdf/2409.14307, 2025-07-09
2025-11-09 16:53:16,348 - INFO - root - Page:5, Index:5, Robust Training of Neural Networks at Arbitrary Precision and Sparsity, https://arxiv.org/pdf/2409.09245, 2025-09-23
2025-11-09 16:53:16,348 - INFO - root - Page:5, Index:6, VQ-CTAP: Cross-Modal Fine-Grained Sequence Representation Learning for Speech Processing, https://arxiv.org/pdf/2408.05758, 2025-05-27
2025-11-09 16:53:16,349 - INFO - root - Page:5, Index:7, DopQ-ViT: Towards Distribution-Friendly and Outlier-Aware Post-Training Quantization for Vision Transformers, https://arxiv.org/pdf/2408.03291, 2025-06-19
2025-11-09 16:53:16,349 - INFO - root - Page:5, Index:8, Temporal Feature Matters: A Framework for Diffusion Model Quantization, https://arxiv.org/pdf/2407.19547, 2025-07-11
2025-11-09 16:53:16,349 - INFO - root - Page:5, Index:9, EfficientQAT: Efficient Quantization-Aware Training for Large Language Models, https://arxiv.org/pdf/2407.11062, 2025-05-19
2025-11-09 16:53:16,350 - INFO - root - Page:5, Index:10, Integer-only Quantized Transformers for Embedded FPGA-based Time-series Forecasting in AIoT, https://arxiv.org/pdf/2407.11041, 2025-10-31
2025-11-09 16:53:16,350 - INFO - root - Fetching page 7 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=300
2025-11-09 16:53:18,928 - INFO - root - get_all_titles_from_web 
2025-11-09 16:53:18,929 - INFO - root - Page:6, Index:0, BoA: Attention-aware Post-training Quantization without Backpropagation, https://arxiv.org/pdf/2406.13474, 2025-06-06
2025-11-09 16:53:18,929 - INFO - root - Page:6, Index:1, A Rescaling-Invariant Lipschitz Bound Based on Path-Metrics for Modern ReLU Network Parameterizations, https://arxiv.org/pdf/2405.15006, 2025-06-13
2025-11-09 16:53:18,930 - INFO - root - Page:6, Index:2, Scheduling Weight Transitions for Quantization-Aware Training, https://arxiv.org/pdf/2404.19248, 2025-10-01
2025-11-09 16:53:18,930 - INFO - root - Page:6, Index:3, GPTVQ: The Blessing of Dimensionality for LLM Quantization, https://arxiv.org/pdf/2402.15319, 2025-06-03
2025-11-09 16:53:18,930 - INFO - root - Fetching page 8 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=350
2025-11-09 16:53:21,281 - INFO - root - get_all_titles_from_web 
2025-11-09 16:53:21,281 - INFO - root - Page:7, Index:0, Squat: Quant Small Language Models on the Edge, https://arxiv.org/pdf/2402.10787, 2025-07-01
2025-11-09 16:53:21,281 - INFO - root - Page:7, Index:1, L4Q: Parameter Efficient Quantization-Aware Fine-Tuning on Large Language Models, https://arxiv.org/pdf/2402.04902, 2025-07-21
2025-11-09 16:53:21,282 - INFO - root - Fetching page 9 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=400
2025-11-09 16:53:23,427 - INFO - root - ------------------------------------------------------------------------------------------------------------------------
2025-11-09 16:53:50,568 - INFO - root - 正在总结论文 1/10: A Quantized VAE-MLP Botnet Detection Model: A Systematic Evaluation of Quantization-Aware Training and Post-Training Quantization Strategies
2025-11-09 16:54:10,990 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 16:55:27,773 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 16:56:14,124 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 16:56:14,128 - INFO - root - 正在提取论文图片...
2025-11-09 16:56:18,215 - INFO - root - 已保存图片 1/10：./export\images_A Quantized VAE-MLP Botnet Detection Model_ A Systematic Evaluation of Quantizat\figure_1_page4.png
2025-11-09 16:56:18,531 - INFO - root - 已保存图片 2/10：./export\images_A Quantized VAE-MLP Botnet Detection Model_ A Systematic Evaluation of Quantizat\figure_2_page4.png
2025-11-09 16:56:18,874 - INFO - root - 已保存图片 3/10：./export\images_A Quantized VAE-MLP Botnet Detection Model_ A Systematic Evaluation of Quantizat\figure_3_page4.png
2025-11-09 16:56:19,094 - INFO - root - 已保存图片 4/10：./export\images_A Quantized VAE-MLP Botnet Detection Model_ A Systematic Evaluation of Quantizat\figure_4_page5.png
2025-11-09 16:56:19,201 - INFO - root - 已保存图片 5/10：./export\images_A Quantized VAE-MLP Botnet Detection Model_ A Systematic Evaluation of Quantizat\figure_5_page3.png
2025-11-09 16:56:19,379 - INFO - root - 已保存图片 6/10：./export\images_A Quantized VAE-MLP Botnet Detection Model_ A Systematic Evaluation of Quantizat\figure_6_page4.png
2025-11-09 16:56:19,381 - INFO - root - 成功添加图片 1：./export\images_A Quantized VAE-MLP Botnet Detection Model_ A Systematic Evaluation of Quantizat\figure_1_page4.png
2025-11-09 16:56:19,382 - INFO - root - 成功添加图片 2：./export\images_A Quantized VAE-MLP Botnet Detection Model_ A Systematic Evaluation of Quantizat\figure_2_page4.png
2025-11-09 16:56:19,382 - INFO - root - 成功添加图片 3：./export\images_A Quantized VAE-MLP Botnet Detection Model_ A Systematic Evaluation of Quantizat\figure_3_page4.png
2025-11-09 16:56:19,383 - INFO - root - 成功添加图片 4：./export\images_A Quantized VAE-MLP Botnet Detection Model_ A Systematic Evaluation of Quantizat\figure_4_page5.png
2025-11-09 16:56:19,383 - INFO - root - 成功添加图片 5：./export\images_A Quantized VAE-MLP Botnet Detection Model_ A Systematic Evaluation of Quantizat\figure_5_page3.png
2025-11-09 16:56:19,384 - INFO - root - 成功添加图片 6：./export\images_A Quantized VAE-MLP Botnet Detection Model_ A Systematic Evaluation of Quantizat\figure_6_page4.png
2025-11-09 16:56:19,393 - INFO - root - 论文《A Quantized VAE-MLP Botnet Detection Model: A Systematic Evaluation of Quantization-Aware Training and Post-Training Quantization Strategies》的分析已保存到 ./export\A Quantized VAE-MLP Botnet Detection Model_ A Systematic Evaluation of Quantizat.md
2025-11-09 16:56:19,415 - INFO - root - 正在总结论文 2/10: FP8-Flow-MoE: A Casting-Free FP8 Recipe without Double Quantization Error
2025-11-09 16:56:42,330 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 16:56:57,262 - INFO - openai._base_client - Retrying request to /chat/completions in 0.390960 seconds
2025-11-09 16:56:59,684 - INFO - openai._base_client - Retrying request to /chat/completions in 0.900756 seconds
2025-11-09 16:57:02,610 - ERROR - root - DoubaoClient: generation error: Connection error.
Traceback (most recent call last):
  File "D:\ChatPaper\.venv\Lib\site-packages\httpx\_transports\default.py", line 101, in map_httpcore_exceptions
    yield
  File "D:\ChatPaper\.venv\Lib\site-packages\httpx\_transports\default.py", line 250, in handle_request
    resp = self._pool.handle_request(req)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\httpcore\_sync\connection_pool.py", line 256, in handle_request
    raise exc from None
  File "D:\ChatPaper\.venv\Lib\site-packages\httpcore\_sync\connection_pool.py", line 236, in handle_request
    response = connection.handle_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\httpcore\_sync\http_proxy.py", line 288, in handle_request
    connect_response = self._connection.handle_request(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\httpcore\_sync\connection.py", line 101, in handle_request
    raise exc
  File "D:\ChatPaper\.venv\Lib\site-packages\httpcore\_sync\connection.py", line 78, in handle_request
    stream = self._connect(request)
             ^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\httpcore\_sync\connection.py", line 124, in _connect
    stream = self._network_backend.connect_tcp(**kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\httpcore\_backends\sync.py", line 207, in connect_tcp
    with map_exceptions(exc_map):
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(value)
  File "D:\ChatPaper\.venv\Lib\site-packages\httpcore\_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ConnectError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "D:\ChatPaper\.venv\Lib\site-packages\openai\_base_client.py", line 982, in request
    response = self._client.send(
               ^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\httpx\_client.py", line 914, in send
    response = self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\httpx\_client.py", line 942, in _send_handling_auth
    response = self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\httpx\_client.py", line 979, in _send_handling_redirects
    response = self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\httpx\_client.py", line 1014, in _send_single_request
    response = transport.handle_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\httpx\_transports\default.py", line 249, in handle_request
    with map_httpcore_exceptions():
         ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(value)
  File "D:\ChatPaper\.venv\Lib\site-packages\httpx\_transports\default.py", line 118, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "D:\ChatPaper\llm_client_merged.py", line 632, in generate
    completion = self.client.chat.completions.create(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\openai\_utils\_utils.py", line 286, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\openai\resources\chat\completions\completions.py", line 1156, in create
    return self._post(
           ^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\openai\_base_client.py", line 1259, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\openai\_base_client.py", line 1014, in request
    raise APIConnectionError(request=request) from err
openai.APIConnectionError: Connection error.
2025-11-09 16:57:02,650 - WARNING - root - DoubaoClient: 网络连接问题 检测到，等待 60 秒后重试
2025-11-09 16:58:02,653 - INFO - root - DoubaoClient: retry attempt 2 for generation
2025-11-09 16:58:04,699 - INFO - openai._base_client - Retrying request to /chat/completions in 0.449534 seconds
2025-11-09 16:58:07,192 - INFO - openai._base_client - Retrying request to /chat/completions in 0.840435 seconds
2025-11-09 16:58:10,065 - ERROR - root - DoubaoClient: generation error: Connection error.
Traceback (most recent call last):
  File "D:\ChatPaper\.venv\Lib\site-packages\httpx\_transports\default.py", line 101, in map_httpcore_exceptions
    yield
  File "D:\ChatPaper\.venv\Lib\site-packages\httpx\_transports\default.py", line 250, in handle_request
    resp = self._pool.handle_request(req)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\httpcore\_sync\connection_pool.py", line 256, in handle_request
    raise exc from None
  File "D:\ChatPaper\.venv\Lib\site-packages\httpcore\_sync\connection_pool.py", line 236, in handle_request
    response = connection.handle_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\httpcore\_sync\http_proxy.py", line 288, in handle_request
    connect_response = self._connection.handle_request(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\httpcore\_sync\connection.py", line 101, in handle_request
    raise exc
  File "D:\ChatPaper\.venv\Lib\site-packages\httpcore\_sync\connection.py", line 78, in handle_request
    stream = self._connect(request)
             ^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\httpcore\_sync\connection.py", line 124, in _connect
    stream = self._network_backend.connect_tcp(**kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\httpcore\_backends\sync.py", line 207, in connect_tcp
    with map_exceptions(exc_map):
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(value)
  File "D:\ChatPaper\.venv\Lib\site-packages\httpcore\_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ConnectError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "D:\ChatPaper\.venv\Lib\site-packages\openai\_base_client.py", line 982, in request
    response = self._client.send(
               ^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\httpx\_client.py", line 914, in send
    response = self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\httpx\_client.py", line 942, in _send_handling_auth
    response = self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\httpx\_client.py", line 979, in _send_handling_redirects
    response = self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\httpx\_client.py", line 1014, in _send_single_request
    response = transport.handle_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\httpx\_transports\default.py", line 249, in handle_request
    with map_httpcore_exceptions():
         ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(value)
  File "D:\ChatPaper\.venv\Lib\site-packages\httpx\_transports\default.py", line 118, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "D:\ChatPaper\llm_client_merged.py", line 632, in generate
    completion = self.client.chat.completions.create(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\openai\_utils\_utils.py", line 286, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\openai\resources\chat\completions\completions.py", line 1156, in create
    return self._post(
           ^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\openai\_base_client.py", line 1259, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\openai\_base_client.py", line 1014, in request
    raise APIConnectionError(request=request) from err
openai.APIConnectionError: Connection error.
2025-11-09 16:58:10,074 - WARNING - root - DoubaoClient: 网络连接问题 检测到，等待 60 秒后重试
2025-11-09 16:59:10,077 - INFO - root - DoubaoClient: retry attempt 3 for generation
2025-11-09 16:59:12,128 - INFO - openai._base_client - Retrying request to /chat/completions in 0.419260 seconds
2025-11-09 16:59:14,569 - INFO - openai._base_client - Retrying request to /chat/completions in 0.863384 seconds
2025-11-09 16:59:17,468 - ERROR - root - DoubaoClient: generation error: Connection error.
Traceback (most recent call last):
  File "D:\ChatPaper\.venv\Lib\site-packages\httpx\_transports\default.py", line 101, in map_httpcore_exceptions
    yield
  File "D:\ChatPaper\.venv\Lib\site-packages\httpx\_transports\default.py", line 250, in handle_request
    resp = self._pool.handle_request(req)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\httpcore\_sync\connection_pool.py", line 256, in handle_request
    raise exc from None
  File "D:\ChatPaper\.venv\Lib\site-packages\httpcore\_sync\connection_pool.py", line 236, in handle_request
    response = connection.handle_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\httpcore\_sync\http_proxy.py", line 288, in handle_request
    connect_response = self._connection.handle_request(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\httpcore\_sync\connection.py", line 101, in handle_request
    raise exc
  File "D:\ChatPaper\.venv\Lib\site-packages\httpcore\_sync\connection.py", line 78, in handle_request
    stream = self._connect(request)
             ^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\httpcore\_sync\connection.py", line 124, in _connect
    stream = self._network_backend.connect_tcp(**kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\httpcore\_backends\sync.py", line 207, in connect_tcp
    with map_exceptions(exc_map):
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(value)
  File "D:\ChatPaper\.venv\Lib\site-packages\httpcore\_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ConnectError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "D:\ChatPaper\.venv\Lib\site-packages\openai\_base_client.py", line 982, in request
    response = self._client.send(
               ^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\httpx\_client.py", line 914, in send
    response = self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\httpx\_client.py", line 942, in _send_handling_auth
    response = self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\httpx\_client.py", line 979, in _send_handling_redirects
    response = self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\httpx\_client.py", line 1014, in _send_single_request
    response = transport.handle_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\httpx\_transports\default.py", line 249, in handle_request
    with map_httpcore_exceptions():
         ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(value)
  File "D:\ChatPaper\.venv\Lib\site-packages\httpx\_transports\default.py", line 118, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "D:\ChatPaper\llm_client_merged.py", line 632, in generate
    completion = self.client.chat.completions.create(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\openai\_utils\_utils.py", line 286, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\openai\resources\chat\completions\completions.py", line 1156, in create
    return self._post(
           ^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\openai\_base_client.py", line 1259, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\openai\_base_client.py", line 1014, in request
    raise APIConnectionError(request=request) from err
openai.APIConnectionError: Connection error.
2025-11-09 16:59:17,480 - ERROR - root - DoubaoClient: 最终失败 - 抱歉，豆包生成内容时遇到问题：Connection error.
2025-11-09 16:59:19,520 - INFO - openai._base_client - Retrying request to /chat/completions in 0.457668 seconds
2025-11-09 16:59:22,010 - INFO - openai._base_client - Retrying request to /chat/completions in 0.784081 seconds
2025-11-09 16:59:24,810 - ERROR - root - DoubaoClient: generation error: Connection error.
Traceback (most recent call last):
  File "D:\ChatPaper\.venv\Lib\site-packages\httpx\_transports\default.py", line 101, in map_httpcore_exceptions
    yield
  File "D:\ChatPaper\.venv\Lib\site-packages\httpx\_transports\default.py", line 250, in handle_request
    resp = self._pool.handle_request(req)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\httpcore\_sync\connection_pool.py", line 256, in handle_request
    raise exc from None
  File "D:\ChatPaper\.venv\Lib\site-packages\httpcore\_sync\connection_pool.py", line 236, in handle_request
    response = connection.handle_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\httpcore\_sync\http_proxy.py", line 288, in handle_request
    connect_response = self._connection.handle_request(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\httpcore\_sync\connection.py", line 101, in handle_request
    raise exc
  File "D:\ChatPaper\.venv\Lib\site-packages\httpcore\_sync\connection.py", line 78, in handle_request
    stream = self._connect(request)
             ^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\httpcore\_sync\connection.py", line 124, in _connect
    stream = self._network_backend.connect_tcp(**kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\httpcore\_backends\sync.py", line 207, in connect_tcp
    with map_exceptions(exc_map):
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(value)
  File "D:\ChatPaper\.venv\Lib\site-packages\httpcore\_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ConnectError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "D:\ChatPaper\.venv\Lib\site-packages\openai\_base_client.py", line 982, in request
    response = self._client.send(
               ^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\httpx\_client.py", line 914, in send
    response = self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\httpx\_client.py", line 942, in _send_handling_auth
    response = self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\httpx\_client.py", line 979, in _send_handling_redirects
    response = self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\httpx\_client.py", line 1014, in _send_single_request
    response = transport.handle_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\httpx\_transports\default.py", line 249, in handle_request
    with map_httpcore_exceptions():
         ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(value)
  File "D:\ChatPaper\.venv\Lib\site-packages\httpx\_transports\default.py", line 118, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "D:\ChatPaper\llm_client_merged.py", line 632, in generate
    completion = self.client.chat.completions.create(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\openai\_utils\_utils.py", line 286, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\openai\resources\chat\completions\completions.py", line 1156, in create
    return self._post(
           ^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\openai\_base_client.py", line 1259, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\openai\_base_client.py", line 1014, in request
    raise APIConnectionError(request=request) from err
openai.APIConnectionError: Connection error.
2025-11-09 16:59:24,818 - WARNING - root - DoubaoClient: 网络连接问题 检测到，等待 60 秒后重试
2025-11-09 17:12:12,059 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-09 17:12:12,062 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-09 17:12:12,065 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-09 17:25:58,418 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-09 17:25:58,423 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-09 17:25:58,426 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-09 17:36:52,097 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-09 17:36:52,104 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-09 17:36:52,110 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-09 17:36:54,026 - INFO - root - LLMClientManager: 指定使用客户端: Doubao
2025-11-09 17:36:54,028 - INFO - root - DoubaoClient: API key found: 9f9e270e-b...
2025-11-09 17:36:58,431 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 17:36:58,453 - INFO - root - DoubaoClient: initialized successfully with model doubao-seed-1-6-lite-251015
2025-11-09 17:36:58,454 - INFO - root - LLMClientManager: Doubao 客户端初始化成功
2025-11-09 17:36:58,454 - INFO - root - LLMClientManager: switched to Doubao client
2025-11-09 17:36:58,454 - INFO - root - 已手动切换到 LLM 客户端: Doubao
2025-11-09 17:36:58,454 - INFO - root - 使用 LLM 模型: doubao-seed-1-6-lite-251015
2025-11-09 17:36:58,454 - INFO - root - 可用客户端: ['Doubao']
2025-11-09 17:36:58,455 - INFO - root - === 运行配置 ===
2025-11-09 17:36:58,455 - INFO - root - 处理模式: arxiv在线搜索
2025-11-09 17:36:58,455 - INFO - root - 关键词: QAT
2025-11-09 17:36:58,456 - INFO - root - 查询: Quantization-Aware-Training
2025-11-09 17:36:58,456 - INFO - root - 排序: None
2025-11-09 17:36:58,456 - INFO - root - 最近天数: 180
2025-11-09 17:36:58,457 - INFO - root - 最大处理数量: 20
2025-11-09 17:36:58,457 - INFO - root - 保存图片: 是
2025-11-09 17:36:58,457 - INFO - root - 输出语言: 中文
2025-11-09 17:36:58,457 - INFO - root - 强制重新处理: 否
2025-11-09 17:36:58,457 - INFO - root - ====================
2025-11-09 17:36:58,457 - INFO - root - 使用 arXiv 搜索模式（通过 chat_arxiv 模块获取）
2025-11-09 17:36:58,459 - INFO - root - Fetching page 1 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50
2025-11-09 17:37:16,996 - INFO - root - get_all_titles_from_web 
2025-11-09 17:37:16,997 - INFO - root - Page:0, Index:0, A Quantized VAE-MLP Botnet Detection Model: A Systematic Evaluation of Quantization-Aware Training and Post-Training Quantization Strategies, https://arxiv.org/pdf/2511.03201, 2025-11-05
2025-11-09 17:37:16,997 - INFO - root - Page:0, Index:1, FP8-Flow-MoE: A Casting-Free FP8 Recipe without Double Quantization Error, https://arxiv.org/pdf/2511.02302, 2025-11-04
2025-11-09 17:37:16,997 - INFO - root - Page:0, Index:2, Outlier-Aware Post-Training Quantization for Image Super-Resolution, https://arxiv.org/pdf/2511.00682, 2025-11-01
2025-11-09 17:37:16,998 - INFO - root - Page:0, Index:3, Evaluation of Wafer-Scale SOT-MRAM for Analog Crossbar Array Applications, https://arxiv.org/pdf/2510.25853, 2025-11-03
2025-11-09 17:37:16,999 - INFO - root - Page:0, Index:4, Improving the Straight-Through Estimator with Zeroth-Order Information, https://arxiv.org/pdf/2510.23926, 2025-10-27
2025-11-09 17:37:16,999 - INFO - root - Page:0, Index:5, Real-Time Semantic Segmentation on FPGA for Autonomous Vehicles Using LMIINet with the CGRA4ML Framework, https://arxiv.org/pdf/2510.22243, 2025-10-25
2025-11-09 17:37:17,000 - INFO - root - Page:0, Index:6, TernaryCLIP: Efficiently Compressing Vision-Language Models with Ternary Weights and Distilled Knowledge, https://arxiv.org/pdf/2510.21879, 2025-10-23
2025-11-09 17:37:17,000 - INFO - root - Page:0, Index:7, KARIPAP: Quantum-Inspired Tensor Network Compression of Large Language Models Using Infinite Projected Entangled Pair States and Tensor Renormalization Group, https://arxiv.org/pdf/2510.21844, 2025-10-22
2025-11-09 17:37:17,001 - INFO - root - Page:0, Index:8, A Convergence Analysis of Adaptive Optimizers under Floating-point Quantization, https://arxiv.org/pdf/2510.21314, 2025-10-24
2025-11-09 17:37:17,001 - INFO - root - Page:0, Index:9, Adaptive Distribution-aware Quantization for Mixed-Precision Neural Networks, https://arxiv.org/pdf/2510.19760, 2025-10-22
2025-11-09 17:37:17,001 - INFO - root - Page:0, Index:10, CAGE: Curvature-Aware Gradient Estimation For Accurate Quantization-Aware Training, https://arxiv.org/pdf/2510.18784, 2025-10-21
2025-11-09 17:37:17,002 - INFO - root - Page:0, Index:11, Mixed-Precision Quantization for Language Models: Techniques and Prospects, https://arxiv.org/pdf/2510.16805, 2025-10-19
2025-11-09 17:37:17,002 - INFO - root - Page:0, Index:12, SPLite Hand: Sparsity-Aware Lightweight 3D Hand Pose Estimation, https://arxiv.org/pdf/2510.16396, 2025-10-30
2025-11-09 17:37:17,002 - INFO - root - Page:0, Index:13, CTR-LoRA: Curvature-Aware and Trust-Region Guided Low-Rank Adaptation for Large Language Models, https://arxiv.org/pdf/2510.15962, 2025-10-11
2025-11-09 17:37:17,003 - INFO - root - Page:0, Index:14, SANR: Scene-Aware Neural Representation for Light Field Image Compression with Rate-Distortion Optimization, https://arxiv.org/pdf/2510.15775, 2025-10-17
2025-11-09 17:37:17,004 - INFO - root - Page:0, Index:15, SpikeFit: Towards Optimal Deployment of Spiking Networks on Neuromorphic Hardware, https://arxiv.org/pdf/2510.15542, 2025-10-31
2025-11-09 17:37:17,006 - INFO - root - Page:0, Index:16, GRank: Towards Target-Aware and Streamlined Industrial Retrieval with a Generate-Rank Framework, https://arxiv.org/pdf/2510.15299, 2025-10-17
2025-11-09 17:37:17,007 - INFO - root - Page:0, Index:17, SaLon3R: Structure-aware Long-term Generalizable 3D Reconstruction from Unposed Images, https://arxiv.org/pdf/2510.15072, 2025-10-16
2025-11-09 17:37:17,007 - INFO - root - Page:0, Index:18, FraQAT: Quantization Aware Training with Fractional bits, https://arxiv.org/pdf/2510.14823, 2025-10-16
2025-11-09 17:37:17,007 - INFO - root - Page:0, Index:19, Computing-In-Memory Aware Model Adaption For Edge Devices, https://arxiv.org/pdf/2510.14379, 2025-10-16
2025-11-09 17:37:17,007 - INFO - root - Page:0, Index:20, Invited Paper: BitMedViT: Ternary-Quantized Vision Transformer for Medical AI Assistants on the Edge, https://arxiv.org/pdf/2510.13760, 2025-11-04
2025-11-09 17:37:17,009 - INFO - root - Page:0, Index:21, NeuroRVQ: Multi-Scale EEG Tokenization for Generative Large Brainwave Models, https://arxiv.org/pdf/2510.13068, 2025-10-14
2025-11-09 17:37:17,009 - INFO - root - Page:0, Index:22, Detect Anything via Next Point Prediction, https://arxiv.org/pdf/2510.12798, 2025-10-14
2025-11-09 17:37:17,013 - INFO - root - Page:0, Index:23, AndesVL Technical Report: An Efficient Mobile-side Multimodal Large Language Model, https://arxiv.org/pdf/2510.11496, 2025-10-14
2025-11-09 17:37:17,042 - INFO - root - Page:0, Index:24, Rescaling-Aware Training for Efficient Deployment of Deep Learning Models on Full-Integer Hardware, https://arxiv.org/pdf/2510.11484, 2025-10-13
2025-11-09 17:37:17,044 - INFO - root - Page:0, Index:25, SASER: Stego attacks on open-source LLMs, https://arxiv.org/pdf/2510.10486, 2025-10-12
2025-11-09 17:37:17,046 - INFO - root - Page:0, Index:26, Ultralytics YOLO Evolution: An Overview of YOLO26, YOLO11, YOLOv8 and YOLOv5 Object Detectors for Computer Vision and Pattern Recognition, https://arxiv.org/pdf/2510.09653, 2025-10-15
2025-11-09 17:37:17,047 - INFO - root - Page:0, Index:27, A Theoretically-Grounded Codebook for Digital Semantic Communications, https://arxiv.org/pdf/2510.07108, 2025-10-14
2025-11-09 17:37:17,047 - INFO - root - Page:0, Index:28, QuantDemoire: Quantization with Outlier Aware for Image Demoiréing, https://arxiv.org/pdf/2510.04066, 2025-10-05
2025-11-09 17:37:17,047 - INFO - root - Page:0, Index:29, Adaptively Sampling-Reusing-Mixing Decomposed Gradients to Speed Up Sharpness Aware Minimization, https://arxiv.org/pdf/2510.03763, 2025-10-04
2025-11-09 17:37:17,047 - INFO - root - Page:0, Index:30, Quant-dLLM: Post-Training Extreme Low-Bit Quantization for Diffusion Large Language Models, https://arxiv.org/pdf/2510.03274, 2025-09-27
2025-11-09 17:37:17,049 - INFO - root - Page:0, Index:31, PT$^2$-LLM: Post-Training Ternarization for Large Language Models, https://arxiv.org/pdf/2510.03267, 2025-09-26
2025-11-09 17:37:17,053 - INFO - root - Page:0, Index:32, Purrception: Variational Flow Matching for Vector-Quantized Image Generation, https://arxiv.org/pdf/2510.01478, 2025-10-01
2025-11-09 17:37:17,054 - INFO - root - Page:0, Index:33, Post-Training Quantization for Audio Diffusion Transformers, https://arxiv.org/pdf/2510.00313, 2025-09-30
2025-11-09 17:37:17,055 - INFO - root - Page:0, Index:34, Rethinking RoPE Scaling in Quantized LLM: Theory, Outlier, and Channel-Band Analysis with Weight Rescaling, https://arxiv.org/pdf/2510.00028, 2025-09-25
2025-11-09 17:37:17,056 - INFO - root - Page:0, Index:35, Post-Training Quantization via Residual Truncation and Zero Suppression for Diffusion Models, https://arxiv.org/pdf/2509.26436, 2025-09-30
2025-11-09 17:37:17,056 - INFO - root - Page:0, Index:36, Cat: Post-Training Quantization Error Reduction via Cluster-based Affine Transformation, https://arxiv.org/pdf/2509.26277, 2025-10-07
2025-11-09 17:37:17,057 - INFO - root - Page:0, Index:37, CAST: Continuous and Differentiable Semi-Structured Sparsity-Aware Training for Large Language Models, https://arxiv.org/pdf/2509.25996, 2025-09-30
2025-11-09 17:37:17,057 - INFO - root - Page:0, Index:38, Norm-Q: Effective Compression Method for Hidden Markov Models in Neuro-Symbolic Applications, https://arxiv.org/pdf/2509.25439, 2025-09-29
2025-11-09 17:37:17,072 - INFO - root - Page:0, Index:39, On-the-Fly Adaptation to Quantization: Configuration-Aware LoRA for Efficient Fine-Tuning of Quantized LLMs, https://arxiv.org/pdf/2509.25214, 2025-09-22
2025-11-09 17:37:17,076 - INFO - root - Page:0, Index:40, VoxCPM: Tokenizer-Free TTS for Context-Aware Speech Generation and True-to-Life Voice Cloning, https://arxiv.org/pdf/2509.24650, 2025-09-29
2025-11-09 17:37:17,076 - INFO - root - Page:0, Index:41, S$^2$NN: Sub-bit Spiking Neural Networks, https://arxiv.org/pdf/2509.24266, 2025-10-24
2025-11-09 17:37:17,077 - INFO - root - Page:0, Index:42, Tequila: Trapping-free Ternary Quantization for Large Language Models, https://arxiv.org/pdf/2509.23809, 2025-10-17
2025-11-09 17:37:17,077 - INFO - root - Page:0, Index:43, Texture Vector-Quantization and Reconstruction Aware Prediction for Generative Super-Resolution, https://arxiv.org/pdf/2509.23774, 2025-09-30
2025-11-09 17:37:17,077 - INFO - root - Page:0, Index:44, RobuQ: Pushing DiTs to W1.58A2 via Robust Activation Quantization, https://arxiv.org/pdf/2509.23582, 2025-09-27
2025-11-09 17:37:17,078 - INFO - root - Page:0, Index:45, Beyond Outliers: A Study of Optimizers Under Quantization, https://arxiv.org/pdf/2509.23500, 2025-10-02
2025-11-09 17:37:17,078 - INFO - root - Page:0, Index:46, Compute-Optimal Quantization-Aware Training, https://arxiv.org/pdf/2509.22935, 2025-09-26
2025-11-09 17:37:17,079 - INFO - root - Page:0, Index:47, COSPADI: Compressing LLMs via Calibration-Guided Sparse Dictionary Learning, https://arxiv.org/pdf/2509.22075, 2025-10-06
2025-11-09 17:37:17,079 - INFO - root - Page:0, Index:48, SlimDiff: Training-Free, Activation-Guided Hands-free Slimming of Diffusion Models, https://arxiv.org/pdf/2509.21498, 2025-09-25
2025-11-09 17:37:17,086 - INFO - root - Page:0, Index:49, Quantized Visual Geometry Grounded Transformer, https://arxiv.org/pdf/2509.21302, 2025-09-29
2025-11-09 17:37:17,089 - INFO - root - Fetching page 2 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=50
2025-11-09 17:37:39,510 - INFO - root - get_all_titles_from_web 
2025-11-09 17:37:39,510 - INFO - root - Page:1, Index:0, Can Less Precise Be More Reliable? A Systematic Evaluation of Quantization's Impact on CLIP Beyond Accuracy, https://arxiv.org/pdf/2509.21173, 2025-10-27
2025-11-09 17:37:39,510 - INFO - root - Page:1, Index:1, Punching Above Precision: Small Quantized Model Distillation with Learnable Regularizer, https://arxiv.org/pdf/2509.20854, 2025-09-25
2025-11-09 17:37:39,512 - INFO - root - Page:1, Index:2, TinyEcoWeedNet: Edge Efficient Real-Time Aerial Agricultural Weed Detection, https://arxiv.org/pdf/2509.18193, 2025-09-19
2025-11-09 17:37:39,512 - INFO - root - Page:1, Index:3, SBVR: Summation of BitVector Representation for Efficient LLM Quantization, https://arxiv.org/pdf/2509.18172, 2025-09-17
2025-11-09 17:37:39,512 - INFO - root - Page:1, Index:4, QWHA: Quantization-Aware Walsh-Hadamard Adaptation for Parameter-Efficient Fine-Tuning on Large Language Models, https://arxiv.org/pdf/2509.17428, 2025-09-26
2025-11-09 17:37:39,512 - INFO - root - Page:1, Index:5, PTQTP: Post-Training Quantization to Trit-Planes for Large Language Models, https://arxiv.org/pdf/2509.16989, 2025-10-28
2025-11-09 17:37:39,513 - INFO - root - Page:1, Index:6, MEC-Quant: Maximum Entropy Coding for Extremely Low Bit Quantization-Aware Training, https://arxiv.org/pdf/2509.15514, 2025-09-18
2025-11-09 17:37:39,513 - INFO - root - Page:1, Index:7, Q-ROAR: Outlier-Aware Rescaling for RoPE Position Interpolation in Quantized Long-Context LLMs, https://arxiv.org/pdf/2509.14391, 2025-09-17
2025-11-09 17:37:39,513 - INFO - root - Page:1, Index:8, Efficient Quantization-Aware Neural Receivers: Beyond Post-Training Quantization, https://arxiv.org/pdf/2509.13786, 2025-09-19
2025-11-09 17:37:39,514 - INFO - root - Page:1, Index:9, Rate-Distortion Limits for Multimodal Retrieval: Theory, Optimal Codes, and Finite-Sample Guarantees, https://arxiv.org/pdf/2509.11054, 2025-09-13
2025-11-09 17:37:39,514 - INFO - root - Page:1, Index:10, SQAP-VLA: A Synergistic Quantization-Aware Pruning Framework for High-Performance Vision-Language-Action Models, https://arxiv.org/pdf/2509.09090, 2025-09-10
2025-11-09 17:37:39,514 - INFO - root - Page:1, Index:11, CSI Compression Beyond Latents: End-to-End Hybrid Attention-CNN Networks with Entropy Regularization, https://arxiv.org/pdf/2509.08776, 2025-09-10
2025-11-09 17:37:39,514 - INFO - root - Page:1, Index:12, Explaining How Quantization Disparately Skews a Model, https://arxiv.org/pdf/2509.07222, 2025-09-08
2025-11-09 17:37:39,515 - INFO - root - Page:1, Index:13, LoaQ: Layer-wise Output Approximation Quantization, https://arxiv.org/pdf/2509.06297, 2025-09-07
2025-11-09 17:37:39,515 - INFO - root - Page:1, Index:14, FineServe: Precision-Aware KV Slab and Two-Level Scheduling for Heterogeneous Precision LLM Serving, https://arxiv.org/pdf/2509.06261, 2025-09-14
2025-11-09 17:37:39,515 - INFO - root - Page:1, Index:15, Sensitivity-Aware Post-Training Quantization for Deep Neural Networks, https://arxiv.org/pdf/2509.05576, 2025-09-05
2025-11-09 17:37:39,515 - INFO - root - Page:1, Index:16, SuperSNN: A Hardware-Aware Framework for Physically Realizable, High-Performance Superconducting Spiking Neural Network Chips, https://arxiv.org/pdf/2509.05532, 2025-09-05
2025-11-09 17:37:39,517 - INFO - root - Page:1, Index:17, Data-Augmented Quantization-Aware Knowledge Distillation, https://arxiv.org/pdf/2509.03850, 2025-09-03
2025-11-09 17:37:39,517 - INFO - root - Page:1, Index:18, DPQuant: Efficient and Differentially-Private Model Training via Dynamic Quantization Scheduling, https://arxiv.org/pdf/2509.03472, 2025-09-03
2025-11-09 17:37:39,517 - INFO - root - Page:1, Index:19, Empowering Large Language Model for Sequential Recommendation via Multimodal Embeddings and Semantic IDs, https://arxiv.org/pdf/2509.02017, 2025-09-02
2025-11-09 17:37:39,518 - INFO - root - Page:1, Index:20, Q-Sched: Pushing the Boundaries of Few-Step Diffusion Models with Quantization-Aware Scheduling, https://arxiv.org/pdf/2509.01624, 2025-09-01
2025-11-09 17:37:39,518 - INFO - root - Page:1, Index:21, Quantization Meets OOD: Generalizable Quantization-aware Training from a Flatness Perspective, https://arxiv.org/pdf/2509.00859, 2025-08-31
2025-11-09 17:37:39,519 - INFO - root - Page:1, Index:22, Progressive Element-wise Gradient Estimation for Neural Network Quantization, https://arxiv.org/pdf/2509.00097, 2025-08-27
2025-11-09 17:37:39,519 - INFO - root - Page:1, Index:23, End-to-End On-Device Quantization-Aware Training for LLMs at Inference Cost, https://arxiv.org/pdf/2509.00031, 2025-09-29
2025-11-09 17:37:39,519 - INFO - root - Page:1, Index:24, Quantization Robustness to Input Degradations for Object Detection, https://arxiv.org/pdf/2508.19600, 2025-08-27
2025-11-09 17:37:39,520 - INFO - root - Page:1, Index:25, Scaling Laws for Task-Stratified Knowledge in Post-Training Quantized Large Language Models, https://arxiv.org/pdf/2508.18609, 2025-08-27
2025-11-09 17:37:39,521 - INFO - root - Page:1, Index:26, AQ-PCDSys: An Adaptive Quantized Planetary Crater Detection System for Autonomous Space Exploration, https://arxiv.org/pdf/2508.18025, 2025-08-25
2025-11-09 17:37:39,522 - INFO - root - Page:1, Index:27, TaDiCodec: Text-aware Diffusion Speech Tokenizer for Speech Language Modeling, https://arxiv.org/pdf/2508.16790, 2025-08-22
2025-11-09 17:37:39,522 - INFO - root - Page:1, Index:28, A Node-Aware Dynamic Quantization Approach for Graph Collaborative Filtering, https://arxiv.org/pdf/2508.16516, 2025-08-22
2025-11-09 17:37:39,523 - INFO - root - Page:1, Index:29, JEDI-linear: Fast and Efficient Graph Neural Networks for Jet Tagging on FPGAs, https://arxiv.org/pdf/2508.15468, 2025-08-21
2025-11-09 17:37:39,523 - INFO - root - Page:1, Index:30, MMQ: Multimodal Mixture-of-Quantization Tokenization for Semantic ID Generation and User Behavioral Adaptation, https://arxiv.org/pdf/2508.15281, 2025-08-21
2025-11-09 17:37:39,524 - INFO - root - Page:1, Index:31, DLLMQuant: Quantizing Diffusion-based Large Language Models, https://arxiv.org/pdf/2508.14090, 2025-08-25
2025-11-09 17:37:39,524 - INFO - root - Page:1, Index:32, Automated Energy-Aware Time-Series Model Deployment on Embedded FPGAs for Resilient Combined Sewer Overflow Management, https://arxiv.org/pdf/2508.13905, 2025-08-19
2025-11-09 17:37:39,525 - INFO - root - Page:1, Index:33, XR-NPE: High-Throughput Mixed-precision SIMD Neural Processing Engine for Extended Reality Perception Workloads, https://arxiv.org/pdf/2508.13049, 2025-08-18
2025-11-09 17:37:39,526 - INFO - root - Page:1, Index:34, Exploring Self-Supervised Audio Models for Generalized Anomalous Sound Detection, https://arxiv.org/pdf/2508.12230, 2025-08-17
2025-11-09 17:37:39,530 - INFO - root - Page:1, Index:35, TriQDef: Disrupting Semantic and Gradient Alignment to Prevent Adversarial Patch Transferability in Quantized Neural Networks, https://arxiv.org/pdf/2508.12132, 2025-08-16
2025-11-09 17:37:39,534 - INFO - root - Page:1, Index:36, Error Propagation Mechanisms and Compensation Strategies for Quantized Diffusion, https://arxiv.org/pdf/2508.12094, 2025-10-13
2025-11-09 17:37:39,534 - INFO - root - Page:1, Index:37, Extending Straight-Through Estimation for Robust Neural Networks on Analog CIM Hardware, https://arxiv.org/pdf/2508.11940, 2025-08-16
2025-11-09 17:37:39,535 - INFO - root - Page:1, Index:38, PTQAT: A Hybrid Parameter-Efficient Quantization Algorithm for 3D Perception Tasks, https://arxiv.org/pdf/2508.10557, 2025-08-15
2025-11-09 17:37:39,536 - INFO - root - Page:1, Index:39, MiCo: End-to-End Mixed Precision Neural Network Co-Exploration Framework for Edge AI, https://arxiv.org/pdf/2508.09500, 2025-08-13
2025-11-09 17:37:39,537 - INFO - root - Page:1, Index:40, SPARC: Soft Probabilistic Adaptive multi-interest Retrieval Model via Codebooks for recommender system, https://arxiv.org/pdf/2508.09090, 2025-08-12
2025-11-09 17:37:39,537 - INFO - root - Page:1, Index:41, Rethinking 1-bit Optimization Leveraging Pre-trained Large Language Models, https://arxiv.org/pdf/2508.06974, 2025-08-09
2025-11-09 17:37:39,542 - INFO - root - Page:1, Index:42, Efficient Deep Neural Receiver with Post-Training Quantization, https://arxiv.org/pdf/2508.06275, 2025-08-08
2025-11-09 17:37:39,545 - INFO - root - Page:1, Index:43, iFairy: the First 2-bit Complex LLM with All Parameters in $\{\pm1, \pm i\}$, https://arxiv.org/pdf/2508.05571, 2025-08-16
2025-11-09 17:37:39,546 - INFO - root - Page:1, Index:44, S$^2$Q-VDiT: Accurate Quantized Video Diffusion Transformer with Salient Data and Sparse Token Distillation, https://arxiv.org/pdf/2508.04016, 2025-10-27
2025-11-09 17:37:39,547 - INFO - root - Page:1, Index:45, LRQ-DiT: Log-Rotation Post-Training Quantization of Diffusion Transformers for Image and Video Generation, https://arxiv.org/pdf/2508.03485, 2025-09-23
2025-11-09 17:37:39,547 - INFO - root - Page:1, Index:46, VLMQ: Efficient Post-Training Quantization for Large Vision-Language Models via Hessian Augmentation, https://arxiv.org/pdf/2508.03351, 2025-08-05
2025-11-09 17:37:39,547 - INFO - root - Page:1, Index:47, TF-MLPNet: Tiny Real-Time Neural Speech Separation, https://arxiv.org/pdf/2508.03047, 2025-08-04
2025-11-09 17:37:39,548 - INFO - root - Page:1, Index:48, SaviorRec: Semantic-Behavior Alignment for Cold-Start Recommendation, https://arxiv.org/pdf/2508.01375, 2025-08-02
2025-11-09 17:37:39,548 - INFO - root - Page:1, Index:49, MixA-Q: Revisiting Activation Sparsity for Vision Transformers from a Mixed-Precision Quantization Perspective, https://arxiv.org/pdf/2507.19131, 2025-07-25
2025-11-09 17:37:39,549 - INFO - root - Fetching page 3 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=100
2025-11-09 17:37:50,057 - INFO - root - get_all_titles_from_web 
2025-11-09 17:37:50,058 - INFO - root - Page:2, Index:0, Enhancing Quantization-Aware Training on Edge Devices via Relative Entropy Coreset Selection and Cascaded Layer Correction, https://arxiv.org/pdf/2507.17768, 2025-07-16
2025-11-09 17:37:50,058 - INFO - root - Page:2, Index:1, SiLQ: Simple Large Language Model Quantization-Aware Training, https://arxiv.org/pdf/2507.16933, 2025-07-22
2025-11-09 17:37:50,059 - INFO - root - Page:2, Index:2, Task-Specific Zero-shot Quantization-Aware Training for Object Detection, https://arxiv.org/pdf/2507.16782, 2025-07-22
2025-11-09 17:37:50,059 - INFO - root - Page:2, Index:3, TorchAO: PyTorch-Native Training-to-Serving Model Optimization, https://arxiv.org/pdf/2507.16099, 2025-07-21
2025-11-09 17:37:50,059 - INFO - root - Page:2, Index:4, SegQuant: A Semantics-Aware and Generalizable Quantization Framework for Diffusion Models, https://arxiv.org/pdf/2507.14811, 2025-08-27
2025-11-09 17:37:50,059 - INFO - root - Page:2, Index:5, Apple Intelligence Foundation Language Models: Tech Report 2025, https://arxiv.org/pdf/2507.13575, 2025-08-27
2025-11-09 17:37:50,060 - INFO - root - Page:2, Index:6, Generative Multi-Target Cross-Domain Recommendation, https://arxiv.org/pdf/2507.12871, 2025-08-07
2025-11-09 17:37:50,060 - INFO - root - Page:2, Index:7, DAF: An Efficient End-to-End Dynamic Activation Framework for on-Device DNN Training, https://arxiv.org/pdf/2507.07149, 2025-07-09
2025-11-09 17:37:50,060 - INFO - root - Page:2, Index:8, Opto-ViT: Architecting a Near-Sensor Region of Interest-Aware Vision Transformer Accelerator with Silicon Photonics, https://arxiv.org/pdf/2507.07044, 2025-07-15
2025-11-09 17:37:50,060 - INFO - root - Page:2, Index:9, QS4D: Quantization-aware training for efficient hardware deployment of structured state-space sequential models, https://arxiv.org/pdf/2507.06079, 2025-07-08
2025-11-09 17:37:50,062 - INFO - root - Page:2, Index:10, GSVR: 2D Gaussian-based Video Representation for 800+ FPS with Hybrid Deformation Field, https://arxiv.org/pdf/2507.05594, 2025-07-07
2025-11-09 17:37:50,062 - INFO - root - Page:2, Index:11, Hita: Holistic Tokenizer for Autoregressive Image Generation, https://arxiv.org/pdf/2507.02358, 2025-07-11
2025-11-09 17:37:50,062 - INFO - root - Page:2, Index:12, QPART: Adaptive Model Quantization and Dynamic Workload Balancing for Accuracy-aware Edge Inference, https://arxiv.org/pdf/2506.23934, 2025-06-30
2025-11-09 17:37:50,063 - INFO - root - Page:2, Index:13, FedWSQ: Efficient Federated Learning with Weight Standardization and Distribution-Aware Non-Uniform Quantization, https://arxiv.org/pdf/2506.23516, 2025-07-21
2025-11-09 17:37:50,064 - INFO - root - Page:2, Index:14, Spectra 1.1: Scaling Laws and Efficient Inference for Ternary Language Models, https://arxiv.org/pdf/2506.23025, 2025-06-28
2025-11-09 17:37:50,064 - INFO - root - Page:2, Index:15, Joint Quantization and Pruning Neural Networks Approach: A Case Study on FSO Receivers, https://arxiv.org/pdf/2506.20084, 2025-06-24
2025-11-09 17:37:50,066 - INFO - root - Page:2, Index:16, Single-step Diffusion for Image Compression at Ultra-Low Bitrates, https://arxiv.org/pdf/2506.16572, 2025-09-22
2025-11-09 17:37:50,066 - INFO - root - Page:2, Index:17, LittleBit: Ultra Low-Bit Quantization via Latent Factorization, https://arxiv.org/pdf/2506.13771, 2025-10-28
2025-11-09 17:37:50,067 - INFO - root - Page:2, Index:18, MARCO: Hardware-Aware Neural Architecture Search for Edge Devices with Multi-Agent Reinforcement Learning and Conformal Prediction Filtering, https://arxiv.org/pdf/2506.13755, 2025-06-16
2025-11-09 17:37:50,067 - INFO - root - Page:2, Index:19, EAQuant: Enhancing Post-Training Quantization for MoE Models via Expert-Aware Optimization, https://arxiv.org/pdf/2506.13329, 2025-07-04
2025-11-09 17:37:50,068 - INFO - root - Page:2, Index:20, Towards Neural Audio Codec Source Parsing, https://arxiv.org/pdf/2506.12627, 2025-06-14
2025-11-09 17:37:50,068 - INFO - root - Page:2, Index:21, Quantizing Small-Scale State-Space Models for Edge AI, https://arxiv.org/pdf/2506.12480, 2025-06-14
2025-11-09 17:37:50,069 - INFO - root - Page:2, Index:22, EMLoC: Emulator-based Memory-efficient Fine-tuning with LoRA Correction, https://arxiv.org/pdf/2506.12015, 2025-06-13
2025-11-09 17:37:50,069 - INFO - root - Page:2, Index:23, Compression Aware Certified Training, https://arxiv.org/pdf/2506.11992, 2025-06-13
2025-11-09 17:37:50,069 - INFO - root - Page:2, Index:24, GPLQ: A General, Practical, and Lightning QAT Method for Vision Transformers, https://arxiv.org/pdf/2506.11784, 2025-06-13
2025-11-09 17:37:50,070 - INFO - root - Page:2, Index:25, TruncQuant: Truncation-Ready Quantization for DNNs with Flexible Weight Bit Precision, https://arxiv.org/pdf/2506.11431, 2025-06-12
2025-11-09 17:37:50,071 - INFO - root - Page:2, Index:26, EfficientQuant: An Efficient Post-Training Quantization for CNN-Transformer Hybrid Models on Edge Devices, https://arxiv.org/pdf/2506.11093, 2025-06-05
2025-11-09 17:37:50,072 - INFO - root - Page:2, Index:27, Starting Positions Matter: A Study on Better Weight Initialization for Neural Network Quantization, https://arxiv.org/pdf/2506.10463, 2025-06-12
2025-11-09 17:37:50,072 - INFO - root - Page:2, Index:28, AWP: Activation-Aware Weight Pruning and Quantization with Projected Gradient Descent, https://arxiv.org/pdf/2506.10205, 2025-06-11
2025-11-09 17:37:50,072 - INFO - root - Page:2, Index:29, Q-SAM2: Accurate Quantization for Segment Anything Model 2, https://arxiv.org/pdf/2506.09782, 2025-06-11
2025-11-09 17:37:50,074 - INFO - root - Page:2, Index:30, Unifying Block-wise PTQ and Distillation-based QAT for Progressive Quantization toward 2-bit Instruction-Tuned LLMs, https://arxiv.org/pdf/2506.09104, 2025-06-10
2025-11-09 17:37:50,078 - INFO - root - Page:2, Index:31, Implementing Keyword Spotting on the MCUX947 Microcontroller with Integrated NPU, https://arxiv.org/pdf/2506.08911, 2025-06-10
2025-11-09 17:37:50,081 - INFO - root - Page:2, Index:32, POLARON: Precision-aware On-device Learning and Adaptive Runtime-cONfigurable AI acceleration, https://arxiv.org/pdf/2506.08785, 2025-06-10
2025-11-09 17:37:50,084 - INFO - root - Page:2, Index:33, MoQAE: Mixed-Precision Quantization for Long-Context LLM Inference via Mixture of Quantization-Aware Experts, https://arxiv.org/pdf/2506.07533, 2025-06-09
2025-11-09 17:37:50,088 - INFO - root - Page:2, Index:34, BitVLA: 1-bit Vision-Language-Action Models for Robotics Manipulation, https://arxiv.org/pdf/2506.07530, 2025-06-09
2025-11-09 17:37:50,094 - INFO - root - Page:2, Index:35, RecGPT: A Foundation Model for Sequential Recommendation, https://arxiv.org/pdf/2506.06270, 2025-06-12
2025-11-09 17:37:50,096 - INFO - root - Page:2, Index:36, FPSAttention: Training-Aware FP8 and Sparsity Co-Design for Fast Video Diffusion, https://arxiv.org/pdf/2506.04648, 2025-06-05
2025-11-09 17:37:50,097 - INFO - root - Page:2, Index:37, BitTTS: Highly Compact Text-to-Speech Using 1.58-bit Quantization and Weight Indexing, https://arxiv.org/pdf/2506.03515, 2025-06-03
2025-11-09 17:37:50,098 - INFO - root - Page:2, Index:38, ShapeLLM-Omni: A Native Multimodal LLM for 3D Generation and Understanding, https://arxiv.org/pdf/2506.01853, 2025-06-02
2025-11-09 17:37:50,098 - INFO - root - Page:2, Index:39, Movable Antenna Enhanced Federated Fine-Tuning of Large Language Models via Hybrid Client Selection Optimization, https://arxiv.org/pdf/2506.00011, 2025-10-26
2025-11-09 17:37:50,114 - INFO - root - Page:2, Index:40, Running Conventional Automatic Speech Recognition on Memristor Hardware: A Simulated Approach, https://arxiv.org/pdf/2505.24721, 2025-05-30
2025-11-09 17:37:50,119 - INFO - root - Page:2, Index:41, GARLIC: GAussian Representation LearnIng for spaCe partitioning, https://arxiv.org/pdf/2505.24608, 2025-10-02
2025-11-09 17:37:50,121 - INFO - root - Page:2, Index:42, AutoChemSchematic AI: Agentic Physics-Aware Automation for Chemical Manufacturing Scale-Up, https://arxiv.org/pdf/2505.24584, 2025-08-18
2025-11-09 17:37:50,122 - INFO - root - Page:2, Index:43, Model-Preserving Adaptive Rounding, https://arxiv.org/pdf/2505.22988, 2025-09-25
2025-11-09 17:37:50,123 - INFO - root - Page:2, Index:44, Highly Efficient and Effective LLMs with Multi-Boolean Architectures, https://arxiv.org/pdf/2505.22811, 2025-10-03
2025-11-09 17:37:50,123 - INFO - root - Page:2, Index:45, Pioneering 4-Bit FP Quantization for Diffusion Models: Mixup-Sign Quantization and Timestep-Aware Fine-Tuning, https://arxiv.org/pdf/2505.21591, 2025-05-27
2025-11-09 17:37:50,123 - INFO - root - Page:2, Index:46, Frequency Composition for Compressed and Domain-Adaptive Neural Networks, https://arxiv.org/pdf/2505.20890, 2025-05-27
2025-11-09 17:37:50,124 - INFO - root - Page:2, Index:47, MoPFormer: Motion-Primitive Transformer for Wearable-Sensor Activity Recognition, https://arxiv.org/pdf/2505.20744, 2025-10-27
2025-11-09 17:37:50,125 - INFO - root - Page:2, Index:48, Optimizing edge AI models on HPC systems with the edge in the loop, https://arxiv.org/pdf/2505.19995, 2025-05-26
2025-11-09 17:37:50,126 - INFO - root - Fetching page 4 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=150
2025-11-09 17:38:07,293 - INFO - root - get_all_titles_from_web 
2025-11-09 17:38:07,294 - INFO - root - Page:3, Index:0, DPASyn: Mechanism-Aware Drug Synergy Prediction via Dual Attention and Precision-Aware Quantization, https://arxiv.org/pdf/2505.19144, 2025-09-20
2025-11-09 17:38:07,294 - INFO - root - Page:3, Index:1, Reducing Storage of Pretrained Neural Networks by Rate-Constrained Quantization and Entropy Coding, https://arxiv.org/pdf/2505.18758, 2025-05-24
2025-11-09 17:38:07,294 - INFO - root - Page:3, Index:2, Beyond Discreteness: Finite-Sample Analysis of Straight-Through Estimator for Quantization, https://arxiv.org/pdf/2505.18113, 2025-05-23
2025-11-09 17:38:07,295 - INFO - root - Page:3, Index:3, Automating Versatile Time-Series Analysis with Tiny Transformers on Embedded FPGAs, https://arxiv.org/pdf/2505.17662, 2025-09-19
2025-11-09 17:38:07,295 - INFO - root - Page:3, Index:4, FPQVAR: Floating Point Quantization for Visual Autoregressive Model with FPGA Hardware Co-design, https://arxiv.org/pdf/2505.16335, 2025-05-22
2025-11-09 17:38:07,295 - INFO - root - Page:3, Index:5, Saliency-Aware Quantized Imitation Learning for Efficient Robotic Control, https://arxiv.org/pdf/2505.15304, 2025-05-30
2025-11-09 17:38:07,296 - INFO - root - Page:3, Index:6, Scaling Law for Quantization-Aware Training, https://arxiv.org/pdf/2505.14302, 2025-05-20
2025-11-09 17:38:07,296 - INFO - root - Page:3, Index:7, Automatic mixed precision for optimizing gained time with constrained loss mean-squared-error based on model partition to sequential sub-graphs, https://arxiv.org/pdf/2505.13060, 2025-05-19
2025-11-09 17:38:07,296 - INFO - root - Page:3, Index:8, Deep Unfolding with Kernel-based Quantization in MIMO Detection, https://arxiv.org/pdf/2505.12736, 2025-05-19
2025-11-09 17:38:07,297 - INFO - root - Page:3, Index:9, FedHQ: Hybrid Runtime Quantization for Federated Learning, https://arxiv.org/pdf/2505.11982, 2025-05-17
2025-11-09 17:38:07,297 - INFO - root - Page:3, Index:10, QVGen: Pushing the Limit of Quantized Video Generative Models, https://arxiv.org/pdf/2505.11497, 2025-09-27
2025-11-09 17:38:07,297 - INFO - root - Page:3, Index:11, EA-3DGS: Efficient and Adaptive 3D Gaussians with Highly Enhanced Quality for outdoor scenes, https://arxiv.org/pdf/2505.10787, 2025-05-15
2025-11-09 17:38:07,297 - INFO - root - Page:3, Index:12, ITERA-LLM: Boosting Sub-8-Bit Large Language Model Inference via Iterative Tensor Decomposition, https://arxiv.org/pdf/2505.08981, 2025-05-13
2025-11-09 17:38:07,298 - INFO - root - Page:3, Index:13, PROM: Prioritize Reduction of Multiplications Over Lower Bit-Widths for Efficient CNNs, https://arxiv.org/pdf/2505.03254, 2025-08-06
2025-11-09 17:38:07,298 - INFO - root - Page:3, Index:14, ICQuant: Index Coding enables Low-bit LLM Quantization, https://arxiv.org/pdf/2505.00850, 2025-08-24
2025-11-09 17:38:07,298 - INFO - root - Page:3, Index:15, Enhancing Ultra-Low-Bit Quantization of Large Language Models Through Saliency-Aware Partial Retraining, https://arxiv.org/pdf/2504.13932, 2025-07-30
2025-11-09 17:38:07,298 - INFO - root - Page:3, Index:16, Achieving binary weight and activation for LLMs using Post-Training Quantization, https://arxiv.org/pdf/2504.05352, 2025-06-30
2025-11-09 17:38:07,299 - INFO - root - Page:3, Index:17, Wireless Hearables With Programmable Speech AI Accelerators, https://arxiv.org/pdf/2503.18698, 2025-10-21
2025-11-09 17:38:07,299 - INFO - root - Page:3, Index:18, GranQ: Efficient Channel-wise Quantization via Vectorized Pre-Scaling for Zero-Shot QAT, https://arxiv.org/pdf/2503.18339, 2025-10-15
2025-11-09 17:38:07,300 - INFO - root - Page:3, Index:19, CompMarkGS: Robust Watermarking for Compressed 3D Gaussian Splatting, https://arxiv.org/pdf/2503.12836, 2025-09-29
2025-11-09 17:38:07,300 - INFO - root - Page:3, Index:20, AHCPTQ: Accurate and Hardware-Compatible Post-Training Quantization for Segment Anything Model, https://arxiv.org/pdf/2503.03088, 2025-07-11
2025-11-09 17:38:07,302 - INFO - root - Page:3, Index:21, Teaching Metric Distance to Discrete Autoregressive Language Models, https://arxiv.org/pdf/2503.02379, 2025-10-07
2025-11-09 17:38:07,303 - INFO - root - Page:3, Index:22, Regularization-based Framework for Quantization-, Fault- and Variability-Aware Training, https://arxiv.org/pdf/2503.01297, 2025-07-12
2025-11-09 17:38:07,303 - INFO - root - Fetching page 5 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=200
2025-11-09 17:38:12,599 - INFO - root - get_all_titles_from_web 
2025-11-09 17:38:12,600 - INFO - root - Page:4, Index:0, Investigating the Impact of Quantization Methods on the Safety and Reliability of Large Language Models, https://arxiv.org/pdf/2502.15799, 2025-06-29
2025-11-09 17:38:12,600 - INFO - root - Page:4, Index:1, Rotate, Clip, and Partition: Towards W2A4KV4 Quantization by Integrating Rotation and Learnable Non-uniform Quantizer, https://arxiv.org/pdf/2502.15779, 2025-09-01
2025-11-09 17:38:12,601 - INFO - root - Page:4, Index:2, RoSTE: An Efficient Quantization-Aware Supervised Fine-Tuning Approach for Large Language Models, https://arxiv.org/pdf/2502.09003, 2025-06-05
2025-11-09 17:38:12,601 - INFO - root - Page:4, Index:3, Spatial Degradation-Aware and Temporal Consistent Diffusion Model for Compressed Video Super-Resolution, https://arxiv.org/pdf/2502.07381, 2025-06-27
2025-11-09 17:38:12,601 - INFO - root - Page:4, Index:4, QuEST: Stable Training of LLMs with 1-Bit Weights and Activations, https://arxiv.org/pdf/2502.05003, 2025-06-10
2025-11-09 17:38:12,601 - INFO - root - Page:4, Index:5, HALO: Hadamard-Assisted Lower-Precision Optimization for LLMs, https://arxiv.org/pdf/2501.02625, 2025-11-05
2025-11-09 17:38:12,602 - INFO - root - Page:4, Index:6, TAR3D: Creating High-Quality 3D Assets via Next-Part Prediction, https://arxiv.org/pdf/2412.16919, 2025-08-08
2025-11-09 17:38:12,602 - INFO - root - Page:4, Index:7, Training Multi-Layer Binary Neural Networks With Local Binary Error Signals, https://arxiv.org/pdf/2412.00119, 2025-08-05
2025-11-09 17:38:12,602 - INFO - root - Page:4, Index:8, Scaling Large-scale GNN Training to Thousands of Processors on CPU-based Supercomputers, https://arxiv.org/pdf/2411.16025, 2025-05-26
2025-11-09 17:38:12,602 - INFO - root - Page:4, Index:9, HAFLQ: Heterogeneous Adaptive Federated LoRA Fine-tuned LLM with Quantization, https://arxiv.org/pdf/2411.06581, 2025-05-16
2025-11-09 17:38:12,604 - INFO - root - Fetching page 6 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=250
2025-11-09 17:38:25,080 - INFO - root - get_all_titles_from_web 
2025-11-09 17:38:25,082 - INFO - root - Page:5, Index:0, Gradient-Free Training of Quantized Neural Networks, https://arxiv.org/pdf/2410.09734, 2025-09-29
2025-11-09 17:38:25,082 - INFO - root - Page:5, Index:1, QT-DoG: Quantization-aware Training for Domain Generalization, https://arxiv.org/pdf/2410.06020, 2025-06-26
2025-11-09 17:38:25,083 - INFO - root - Page:5, Index:2, Constraint Guided Model Quantization of Neural Networks, https://arxiv.org/pdf/2409.20138, 2025-09-12
2025-11-09 17:38:25,083 - INFO - root - Page:5, Index:3, Accumulator-Aware Post-Training Quantization for Large Language Models, https://arxiv.org/pdf/2409.17092, 2025-07-30
2025-11-09 17:38:25,084 - INFO - root - Page:5, Index:4, DilateQuant: Accurate and Efficient Diffusion Quantization via Weight Dilation, https://arxiv.org/pdf/2409.14307, 2025-07-09
2025-11-09 17:38:25,086 - INFO - root - Page:5, Index:5, Robust Training of Neural Networks at Arbitrary Precision and Sparsity, https://arxiv.org/pdf/2409.09245, 2025-09-23
2025-11-09 17:38:25,116 - INFO - root - Page:5, Index:6, VQ-CTAP: Cross-Modal Fine-Grained Sequence Representation Learning for Speech Processing, https://arxiv.org/pdf/2408.05758, 2025-05-27
2025-11-09 17:38:25,140 - INFO - root - Page:5, Index:7, DopQ-ViT: Towards Distribution-Friendly and Outlier-Aware Post-Training Quantization for Vision Transformers, https://arxiv.org/pdf/2408.03291, 2025-06-19
2025-11-09 17:38:25,174 - INFO - root - Page:5, Index:8, Temporal Feature Matters: A Framework for Diffusion Model Quantization, https://arxiv.org/pdf/2407.19547, 2025-07-11
2025-11-09 17:38:25,208 - INFO - root - Page:5, Index:9, EfficientQAT: Efficient Quantization-Aware Training for Large Language Models, https://arxiv.org/pdf/2407.11062, 2025-05-19
2025-11-09 17:38:25,260 - INFO - root - Page:5, Index:10, Integer-only Quantized Transformers for Embedded FPGA-based Time-series Forecasting in AIoT, https://arxiv.org/pdf/2407.11041, 2025-10-31
2025-11-09 17:38:25,361 - INFO - root - Fetching page 7 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=300
2025-11-09 17:39:04,384 - INFO - root - get_all_titles_from_web 
2025-11-09 17:39:04,385 - INFO - root - Page:6, Index:0, BoA: Attention-aware Post-training Quantization without Backpropagation, https://arxiv.org/pdf/2406.13474, 2025-06-06
2025-11-09 17:39:04,386 - INFO - root - Page:6, Index:1, A Rescaling-Invariant Lipschitz Bound Based on Path-Metrics for Modern ReLU Network Parameterizations, https://arxiv.org/pdf/2405.15006, 2025-06-13
2025-11-09 17:39:04,386 - INFO - root - Page:6, Index:2, Scheduling Weight Transitions for Quantization-Aware Training, https://arxiv.org/pdf/2404.19248, 2025-10-01
2025-11-09 17:39:04,387 - INFO - root - Page:6, Index:3, GPTVQ: The Blessing of Dimensionality for LLM Quantization, https://arxiv.org/pdf/2402.15319, 2025-06-03
2025-11-09 17:39:04,392 - INFO - root - Fetching page 8 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=350
2025-11-09 17:39:32,163 - INFO - root - get_all_titles_from_web 
2025-11-09 17:39:32,163 - INFO - root - Page:7, Index:0, Squat: Quant Small Language Models on the Edge, https://arxiv.org/pdf/2402.10787, 2025-07-01
2025-11-09 17:39:32,163 - INFO - root - Page:7, Index:1, L4Q: Parameter Efficient Quantization-Aware Fine-Tuning on Large Language Models, https://arxiv.org/pdf/2402.04902, 2025-07-21
2025-11-09 17:39:32,164 - INFO - root - Fetching page 9 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=400
2025-11-09 17:39:50,822 - INFO - root - ------------------------------------------------------------------------------------------------------------------------
2025-11-09 19:30:28,901 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-09 19:30:28,903 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-09 19:30:28,907 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-09 19:31:20,197 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-09 19:31:20,198 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-09 19:31:20,204 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-09 19:31:21,363 - INFO - root - LLMClientManager: 指定使用客户端: Doubao
2025-11-09 19:31:21,366 - INFO - root - DoubaoClient: API key found: 9f9e270e-b...
2025-11-09 19:31:25,824 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 19:31:25,870 - INFO - root - DoubaoClient: initialized successfully with model doubao-seed-1-6-lite-251015
2025-11-09 19:31:25,871 - INFO - root - LLMClientManager: Doubao 客户端初始化成功
2025-11-09 19:31:25,871 - INFO - root - LLMClientManager: switched to Doubao client
2025-11-09 19:31:25,871 - INFO - root - 已手动切换到 LLM 客户端: Doubao
2025-11-09 19:31:25,873 - INFO - root - 使用 LLM 模型: doubao-seed-1-6-lite-251015
2025-11-09 19:31:25,876 - INFO - root - 可用客户端: ['Doubao']
2025-11-09 19:31:25,877 - INFO - root - === 运行配置 ===
2025-11-09 19:31:25,877 - INFO - root - 处理模式: arxiv在线搜索
2025-11-09 19:31:25,877 - INFO - root - 关键词: hp
2025-11-09 19:31:25,877 - INFO - root - 查询: high pressure selenium
2025-11-09 19:31:25,877 - INFO - root - 排序: None
2025-11-09 19:31:25,879 - INFO - root - 最近天数: 180
2025-11-09 19:31:25,879 - INFO - root - 最大处理数量: 2
2025-11-09 19:31:25,881 - INFO - root - 保存图片: 是
2025-11-09 19:31:25,882 - INFO - root - 输出语言: 中文
2025-11-09 19:31:25,882 - INFO - root - 强制重新处理: 否
2025-11-09 19:31:25,882 - INFO - root - ====================
2025-11-09 19:31:25,883 - INFO - root - 使用 arXiv 搜索模式（通过 chat_arxiv 模块获取）
2025-11-09 19:31:25,883 - INFO - root - Fetching page 1 with URL: https://arxiv.org/search/?query=high+pressure+selenium&searchtype=all&abstracts=show&order=-announced_date_first&size=50
2025-11-09 19:31:31,884 - INFO - root - ------------------------------------------------------------------------------------------------------------------------
2025-11-09 19:31:31,884 - INFO - root - 没有找到要处理的论文，程序退出
2025-11-09 19:31:31,885 - INFO - root - summary time: 11.69 seconds
2025-11-09 19:42:52,555 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-09 19:42:52,558 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-09 19:42:52,559 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-09 19:42:53,724 - INFO - root - LLMClientManager: 指定使用客户端: Deepseek
2025-11-09 19:42:53,725 - INFO - root - DeepSeekClient: API key found: your_deeps...
2025-11-09 19:42:53,726 - INFO - root - DeepSeekClient: 使用模式: 直接API
2025-11-09 19:42:53,727 - WARNING - root - DeepSeekClient: API key not provided or using placeholder. LLM disabled.
2025-11-09 19:42:53,727 - ERROR - root - LLMClientManager: 指定的客户端 DeepSeek 初始化失败
2025-11-09 19:42:53,728 - WARNING - root - LLMClientManager: 指定的客户端 Deepseek 不可用，将尝试其他客户端
2025-11-09 19:42:54,520 - INFO - root - GeminiClient: trying model gemini-2.5-flash
2025-11-09 19:44:04,414 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-09 19:44:04,416 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-09 19:44:04,419 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-09 19:44:07,571 - INFO - root - LLMClientManager: 指定使用客户端: Deepseek
2025-11-09 19:44:07,572 - INFO - root - DeepSeekClient: API key found: your_deeps...
2025-11-09 19:44:07,573 - INFO - root - DeepSeekClient: 使用模式: 直接API
2025-11-09 19:44:07,573 - WARNING - root - DeepSeekClient: API key not provided or using placeholder. LLM disabled.
2025-11-09 19:44:07,574 - ERROR - root - LLMClientManager: 指定的客户端 DeepSeek 初始化失败
2025-11-09 19:44:07,574 - WARNING - root - LLMClientManager: 指定的客户端 Deepseek 不可用，将尝试其他客户端
2025-11-09 19:44:08,406 - INFO - root - GeminiClient: trying model gemini-2.5-flash
2025-11-09 19:44:11,267 - INFO - root - GeminiClient: initialized model gemini-2.5-flash
2025-11-09 19:44:11,269 - INFO - root - LLMClientManager: Gemini client initialized successfully
2025-11-09 19:44:11,269 - INFO - root - LLMClientManager: using Gemini as default client
2025-11-09 19:44:11,270 - WARNING - root - KimiClient: API key not provided. LLM disabled.
2025-11-09 19:44:11,271 - WARNING - root - LLMClientManager: Kimi client initialization failed
2025-11-09 19:44:11,272 - WARNING - root - QwenClient: API key not provided. LLM disabled.
2025-11-09 19:44:11,272 - WARNING - root - LLMClientManager: Qwen client initialization failed
2025-11-09 19:44:11,282 - INFO - root - DoubaoClient: API key found: 9f9e270e-b...
2025-11-09 19:44:19,859 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 19:44:19,910 - INFO - root - DoubaoClient: initialized successfully with model doubao-seed-1-6-lite-251015
2025-11-09 19:44:19,910 - INFO - root - LLMClientManager: Doubao client initialized successfully
2025-11-09 19:44:19,910 - WARNING - root - LLMClientManager: client Deepseek not available
2025-11-09 19:44:19,911 - WARNING - root - 无法切换到指定的客户端 Deepseek，将使用默认客户端
2025-11-09 19:44:19,911 - INFO - root - 可用客户端: ['Gemini', 'Doubao']
2025-11-09 19:44:19,912 - INFO - root - 使用 LLM 模型: gemini-2.5-flash
2025-11-09 19:44:19,912 - INFO - root - 可用客户端: ['Gemini', 'Doubao']
2025-11-09 19:44:19,913 - INFO - root - === 运行配置 ===
2025-11-09 19:44:19,914 - INFO - root - 处理模式: arxiv在线搜索
2025-11-09 19:44:19,914 - INFO - root - 关键词: QAT
2025-11-09 19:44:19,914 - INFO - root - 查询: Quantization-Aware-Training
2025-11-09 19:44:19,915 - INFO - root - 排序: None
2025-11-09 19:44:19,917 - INFO - root - 最近天数: 180
2025-11-09 19:44:19,919 - INFO - root - 最大处理数量: 2
2025-11-09 19:44:19,922 - INFO - root - 保存图片: 是
2025-11-09 19:44:19,924 - INFO - root - 输出语言: 中文
2025-11-09 19:44:19,925 - INFO - root - 强制重新处理: 否
2025-11-09 19:44:19,925 - INFO - root - ====================
2025-11-09 19:44:19,927 - INFO - root - 使用 arXiv 搜索模式（通过 chat_arxiv 模块获取）
2025-11-09 19:44:19,928 - INFO - root - Fetching page 1 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50
2025-11-09 19:44:26,277 - INFO - root - get_all_titles_from_web 
2025-11-09 19:44:26,277 - INFO - root - Page:0, Index:0, A Quantized VAE-MLP Botnet Detection Model: A Systematic Evaluation of Quantization-Aware Training and Post-Training Quantization Strategies, https://arxiv.org/pdf/2511.03201, 2025-11-05
2025-11-09 19:44:26,279 - INFO - root - Page:0, Index:1, FP8-Flow-MoE: A Casting-Free FP8 Recipe without Double Quantization Error, https://arxiv.org/pdf/2511.02302, 2025-11-04
2025-11-09 19:44:26,280 - INFO - root - Page:0, Index:2, Outlier-Aware Post-Training Quantization for Image Super-Resolution, https://arxiv.org/pdf/2511.00682, 2025-11-01
2025-11-09 19:44:26,281 - INFO - root - Page:0, Index:3, Evaluation of Wafer-Scale SOT-MRAM for Analog Crossbar Array Applications, https://arxiv.org/pdf/2510.25853, 2025-11-03
2025-11-09 19:44:26,281 - INFO - root - Page:0, Index:4, Improving the Straight-Through Estimator with Zeroth-Order Information, https://arxiv.org/pdf/2510.23926, 2025-10-27
2025-11-09 19:44:26,281 - INFO - root - Page:0, Index:5, Real-Time Semantic Segmentation on FPGA for Autonomous Vehicles Using LMIINet with the CGRA4ML Framework, https://arxiv.org/pdf/2510.22243, 2025-10-25
2025-11-09 19:44:26,282 - INFO - root - Page:0, Index:6, TernaryCLIP: Efficiently Compressing Vision-Language Models with Ternary Weights and Distilled Knowledge, https://arxiv.org/pdf/2510.21879, 2025-10-23
2025-11-09 19:44:26,282 - INFO - root - Page:0, Index:7, KARIPAP: Quantum-Inspired Tensor Network Compression of Large Language Models Using Infinite Projected Entangled Pair States and Tensor Renormalization Group, https://arxiv.org/pdf/2510.21844, 2025-10-22
2025-11-09 19:44:26,283 - INFO - root - Page:0, Index:8, A Convergence Analysis of Adaptive Optimizers under Floating-point Quantization, https://arxiv.org/pdf/2510.21314, 2025-10-24
2025-11-09 19:44:26,283 - INFO - root - Page:0, Index:9, Adaptive Distribution-aware Quantization for Mixed-Precision Neural Networks, https://arxiv.org/pdf/2510.19760, 2025-10-22
2025-11-09 19:44:26,283 - INFO - root - Page:0, Index:10, CAGE: Curvature-Aware Gradient Estimation For Accurate Quantization-Aware Training, https://arxiv.org/pdf/2510.18784, 2025-10-21
2025-11-09 19:44:26,284 - INFO - root - Page:0, Index:11, Mixed-Precision Quantization for Language Models: Techniques and Prospects, https://arxiv.org/pdf/2510.16805, 2025-10-19
2025-11-09 19:44:26,284 - INFO - root - Page:0, Index:12, SPLite Hand: Sparsity-Aware Lightweight 3D Hand Pose Estimation, https://arxiv.org/pdf/2510.16396, 2025-10-30
2025-11-09 19:44:26,285 - INFO - root - Page:0, Index:13, CTR-LoRA: Curvature-Aware and Trust-Region Guided Low-Rank Adaptation for Large Language Models, https://arxiv.org/pdf/2510.15962, 2025-10-11
2025-11-09 19:44:26,285 - INFO - root - Page:0, Index:14, SANR: Scene-Aware Neural Representation for Light Field Image Compression with Rate-Distortion Optimization, https://arxiv.org/pdf/2510.15775, 2025-10-17
2025-11-09 19:44:26,286 - INFO - root - Page:0, Index:15, SpikeFit: Towards Optimal Deployment of Spiking Networks on Neuromorphic Hardware, https://arxiv.org/pdf/2510.15542, 2025-10-31
2025-11-09 19:44:26,286 - INFO - root - Page:0, Index:16, GRank: Towards Target-Aware and Streamlined Industrial Retrieval with a Generate-Rank Framework, https://arxiv.org/pdf/2510.15299, 2025-10-17
2025-11-09 19:44:26,287 - INFO - root - Page:0, Index:17, SaLon3R: Structure-aware Long-term Generalizable 3D Reconstruction from Unposed Images, https://arxiv.org/pdf/2510.15072, 2025-10-16
2025-11-09 19:44:26,288 - INFO - root - Page:0, Index:18, FraQAT: Quantization Aware Training with Fractional bits, https://arxiv.org/pdf/2510.14823, 2025-10-16
2025-11-09 19:44:26,290 - INFO - root - Page:0, Index:19, Computing-In-Memory Aware Model Adaption For Edge Devices, https://arxiv.org/pdf/2510.14379, 2025-10-16
2025-11-09 19:44:26,292 - INFO - root - Page:0, Index:20, Invited Paper: BitMedViT: Ternary-Quantized Vision Transformer for Medical AI Assistants on the Edge, https://arxiv.org/pdf/2510.13760, 2025-11-04
2025-11-09 19:44:26,292 - INFO - root - Page:0, Index:21, NeuroRVQ: Multi-Scale EEG Tokenization for Generative Large Brainwave Models, https://arxiv.org/pdf/2510.13068, 2025-10-14
2025-11-09 19:44:26,293 - INFO - root - Page:0, Index:22, Detect Anything via Next Point Prediction, https://arxiv.org/pdf/2510.12798, 2025-10-14
2025-11-09 19:44:26,294 - INFO - root - Page:0, Index:23, AndesVL Technical Report: An Efficient Mobile-side Multimodal Large Language Model, https://arxiv.org/pdf/2510.11496, 2025-10-14
2025-11-09 19:44:26,294 - INFO - root - Page:0, Index:24, Rescaling-Aware Training for Efficient Deployment of Deep Learning Models on Full-Integer Hardware, https://arxiv.org/pdf/2510.11484, 2025-10-13
2025-11-09 19:44:26,295 - INFO - root - Page:0, Index:25, SASER: Stego attacks on open-source LLMs, https://arxiv.org/pdf/2510.10486, 2025-10-12
2025-11-09 19:44:26,295 - INFO - root - Page:0, Index:26, Ultralytics YOLO Evolution: An Overview of YOLO26, YOLO11, YOLOv8 and YOLOv5 Object Detectors for Computer Vision and Pattern Recognition, https://arxiv.org/pdf/2510.09653, 2025-10-15
2025-11-09 19:44:26,296 - INFO - root - Page:0, Index:27, A Theoretically-Grounded Codebook for Digital Semantic Communications, https://arxiv.org/pdf/2510.07108, 2025-10-14
2025-11-09 19:44:26,297 - INFO - root - Page:0, Index:28, QuantDemoire: Quantization with Outlier Aware for Image Demoiréing, https://arxiv.org/pdf/2510.04066, 2025-10-05
2025-11-09 19:44:26,300 - INFO - root - Page:0, Index:29, Adaptively Sampling-Reusing-Mixing Decomposed Gradients to Speed Up Sharpness Aware Minimization, https://arxiv.org/pdf/2510.03763, 2025-10-04
2025-11-09 19:44:26,301 - INFO - root - Page:0, Index:30, Quant-dLLM: Post-Training Extreme Low-Bit Quantization for Diffusion Large Language Models, https://arxiv.org/pdf/2510.03274, 2025-09-27
2025-11-09 19:44:26,302 - INFO - root - Page:0, Index:31, PT$^2$-LLM: Post-Training Ternarization for Large Language Models, https://arxiv.org/pdf/2510.03267, 2025-09-26
2025-11-09 19:44:26,302 - INFO - root - Page:0, Index:32, Purrception: Variational Flow Matching for Vector-Quantized Image Generation, https://arxiv.org/pdf/2510.01478, 2025-10-01
2025-11-09 19:44:26,302 - INFO - root - Page:0, Index:33, Post-Training Quantization for Audio Diffusion Transformers, https://arxiv.org/pdf/2510.00313, 2025-09-30
2025-11-09 19:44:26,305 - INFO - root - Page:0, Index:34, Rethinking RoPE Scaling in Quantized LLM: Theory, Outlier, and Channel-Band Analysis with Weight Rescaling, https://arxiv.org/pdf/2510.00028, 2025-09-25
2025-11-09 19:44:26,306 - INFO - root - Page:0, Index:35, Post-Training Quantization via Residual Truncation and Zero Suppression for Diffusion Models, https://arxiv.org/pdf/2509.26436, 2025-09-30
2025-11-09 19:44:26,307 - INFO - root - Page:0, Index:36, Cat: Post-Training Quantization Error Reduction via Cluster-based Affine Transformation, https://arxiv.org/pdf/2509.26277, 2025-10-07
2025-11-09 19:44:26,308 - INFO - root - Page:0, Index:37, CAST: Continuous and Differentiable Semi-Structured Sparsity-Aware Training for Large Language Models, https://arxiv.org/pdf/2509.25996, 2025-09-30
2025-11-09 19:44:26,309 - INFO - root - Page:0, Index:38, Norm-Q: Effective Compression Method for Hidden Markov Models in Neuro-Symbolic Applications, https://arxiv.org/pdf/2509.25439, 2025-09-29
2025-11-09 19:44:26,310 - INFO - root - Page:0, Index:39, On-the-Fly Adaptation to Quantization: Configuration-Aware LoRA for Efficient Fine-Tuning of Quantized LLMs, https://arxiv.org/pdf/2509.25214, 2025-09-22
2025-11-09 19:44:26,310 - INFO - root - Page:0, Index:40, VoxCPM: Tokenizer-Free TTS for Context-Aware Speech Generation and True-to-Life Voice Cloning, https://arxiv.org/pdf/2509.24650, 2025-09-29
2025-11-09 19:44:26,311 - INFO - root - Page:0, Index:41, S$^2$NN: Sub-bit Spiking Neural Networks, https://arxiv.org/pdf/2509.24266, 2025-10-24
2025-11-09 19:44:26,311 - INFO - root - Page:0, Index:42, Tequila: Trapping-free Ternary Quantization for Large Language Models, https://arxiv.org/pdf/2509.23809, 2025-10-17
2025-11-09 19:44:26,312 - INFO - root - Page:0, Index:43, Texture Vector-Quantization and Reconstruction Aware Prediction for Generative Super-Resolution, https://arxiv.org/pdf/2509.23774, 2025-09-30
2025-11-09 19:44:26,312 - INFO - root - Page:0, Index:44, RobuQ: Pushing DiTs to W1.58A2 via Robust Activation Quantization, https://arxiv.org/pdf/2509.23582, 2025-09-27
2025-11-09 19:44:26,313 - INFO - root - Page:0, Index:45, Beyond Outliers: A Study of Optimizers Under Quantization, https://arxiv.org/pdf/2509.23500, 2025-10-02
2025-11-09 19:44:26,313 - INFO - root - Page:0, Index:46, Compute-Optimal Quantization-Aware Training, https://arxiv.org/pdf/2509.22935, 2025-09-26
2025-11-09 19:44:26,314 - INFO - root - Page:0, Index:47, COSPADI: Compressing LLMs via Calibration-Guided Sparse Dictionary Learning, https://arxiv.org/pdf/2509.22075, 2025-10-06
2025-11-09 19:44:26,314 - INFO - root - Page:0, Index:48, SlimDiff: Training-Free, Activation-Guided Hands-free Slimming of Diffusion Models, https://arxiv.org/pdf/2509.21498, 2025-09-25
2025-11-09 19:44:26,314 - INFO - root - Page:0, Index:49, Quantized Visual Geometry Grounded Transformer, https://arxiv.org/pdf/2509.21302, 2025-09-29
2025-11-09 19:44:26,316 - INFO - root - Fetching page 2 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=50
2025-11-09 19:44:36,067 - INFO - root - get_all_titles_from_web 
2025-11-09 19:44:36,068 - INFO - root - Page:1, Index:0, Can Less Precise Be More Reliable? A Systematic Evaluation of Quantization's Impact on CLIP Beyond Accuracy, https://arxiv.org/pdf/2509.21173, 2025-10-27
2025-11-09 19:44:36,069 - INFO - root - Page:1, Index:1, Punching Above Precision: Small Quantized Model Distillation with Learnable Regularizer, https://arxiv.org/pdf/2509.20854, 2025-09-25
2025-11-09 19:44:36,069 - INFO - root - Page:1, Index:2, TinyEcoWeedNet: Edge Efficient Real-Time Aerial Agricultural Weed Detection, https://arxiv.org/pdf/2509.18193, 2025-09-19
2025-11-09 19:44:36,070 - INFO - root - Page:1, Index:3, SBVR: Summation of BitVector Representation for Efficient LLM Quantization, https://arxiv.org/pdf/2509.18172, 2025-09-17
2025-11-09 19:44:36,070 - INFO - root - Page:1, Index:4, QWHA: Quantization-Aware Walsh-Hadamard Adaptation for Parameter-Efficient Fine-Tuning on Large Language Models, https://arxiv.org/pdf/2509.17428, 2025-09-26
2025-11-09 19:44:36,071 - INFO - root - Page:1, Index:5, PTQTP: Post-Training Quantization to Trit-Planes for Large Language Models, https://arxiv.org/pdf/2509.16989, 2025-10-28
2025-11-09 19:44:36,071 - INFO - root - Page:1, Index:6, MEC-Quant: Maximum Entropy Coding for Extremely Low Bit Quantization-Aware Training, https://arxiv.org/pdf/2509.15514, 2025-09-18
2025-11-09 19:44:36,071 - INFO - root - Page:1, Index:7, Q-ROAR: Outlier-Aware Rescaling for RoPE Position Interpolation in Quantized Long-Context LLMs, https://arxiv.org/pdf/2509.14391, 2025-09-17
2025-11-09 19:44:36,076 - INFO - root - Page:1, Index:8, Efficient Quantization-Aware Neural Receivers: Beyond Post-Training Quantization, https://arxiv.org/pdf/2509.13786, 2025-09-19
2025-11-09 19:44:36,077 - INFO - root - Page:1, Index:9, Rate-Distortion Limits for Multimodal Retrieval: Theory, Optimal Codes, and Finite-Sample Guarantees, https://arxiv.org/pdf/2509.11054, 2025-09-13
2025-11-09 19:44:36,078 - INFO - root - Page:1, Index:10, SQAP-VLA: A Synergistic Quantization-Aware Pruning Framework for High-Performance Vision-Language-Action Models, https://arxiv.org/pdf/2509.09090, 2025-09-10
2025-11-09 19:44:36,078 - INFO - root - Page:1, Index:11, CSI Compression Beyond Latents: End-to-End Hybrid Attention-CNN Networks with Entropy Regularization, https://arxiv.org/pdf/2509.08776, 2025-09-10
2025-11-09 19:44:36,079 - INFO - root - Page:1, Index:12, Explaining How Quantization Disparately Skews a Model, https://arxiv.org/pdf/2509.07222, 2025-09-08
2025-11-09 19:44:36,079 - INFO - root - Page:1, Index:13, LoaQ: Layer-wise Output Approximation Quantization, https://arxiv.org/pdf/2509.06297, 2025-09-07
2025-11-09 19:44:36,080 - INFO - root - Page:1, Index:14, FineServe: Precision-Aware KV Slab and Two-Level Scheduling for Heterogeneous Precision LLM Serving, https://arxiv.org/pdf/2509.06261, 2025-09-14
2025-11-09 19:44:36,081 - INFO - root - Page:1, Index:15, Sensitivity-Aware Post-Training Quantization for Deep Neural Networks, https://arxiv.org/pdf/2509.05576, 2025-09-05
2025-11-09 19:44:36,082 - INFO - root - Page:1, Index:16, SuperSNN: A Hardware-Aware Framework for Physically Realizable, High-Performance Superconducting Spiking Neural Network Chips, https://arxiv.org/pdf/2509.05532, 2025-09-05
2025-11-09 19:44:36,084 - INFO - root - Page:1, Index:17, Data-Augmented Quantization-Aware Knowledge Distillation, https://arxiv.org/pdf/2509.03850, 2025-09-03
2025-11-09 19:44:36,085 - INFO - root - Page:1, Index:18, DPQuant: Efficient and Differentially-Private Model Training via Dynamic Quantization Scheduling, https://arxiv.org/pdf/2509.03472, 2025-09-03
2025-11-09 19:44:36,086 - INFO - root - Page:1, Index:19, Empowering Large Language Model for Sequential Recommendation via Multimodal Embeddings and Semantic IDs, https://arxiv.org/pdf/2509.02017, 2025-09-02
2025-11-09 19:44:36,086 - INFO - root - Page:1, Index:20, Q-Sched: Pushing the Boundaries of Few-Step Diffusion Models with Quantization-Aware Scheduling, https://arxiv.org/pdf/2509.01624, 2025-09-01
2025-11-09 19:44:36,087 - INFO - root - Page:1, Index:21, Quantization Meets OOD: Generalizable Quantization-aware Training from a Flatness Perspective, https://arxiv.org/pdf/2509.00859, 2025-08-31
2025-11-09 19:44:36,087 - INFO - root - Page:1, Index:22, Progressive Element-wise Gradient Estimation for Neural Network Quantization, https://arxiv.org/pdf/2509.00097, 2025-08-27
2025-11-09 19:44:36,088 - INFO - root - Page:1, Index:23, End-to-End On-Device Quantization-Aware Training for LLMs at Inference Cost, https://arxiv.org/pdf/2509.00031, 2025-09-29
2025-11-09 19:44:36,089 - INFO - root - Page:1, Index:24, Quantization Robustness to Input Degradations for Object Detection, https://arxiv.org/pdf/2508.19600, 2025-08-27
2025-11-09 19:44:36,090 - INFO - root - Page:1, Index:25, Scaling Laws for Task-Stratified Knowledge in Post-Training Quantized Large Language Models, https://arxiv.org/pdf/2508.18609, 2025-08-27
2025-11-09 19:44:36,091 - INFO - root - Page:1, Index:26, AQ-PCDSys: An Adaptive Quantized Planetary Crater Detection System for Autonomous Space Exploration, https://arxiv.org/pdf/2508.18025, 2025-08-25
2025-11-09 19:44:36,091 - INFO - root - Page:1, Index:27, TaDiCodec: Text-aware Diffusion Speech Tokenizer for Speech Language Modeling, https://arxiv.org/pdf/2508.16790, 2025-08-22
2025-11-09 19:44:36,092 - INFO - root - Page:1, Index:28, A Node-Aware Dynamic Quantization Approach for Graph Collaborative Filtering, https://arxiv.org/pdf/2508.16516, 2025-08-22
2025-11-09 19:44:36,093 - INFO - root - Page:1, Index:29, JEDI-linear: Fast and Efficient Graph Neural Networks for Jet Tagging on FPGAs, https://arxiv.org/pdf/2508.15468, 2025-08-21
2025-11-09 19:44:36,094 - INFO - root - Page:1, Index:30, MMQ: Multimodal Mixture-of-Quantization Tokenization for Semantic ID Generation and User Behavioral Adaptation, https://arxiv.org/pdf/2508.15281, 2025-08-21
2025-11-09 19:44:36,094 - INFO - root - Page:1, Index:31, DLLMQuant: Quantizing Diffusion-based Large Language Models, https://arxiv.org/pdf/2508.14090, 2025-08-25
2025-11-09 19:44:36,096 - INFO - root - Page:1, Index:32, Automated Energy-Aware Time-Series Model Deployment on Embedded FPGAs for Resilient Combined Sewer Overflow Management, https://arxiv.org/pdf/2508.13905, 2025-08-19
2025-11-09 19:44:36,106 - INFO - root - Page:1, Index:33, XR-NPE: High-Throughput Mixed-precision SIMD Neural Processing Engine for Extended Reality Perception Workloads, https://arxiv.org/pdf/2508.13049, 2025-08-18
2025-11-09 19:44:36,107 - INFO - root - Page:1, Index:34, Exploring Self-Supervised Audio Models for Generalized Anomalous Sound Detection, https://arxiv.org/pdf/2508.12230, 2025-08-17
2025-11-09 19:44:36,107 - INFO - root - Page:1, Index:35, TriQDef: Disrupting Semantic and Gradient Alignment to Prevent Adversarial Patch Transferability in Quantized Neural Networks, https://arxiv.org/pdf/2508.12132, 2025-08-16
2025-11-09 19:44:36,107 - INFO - root - Page:1, Index:36, Error Propagation Mechanisms and Compensation Strategies for Quantized Diffusion, https://arxiv.org/pdf/2508.12094, 2025-10-13
2025-11-09 19:44:36,108 - INFO - root - Page:1, Index:37, Extending Straight-Through Estimation for Robust Neural Networks on Analog CIM Hardware, https://arxiv.org/pdf/2508.11940, 2025-08-16
2025-11-09 19:44:36,108 - INFO - root - Page:1, Index:38, PTQAT: A Hybrid Parameter-Efficient Quantization Algorithm for 3D Perception Tasks, https://arxiv.org/pdf/2508.10557, 2025-08-15
2025-11-09 19:44:36,108 - INFO - root - Page:1, Index:39, MiCo: End-to-End Mixed Precision Neural Network Co-Exploration Framework for Edge AI, https://arxiv.org/pdf/2508.09500, 2025-08-13
2025-11-09 19:44:36,109 - INFO - root - Page:1, Index:40, SPARC: Soft Probabilistic Adaptive multi-interest Retrieval Model via Codebooks for recommender system, https://arxiv.org/pdf/2508.09090, 2025-08-12
2025-11-09 19:44:36,109 - INFO - root - Page:1, Index:41, Rethinking 1-bit Optimization Leveraging Pre-trained Large Language Models, https://arxiv.org/pdf/2508.06974, 2025-08-09
2025-11-09 19:44:36,110 - INFO - root - Page:1, Index:42, Efficient Deep Neural Receiver with Post-Training Quantization, https://arxiv.org/pdf/2508.06275, 2025-08-08
2025-11-09 19:44:36,110 - INFO - root - Page:1, Index:43, iFairy: the First 2-bit Complex LLM with All Parameters in $\{\pm1, \pm i\}$, https://arxiv.org/pdf/2508.05571, 2025-08-16
2025-11-09 19:44:36,111 - INFO - root - Page:1, Index:44, S$^2$Q-VDiT: Accurate Quantized Video Diffusion Transformer with Salient Data and Sparse Token Distillation, https://arxiv.org/pdf/2508.04016, 2025-10-27
2025-11-09 19:44:36,111 - INFO - root - Page:1, Index:45, LRQ-DiT: Log-Rotation Post-Training Quantization of Diffusion Transformers for Image and Video Generation, https://arxiv.org/pdf/2508.03485, 2025-09-23
2025-11-09 19:44:36,112 - INFO - root - Page:1, Index:46, VLMQ: Efficient Post-Training Quantization for Large Vision-Language Models via Hessian Augmentation, https://arxiv.org/pdf/2508.03351, 2025-08-05
2025-11-09 19:44:36,113 - INFO - root - Page:1, Index:47, TF-MLPNet: Tiny Real-Time Neural Speech Separation, https://arxiv.org/pdf/2508.03047, 2025-08-04
2025-11-09 19:44:36,113 - INFO - root - Page:1, Index:48, SaviorRec: Semantic-Behavior Alignment for Cold-Start Recommendation, https://arxiv.org/pdf/2508.01375, 2025-08-02
2025-11-09 19:44:36,114 - INFO - root - Page:1, Index:49, MixA-Q: Revisiting Activation Sparsity for Vision Transformers from a Mixed-Precision Quantization Perspective, https://arxiv.org/pdf/2507.19131, 2025-07-25
2025-11-09 19:44:36,114 - INFO - root - Fetching page 3 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=100
2025-11-09 19:44:42,546 - INFO - root - get_all_titles_from_web 
2025-11-09 19:44:42,546 - INFO - root - Page:2, Index:0, Enhancing Quantization-Aware Training on Edge Devices via Relative Entropy Coreset Selection and Cascaded Layer Correction, https://arxiv.org/pdf/2507.17768, 2025-07-16
2025-11-09 19:44:42,547 - INFO - root - Page:2, Index:1, SiLQ: Simple Large Language Model Quantization-Aware Training, https://arxiv.org/pdf/2507.16933, 2025-07-22
2025-11-09 19:44:42,547 - INFO - root - Page:2, Index:2, Task-Specific Zero-shot Quantization-Aware Training for Object Detection, https://arxiv.org/pdf/2507.16782, 2025-07-22
2025-11-09 19:44:42,548 - INFO - root - Page:2, Index:3, TorchAO: PyTorch-Native Training-to-Serving Model Optimization, https://arxiv.org/pdf/2507.16099, 2025-07-21
2025-11-09 19:44:42,548 - INFO - root - Page:2, Index:4, SegQuant: A Semantics-Aware and Generalizable Quantization Framework for Diffusion Models, https://arxiv.org/pdf/2507.14811, 2025-08-27
2025-11-09 19:44:42,549 - INFO - root - Page:2, Index:5, Apple Intelligence Foundation Language Models: Tech Report 2025, https://arxiv.org/pdf/2507.13575, 2025-08-27
2025-11-09 19:44:42,549 - INFO - root - Page:2, Index:6, Generative Multi-Target Cross-Domain Recommendation, https://arxiv.org/pdf/2507.12871, 2025-08-07
2025-11-09 19:44:42,550 - INFO - root - Page:2, Index:7, DAF: An Efficient End-to-End Dynamic Activation Framework for on-Device DNN Training, https://arxiv.org/pdf/2507.07149, 2025-07-09
2025-11-09 19:44:42,550 - INFO - root - Page:2, Index:8, Opto-ViT: Architecting a Near-Sensor Region of Interest-Aware Vision Transformer Accelerator with Silicon Photonics, https://arxiv.org/pdf/2507.07044, 2025-07-15
2025-11-09 19:44:42,550 - INFO - root - Page:2, Index:9, QS4D: Quantization-aware training for efficient hardware deployment of structured state-space sequential models, https://arxiv.org/pdf/2507.06079, 2025-07-08
2025-11-09 19:44:42,551 - INFO - root - Page:2, Index:10, GSVR: 2D Gaussian-based Video Representation for 800+ FPS with Hybrid Deformation Field, https://arxiv.org/pdf/2507.05594, 2025-07-07
2025-11-09 19:44:42,551 - INFO - root - Page:2, Index:11, Hita: Holistic Tokenizer for Autoregressive Image Generation, https://arxiv.org/pdf/2507.02358, 2025-07-11
2025-11-09 19:44:42,552 - INFO - root - Page:2, Index:12, QPART: Adaptive Model Quantization and Dynamic Workload Balancing for Accuracy-aware Edge Inference, https://arxiv.org/pdf/2506.23934, 2025-06-30
2025-11-09 19:44:42,552 - INFO - root - Page:2, Index:13, FedWSQ: Efficient Federated Learning with Weight Standardization and Distribution-Aware Non-Uniform Quantization, https://arxiv.org/pdf/2506.23516, 2025-07-21
2025-11-09 19:44:42,553 - INFO - root - Page:2, Index:14, Spectra 1.1: Scaling Laws and Efficient Inference for Ternary Language Models, https://arxiv.org/pdf/2506.23025, 2025-06-28
2025-11-09 19:44:42,554 - INFO - root - Page:2, Index:15, Joint Quantization and Pruning Neural Networks Approach: A Case Study on FSO Receivers, https://arxiv.org/pdf/2506.20084, 2025-06-24
2025-11-09 19:44:42,555 - INFO - root - Page:2, Index:16, Single-step Diffusion for Image Compression at Ultra-Low Bitrates, https://arxiv.org/pdf/2506.16572, 2025-09-22
2025-11-09 19:44:42,561 - INFO - root - Page:2, Index:17, LittleBit: Ultra Low-Bit Quantization via Latent Factorization, https://arxiv.org/pdf/2506.13771, 2025-10-28
2025-11-09 19:44:42,562 - INFO - root - Page:2, Index:18, MARCO: Hardware-Aware Neural Architecture Search for Edge Devices with Multi-Agent Reinforcement Learning and Conformal Prediction Filtering, https://arxiv.org/pdf/2506.13755, 2025-06-16
2025-11-09 19:44:42,562 - INFO - root - Page:2, Index:19, EAQuant: Enhancing Post-Training Quantization for MoE Models via Expert-Aware Optimization, https://arxiv.org/pdf/2506.13329, 2025-07-04
2025-11-09 19:44:42,562 - INFO - root - Page:2, Index:20, Towards Neural Audio Codec Source Parsing, https://arxiv.org/pdf/2506.12627, 2025-06-14
2025-11-09 19:44:42,563 - INFO - root - Page:2, Index:21, Quantizing Small-Scale State-Space Models for Edge AI, https://arxiv.org/pdf/2506.12480, 2025-06-14
2025-11-09 19:44:42,563 - INFO - root - Page:2, Index:22, EMLoC: Emulator-based Memory-efficient Fine-tuning with LoRA Correction, https://arxiv.org/pdf/2506.12015, 2025-06-13
2025-11-09 19:44:42,564 - INFO - root - Page:2, Index:23, Compression Aware Certified Training, https://arxiv.org/pdf/2506.11992, 2025-06-13
2025-11-09 19:44:42,565 - INFO - root - Page:2, Index:24, GPLQ: A General, Practical, and Lightning QAT Method for Vision Transformers, https://arxiv.org/pdf/2506.11784, 2025-06-13
2025-11-09 19:44:42,566 - INFO - root - Page:2, Index:25, TruncQuant: Truncation-Ready Quantization for DNNs with Flexible Weight Bit Precision, https://arxiv.org/pdf/2506.11431, 2025-06-12
2025-11-09 19:44:42,568 - INFO - root - Page:2, Index:26, EfficientQuant: An Efficient Post-Training Quantization for CNN-Transformer Hybrid Models on Edge Devices, https://arxiv.org/pdf/2506.11093, 2025-06-05
2025-11-09 19:44:42,569 - INFO - root - Page:2, Index:27, Starting Positions Matter: A Study on Better Weight Initialization for Neural Network Quantization, https://arxiv.org/pdf/2506.10463, 2025-06-12
2025-11-09 19:44:42,570 - INFO - root - Page:2, Index:28, AWP: Activation-Aware Weight Pruning and Quantization with Projected Gradient Descent, https://arxiv.org/pdf/2506.10205, 2025-06-11
2025-11-09 19:44:42,571 - INFO - root - Page:2, Index:29, Q-SAM2: Accurate Quantization for Segment Anything Model 2, https://arxiv.org/pdf/2506.09782, 2025-06-11
2025-11-09 19:44:42,571 - INFO - root - Page:2, Index:30, Unifying Block-wise PTQ and Distillation-based QAT for Progressive Quantization toward 2-bit Instruction-Tuned LLMs, https://arxiv.org/pdf/2506.09104, 2025-06-10
2025-11-09 19:44:42,571 - INFO - root - Page:2, Index:31, Implementing Keyword Spotting on the MCUX947 Microcontroller with Integrated NPU, https://arxiv.org/pdf/2506.08911, 2025-06-10
2025-11-09 19:44:42,572 - INFO - root - Page:2, Index:32, POLARON: Precision-aware On-device Learning and Adaptive Runtime-cONfigurable AI acceleration, https://arxiv.org/pdf/2506.08785, 2025-06-10
2025-11-09 19:44:42,574 - INFO - root - Page:2, Index:33, MoQAE: Mixed-Precision Quantization for Long-Context LLM Inference via Mixture of Quantization-Aware Experts, https://arxiv.org/pdf/2506.07533, 2025-06-09
2025-11-09 19:44:42,575 - INFO - root - Page:2, Index:34, BitVLA: 1-bit Vision-Language-Action Models for Robotics Manipulation, https://arxiv.org/pdf/2506.07530, 2025-06-09
2025-11-09 19:44:42,577 - INFO - root - Page:2, Index:35, RecGPT: A Foundation Model for Sequential Recommendation, https://arxiv.org/pdf/2506.06270, 2025-06-12
2025-11-09 19:44:42,577 - INFO - root - Page:2, Index:36, FPSAttention: Training-Aware FP8 and Sparsity Co-Design for Fast Video Diffusion, https://arxiv.org/pdf/2506.04648, 2025-06-05
2025-11-09 19:44:42,577 - INFO - root - Page:2, Index:37, BitTTS: Highly Compact Text-to-Speech Using 1.58-bit Quantization and Weight Indexing, https://arxiv.org/pdf/2506.03515, 2025-06-03
2025-11-09 19:44:42,579 - INFO - root - Page:2, Index:38, ShapeLLM-Omni: A Native Multimodal LLM for 3D Generation and Understanding, https://arxiv.org/pdf/2506.01853, 2025-06-02
2025-11-09 19:44:42,579 - INFO - root - Page:2, Index:39, Movable Antenna Enhanced Federated Fine-Tuning of Large Language Models via Hybrid Client Selection Optimization, https://arxiv.org/pdf/2506.00011, 2025-10-26
2025-11-09 19:44:42,580 - INFO - root - Page:2, Index:40, Running Conventional Automatic Speech Recognition on Memristor Hardware: A Simulated Approach, https://arxiv.org/pdf/2505.24721, 2025-05-30
2025-11-09 19:44:42,580 - INFO - root - Page:2, Index:41, GARLIC: GAussian Representation LearnIng for spaCe partitioning, https://arxiv.org/pdf/2505.24608, 2025-10-02
2025-11-09 19:44:42,582 - INFO - root - Page:2, Index:42, AutoChemSchematic AI: Agentic Physics-Aware Automation for Chemical Manufacturing Scale-Up, https://arxiv.org/pdf/2505.24584, 2025-08-18
2025-11-09 19:44:42,582 - INFO - root - Page:2, Index:43, Model-Preserving Adaptive Rounding, https://arxiv.org/pdf/2505.22988, 2025-09-25
2025-11-09 19:44:42,584 - INFO - root - Page:2, Index:44, Highly Efficient and Effective LLMs with Multi-Boolean Architectures, https://arxiv.org/pdf/2505.22811, 2025-10-03
2025-11-09 19:44:42,587 - INFO - root - Page:2, Index:45, Pioneering 4-Bit FP Quantization for Diffusion Models: Mixup-Sign Quantization and Timestep-Aware Fine-Tuning, https://arxiv.org/pdf/2505.21591, 2025-05-27
2025-11-09 19:44:42,592 - INFO - root - Page:2, Index:46, Frequency Composition for Compressed and Domain-Adaptive Neural Networks, https://arxiv.org/pdf/2505.20890, 2025-05-27
2025-11-09 19:44:42,596 - INFO - root - Page:2, Index:47, MoPFormer: Motion-Primitive Transformer for Wearable-Sensor Activity Recognition, https://arxiv.org/pdf/2505.20744, 2025-10-27
2025-11-09 19:44:42,597 - INFO - root - Page:2, Index:48, Optimizing edge AI models on HPC systems with the edge in the loop, https://arxiv.org/pdf/2505.19995, 2025-05-26
2025-11-09 19:44:42,597 - INFO - root - Fetching page 4 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=150
2025-11-09 19:44:49,700 - INFO - root - get_all_titles_from_web 
2025-11-09 19:44:49,701 - INFO - root - Page:3, Index:0, DPASyn: Mechanism-Aware Drug Synergy Prediction via Dual Attention and Precision-Aware Quantization, https://arxiv.org/pdf/2505.19144, 2025-09-20
2025-11-09 19:44:49,701 - INFO - root - Page:3, Index:1, Reducing Storage of Pretrained Neural Networks by Rate-Constrained Quantization and Entropy Coding, https://arxiv.org/pdf/2505.18758, 2025-05-24
2025-11-09 19:44:49,701 - INFO - root - Page:3, Index:2, Beyond Discreteness: Finite-Sample Analysis of Straight-Through Estimator for Quantization, https://arxiv.org/pdf/2505.18113, 2025-05-23
2025-11-09 19:44:49,702 - INFO - root - Page:3, Index:3, Automating Versatile Time-Series Analysis with Tiny Transformers on Embedded FPGAs, https://arxiv.org/pdf/2505.17662, 2025-09-19
2025-11-09 19:44:49,702 - INFO - root - Page:3, Index:4, FPQVAR: Floating Point Quantization for Visual Autoregressive Model with FPGA Hardware Co-design, https://arxiv.org/pdf/2505.16335, 2025-05-22
2025-11-09 19:44:49,702 - INFO - root - Page:3, Index:5, Saliency-Aware Quantized Imitation Learning for Efficient Robotic Control, https://arxiv.org/pdf/2505.15304, 2025-05-30
2025-11-09 19:44:49,703 - INFO - root - Page:3, Index:6, Scaling Law for Quantization-Aware Training, https://arxiv.org/pdf/2505.14302, 2025-05-20
2025-11-09 19:44:49,703 - INFO - root - Page:3, Index:7, Automatic mixed precision for optimizing gained time with constrained loss mean-squared-error based on model partition to sequential sub-graphs, https://arxiv.org/pdf/2505.13060, 2025-05-19
2025-11-09 19:44:49,703 - INFO - root - Page:3, Index:8, Deep Unfolding with Kernel-based Quantization in MIMO Detection, https://arxiv.org/pdf/2505.12736, 2025-05-19
2025-11-09 19:44:49,703 - INFO - root - Page:3, Index:9, FedHQ: Hybrid Runtime Quantization for Federated Learning, https://arxiv.org/pdf/2505.11982, 2025-05-17
2025-11-09 19:44:49,704 - INFO - root - Page:3, Index:10, QVGen: Pushing the Limit of Quantized Video Generative Models, https://arxiv.org/pdf/2505.11497, 2025-09-27
2025-11-09 19:44:49,704 - INFO - root - Page:3, Index:11, EA-3DGS: Efficient and Adaptive 3D Gaussians with Highly Enhanced Quality for outdoor scenes, https://arxiv.org/pdf/2505.10787, 2025-05-15
2025-11-09 19:44:49,704 - INFO - root - Page:3, Index:12, ITERA-LLM: Boosting Sub-8-Bit Large Language Model Inference via Iterative Tensor Decomposition, https://arxiv.org/pdf/2505.08981, 2025-05-13
2025-11-09 19:44:49,705 - INFO - root - Page:3, Index:13, PROM: Prioritize Reduction of Multiplications Over Lower Bit-Widths for Efficient CNNs, https://arxiv.org/pdf/2505.03254, 2025-08-06
2025-11-09 19:44:49,705 - INFO - root - Page:3, Index:14, ICQuant: Index Coding enables Low-bit LLM Quantization, https://arxiv.org/pdf/2505.00850, 2025-08-24
2025-11-09 19:44:49,705 - INFO - root - Page:3, Index:15, Enhancing Ultra-Low-Bit Quantization of Large Language Models Through Saliency-Aware Partial Retraining, https://arxiv.org/pdf/2504.13932, 2025-07-30
2025-11-09 19:44:49,706 - INFO - root - Page:3, Index:16, Achieving binary weight and activation for LLMs using Post-Training Quantization, https://arxiv.org/pdf/2504.05352, 2025-06-30
2025-11-09 19:44:49,706 - INFO - root - Page:3, Index:17, Wireless Hearables With Programmable Speech AI Accelerators, https://arxiv.org/pdf/2503.18698, 2025-10-21
2025-11-09 19:44:49,707 - INFO - root - Page:3, Index:18, GranQ: Efficient Channel-wise Quantization via Vectorized Pre-Scaling for Zero-Shot QAT, https://arxiv.org/pdf/2503.18339, 2025-10-15
2025-11-09 19:44:49,707 - INFO - root - Page:3, Index:19, CompMarkGS: Robust Watermarking for Compressed 3D Gaussian Splatting, https://arxiv.org/pdf/2503.12836, 2025-09-29
2025-11-09 19:44:49,707 - INFO - root - Page:3, Index:20, AHCPTQ: Accurate and Hardware-Compatible Post-Training Quantization for Segment Anything Model, https://arxiv.org/pdf/2503.03088, 2025-07-11
2025-11-09 19:44:49,708 - INFO - root - Page:3, Index:21, Teaching Metric Distance to Discrete Autoregressive Language Models, https://arxiv.org/pdf/2503.02379, 2025-10-07
2025-11-09 19:44:49,708 - INFO - root - Page:3, Index:22, Regularization-based Framework for Quantization-, Fault- and Variability-Aware Training, https://arxiv.org/pdf/2503.01297, 2025-07-12
2025-11-09 19:44:49,709 - INFO - root - Fetching page 5 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=200
2025-11-09 19:44:54,374 - INFO - root - get_all_titles_from_web 
2025-11-09 19:44:54,374 - INFO - root - Page:4, Index:0, Investigating the Impact of Quantization Methods on the Safety and Reliability of Large Language Models, https://arxiv.org/pdf/2502.15799, 2025-06-29
2025-11-09 19:44:54,374 - INFO - root - Page:4, Index:1, Rotate, Clip, and Partition: Towards W2A4KV4 Quantization by Integrating Rotation and Learnable Non-uniform Quantizer, https://arxiv.org/pdf/2502.15779, 2025-09-01
2025-11-09 19:44:54,375 - INFO - root - Page:4, Index:2, RoSTE: An Efficient Quantization-Aware Supervised Fine-Tuning Approach for Large Language Models, https://arxiv.org/pdf/2502.09003, 2025-06-05
2025-11-09 19:44:54,375 - INFO - root - Page:4, Index:3, Spatial Degradation-Aware and Temporal Consistent Diffusion Model for Compressed Video Super-Resolution, https://arxiv.org/pdf/2502.07381, 2025-06-27
2025-11-09 19:44:54,375 - INFO - root - Page:4, Index:4, QuEST: Stable Training of LLMs with 1-Bit Weights and Activations, https://arxiv.org/pdf/2502.05003, 2025-06-10
2025-11-09 19:44:54,376 - INFO - root - Page:4, Index:5, HALO: Hadamard-Assisted Lower-Precision Optimization for LLMs, https://arxiv.org/pdf/2501.02625, 2025-11-05
2025-11-09 19:44:54,376 - INFO - root - Page:4, Index:6, TAR3D: Creating High-Quality 3D Assets via Next-Part Prediction, https://arxiv.org/pdf/2412.16919, 2025-08-08
2025-11-09 19:44:54,376 - INFO - root - Page:4, Index:7, Training Multi-Layer Binary Neural Networks With Local Binary Error Signals, https://arxiv.org/pdf/2412.00119, 2025-08-05
2025-11-09 19:44:54,376 - INFO - root - Page:4, Index:8, Scaling Large-scale GNN Training to Thousands of Processors on CPU-based Supercomputers, https://arxiv.org/pdf/2411.16025, 2025-05-26
2025-11-09 19:44:54,377 - INFO - root - Page:4, Index:9, HAFLQ: Heterogeneous Adaptive Federated LoRA Fine-tuned LLM with Quantization, https://arxiv.org/pdf/2411.06581, 2025-05-16
2025-11-09 19:44:54,377 - INFO - root - Fetching page 6 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=250
2025-11-09 19:45:00,926 - INFO - root - get_all_titles_from_web 
2025-11-09 19:45:00,927 - INFO - root - Page:5, Index:0, Gradient-Free Training of Quantized Neural Networks, https://arxiv.org/pdf/2410.09734, 2025-09-29
2025-11-09 19:45:00,927 - INFO - root - Page:5, Index:1, QT-DoG: Quantization-aware Training for Domain Generalization, https://arxiv.org/pdf/2410.06020, 2025-06-26
2025-11-09 19:45:00,928 - INFO - root - Page:5, Index:2, Constraint Guided Model Quantization of Neural Networks, https://arxiv.org/pdf/2409.20138, 2025-09-12
2025-11-09 19:45:00,928 - INFO - root - Page:5, Index:3, Accumulator-Aware Post-Training Quantization for Large Language Models, https://arxiv.org/pdf/2409.17092, 2025-07-30
2025-11-09 19:45:00,928 - INFO - root - Page:5, Index:4, DilateQuant: Accurate and Efficient Diffusion Quantization via Weight Dilation, https://arxiv.org/pdf/2409.14307, 2025-07-09
2025-11-09 19:45:00,928 - INFO - root - Page:5, Index:5, Robust Training of Neural Networks at Arbitrary Precision and Sparsity, https://arxiv.org/pdf/2409.09245, 2025-09-23
2025-11-09 19:45:00,929 - INFO - root - Page:5, Index:6, VQ-CTAP: Cross-Modal Fine-Grained Sequence Representation Learning for Speech Processing, https://arxiv.org/pdf/2408.05758, 2025-05-27
2025-11-09 19:45:00,929 - INFO - root - Page:5, Index:7, DopQ-ViT: Towards Distribution-Friendly and Outlier-Aware Post-Training Quantization for Vision Transformers, https://arxiv.org/pdf/2408.03291, 2025-06-19
2025-11-09 19:45:00,929 - INFO - root - Page:5, Index:8, Temporal Feature Matters: A Framework for Diffusion Model Quantization, https://arxiv.org/pdf/2407.19547, 2025-07-11
2025-11-09 19:45:00,930 - INFO - root - Page:5, Index:9, EfficientQAT: Efficient Quantization-Aware Training for Large Language Models, https://arxiv.org/pdf/2407.11062, 2025-05-19
2025-11-09 19:45:00,930 - INFO - root - Page:5, Index:10, Integer-only Quantized Transformers for Embedded FPGA-based Time-series Forecasting in AIoT, https://arxiv.org/pdf/2407.11041, 2025-10-31
2025-11-09 19:45:00,930 - INFO - root - Fetching page 7 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=300
2025-11-09 19:45:07,602 - INFO - root - get_all_titles_from_web 
2025-11-09 19:45:07,603 - INFO - root - Page:6, Index:0, BoA: Attention-aware Post-training Quantization without Backpropagation, https://arxiv.org/pdf/2406.13474, 2025-06-06
2025-11-09 19:45:07,603 - INFO - root - Page:6, Index:1, A Rescaling-Invariant Lipschitz Bound Based on Path-Metrics for Modern ReLU Network Parameterizations, https://arxiv.org/pdf/2405.15006, 2025-06-13
2025-11-09 19:45:07,604 - INFO - root - Page:6, Index:2, Scheduling Weight Transitions for Quantization-Aware Training, https://arxiv.org/pdf/2404.19248, 2025-10-01
2025-11-09 19:45:07,604 - INFO - root - Page:6, Index:3, GPTVQ: The Blessing of Dimensionality for LLM Quantization, https://arxiv.org/pdf/2402.15319, 2025-06-03
2025-11-09 19:45:07,604 - INFO - root - Fetching page 8 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=350
2025-11-09 19:45:13,986 - INFO - root - get_all_titles_from_web 
2025-11-09 19:45:13,989 - INFO - root - Page:7, Index:0, Squat: Quant Small Language Models on the Edge, https://arxiv.org/pdf/2402.10787, 2025-07-01
2025-11-09 19:45:13,990 - INFO - root - Page:7, Index:1, L4Q: Parameter Efficient Quantization-Aware Fine-Tuning on Large Language Models, https://arxiv.org/pdf/2402.04902, 2025-07-21
2025-11-09 19:45:13,990 - INFO - root - Fetching page 9 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=400
2025-11-09 19:45:21,043 - INFO - root - ------------------------------------------------------------------------------------------------------------------------
2025-11-09 19:45:33,772 - INFO - root - 跳过已处理论文 A Quantized VAE-MLP Botnet Detection Model: A Systematic Evaluation of Quantization-Aware Training and Post-Training Quantization Strategies：D:\ChatPaper\academic Papers\Quantization-Aware-Training\A Quantized VAE-MLP Botnet Detection Model_ A Systematic Evaluation of Quantizat-2.pdf
2025-11-09 19:45:33,773 - INFO - root - 正在总结论文 2/2: FP8-Flow-MoE: A Casting-Free FP8 Recipe without Double Quantization Error
2025-11-09 19:46:16,637 - INFO - root - LLMClient: rate limit reached, sleeping 17.1s
2025-11-09 19:46:52,812 - INFO - root - 正在提取论文图片...
2025-11-09 19:47:00,391 - INFO - root - 已保存图片 1/10：./export\images_FP8-Flow-MoE_ A Casting-Free FP8 Recipe without Double Quantization Error\figure_1_page6.png
2025-11-09 19:47:01,367 - INFO - root - 已保存图片 2/10：./export\images_FP8-Flow-MoE_ A Casting-Free FP8 Recipe without Double Quantization Error\figure_2_page6.png
2025-11-09 19:47:01,725 - INFO - root - 已保存图片 3/10：./export\images_FP8-Flow-MoE_ A Casting-Free FP8 Recipe without Double Quantization Error\figure_3_page6.png
2025-11-09 19:47:02,103 - INFO - root - 已保存图片 4/10：./export\images_FP8-Flow-MoE_ A Casting-Free FP8 Recipe without Double Quantization Error\figure_4_page6.png
2025-11-09 19:47:02,152 - INFO - root - 成功添加图片 1：./export\images_FP8-Flow-MoE_ A Casting-Free FP8 Recipe without Double Quantization Error\figure_1_page6.png
2025-11-09 19:47:02,153 - INFO - root - 成功添加图片 2：./export\images_FP8-Flow-MoE_ A Casting-Free FP8 Recipe without Double Quantization Error\figure_2_page6.png
2025-11-09 19:47:02,153 - INFO - root - 成功添加图片 3：./export\images_FP8-Flow-MoE_ A Casting-Free FP8 Recipe without Double Quantization Error\figure_3_page6.png
2025-11-09 19:47:02,153 - INFO - root - 成功添加图片 4：./export\images_FP8-Flow-MoE_ A Casting-Free FP8 Recipe without Double Quantization Error\figure_4_page6.png
2025-11-09 19:47:02,178 - INFO - root - 论文《FP8-Flow-MoE: A Casting-Free FP8 Recipe without Double Quantization Error》的分析已保存到 ./export\FP8-Flow-MoE_ A Casting-Free FP8 Recipe without Double Quantization Error.md
2025-11-09 19:47:02,276 - INFO - root - summary time: 177.86 seconds
2025-11-09 20:00:55,741 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-09 20:00:55,743 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-09 20:00:55,745 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-09 20:00:57,021 - INFO - root - LLMClientManager: 指定使用客户端: Deepseek
2025-11-09 20:00:57,021 - INFO - root - DeepSeekClient: API key found: 9f9e270e-b...
2025-11-09 20:00:57,023 - INFO - root - DeepSeekClient: 使用模式: 火山引擎
2025-11-09 20:01:00,188 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 404 Not Found"
2025-11-09 20:01:00,190 - ERROR - root - DeepSeekClient: error during initialization: Error code: 404 - {'error': {'code': 'InvalidEndpointOrModel.NotFound', 'message': 'The model or endpoint deepseek-chat does not exist or you do not have access to it. Request id: 021762689659689f83b1f853f59e3d47d2ccd8cfd02b65a46c588', 'param': '', 'type': 'Not Found'}}
2025-11-09 20:01:00,190 - ERROR - root - LLMClientManager: 指定的客户端 DeepSeek 初始化失败
2025-11-09 20:01:00,190 - WARNING - root - LLMClientManager: 指定的客户端 Deepseek 不可用，将尝试其他客户端
2025-11-09 20:01:01,087 - INFO - root - GeminiClient: trying model gemini-2.5-flash
2025-11-09 20:01:03,306 - INFO - root - GeminiClient: initialized model gemini-2.5-flash
2025-11-09 20:01:03,307 - INFO - root - LLMClientManager: Gemini client initialized successfully
2025-11-09 20:01:03,307 - INFO - root - LLMClientManager: using Gemini as default client
2025-11-09 20:01:03,307 - WARNING - root - KimiClient: API key not provided. LLM disabled.
2025-11-09 20:01:03,308 - WARNING - root - LLMClientManager: Kimi client initialization failed
2025-11-09 20:01:03,308 - WARNING - root - QwenClient: API key not provided. LLM disabled.
2025-11-09 20:01:03,309 - WARNING - root - LLMClientManager: Qwen client initialization failed
2025-11-09 20:01:03,309 - INFO - root - DoubaoClient: API key found: 9f9e270e-b...
2025-11-09 20:01:07,975 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 20:01:07,985 - INFO - root - DoubaoClient: initialized successfully with model doubao-seed-1-6-lite-251015
2025-11-09 20:01:07,986 - INFO - root - LLMClientManager: Doubao client initialized successfully
2025-11-09 20:01:07,986 - WARNING - root - LLMClientManager: client Deepseek not available
2025-11-09 20:01:07,987 - WARNING - root - 无法切换到指定的客户端 Deepseek，将使用默认客户端
2025-11-09 20:01:07,987 - INFO - root - 可用客户端: ['Gemini', 'Doubao']
2025-11-09 20:01:07,987 - INFO - root - 使用 LLM 模型: gemini-2.5-flash
2025-11-09 20:01:07,988 - INFO - root - 可用客户端: ['Gemini', 'Doubao']
2025-11-09 20:01:07,988 - INFO - root - === 运行配置 ===
2025-11-09 20:01:07,988 - INFO - root - 处理模式: arxiv在线搜索
2025-11-09 20:01:07,989 - INFO - root - 关键词: QAT
2025-11-09 20:01:07,989 - INFO - root - 查询: Quantization-Aware-Training
2025-11-09 20:01:07,989 - INFO - root - 排序: None
2025-11-09 20:01:07,989 - INFO - root - 最近天数: 180
2025-11-09 20:01:07,990 - INFO - root - 最大处理数量: 2
2025-11-09 20:01:07,990 - INFO - root - 保存图片: 是
2025-11-09 20:01:07,991 - INFO - root - 输出语言: 中文
2025-11-09 20:01:07,991 - INFO - root - 强制重新处理: 否
2025-11-09 20:01:07,991 - INFO - root - ====================
2025-11-09 20:01:07,992 - INFO - root - 使用 arXiv 搜索模式（通过 chat_arxiv 模块获取）
2025-11-09 20:01:07,994 - INFO - root - Fetching page 1 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50
2025-11-09 20:01:14,406 - INFO - root - get_all_titles_from_web 
2025-11-09 20:01:14,407 - INFO - root - Page:0, Index:0, A Quantized VAE-MLP Botnet Detection Model: A Systematic Evaluation of Quantization-Aware Training and Post-Training Quantization Strategies, https://arxiv.org/pdf/2511.03201, 2025-11-05
2025-11-09 20:01:14,407 - INFO - root - Page:0, Index:1, FP8-Flow-MoE: A Casting-Free FP8 Recipe without Double Quantization Error, https://arxiv.org/pdf/2511.02302, 2025-11-04
2025-11-09 20:01:14,407 - INFO - root - Page:0, Index:2, Outlier-Aware Post-Training Quantization for Image Super-Resolution, https://arxiv.org/pdf/2511.00682, 2025-11-01
2025-11-09 20:01:14,407 - INFO - root - Page:0, Index:3, Evaluation of Wafer-Scale SOT-MRAM for Analog Crossbar Array Applications, https://arxiv.org/pdf/2510.25853, 2025-11-03
2025-11-09 20:01:14,408 - INFO - root - Page:0, Index:4, Improving the Straight-Through Estimator with Zeroth-Order Information, https://arxiv.org/pdf/2510.23926, 2025-10-27
2025-11-09 20:01:14,408 - INFO - root - Page:0, Index:5, Real-Time Semantic Segmentation on FPGA for Autonomous Vehicles Using LMIINet with the CGRA4ML Framework, https://arxiv.org/pdf/2510.22243, 2025-10-25
2025-11-09 20:01:14,408 - INFO - root - Page:0, Index:6, TernaryCLIP: Efficiently Compressing Vision-Language Models with Ternary Weights and Distilled Knowledge, https://arxiv.org/pdf/2510.21879, 2025-10-23
2025-11-09 20:01:14,409 - INFO - root - Page:0, Index:7, KARIPAP: Quantum-Inspired Tensor Network Compression of Large Language Models Using Infinite Projected Entangled Pair States and Tensor Renormalization Group, https://arxiv.org/pdf/2510.21844, 2025-10-22
2025-11-09 20:01:14,409 - INFO - root - Page:0, Index:8, A Convergence Analysis of Adaptive Optimizers under Floating-point Quantization, https://arxiv.org/pdf/2510.21314, 2025-10-24
2025-11-09 20:01:14,409 - INFO - root - Page:0, Index:9, Adaptive Distribution-aware Quantization for Mixed-Precision Neural Networks, https://arxiv.org/pdf/2510.19760, 2025-10-22
2025-11-09 20:01:14,409 - INFO - root - Page:0, Index:10, CAGE: Curvature-Aware Gradient Estimation For Accurate Quantization-Aware Training, https://arxiv.org/pdf/2510.18784, 2025-10-21
2025-11-09 20:01:14,409 - INFO - root - Page:0, Index:11, Mixed-Precision Quantization for Language Models: Techniques and Prospects, https://arxiv.org/pdf/2510.16805, 2025-10-19
2025-11-09 20:01:14,410 - INFO - root - Page:0, Index:12, SPLite Hand: Sparsity-Aware Lightweight 3D Hand Pose Estimation, https://arxiv.org/pdf/2510.16396, 2025-10-30
2025-11-09 20:01:14,411 - INFO - root - Page:0, Index:13, CTR-LoRA: Curvature-Aware and Trust-Region Guided Low-Rank Adaptation for Large Language Models, https://arxiv.org/pdf/2510.15962, 2025-10-11
2025-11-09 20:01:14,412 - INFO - root - Page:0, Index:14, SANR: Scene-Aware Neural Representation for Light Field Image Compression with Rate-Distortion Optimization, https://arxiv.org/pdf/2510.15775, 2025-10-17
2025-11-09 20:01:14,412 - INFO - root - Page:0, Index:15, SpikeFit: Towards Optimal Deployment of Spiking Networks on Neuromorphic Hardware, https://arxiv.org/pdf/2510.15542, 2025-10-31
2025-11-09 20:01:14,413 - INFO - root - Page:0, Index:16, GRank: Towards Target-Aware and Streamlined Industrial Retrieval with a Generate-Rank Framework, https://arxiv.org/pdf/2510.15299, 2025-10-17
2025-11-09 20:01:14,413 - INFO - root - Page:0, Index:17, SaLon3R: Structure-aware Long-term Generalizable 3D Reconstruction from Unposed Images, https://arxiv.org/pdf/2510.15072, 2025-10-16
2025-11-09 20:01:14,414 - INFO - root - Page:0, Index:18, FraQAT: Quantization Aware Training with Fractional bits, https://arxiv.org/pdf/2510.14823, 2025-10-16
2025-11-09 20:01:14,414 - INFO - root - Page:0, Index:19, Computing-In-Memory Aware Model Adaption For Edge Devices, https://arxiv.org/pdf/2510.14379, 2025-10-16
2025-11-09 20:01:14,414 - INFO - root - Page:0, Index:20, Invited Paper: BitMedViT: Ternary-Quantized Vision Transformer for Medical AI Assistants on the Edge, https://arxiv.org/pdf/2510.13760, 2025-11-04
2025-11-09 20:01:14,419 - INFO - root - Page:0, Index:21, NeuroRVQ: Multi-Scale EEG Tokenization for Generative Large Brainwave Models, https://arxiv.org/pdf/2510.13068, 2025-10-14
2025-11-09 20:01:14,425 - INFO - root - Page:0, Index:22, Detect Anything via Next Point Prediction, https://arxiv.org/pdf/2510.12798, 2025-10-14
2025-11-09 20:01:14,426 - INFO - root - Page:0, Index:23, AndesVL Technical Report: An Efficient Mobile-side Multimodal Large Language Model, https://arxiv.org/pdf/2510.11496, 2025-10-14
2025-11-09 20:01:14,426 - INFO - root - Page:0, Index:24, Rescaling-Aware Training for Efficient Deployment of Deep Learning Models on Full-Integer Hardware, https://arxiv.org/pdf/2510.11484, 2025-10-13
2025-11-09 20:01:14,427 - INFO - root - Page:0, Index:25, SASER: Stego attacks on open-source LLMs, https://arxiv.org/pdf/2510.10486, 2025-10-12
2025-11-09 20:01:14,427 - INFO - root - Page:0, Index:26, Ultralytics YOLO Evolution: An Overview of YOLO26, YOLO11, YOLOv8 and YOLOv5 Object Detectors for Computer Vision and Pattern Recognition, https://arxiv.org/pdf/2510.09653, 2025-10-15
2025-11-09 20:01:14,428 - INFO - root - Page:0, Index:27, A Theoretically-Grounded Codebook for Digital Semantic Communications, https://arxiv.org/pdf/2510.07108, 2025-10-14
2025-11-09 20:01:14,428 - INFO - root - Page:0, Index:28, QuantDemoire: Quantization with Outlier Aware for Image Demoiréing, https://arxiv.org/pdf/2510.04066, 2025-10-05
2025-11-09 20:01:14,429 - INFO - root - Page:0, Index:29, Adaptively Sampling-Reusing-Mixing Decomposed Gradients to Speed Up Sharpness Aware Minimization, https://arxiv.org/pdf/2510.03763, 2025-10-04
2025-11-09 20:01:14,429 - INFO - root - Page:0, Index:30, Quant-dLLM: Post-Training Extreme Low-Bit Quantization for Diffusion Large Language Models, https://arxiv.org/pdf/2510.03274, 2025-09-27
2025-11-09 20:01:14,430 - INFO - root - Page:0, Index:31, PT$^2$-LLM: Post-Training Ternarization for Large Language Models, https://arxiv.org/pdf/2510.03267, 2025-09-26
2025-11-09 20:01:14,430 - INFO - root - Page:0, Index:32, Purrception: Variational Flow Matching for Vector-Quantized Image Generation, https://arxiv.org/pdf/2510.01478, 2025-10-01
2025-11-09 20:01:14,431 - INFO - root - Page:0, Index:33, Post-Training Quantization for Audio Diffusion Transformers, https://arxiv.org/pdf/2510.00313, 2025-09-30
2025-11-09 20:01:14,431 - INFO - root - Page:0, Index:34, Rethinking RoPE Scaling in Quantized LLM: Theory, Outlier, and Channel-Band Analysis with Weight Rescaling, https://arxiv.org/pdf/2510.00028, 2025-09-25
2025-11-09 20:01:14,443 - INFO - root - Page:0, Index:35, Post-Training Quantization via Residual Truncation and Zero Suppression for Diffusion Models, https://arxiv.org/pdf/2509.26436, 2025-09-30
2025-11-09 20:01:14,450 - INFO - root - Page:0, Index:36, Cat: Post-Training Quantization Error Reduction via Cluster-based Affine Transformation, https://arxiv.org/pdf/2509.26277, 2025-10-07
2025-11-09 20:01:14,452 - INFO - root - Page:0, Index:37, CAST: Continuous and Differentiable Semi-Structured Sparsity-Aware Training for Large Language Models, https://arxiv.org/pdf/2509.25996, 2025-09-30
2025-11-09 20:01:14,452 - INFO - root - Page:0, Index:38, Norm-Q: Effective Compression Method for Hidden Markov Models in Neuro-Symbolic Applications, https://arxiv.org/pdf/2509.25439, 2025-09-29
2025-11-09 20:01:14,453 - INFO - root - Page:0, Index:39, On-the-Fly Adaptation to Quantization: Configuration-Aware LoRA for Efficient Fine-Tuning of Quantized LLMs, https://arxiv.org/pdf/2509.25214, 2025-09-22
2025-11-09 20:01:14,453 - INFO - root - Page:0, Index:40, VoxCPM: Tokenizer-Free TTS for Context-Aware Speech Generation and True-to-Life Voice Cloning, https://arxiv.org/pdf/2509.24650, 2025-09-29
2025-11-09 20:01:14,454 - INFO - root - Page:0, Index:41, S$^2$NN: Sub-bit Spiking Neural Networks, https://arxiv.org/pdf/2509.24266, 2025-10-24
2025-11-09 20:01:14,454 - INFO - root - Page:0, Index:42, Tequila: Trapping-free Ternary Quantization for Large Language Models, https://arxiv.org/pdf/2509.23809, 2025-10-17
2025-11-09 20:01:14,454 - INFO - root - Page:0, Index:43, Texture Vector-Quantization and Reconstruction Aware Prediction for Generative Super-Resolution, https://arxiv.org/pdf/2509.23774, 2025-09-30
2025-11-09 20:01:14,454 - INFO - root - Page:0, Index:44, RobuQ: Pushing DiTs to W1.58A2 via Robust Activation Quantization, https://arxiv.org/pdf/2509.23582, 2025-09-27
2025-11-09 20:01:14,455 - INFO - root - Page:0, Index:45, Beyond Outliers: A Study of Optimizers Under Quantization, https://arxiv.org/pdf/2509.23500, 2025-10-02
2025-11-09 20:01:14,455 - INFO - root - Page:0, Index:46, Compute-Optimal Quantization-Aware Training, https://arxiv.org/pdf/2509.22935, 2025-09-26
2025-11-09 20:01:14,456 - INFO - root - Page:0, Index:47, COSPADI: Compressing LLMs via Calibration-Guided Sparse Dictionary Learning, https://arxiv.org/pdf/2509.22075, 2025-10-06
2025-11-09 20:01:14,457 - INFO - root - Page:0, Index:48, SlimDiff: Training-Free, Activation-Guided Hands-free Slimming of Diffusion Models, https://arxiv.org/pdf/2509.21498, 2025-09-25
2025-11-09 20:01:14,459 - INFO - root - Page:0, Index:49, Quantized Visual Geometry Grounded Transformer, https://arxiv.org/pdf/2509.21302, 2025-09-29
2025-11-09 20:01:14,459 - INFO - root - Fetching page 2 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=50
2025-11-09 20:01:20,927 - INFO - root - get_all_titles_from_web 
2025-11-09 20:01:20,927 - INFO - root - Page:1, Index:0, Can Less Precise Be More Reliable? A Systematic Evaluation of Quantization's Impact on CLIP Beyond Accuracy, https://arxiv.org/pdf/2509.21173, 2025-10-27
2025-11-09 20:01:20,927 - INFO - root - Page:1, Index:1, Punching Above Precision: Small Quantized Model Distillation with Learnable Regularizer, https://arxiv.org/pdf/2509.20854, 2025-09-25
2025-11-09 20:01:20,928 - INFO - root - Page:1, Index:2, TinyEcoWeedNet: Edge Efficient Real-Time Aerial Agricultural Weed Detection, https://arxiv.org/pdf/2509.18193, 2025-09-19
2025-11-09 20:01:20,928 - INFO - root - Page:1, Index:3, SBVR: Summation of BitVector Representation for Efficient LLM Quantization, https://arxiv.org/pdf/2509.18172, 2025-09-17
2025-11-09 20:01:20,929 - INFO - root - Page:1, Index:4, QWHA: Quantization-Aware Walsh-Hadamard Adaptation for Parameter-Efficient Fine-Tuning on Large Language Models, https://arxiv.org/pdf/2509.17428, 2025-09-26
2025-11-09 20:01:20,929 - INFO - root - Page:1, Index:5, PTQTP: Post-Training Quantization to Trit-Planes for Large Language Models, https://arxiv.org/pdf/2509.16989, 2025-10-28
2025-11-09 20:01:20,929 - INFO - root - Page:1, Index:6, MEC-Quant: Maximum Entropy Coding for Extremely Low Bit Quantization-Aware Training, https://arxiv.org/pdf/2509.15514, 2025-09-18
2025-11-09 20:01:20,929 - INFO - root - Page:1, Index:7, Q-ROAR: Outlier-Aware Rescaling for RoPE Position Interpolation in Quantized Long-Context LLMs, https://arxiv.org/pdf/2509.14391, 2025-09-17
2025-11-09 20:01:20,930 - INFO - root - Page:1, Index:8, Efficient Quantization-Aware Neural Receivers: Beyond Post-Training Quantization, https://arxiv.org/pdf/2509.13786, 2025-09-19
2025-11-09 20:01:20,930 - INFO - root - Page:1, Index:9, Rate-Distortion Limits for Multimodal Retrieval: Theory, Optimal Codes, and Finite-Sample Guarantees, https://arxiv.org/pdf/2509.11054, 2025-09-13
2025-11-09 20:01:20,930 - INFO - root - Page:1, Index:10, SQAP-VLA: A Synergistic Quantization-Aware Pruning Framework for High-Performance Vision-Language-Action Models, https://arxiv.org/pdf/2509.09090, 2025-09-10
2025-11-09 20:01:20,931 - INFO - root - Page:1, Index:11, CSI Compression Beyond Latents: End-to-End Hybrid Attention-CNN Networks with Entropy Regularization, https://arxiv.org/pdf/2509.08776, 2025-09-10
2025-11-09 20:01:20,931 - INFO - root - Page:1, Index:12, Explaining How Quantization Disparately Skews a Model, https://arxiv.org/pdf/2509.07222, 2025-09-08
2025-11-09 20:01:20,932 - INFO - root - Page:1, Index:13, LoaQ: Layer-wise Output Approximation Quantization, https://arxiv.org/pdf/2509.06297, 2025-09-07
2025-11-09 20:01:20,932 - INFO - root - Page:1, Index:14, FineServe: Precision-Aware KV Slab and Two-Level Scheduling for Heterogeneous Precision LLM Serving, https://arxiv.org/pdf/2509.06261, 2025-09-14
2025-11-09 20:01:20,933 - INFO - root - Page:1, Index:15, Sensitivity-Aware Post-Training Quantization for Deep Neural Networks, https://arxiv.org/pdf/2509.05576, 2025-09-05
2025-11-09 20:01:20,933 - INFO - root - Page:1, Index:16, SuperSNN: A Hardware-Aware Framework for Physically Realizable, High-Performance Superconducting Spiking Neural Network Chips, https://arxiv.org/pdf/2509.05532, 2025-09-05
2025-11-09 20:01:20,934 - INFO - root - Page:1, Index:17, Data-Augmented Quantization-Aware Knowledge Distillation, https://arxiv.org/pdf/2509.03850, 2025-09-03
2025-11-09 20:01:20,934 - INFO - root - Page:1, Index:18, DPQuant: Efficient and Differentially-Private Model Training via Dynamic Quantization Scheduling, https://arxiv.org/pdf/2509.03472, 2025-09-03
2025-11-09 20:01:20,934 - INFO - root - Page:1, Index:19, Empowering Large Language Model for Sequential Recommendation via Multimodal Embeddings and Semantic IDs, https://arxiv.org/pdf/2509.02017, 2025-09-02
2025-11-09 20:01:20,935 - INFO - root - Page:1, Index:20, Q-Sched: Pushing the Boundaries of Few-Step Diffusion Models with Quantization-Aware Scheduling, https://arxiv.org/pdf/2509.01624, 2025-09-01
2025-11-09 20:01:20,935 - INFO - root - Page:1, Index:21, Quantization Meets OOD: Generalizable Quantization-aware Training from a Flatness Perspective, https://arxiv.org/pdf/2509.00859, 2025-08-31
2025-11-09 20:01:20,936 - INFO - root - Page:1, Index:22, Progressive Element-wise Gradient Estimation for Neural Network Quantization, https://arxiv.org/pdf/2509.00097, 2025-08-27
2025-11-09 20:01:20,936 - INFO - root - Page:1, Index:23, End-to-End On-Device Quantization-Aware Training for LLMs at Inference Cost, https://arxiv.org/pdf/2509.00031, 2025-09-29
2025-11-09 20:01:20,936 - INFO - root - Page:1, Index:24, Quantization Robustness to Input Degradations for Object Detection, https://arxiv.org/pdf/2508.19600, 2025-08-27
2025-11-09 20:01:20,937 - INFO - root - Page:1, Index:25, Scaling Laws for Task-Stratified Knowledge in Post-Training Quantized Large Language Models, https://arxiv.org/pdf/2508.18609, 2025-08-27
2025-11-09 20:01:20,937 - INFO - root - Page:1, Index:26, AQ-PCDSys: An Adaptive Quantized Planetary Crater Detection System for Autonomous Space Exploration, https://arxiv.org/pdf/2508.18025, 2025-08-25
2025-11-09 20:01:20,937 - INFO - root - Page:1, Index:27, TaDiCodec: Text-aware Diffusion Speech Tokenizer for Speech Language Modeling, https://arxiv.org/pdf/2508.16790, 2025-08-22
2025-11-09 20:01:20,937 - INFO - root - Page:1, Index:28, A Node-Aware Dynamic Quantization Approach for Graph Collaborative Filtering, https://arxiv.org/pdf/2508.16516, 2025-08-22
2025-11-09 20:01:20,939 - INFO - root - Page:1, Index:29, JEDI-linear: Fast and Efficient Graph Neural Networks for Jet Tagging on FPGAs, https://arxiv.org/pdf/2508.15468, 2025-08-21
2025-11-09 20:01:20,944 - INFO - root - Page:1, Index:30, MMQ: Multimodal Mixture-of-Quantization Tokenization for Semantic ID Generation and User Behavioral Adaptation, https://arxiv.org/pdf/2508.15281, 2025-08-21
2025-11-09 20:01:20,945 - INFO - root - Page:1, Index:31, DLLMQuant: Quantizing Diffusion-based Large Language Models, https://arxiv.org/pdf/2508.14090, 2025-08-25
2025-11-09 20:01:20,946 - INFO - root - Page:1, Index:32, Automated Energy-Aware Time-Series Model Deployment on Embedded FPGAs for Resilient Combined Sewer Overflow Management, https://arxiv.org/pdf/2508.13905, 2025-08-19
2025-11-09 20:01:20,946 - INFO - root - Page:1, Index:33, XR-NPE: High-Throughput Mixed-precision SIMD Neural Processing Engine for Extended Reality Perception Workloads, https://arxiv.org/pdf/2508.13049, 2025-08-18
2025-11-09 20:01:20,946 - INFO - root - Page:1, Index:34, Exploring Self-Supervised Audio Models for Generalized Anomalous Sound Detection, https://arxiv.org/pdf/2508.12230, 2025-08-17
2025-11-09 20:01:20,947 - INFO - root - Page:1, Index:35, TriQDef: Disrupting Semantic and Gradient Alignment to Prevent Adversarial Patch Transferability in Quantized Neural Networks, https://arxiv.org/pdf/2508.12132, 2025-08-16
2025-11-09 20:01:20,947 - INFO - root - Page:1, Index:36, Error Propagation Mechanisms and Compensation Strategies for Quantized Diffusion, https://arxiv.org/pdf/2508.12094, 2025-10-13
2025-11-09 20:01:20,948 - INFO - root - Page:1, Index:37, Extending Straight-Through Estimation for Robust Neural Networks on Analog CIM Hardware, https://arxiv.org/pdf/2508.11940, 2025-08-16
2025-11-09 20:01:20,948 - INFO - root - Page:1, Index:38, PTQAT: A Hybrid Parameter-Efficient Quantization Algorithm for 3D Perception Tasks, https://arxiv.org/pdf/2508.10557, 2025-08-15
2025-11-09 20:01:20,948 - INFO - root - Page:1, Index:39, MiCo: End-to-End Mixed Precision Neural Network Co-Exploration Framework for Edge AI, https://arxiv.org/pdf/2508.09500, 2025-08-13
2025-11-09 20:01:20,949 - INFO - root - Page:1, Index:40, SPARC: Soft Probabilistic Adaptive multi-interest Retrieval Model via Codebooks for recommender system, https://arxiv.org/pdf/2508.09090, 2025-08-12
2025-11-09 20:01:20,949 - INFO - root - Page:1, Index:41, Rethinking 1-bit Optimization Leveraging Pre-trained Large Language Models, https://arxiv.org/pdf/2508.06974, 2025-08-09
2025-11-09 20:01:20,949 - INFO - root - Page:1, Index:42, Efficient Deep Neural Receiver with Post-Training Quantization, https://arxiv.org/pdf/2508.06275, 2025-08-08
2025-11-09 20:01:20,950 - INFO - root - Page:1, Index:43, iFairy: the First 2-bit Complex LLM with All Parameters in $\{\pm1, \pm i\}$, https://arxiv.org/pdf/2508.05571, 2025-08-16
2025-11-09 20:01:20,950 - INFO - root - Page:1, Index:44, S$^2$Q-VDiT: Accurate Quantized Video Diffusion Transformer with Salient Data and Sparse Token Distillation, https://arxiv.org/pdf/2508.04016, 2025-10-27
2025-11-09 20:01:20,950 - INFO - root - Page:1, Index:45, LRQ-DiT: Log-Rotation Post-Training Quantization of Diffusion Transformers for Image and Video Generation, https://arxiv.org/pdf/2508.03485, 2025-09-23
2025-11-09 20:01:20,951 - INFO - root - Page:1, Index:46, VLMQ: Efficient Post-Training Quantization for Large Vision-Language Models via Hessian Augmentation, https://arxiv.org/pdf/2508.03351, 2025-08-05
2025-11-09 20:01:20,951 - INFO - root - Page:1, Index:47, TF-MLPNet: Tiny Real-Time Neural Speech Separation, https://arxiv.org/pdf/2508.03047, 2025-08-04
2025-11-09 20:01:20,951 - INFO - root - Page:1, Index:48, SaviorRec: Semantic-Behavior Alignment for Cold-Start Recommendation, https://arxiv.org/pdf/2508.01375, 2025-08-02
2025-11-09 20:01:20,952 - INFO - root - Page:1, Index:49, MixA-Q: Revisiting Activation Sparsity for Vision Transformers from a Mixed-Precision Quantization Perspective, https://arxiv.org/pdf/2507.19131, 2025-07-25
2025-11-09 20:01:20,952 - INFO - root - Fetching page 3 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=100
2025-11-09 20:01:27,192 - INFO - root - get_all_titles_from_web 
2025-11-09 20:01:27,192 - INFO - root - Page:2, Index:0, Enhancing Quantization-Aware Training on Edge Devices via Relative Entropy Coreset Selection and Cascaded Layer Correction, https://arxiv.org/pdf/2507.17768, 2025-07-16
2025-11-09 20:01:27,193 - INFO - root - Page:2, Index:1, SiLQ: Simple Large Language Model Quantization-Aware Training, https://arxiv.org/pdf/2507.16933, 2025-07-22
2025-11-09 20:01:27,193 - INFO - root - Page:2, Index:2, Task-Specific Zero-shot Quantization-Aware Training for Object Detection, https://arxiv.org/pdf/2507.16782, 2025-07-22
2025-11-09 20:01:27,193 - INFO - root - Page:2, Index:3, TorchAO: PyTorch-Native Training-to-Serving Model Optimization, https://arxiv.org/pdf/2507.16099, 2025-07-21
2025-11-09 20:01:27,193 - INFO - root - Page:2, Index:4, SegQuant: A Semantics-Aware and Generalizable Quantization Framework for Diffusion Models, https://arxiv.org/pdf/2507.14811, 2025-08-27
2025-11-09 20:01:27,193 - INFO - root - Page:2, Index:5, Apple Intelligence Foundation Language Models: Tech Report 2025, https://arxiv.org/pdf/2507.13575, 2025-08-27
2025-11-09 20:01:27,193 - INFO - root - Page:2, Index:6, Generative Multi-Target Cross-Domain Recommendation, https://arxiv.org/pdf/2507.12871, 2025-08-07
2025-11-09 20:01:27,195 - INFO - root - Page:2, Index:7, DAF: An Efficient End-to-End Dynamic Activation Framework for on-Device DNN Training, https://arxiv.org/pdf/2507.07149, 2025-07-09
2025-11-09 20:01:27,195 - INFO - root - Page:2, Index:8, Opto-ViT: Architecting a Near-Sensor Region of Interest-Aware Vision Transformer Accelerator with Silicon Photonics, https://arxiv.org/pdf/2507.07044, 2025-07-15
2025-11-09 20:01:27,196 - INFO - root - Page:2, Index:9, QS4D: Quantization-aware training for efficient hardware deployment of structured state-space sequential models, https://arxiv.org/pdf/2507.06079, 2025-07-08
2025-11-09 20:01:27,196 - INFO - root - Page:2, Index:10, GSVR: 2D Gaussian-based Video Representation for 800+ FPS with Hybrid Deformation Field, https://arxiv.org/pdf/2507.05594, 2025-07-07
2025-11-09 20:01:27,196 - INFO - root - Page:2, Index:11, Hita: Holistic Tokenizer for Autoregressive Image Generation, https://arxiv.org/pdf/2507.02358, 2025-07-11
2025-11-09 20:01:27,196 - INFO - root - Page:2, Index:12, QPART: Adaptive Model Quantization and Dynamic Workload Balancing for Accuracy-aware Edge Inference, https://arxiv.org/pdf/2506.23934, 2025-06-30
2025-11-09 20:01:27,197 - INFO - root - Page:2, Index:13, FedWSQ: Efficient Federated Learning with Weight Standardization and Distribution-Aware Non-Uniform Quantization, https://arxiv.org/pdf/2506.23516, 2025-07-21
2025-11-09 20:01:27,197 - INFO - root - Page:2, Index:14, Spectra 1.1: Scaling Laws and Efficient Inference for Ternary Language Models, https://arxiv.org/pdf/2506.23025, 2025-06-28
2025-11-09 20:01:27,198 - INFO - root - Page:2, Index:15, Joint Quantization and Pruning Neural Networks Approach: A Case Study on FSO Receivers, https://arxiv.org/pdf/2506.20084, 2025-06-24
2025-11-09 20:01:27,198 - INFO - root - Page:2, Index:16, Single-step Diffusion for Image Compression at Ultra-Low Bitrates, https://arxiv.org/pdf/2506.16572, 2025-09-22
2025-11-09 20:01:27,199 - INFO - root - Page:2, Index:17, LittleBit: Ultra Low-Bit Quantization via Latent Factorization, https://arxiv.org/pdf/2506.13771, 2025-10-28
2025-11-09 20:01:27,199 - INFO - root - Page:2, Index:18, MARCO: Hardware-Aware Neural Architecture Search for Edge Devices with Multi-Agent Reinforcement Learning and Conformal Prediction Filtering, https://arxiv.org/pdf/2506.13755, 2025-06-16
2025-11-09 20:01:27,200 - INFO - root - Page:2, Index:19, EAQuant: Enhancing Post-Training Quantization for MoE Models via Expert-Aware Optimization, https://arxiv.org/pdf/2506.13329, 2025-07-04
2025-11-09 20:01:27,200 - INFO - root - Page:2, Index:20, Towards Neural Audio Codec Source Parsing, https://arxiv.org/pdf/2506.12627, 2025-06-14
2025-11-09 20:01:27,200 - INFO - root - Page:2, Index:21, Quantizing Small-Scale State-Space Models for Edge AI, https://arxiv.org/pdf/2506.12480, 2025-06-14
2025-11-09 20:01:27,200 - INFO - root - Page:2, Index:22, EMLoC: Emulator-based Memory-efficient Fine-tuning with LoRA Correction, https://arxiv.org/pdf/2506.12015, 2025-06-13
2025-11-09 20:01:27,200 - INFO - root - Page:2, Index:23, Compression Aware Certified Training, https://arxiv.org/pdf/2506.11992, 2025-06-13
2025-11-09 20:01:27,203 - INFO - root - Page:2, Index:24, GPLQ: A General, Practical, and Lightning QAT Method for Vision Transformers, https://arxiv.org/pdf/2506.11784, 2025-06-13
2025-11-09 20:01:27,203 - INFO - root - Page:2, Index:25, TruncQuant: Truncation-Ready Quantization for DNNs with Flexible Weight Bit Precision, https://arxiv.org/pdf/2506.11431, 2025-06-12
2025-11-09 20:01:27,203 - INFO - root - Page:2, Index:26, EfficientQuant: An Efficient Post-Training Quantization for CNN-Transformer Hybrid Models on Edge Devices, https://arxiv.org/pdf/2506.11093, 2025-06-05
2025-11-09 20:01:27,204 - INFO - root - Page:2, Index:27, Starting Positions Matter: A Study on Better Weight Initialization for Neural Network Quantization, https://arxiv.org/pdf/2506.10463, 2025-06-12
2025-11-09 20:01:27,204 - INFO - root - Page:2, Index:28, AWP: Activation-Aware Weight Pruning and Quantization with Projected Gradient Descent, https://arxiv.org/pdf/2506.10205, 2025-06-11
2025-11-09 20:01:27,204 - INFO - root - Page:2, Index:29, Q-SAM2: Accurate Quantization for Segment Anything Model 2, https://arxiv.org/pdf/2506.09782, 2025-06-11
2025-11-09 20:01:27,204 - INFO - root - Page:2, Index:30, Unifying Block-wise PTQ and Distillation-based QAT for Progressive Quantization toward 2-bit Instruction-Tuned LLMs, https://arxiv.org/pdf/2506.09104, 2025-06-10
2025-11-09 20:01:27,205 - INFO - root - Page:2, Index:31, Implementing Keyword Spotting on the MCUX947 Microcontroller with Integrated NPU, https://arxiv.org/pdf/2506.08911, 2025-06-10
2025-11-09 20:01:27,207 - INFO - root - Page:2, Index:32, POLARON: Precision-aware On-device Learning and Adaptive Runtime-cONfigurable AI acceleration, https://arxiv.org/pdf/2506.08785, 2025-06-10
2025-11-09 20:01:27,207 - INFO - root - Page:2, Index:33, MoQAE: Mixed-Precision Quantization for Long-Context LLM Inference via Mixture of Quantization-Aware Experts, https://arxiv.org/pdf/2506.07533, 2025-06-09
2025-11-09 20:01:27,209 - INFO - root - Page:2, Index:34, BitVLA: 1-bit Vision-Language-Action Models for Robotics Manipulation, https://arxiv.org/pdf/2506.07530, 2025-06-09
2025-11-09 20:01:27,209 - INFO - root - Page:2, Index:35, RecGPT: A Foundation Model for Sequential Recommendation, https://arxiv.org/pdf/2506.06270, 2025-06-12
2025-11-09 20:01:27,209 - INFO - root - Page:2, Index:36, FPSAttention: Training-Aware FP8 and Sparsity Co-Design for Fast Video Diffusion, https://arxiv.org/pdf/2506.04648, 2025-06-05
2025-11-09 20:01:27,211 - INFO - root - Page:2, Index:37, BitTTS: Highly Compact Text-to-Speech Using 1.58-bit Quantization and Weight Indexing, https://arxiv.org/pdf/2506.03515, 2025-06-03
2025-11-09 20:01:27,212 - INFO - root - Page:2, Index:38, ShapeLLM-Omni: A Native Multimodal LLM for 3D Generation and Understanding, https://arxiv.org/pdf/2506.01853, 2025-06-02
2025-11-09 20:01:27,213 - INFO - root - Page:2, Index:39, Movable Antenna Enhanced Federated Fine-Tuning of Large Language Models via Hybrid Client Selection Optimization, https://arxiv.org/pdf/2506.00011, 2025-10-26
2025-11-09 20:01:27,215 - INFO - root - Page:2, Index:40, Running Conventional Automatic Speech Recognition on Memristor Hardware: A Simulated Approach, https://arxiv.org/pdf/2505.24721, 2025-05-30
2025-11-09 20:01:27,215 - INFO - root - Page:2, Index:41, GARLIC: GAussian Representation LearnIng for spaCe partitioning, https://arxiv.org/pdf/2505.24608, 2025-10-02
2025-11-09 20:01:27,216 - INFO - root - Page:2, Index:42, AutoChemSchematic AI: Agentic Physics-Aware Automation for Chemical Manufacturing Scale-Up, https://arxiv.org/pdf/2505.24584, 2025-08-18
2025-11-09 20:01:27,217 - INFO - root - Page:2, Index:43, Model-Preserving Adaptive Rounding, https://arxiv.org/pdf/2505.22988, 2025-09-25
2025-11-09 20:01:27,217 - INFO - root - Page:2, Index:44, Highly Efficient and Effective LLMs with Multi-Boolean Architectures, https://arxiv.org/pdf/2505.22811, 2025-10-03
2025-11-09 20:01:27,217 - INFO - root - Page:2, Index:45, Pioneering 4-Bit FP Quantization for Diffusion Models: Mixup-Sign Quantization and Timestep-Aware Fine-Tuning, https://arxiv.org/pdf/2505.21591, 2025-05-27
2025-11-09 20:01:27,217 - INFO - root - Page:2, Index:46, Frequency Composition for Compressed and Domain-Adaptive Neural Networks, https://arxiv.org/pdf/2505.20890, 2025-05-27
2025-11-09 20:01:27,218 - INFO - root - Page:2, Index:47, MoPFormer: Motion-Primitive Transformer for Wearable-Sensor Activity Recognition, https://arxiv.org/pdf/2505.20744, 2025-10-27
2025-11-09 20:01:27,218 - INFO - root - Page:2, Index:48, Optimizing edge AI models on HPC systems with the edge in the loop, https://arxiv.org/pdf/2505.19995, 2025-05-26
2025-11-09 20:01:27,223 - INFO - root - Fetching page 4 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=150
2025-11-09 20:01:33,695 - INFO - root - get_all_titles_from_web 
2025-11-09 20:01:33,696 - INFO - root - Page:3, Index:0, DPASyn: Mechanism-Aware Drug Synergy Prediction via Dual Attention and Precision-Aware Quantization, https://arxiv.org/pdf/2505.19144, 2025-09-20
2025-11-09 20:01:33,697 - INFO - root - Page:3, Index:1, Reducing Storage of Pretrained Neural Networks by Rate-Constrained Quantization and Entropy Coding, https://arxiv.org/pdf/2505.18758, 2025-05-24
2025-11-09 20:01:33,697 - INFO - root - Page:3, Index:2, Beyond Discreteness: Finite-Sample Analysis of Straight-Through Estimator for Quantization, https://arxiv.org/pdf/2505.18113, 2025-05-23
2025-11-09 20:01:33,698 - INFO - root - Page:3, Index:3, Automating Versatile Time-Series Analysis with Tiny Transformers on Embedded FPGAs, https://arxiv.org/pdf/2505.17662, 2025-09-19
2025-11-09 20:01:33,698 - INFO - root - Page:3, Index:4, FPQVAR: Floating Point Quantization for Visual Autoregressive Model with FPGA Hardware Co-design, https://arxiv.org/pdf/2505.16335, 2025-05-22
2025-11-09 20:01:33,698 - INFO - root - Page:3, Index:5, Saliency-Aware Quantized Imitation Learning for Efficient Robotic Control, https://arxiv.org/pdf/2505.15304, 2025-05-30
2025-11-09 20:01:33,700 - INFO - root - Page:3, Index:6, Scaling Law for Quantization-Aware Training, https://arxiv.org/pdf/2505.14302, 2025-05-20
2025-11-09 20:01:33,701 - INFO - root - Page:3, Index:7, Automatic mixed precision for optimizing gained time with constrained loss mean-squared-error based on model partition to sequential sub-graphs, https://arxiv.org/pdf/2505.13060, 2025-05-19
2025-11-09 20:01:33,706 - INFO - root - Page:3, Index:8, Deep Unfolding with Kernel-based Quantization in MIMO Detection, https://arxiv.org/pdf/2505.12736, 2025-05-19
2025-11-09 20:01:33,707 - INFO - root - Page:3, Index:9, FedHQ: Hybrid Runtime Quantization for Federated Learning, https://arxiv.org/pdf/2505.11982, 2025-05-17
2025-11-09 20:01:33,709 - INFO - root - Page:3, Index:10, QVGen: Pushing the Limit of Quantized Video Generative Models, https://arxiv.org/pdf/2505.11497, 2025-09-27
2025-11-09 20:01:33,711 - INFO - root - Page:3, Index:11, EA-3DGS: Efficient and Adaptive 3D Gaussians with Highly Enhanced Quality for outdoor scenes, https://arxiv.org/pdf/2505.10787, 2025-05-15
2025-11-09 20:01:33,713 - INFO - root - Page:3, Index:12, ITERA-LLM: Boosting Sub-8-Bit Large Language Model Inference via Iterative Tensor Decomposition, https://arxiv.org/pdf/2505.08981, 2025-05-13
2025-11-09 20:01:33,714 - INFO - root - Page:3, Index:13, PROM: Prioritize Reduction of Multiplications Over Lower Bit-Widths for Efficient CNNs, https://arxiv.org/pdf/2505.03254, 2025-08-06
2025-11-09 20:01:33,714 - INFO - root - Page:3, Index:14, ICQuant: Index Coding enables Low-bit LLM Quantization, https://arxiv.org/pdf/2505.00850, 2025-08-24
2025-11-09 20:01:33,714 - INFO - root - Page:3, Index:15, Enhancing Ultra-Low-Bit Quantization of Large Language Models Through Saliency-Aware Partial Retraining, https://arxiv.org/pdf/2504.13932, 2025-07-30
2025-11-09 20:01:33,715 - INFO - root - Page:3, Index:16, Achieving binary weight and activation for LLMs using Post-Training Quantization, https://arxiv.org/pdf/2504.05352, 2025-06-30
2025-11-09 20:01:33,715 - INFO - root - Page:3, Index:17, Wireless Hearables With Programmable Speech AI Accelerators, https://arxiv.org/pdf/2503.18698, 2025-10-21
2025-11-09 20:01:33,715 - INFO - root - Page:3, Index:18, GranQ: Efficient Channel-wise Quantization via Vectorized Pre-Scaling for Zero-Shot QAT, https://arxiv.org/pdf/2503.18339, 2025-10-15
2025-11-09 20:01:33,716 - INFO - root - Page:3, Index:19, CompMarkGS: Robust Watermarking for Compressed 3D Gaussian Splatting, https://arxiv.org/pdf/2503.12836, 2025-09-29
2025-11-09 20:01:33,716 - INFO - root - Page:3, Index:20, AHCPTQ: Accurate and Hardware-Compatible Post-Training Quantization for Segment Anything Model, https://arxiv.org/pdf/2503.03088, 2025-07-11
2025-11-09 20:01:33,717 - INFO - root - Page:3, Index:21, Teaching Metric Distance to Discrete Autoregressive Language Models, https://arxiv.org/pdf/2503.02379, 2025-10-07
2025-11-09 20:01:33,718 - INFO - root - Page:3, Index:22, Regularization-based Framework for Quantization-, Fault- and Variability-Aware Training, https://arxiv.org/pdf/2503.01297, 2025-07-12
2025-11-09 20:01:33,721 - INFO - root - Fetching page 5 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=200
2025-11-09 20:01:41,539 - INFO - root - get_all_titles_from_web 
2025-11-09 20:01:41,539 - INFO - root - Page:4, Index:0, Investigating the Impact of Quantization Methods on the Safety and Reliability of Large Language Models, https://arxiv.org/pdf/2502.15799, 2025-06-29
2025-11-09 20:01:41,540 - INFO - root - Page:4, Index:1, Rotate, Clip, and Partition: Towards W2A4KV4 Quantization by Integrating Rotation and Learnable Non-uniform Quantizer, https://arxiv.org/pdf/2502.15779, 2025-09-01
2025-11-09 20:01:41,540 - INFO - root - Page:4, Index:2, RoSTE: An Efficient Quantization-Aware Supervised Fine-Tuning Approach for Large Language Models, https://arxiv.org/pdf/2502.09003, 2025-06-05
2025-11-09 20:01:41,540 - INFO - root - Page:4, Index:3, Spatial Degradation-Aware and Temporal Consistent Diffusion Model for Compressed Video Super-Resolution, https://arxiv.org/pdf/2502.07381, 2025-06-27
2025-11-09 20:01:41,540 - INFO - root - Page:4, Index:4, QuEST: Stable Training of LLMs with 1-Bit Weights and Activations, https://arxiv.org/pdf/2502.05003, 2025-06-10
2025-11-09 20:01:41,540 - INFO - root - Page:4, Index:5, HALO: Hadamard-Assisted Lower-Precision Optimization for LLMs, https://arxiv.org/pdf/2501.02625, 2025-11-05
2025-11-09 20:01:41,540 - INFO - root - Page:4, Index:6, TAR3D: Creating High-Quality 3D Assets via Next-Part Prediction, https://arxiv.org/pdf/2412.16919, 2025-08-08
2025-11-09 20:01:41,542 - INFO - root - Page:4, Index:7, Training Multi-Layer Binary Neural Networks With Local Binary Error Signals, https://arxiv.org/pdf/2412.00119, 2025-08-05
2025-11-09 20:01:41,542 - INFO - root - Page:4, Index:8, Scaling Large-scale GNN Training to Thousands of Processors on CPU-based Supercomputers, https://arxiv.org/pdf/2411.16025, 2025-05-26
2025-11-09 20:01:41,542 - INFO - root - Page:4, Index:9, HAFLQ: Heterogeneous Adaptive Federated LoRA Fine-tuned LLM with Quantization, https://arxiv.org/pdf/2411.06581, 2025-05-16
2025-11-09 20:01:41,544 - INFO - root - Fetching page 6 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=250
2025-11-09 20:01:51,894 - INFO - root - get_all_titles_from_web 
2025-11-09 20:01:51,895 - INFO - root - Page:5, Index:0, Gradient-Free Training of Quantized Neural Networks, https://arxiv.org/pdf/2410.09734, 2025-09-29
2025-11-09 20:01:51,895 - INFO - root - Page:5, Index:1, QT-DoG: Quantization-aware Training for Domain Generalization, https://arxiv.org/pdf/2410.06020, 2025-06-26
2025-11-09 20:01:51,897 - INFO - root - Page:5, Index:2, Constraint Guided Model Quantization of Neural Networks, https://arxiv.org/pdf/2409.20138, 2025-09-12
2025-11-09 20:01:51,899 - INFO - root - Page:5, Index:3, Accumulator-Aware Post-Training Quantization for Large Language Models, https://arxiv.org/pdf/2409.17092, 2025-07-30
2025-11-09 20:01:51,899 - INFO - root - Page:5, Index:4, DilateQuant: Accurate and Efficient Diffusion Quantization via Weight Dilation, https://arxiv.org/pdf/2409.14307, 2025-07-09
2025-11-09 20:01:51,901 - INFO - root - Page:5, Index:5, Robust Training of Neural Networks at Arbitrary Precision and Sparsity, https://arxiv.org/pdf/2409.09245, 2025-09-23
2025-11-09 20:01:51,931 - INFO - root - Page:5, Index:6, VQ-CTAP: Cross-Modal Fine-Grained Sequence Representation Learning for Speech Processing, https://arxiv.org/pdf/2408.05758, 2025-05-27
2025-11-09 20:01:51,934 - INFO - root - Page:5, Index:7, DopQ-ViT: Towards Distribution-Friendly and Outlier-Aware Post-Training Quantization for Vision Transformers, https://arxiv.org/pdf/2408.03291, 2025-06-19
2025-11-09 20:01:51,935 - INFO - root - Page:5, Index:8, Temporal Feature Matters: A Framework for Diffusion Model Quantization, https://arxiv.org/pdf/2407.19547, 2025-07-11
2025-11-09 20:01:51,953 - INFO - root - Page:5, Index:9, EfficientQAT: Efficient Quantization-Aware Training for Large Language Models, https://arxiv.org/pdf/2407.11062, 2025-05-19
2025-11-09 20:01:51,977 - INFO - root - Page:5, Index:10, Integer-only Quantized Transformers for Embedded FPGA-based Time-series Forecasting in AIoT, https://arxiv.org/pdf/2407.11041, 2025-10-31
2025-11-09 20:01:51,979 - INFO - root - Fetching page 7 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=300
2025-11-09 20:01:58,534 - INFO - root - get_all_titles_from_web 
2025-11-09 20:01:58,534 - INFO - root - Page:6, Index:0, BoA: Attention-aware Post-training Quantization without Backpropagation, https://arxiv.org/pdf/2406.13474, 2025-06-06
2025-11-09 20:01:58,534 - INFO - root - Page:6, Index:1, A Rescaling-Invariant Lipschitz Bound Based on Path-Metrics for Modern ReLU Network Parameterizations, https://arxiv.org/pdf/2405.15006, 2025-06-13
2025-11-09 20:01:58,535 - INFO - root - Page:6, Index:2, Scheduling Weight Transitions for Quantization-Aware Training, https://arxiv.org/pdf/2404.19248, 2025-10-01
2025-11-09 20:01:58,535 - INFO - root - Page:6, Index:3, GPTVQ: The Blessing of Dimensionality for LLM Quantization, https://arxiv.org/pdf/2402.15319, 2025-06-03
2025-11-09 20:01:58,535 - INFO - root - Fetching page 8 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=350
2025-11-09 20:02:06,126 - INFO - root - get_all_titles_from_web 
2025-11-09 20:02:06,126 - INFO - root - Page:7, Index:0, Squat: Quant Small Language Models on the Edge, https://arxiv.org/pdf/2402.10787, 2025-07-01
2025-11-09 20:02:06,127 - INFO - root - Page:7, Index:1, L4Q: Parameter Efficient Quantization-Aware Fine-Tuning on Large Language Models, https://arxiv.org/pdf/2402.04902, 2025-07-21
2025-11-09 20:02:06,127 - INFO - root - Fetching page 9 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=400
2025-11-09 20:02:12,933 - INFO - root - ------------------------------------------------------------------------------------------------------------------------
2025-11-09 20:02:25,773 - INFO - root - 跳过已处理论文 A Quantized VAE-MLP Botnet Detection Model: A Systematic Evaluation of Quantization-Aware Training and Post-Training Quantization Strategies：D:\ChatPaper\academic Papers\Quantization-Aware-Training\A Quantized VAE-MLP Botnet Detection Model_ A Systematic Evaluation of Quantizat-3.pdf
2025-11-09 20:02:25,779 - INFO - root - 跳过已处理论文 FP8-Flow-MoE: A Casting-Free FP8 Recipe without Double Quantization Error：D:\ChatPaper\academic Papers\Quantization-Aware-Training\FP8-Flow-MoE_ A Casting-Free FP8 Recipe without Double Quantization Error-3.pdf
2025-11-09 20:02:25,832 - INFO - root - summary time: 90.09 seconds
2025-11-09 20:12:00,720 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-09 20:12:00,723 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-09 20:12:00,726 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-09 20:12:02,579 - INFO - root - LLMClientManager: 指定使用客户端: Deepseek
2025-11-09 20:12:02,580 - INFO - root - DeepSeekClient: API key found: 9f9e270e-b...
2025-11-09 20:12:02,582 - INFO - root - DeepSeekClient: 使用模式: 火山引擎
2025-11-09 20:12:02,583 - INFO - root - DeepSeekClient: 模型名称: deepseek-v3-1-terminus
2025-11-09 20:12:06,717 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 20:12:06,745 - INFO - root - DeepSeekClient: initialized successfully with model deepseek-v3-1-terminus
2025-11-09 20:12:06,745 - INFO - root - LLMClientManager: DeepSeek 客户端初始化成功
2025-11-09 20:12:06,745 - WARNING - root - LLMClientManager: client Deepseek not available
2025-11-09 20:12:06,746 - WARNING - root - 无法切换到指定的客户端 Deepseek，将使用默认客户端
2025-11-09 20:12:06,746 - INFO - root - 可用客户端: ['DeepSeek']
2025-11-09 20:12:06,746 - INFO - root - 使用 LLM 模型: deepseek-v3-1-terminus
2025-11-09 20:12:06,747 - INFO - root - 可用客户端: ['DeepSeek']
2025-11-09 20:12:06,748 - INFO - root - === 运行配置 ===
2025-11-09 20:12:06,749 - INFO - root - 处理模式: arxiv在线搜索
2025-11-09 20:12:06,750 - INFO - root - 关键词: QAT
2025-11-09 20:12:06,760 - INFO - root - 查询: Quantization-Aware-Training
2025-11-09 20:12:06,776 - INFO - root - 排序: None
2025-11-09 20:12:06,793 - INFO - root - 最近天数: 180
2025-11-09 20:12:06,794 - INFO - root - 最大处理数量: 2
2025-11-09 20:12:06,794 - INFO - root - 保存图片: 是
2025-11-09 20:12:06,794 - INFO - root - 输出语言: 中文
2025-11-09 20:12:06,795 - INFO - root - 强制重新处理: 否
2025-11-09 20:12:06,795 - INFO - root - ====================
2025-11-09 20:12:06,796 - INFO - root - 使用 arXiv 搜索模式（通过 chat_arxiv 模块获取）
2025-11-09 20:12:06,797 - INFO - root - Fetching page 1 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50
2025-11-09 20:12:13,586 - INFO - root - get_all_titles_from_web 
2025-11-09 20:12:13,587 - INFO - root - Page:0, Index:0, A Quantized VAE-MLP Botnet Detection Model: A Systematic Evaluation of Quantization-Aware Training and Post-Training Quantization Strategies, https://arxiv.org/pdf/2511.03201, 2025-11-05
2025-11-09 20:12:13,587 - INFO - root - Page:0, Index:1, FP8-Flow-MoE: A Casting-Free FP8 Recipe without Double Quantization Error, https://arxiv.org/pdf/2511.02302, 2025-11-04
2025-11-09 20:12:13,587 - INFO - root - Page:0, Index:2, Outlier-Aware Post-Training Quantization for Image Super-Resolution, https://arxiv.org/pdf/2511.00682, 2025-11-01
2025-11-09 20:12:13,587 - INFO - root - Page:0, Index:3, Evaluation of Wafer-Scale SOT-MRAM for Analog Crossbar Array Applications, https://arxiv.org/pdf/2510.25853, 2025-11-03
2025-11-09 20:12:13,588 - INFO - root - Page:0, Index:4, Improving the Straight-Through Estimator with Zeroth-Order Information, https://arxiv.org/pdf/2510.23926, 2025-10-27
2025-11-09 20:12:13,588 - INFO - root - Page:0, Index:5, Real-Time Semantic Segmentation on FPGA for Autonomous Vehicles Using LMIINet with the CGRA4ML Framework, https://arxiv.org/pdf/2510.22243, 2025-10-25
2025-11-09 20:12:13,588 - INFO - root - Page:0, Index:6, TernaryCLIP: Efficiently Compressing Vision-Language Models with Ternary Weights and Distilled Knowledge, https://arxiv.org/pdf/2510.21879, 2025-10-23
2025-11-09 20:12:13,588 - INFO - root - Page:0, Index:7, KARIPAP: Quantum-Inspired Tensor Network Compression of Large Language Models Using Infinite Projected Entangled Pair States and Tensor Renormalization Group, https://arxiv.org/pdf/2510.21844, 2025-10-22
2025-11-09 20:12:13,590 - INFO - root - Page:0, Index:8, A Convergence Analysis of Adaptive Optimizers under Floating-point Quantization, https://arxiv.org/pdf/2510.21314, 2025-10-24
2025-11-09 20:12:13,590 - INFO - root - Page:0, Index:9, Adaptive Distribution-aware Quantization for Mixed-Precision Neural Networks, https://arxiv.org/pdf/2510.19760, 2025-10-22
2025-11-09 20:12:13,590 - INFO - root - Page:0, Index:10, CAGE: Curvature-Aware Gradient Estimation For Accurate Quantization-Aware Training, https://arxiv.org/pdf/2510.18784, 2025-10-21
2025-11-09 20:12:13,590 - INFO - root - Page:0, Index:11, Mixed-Precision Quantization for Language Models: Techniques and Prospects, https://arxiv.org/pdf/2510.16805, 2025-10-19
2025-11-09 20:12:13,591 - INFO - root - Page:0, Index:12, SPLite Hand: Sparsity-Aware Lightweight 3D Hand Pose Estimation, https://arxiv.org/pdf/2510.16396, 2025-10-30
2025-11-09 20:12:13,591 - INFO - root - Page:0, Index:13, CTR-LoRA: Curvature-Aware and Trust-Region Guided Low-Rank Adaptation for Large Language Models, https://arxiv.org/pdf/2510.15962, 2025-10-11
2025-11-09 20:12:13,592 - INFO - root - Page:0, Index:14, SANR: Scene-Aware Neural Representation for Light Field Image Compression with Rate-Distortion Optimization, https://arxiv.org/pdf/2510.15775, 2025-10-17
2025-11-09 20:12:13,592 - INFO - root - Page:0, Index:15, SpikeFit: Towards Optimal Deployment of Spiking Networks on Neuromorphic Hardware, https://arxiv.org/pdf/2510.15542, 2025-10-31
2025-11-09 20:12:13,592 - INFO - root - Page:0, Index:16, GRank: Towards Target-Aware and Streamlined Industrial Retrieval with a Generate-Rank Framework, https://arxiv.org/pdf/2510.15299, 2025-10-17
2025-11-09 20:12:13,593 - INFO - root - Page:0, Index:17, SaLon3R: Structure-aware Long-term Generalizable 3D Reconstruction from Unposed Images, https://arxiv.org/pdf/2510.15072, 2025-10-16
2025-11-09 20:12:13,593 - INFO - root - Page:0, Index:18, FraQAT: Quantization Aware Training with Fractional bits, https://arxiv.org/pdf/2510.14823, 2025-10-16
2025-11-09 20:12:13,594 - INFO - root - Page:0, Index:19, Computing-In-Memory Aware Model Adaption For Edge Devices, https://arxiv.org/pdf/2510.14379, 2025-10-16
2025-11-09 20:12:13,594 - INFO - root - Page:0, Index:20, Invited Paper: BitMedViT: Ternary-Quantized Vision Transformer for Medical AI Assistants on the Edge, https://arxiv.org/pdf/2510.13760, 2025-11-04
2025-11-09 20:12:13,594 - INFO - root - Page:0, Index:21, NeuroRVQ: Multi-Scale EEG Tokenization for Generative Large Brainwave Models, https://arxiv.org/pdf/2510.13068, 2025-10-14
2025-11-09 20:12:13,595 - INFO - root - Page:0, Index:22, Detect Anything via Next Point Prediction, https://arxiv.org/pdf/2510.12798, 2025-10-14
2025-11-09 20:12:13,595 - INFO - root - Page:0, Index:23, AndesVL Technical Report: An Efficient Mobile-side Multimodal Large Language Model, https://arxiv.org/pdf/2510.11496, 2025-10-14
2025-11-09 20:12:13,595 - INFO - root - Page:0, Index:24, Rescaling-Aware Training for Efficient Deployment of Deep Learning Models on Full-Integer Hardware, https://arxiv.org/pdf/2510.11484, 2025-10-13
2025-11-09 20:12:13,595 - INFO - root - Page:0, Index:25, SASER: Stego attacks on open-source LLMs, https://arxiv.org/pdf/2510.10486, 2025-10-12
2025-11-09 20:12:13,597 - INFO - root - Page:0, Index:26, Ultralytics YOLO Evolution: An Overview of YOLO26, YOLO11, YOLOv8 and YOLOv5 Object Detectors for Computer Vision and Pattern Recognition, https://arxiv.org/pdf/2510.09653, 2025-10-15
2025-11-09 20:12:13,597 - INFO - root - Page:0, Index:27, A Theoretically-Grounded Codebook for Digital Semantic Communications, https://arxiv.org/pdf/2510.07108, 2025-10-14
2025-11-09 20:12:13,597 - INFO - root - Page:0, Index:28, QuantDemoire: Quantization with Outlier Aware for Image Demoiréing, https://arxiv.org/pdf/2510.04066, 2025-10-05
2025-11-09 20:12:13,598 - INFO - root - Page:0, Index:29, Adaptively Sampling-Reusing-Mixing Decomposed Gradients to Speed Up Sharpness Aware Minimization, https://arxiv.org/pdf/2510.03763, 2025-10-04
2025-11-09 20:12:13,598 - INFO - root - Page:0, Index:30, Quant-dLLM: Post-Training Extreme Low-Bit Quantization for Diffusion Large Language Models, https://arxiv.org/pdf/2510.03274, 2025-09-27
2025-11-09 20:12:13,598 - INFO - root - Page:0, Index:31, PT$^2$-LLM: Post-Training Ternarization for Large Language Models, https://arxiv.org/pdf/2510.03267, 2025-09-26
2025-11-09 20:12:13,602 - INFO - root - Page:0, Index:32, Purrception: Variational Flow Matching for Vector-Quantized Image Generation, https://arxiv.org/pdf/2510.01478, 2025-10-01
2025-11-09 20:12:13,602 - INFO - root - Page:0, Index:33, Post-Training Quantization for Audio Diffusion Transformers, https://arxiv.org/pdf/2510.00313, 2025-09-30
2025-11-09 20:12:13,603 - INFO - root - Page:0, Index:34, Rethinking RoPE Scaling in Quantized LLM: Theory, Outlier, and Channel-Band Analysis with Weight Rescaling, https://arxiv.org/pdf/2510.00028, 2025-09-25
2025-11-09 20:12:13,603 - INFO - root - Page:0, Index:35, Post-Training Quantization via Residual Truncation and Zero Suppression for Diffusion Models, https://arxiv.org/pdf/2509.26436, 2025-09-30
2025-11-09 20:12:13,604 - INFO - root - Page:0, Index:36, Cat: Post-Training Quantization Error Reduction via Cluster-based Affine Transformation, https://arxiv.org/pdf/2509.26277, 2025-10-07
2025-11-09 20:12:13,604 - INFO - root - Page:0, Index:37, CAST: Continuous and Differentiable Semi-Structured Sparsity-Aware Training for Large Language Models, https://arxiv.org/pdf/2509.25996, 2025-09-30
2025-11-09 20:12:13,604 - INFO - root - Page:0, Index:38, Norm-Q: Effective Compression Method for Hidden Markov Models in Neuro-Symbolic Applications, https://arxiv.org/pdf/2509.25439, 2025-09-29
2025-11-09 20:12:13,606 - INFO - root - Page:0, Index:39, On-the-Fly Adaptation to Quantization: Configuration-Aware LoRA for Efficient Fine-Tuning of Quantized LLMs, https://arxiv.org/pdf/2509.25214, 2025-09-22
2025-11-09 20:12:13,606 - INFO - root - Page:0, Index:40, VoxCPM: Tokenizer-Free TTS for Context-Aware Speech Generation and True-to-Life Voice Cloning, https://arxiv.org/pdf/2509.24650, 2025-09-29
2025-11-09 20:12:13,606 - INFO - root - Page:0, Index:41, S$^2$NN: Sub-bit Spiking Neural Networks, https://arxiv.org/pdf/2509.24266, 2025-10-24
2025-11-09 20:12:13,606 - INFO - root - Page:0, Index:42, Tequila: Trapping-free Ternary Quantization for Large Language Models, https://arxiv.org/pdf/2509.23809, 2025-10-17
2025-11-09 20:12:13,607 - INFO - root - Page:0, Index:43, Texture Vector-Quantization and Reconstruction Aware Prediction for Generative Super-Resolution, https://arxiv.org/pdf/2509.23774, 2025-09-30
2025-11-09 20:12:13,607 - INFO - root - Page:0, Index:44, RobuQ: Pushing DiTs to W1.58A2 via Robust Activation Quantization, https://arxiv.org/pdf/2509.23582, 2025-09-27
2025-11-09 20:12:13,612 - INFO - root - Page:0, Index:45, Beyond Outliers: A Study of Optimizers Under Quantization, https://arxiv.org/pdf/2509.23500, 2025-10-02
2025-11-09 20:12:13,613 - INFO - root - Page:0, Index:46, Compute-Optimal Quantization-Aware Training, https://arxiv.org/pdf/2509.22935, 2025-09-26
2025-11-09 20:12:13,613 - INFO - root - Page:0, Index:47, COSPADI: Compressing LLMs via Calibration-Guided Sparse Dictionary Learning, https://arxiv.org/pdf/2509.22075, 2025-10-06
2025-11-09 20:12:13,614 - INFO - root - Page:0, Index:48, SlimDiff: Training-Free, Activation-Guided Hands-free Slimming of Diffusion Models, https://arxiv.org/pdf/2509.21498, 2025-09-25
2025-11-09 20:12:13,614 - INFO - root - Page:0, Index:49, Quantized Visual Geometry Grounded Transformer, https://arxiv.org/pdf/2509.21302, 2025-09-29
2025-11-09 20:12:13,615 - INFO - root - Fetching page 2 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=50
2025-11-09 20:12:20,154 - INFO - root - get_all_titles_from_web 
2025-11-09 20:12:20,155 - INFO - root - Page:1, Index:0, Can Less Precise Be More Reliable? A Systematic Evaluation of Quantization's Impact on CLIP Beyond Accuracy, https://arxiv.org/pdf/2509.21173, 2025-10-27
2025-11-09 20:12:20,156 - INFO - root - Page:1, Index:1, Punching Above Precision: Small Quantized Model Distillation with Learnable Regularizer, https://arxiv.org/pdf/2509.20854, 2025-09-25
2025-11-09 20:12:20,156 - INFO - root - Page:1, Index:2, TinyEcoWeedNet: Edge Efficient Real-Time Aerial Agricultural Weed Detection, https://arxiv.org/pdf/2509.18193, 2025-09-19
2025-11-09 20:12:20,156 - INFO - root - Page:1, Index:3, SBVR: Summation of BitVector Representation for Efficient LLM Quantization, https://arxiv.org/pdf/2509.18172, 2025-09-17
2025-11-09 20:12:20,156 - INFO - root - Page:1, Index:4, QWHA: Quantization-Aware Walsh-Hadamard Adaptation for Parameter-Efficient Fine-Tuning on Large Language Models, https://arxiv.org/pdf/2509.17428, 2025-09-26
2025-11-09 20:12:20,156 - INFO - root - Page:1, Index:5, PTQTP: Post-Training Quantization to Trit-Planes for Large Language Models, https://arxiv.org/pdf/2509.16989, 2025-10-28
2025-11-09 20:12:20,156 - INFO - root - Page:1, Index:6, MEC-Quant: Maximum Entropy Coding for Extremely Low Bit Quantization-Aware Training, https://arxiv.org/pdf/2509.15514, 2025-09-18
2025-11-09 20:12:20,157 - INFO - root - Page:1, Index:7, Q-ROAR: Outlier-Aware Rescaling for RoPE Position Interpolation in Quantized Long-Context LLMs, https://arxiv.org/pdf/2509.14391, 2025-09-17
2025-11-09 20:12:20,157 - INFO - root - Page:1, Index:8, Efficient Quantization-Aware Neural Receivers: Beyond Post-Training Quantization, https://arxiv.org/pdf/2509.13786, 2025-09-19
2025-11-09 20:12:20,157 - INFO - root - Page:1, Index:9, Rate-Distortion Limits for Multimodal Retrieval: Theory, Optimal Codes, and Finite-Sample Guarantees, https://arxiv.org/pdf/2509.11054, 2025-09-13
2025-11-09 20:12:20,157 - INFO - root - Page:1, Index:10, SQAP-VLA: A Synergistic Quantization-Aware Pruning Framework for High-Performance Vision-Language-Action Models, https://arxiv.org/pdf/2509.09090, 2025-09-10
2025-11-09 20:12:20,158 - INFO - root - Page:1, Index:11, CSI Compression Beyond Latents: End-to-End Hybrid Attention-CNN Networks with Entropy Regularization, https://arxiv.org/pdf/2509.08776, 2025-09-10
2025-11-09 20:12:20,158 - INFO - root - Page:1, Index:12, Explaining How Quantization Disparately Skews a Model, https://arxiv.org/pdf/2509.07222, 2025-09-08
2025-11-09 20:12:20,158 - INFO - root - Page:1, Index:13, LoaQ: Layer-wise Output Approximation Quantization, https://arxiv.org/pdf/2509.06297, 2025-09-07
2025-11-09 20:12:20,159 - INFO - root - Page:1, Index:14, FineServe: Precision-Aware KV Slab and Two-Level Scheduling for Heterogeneous Precision LLM Serving, https://arxiv.org/pdf/2509.06261, 2025-09-14
2025-11-09 20:12:20,159 - INFO - root - Page:1, Index:15, Sensitivity-Aware Post-Training Quantization for Deep Neural Networks, https://arxiv.org/pdf/2509.05576, 2025-09-05
2025-11-09 20:12:20,159 - INFO - root - Page:1, Index:16, SuperSNN: A Hardware-Aware Framework for Physically Realizable, High-Performance Superconducting Spiking Neural Network Chips, https://arxiv.org/pdf/2509.05532, 2025-09-05
2025-11-09 20:12:20,160 - INFO - root - Page:1, Index:17, Data-Augmented Quantization-Aware Knowledge Distillation, https://arxiv.org/pdf/2509.03850, 2025-09-03
2025-11-09 20:12:20,161 - INFO - root - Page:1, Index:18, DPQuant: Efficient and Differentially-Private Model Training via Dynamic Quantization Scheduling, https://arxiv.org/pdf/2509.03472, 2025-09-03
2025-11-09 20:12:20,161 - INFO - root - Page:1, Index:19, Empowering Large Language Model for Sequential Recommendation via Multimodal Embeddings and Semantic IDs, https://arxiv.org/pdf/2509.02017, 2025-09-02
2025-11-09 20:12:20,162 - INFO - root - Page:1, Index:20, Q-Sched: Pushing the Boundaries of Few-Step Diffusion Models with Quantization-Aware Scheduling, https://arxiv.org/pdf/2509.01624, 2025-09-01
2025-11-09 20:12:20,162 - INFO - root - Page:1, Index:21, Quantization Meets OOD: Generalizable Quantization-aware Training from a Flatness Perspective, https://arxiv.org/pdf/2509.00859, 2025-08-31
2025-11-09 20:12:20,163 - INFO - root - Page:1, Index:22, Progressive Element-wise Gradient Estimation for Neural Network Quantization, https://arxiv.org/pdf/2509.00097, 2025-08-27
2025-11-09 20:12:20,163 - INFO - root - Page:1, Index:23, End-to-End On-Device Quantization-Aware Training for LLMs at Inference Cost, https://arxiv.org/pdf/2509.00031, 2025-09-29
2025-11-09 20:12:20,163 - INFO - root - Page:1, Index:24, Quantization Robustness to Input Degradations for Object Detection, https://arxiv.org/pdf/2508.19600, 2025-08-27
2025-11-09 20:12:20,163 - INFO - root - Page:1, Index:25, Scaling Laws for Task-Stratified Knowledge in Post-Training Quantized Large Language Models, https://arxiv.org/pdf/2508.18609, 2025-08-27
2025-11-09 20:12:20,164 - INFO - root - Page:1, Index:26, AQ-PCDSys: An Adaptive Quantized Planetary Crater Detection System for Autonomous Space Exploration, https://arxiv.org/pdf/2508.18025, 2025-08-25
2025-11-09 20:12:20,166 - INFO - root - Page:1, Index:27, TaDiCodec: Text-aware Diffusion Speech Tokenizer for Speech Language Modeling, https://arxiv.org/pdf/2508.16790, 2025-08-22
2025-11-09 20:12:20,166 - INFO - root - Page:1, Index:28, A Node-Aware Dynamic Quantization Approach for Graph Collaborative Filtering, https://arxiv.org/pdf/2508.16516, 2025-08-22
2025-11-09 20:12:20,166 - INFO - root - Page:1, Index:29, JEDI-linear: Fast and Efficient Graph Neural Networks for Jet Tagging on FPGAs, https://arxiv.org/pdf/2508.15468, 2025-08-21
2025-11-09 20:12:20,166 - INFO - root - Page:1, Index:30, MMQ: Multimodal Mixture-of-Quantization Tokenization for Semantic ID Generation and User Behavioral Adaptation, https://arxiv.org/pdf/2508.15281, 2025-08-21
2025-11-09 20:12:20,167 - INFO - root - Page:1, Index:31, DLLMQuant: Quantizing Diffusion-based Large Language Models, https://arxiv.org/pdf/2508.14090, 2025-08-25
2025-11-09 20:12:20,168 - INFO - root - Page:1, Index:32, Automated Energy-Aware Time-Series Model Deployment on Embedded FPGAs for Resilient Combined Sewer Overflow Management, https://arxiv.org/pdf/2508.13905, 2025-08-19
2025-11-09 20:12:20,172 - INFO - root - Page:1, Index:33, XR-NPE: High-Throughput Mixed-precision SIMD Neural Processing Engine for Extended Reality Perception Workloads, https://arxiv.org/pdf/2508.13049, 2025-08-18
2025-11-09 20:12:20,172 - INFO - root - Page:1, Index:34, Exploring Self-Supervised Audio Models for Generalized Anomalous Sound Detection, https://arxiv.org/pdf/2508.12230, 2025-08-17
2025-11-09 20:12:20,172 - INFO - root - Page:1, Index:35, TriQDef: Disrupting Semantic and Gradient Alignment to Prevent Adversarial Patch Transferability in Quantized Neural Networks, https://arxiv.org/pdf/2508.12132, 2025-08-16
2025-11-09 20:12:20,173 - INFO - root - Page:1, Index:36, Error Propagation Mechanisms and Compensation Strategies for Quantized Diffusion, https://arxiv.org/pdf/2508.12094, 2025-10-13
2025-11-09 20:12:20,173 - INFO - root - Page:1, Index:37, Extending Straight-Through Estimation for Robust Neural Networks on Analog CIM Hardware, https://arxiv.org/pdf/2508.11940, 2025-08-16
2025-11-09 20:12:20,173 - INFO - root - Page:1, Index:38, PTQAT: A Hybrid Parameter-Efficient Quantization Algorithm for 3D Perception Tasks, https://arxiv.org/pdf/2508.10557, 2025-08-15
2025-11-09 20:12:20,173 - INFO - root - Page:1, Index:39, MiCo: End-to-End Mixed Precision Neural Network Co-Exploration Framework for Edge AI, https://arxiv.org/pdf/2508.09500, 2025-08-13
2025-11-09 20:12:20,174 - INFO - root - Page:1, Index:40, SPARC: Soft Probabilistic Adaptive multi-interest Retrieval Model via Codebooks for recommender system, https://arxiv.org/pdf/2508.09090, 2025-08-12
2025-11-09 20:12:20,174 - INFO - root - Page:1, Index:41, Rethinking 1-bit Optimization Leveraging Pre-trained Large Language Models, https://arxiv.org/pdf/2508.06974, 2025-08-09
2025-11-09 20:12:20,174 - INFO - root - Page:1, Index:42, Efficient Deep Neural Receiver with Post-Training Quantization, https://arxiv.org/pdf/2508.06275, 2025-08-08
2025-11-09 20:12:20,175 - INFO - root - Page:1, Index:43, iFairy: the First 2-bit Complex LLM with All Parameters in $\{\pm1, \pm i\}$, https://arxiv.org/pdf/2508.05571, 2025-08-16
2025-11-09 20:12:20,175 - INFO - root - Page:1, Index:44, S$^2$Q-VDiT: Accurate Quantized Video Diffusion Transformer with Salient Data and Sparse Token Distillation, https://arxiv.org/pdf/2508.04016, 2025-10-27
2025-11-09 20:12:20,175 - INFO - root - Page:1, Index:45, LRQ-DiT: Log-Rotation Post-Training Quantization of Diffusion Transformers for Image and Video Generation, https://arxiv.org/pdf/2508.03485, 2025-09-23
2025-11-09 20:12:20,176 - INFO - root - Page:1, Index:46, VLMQ: Efficient Post-Training Quantization for Large Vision-Language Models via Hessian Augmentation, https://arxiv.org/pdf/2508.03351, 2025-08-05
2025-11-09 20:12:20,176 - INFO - root - Page:1, Index:47, TF-MLPNet: Tiny Real-Time Neural Speech Separation, https://arxiv.org/pdf/2508.03047, 2025-08-04
2025-11-09 20:12:20,177 - INFO - root - Page:1, Index:48, SaviorRec: Semantic-Behavior Alignment for Cold-Start Recommendation, https://arxiv.org/pdf/2508.01375, 2025-08-02
2025-11-09 20:12:20,177 - INFO - root - Page:1, Index:49, MixA-Q: Revisiting Activation Sparsity for Vision Transformers from a Mixed-Precision Quantization Perspective, https://arxiv.org/pdf/2507.19131, 2025-07-25
2025-11-09 20:12:20,177 - INFO - root - Fetching page 3 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=100
2025-11-09 20:12:26,765 - INFO - root - get_all_titles_from_web 
2025-11-09 20:12:26,765 - INFO - root - Page:2, Index:0, Enhancing Quantization-Aware Training on Edge Devices via Relative Entropy Coreset Selection and Cascaded Layer Correction, https://arxiv.org/pdf/2507.17768, 2025-07-16
2025-11-09 20:12:26,766 - INFO - root - Page:2, Index:1, SiLQ: Simple Large Language Model Quantization-Aware Training, https://arxiv.org/pdf/2507.16933, 2025-07-22
2025-11-09 20:12:26,770 - INFO - root - Page:2, Index:2, Task-Specific Zero-shot Quantization-Aware Training for Object Detection, https://arxiv.org/pdf/2507.16782, 2025-07-22
2025-11-09 20:12:26,779 - INFO - root - Page:2, Index:3, TorchAO: PyTorch-Native Training-to-Serving Model Optimization, https://arxiv.org/pdf/2507.16099, 2025-07-21
2025-11-09 20:12:26,783 - INFO - root - Page:2, Index:4, SegQuant: A Semantics-Aware and Generalizable Quantization Framework for Diffusion Models, https://arxiv.org/pdf/2507.14811, 2025-08-27
2025-11-09 20:12:26,799 - INFO - root - Page:2, Index:5, Apple Intelligence Foundation Language Models: Tech Report 2025, https://arxiv.org/pdf/2507.13575, 2025-08-27
2025-11-09 20:12:26,813 - INFO - root - Page:2, Index:6, Generative Multi-Target Cross-Domain Recommendation, https://arxiv.org/pdf/2507.12871, 2025-08-07
2025-11-09 20:12:26,816 - INFO - root - Page:2, Index:7, DAF: An Efficient End-to-End Dynamic Activation Framework for on-Device DNN Training, https://arxiv.org/pdf/2507.07149, 2025-07-09
2025-11-09 20:12:26,828 - INFO - root - Page:2, Index:8, Opto-ViT: Architecting a Near-Sensor Region of Interest-Aware Vision Transformer Accelerator with Silicon Photonics, https://arxiv.org/pdf/2507.07044, 2025-07-15
2025-11-09 20:12:26,832 - INFO - root - Page:2, Index:9, QS4D: Quantization-aware training for efficient hardware deployment of structured state-space sequential models, https://arxiv.org/pdf/2507.06079, 2025-07-08
2025-11-09 20:12:26,836 - INFO - root - Page:2, Index:10, GSVR: 2D Gaussian-based Video Representation for 800+ FPS with Hybrid Deformation Field, https://arxiv.org/pdf/2507.05594, 2025-07-07
2025-11-09 20:12:26,840 - INFO - root - Page:2, Index:11, Hita: Holistic Tokenizer for Autoregressive Image Generation, https://arxiv.org/pdf/2507.02358, 2025-07-11
2025-11-09 20:12:26,845 - INFO - root - Page:2, Index:12, QPART: Adaptive Model Quantization and Dynamic Workload Balancing for Accuracy-aware Edge Inference, https://arxiv.org/pdf/2506.23934, 2025-06-30
2025-11-09 20:12:26,849 - INFO - root - Page:2, Index:13, FedWSQ: Efficient Federated Learning with Weight Standardization and Distribution-Aware Non-Uniform Quantization, https://arxiv.org/pdf/2506.23516, 2025-07-21
2025-11-09 20:12:26,857 - INFO - root - Page:2, Index:14, Spectra 1.1: Scaling Laws and Efficient Inference for Ternary Language Models, https://arxiv.org/pdf/2506.23025, 2025-06-28
2025-11-09 20:12:26,860 - INFO - root - Page:2, Index:15, Joint Quantization and Pruning Neural Networks Approach: A Case Study on FSO Receivers, https://arxiv.org/pdf/2506.20084, 2025-06-24
2025-11-09 20:12:26,866 - INFO - root - Page:2, Index:16, Single-step Diffusion for Image Compression at Ultra-Low Bitrates, https://arxiv.org/pdf/2506.16572, 2025-09-22
2025-11-09 20:12:26,871 - INFO - root - Page:2, Index:17, LittleBit: Ultra Low-Bit Quantization via Latent Factorization, https://arxiv.org/pdf/2506.13771, 2025-10-28
2025-11-09 20:12:26,876 - INFO - root - Page:2, Index:18, MARCO: Hardware-Aware Neural Architecture Search for Edge Devices with Multi-Agent Reinforcement Learning and Conformal Prediction Filtering, https://arxiv.org/pdf/2506.13755, 2025-06-16
2025-11-09 20:12:26,879 - INFO - root - Page:2, Index:19, EAQuant: Enhancing Post-Training Quantization for MoE Models via Expert-Aware Optimization, https://arxiv.org/pdf/2506.13329, 2025-07-04
2025-11-09 20:12:26,885 - INFO - root - Page:2, Index:20, Towards Neural Audio Codec Source Parsing, https://arxiv.org/pdf/2506.12627, 2025-06-14
2025-11-09 20:12:26,886 - INFO - root - Page:2, Index:21, Quantizing Small-Scale State-Space Models for Edge AI, https://arxiv.org/pdf/2506.12480, 2025-06-14
2025-11-09 20:12:26,892 - INFO - root - Page:2, Index:22, EMLoC: Emulator-based Memory-efficient Fine-tuning with LoRA Correction, https://arxiv.org/pdf/2506.12015, 2025-06-13
2025-11-09 20:12:26,898 - INFO - root - Page:2, Index:23, Compression Aware Certified Training, https://arxiv.org/pdf/2506.11992, 2025-06-13
2025-11-09 20:12:26,902 - INFO - root - Page:2, Index:24, GPLQ: A General, Practical, and Lightning QAT Method for Vision Transformers, https://arxiv.org/pdf/2506.11784, 2025-06-13
2025-11-09 20:12:26,907 - INFO - root - Page:2, Index:25, TruncQuant: Truncation-Ready Quantization for DNNs with Flexible Weight Bit Precision, https://arxiv.org/pdf/2506.11431, 2025-06-12
2025-11-09 20:12:26,911 - INFO - root - Page:2, Index:26, EfficientQuant: An Efficient Post-Training Quantization for CNN-Transformer Hybrid Models on Edge Devices, https://arxiv.org/pdf/2506.11093, 2025-06-05
2025-11-09 20:12:26,916 - INFO - root - Page:2, Index:27, Starting Positions Matter: A Study on Better Weight Initialization for Neural Network Quantization, https://arxiv.org/pdf/2506.10463, 2025-06-12
2025-11-09 20:12:26,918 - INFO - root - Page:2, Index:28, AWP: Activation-Aware Weight Pruning and Quantization with Projected Gradient Descent, https://arxiv.org/pdf/2506.10205, 2025-06-11
2025-11-09 20:12:26,924 - INFO - root - Page:2, Index:29, Q-SAM2: Accurate Quantization for Segment Anything Model 2, https://arxiv.org/pdf/2506.09782, 2025-06-11
2025-11-09 20:12:26,926 - INFO - root - Page:2, Index:30, Unifying Block-wise PTQ and Distillation-based QAT for Progressive Quantization toward 2-bit Instruction-Tuned LLMs, https://arxiv.org/pdf/2506.09104, 2025-06-10
2025-11-09 20:12:26,934 - INFO - root - Page:2, Index:31, Implementing Keyword Spotting on the MCUX947 Microcontroller with Integrated NPU, https://arxiv.org/pdf/2506.08911, 2025-06-10
2025-11-09 20:12:26,945 - INFO - root - Page:2, Index:32, POLARON: Precision-aware On-device Learning and Adaptive Runtime-cONfigurable AI acceleration, https://arxiv.org/pdf/2506.08785, 2025-06-10
2025-11-09 20:12:26,987 - INFO - root - Page:2, Index:33, MoQAE: Mixed-Precision Quantization for Long-Context LLM Inference via Mixture of Quantization-Aware Experts, https://arxiv.org/pdf/2506.07533, 2025-06-09
2025-11-09 20:12:27,010 - INFO - root - Page:2, Index:34, BitVLA: 1-bit Vision-Language-Action Models for Robotics Manipulation, https://arxiv.org/pdf/2506.07530, 2025-06-09
2025-11-09 20:12:27,033 - INFO - root - Page:2, Index:35, RecGPT: A Foundation Model for Sequential Recommendation, https://arxiv.org/pdf/2506.06270, 2025-06-12
2025-11-09 20:12:27,045 - INFO - root - Page:2, Index:36, FPSAttention: Training-Aware FP8 and Sparsity Co-Design for Fast Video Diffusion, https://arxiv.org/pdf/2506.04648, 2025-06-05
2025-11-09 20:12:27,052 - INFO - root - Page:2, Index:37, BitTTS: Highly Compact Text-to-Speech Using 1.58-bit Quantization and Weight Indexing, https://arxiv.org/pdf/2506.03515, 2025-06-03
2025-11-09 20:12:27,060 - INFO - root - Page:2, Index:38, ShapeLLM-Omni: A Native Multimodal LLM for 3D Generation and Understanding, https://arxiv.org/pdf/2506.01853, 2025-06-02
2025-11-09 20:12:27,062 - INFO - root - Page:2, Index:39, Movable Antenna Enhanced Federated Fine-Tuning of Large Language Models via Hybrid Client Selection Optimization, https://arxiv.org/pdf/2506.00011, 2025-10-26
2025-11-09 20:12:27,063 - INFO - root - Page:2, Index:40, Running Conventional Automatic Speech Recognition on Memristor Hardware: A Simulated Approach, https://arxiv.org/pdf/2505.24721, 2025-05-30
2025-11-09 20:12:27,063 - INFO - root - Page:2, Index:41, GARLIC: GAussian Representation LearnIng for spaCe partitioning, https://arxiv.org/pdf/2505.24608, 2025-10-02
2025-11-09 20:12:27,064 - INFO - root - Page:2, Index:42, AutoChemSchematic AI: Agentic Physics-Aware Automation for Chemical Manufacturing Scale-Up, https://arxiv.org/pdf/2505.24584, 2025-08-18
2025-11-09 20:12:27,065 - INFO - root - Page:2, Index:43, Model-Preserving Adaptive Rounding, https://arxiv.org/pdf/2505.22988, 2025-09-25
2025-11-09 20:12:27,066 - INFO - root - Page:2, Index:44, Highly Efficient and Effective LLMs with Multi-Boolean Architectures, https://arxiv.org/pdf/2505.22811, 2025-10-03
2025-11-09 20:12:27,066 - INFO - root - Page:2, Index:45, Pioneering 4-Bit FP Quantization for Diffusion Models: Mixup-Sign Quantization and Timestep-Aware Fine-Tuning, https://arxiv.org/pdf/2505.21591, 2025-05-27
2025-11-09 20:12:27,066 - INFO - root - Page:2, Index:46, Frequency Composition for Compressed and Domain-Adaptive Neural Networks, https://arxiv.org/pdf/2505.20890, 2025-05-27
2025-11-09 20:12:27,067 - INFO - root - Page:2, Index:47, MoPFormer: Motion-Primitive Transformer for Wearable-Sensor Activity Recognition, https://arxiv.org/pdf/2505.20744, 2025-10-27
2025-11-09 20:12:27,067 - INFO - root - Page:2, Index:48, Optimizing edge AI models on HPC systems with the edge in the loop, https://arxiv.org/pdf/2505.19995, 2025-05-26
2025-11-09 20:12:27,067 - INFO - root - Fetching page 4 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=150
2025-11-09 20:12:34,212 - INFO - root - get_all_titles_from_web 
2025-11-09 20:12:34,213 - INFO - root - Page:3, Index:0, DPASyn: Mechanism-Aware Drug Synergy Prediction via Dual Attention and Precision-Aware Quantization, https://arxiv.org/pdf/2505.19144, 2025-09-20
2025-11-09 20:12:34,214 - INFO - root - Page:3, Index:1, Reducing Storage of Pretrained Neural Networks by Rate-Constrained Quantization and Entropy Coding, https://arxiv.org/pdf/2505.18758, 2025-05-24
2025-11-09 20:12:34,215 - INFO - root - Page:3, Index:2, Beyond Discreteness: Finite-Sample Analysis of Straight-Through Estimator for Quantization, https://arxiv.org/pdf/2505.18113, 2025-05-23
2025-11-09 20:12:34,215 - INFO - root - Page:3, Index:3, Automating Versatile Time-Series Analysis with Tiny Transformers on Embedded FPGAs, https://arxiv.org/pdf/2505.17662, 2025-09-19
2025-11-09 20:12:34,215 - INFO - root - Page:3, Index:4, FPQVAR: Floating Point Quantization for Visual Autoregressive Model with FPGA Hardware Co-design, https://arxiv.org/pdf/2505.16335, 2025-05-22
2025-11-09 20:12:34,216 - INFO - root - Page:3, Index:5, Saliency-Aware Quantized Imitation Learning for Efficient Robotic Control, https://arxiv.org/pdf/2505.15304, 2025-05-30
2025-11-09 20:12:34,216 - INFO - root - Page:3, Index:6, Scaling Law for Quantization-Aware Training, https://arxiv.org/pdf/2505.14302, 2025-05-20
2025-11-09 20:12:34,216 - INFO - root - Page:3, Index:7, Automatic mixed precision for optimizing gained time with constrained loss mean-squared-error based on model partition to sequential sub-graphs, https://arxiv.org/pdf/2505.13060, 2025-05-19
2025-11-09 20:12:34,216 - INFO - root - Page:3, Index:8, Deep Unfolding with Kernel-based Quantization in MIMO Detection, https://arxiv.org/pdf/2505.12736, 2025-05-19
2025-11-09 20:12:34,217 - INFO - root - Page:3, Index:9, FedHQ: Hybrid Runtime Quantization for Federated Learning, https://arxiv.org/pdf/2505.11982, 2025-05-17
2025-11-09 20:12:34,217 - INFO - root - Page:3, Index:10, QVGen: Pushing the Limit of Quantized Video Generative Models, https://arxiv.org/pdf/2505.11497, 2025-09-27
2025-11-09 20:12:34,218 - INFO - root - Page:3, Index:11, EA-3DGS: Efficient and Adaptive 3D Gaussians with Highly Enhanced Quality for outdoor scenes, https://arxiv.org/pdf/2505.10787, 2025-05-15
2025-11-09 20:12:34,219 - INFO - root - Page:3, Index:12, ITERA-LLM: Boosting Sub-8-Bit Large Language Model Inference via Iterative Tensor Decomposition, https://arxiv.org/pdf/2505.08981, 2025-05-13
2025-11-09 20:12:34,220 - INFO - root - Page:3, Index:13, PROM: Prioritize Reduction of Multiplications Over Lower Bit-Widths for Efficient CNNs, https://arxiv.org/pdf/2505.03254, 2025-08-06
2025-11-09 20:12:34,220 - INFO - root - Page:3, Index:14, ICQuant: Index Coding enables Low-bit LLM Quantization, https://arxiv.org/pdf/2505.00850, 2025-08-24
2025-11-09 20:12:34,222 - INFO - root - Page:3, Index:15, Enhancing Ultra-Low-Bit Quantization of Large Language Models Through Saliency-Aware Partial Retraining, https://arxiv.org/pdf/2504.13932, 2025-07-30
2025-11-09 20:12:34,223 - INFO - root - Page:3, Index:16, Achieving binary weight and activation for LLMs using Post-Training Quantization, https://arxiv.org/pdf/2504.05352, 2025-06-30
2025-11-09 20:12:34,223 - INFO - root - Page:3, Index:17, Wireless Hearables With Programmable Speech AI Accelerators, https://arxiv.org/pdf/2503.18698, 2025-10-21
2025-11-09 20:12:34,224 - INFO - root - Page:3, Index:18, GranQ: Efficient Channel-wise Quantization via Vectorized Pre-Scaling for Zero-Shot QAT, https://arxiv.org/pdf/2503.18339, 2025-10-15
2025-11-09 20:12:34,224 - INFO - root - Page:3, Index:19, CompMarkGS: Robust Watermarking for Compressed 3D Gaussian Splatting, https://arxiv.org/pdf/2503.12836, 2025-09-29
2025-11-09 20:12:34,226 - INFO - root - Page:3, Index:20, AHCPTQ: Accurate and Hardware-Compatible Post-Training Quantization for Segment Anything Model, https://arxiv.org/pdf/2503.03088, 2025-07-11
2025-11-09 20:12:34,226 - INFO - root - Page:3, Index:21, Teaching Metric Distance to Discrete Autoregressive Language Models, https://arxiv.org/pdf/2503.02379, 2025-10-07
2025-11-09 20:12:34,227 - INFO - root - Page:3, Index:22, Regularization-based Framework for Quantization-, Fault- and Variability-Aware Training, https://arxiv.org/pdf/2503.01297, 2025-07-12
2025-11-09 20:12:34,228 - INFO - root - Fetching page 5 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=200
2025-11-09 20:12:40,773 - INFO - root - get_all_titles_from_web 
2025-11-09 20:12:40,773 - INFO - root - Page:4, Index:0, Investigating the Impact of Quantization Methods on the Safety and Reliability of Large Language Models, https://arxiv.org/pdf/2502.15799, 2025-06-29
2025-11-09 20:12:40,774 - INFO - root - Page:4, Index:1, Rotate, Clip, and Partition: Towards W2A4KV4 Quantization by Integrating Rotation and Learnable Non-uniform Quantizer, https://arxiv.org/pdf/2502.15779, 2025-09-01
2025-11-09 20:12:40,774 - INFO - root - Page:4, Index:2, RoSTE: An Efficient Quantization-Aware Supervised Fine-Tuning Approach for Large Language Models, https://arxiv.org/pdf/2502.09003, 2025-06-05
2025-11-09 20:12:40,774 - INFO - root - Page:4, Index:3, Spatial Degradation-Aware and Temporal Consistent Diffusion Model for Compressed Video Super-Resolution, https://arxiv.org/pdf/2502.07381, 2025-06-27
2025-11-09 20:12:40,774 - INFO - root - Page:4, Index:4, QuEST: Stable Training of LLMs with 1-Bit Weights and Activations, https://arxiv.org/pdf/2502.05003, 2025-06-10
2025-11-09 20:12:40,774 - INFO - root - Page:4, Index:5, HALO: Hadamard-Assisted Lower-Precision Optimization for LLMs, https://arxiv.org/pdf/2501.02625, 2025-11-05
2025-11-09 20:12:40,775 - INFO - root - Page:4, Index:6, TAR3D: Creating High-Quality 3D Assets via Next-Part Prediction, https://arxiv.org/pdf/2412.16919, 2025-08-08
2025-11-09 20:12:40,775 - INFO - root - Page:4, Index:7, Training Multi-Layer Binary Neural Networks With Local Binary Error Signals, https://arxiv.org/pdf/2412.00119, 2025-08-05
2025-11-09 20:12:40,775 - INFO - root - Page:4, Index:8, Scaling Large-scale GNN Training to Thousands of Processors on CPU-based Supercomputers, https://arxiv.org/pdf/2411.16025, 2025-05-26
2025-11-09 20:12:40,775 - INFO - root - Page:4, Index:9, HAFLQ: Heterogeneous Adaptive Federated LoRA Fine-tuned LLM with Quantization, https://arxiv.org/pdf/2411.06581, 2025-05-16
2025-11-09 20:12:40,776 - INFO - root - Fetching page 6 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=250
2025-11-09 20:12:47,553 - INFO - root - get_all_titles_from_web 
2025-11-09 20:12:47,553 - INFO - root - Page:5, Index:0, Gradient-Free Training of Quantized Neural Networks, https://arxiv.org/pdf/2410.09734, 2025-09-29
2025-11-09 20:12:47,554 - INFO - root - Page:5, Index:1, QT-DoG: Quantization-aware Training for Domain Generalization, https://arxiv.org/pdf/2410.06020, 2025-06-26
2025-11-09 20:12:47,554 - INFO - root - Page:5, Index:2, Constraint Guided Model Quantization of Neural Networks, https://arxiv.org/pdf/2409.20138, 2025-09-12
2025-11-09 20:12:47,556 - INFO - root - Page:5, Index:3, Accumulator-Aware Post-Training Quantization for Large Language Models, https://arxiv.org/pdf/2409.17092, 2025-07-30
2025-11-09 20:12:47,556 - INFO - root - Page:5, Index:4, DilateQuant: Accurate and Efficient Diffusion Quantization via Weight Dilation, https://arxiv.org/pdf/2409.14307, 2025-07-09
2025-11-09 20:12:47,556 - INFO - root - Page:5, Index:5, Robust Training of Neural Networks at Arbitrary Precision and Sparsity, https://arxiv.org/pdf/2409.09245, 2025-09-23
2025-11-09 20:12:47,557 - INFO - root - Page:5, Index:6, VQ-CTAP: Cross-Modal Fine-Grained Sequence Representation Learning for Speech Processing, https://arxiv.org/pdf/2408.05758, 2025-05-27
2025-11-09 20:12:47,557 - INFO - root - Page:5, Index:7, DopQ-ViT: Towards Distribution-Friendly and Outlier-Aware Post-Training Quantization for Vision Transformers, https://arxiv.org/pdf/2408.03291, 2025-06-19
2025-11-09 20:12:47,558 - INFO - root - Page:5, Index:8, Temporal Feature Matters: A Framework for Diffusion Model Quantization, https://arxiv.org/pdf/2407.19547, 2025-07-11
2025-11-09 20:12:47,560 - INFO - root - Page:5, Index:9, EfficientQAT: Efficient Quantization-Aware Training for Large Language Models, https://arxiv.org/pdf/2407.11062, 2025-05-19
2025-11-09 20:12:47,563 - INFO - root - Page:5, Index:10, Integer-only Quantized Transformers for Embedded FPGA-based Time-series Forecasting in AIoT, https://arxiv.org/pdf/2407.11041, 2025-10-31
2025-11-09 20:12:47,566 - INFO - root - Fetching page 7 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=300
2025-11-09 20:12:54,121 - INFO - root - get_all_titles_from_web 
2025-11-09 20:12:54,122 - INFO - root - Page:6, Index:0, BoA: Attention-aware Post-training Quantization without Backpropagation, https://arxiv.org/pdf/2406.13474, 2025-06-06
2025-11-09 20:12:54,123 - INFO - root - Page:6, Index:1, A Rescaling-Invariant Lipschitz Bound Based on Path-Metrics for Modern ReLU Network Parameterizations, https://arxiv.org/pdf/2405.15006, 2025-06-13
2025-11-09 20:12:54,123 - INFO - root - Page:6, Index:2, Scheduling Weight Transitions for Quantization-Aware Training, https://arxiv.org/pdf/2404.19248, 2025-10-01
2025-11-09 20:12:54,123 - INFO - root - Page:6, Index:3, GPTVQ: The Blessing of Dimensionality for LLM Quantization, https://arxiv.org/pdf/2402.15319, 2025-06-03
2025-11-09 20:12:54,123 - INFO - root - Fetching page 8 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=350
2025-11-09 20:13:00,649 - INFO - root - get_all_titles_from_web 
2025-11-09 20:13:00,649 - INFO - root - Page:7, Index:0, Squat: Quant Small Language Models on the Edge, https://arxiv.org/pdf/2402.10787, 2025-07-01
2025-11-09 20:13:00,649 - INFO - root - Page:7, Index:1, L4Q: Parameter Efficient Quantization-Aware Fine-Tuning on Large Language Models, https://arxiv.org/pdf/2402.04902, 2025-07-21
2025-11-09 20:13:00,650 - INFO - root - Fetching page 9 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=400
2025-11-09 20:13:07,499 - INFO - root - ------------------------------------------------------------------------------------------------------------------------
2025-11-09 20:13:21,213 - INFO - root - 跳过已处理论文 A Quantized VAE-MLP Botnet Detection Model: A Systematic Evaluation of Quantization-Aware Training and Post-Training Quantization Strategies：D:\ChatPaper\academic Papers\Quantization-Aware-Training\A Quantized VAE-MLP Botnet Detection Model_ A Systematic Evaluation of Quantizat-4.pdf
2025-11-09 20:13:21,214 - INFO - root - 跳过已处理论文 FP8-Flow-MoE: A Casting-Free FP8 Recipe without Double Quantization Error：D:\ChatPaper\academic Papers\Quantization-Aware-Training\FP8-Flow-MoE_ A Casting-Free FP8 Recipe without Double Quantization Error-4.pdf
2025-11-09 20:13:21,215 - INFO - root - summary time: 80.50 seconds
2025-11-09 20:14:13,113 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-09 20:14:13,114 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-09 20:14:13,116 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-09 20:14:14,181 - INFO - root - LLMClientManager: 指定使用客户端: Gemini
2025-11-09 20:14:15,286 - INFO - root - GeminiClient: trying model gemini-2.5-flash
2025-11-09 20:14:18,313 - INFO - root - GeminiClient: initialized model gemini-2.5-flash
2025-11-09 20:14:18,313 - INFO - root - LLMClientManager: Gemini 客户端初始化成功
2025-11-09 20:14:18,314 - INFO - root - LLMClientManager: switched to Gemini client
2025-11-09 20:14:18,315 - INFO - root - 已手动切换到 LLM 客户端: Gemini
2025-11-09 20:14:18,315 - INFO - root - 使用 LLM 模型: gemini-2.5-flash
2025-11-09 20:14:18,315 - INFO - root - 可用客户端: ['Gemini']
2025-11-09 20:14:18,316 - INFO - root - === 运行配置 ===
2025-11-09 20:14:18,317 - INFO - root - 处理模式: arxiv在线搜索
2025-11-09 20:14:18,317 - INFO - root - 关键词: QAT
2025-11-09 20:14:18,318 - INFO - root - 查询: Quantization-Aware-Training
2025-11-09 20:14:18,318 - INFO - root - 排序: None
2025-11-09 20:14:18,319 - INFO - root - 最近天数: 180
2025-11-09 20:14:18,320 - INFO - root - 最大处理数量: 2
2025-11-09 20:14:18,320 - INFO - root - 保存图片: 是
2025-11-09 20:14:18,321 - INFO - root - 输出语言: 中文
2025-11-09 20:14:18,321 - INFO - root - 强制重新处理: 否
2025-11-09 20:14:18,321 - INFO - root - ====================
2025-11-09 20:14:18,321 - INFO - root - 使用 arXiv 搜索模式（通过 chat_arxiv 模块获取）
2025-11-09 20:14:18,321 - INFO - root - Fetching page 1 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50
2025-11-09 20:14:25,132 - INFO - root - get_all_titles_from_web 
2025-11-09 20:14:25,133 - INFO - root - Page:0, Index:0, A Quantized VAE-MLP Botnet Detection Model: A Systematic Evaluation of Quantization-Aware Training and Post-Training Quantization Strategies, https://arxiv.org/pdf/2511.03201, 2025-11-05
2025-11-09 20:14:25,133 - INFO - root - Page:0, Index:1, FP8-Flow-MoE: A Casting-Free FP8 Recipe without Double Quantization Error, https://arxiv.org/pdf/2511.02302, 2025-11-04
2025-11-09 20:14:25,133 - INFO - root - Page:0, Index:2, Outlier-Aware Post-Training Quantization for Image Super-Resolution, https://arxiv.org/pdf/2511.00682, 2025-11-01
2025-11-09 20:14:25,133 - INFO - root - Page:0, Index:3, Evaluation of Wafer-Scale SOT-MRAM for Analog Crossbar Array Applications, https://arxiv.org/pdf/2510.25853, 2025-11-03
2025-11-09 20:14:25,134 - INFO - root - Page:0, Index:4, Improving the Straight-Through Estimator with Zeroth-Order Information, https://arxiv.org/pdf/2510.23926, 2025-10-27
2025-11-09 20:14:25,134 - INFO - root - Page:0, Index:5, Real-Time Semantic Segmentation on FPGA for Autonomous Vehicles Using LMIINet with the CGRA4ML Framework, https://arxiv.org/pdf/2510.22243, 2025-10-25
2025-11-09 20:14:25,134 - INFO - root - Page:0, Index:6, TernaryCLIP: Efficiently Compressing Vision-Language Models with Ternary Weights and Distilled Knowledge, https://arxiv.org/pdf/2510.21879, 2025-10-23
2025-11-09 20:14:25,134 - INFO - root - Page:0, Index:7, KARIPAP: Quantum-Inspired Tensor Network Compression of Large Language Models Using Infinite Projected Entangled Pair States and Tensor Renormalization Group, https://arxiv.org/pdf/2510.21844, 2025-10-22
2025-11-09 20:14:25,136 - INFO - root - Page:0, Index:8, A Convergence Analysis of Adaptive Optimizers under Floating-point Quantization, https://arxiv.org/pdf/2510.21314, 2025-10-24
2025-11-09 20:14:25,136 - INFO - root - Page:0, Index:9, Adaptive Distribution-aware Quantization for Mixed-Precision Neural Networks, https://arxiv.org/pdf/2510.19760, 2025-10-22
2025-11-09 20:14:25,136 - INFO - root - Page:0, Index:10, CAGE: Curvature-Aware Gradient Estimation For Accurate Quantization-Aware Training, https://arxiv.org/pdf/2510.18784, 2025-10-21
2025-11-09 20:14:25,136 - INFO - root - Page:0, Index:11, Mixed-Precision Quantization for Language Models: Techniques and Prospects, https://arxiv.org/pdf/2510.16805, 2025-10-19
2025-11-09 20:14:25,136 - INFO - root - Page:0, Index:12, SPLite Hand: Sparsity-Aware Lightweight 3D Hand Pose Estimation, https://arxiv.org/pdf/2510.16396, 2025-10-30
2025-11-09 20:14:25,136 - INFO - root - Page:0, Index:13, CTR-LoRA: Curvature-Aware and Trust-Region Guided Low-Rank Adaptation for Large Language Models, https://arxiv.org/pdf/2510.15962, 2025-10-11
2025-11-09 20:14:25,136 - INFO - root - Page:0, Index:14, SANR: Scene-Aware Neural Representation for Light Field Image Compression with Rate-Distortion Optimization, https://arxiv.org/pdf/2510.15775, 2025-10-17
2025-11-09 20:14:25,138 - INFO - root - Page:0, Index:15, SpikeFit: Towards Optimal Deployment of Spiking Networks on Neuromorphic Hardware, https://arxiv.org/pdf/2510.15542, 2025-10-31
2025-11-09 20:14:25,138 - INFO - root - Page:0, Index:16, GRank: Towards Target-Aware and Streamlined Industrial Retrieval with a Generate-Rank Framework, https://arxiv.org/pdf/2510.15299, 2025-10-17
2025-11-09 20:14:25,142 - INFO - root - Page:0, Index:17, SaLon3R: Structure-aware Long-term Generalizable 3D Reconstruction from Unposed Images, https://arxiv.org/pdf/2510.15072, 2025-10-16
2025-11-09 20:14:25,144 - INFO - root - Page:0, Index:18, FraQAT: Quantization Aware Training with Fractional bits, https://arxiv.org/pdf/2510.14823, 2025-10-16
2025-11-09 20:14:25,144 - INFO - root - Page:0, Index:19, Computing-In-Memory Aware Model Adaption For Edge Devices, https://arxiv.org/pdf/2510.14379, 2025-10-16
2025-11-09 20:14:25,144 - INFO - root - Page:0, Index:20, Invited Paper: BitMedViT: Ternary-Quantized Vision Transformer for Medical AI Assistants on the Edge, https://arxiv.org/pdf/2510.13760, 2025-11-04
2025-11-09 20:14:25,145 - INFO - root - Page:0, Index:21, NeuroRVQ: Multi-Scale EEG Tokenization for Generative Large Brainwave Models, https://arxiv.org/pdf/2510.13068, 2025-10-14
2025-11-09 20:14:25,145 - INFO - root - Page:0, Index:22, Detect Anything via Next Point Prediction, https://arxiv.org/pdf/2510.12798, 2025-10-14
2025-11-09 20:14:25,146 - INFO - root - Page:0, Index:23, AndesVL Technical Report: An Efficient Mobile-side Multimodal Large Language Model, https://arxiv.org/pdf/2510.11496, 2025-10-14
2025-11-09 20:14:25,146 - INFO - root - Page:0, Index:24, Rescaling-Aware Training for Efficient Deployment of Deep Learning Models on Full-Integer Hardware, https://arxiv.org/pdf/2510.11484, 2025-10-13
2025-11-09 20:14:25,146 - INFO - root - Page:0, Index:25, SASER: Stego attacks on open-source LLMs, https://arxiv.org/pdf/2510.10486, 2025-10-12
2025-11-09 20:14:25,146 - INFO - root - Page:0, Index:26, Ultralytics YOLO Evolution: An Overview of YOLO26, YOLO11, YOLOv8 and YOLOv5 Object Detectors for Computer Vision and Pattern Recognition, https://arxiv.org/pdf/2510.09653, 2025-10-15
2025-11-09 20:14:25,147 - INFO - root - Page:0, Index:27, A Theoretically-Grounded Codebook for Digital Semantic Communications, https://arxiv.org/pdf/2510.07108, 2025-10-14
2025-11-09 20:14:25,147 - INFO - root - Page:0, Index:28, QuantDemoire: Quantization with Outlier Aware for Image Demoiréing, https://arxiv.org/pdf/2510.04066, 2025-10-05
2025-11-09 20:14:25,147 - INFO - root - Page:0, Index:29, Adaptively Sampling-Reusing-Mixing Decomposed Gradients to Speed Up Sharpness Aware Minimization, https://arxiv.org/pdf/2510.03763, 2025-10-04
2025-11-09 20:14:25,148 - INFO - root - Page:0, Index:30, Quant-dLLM: Post-Training Extreme Low-Bit Quantization for Diffusion Large Language Models, https://arxiv.org/pdf/2510.03274, 2025-09-27
2025-11-09 20:14:25,148 - INFO - root - Page:0, Index:31, PT$^2$-LLM: Post-Training Ternarization for Large Language Models, https://arxiv.org/pdf/2510.03267, 2025-09-26
2025-11-09 20:14:25,148 - INFO - root - Page:0, Index:32, Purrception: Variational Flow Matching for Vector-Quantized Image Generation, https://arxiv.org/pdf/2510.01478, 2025-10-01
2025-11-09 20:14:25,148 - INFO - root - Page:0, Index:33, Post-Training Quantization for Audio Diffusion Transformers, https://arxiv.org/pdf/2510.00313, 2025-09-30
2025-11-09 20:14:25,148 - INFO - root - Page:0, Index:34, Rethinking RoPE Scaling in Quantized LLM: Theory, Outlier, and Channel-Band Analysis with Weight Rescaling, https://arxiv.org/pdf/2510.00028, 2025-09-25
2025-11-09 20:14:25,148 - INFO - root - Page:0, Index:35, Post-Training Quantization via Residual Truncation and Zero Suppression for Diffusion Models, https://arxiv.org/pdf/2509.26436, 2025-09-30
2025-11-09 20:14:25,149 - INFO - root - Page:0, Index:36, Cat: Post-Training Quantization Error Reduction via Cluster-based Affine Transformation, https://arxiv.org/pdf/2509.26277, 2025-10-07
2025-11-09 20:14:25,149 - INFO - root - Page:0, Index:37, CAST: Continuous and Differentiable Semi-Structured Sparsity-Aware Training for Large Language Models, https://arxiv.org/pdf/2509.25996, 2025-09-30
2025-11-09 20:14:25,149 - INFO - root - Page:0, Index:38, Norm-Q: Effective Compression Method for Hidden Markov Models in Neuro-Symbolic Applications, https://arxiv.org/pdf/2509.25439, 2025-09-29
2025-11-09 20:14:25,149 - INFO - root - Page:0, Index:39, On-the-Fly Adaptation to Quantization: Configuration-Aware LoRA for Efficient Fine-Tuning of Quantized LLMs, https://arxiv.org/pdf/2509.25214, 2025-09-22
2025-11-09 20:14:25,149 - INFO - root - Page:0, Index:40, VoxCPM: Tokenizer-Free TTS for Context-Aware Speech Generation and True-to-Life Voice Cloning, https://arxiv.org/pdf/2509.24650, 2025-09-29
2025-11-09 20:14:25,150 - INFO - root - Page:0, Index:41, S$^2$NN: Sub-bit Spiking Neural Networks, https://arxiv.org/pdf/2509.24266, 2025-10-24
2025-11-09 20:14:25,150 - INFO - root - Page:0, Index:42, Tequila: Trapping-free Ternary Quantization for Large Language Models, https://arxiv.org/pdf/2509.23809, 2025-10-17
2025-11-09 20:14:25,150 - INFO - root - Page:0, Index:43, Texture Vector-Quantization and Reconstruction Aware Prediction for Generative Super-Resolution, https://arxiv.org/pdf/2509.23774, 2025-09-30
2025-11-09 20:14:25,150 - INFO - root - Page:0, Index:44, RobuQ: Pushing DiTs to W1.58A2 via Robust Activation Quantization, https://arxiv.org/pdf/2509.23582, 2025-09-27
2025-11-09 20:14:25,150 - INFO - root - Page:0, Index:45, Beyond Outliers: A Study of Optimizers Under Quantization, https://arxiv.org/pdf/2509.23500, 2025-10-02
2025-11-09 20:14:25,150 - INFO - root - Page:0, Index:46, Compute-Optimal Quantization-Aware Training, https://arxiv.org/pdf/2509.22935, 2025-09-26
2025-11-09 20:14:25,151 - INFO - root - Page:0, Index:47, COSPADI: Compressing LLMs via Calibration-Guided Sparse Dictionary Learning, https://arxiv.org/pdf/2509.22075, 2025-10-06
2025-11-09 20:14:25,151 - INFO - root - Page:0, Index:48, SlimDiff: Training-Free, Activation-Guided Hands-free Slimming of Diffusion Models, https://arxiv.org/pdf/2509.21498, 2025-09-25
2025-11-09 20:14:25,151 - INFO - root - Page:0, Index:49, Quantized Visual Geometry Grounded Transformer, https://arxiv.org/pdf/2509.21302, 2025-09-29
2025-11-09 20:14:25,151 - INFO - root - Fetching page 2 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=50
2025-11-09 20:14:31,601 - INFO - root - get_all_titles_from_web 
2025-11-09 20:14:31,601 - INFO - root - Page:1, Index:0, Can Less Precise Be More Reliable? A Systematic Evaluation of Quantization's Impact on CLIP Beyond Accuracy, https://arxiv.org/pdf/2509.21173, 2025-10-27
2025-11-09 20:14:31,601 - INFO - root - Page:1, Index:1, Punching Above Precision: Small Quantized Model Distillation with Learnable Regularizer, https://arxiv.org/pdf/2509.20854, 2025-09-25
2025-11-09 20:14:31,603 - INFO - root - Page:1, Index:2, TinyEcoWeedNet: Edge Efficient Real-Time Aerial Agricultural Weed Detection, https://arxiv.org/pdf/2509.18193, 2025-09-19
2025-11-09 20:14:31,603 - INFO - root - Page:1, Index:3, SBVR: Summation of BitVector Representation for Efficient LLM Quantization, https://arxiv.org/pdf/2509.18172, 2025-09-17
2025-11-09 20:14:31,603 - INFO - root - Page:1, Index:4, QWHA: Quantization-Aware Walsh-Hadamard Adaptation for Parameter-Efficient Fine-Tuning on Large Language Models, https://arxiv.org/pdf/2509.17428, 2025-09-26
2025-11-09 20:14:31,603 - INFO - root - Page:1, Index:5, PTQTP: Post-Training Quantization to Trit-Planes for Large Language Models, https://arxiv.org/pdf/2509.16989, 2025-10-28
2025-11-09 20:14:31,604 - INFO - root - Page:1, Index:6, MEC-Quant: Maximum Entropy Coding for Extremely Low Bit Quantization-Aware Training, https://arxiv.org/pdf/2509.15514, 2025-09-18
2025-11-09 20:14:31,604 - INFO - root - Page:1, Index:7, Q-ROAR: Outlier-Aware Rescaling for RoPE Position Interpolation in Quantized Long-Context LLMs, https://arxiv.org/pdf/2509.14391, 2025-09-17
2025-11-09 20:14:31,604 - INFO - root - Page:1, Index:8, Efficient Quantization-Aware Neural Receivers: Beyond Post-Training Quantization, https://arxiv.org/pdf/2509.13786, 2025-09-19
2025-11-09 20:14:31,605 - INFO - root - Page:1, Index:9, Rate-Distortion Limits for Multimodal Retrieval: Theory, Optimal Codes, and Finite-Sample Guarantees, https://arxiv.org/pdf/2509.11054, 2025-09-13
2025-11-09 20:14:31,605 - INFO - root - Page:1, Index:10, SQAP-VLA: A Synergistic Quantization-Aware Pruning Framework for High-Performance Vision-Language-Action Models, https://arxiv.org/pdf/2509.09090, 2025-09-10
2025-11-09 20:14:31,605 - INFO - root - Page:1, Index:11, CSI Compression Beyond Latents: End-to-End Hybrid Attention-CNN Networks with Entropy Regularization, https://arxiv.org/pdf/2509.08776, 2025-09-10
2025-11-09 20:14:31,606 - INFO - root - Page:1, Index:12, Explaining How Quantization Disparately Skews a Model, https://arxiv.org/pdf/2509.07222, 2025-09-08
2025-11-09 20:14:31,606 - INFO - root - Page:1, Index:13, LoaQ: Layer-wise Output Approximation Quantization, https://arxiv.org/pdf/2509.06297, 2025-09-07
2025-11-09 20:14:31,606 - INFO - root - Page:1, Index:14, FineServe: Precision-Aware KV Slab and Two-Level Scheduling for Heterogeneous Precision LLM Serving, https://arxiv.org/pdf/2509.06261, 2025-09-14
2025-11-09 20:14:31,606 - INFO - root - Page:1, Index:15, Sensitivity-Aware Post-Training Quantization for Deep Neural Networks, https://arxiv.org/pdf/2509.05576, 2025-09-05
2025-11-09 20:14:31,607 - INFO - root - Page:1, Index:16, SuperSNN: A Hardware-Aware Framework for Physically Realizable, High-Performance Superconducting Spiking Neural Network Chips, https://arxiv.org/pdf/2509.05532, 2025-09-05
2025-11-09 20:14:31,607 - INFO - root - Page:1, Index:17, Data-Augmented Quantization-Aware Knowledge Distillation, https://arxiv.org/pdf/2509.03850, 2025-09-03
2025-11-09 20:14:31,608 - INFO - root - Page:1, Index:18, DPQuant: Efficient and Differentially-Private Model Training via Dynamic Quantization Scheduling, https://arxiv.org/pdf/2509.03472, 2025-09-03
2025-11-09 20:14:31,608 - INFO - root - Page:1, Index:19, Empowering Large Language Model for Sequential Recommendation via Multimodal Embeddings and Semantic IDs, https://arxiv.org/pdf/2509.02017, 2025-09-02
2025-11-09 20:14:31,608 - INFO - root - Page:1, Index:20, Q-Sched: Pushing the Boundaries of Few-Step Diffusion Models with Quantization-Aware Scheduling, https://arxiv.org/pdf/2509.01624, 2025-09-01
2025-11-09 20:14:31,608 - INFO - root - Page:1, Index:21, Quantization Meets OOD: Generalizable Quantization-aware Training from a Flatness Perspective, https://arxiv.org/pdf/2509.00859, 2025-08-31
2025-11-09 20:14:31,609 - INFO - root - Page:1, Index:22, Progressive Element-wise Gradient Estimation for Neural Network Quantization, https://arxiv.org/pdf/2509.00097, 2025-08-27
2025-11-09 20:14:31,609 - INFO - root - Page:1, Index:23, End-to-End On-Device Quantization-Aware Training for LLMs at Inference Cost, https://arxiv.org/pdf/2509.00031, 2025-09-29
2025-11-09 20:14:31,609 - INFO - root - Page:1, Index:24, Quantization Robustness to Input Degradations for Object Detection, https://arxiv.org/pdf/2508.19600, 2025-08-27
2025-11-09 20:14:31,610 - INFO - root - Page:1, Index:25, Scaling Laws for Task-Stratified Knowledge in Post-Training Quantized Large Language Models, https://arxiv.org/pdf/2508.18609, 2025-08-27
2025-11-09 20:14:31,610 - INFO - root - Page:1, Index:26, AQ-PCDSys: An Adaptive Quantized Planetary Crater Detection System for Autonomous Space Exploration, https://arxiv.org/pdf/2508.18025, 2025-08-25
2025-11-09 20:14:31,610 - INFO - root - Page:1, Index:27, TaDiCodec: Text-aware Diffusion Speech Tokenizer for Speech Language Modeling, https://arxiv.org/pdf/2508.16790, 2025-08-22
2025-11-09 20:14:31,611 - INFO - root - Page:1, Index:28, A Node-Aware Dynamic Quantization Approach for Graph Collaborative Filtering, https://arxiv.org/pdf/2508.16516, 2025-08-22
2025-11-09 20:14:31,611 - INFO - root - Page:1, Index:29, JEDI-linear: Fast and Efficient Graph Neural Networks for Jet Tagging on FPGAs, https://arxiv.org/pdf/2508.15468, 2025-08-21
2025-11-09 20:14:31,611 - INFO - root - Page:1, Index:30, MMQ: Multimodal Mixture-of-Quantization Tokenization for Semantic ID Generation and User Behavioral Adaptation, https://arxiv.org/pdf/2508.15281, 2025-08-21
2025-11-09 20:14:31,611 - INFO - root - Page:1, Index:31, DLLMQuant: Quantizing Diffusion-based Large Language Models, https://arxiv.org/pdf/2508.14090, 2025-08-25
2025-11-09 20:14:31,613 - INFO - root - Page:1, Index:32, Automated Energy-Aware Time-Series Model Deployment on Embedded FPGAs for Resilient Combined Sewer Overflow Management, https://arxiv.org/pdf/2508.13905, 2025-08-19
2025-11-09 20:14:31,614 - INFO - root - Page:1, Index:33, XR-NPE: High-Throughput Mixed-precision SIMD Neural Processing Engine for Extended Reality Perception Workloads, https://arxiv.org/pdf/2508.13049, 2025-08-18
2025-11-09 20:14:31,616 - INFO - root - Page:1, Index:34, Exploring Self-Supervised Audio Models for Generalized Anomalous Sound Detection, https://arxiv.org/pdf/2508.12230, 2025-08-17
2025-11-09 20:14:31,618 - INFO - root - Page:1, Index:35, TriQDef: Disrupting Semantic and Gradient Alignment to Prevent Adversarial Patch Transferability in Quantized Neural Networks, https://arxiv.org/pdf/2508.12132, 2025-08-16
2025-11-09 20:14:31,620 - INFO - root - Page:1, Index:36, Error Propagation Mechanisms and Compensation Strategies for Quantized Diffusion, https://arxiv.org/pdf/2508.12094, 2025-10-13
2025-11-09 20:14:31,620 - INFO - root - Page:1, Index:37, Extending Straight-Through Estimation for Robust Neural Networks on Analog CIM Hardware, https://arxiv.org/pdf/2508.11940, 2025-08-16
2025-11-09 20:14:31,620 - INFO - root - Page:1, Index:38, PTQAT: A Hybrid Parameter-Efficient Quantization Algorithm for 3D Perception Tasks, https://arxiv.org/pdf/2508.10557, 2025-08-15
2025-11-09 20:14:31,620 - INFO - root - Page:1, Index:39, MiCo: End-to-End Mixed Precision Neural Network Co-Exploration Framework for Edge AI, https://arxiv.org/pdf/2508.09500, 2025-08-13
2025-11-09 20:14:31,622 - INFO - root - Page:1, Index:40, SPARC: Soft Probabilistic Adaptive multi-interest Retrieval Model via Codebooks for recommender system, https://arxiv.org/pdf/2508.09090, 2025-08-12
2025-11-09 20:14:31,622 - INFO - root - Page:1, Index:41, Rethinking 1-bit Optimization Leveraging Pre-trained Large Language Models, https://arxiv.org/pdf/2508.06974, 2025-08-09
2025-11-09 20:14:31,622 - INFO - root - Page:1, Index:42, Efficient Deep Neural Receiver with Post-Training Quantization, https://arxiv.org/pdf/2508.06275, 2025-08-08
2025-11-09 20:14:31,623 - INFO - root - Page:1, Index:43, iFairy: the First 2-bit Complex LLM with All Parameters in $\{\pm1, \pm i\}$, https://arxiv.org/pdf/2508.05571, 2025-08-16
2025-11-09 20:14:31,623 - INFO - root - Page:1, Index:44, S$^2$Q-VDiT: Accurate Quantized Video Diffusion Transformer with Salient Data and Sparse Token Distillation, https://arxiv.org/pdf/2508.04016, 2025-10-27
2025-11-09 20:14:31,623 - INFO - root - Page:1, Index:45, LRQ-DiT: Log-Rotation Post-Training Quantization of Diffusion Transformers for Image and Video Generation, https://arxiv.org/pdf/2508.03485, 2025-09-23
2025-11-09 20:14:31,624 - INFO - root - Page:1, Index:46, VLMQ: Efficient Post-Training Quantization for Large Vision-Language Models via Hessian Augmentation, https://arxiv.org/pdf/2508.03351, 2025-08-05
2025-11-09 20:14:31,624 - INFO - root - Page:1, Index:47, TF-MLPNet: Tiny Real-Time Neural Speech Separation, https://arxiv.org/pdf/2508.03047, 2025-08-04
2025-11-09 20:14:31,624 - INFO - root - Page:1, Index:48, SaviorRec: Semantic-Behavior Alignment for Cold-Start Recommendation, https://arxiv.org/pdf/2508.01375, 2025-08-02
2025-11-09 20:14:31,624 - INFO - root - Page:1, Index:49, MixA-Q: Revisiting Activation Sparsity for Vision Transformers from a Mixed-Precision Quantization Perspective, https://arxiv.org/pdf/2507.19131, 2025-07-25
2025-11-09 20:14:31,625 - INFO - root - Fetching page 3 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=100
2025-11-09 20:14:38,390 - INFO - root - get_all_titles_from_web 
2025-11-09 20:14:38,390 - INFO - root - Page:2, Index:0, Enhancing Quantization-Aware Training on Edge Devices via Relative Entropy Coreset Selection and Cascaded Layer Correction, https://arxiv.org/pdf/2507.17768, 2025-07-16
2025-11-09 20:14:38,390 - INFO - root - Page:2, Index:1, SiLQ: Simple Large Language Model Quantization-Aware Training, https://arxiv.org/pdf/2507.16933, 2025-07-22
2025-11-09 20:14:38,390 - INFO - root - Page:2, Index:2, Task-Specific Zero-shot Quantization-Aware Training for Object Detection, https://arxiv.org/pdf/2507.16782, 2025-07-22
2025-11-09 20:14:38,391 - INFO - root - Page:2, Index:3, TorchAO: PyTorch-Native Training-to-Serving Model Optimization, https://arxiv.org/pdf/2507.16099, 2025-07-21
2025-11-09 20:14:38,391 - INFO - root - Page:2, Index:4, SegQuant: A Semantics-Aware and Generalizable Quantization Framework for Diffusion Models, https://arxiv.org/pdf/2507.14811, 2025-08-27
2025-11-09 20:14:38,391 - INFO - root - Page:2, Index:5, Apple Intelligence Foundation Language Models: Tech Report 2025, https://arxiv.org/pdf/2507.13575, 2025-08-27
2025-11-09 20:14:38,391 - INFO - root - Page:2, Index:6, Generative Multi-Target Cross-Domain Recommendation, https://arxiv.org/pdf/2507.12871, 2025-08-07
2025-11-09 20:14:38,391 - INFO - root - Page:2, Index:7, DAF: An Efficient End-to-End Dynamic Activation Framework for on-Device DNN Training, https://arxiv.org/pdf/2507.07149, 2025-07-09
2025-11-09 20:14:38,391 - INFO - root - Page:2, Index:8, Opto-ViT: Architecting a Near-Sensor Region of Interest-Aware Vision Transformer Accelerator with Silicon Photonics, https://arxiv.org/pdf/2507.07044, 2025-07-15
2025-11-09 20:14:38,392 - INFO - root - Page:2, Index:9, QS4D: Quantization-aware training for efficient hardware deployment of structured state-space sequential models, https://arxiv.org/pdf/2507.06079, 2025-07-08
2025-11-09 20:14:38,392 - INFO - root - Page:2, Index:10, GSVR: 2D Gaussian-based Video Representation for 800+ FPS with Hybrid Deformation Field, https://arxiv.org/pdf/2507.05594, 2025-07-07
2025-11-09 20:14:38,392 - INFO - root - Page:2, Index:11, Hita: Holistic Tokenizer for Autoregressive Image Generation, https://arxiv.org/pdf/2507.02358, 2025-07-11
2025-11-09 20:14:38,392 - INFO - root - Page:2, Index:12, QPART: Adaptive Model Quantization and Dynamic Workload Balancing for Accuracy-aware Edge Inference, https://arxiv.org/pdf/2506.23934, 2025-06-30
2025-11-09 20:14:38,392 - INFO - root - Page:2, Index:13, FedWSQ: Efficient Federated Learning with Weight Standardization and Distribution-Aware Non-Uniform Quantization, https://arxiv.org/pdf/2506.23516, 2025-07-21
2025-11-09 20:14:38,393 - INFO - root - Page:2, Index:14, Spectra 1.1: Scaling Laws and Efficient Inference for Ternary Language Models, https://arxiv.org/pdf/2506.23025, 2025-06-28
2025-11-09 20:14:38,393 - INFO - root - Page:2, Index:15, Joint Quantization and Pruning Neural Networks Approach: A Case Study on FSO Receivers, https://arxiv.org/pdf/2506.20084, 2025-06-24
2025-11-09 20:14:38,393 - INFO - root - Page:2, Index:16, Single-step Diffusion for Image Compression at Ultra-Low Bitrates, https://arxiv.org/pdf/2506.16572, 2025-09-22
2025-11-09 20:14:38,394 - INFO - root - Page:2, Index:17, LittleBit: Ultra Low-Bit Quantization via Latent Factorization, https://arxiv.org/pdf/2506.13771, 2025-10-28
2025-11-09 20:14:38,394 - INFO - root - Page:2, Index:18, MARCO: Hardware-Aware Neural Architecture Search for Edge Devices with Multi-Agent Reinforcement Learning and Conformal Prediction Filtering, https://arxiv.org/pdf/2506.13755, 2025-06-16
2025-11-09 20:14:38,395 - INFO - root - Page:2, Index:19, EAQuant: Enhancing Post-Training Quantization for MoE Models via Expert-Aware Optimization, https://arxiv.org/pdf/2506.13329, 2025-07-04
2025-11-09 20:14:38,395 - INFO - root - Page:2, Index:20, Towards Neural Audio Codec Source Parsing, https://arxiv.org/pdf/2506.12627, 2025-06-14
2025-11-09 20:14:38,396 - INFO - root - Page:2, Index:21, Quantizing Small-Scale State-Space Models for Edge AI, https://arxiv.org/pdf/2506.12480, 2025-06-14
2025-11-09 20:14:38,396 - INFO - root - Page:2, Index:22, EMLoC: Emulator-based Memory-efficient Fine-tuning with LoRA Correction, https://arxiv.org/pdf/2506.12015, 2025-06-13
2025-11-09 20:14:38,397 - INFO - root - Page:2, Index:23, Compression Aware Certified Training, https://arxiv.org/pdf/2506.11992, 2025-06-13
2025-11-09 20:14:38,397 - INFO - root - Page:2, Index:24, GPLQ: A General, Practical, and Lightning QAT Method for Vision Transformers, https://arxiv.org/pdf/2506.11784, 2025-06-13
2025-11-09 20:14:38,397 - INFO - root - Page:2, Index:25, TruncQuant: Truncation-Ready Quantization for DNNs with Flexible Weight Bit Precision, https://arxiv.org/pdf/2506.11431, 2025-06-12
2025-11-09 20:14:38,398 - INFO - root - Page:2, Index:26, EfficientQuant: An Efficient Post-Training Quantization for CNN-Transformer Hybrid Models on Edge Devices, https://arxiv.org/pdf/2506.11093, 2025-06-05
2025-11-09 20:14:38,399 - INFO - root - Page:2, Index:27, Starting Positions Matter: A Study on Better Weight Initialization for Neural Network Quantization, https://arxiv.org/pdf/2506.10463, 2025-06-12
2025-11-09 20:14:38,402 - INFO - root - Page:2, Index:28, AWP: Activation-Aware Weight Pruning and Quantization with Projected Gradient Descent, https://arxiv.org/pdf/2506.10205, 2025-06-11
2025-11-09 20:14:38,403 - INFO - root - Page:2, Index:29, Q-SAM2: Accurate Quantization for Segment Anything Model 2, https://arxiv.org/pdf/2506.09782, 2025-06-11
2025-11-09 20:14:38,405 - INFO - root - Page:2, Index:30, Unifying Block-wise PTQ and Distillation-based QAT for Progressive Quantization toward 2-bit Instruction-Tuned LLMs, https://arxiv.org/pdf/2506.09104, 2025-06-10
2025-11-09 20:14:38,406 - INFO - root - Page:2, Index:31, Implementing Keyword Spotting on the MCUX947 Microcontroller with Integrated NPU, https://arxiv.org/pdf/2506.08911, 2025-06-10
2025-11-09 20:14:38,406 - INFO - root - Page:2, Index:32, POLARON: Precision-aware On-device Learning and Adaptive Runtime-cONfigurable AI acceleration, https://arxiv.org/pdf/2506.08785, 2025-06-10
2025-11-09 20:14:38,407 - INFO - root - Page:2, Index:33, MoQAE: Mixed-Precision Quantization for Long-Context LLM Inference via Mixture of Quantization-Aware Experts, https://arxiv.org/pdf/2506.07533, 2025-06-09
2025-11-09 20:14:38,407 - INFO - root - Page:2, Index:34, BitVLA: 1-bit Vision-Language-Action Models for Robotics Manipulation, https://arxiv.org/pdf/2506.07530, 2025-06-09
2025-11-09 20:14:38,407 - INFO - root - Page:2, Index:35, RecGPT: A Foundation Model for Sequential Recommendation, https://arxiv.org/pdf/2506.06270, 2025-06-12
2025-11-09 20:14:38,408 - INFO - root - Page:2, Index:36, FPSAttention: Training-Aware FP8 and Sparsity Co-Design for Fast Video Diffusion, https://arxiv.org/pdf/2506.04648, 2025-06-05
2025-11-09 20:14:38,408 - INFO - root - Page:2, Index:37, BitTTS: Highly Compact Text-to-Speech Using 1.58-bit Quantization and Weight Indexing, https://arxiv.org/pdf/2506.03515, 2025-06-03
2025-11-09 20:14:38,408 - INFO - root - Page:2, Index:38, ShapeLLM-Omni: A Native Multimodal LLM for 3D Generation and Understanding, https://arxiv.org/pdf/2506.01853, 2025-06-02
2025-11-09 20:14:38,408 - INFO - root - Page:2, Index:39, Movable Antenna Enhanced Federated Fine-Tuning of Large Language Models via Hybrid Client Selection Optimization, https://arxiv.org/pdf/2506.00011, 2025-10-26
2025-11-09 20:14:38,409 - INFO - root - Page:2, Index:40, Running Conventional Automatic Speech Recognition on Memristor Hardware: A Simulated Approach, https://arxiv.org/pdf/2505.24721, 2025-05-30
2025-11-09 20:14:38,411 - INFO - root - Page:2, Index:41, GARLIC: GAussian Representation LearnIng for spaCe partitioning, https://arxiv.org/pdf/2505.24608, 2025-10-02
2025-11-09 20:14:38,411 - INFO - root - Page:2, Index:42, AutoChemSchematic AI: Agentic Physics-Aware Automation for Chemical Manufacturing Scale-Up, https://arxiv.org/pdf/2505.24584, 2025-08-18
2025-11-09 20:14:38,414 - INFO - root - Page:2, Index:43, Model-Preserving Adaptive Rounding, https://arxiv.org/pdf/2505.22988, 2025-09-25
2025-11-09 20:14:38,414 - INFO - root - Page:2, Index:44, Highly Efficient and Effective LLMs with Multi-Boolean Architectures, https://arxiv.org/pdf/2505.22811, 2025-10-03
2025-11-09 20:14:38,414 - INFO - root - Page:2, Index:45, Pioneering 4-Bit FP Quantization for Diffusion Models: Mixup-Sign Quantization and Timestep-Aware Fine-Tuning, https://arxiv.org/pdf/2505.21591, 2025-05-27
2025-11-09 20:14:38,414 - INFO - root - Page:2, Index:46, Frequency Composition for Compressed and Domain-Adaptive Neural Networks, https://arxiv.org/pdf/2505.20890, 2025-05-27
2025-11-09 20:14:38,416 - INFO - root - Page:2, Index:47, MoPFormer: Motion-Primitive Transformer for Wearable-Sensor Activity Recognition, https://arxiv.org/pdf/2505.20744, 2025-10-27
2025-11-09 20:14:38,416 - INFO - root - Page:2, Index:48, Optimizing edge AI models on HPC systems with the edge in the loop, https://arxiv.org/pdf/2505.19995, 2025-05-26
2025-11-09 20:14:38,416 - INFO - root - Fetching page 4 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=150
2025-11-09 20:14:45,563 - INFO - root - get_all_titles_from_web 
2025-11-09 20:14:45,564 - INFO - root - Page:3, Index:0, DPASyn: Mechanism-Aware Drug Synergy Prediction via Dual Attention and Precision-Aware Quantization, https://arxiv.org/pdf/2505.19144, 2025-09-20
2025-11-09 20:14:45,564 - INFO - root - Page:3, Index:1, Reducing Storage of Pretrained Neural Networks by Rate-Constrained Quantization and Entropy Coding, https://arxiv.org/pdf/2505.18758, 2025-05-24
2025-11-09 20:14:45,564 - INFO - root - Page:3, Index:2, Beyond Discreteness: Finite-Sample Analysis of Straight-Through Estimator for Quantization, https://arxiv.org/pdf/2505.18113, 2025-05-23
2025-11-09 20:14:45,564 - INFO - root - Page:3, Index:3, Automating Versatile Time-Series Analysis with Tiny Transformers on Embedded FPGAs, https://arxiv.org/pdf/2505.17662, 2025-09-19
2025-11-09 20:14:45,565 - INFO - root - Page:3, Index:4, FPQVAR: Floating Point Quantization for Visual Autoregressive Model with FPGA Hardware Co-design, https://arxiv.org/pdf/2505.16335, 2025-05-22
2025-11-09 20:14:45,565 - INFO - root - Page:3, Index:5, Saliency-Aware Quantized Imitation Learning for Efficient Robotic Control, https://arxiv.org/pdf/2505.15304, 2025-05-30
2025-11-09 20:14:45,565 - INFO - root - Page:3, Index:6, Scaling Law for Quantization-Aware Training, https://arxiv.org/pdf/2505.14302, 2025-05-20
2025-11-09 20:14:45,565 - INFO - root - Page:3, Index:7, Automatic mixed precision for optimizing gained time with constrained loss mean-squared-error based on model partition to sequential sub-graphs, https://arxiv.org/pdf/2505.13060, 2025-05-19
2025-11-09 20:14:45,566 - INFO - root - Page:3, Index:8, Deep Unfolding with Kernel-based Quantization in MIMO Detection, https://arxiv.org/pdf/2505.12736, 2025-05-19
2025-11-09 20:14:45,566 - INFO - root - Page:3, Index:9, FedHQ: Hybrid Runtime Quantization for Federated Learning, https://arxiv.org/pdf/2505.11982, 2025-05-17
2025-11-09 20:14:45,567 - INFO - root - Page:3, Index:10, QVGen: Pushing the Limit of Quantized Video Generative Models, https://arxiv.org/pdf/2505.11497, 2025-09-27
2025-11-09 20:14:45,567 - INFO - root - Page:3, Index:11, EA-3DGS: Efficient and Adaptive 3D Gaussians with Highly Enhanced Quality for outdoor scenes, https://arxiv.org/pdf/2505.10787, 2025-05-15
2025-11-09 20:14:45,567 - INFO - root - Page:3, Index:12, ITERA-LLM: Boosting Sub-8-Bit Large Language Model Inference via Iterative Tensor Decomposition, https://arxiv.org/pdf/2505.08981, 2025-05-13
2025-11-09 20:14:45,567 - INFO - root - Page:3, Index:13, PROM: Prioritize Reduction of Multiplications Over Lower Bit-Widths for Efficient CNNs, https://arxiv.org/pdf/2505.03254, 2025-08-06
2025-11-09 20:14:45,568 - INFO - root - Page:3, Index:14, ICQuant: Index Coding enables Low-bit LLM Quantization, https://arxiv.org/pdf/2505.00850, 2025-08-24
2025-11-09 20:14:45,568 - INFO - root - Page:3, Index:15, Enhancing Ultra-Low-Bit Quantization of Large Language Models Through Saliency-Aware Partial Retraining, https://arxiv.org/pdf/2504.13932, 2025-07-30
2025-11-09 20:14:45,568 - INFO - root - Page:3, Index:16, Achieving binary weight and activation for LLMs using Post-Training Quantization, https://arxiv.org/pdf/2504.05352, 2025-06-30
2025-11-09 20:14:45,568 - INFO - root - Page:3, Index:17, Wireless Hearables With Programmable Speech AI Accelerators, https://arxiv.org/pdf/2503.18698, 2025-10-21
2025-11-09 20:14:45,568 - INFO - root - Page:3, Index:18, GranQ: Efficient Channel-wise Quantization via Vectorized Pre-Scaling for Zero-Shot QAT, https://arxiv.org/pdf/2503.18339, 2025-10-15
2025-11-09 20:14:45,569 - INFO - root - Page:3, Index:19, CompMarkGS: Robust Watermarking for Compressed 3D Gaussian Splatting, https://arxiv.org/pdf/2503.12836, 2025-09-29
2025-11-09 20:14:45,569 - INFO - root - Page:3, Index:20, AHCPTQ: Accurate and Hardware-Compatible Post-Training Quantization for Segment Anything Model, https://arxiv.org/pdf/2503.03088, 2025-07-11
2025-11-09 20:14:45,569 - INFO - root - Page:3, Index:21, Teaching Metric Distance to Discrete Autoregressive Language Models, https://arxiv.org/pdf/2503.02379, 2025-10-07
2025-11-09 20:14:45,570 - INFO - root - Page:3, Index:22, Regularization-based Framework for Quantization-, Fault- and Variability-Aware Training, https://arxiv.org/pdf/2503.01297, 2025-07-12
2025-11-09 20:14:45,570 - INFO - root - Fetching page 5 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=200
2025-11-09 20:14:52,400 - INFO - root - get_all_titles_from_web 
2025-11-09 20:14:52,400 - INFO - root - Page:4, Index:0, Investigating the Impact of Quantization Methods on the Safety and Reliability of Large Language Models, https://arxiv.org/pdf/2502.15799, 2025-06-29
2025-11-09 20:14:52,401 - INFO - root - Page:4, Index:1, Rotate, Clip, and Partition: Towards W2A4KV4 Quantization by Integrating Rotation and Learnable Non-uniform Quantizer, https://arxiv.org/pdf/2502.15779, 2025-09-01
2025-11-09 20:14:52,401 - INFO - root - Page:4, Index:2, RoSTE: An Efficient Quantization-Aware Supervised Fine-Tuning Approach for Large Language Models, https://arxiv.org/pdf/2502.09003, 2025-06-05
2025-11-09 20:14:52,401 - INFO - root - Page:4, Index:3, Spatial Degradation-Aware and Temporal Consistent Diffusion Model for Compressed Video Super-Resolution, https://arxiv.org/pdf/2502.07381, 2025-06-27
2025-11-09 20:14:52,402 - INFO - root - Page:4, Index:4, QuEST: Stable Training of LLMs with 1-Bit Weights and Activations, https://arxiv.org/pdf/2502.05003, 2025-06-10
2025-11-09 20:14:52,402 - INFO - root - Page:4, Index:5, HALO: Hadamard-Assisted Lower-Precision Optimization for LLMs, https://arxiv.org/pdf/2501.02625, 2025-11-05
2025-11-09 20:14:52,402 - INFO - root - Page:4, Index:6, TAR3D: Creating High-Quality 3D Assets via Next-Part Prediction, https://arxiv.org/pdf/2412.16919, 2025-08-08
2025-11-09 20:14:52,402 - INFO - root - Page:4, Index:7, Training Multi-Layer Binary Neural Networks With Local Binary Error Signals, https://arxiv.org/pdf/2412.00119, 2025-08-05
2025-11-09 20:14:52,404 - INFO - root - Page:4, Index:8, Scaling Large-scale GNN Training to Thousands of Processors on CPU-based Supercomputers, https://arxiv.org/pdf/2411.16025, 2025-05-26
2025-11-09 20:14:52,404 - INFO - root - Page:4, Index:9, HAFLQ: Heterogeneous Adaptive Federated LoRA Fine-tuned LLM with Quantization, https://arxiv.org/pdf/2411.06581, 2025-05-16
2025-11-09 20:14:52,404 - INFO - root - Fetching page 6 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=250
2025-11-09 20:14:59,509 - INFO - root - get_all_titles_from_web 
2025-11-09 20:14:59,509 - INFO - root - Page:5, Index:0, Gradient-Free Training of Quantized Neural Networks, https://arxiv.org/pdf/2410.09734, 2025-09-29
2025-11-09 20:14:59,510 - INFO - root - Page:5, Index:1, QT-DoG: Quantization-aware Training for Domain Generalization, https://arxiv.org/pdf/2410.06020, 2025-06-26
2025-11-09 20:14:59,510 - INFO - root - Page:5, Index:2, Constraint Guided Model Quantization of Neural Networks, https://arxiv.org/pdf/2409.20138, 2025-09-12
2025-11-09 20:14:59,510 - INFO - root - Page:5, Index:3, Accumulator-Aware Post-Training Quantization for Large Language Models, https://arxiv.org/pdf/2409.17092, 2025-07-30
2025-11-09 20:14:59,511 - INFO - root - Page:5, Index:4, DilateQuant: Accurate and Efficient Diffusion Quantization via Weight Dilation, https://arxiv.org/pdf/2409.14307, 2025-07-09
2025-11-09 20:14:59,511 - INFO - root - Page:5, Index:5, Robust Training of Neural Networks at Arbitrary Precision and Sparsity, https://arxiv.org/pdf/2409.09245, 2025-09-23
2025-11-09 20:14:59,511 - INFO - root - Page:5, Index:6, VQ-CTAP: Cross-Modal Fine-Grained Sequence Representation Learning for Speech Processing, https://arxiv.org/pdf/2408.05758, 2025-05-27
2025-11-09 20:14:59,511 - INFO - root - Page:5, Index:7, DopQ-ViT: Towards Distribution-Friendly and Outlier-Aware Post-Training Quantization for Vision Transformers, https://arxiv.org/pdf/2408.03291, 2025-06-19
2025-11-09 20:14:59,513 - INFO - root - Page:5, Index:8, Temporal Feature Matters: A Framework for Diffusion Model Quantization, https://arxiv.org/pdf/2407.19547, 2025-07-11
2025-11-09 20:14:59,513 - INFO - root - Page:5, Index:9, EfficientQAT: Efficient Quantization-Aware Training for Large Language Models, https://arxiv.org/pdf/2407.11062, 2025-05-19
2025-11-09 20:14:59,513 - INFO - root - Page:5, Index:10, Integer-only Quantized Transformers for Embedded FPGA-based Time-series Forecasting in AIoT, https://arxiv.org/pdf/2407.11041, 2025-10-31
2025-11-09 20:14:59,514 - INFO - root - Fetching page 7 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=300
2025-11-09 20:15:06,532 - INFO - root - get_all_titles_from_web 
2025-11-09 20:15:06,534 - INFO - root - Page:6, Index:0, BoA: Attention-aware Post-training Quantization without Backpropagation, https://arxiv.org/pdf/2406.13474, 2025-06-06
2025-11-09 20:15:06,535 - INFO - root - Page:6, Index:1, A Rescaling-Invariant Lipschitz Bound Based on Path-Metrics for Modern ReLU Network Parameterizations, https://arxiv.org/pdf/2405.15006, 2025-06-13
2025-11-09 20:15:06,536 - INFO - root - Page:6, Index:2, Scheduling Weight Transitions for Quantization-Aware Training, https://arxiv.org/pdf/2404.19248, 2025-10-01
2025-11-09 20:15:06,536 - INFO - root - Page:6, Index:3, GPTVQ: The Blessing of Dimensionality for LLM Quantization, https://arxiv.org/pdf/2402.15319, 2025-06-03
2025-11-09 20:15:06,537 - INFO - root - Fetching page 8 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=350
2025-11-09 20:15:13,032 - INFO - root - get_all_titles_from_web 
2025-11-09 20:15:13,032 - INFO - root - Page:7, Index:0, Squat: Quant Small Language Models on the Edge, https://arxiv.org/pdf/2402.10787, 2025-07-01
2025-11-09 20:15:13,032 - INFO - root - Page:7, Index:1, L4Q: Parameter Efficient Quantization-Aware Fine-Tuning on Large Language Models, https://arxiv.org/pdf/2402.04902, 2025-07-21
2025-11-09 20:15:13,034 - INFO - root - Fetching page 9 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=400
2025-11-09 20:15:19,488 - INFO - root - ------------------------------------------------------------------------------------------------------------------------
2025-11-09 20:15:33,034 - INFO - root - 跳过已处理论文 A Quantized VAE-MLP Botnet Detection Model: A Systematic Evaluation of Quantization-Aware Training and Post-Training Quantization Strategies：D:\ChatPaper\academic Papers\Quantization-Aware-Training\A Quantized VAE-MLP Botnet Detection Model_ A Systematic Evaluation of Quantizat-5.pdf
2025-11-09 20:15:33,035 - INFO - root - 跳过已处理论文 FP8-Flow-MoE: A Casting-Free FP8 Recipe without Double Quantization Error：D:\ChatPaper\academic Papers\Quantization-Aware-Training\FP8-Flow-MoE_ A Casting-Free FP8 Recipe without Double Quantization Error-5.pdf
2025-11-09 20:15:33,035 - INFO - root - summary time: 79.92 seconds
2025-11-09 20:28:53,722 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-09 20:28:53,728 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-09 20:28:53,751 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-09 20:28:57,059 - INFO - root - LLMClientManager: 指定使用客户端: Deepseek
2025-11-09 20:28:57,069 - INFO - root - DeepSeekClient: API key found: 9f9e270e-b...
2025-11-09 20:28:57,110 - INFO - root - DeepSeekClient: 使用模式: 火山引擎
2025-11-09 20:28:57,126 - INFO - root - DeepSeekClient: 模型名称: deepseek-v3-1-terminus
2025-11-09 20:29:04,506 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 20:29:04,566 - INFO - root - DeepSeekClient: initialized successfully with model deepseek-v3-1-terminus
2025-11-09 20:29:04,566 - INFO - root - LLMClientManager: DeepSeek 客户端初始化成功
2025-11-09 20:29:04,567 - WARNING - root - LLMClientManager: client Deepseek not available
2025-11-09 20:29:04,568 - WARNING - root - 无法切换到指定的客户端 Deepseek，将使用默认客户端
2025-11-09 20:29:04,568 - INFO - root - 可用客户端: ['DeepSeek']
2025-11-09 20:29:04,568 - INFO - root - 使用 LLM 模型: deepseek-v3-1-terminus
2025-11-09 20:29:04,569 - INFO - root - 可用客户端: ['DeepSeek']
2025-11-09 20:29:04,574 - INFO - root - === 运行配置 ===
2025-11-09 20:29:04,575 - INFO - root - 处理模式: arxiv在线搜索
2025-11-09 20:29:04,575 - INFO - root - 关键词: QAT
2025-11-09 20:29:04,577 - INFO - root - 查询: Quantization-Aware-Training
2025-11-09 20:29:04,577 - INFO - root - 排序: None
2025-11-09 20:29:04,577 - INFO - root - 最近天数: 180
2025-11-09 20:29:04,578 - INFO - root - 最大处理数量: 2
2025-11-09 20:29:04,578 - INFO - root - 保存图片: 是
2025-11-09 20:29:04,578 - INFO - root - 输出语言: 中文
2025-11-09 20:29:04,581 - INFO - root - 强制重新处理: 否
2025-11-09 20:29:04,581 - INFO - root - ====================
2025-11-09 20:29:04,582 - INFO - root - 使用 arXiv 搜索模式（通过 chat_arxiv 模块获取）
2025-11-09 20:29:04,582 - INFO - root - Fetching page 1 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50
2025-11-09 20:29:11,959 - INFO - root - get_all_titles_from_web 
2025-11-09 20:29:11,965 - INFO - root - Page:0, Index:0, A Quantized VAE-MLP Botnet Detection Model: A Systematic Evaluation of Quantization-Aware Training and Post-Training Quantization Strategies, https://arxiv.org/pdf/2511.03201, 2025-11-05
2025-11-09 20:29:11,966 - INFO - root - Page:0, Index:1, FP8-Flow-MoE: A Casting-Free FP8 Recipe without Double Quantization Error, https://arxiv.org/pdf/2511.02302, 2025-11-04
2025-11-09 20:29:11,967 - INFO - root - Page:0, Index:2, Outlier-Aware Post-Training Quantization for Image Super-Resolution, https://arxiv.org/pdf/2511.00682, 2025-11-01
2025-11-09 20:29:11,975 - INFO - root - Page:0, Index:3, Evaluation of Wafer-Scale SOT-MRAM for Analog Crossbar Array Applications, https://arxiv.org/pdf/2510.25853, 2025-11-03
2025-11-09 20:29:11,991 - INFO - root - Page:0, Index:4, Improving the Straight-Through Estimator with Zeroth-Order Information, https://arxiv.org/pdf/2510.23926, 2025-10-27
2025-11-09 20:29:12,007 - INFO - root - Page:0, Index:5, Real-Time Semantic Segmentation on FPGA for Autonomous Vehicles Using LMIINet with the CGRA4ML Framework, https://arxiv.org/pdf/2510.22243, 2025-10-25
2025-11-09 20:29:12,015 - INFO - root - Page:0, Index:6, TernaryCLIP: Efficiently Compressing Vision-Language Models with Ternary Weights and Distilled Knowledge, https://arxiv.org/pdf/2510.21879, 2025-10-23
2025-11-09 20:29:12,016 - INFO - root - Page:0, Index:7, KARIPAP: Quantum-Inspired Tensor Network Compression of Large Language Models Using Infinite Projected Entangled Pair States and Tensor Renormalization Group, https://arxiv.org/pdf/2510.21844, 2025-10-22
2025-11-09 20:29:12,016 - INFO - root - Page:0, Index:8, A Convergence Analysis of Adaptive Optimizers under Floating-point Quantization, https://arxiv.org/pdf/2510.21314, 2025-10-24
2025-11-09 20:29:12,018 - INFO - root - Page:0, Index:9, Adaptive Distribution-aware Quantization for Mixed-Precision Neural Networks, https://arxiv.org/pdf/2510.19760, 2025-10-22
2025-11-09 20:29:12,019 - INFO - root - Page:0, Index:10, CAGE: Curvature-Aware Gradient Estimation For Accurate Quantization-Aware Training, https://arxiv.org/pdf/2510.18784, 2025-10-21
2025-11-09 20:29:12,021 - INFO - root - Page:0, Index:11, Mixed-Precision Quantization for Language Models: Techniques and Prospects, https://arxiv.org/pdf/2510.16805, 2025-10-19
2025-11-09 20:29:12,021 - INFO - root - Page:0, Index:12, SPLite Hand: Sparsity-Aware Lightweight 3D Hand Pose Estimation, https://arxiv.org/pdf/2510.16396, 2025-10-30
2025-11-09 20:29:12,022 - INFO - root - Page:0, Index:13, CTR-LoRA: Curvature-Aware and Trust-Region Guided Low-Rank Adaptation for Large Language Models, https://arxiv.org/pdf/2510.15962, 2025-10-11
2025-11-09 20:29:12,022 - INFO - root - Page:0, Index:14, SANR: Scene-Aware Neural Representation for Light Field Image Compression with Rate-Distortion Optimization, https://arxiv.org/pdf/2510.15775, 2025-10-17
2025-11-09 20:29:12,023 - INFO - root - Page:0, Index:15, SpikeFit: Towards Optimal Deployment of Spiking Networks on Neuromorphic Hardware, https://arxiv.org/pdf/2510.15542, 2025-10-31
2025-11-09 20:29:12,023 - INFO - root - Page:0, Index:16, GRank: Towards Target-Aware and Streamlined Industrial Retrieval with a Generate-Rank Framework, https://arxiv.org/pdf/2510.15299, 2025-10-17
2025-11-09 20:29:12,023 - INFO - root - Page:0, Index:17, SaLon3R: Structure-aware Long-term Generalizable 3D Reconstruction from Unposed Images, https://arxiv.org/pdf/2510.15072, 2025-10-16
2025-11-09 20:29:12,023 - INFO - root - Page:0, Index:18, FraQAT: Quantization Aware Training with Fractional bits, https://arxiv.org/pdf/2510.14823, 2025-10-16
2025-11-09 20:29:12,024 - INFO - root - Page:0, Index:19, Computing-In-Memory Aware Model Adaption For Edge Devices, https://arxiv.org/pdf/2510.14379, 2025-10-16
2025-11-09 20:29:12,024 - INFO - root - Page:0, Index:20, Invited Paper: BitMedViT: Ternary-Quantized Vision Transformer for Medical AI Assistants on the Edge, https://arxiv.org/pdf/2510.13760, 2025-11-04
2025-11-09 20:29:12,024 - INFO - root - Page:0, Index:21, NeuroRVQ: Multi-Scale EEG Tokenization for Generative Large Brainwave Models, https://arxiv.org/pdf/2510.13068, 2025-10-14
2025-11-09 20:29:12,025 - INFO - root - Page:0, Index:22, Detect Anything via Next Point Prediction, https://arxiv.org/pdf/2510.12798, 2025-10-14
2025-11-09 20:29:12,025 - INFO - root - Page:0, Index:23, AndesVL Technical Report: An Efficient Mobile-side Multimodal Large Language Model, https://arxiv.org/pdf/2510.11496, 2025-10-14
2025-11-09 20:29:12,026 - INFO - root - Page:0, Index:24, Rescaling-Aware Training for Efficient Deployment of Deep Learning Models on Full-Integer Hardware, https://arxiv.org/pdf/2510.11484, 2025-10-13
2025-11-09 20:29:12,035 - INFO - root - Page:0, Index:25, SASER: Stego attacks on open-source LLMs, https://arxiv.org/pdf/2510.10486, 2025-10-12
2025-11-09 20:29:12,036 - INFO - root - Page:0, Index:26, Ultralytics YOLO Evolution: An Overview of YOLO26, YOLO11, YOLOv8 and YOLOv5 Object Detectors for Computer Vision and Pattern Recognition, https://arxiv.org/pdf/2510.09653, 2025-10-15
2025-11-09 20:29:12,040 - INFO - root - Page:0, Index:27, A Theoretically-Grounded Codebook for Digital Semantic Communications, https://arxiv.org/pdf/2510.07108, 2025-10-14
2025-11-09 20:29:12,056 - INFO - root - Page:0, Index:28, QuantDemoire: Quantization with Outlier Aware for Image Demoiréing, https://arxiv.org/pdf/2510.04066, 2025-10-05
2025-11-09 20:29:12,066 - INFO - root - Page:0, Index:29, Adaptively Sampling-Reusing-Mixing Decomposed Gradients to Speed Up Sharpness Aware Minimization, https://arxiv.org/pdf/2510.03763, 2025-10-04
2025-11-09 20:29:12,067 - INFO - root - Page:0, Index:30, Quant-dLLM: Post-Training Extreme Low-Bit Quantization for Diffusion Large Language Models, https://arxiv.org/pdf/2510.03274, 2025-09-27
2025-11-09 20:29:12,068 - INFO - root - Page:0, Index:31, PT$^2$-LLM: Post-Training Ternarization for Large Language Models, https://arxiv.org/pdf/2510.03267, 2025-09-26
2025-11-09 20:29:12,071 - INFO - root - Page:0, Index:32, Purrception: Variational Flow Matching for Vector-Quantized Image Generation, https://arxiv.org/pdf/2510.01478, 2025-10-01
2025-11-09 20:29:12,072 - INFO - root - Page:0, Index:33, Post-Training Quantization for Audio Diffusion Transformers, https://arxiv.org/pdf/2510.00313, 2025-09-30
2025-11-09 20:29:12,074 - INFO - root - Page:0, Index:34, Rethinking RoPE Scaling in Quantized LLM: Theory, Outlier, and Channel-Band Analysis with Weight Rescaling, https://arxiv.org/pdf/2510.00028, 2025-09-25
2025-11-09 20:29:12,074 - INFO - root - Page:0, Index:35, Post-Training Quantization via Residual Truncation and Zero Suppression for Diffusion Models, https://arxiv.org/pdf/2509.26436, 2025-09-30
2025-11-09 20:29:12,076 - INFO - root - Page:0, Index:36, Cat: Post-Training Quantization Error Reduction via Cluster-based Affine Transformation, https://arxiv.org/pdf/2509.26277, 2025-10-07
2025-11-09 20:29:12,088 - INFO - root - Page:0, Index:37, CAST: Continuous and Differentiable Semi-Structured Sparsity-Aware Training for Large Language Models, https://arxiv.org/pdf/2509.25996, 2025-09-30
2025-11-09 20:29:12,107 - INFO - root - Page:0, Index:38, Norm-Q: Effective Compression Method for Hidden Markov Models in Neuro-Symbolic Applications, https://arxiv.org/pdf/2509.25439, 2025-09-29
2025-11-09 20:29:12,114 - INFO - root - Page:0, Index:39, On-the-Fly Adaptation to Quantization: Configuration-Aware LoRA for Efficient Fine-Tuning of Quantized LLMs, https://arxiv.org/pdf/2509.25214, 2025-09-22
2025-11-09 20:29:12,117 - INFO - root - Page:0, Index:40, VoxCPM: Tokenizer-Free TTS for Context-Aware Speech Generation and True-to-Life Voice Cloning, https://arxiv.org/pdf/2509.24650, 2025-09-29
2025-11-09 20:29:12,123 - INFO - root - Page:0, Index:41, S$^2$NN: Sub-bit Spiking Neural Networks, https://arxiv.org/pdf/2509.24266, 2025-10-24
2025-11-09 20:29:12,125 - INFO - root - Page:0, Index:42, Tequila: Trapping-free Ternary Quantization for Large Language Models, https://arxiv.org/pdf/2509.23809, 2025-10-17
2025-11-09 20:29:12,125 - INFO - root - Page:0, Index:43, Texture Vector-Quantization and Reconstruction Aware Prediction for Generative Super-Resolution, https://arxiv.org/pdf/2509.23774, 2025-09-30
2025-11-09 20:29:12,125 - INFO - root - Page:0, Index:44, RobuQ: Pushing DiTs to W1.58A2 via Robust Activation Quantization, https://arxiv.org/pdf/2509.23582, 2025-09-27
2025-11-09 20:29:12,133 - INFO - root - Page:0, Index:45, Beyond Outliers: A Study of Optimizers Under Quantization, https://arxiv.org/pdf/2509.23500, 2025-10-02
2025-11-09 20:29:12,134 - INFO - root - Page:0, Index:46, Compute-Optimal Quantization-Aware Training, https://arxiv.org/pdf/2509.22935, 2025-09-26
2025-11-09 20:29:12,136 - INFO - root - Page:0, Index:47, COSPADI: Compressing LLMs via Calibration-Guided Sparse Dictionary Learning, https://arxiv.org/pdf/2509.22075, 2025-10-06
2025-11-09 20:29:12,142 - INFO - root - Page:0, Index:48, SlimDiff: Training-Free, Activation-Guided Hands-free Slimming of Diffusion Models, https://arxiv.org/pdf/2509.21498, 2025-09-25
2025-11-09 20:29:12,159 - INFO - root - Page:0, Index:49, Quantized Visual Geometry Grounded Transformer, https://arxiv.org/pdf/2509.21302, 2025-09-29
2025-11-09 20:29:12,185 - INFO - root - Fetching page 2 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=50
2025-11-09 20:29:19,926 - INFO - root - get_all_titles_from_web 
2025-11-09 20:29:19,932 - INFO - root - Page:1, Index:0, Can Less Precise Be More Reliable? A Systematic Evaluation of Quantization's Impact on CLIP Beyond Accuracy, https://arxiv.org/pdf/2509.21173, 2025-10-27
2025-11-09 20:29:19,960 - INFO - root - Page:1, Index:1, Punching Above Precision: Small Quantized Model Distillation with Learnable Regularizer, https://arxiv.org/pdf/2509.20854, 2025-09-25
2025-11-09 20:29:19,976 - INFO - root - Page:1, Index:2, TinyEcoWeedNet: Edge Efficient Real-Time Aerial Agricultural Weed Detection, https://arxiv.org/pdf/2509.18193, 2025-09-19
2025-11-09 20:29:19,978 - INFO - root - Page:1, Index:3, SBVR: Summation of BitVector Representation for Efficient LLM Quantization, https://arxiv.org/pdf/2509.18172, 2025-09-17
2025-11-09 20:29:19,983 - INFO - root - Page:1, Index:4, QWHA: Quantization-Aware Walsh-Hadamard Adaptation for Parameter-Efficient Fine-Tuning on Large Language Models, https://arxiv.org/pdf/2509.17428, 2025-09-26
2025-11-09 20:29:20,008 - INFO - root - Page:1, Index:5, PTQTP: Post-Training Quantization to Trit-Planes for Large Language Models, https://arxiv.org/pdf/2509.16989, 2025-10-28
2025-11-09 20:29:20,030 - INFO - root - Page:1, Index:6, MEC-Quant: Maximum Entropy Coding for Extremely Low Bit Quantization-Aware Training, https://arxiv.org/pdf/2509.15514, 2025-09-18
2025-11-09 20:29:20,045 - INFO - root - Page:1, Index:7, Q-ROAR: Outlier-Aware Rescaling for RoPE Position Interpolation in Quantized Long-Context LLMs, https://arxiv.org/pdf/2509.14391, 2025-09-17
2025-11-09 20:29:20,078 - INFO - root - Page:1, Index:8, Efficient Quantization-Aware Neural Receivers: Beyond Post-Training Quantization, https://arxiv.org/pdf/2509.13786, 2025-09-19
2025-11-09 20:29:20,093 - INFO - root - Page:1, Index:9, Rate-Distortion Limits for Multimodal Retrieval: Theory, Optimal Codes, and Finite-Sample Guarantees, https://arxiv.org/pdf/2509.11054, 2025-09-13
2025-11-09 20:29:20,156 - INFO - root - Page:1, Index:10, SQAP-VLA: A Synergistic Quantization-Aware Pruning Framework for High-Performance Vision-Language-Action Models, https://arxiv.org/pdf/2509.09090, 2025-09-10
2025-11-09 20:29:20,280 - INFO - root - Page:1, Index:11, CSI Compression Beyond Latents: End-to-End Hybrid Attention-CNN Networks with Entropy Regularization, https://arxiv.org/pdf/2509.08776, 2025-09-10
2025-11-09 20:29:20,397 - INFO - root - Page:1, Index:12, Explaining How Quantization Disparately Skews a Model, https://arxiv.org/pdf/2509.07222, 2025-09-08
2025-11-09 20:29:20,433 - INFO - root - Page:1, Index:13, LoaQ: Layer-wise Output Approximation Quantization, https://arxiv.org/pdf/2509.06297, 2025-09-07
2025-11-09 20:29:20,501 - INFO - root - Page:1, Index:14, FineServe: Precision-Aware KV Slab and Two-Level Scheduling for Heterogeneous Precision LLM Serving, https://arxiv.org/pdf/2509.06261, 2025-09-14
2025-11-09 20:29:20,513 - INFO - root - Page:1, Index:15, Sensitivity-Aware Post-Training Quantization for Deep Neural Networks, https://arxiv.org/pdf/2509.05576, 2025-09-05
2025-11-09 20:29:20,529 - INFO - root - Page:1, Index:16, SuperSNN: A Hardware-Aware Framework for Physically Realizable, High-Performance Superconducting Spiking Neural Network Chips, https://arxiv.org/pdf/2509.05532, 2025-09-05
2025-11-09 20:29:20,533 - INFO - root - Page:1, Index:17, Data-Augmented Quantization-Aware Knowledge Distillation, https://arxiv.org/pdf/2509.03850, 2025-09-03
2025-11-09 20:29:20,540 - INFO - root - Page:1, Index:18, DPQuant: Efficient and Differentially-Private Model Training via Dynamic Quantization Scheduling, https://arxiv.org/pdf/2509.03472, 2025-09-03
2025-11-09 20:29:20,590 - INFO - root - Page:1, Index:19, Empowering Large Language Model for Sequential Recommendation via Multimodal Embeddings and Semantic IDs, https://arxiv.org/pdf/2509.02017, 2025-09-02
2025-11-09 20:29:20,597 - INFO - root - Page:1, Index:20, Q-Sched: Pushing the Boundaries of Few-Step Diffusion Models with Quantization-Aware Scheduling, https://arxiv.org/pdf/2509.01624, 2025-09-01
2025-11-09 20:29:20,616 - INFO - root - Page:1, Index:21, Quantization Meets OOD: Generalizable Quantization-aware Training from a Flatness Perspective, https://arxiv.org/pdf/2509.00859, 2025-08-31
2025-11-09 20:29:20,627 - INFO - root - Page:1, Index:22, Progressive Element-wise Gradient Estimation for Neural Network Quantization, https://arxiv.org/pdf/2509.00097, 2025-08-27
2025-11-09 20:29:20,645 - INFO - root - Page:1, Index:23, End-to-End On-Device Quantization-Aware Training for LLMs at Inference Cost, https://arxiv.org/pdf/2509.00031, 2025-09-29
2025-11-09 20:29:20,646 - INFO - root - Page:1, Index:24, Quantization Robustness to Input Degradations for Object Detection, https://arxiv.org/pdf/2508.19600, 2025-08-27
2025-11-09 20:29:20,647 - INFO - root - Page:1, Index:25, Scaling Laws for Task-Stratified Knowledge in Post-Training Quantized Large Language Models, https://arxiv.org/pdf/2508.18609, 2025-08-27
2025-11-09 20:29:20,648 - INFO - root - Page:1, Index:26, AQ-PCDSys: An Adaptive Quantized Planetary Crater Detection System for Autonomous Space Exploration, https://arxiv.org/pdf/2508.18025, 2025-08-25
2025-11-09 20:29:20,649 - INFO - root - Page:1, Index:27, TaDiCodec: Text-aware Diffusion Speech Tokenizer for Speech Language Modeling, https://arxiv.org/pdf/2508.16790, 2025-08-22
2025-11-09 20:29:20,649 - INFO - root - Page:1, Index:28, A Node-Aware Dynamic Quantization Approach for Graph Collaborative Filtering, https://arxiv.org/pdf/2508.16516, 2025-08-22
2025-11-09 20:29:20,697 - INFO - root - Page:1, Index:29, JEDI-linear: Fast and Efficient Graph Neural Networks for Jet Tagging on FPGAs, https://arxiv.org/pdf/2508.15468, 2025-08-21
2025-11-09 20:29:20,698 - INFO - root - Page:1, Index:30, MMQ: Multimodal Mixture-of-Quantization Tokenization for Semantic ID Generation and User Behavioral Adaptation, https://arxiv.org/pdf/2508.15281, 2025-08-21
2025-11-09 20:29:20,700 - INFO - root - Page:1, Index:31, DLLMQuant: Quantizing Diffusion-based Large Language Models, https://arxiv.org/pdf/2508.14090, 2025-08-25
2025-11-09 20:29:20,700 - INFO - root - Page:1, Index:32, Automated Energy-Aware Time-Series Model Deployment on Embedded FPGAs for Resilient Combined Sewer Overflow Management, https://arxiv.org/pdf/2508.13905, 2025-08-19
2025-11-09 20:29:20,707 - INFO - root - Page:1, Index:33, XR-NPE: High-Throughput Mixed-precision SIMD Neural Processing Engine for Extended Reality Perception Workloads, https://arxiv.org/pdf/2508.13049, 2025-08-18
2025-11-09 20:29:20,708 - INFO - root - Page:1, Index:34, Exploring Self-Supervised Audio Models for Generalized Anomalous Sound Detection, https://arxiv.org/pdf/2508.12230, 2025-08-17
2025-11-09 20:29:20,712 - INFO - root - Page:1, Index:35, TriQDef: Disrupting Semantic and Gradient Alignment to Prevent Adversarial Patch Transferability in Quantized Neural Networks, https://arxiv.org/pdf/2508.12132, 2025-08-16
2025-11-09 20:29:20,715 - INFO - root - Page:1, Index:36, Error Propagation Mechanisms and Compensation Strategies for Quantized Diffusion, https://arxiv.org/pdf/2508.12094, 2025-10-13
2025-11-09 20:29:20,724 - INFO - root - Page:1, Index:37, Extending Straight-Through Estimation for Robust Neural Networks on Analog CIM Hardware, https://arxiv.org/pdf/2508.11940, 2025-08-16
2025-11-09 20:29:20,730 - INFO - root - Page:1, Index:38, PTQAT: A Hybrid Parameter-Efficient Quantization Algorithm for 3D Perception Tasks, https://arxiv.org/pdf/2508.10557, 2025-08-15
2025-11-09 20:29:20,731 - INFO - root - Page:1, Index:39, MiCo: End-to-End Mixed Precision Neural Network Co-Exploration Framework for Edge AI, https://arxiv.org/pdf/2508.09500, 2025-08-13
2025-11-09 20:29:20,731 - INFO - root - Page:1, Index:40, SPARC: Soft Probabilistic Adaptive multi-interest Retrieval Model via Codebooks for recommender system, https://arxiv.org/pdf/2508.09090, 2025-08-12
2025-11-09 20:29:20,734 - INFO - root - Page:1, Index:41, Rethinking 1-bit Optimization Leveraging Pre-trained Large Language Models, https://arxiv.org/pdf/2508.06974, 2025-08-09
2025-11-09 20:29:20,734 - INFO - root - Page:1, Index:42, Efficient Deep Neural Receiver with Post-Training Quantization, https://arxiv.org/pdf/2508.06275, 2025-08-08
2025-11-09 20:29:20,735 - INFO - root - Page:1, Index:43, iFairy: the First 2-bit Complex LLM with All Parameters in $\{\pm1, \pm i\}$, https://arxiv.org/pdf/2508.05571, 2025-08-16
2025-11-09 20:29:20,767 - INFO - root - Page:1, Index:44, S$^2$Q-VDiT: Accurate Quantized Video Diffusion Transformer with Salient Data and Sparse Token Distillation, https://arxiv.org/pdf/2508.04016, 2025-10-27
2025-11-09 20:29:20,780 - INFO - root - Page:1, Index:45, LRQ-DiT: Log-Rotation Post-Training Quantization of Diffusion Transformers for Image and Video Generation, https://arxiv.org/pdf/2508.03485, 2025-09-23
2025-11-09 20:29:20,795 - INFO - root - Page:1, Index:46, VLMQ: Efficient Post-Training Quantization for Large Vision-Language Models via Hessian Augmentation, https://arxiv.org/pdf/2508.03351, 2025-08-05
2025-11-09 20:29:20,798 - INFO - root - Page:1, Index:47, TF-MLPNet: Tiny Real-Time Neural Speech Separation, https://arxiv.org/pdf/2508.03047, 2025-08-04
2025-11-09 20:29:20,811 - INFO - root - Page:1, Index:48, SaviorRec: Semantic-Behavior Alignment for Cold-Start Recommendation, https://arxiv.org/pdf/2508.01375, 2025-08-02
2025-11-09 20:29:20,860 - INFO - root - Page:1, Index:49, MixA-Q: Revisiting Activation Sparsity for Vision Transformers from a Mixed-Precision Quantization Perspective, https://arxiv.org/pdf/2507.19131, 2025-07-25
2025-11-09 20:29:20,893 - INFO - root - Fetching page 3 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=100
2025-11-09 20:29:28,070 - INFO - root - get_all_titles_from_web 
2025-11-09 20:29:28,071 - INFO - root - Page:2, Index:0, Enhancing Quantization-Aware Training on Edge Devices via Relative Entropy Coreset Selection and Cascaded Layer Correction, https://arxiv.org/pdf/2507.17768, 2025-07-16
2025-11-09 20:29:28,072 - INFO - root - Page:2, Index:1, SiLQ: Simple Large Language Model Quantization-Aware Training, https://arxiv.org/pdf/2507.16933, 2025-07-22
2025-11-09 20:29:28,072 - INFO - root - Page:2, Index:2, Task-Specific Zero-shot Quantization-Aware Training for Object Detection, https://arxiv.org/pdf/2507.16782, 2025-07-22
2025-11-09 20:29:28,072 - INFO - root - Page:2, Index:3, TorchAO: PyTorch-Native Training-to-Serving Model Optimization, https://arxiv.org/pdf/2507.16099, 2025-07-21
2025-11-09 20:29:28,072 - INFO - root - Page:2, Index:4, SegQuant: A Semantics-Aware and Generalizable Quantization Framework for Diffusion Models, https://arxiv.org/pdf/2507.14811, 2025-08-27
2025-11-09 20:29:28,072 - INFO - root - Page:2, Index:5, Apple Intelligence Foundation Language Models: Tech Report 2025, https://arxiv.org/pdf/2507.13575, 2025-08-27
2025-11-09 20:29:28,073 - INFO - root - Page:2, Index:6, Generative Multi-Target Cross-Domain Recommendation, https://arxiv.org/pdf/2507.12871, 2025-08-07
2025-11-09 20:29:28,073 - INFO - root - Page:2, Index:7, DAF: An Efficient End-to-End Dynamic Activation Framework for on-Device DNN Training, https://arxiv.org/pdf/2507.07149, 2025-07-09
2025-11-09 20:29:28,073 - INFO - root - Page:2, Index:8, Opto-ViT: Architecting a Near-Sensor Region of Interest-Aware Vision Transformer Accelerator with Silicon Photonics, https://arxiv.org/pdf/2507.07044, 2025-07-15
2025-11-09 20:29:28,073 - INFO - root - Page:2, Index:9, QS4D: Quantization-aware training for efficient hardware deployment of structured state-space sequential models, https://arxiv.org/pdf/2507.06079, 2025-07-08
2025-11-09 20:29:28,073 - INFO - root - Page:2, Index:10, GSVR: 2D Gaussian-based Video Representation for 800+ FPS with Hybrid Deformation Field, https://arxiv.org/pdf/2507.05594, 2025-07-07
2025-11-09 20:29:28,074 - INFO - root - Page:2, Index:11, Hita: Holistic Tokenizer for Autoregressive Image Generation, https://arxiv.org/pdf/2507.02358, 2025-07-11
2025-11-09 20:29:28,074 - INFO - root - Page:2, Index:12, QPART: Adaptive Model Quantization and Dynamic Workload Balancing for Accuracy-aware Edge Inference, https://arxiv.org/pdf/2506.23934, 2025-06-30
2025-11-09 20:29:28,074 - INFO - root - Page:2, Index:13, FedWSQ: Efficient Federated Learning with Weight Standardization and Distribution-Aware Non-Uniform Quantization, https://arxiv.org/pdf/2506.23516, 2025-07-21
2025-11-09 20:29:28,074 - INFO - root - Page:2, Index:14, Spectra 1.1: Scaling Laws and Efficient Inference for Ternary Language Models, https://arxiv.org/pdf/2506.23025, 2025-06-28
2025-11-09 20:29:28,074 - INFO - root - Page:2, Index:15, Joint Quantization and Pruning Neural Networks Approach: A Case Study on FSO Receivers, https://arxiv.org/pdf/2506.20084, 2025-06-24
2025-11-09 20:29:28,074 - INFO - root - Page:2, Index:16, Single-step Diffusion for Image Compression at Ultra-Low Bitrates, https://arxiv.org/pdf/2506.16572, 2025-09-22
2025-11-09 20:29:28,075 - INFO - root - Page:2, Index:17, LittleBit: Ultra Low-Bit Quantization via Latent Factorization, https://arxiv.org/pdf/2506.13771, 2025-10-28
2025-11-09 20:29:28,075 - INFO - root - Page:2, Index:18, MARCO: Hardware-Aware Neural Architecture Search for Edge Devices with Multi-Agent Reinforcement Learning and Conformal Prediction Filtering, https://arxiv.org/pdf/2506.13755, 2025-06-16
2025-11-09 20:29:28,075 - INFO - root - Page:2, Index:19, EAQuant: Enhancing Post-Training Quantization for MoE Models via Expert-Aware Optimization, https://arxiv.org/pdf/2506.13329, 2025-07-04
2025-11-09 20:29:28,075 - INFO - root - Page:2, Index:20, Towards Neural Audio Codec Source Parsing, https://arxiv.org/pdf/2506.12627, 2025-06-14
2025-11-09 20:29:28,077 - INFO - root - Page:2, Index:21, Quantizing Small-Scale State-Space Models for Edge AI, https://arxiv.org/pdf/2506.12480, 2025-06-14
2025-11-09 20:29:28,078 - INFO - root - Page:2, Index:22, EMLoC: Emulator-based Memory-efficient Fine-tuning with LoRA Correction, https://arxiv.org/pdf/2506.12015, 2025-06-13
2025-11-09 20:29:28,078 - INFO - root - Page:2, Index:23, Compression Aware Certified Training, https://arxiv.org/pdf/2506.11992, 2025-06-13
2025-11-09 20:29:28,078 - INFO - root - Page:2, Index:24, GPLQ: A General, Practical, and Lightning QAT Method for Vision Transformers, https://arxiv.org/pdf/2506.11784, 2025-06-13
2025-11-09 20:29:28,078 - INFO - root - Page:2, Index:25, TruncQuant: Truncation-Ready Quantization for DNNs with Flexible Weight Bit Precision, https://arxiv.org/pdf/2506.11431, 2025-06-12
2025-11-09 20:29:28,080 - INFO - root - Page:2, Index:26, EfficientQuant: An Efficient Post-Training Quantization for CNN-Transformer Hybrid Models on Edge Devices, https://arxiv.org/pdf/2506.11093, 2025-06-05
2025-11-09 20:29:28,081 - INFO - root - Page:2, Index:27, Starting Positions Matter: A Study on Better Weight Initialization for Neural Network Quantization, https://arxiv.org/pdf/2506.10463, 2025-06-12
2025-11-09 20:29:28,081 - INFO - root - Page:2, Index:28, AWP: Activation-Aware Weight Pruning and Quantization with Projected Gradient Descent, https://arxiv.org/pdf/2506.10205, 2025-06-11
2025-11-09 20:29:28,081 - INFO - root - Page:2, Index:29, Q-SAM2: Accurate Quantization for Segment Anything Model 2, https://arxiv.org/pdf/2506.09782, 2025-06-11
2025-11-09 20:29:28,081 - INFO - root - Page:2, Index:30, Unifying Block-wise PTQ and Distillation-based QAT for Progressive Quantization toward 2-bit Instruction-Tuned LLMs, https://arxiv.org/pdf/2506.09104, 2025-06-10
2025-11-09 20:29:28,081 - INFO - root - Page:2, Index:31, Implementing Keyword Spotting on the MCUX947 Microcontroller with Integrated NPU, https://arxiv.org/pdf/2506.08911, 2025-06-10
2025-11-09 20:29:28,081 - INFO - root - Page:2, Index:32, POLARON: Precision-aware On-device Learning and Adaptive Runtime-cONfigurable AI acceleration, https://arxiv.org/pdf/2506.08785, 2025-06-10
2025-11-09 20:29:28,083 - INFO - root - Page:2, Index:33, MoQAE: Mixed-Precision Quantization for Long-Context LLM Inference via Mixture of Quantization-Aware Experts, https://arxiv.org/pdf/2506.07533, 2025-06-09
2025-11-09 20:29:28,084 - INFO - root - Page:2, Index:34, BitVLA: 1-bit Vision-Language-Action Models for Robotics Manipulation, https://arxiv.org/pdf/2506.07530, 2025-06-09
2025-11-09 20:29:28,084 - INFO - root - Page:2, Index:35, RecGPT: A Foundation Model for Sequential Recommendation, https://arxiv.org/pdf/2506.06270, 2025-06-12
2025-11-09 20:29:28,086 - INFO - root - Page:2, Index:36, FPSAttention: Training-Aware FP8 and Sparsity Co-Design for Fast Video Diffusion, https://arxiv.org/pdf/2506.04648, 2025-06-05
2025-11-09 20:29:28,086 - INFO - root - Page:2, Index:37, BitTTS: Highly Compact Text-to-Speech Using 1.58-bit Quantization and Weight Indexing, https://arxiv.org/pdf/2506.03515, 2025-06-03
2025-11-09 20:29:28,087 - INFO - root - Page:2, Index:38, ShapeLLM-Omni: A Native Multimodal LLM for 3D Generation and Understanding, https://arxiv.org/pdf/2506.01853, 2025-06-02
2025-11-09 20:29:28,087 - INFO - root - Page:2, Index:39, Movable Antenna Enhanced Federated Fine-Tuning of Large Language Models via Hybrid Client Selection Optimization, https://arxiv.org/pdf/2506.00011, 2025-10-26
2025-11-09 20:29:28,088 - INFO - root - Page:2, Index:40, Running Conventional Automatic Speech Recognition on Memristor Hardware: A Simulated Approach, https://arxiv.org/pdf/2505.24721, 2025-05-30
2025-11-09 20:29:28,088 - INFO - root - Page:2, Index:41, GARLIC: GAussian Representation LearnIng for spaCe partitioning, https://arxiv.org/pdf/2505.24608, 2025-10-02
2025-11-09 20:29:28,088 - INFO - root - Page:2, Index:42, AutoChemSchematic AI: Agentic Physics-Aware Automation for Chemical Manufacturing Scale-Up, https://arxiv.org/pdf/2505.24584, 2025-08-18
2025-11-09 20:29:28,089 - INFO - root - Page:2, Index:43, Model-Preserving Adaptive Rounding, https://arxiv.org/pdf/2505.22988, 2025-09-25
2025-11-09 20:29:28,089 - INFO - root - Page:2, Index:44, Highly Efficient and Effective LLMs with Multi-Boolean Architectures, https://arxiv.org/pdf/2505.22811, 2025-10-03
2025-11-09 20:29:28,089 - INFO - root - Page:2, Index:45, Pioneering 4-Bit FP Quantization for Diffusion Models: Mixup-Sign Quantization and Timestep-Aware Fine-Tuning, https://arxiv.org/pdf/2505.21591, 2025-05-27
2025-11-09 20:29:28,089 - INFO - root - Page:2, Index:46, Frequency Composition for Compressed and Domain-Adaptive Neural Networks, https://arxiv.org/pdf/2505.20890, 2025-05-27
2025-11-09 20:29:28,090 - INFO - root - Page:2, Index:47, MoPFormer: Motion-Primitive Transformer for Wearable-Sensor Activity Recognition, https://arxiv.org/pdf/2505.20744, 2025-10-27
2025-11-09 20:29:28,091 - INFO - root - Page:2, Index:48, Optimizing edge AI models on HPC systems with the edge in the loop, https://arxiv.org/pdf/2505.19995, 2025-05-26
2025-11-09 20:29:28,091 - INFO - root - Fetching page 4 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=150
2025-11-09 20:29:36,313 - INFO - root - get_all_titles_from_web 
2025-11-09 20:29:36,313 - INFO - root - Page:3, Index:0, DPASyn: Mechanism-Aware Drug Synergy Prediction via Dual Attention and Precision-Aware Quantization, https://arxiv.org/pdf/2505.19144, 2025-09-20
2025-11-09 20:29:36,314 - INFO - root - Page:3, Index:1, Reducing Storage of Pretrained Neural Networks by Rate-Constrained Quantization and Entropy Coding, https://arxiv.org/pdf/2505.18758, 2025-05-24
2025-11-09 20:29:36,315 - INFO - root - Page:3, Index:2, Beyond Discreteness: Finite-Sample Analysis of Straight-Through Estimator for Quantization, https://arxiv.org/pdf/2505.18113, 2025-05-23
2025-11-09 20:29:36,315 - INFO - root - Page:3, Index:3, Automating Versatile Time-Series Analysis with Tiny Transformers on Embedded FPGAs, https://arxiv.org/pdf/2505.17662, 2025-09-19
2025-11-09 20:29:36,317 - INFO - root - Page:3, Index:4, FPQVAR: Floating Point Quantization for Visual Autoregressive Model with FPGA Hardware Co-design, https://arxiv.org/pdf/2505.16335, 2025-05-22
2025-11-09 20:29:36,325 - INFO - root - Page:3, Index:5, Saliency-Aware Quantized Imitation Learning for Efficient Robotic Control, https://arxiv.org/pdf/2505.15304, 2025-05-30
2025-11-09 20:29:36,330 - INFO - root - Page:3, Index:6, Scaling Law for Quantization-Aware Training, https://arxiv.org/pdf/2505.14302, 2025-05-20
2025-11-09 20:29:36,341 - INFO - root - Page:3, Index:7, Automatic mixed precision for optimizing gained time with constrained loss mean-squared-error based on model partition to sequential sub-graphs, https://arxiv.org/pdf/2505.13060, 2025-05-19
2025-11-09 20:29:36,344 - INFO - root - Page:3, Index:8, Deep Unfolding with Kernel-based Quantization in MIMO Detection, https://arxiv.org/pdf/2505.12736, 2025-05-19
2025-11-09 20:29:36,344 - INFO - root - Page:3, Index:9, FedHQ: Hybrid Runtime Quantization for Federated Learning, https://arxiv.org/pdf/2505.11982, 2025-05-17
2025-11-09 20:29:36,346 - INFO - root - Page:3, Index:10, QVGen: Pushing the Limit of Quantized Video Generative Models, https://arxiv.org/pdf/2505.11497, 2025-09-27
2025-11-09 20:29:36,347 - INFO - root - Page:3, Index:11, EA-3DGS: Efficient and Adaptive 3D Gaussians with Highly Enhanced Quality for outdoor scenes, https://arxiv.org/pdf/2505.10787, 2025-05-15
2025-11-09 20:29:36,350 - INFO - root - Page:3, Index:12, ITERA-LLM: Boosting Sub-8-Bit Large Language Model Inference via Iterative Tensor Decomposition, https://arxiv.org/pdf/2505.08981, 2025-05-13
2025-11-09 20:29:36,356 - INFO - root - Page:3, Index:13, PROM: Prioritize Reduction of Multiplications Over Lower Bit-Widths for Efficient CNNs, https://arxiv.org/pdf/2505.03254, 2025-08-06
2025-11-09 20:29:36,357 - INFO - root - Page:3, Index:14, ICQuant: Index Coding enables Low-bit LLM Quantization, https://arxiv.org/pdf/2505.00850, 2025-08-24
2025-11-09 20:29:36,360 - INFO - root - Page:3, Index:15, Enhancing Ultra-Low-Bit Quantization of Large Language Models Through Saliency-Aware Partial Retraining, https://arxiv.org/pdf/2504.13932, 2025-07-30
2025-11-09 20:29:36,362 - INFO - root - Page:3, Index:16, Achieving binary weight and activation for LLMs using Post-Training Quantization, https://arxiv.org/pdf/2504.05352, 2025-06-30
2025-11-09 20:29:36,362 - INFO - root - Page:3, Index:17, Wireless Hearables With Programmable Speech AI Accelerators, https://arxiv.org/pdf/2503.18698, 2025-10-21
2025-11-09 20:29:36,373 - INFO - root - Page:3, Index:18, GranQ: Efficient Channel-wise Quantization via Vectorized Pre-Scaling for Zero-Shot QAT, https://arxiv.org/pdf/2503.18339, 2025-10-15
2025-11-09 20:29:36,376 - INFO - root - Page:3, Index:19, CompMarkGS: Robust Watermarking for Compressed 3D Gaussian Splatting, https://arxiv.org/pdf/2503.12836, 2025-09-29
2025-11-09 20:29:36,377 - INFO - root - Page:3, Index:20, AHCPTQ: Accurate and Hardware-Compatible Post-Training Quantization for Segment Anything Model, https://arxiv.org/pdf/2503.03088, 2025-07-11
2025-11-09 20:29:36,379 - INFO - root - Page:3, Index:21, Teaching Metric Distance to Discrete Autoregressive Language Models, https://arxiv.org/pdf/2503.02379, 2025-10-07
2025-11-09 20:29:36,398 - INFO - root - Page:3, Index:22, Regularization-based Framework for Quantization-, Fault- and Variability-Aware Training, https://arxiv.org/pdf/2503.01297, 2025-07-12
2025-11-09 20:29:36,416 - INFO - root - Fetching page 5 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=200
2025-11-09 20:29:43,978 - INFO - root - get_all_titles_from_web 
2025-11-09 20:29:43,978 - INFO - root - Page:4, Index:0, Investigating the Impact of Quantization Methods on the Safety and Reliability of Large Language Models, https://arxiv.org/pdf/2502.15799, 2025-06-29
2025-11-09 20:29:43,979 - INFO - root - Page:4, Index:1, Rotate, Clip, and Partition: Towards W2A4KV4 Quantization by Integrating Rotation and Learnable Non-uniform Quantizer, https://arxiv.org/pdf/2502.15779, 2025-09-01
2025-11-09 20:29:43,979 - INFO - root - Page:4, Index:2, RoSTE: An Efficient Quantization-Aware Supervised Fine-Tuning Approach for Large Language Models, https://arxiv.org/pdf/2502.09003, 2025-06-05
2025-11-09 20:29:43,979 - INFO - root - Page:4, Index:3, Spatial Degradation-Aware and Temporal Consistent Diffusion Model for Compressed Video Super-Resolution, https://arxiv.org/pdf/2502.07381, 2025-06-27
2025-11-09 20:29:43,979 - INFO - root - Page:4, Index:4, QuEST: Stable Training of LLMs with 1-Bit Weights and Activations, https://arxiv.org/pdf/2502.05003, 2025-06-10
2025-11-09 20:29:43,979 - INFO - root - Page:4, Index:5, HALO: Hadamard-Assisted Lower-Precision Optimization for LLMs, https://arxiv.org/pdf/2501.02625, 2025-11-05
2025-11-09 20:29:43,981 - INFO - root - Page:4, Index:6, TAR3D: Creating High-Quality 3D Assets via Next-Part Prediction, https://arxiv.org/pdf/2412.16919, 2025-08-08
2025-11-09 20:29:43,981 - INFO - root - Page:4, Index:7, Training Multi-Layer Binary Neural Networks With Local Binary Error Signals, https://arxiv.org/pdf/2412.00119, 2025-08-05
2025-11-09 20:29:43,981 - INFO - root - Page:4, Index:8, Scaling Large-scale GNN Training to Thousands of Processors on CPU-based Supercomputers, https://arxiv.org/pdf/2411.16025, 2025-05-26
2025-11-09 20:29:43,981 - INFO - root - Page:4, Index:9, HAFLQ: Heterogeneous Adaptive Federated LoRA Fine-tuned LLM with Quantization, https://arxiv.org/pdf/2411.06581, 2025-05-16
2025-11-09 20:29:43,982 - INFO - root - Fetching page 6 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=250
2025-11-09 20:29:50,445 - INFO - root - get_all_titles_from_web 
2025-11-09 20:29:50,446 - INFO - root - Page:5, Index:0, Gradient-Free Training of Quantized Neural Networks, https://arxiv.org/pdf/2410.09734, 2025-09-29
2025-11-09 20:29:50,446 - INFO - root - Page:5, Index:1, QT-DoG: Quantization-aware Training for Domain Generalization, https://arxiv.org/pdf/2410.06020, 2025-06-26
2025-11-09 20:29:50,447 - INFO - root - Page:5, Index:2, Constraint Guided Model Quantization of Neural Networks, https://arxiv.org/pdf/2409.20138, 2025-09-12
2025-11-09 20:29:50,447 - INFO - root - Page:5, Index:3, Accumulator-Aware Post-Training Quantization for Large Language Models, https://arxiv.org/pdf/2409.17092, 2025-07-30
2025-11-09 20:29:50,447 - INFO - root - Page:5, Index:4, DilateQuant: Accurate and Efficient Diffusion Quantization via Weight Dilation, https://arxiv.org/pdf/2409.14307, 2025-07-09
2025-11-09 20:29:50,448 - INFO - root - Page:5, Index:5, Robust Training of Neural Networks at Arbitrary Precision and Sparsity, https://arxiv.org/pdf/2409.09245, 2025-09-23
2025-11-09 20:29:50,448 - INFO - root - Page:5, Index:6, VQ-CTAP: Cross-Modal Fine-Grained Sequence Representation Learning for Speech Processing, https://arxiv.org/pdf/2408.05758, 2025-05-27
2025-11-09 20:29:50,449 - INFO - root - Page:5, Index:7, DopQ-ViT: Towards Distribution-Friendly and Outlier-Aware Post-Training Quantization for Vision Transformers, https://arxiv.org/pdf/2408.03291, 2025-06-19
2025-11-09 20:29:50,451 - INFO - root - Page:5, Index:8, Temporal Feature Matters: A Framework for Diffusion Model Quantization, https://arxiv.org/pdf/2407.19547, 2025-07-11
2025-11-09 20:29:50,451 - INFO - root - Page:5, Index:9, EfficientQAT: Efficient Quantization-Aware Training for Large Language Models, https://arxiv.org/pdf/2407.11062, 2025-05-19
2025-11-09 20:29:50,452 - INFO - root - Page:5, Index:10, Integer-only Quantized Transformers for Embedded FPGA-based Time-series Forecasting in AIoT, https://arxiv.org/pdf/2407.11041, 2025-10-31
2025-11-09 20:29:50,452 - INFO - root - Fetching page 7 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=300
2025-11-09 20:29:57,714 - INFO - root - get_all_titles_from_web 
2025-11-09 20:29:57,715 - INFO - root - Page:6, Index:0, BoA: Attention-aware Post-training Quantization without Backpropagation, https://arxiv.org/pdf/2406.13474, 2025-06-06
2025-11-09 20:29:57,716 - INFO - root - Page:6, Index:1, A Rescaling-Invariant Lipschitz Bound Based on Path-Metrics for Modern ReLU Network Parameterizations, https://arxiv.org/pdf/2405.15006, 2025-06-13
2025-11-09 20:29:57,716 - INFO - root - Page:6, Index:2, Scheduling Weight Transitions for Quantization-Aware Training, https://arxiv.org/pdf/2404.19248, 2025-10-01
2025-11-09 20:29:57,716 - INFO - root - Page:6, Index:3, GPTVQ: The Blessing of Dimensionality for LLM Quantization, https://arxiv.org/pdf/2402.15319, 2025-06-03
2025-11-09 20:29:57,717 - INFO - root - Fetching page 8 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=350
2025-11-09 20:30:06,889 - INFO - root - get_all_titles_from_web 
2025-11-09 20:30:06,891 - INFO - root - Page:7, Index:0, Squat: Quant Small Language Models on the Edge, https://arxiv.org/pdf/2402.10787, 2025-07-01
2025-11-09 20:30:06,892 - INFO - root - Page:7, Index:1, L4Q: Parameter Efficient Quantization-Aware Fine-Tuning on Large Language Models, https://arxiv.org/pdf/2402.04902, 2025-07-21
2025-11-09 20:30:06,893 - INFO - root - Fetching page 9 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=400
2025-11-09 20:30:18,691 - INFO - root - ------------------------------------------------------------------------------------------------------------------------
2025-11-09 20:30:33,568 - INFO - root - 跳过已处理论文 A Quantized VAE-MLP Botnet Detection Model: A Systematic Evaluation of Quantization-Aware Training and Post-Training Quantization Strategies：D:\ChatPaper\academic Papers\Quantization-Aware-Training\A Quantized VAE-MLP Botnet Detection Model_ A Systematic Evaluation of Quantizat-6.pdf
2025-11-09 20:30:33,570 - INFO - root - 跳过已处理论文 FP8-Flow-MoE: A Casting-Free FP8 Recipe without Double Quantization Error：D:\ChatPaper\academic Papers\Quantization-Aware-Training\FP8-Flow-MoE_ A Casting-Free FP8 Recipe without Double Quantization Error-6.pdf
2025-11-09 20:30:33,570 - INFO - root - summary time: 99.85 seconds
2025-11-09 20:41:51,546 - INFO - root - Fetching page 1 with URL: https://arxiv.org/search/?query=traffic+flow+prediction&searchtype=all&abstracts=show&order=-announced_date_first&size=50
2025-11-09 20:41:57,937 - INFO - root - get_all_titles_from_web 
2025-11-09 20:41:57,937 - INFO - root - Page:0, Index:0, A Theoretical Framework for Environmental Similarity and Vessel Mobility as Coupled Predictors of Marine Invasive Species Pathways, https://arxiv.org/pdf/2511.03499, 2025-11-06
2025-11-09 20:41:57,939 - INFO - root - Page:0, Index:1, Towards Sub-millisecond Latency and Guaranteed Bit Rates in 5G User Plane, https://arxiv.org/pdf/2511.00196, 2025-10-31
2025-11-09 20:41:57,939 - INFO - root - Page:0, Index:2, A Cloud-Based Spatio-Temporal GNN-Transformer Hybrid Model for Traffic Flow Forecasting with External Feature Integration, https://arxiv.org/pdf/2510.27039, 2025-10-30
2025-11-09 20:41:57,939 - INFO - root - Page:0, Index:3, Research on Expressway Congestion Warning Technology Based on YOLOv11-DIoU and GRU-Attention, https://arxiv.org/pdf/2509.13361, 2025-11-04
2025-11-09 20:41:57,939 - INFO - root - Fetching page 2 with URL: https://arxiv.org/search/?query=traffic+flow+prediction&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=50
2025-11-09 20:45:14,569 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-09 20:45:14,571 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-09 20:45:14,572 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-09 20:45:15,662 - INFO - root - LLMClientManager: 指定使用客户端: DeepSeek
2025-11-09 20:45:15,663 - WARNING - root - DeepSeekClient: API key not provided. LLM disabled.
2025-11-09 20:45:15,663 - ERROR - root - LLMClientManager: 指定的客户端 DeepSeek 初始化失败
2025-11-09 20:45:15,663 - WARNING - root - LLMClientManager: 指定的客户端 DeepSeek 不可用，将尝试其他客户端
2025-11-09 20:45:16,564 - INFO - root - GeminiClient: trying model gemini-2.5-flash
2025-11-09 20:45:19,999 - INFO - root - GeminiClient: initialized model gemini-2.5-flash
2025-11-09 20:45:20,000 - INFO - root - LLMClientManager: Gemini client initialized successfully
2025-11-09 20:45:20,000 - INFO - root - LLMClientManager: using Gemini as default client
2025-11-09 20:45:20,000 - WARNING - root - KimiClient: API key not provided. LLM disabled.
2025-11-09 20:45:20,001 - WARNING - root - LLMClientManager: Kimi client initialization failed
2025-11-09 20:45:20,001 - WARNING - root - QwenClient: API key not provided. LLM disabled.
2025-11-09 20:45:20,001 - WARNING - root - LLMClientManager: Qwen client initialization failed
2025-11-09 20:45:20,001 - INFO - root - DoubaoClient: API key found: 9f9e270e-b...
2025-11-09 20:45:24,845 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 20:45:24,863 - INFO - root - DoubaoClient: initialized successfully with model doubao-seed-1-6-lite-251015
2025-11-09 20:45:24,863 - INFO - root - LLMClientManager: Doubao client initialized successfully
2025-11-09 20:45:24,864 - WARNING - root - LLMClientManager: client DeepSeek not available
2025-11-09 20:45:24,864 - WARNING - root - 无法切换到指定的客户端 DeepSeek，将使用默认客户端
2025-11-09 20:45:24,864 - INFO - root - 可用客户端: ['Gemini', 'Doubao']
2025-11-09 20:45:24,864 - INFO - root - 使用 LLM 模型: gemini-2.5-flash
2025-11-09 20:45:24,865 - INFO - root - 可用客户端: ['Gemini', 'Doubao']
2025-11-09 20:45:24,866 - INFO - root - === 运行配置 ===
2025-11-09 20:45:24,866 - INFO - root - 处理模式: arxiv在线搜索
2025-11-09 20:45:24,866 - INFO - root - 关键词: QAT
2025-11-09 20:45:24,866 - INFO - root - 查询: Quantization-Aware-Training
2025-11-09 20:45:24,867 - INFO - root - 排序: None
2025-11-09 20:45:24,870 - INFO - root - 最近天数: 180
2025-11-09 20:45:24,871 - INFO - root - 最大处理数量: 2
2025-11-09 20:45:24,872 - INFO - root - 保存图片: 是
2025-11-09 20:45:24,872 - INFO - root - 输出语言: 中文
2025-11-09 20:45:24,872 - INFO - root - 强制重新处理: 否
2025-11-09 20:45:24,873 - INFO - root - ====================
2025-11-09 20:45:24,873 - INFO - root - 使用 arXiv 搜索模式（通过 chat_arxiv 模块获取）
2025-11-09 20:45:24,874 - INFO - root - Fetching page 1 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50
2025-11-09 20:45:32,073 - INFO - root - get_all_titles_from_web 
2025-11-09 20:45:32,074 - INFO - root - Page:0, Index:0, A Quantized VAE-MLP Botnet Detection Model: A Systematic Evaluation of Quantization-Aware Training and Post-Training Quantization Strategies, https://arxiv.org/pdf/2511.03201, 2025-11-05
2025-11-09 20:45:32,074 - INFO - root - Page:0, Index:1, FP8-Flow-MoE: A Casting-Free FP8 Recipe without Double Quantization Error, https://arxiv.org/pdf/2511.02302, 2025-11-04
2025-11-09 20:45:32,074 - INFO - root - Page:0, Index:2, Outlier-Aware Post-Training Quantization for Image Super-Resolution, https://arxiv.org/pdf/2511.00682, 2025-11-01
2025-11-09 20:45:32,074 - INFO - root - Page:0, Index:3, Evaluation of Wafer-Scale SOT-MRAM for Analog Crossbar Array Applications, https://arxiv.org/pdf/2510.25853, 2025-11-03
2025-11-09 20:45:32,074 - INFO - root - Page:0, Index:4, Improving the Straight-Through Estimator with Zeroth-Order Information, https://arxiv.org/pdf/2510.23926, 2025-10-27
2025-11-09 20:45:32,075 - INFO - root - Page:0, Index:5, Real-Time Semantic Segmentation on FPGA for Autonomous Vehicles Using LMIINet with the CGRA4ML Framework, https://arxiv.org/pdf/2510.22243, 2025-10-25
2025-11-09 20:45:32,075 - INFO - root - Page:0, Index:6, TernaryCLIP: Efficiently Compressing Vision-Language Models with Ternary Weights and Distilled Knowledge, https://arxiv.org/pdf/2510.21879, 2025-10-23
2025-11-09 20:45:32,076 - INFO - root - Page:0, Index:7, KARIPAP: Quantum-Inspired Tensor Network Compression of Large Language Models Using Infinite Projected Entangled Pair States and Tensor Renormalization Group, https://arxiv.org/pdf/2510.21844, 2025-10-22
2025-11-09 20:45:32,076 - INFO - root - Page:0, Index:8, A Convergence Analysis of Adaptive Optimizers under Floating-point Quantization, https://arxiv.org/pdf/2510.21314, 2025-10-24
2025-11-09 20:45:32,076 - INFO - root - Page:0, Index:9, Adaptive Distribution-aware Quantization for Mixed-Precision Neural Networks, https://arxiv.org/pdf/2510.19760, 2025-10-22
2025-11-09 20:45:32,076 - INFO - root - Page:0, Index:10, CAGE: Curvature-Aware Gradient Estimation For Accurate Quantization-Aware Training, https://arxiv.org/pdf/2510.18784, 2025-10-21
2025-11-09 20:45:32,078 - INFO - root - Page:0, Index:11, Mixed-Precision Quantization for Language Models: Techniques and Prospects, https://arxiv.org/pdf/2510.16805, 2025-10-19
2025-11-09 20:45:32,078 - INFO - root - Page:0, Index:12, SPLite Hand: Sparsity-Aware Lightweight 3D Hand Pose Estimation, https://arxiv.org/pdf/2510.16396, 2025-10-30
2025-11-09 20:45:32,078 - INFO - root - Page:0, Index:13, CTR-LoRA: Curvature-Aware and Trust-Region Guided Low-Rank Adaptation for Large Language Models, https://arxiv.org/pdf/2510.15962, 2025-10-11
2025-11-09 20:45:32,078 - INFO - root - Page:0, Index:14, SANR: Scene-Aware Neural Representation for Light Field Image Compression with Rate-Distortion Optimization, https://arxiv.org/pdf/2510.15775, 2025-10-17
2025-11-09 20:45:32,079 - INFO - root - Page:0, Index:15, SpikeFit: Towards Optimal Deployment of Spiking Networks on Neuromorphic Hardware, https://arxiv.org/pdf/2510.15542, 2025-10-31
2025-11-09 20:45:32,079 - INFO - root - Page:0, Index:16, GRank: Towards Target-Aware and Streamlined Industrial Retrieval with a Generate-Rank Framework, https://arxiv.org/pdf/2510.15299, 2025-10-17
2025-11-09 20:45:32,080 - INFO - root - Page:0, Index:17, SaLon3R: Structure-aware Long-term Generalizable 3D Reconstruction from Unposed Images, https://arxiv.org/pdf/2510.15072, 2025-10-16
2025-11-09 20:45:32,080 - INFO - root - Page:0, Index:18, FraQAT: Quantization Aware Training with Fractional bits, https://arxiv.org/pdf/2510.14823, 2025-10-16
2025-11-09 20:45:32,080 - INFO - root - Page:0, Index:19, Computing-In-Memory Aware Model Adaption For Edge Devices, https://arxiv.org/pdf/2510.14379, 2025-10-16
2025-11-09 20:45:32,080 - INFO - root - Page:0, Index:20, Invited Paper: BitMedViT: Ternary-Quantized Vision Transformer for Medical AI Assistants on the Edge, https://arxiv.org/pdf/2510.13760, 2025-11-04
2025-11-09 20:45:32,082 - INFO - root - Page:0, Index:21, NeuroRVQ: Multi-Scale EEG Tokenization for Generative Large Brainwave Models, https://arxiv.org/pdf/2510.13068, 2025-10-14
2025-11-09 20:45:32,082 - INFO - root - Page:0, Index:22, Detect Anything via Next Point Prediction, https://arxiv.org/pdf/2510.12798, 2025-10-14
2025-11-09 20:45:32,082 - INFO - root - Page:0, Index:23, AndesVL Technical Report: An Efficient Mobile-side Multimodal Large Language Model, https://arxiv.org/pdf/2510.11496, 2025-10-14
2025-11-09 20:45:32,085 - INFO - root - Page:0, Index:24, Rescaling-Aware Training for Efficient Deployment of Deep Learning Models on Full-Integer Hardware, https://arxiv.org/pdf/2510.11484, 2025-10-13
2025-11-09 20:45:32,085 - INFO - root - Page:0, Index:25, SASER: Stego attacks on open-source LLMs, https://arxiv.org/pdf/2510.10486, 2025-10-12
2025-11-09 20:45:32,085 - INFO - root - Page:0, Index:26, Ultralytics YOLO Evolution: An Overview of YOLO26, YOLO11, YOLOv8 and YOLOv5 Object Detectors for Computer Vision and Pattern Recognition, https://arxiv.org/pdf/2510.09653, 2025-10-15
2025-11-09 20:45:32,086 - INFO - root - Page:0, Index:27, A Theoretically-Grounded Codebook for Digital Semantic Communications, https://arxiv.org/pdf/2510.07108, 2025-10-14
2025-11-09 20:45:32,086 - INFO - root - Page:0, Index:28, QuantDemoire: Quantization with Outlier Aware for Image Demoiréing, https://arxiv.org/pdf/2510.04066, 2025-10-05
2025-11-09 20:45:32,087 - INFO - root - Page:0, Index:29, Adaptively Sampling-Reusing-Mixing Decomposed Gradients to Speed Up Sharpness Aware Minimization, https://arxiv.org/pdf/2510.03763, 2025-10-04
2025-11-09 20:45:32,088 - INFO - root - Page:0, Index:30, Quant-dLLM: Post-Training Extreme Low-Bit Quantization for Diffusion Large Language Models, https://arxiv.org/pdf/2510.03274, 2025-09-27
2025-11-09 20:45:32,090 - INFO - root - Page:0, Index:31, PT$^2$-LLM: Post-Training Ternarization for Large Language Models, https://arxiv.org/pdf/2510.03267, 2025-09-26
2025-11-09 20:45:32,095 - INFO - root - Page:0, Index:32, Purrception: Variational Flow Matching for Vector-Quantized Image Generation, https://arxiv.org/pdf/2510.01478, 2025-10-01
2025-11-09 20:45:32,095 - INFO - root - Page:0, Index:33, Post-Training Quantization for Audio Diffusion Transformers, https://arxiv.org/pdf/2510.00313, 2025-09-30
2025-11-09 20:45:32,096 - INFO - root - Page:0, Index:34, Rethinking RoPE Scaling in Quantized LLM: Theory, Outlier, and Channel-Band Analysis with Weight Rescaling, https://arxiv.org/pdf/2510.00028, 2025-09-25
2025-11-09 20:45:32,096 - INFO - root - Page:0, Index:35, Post-Training Quantization via Residual Truncation and Zero Suppression for Diffusion Models, https://arxiv.org/pdf/2509.26436, 2025-09-30
2025-11-09 20:45:32,096 - INFO - root - Page:0, Index:36, Cat: Post-Training Quantization Error Reduction via Cluster-based Affine Transformation, https://arxiv.org/pdf/2509.26277, 2025-10-07
2025-11-09 20:45:32,097 - INFO - root - Page:0, Index:37, CAST: Continuous and Differentiable Semi-Structured Sparsity-Aware Training for Large Language Models, https://arxiv.org/pdf/2509.25996, 2025-09-30
2025-11-09 20:45:32,097 - INFO - root - Page:0, Index:38, Norm-Q: Effective Compression Method for Hidden Markov Models in Neuro-Symbolic Applications, https://arxiv.org/pdf/2509.25439, 2025-09-29
2025-11-09 20:45:32,097 - INFO - root - Page:0, Index:39, On-the-Fly Adaptation to Quantization: Configuration-Aware LoRA for Efficient Fine-Tuning of Quantized LLMs, https://arxiv.org/pdf/2509.25214, 2025-09-22
2025-11-09 20:45:32,098 - INFO - root - Page:0, Index:40, VoxCPM: Tokenizer-Free TTS for Context-Aware Speech Generation and True-to-Life Voice Cloning, https://arxiv.org/pdf/2509.24650, 2025-09-29
2025-11-09 20:45:32,098 - INFO - root - Page:0, Index:41, S$^2$NN: Sub-bit Spiking Neural Networks, https://arxiv.org/pdf/2509.24266, 2025-10-24
2025-11-09 20:45:32,101 - INFO - root - Page:0, Index:42, Tequila: Trapping-free Ternary Quantization for Large Language Models, https://arxiv.org/pdf/2509.23809, 2025-10-17
2025-11-09 20:45:32,103 - INFO - root - Page:0, Index:43, Texture Vector-Quantization and Reconstruction Aware Prediction for Generative Super-Resolution, https://arxiv.org/pdf/2509.23774, 2025-09-30
2025-11-09 20:45:32,103 - INFO - root - Page:0, Index:44, RobuQ: Pushing DiTs to W1.58A2 via Robust Activation Quantization, https://arxiv.org/pdf/2509.23582, 2025-09-27
2025-11-09 20:45:32,103 - INFO - root - Page:0, Index:45, Beyond Outliers: A Study of Optimizers Under Quantization, https://arxiv.org/pdf/2509.23500, 2025-10-02
2025-11-09 20:45:32,104 - INFO - root - Page:0, Index:46, Compute-Optimal Quantization-Aware Training, https://arxiv.org/pdf/2509.22935, 2025-09-26
2025-11-09 20:45:32,104 - INFO - root - Page:0, Index:47, COSPADI: Compressing LLMs via Calibration-Guided Sparse Dictionary Learning, https://arxiv.org/pdf/2509.22075, 2025-10-06
2025-11-09 20:45:32,105 - INFO - root - Page:0, Index:48, SlimDiff: Training-Free, Activation-Guided Hands-free Slimming of Diffusion Models, https://arxiv.org/pdf/2509.21498, 2025-09-25
2025-11-09 20:45:32,105 - INFO - root - Page:0, Index:49, Quantized Visual Geometry Grounded Transformer, https://arxiv.org/pdf/2509.21302, 2025-09-29
2025-11-09 20:45:32,105 - INFO - root - Fetching page 2 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=50
2025-11-09 20:45:39,008 - INFO - root - get_all_titles_from_web 
2025-11-09 20:45:39,009 - INFO - root - Page:1, Index:0, Can Less Precise Be More Reliable? A Systematic Evaluation of Quantization's Impact on CLIP Beyond Accuracy, https://arxiv.org/pdf/2509.21173, 2025-10-27
2025-11-09 20:45:39,009 - INFO - root - Page:1, Index:1, Punching Above Precision: Small Quantized Model Distillation with Learnable Regularizer, https://arxiv.org/pdf/2509.20854, 2025-09-25
2025-11-09 20:45:39,009 - INFO - root - Page:1, Index:2, TinyEcoWeedNet: Edge Efficient Real-Time Aerial Agricultural Weed Detection, https://arxiv.org/pdf/2509.18193, 2025-09-19
2025-11-09 20:45:39,009 - INFO - root - Page:1, Index:3, SBVR: Summation of BitVector Representation for Efficient LLM Quantization, https://arxiv.org/pdf/2509.18172, 2025-09-17
2025-11-09 20:45:39,010 - INFO - root - Page:1, Index:4, QWHA: Quantization-Aware Walsh-Hadamard Adaptation for Parameter-Efficient Fine-Tuning on Large Language Models, https://arxiv.org/pdf/2509.17428, 2025-09-26
2025-11-09 20:45:39,010 - INFO - root - Page:1, Index:5, PTQTP: Post-Training Quantization to Trit-Planes for Large Language Models, https://arxiv.org/pdf/2509.16989, 2025-10-28
2025-11-09 20:45:39,010 - INFO - root - Page:1, Index:6, MEC-Quant: Maximum Entropy Coding for Extremely Low Bit Quantization-Aware Training, https://arxiv.org/pdf/2509.15514, 2025-09-18
2025-11-09 20:45:39,011 - INFO - root - Page:1, Index:7, Q-ROAR: Outlier-Aware Rescaling for RoPE Position Interpolation in Quantized Long-Context LLMs, https://arxiv.org/pdf/2509.14391, 2025-09-17
2025-11-09 20:45:39,011 - INFO - root - Page:1, Index:8, Efficient Quantization-Aware Neural Receivers: Beyond Post-Training Quantization, https://arxiv.org/pdf/2509.13786, 2025-09-19
2025-11-09 20:45:39,011 - INFO - root - Page:1, Index:9, Rate-Distortion Limits for Multimodal Retrieval: Theory, Optimal Codes, and Finite-Sample Guarantees, https://arxiv.org/pdf/2509.11054, 2025-09-13
2025-11-09 20:45:39,012 - INFO - root - Page:1, Index:10, SQAP-VLA: A Synergistic Quantization-Aware Pruning Framework for High-Performance Vision-Language-Action Models, https://arxiv.org/pdf/2509.09090, 2025-09-10
2025-11-09 20:45:39,012 - INFO - root - Page:1, Index:11, CSI Compression Beyond Latents: End-to-End Hybrid Attention-CNN Networks with Entropy Regularization, https://arxiv.org/pdf/2509.08776, 2025-09-10
2025-11-09 20:45:39,012 - INFO - root - Page:1, Index:12, Explaining How Quantization Disparately Skews a Model, https://arxiv.org/pdf/2509.07222, 2025-09-08
2025-11-09 20:45:39,012 - INFO - root - Page:1, Index:13, LoaQ: Layer-wise Output Approximation Quantization, https://arxiv.org/pdf/2509.06297, 2025-09-07
2025-11-09 20:45:39,012 - INFO - root - Page:1, Index:14, FineServe: Precision-Aware KV Slab and Two-Level Scheduling for Heterogeneous Precision LLM Serving, https://arxiv.org/pdf/2509.06261, 2025-09-14
2025-11-09 20:45:39,014 - INFO - root - Page:1, Index:15, Sensitivity-Aware Post-Training Quantization for Deep Neural Networks, https://arxiv.org/pdf/2509.05576, 2025-09-05
2025-11-09 20:45:39,014 - INFO - root - Page:1, Index:16, SuperSNN: A Hardware-Aware Framework for Physically Realizable, High-Performance Superconducting Spiking Neural Network Chips, https://arxiv.org/pdf/2509.05532, 2025-09-05
2025-11-09 20:45:39,014 - INFO - root - Page:1, Index:17, Data-Augmented Quantization-Aware Knowledge Distillation, https://arxiv.org/pdf/2509.03850, 2025-09-03
2025-11-09 20:45:39,015 - INFO - root - Page:1, Index:18, DPQuant: Efficient and Differentially-Private Model Training via Dynamic Quantization Scheduling, https://arxiv.org/pdf/2509.03472, 2025-09-03
2025-11-09 20:45:39,015 - INFO - root - Page:1, Index:19, Empowering Large Language Model for Sequential Recommendation via Multimodal Embeddings and Semantic IDs, https://arxiv.org/pdf/2509.02017, 2025-09-02
2025-11-09 20:45:39,016 - INFO - root - Page:1, Index:20, Q-Sched: Pushing the Boundaries of Few-Step Diffusion Models with Quantization-Aware Scheduling, https://arxiv.org/pdf/2509.01624, 2025-09-01
2025-11-09 20:45:39,016 - INFO - root - Page:1, Index:21, Quantization Meets OOD: Generalizable Quantization-aware Training from a Flatness Perspective, https://arxiv.org/pdf/2509.00859, 2025-08-31
2025-11-09 20:45:39,017 - INFO - root - Page:1, Index:22, Progressive Element-wise Gradient Estimation for Neural Network Quantization, https://arxiv.org/pdf/2509.00097, 2025-08-27
2025-11-09 20:45:39,017 - INFO - root - Page:1, Index:23, End-to-End On-Device Quantization-Aware Training for LLMs at Inference Cost, https://arxiv.org/pdf/2509.00031, 2025-09-29
2025-11-09 20:45:39,018 - INFO - root - Page:1, Index:24, Quantization Robustness to Input Degradations for Object Detection, https://arxiv.org/pdf/2508.19600, 2025-08-27
2025-11-09 20:45:39,019 - INFO - root - Page:1, Index:25, Scaling Laws for Task-Stratified Knowledge in Post-Training Quantized Large Language Models, https://arxiv.org/pdf/2508.18609, 2025-08-27
2025-11-09 20:45:39,019 - INFO - root - Page:1, Index:26, AQ-PCDSys: An Adaptive Quantized Planetary Crater Detection System for Autonomous Space Exploration, https://arxiv.org/pdf/2508.18025, 2025-08-25
2025-11-09 20:45:39,019 - INFO - root - Page:1, Index:27, TaDiCodec: Text-aware Diffusion Speech Tokenizer for Speech Language Modeling, https://arxiv.org/pdf/2508.16790, 2025-08-22
2025-11-09 20:45:39,020 - INFO - root - Page:1, Index:28, A Node-Aware Dynamic Quantization Approach for Graph Collaborative Filtering, https://arxiv.org/pdf/2508.16516, 2025-08-22
2025-11-09 20:45:39,020 - INFO - root - Page:1, Index:29, JEDI-linear: Fast and Efficient Graph Neural Networks for Jet Tagging on FPGAs, https://arxiv.org/pdf/2508.15468, 2025-08-21
2025-11-09 20:45:39,020 - INFO - root - Page:1, Index:30, MMQ: Multimodal Mixture-of-Quantization Tokenization for Semantic ID Generation and User Behavioral Adaptation, https://arxiv.org/pdf/2508.15281, 2025-08-21
2025-11-09 20:45:39,020 - INFO - root - Page:1, Index:31, DLLMQuant: Quantizing Diffusion-based Large Language Models, https://arxiv.org/pdf/2508.14090, 2025-08-25
2025-11-09 20:45:39,021 - INFO - root - Page:1, Index:32, Automated Energy-Aware Time-Series Model Deployment on Embedded FPGAs for Resilient Combined Sewer Overflow Management, https://arxiv.org/pdf/2508.13905, 2025-08-19
2025-11-09 20:45:39,021 - INFO - root - Page:1, Index:33, XR-NPE: High-Throughput Mixed-precision SIMD Neural Processing Engine for Extended Reality Perception Workloads, https://arxiv.org/pdf/2508.13049, 2025-08-18
2025-11-09 20:45:39,023 - INFO - root - Page:1, Index:34, Exploring Self-Supervised Audio Models for Generalized Anomalous Sound Detection, https://arxiv.org/pdf/2508.12230, 2025-08-17
2025-11-09 20:45:39,025 - INFO - root - Page:1, Index:35, TriQDef: Disrupting Semantic and Gradient Alignment to Prevent Adversarial Patch Transferability in Quantized Neural Networks, https://arxiv.org/pdf/2508.12132, 2025-08-16
2025-11-09 20:45:39,026 - INFO - root - Page:1, Index:36, Error Propagation Mechanisms and Compensation Strategies for Quantized Diffusion, https://arxiv.org/pdf/2508.12094, 2025-10-13
2025-11-09 20:45:39,026 - INFO - root - Page:1, Index:37, Extending Straight-Through Estimation for Robust Neural Networks on Analog CIM Hardware, https://arxiv.org/pdf/2508.11940, 2025-08-16
2025-11-09 20:45:39,026 - INFO - root - Page:1, Index:38, PTQAT: A Hybrid Parameter-Efficient Quantization Algorithm for 3D Perception Tasks, https://arxiv.org/pdf/2508.10557, 2025-08-15
2025-11-09 20:45:39,027 - INFO - root - Page:1, Index:39, MiCo: End-to-End Mixed Precision Neural Network Co-Exploration Framework for Edge AI, https://arxiv.org/pdf/2508.09500, 2025-08-13
2025-11-09 20:45:39,027 - INFO - root - Page:1, Index:40, SPARC: Soft Probabilistic Adaptive multi-interest Retrieval Model via Codebooks for recommender system, https://arxiv.org/pdf/2508.09090, 2025-08-12
2025-11-09 20:45:39,027 - INFO - root - Page:1, Index:41, Rethinking 1-bit Optimization Leveraging Pre-trained Large Language Models, https://arxiv.org/pdf/2508.06974, 2025-08-09
2025-11-09 20:45:39,027 - INFO - root - Page:1, Index:42, Efficient Deep Neural Receiver with Post-Training Quantization, https://arxiv.org/pdf/2508.06275, 2025-08-08
2025-11-09 20:45:39,028 - INFO - root - Page:1, Index:43, iFairy: the First 2-bit Complex LLM with All Parameters in $\{\pm1, \pm i\}$, https://arxiv.org/pdf/2508.05571, 2025-08-16
2025-11-09 20:45:39,028 - INFO - root - Page:1, Index:44, S$^2$Q-VDiT: Accurate Quantized Video Diffusion Transformer with Salient Data and Sparse Token Distillation, https://arxiv.org/pdf/2508.04016, 2025-10-27
2025-11-09 20:45:39,028 - INFO - root - Page:1, Index:45, LRQ-DiT: Log-Rotation Post-Training Quantization of Diffusion Transformers for Image and Video Generation, https://arxiv.org/pdf/2508.03485, 2025-09-23
2025-11-09 20:45:39,030 - INFO - root - Page:1, Index:46, VLMQ: Efficient Post-Training Quantization for Large Vision-Language Models via Hessian Augmentation, https://arxiv.org/pdf/2508.03351, 2025-08-05
2025-11-09 20:45:39,030 - INFO - root - Page:1, Index:47, TF-MLPNet: Tiny Real-Time Neural Speech Separation, https://arxiv.org/pdf/2508.03047, 2025-08-04
2025-11-09 20:45:39,030 - INFO - root - Page:1, Index:48, SaviorRec: Semantic-Behavior Alignment for Cold-Start Recommendation, https://arxiv.org/pdf/2508.01375, 2025-08-02
2025-11-09 20:45:39,031 - INFO - root - Page:1, Index:49, MixA-Q: Revisiting Activation Sparsity for Vision Transformers from a Mixed-Precision Quantization Perspective, https://arxiv.org/pdf/2507.19131, 2025-07-25
2025-11-09 20:45:39,031 - INFO - root - Fetching page 3 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=100
2025-11-09 20:45:46,283 - INFO - root - get_all_titles_from_web 
2025-11-09 20:45:46,283 - INFO - root - Page:2, Index:0, Enhancing Quantization-Aware Training on Edge Devices via Relative Entropy Coreset Selection and Cascaded Layer Correction, https://arxiv.org/pdf/2507.17768, 2025-07-16
2025-11-09 20:45:46,284 - INFO - root - Page:2, Index:1, SiLQ: Simple Large Language Model Quantization-Aware Training, https://arxiv.org/pdf/2507.16933, 2025-07-22
2025-11-09 20:45:46,284 - INFO - root - Page:2, Index:2, Task-Specific Zero-shot Quantization-Aware Training for Object Detection, https://arxiv.org/pdf/2507.16782, 2025-07-22
2025-11-09 20:45:46,284 - INFO - root - Page:2, Index:3, TorchAO: PyTorch-Native Training-to-Serving Model Optimization, https://arxiv.org/pdf/2507.16099, 2025-07-21
2025-11-09 20:45:46,284 - INFO - root - Page:2, Index:4, SegQuant: A Semantics-Aware and Generalizable Quantization Framework for Diffusion Models, https://arxiv.org/pdf/2507.14811, 2025-08-27
2025-11-09 20:45:46,285 - INFO - root - Page:2, Index:5, Apple Intelligence Foundation Language Models: Tech Report 2025, https://arxiv.org/pdf/2507.13575, 2025-08-27
2025-11-09 20:45:46,285 - INFO - root - Page:2, Index:6, Generative Multi-Target Cross-Domain Recommendation, https://arxiv.org/pdf/2507.12871, 2025-08-07
2025-11-09 20:45:46,285 - INFO - root - Page:2, Index:7, DAF: An Efficient End-to-End Dynamic Activation Framework for on-Device DNN Training, https://arxiv.org/pdf/2507.07149, 2025-07-09
2025-11-09 20:45:46,285 - INFO - root - Page:2, Index:8, Opto-ViT: Architecting a Near-Sensor Region of Interest-Aware Vision Transformer Accelerator with Silicon Photonics, https://arxiv.org/pdf/2507.07044, 2025-07-15
2025-11-09 20:45:46,285 - INFO - root - Page:2, Index:9, QS4D: Quantization-aware training for efficient hardware deployment of structured state-space sequential models, https://arxiv.org/pdf/2507.06079, 2025-07-08
2025-11-09 20:45:46,286 - INFO - root - Page:2, Index:10, GSVR: 2D Gaussian-based Video Representation for 800+ FPS with Hybrid Deformation Field, https://arxiv.org/pdf/2507.05594, 2025-07-07
2025-11-09 20:45:46,290 - INFO - root - Page:2, Index:11, Hita: Holistic Tokenizer for Autoregressive Image Generation, https://arxiv.org/pdf/2507.02358, 2025-07-11
2025-11-09 20:45:46,291 - INFO - root - Page:2, Index:12, QPART: Adaptive Model Quantization and Dynamic Workload Balancing for Accuracy-aware Edge Inference, https://arxiv.org/pdf/2506.23934, 2025-06-30
2025-11-09 20:45:46,291 - INFO - root - Page:2, Index:13, FedWSQ: Efficient Federated Learning with Weight Standardization and Distribution-Aware Non-Uniform Quantization, https://arxiv.org/pdf/2506.23516, 2025-07-21
2025-11-09 20:45:46,292 - INFO - root - Page:2, Index:14, Spectra 1.1: Scaling Laws and Efficient Inference for Ternary Language Models, https://arxiv.org/pdf/2506.23025, 2025-06-28
2025-11-09 20:45:46,296 - INFO - root - Page:2, Index:15, Joint Quantization and Pruning Neural Networks Approach: A Case Study on FSO Receivers, https://arxiv.org/pdf/2506.20084, 2025-06-24
2025-11-09 20:45:46,297 - INFO - root - Page:2, Index:16, Single-step Diffusion for Image Compression at Ultra-Low Bitrates, https://arxiv.org/pdf/2506.16572, 2025-09-22
2025-11-09 20:45:46,298 - INFO - root - Page:2, Index:17, LittleBit: Ultra Low-Bit Quantization via Latent Factorization, https://arxiv.org/pdf/2506.13771, 2025-10-28
2025-11-09 20:45:46,298 - INFO - root - Page:2, Index:18, MARCO: Hardware-Aware Neural Architecture Search for Edge Devices with Multi-Agent Reinforcement Learning and Conformal Prediction Filtering, https://arxiv.org/pdf/2506.13755, 2025-06-16
2025-11-09 20:45:46,298 - INFO - root - Page:2, Index:19, EAQuant: Enhancing Post-Training Quantization for MoE Models via Expert-Aware Optimization, https://arxiv.org/pdf/2506.13329, 2025-07-04
2025-11-09 20:45:46,299 - INFO - root - Page:2, Index:20, Towards Neural Audio Codec Source Parsing, https://arxiv.org/pdf/2506.12627, 2025-06-14
2025-11-09 20:45:46,299 - INFO - root - Page:2, Index:21, Quantizing Small-Scale State-Space Models for Edge AI, https://arxiv.org/pdf/2506.12480, 2025-06-14
2025-11-09 20:45:46,299 - INFO - root - Page:2, Index:22, EMLoC: Emulator-based Memory-efficient Fine-tuning with LoRA Correction, https://arxiv.org/pdf/2506.12015, 2025-06-13
2025-11-09 20:45:46,300 - INFO - root - Page:2, Index:23, Compression Aware Certified Training, https://arxiv.org/pdf/2506.11992, 2025-06-13
2025-11-09 20:45:46,300 - INFO - root - Page:2, Index:24, GPLQ: A General, Practical, and Lightning QAT Method for Vision Transformers, https://arxiv.org/pdf/2506.11784, 2025-06-13
2025-11-09 20:45:46,300 - INFO - root - Page:2, Index:25, TruncQuant: Truncation-Ready Quantization for DNNs with Flexible Weight Bit Precision, https://arxiv.org/pdf/2506.11431, 2025-06-12
2025-11-09 20:45:46,300 - INFO - root - Page:2, Index:26, EfficientQuant: An Efficient Post-Training Quantization for CNN-Transformer Hybrid Models on Edge Devices, https://arxiv.org/pdf/2506.11093, 2025-06-05
2025-11-09 20:45:46,302 - INFO - root - Page:2, Index:27, Starting Positions Matter: A Study on Better Weight Initialization for Neural Network Quantization, https://arxiv.org/pdf/2506.10463, 2025-06-12
2025-11-09 20:45:46,303 - INFO - root - Page:2, Index:28, AWP: Activation-Aware Weight Pruning and Quantization with Projected Gradient Descent, https://arxiv.org/pdf/2506.10205, 2025-06-11
2025-11-09 20:45:46,304 - INFO - root - Page:2, Index:29, Q-SAM2: Accurate Quantization for Segment Anything Model 2, https://arxiv.org/pdf/2506.09782, 2025-06-11
2025-11-09 20:45:46,304 - INFO - root - Page:2, Index:30, Unifying Block-wise PTQ and Distillation-based QAT for Progressive Quantization toward 2-bit Instruction-Tuned LLMs, https://arxiv.org/pdf/2506.09104, 2025-06-10
2025-11-09 20:45:46,304 - INFO - root - Page:2, Index:31, Implementing Keyword Spotting on the MCUX947 Microcontroller with Integrated NPU, https://arxiv.org/pdf/2506.08911, 2025-06-10
2025-11-09 20:45:46,304 - INFO - root - Page:2, Index:32, POLARON: Precision-aware On-device Learning and Adaptive Runtime-cONfigurable AI acceleration, https://arxiv.org/pdf/2506.08785, 2025-06-10
2025-11-09 20:45:46,306 - INFO - root - Page:2, Index:33, MoQAE: Mixed-Precision Quantization for Long-Context LLM Inference via Mixture of Quantization-Aware Experts, https://arxiv.org/pdf/2506.07533, 2025-06-09
2025-11-09 20:45:46,306 - INFO - root - Page:2, Index:34, BitVLA: 1-bit Vision-Language-Action Models for Robotics Manipulation, https://arxiv.org/pdf/2506.07530, 2025-06-09
2025-11-09 20:45:46,308 - INFO - root - Page:2, Index:35, RecGPT: A Foundation Model for Sequential Recommendation, https://arxiv.org/pdf/2506.06270, 2025-06-12
2025-11-09 20:45:46,309 - INFO - root - Page:2, Index:36, FPSAttention: Training-Aware FP8 and Sparsity Co-Design for Fast Video Diffusion, https://arxiv.org/pdf/2506.04648, 2025-06-05
2025-11-09 20:45:46,309 - INFO - root - Page:2, Index:37, BitTTS: Highly Compact Text-to-Speech Using 1.58-bit Quantization and Weight Indexing, https://arxiv.org/pdf/2506.03515, 2025-06-03
2025-11-09 20:45:46,311 - INFO - root - Page:2, Index:38, ShapeLLM-Omni: A Native Multimodal LLM for 3D Generation and Understanding, https://arxiv.org/pdf/2506.01853, 2025-06-02
2025-11-09 20:45:46,311 - INFO - root - Page:2, Index:39, Movable Antenna Enhanced Federated Fine-Tuning of Large Language Models via Hybrid Client Selection Optimization, https://arxiv.org/pdf/2506.00011, 2025-10-26
2025-11-09 20:45:46,311 - INFO - root - Page:2, Index:40, Running Conventional Automatic Speech Recognition on Memristor Hardware: A Simulated Approach, https://arxiv.org/pdf/2505.24721, 2025-05-30
2025-11-09 20:45:46,312 - INFO - root - Page:2, Index:41, GARLIC: GAussian Representation LearnIng for spaCe partitioning, https://arxiv.org/pdf/2505.24608, 2025-10-02
2025-11-09 20:45:46,312 - INFO - root - Page:2, Index:42, AutoChemSchematic AI: Agentic Physics-Aware Automation for Chemical Manufacturing Scale-Up, https://arxiv.org/pdf/2505.24584, 2025-08-18
2025-11-09 20:45:46,312 - INFO - root - Page:2, Index:43, Model-Preserving Adaptive Rounding, https://arxiv.org/pdf/2505.22988, 2025-09-25
2025-11-09 20:45:46,312 - INFO - root - Page:2, Index:44, Highly Efficient and Effective LLMs with Multi-Boolean Architectures, https://arxiv.org/pdf/2505.22811, 2025-10-03
2025-11-09 20:45:46,314 - INFO - root - Page:2, Index:45, Pioneering 4-Bit FP Quantization for Diffusion Models: Mixup-Sign Quantization and Timestep-Aware Fine-Tuning, https://arxiv.org/pdf/2505.21591, 2025-05-27
2025-11-09 20:45:46,317 - INFO - root - Page:2, Index:46, Frequency Composition for Compressed and Domain-Adaptive Neural Networks, https://arxiv.org/pdf/2505.20890, 2025-05-27
2025-11-09 20:45:46,319 - INFO - root - Page:2, Index:47, MoPFormer: Motion-Primitive Transformer for Wearable-Sensor Activity Recognition, https://arxiv.org/pdf/2505.20744, 2025-10-27
2025-11-09 20:45:46,320 - INFO - root - Page:2, Index:48, Optimizing edge AI models on HPC systems with the edge in the loop, https://arxiv.org/pdf/2505.19995, 2025-05-26
2025-11-09 20:45:46,320 - INFO - root - Fetching page 4 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=150
2025-11-09 20:45:53,377 - INFO - root - get_all_titles_from_web 
2025-11-09 20:45:53,377 - INFO - root - Page:3, Index:0, DPASyn: Mechanism-Aware Drug Synergy Prediction via Dual Attention and Precision-Aware Quantization, https://arxiv.org/pdf/2505.19144, 2025-09-20
2025-11-09 20:45:53,377 - INFO - root - Page:3, Index:1, Reducing Storage of Pretrained Neural Networks by Rate-Constrained Quantization and Entropy Coding, https://arxiv.org/pdf/2505.18758, 2025-05-24
2025-11-09 20:45:53,380 - INFO - root - Page:3, Index:2, Beyond Discreteness: Finite-Sample Analysis of Straight-Through Estimator for Quantization, https://arxiv.org/pdf/2505.18113, 2025-05-23
2025-11-09 20:45:53,381 - INFO - root - Page:3, Index:3, Automating Versatile Time-Series Analysis with Tiny Transformers on Embedded FPGAs, https://arxiv.org/pdf/2505.17662, 2025-09-19
2025-11-09 20:45:53,382 - INFO - root - Page:3, Index:4, FPQVAR: Floating Point Quantization for Visual Autoregressive Model with FPGA Hardware Co-design, https://arxiv.org/pdf/2505.16335, 2025-05-22
2025-11-09 20:45:53,383 - INFO - root - Page:3, Index:5, Saliency-Aware Quantized Imitation Learning for Efficient Robotic Control, https://arxiv.org/pdf/2505.15304, 2025-05-30
2025-11-09 20:45:53,383 - INFO - root - Page:3, Index:6, Scaling Law for Quantization-Aware Training, https://arxiv.org/pdf/2505.14302, 2025-05-20
2025-11-09 20:45:53,387 - INFO - root - Page:3, Index:7, Automatic mixed precision for optimizing gained time with constrained loss mean-squared-error based on model partition to sequential sub-graphs, https://arxiv.org/pdf/2505.13060, 2025-05-19
2025-11-09 20:45:53,393 - INFO - root - Page:3, Index:8, Deep Unfolding with Kernel-based Quantization in MIMO Detection, https://arxiv.org/pdf/2505.12736, 2025-05-19
2025-11-09 20:45:53,396 - INFO - root - Page:3, Index:9, FedHQ: Hybrid Runtime Quantization for Federated Learning, https://arxiv.org/pdf/2505.11982, 2025-05-17
2025-11-09 20:45:53,396 - INFO - root - Page:3, Index:10, QVGen: Pushing the Limit of Quantized Video Generative Models, https://arxiv.org/pdf/2505.11497, 2025-09-27
2025-11-09 20:45:53,401 - INFO - root - Page:3, Index:11, EA-3DGS: Efficient and Adaptive 3D Gaussians with Highly Enhanced Quality for outdoor scenes, https://arxiv.org/pdf/2505.10787, 2025-05-15
2025-11-09 20:45:53,402 - INFO - root - Page:3, Index:12, ITERA-LLM: Boosting Sub-8-Bit Large Language Model Inference via Iterative Tensor Decomposition, https://arxiv.org/pdf/2505.08981, 2025-05-13
2025-11-09 20:45:53,403 - INFO - root - Page:3, Index:13, PROM: Prioritize Reduction of Multiplications Over Lower Bit-Widths for Efficient CNNs, https://arxiv.org/pdf/2505.03254, 2025-08-06
2025-11-09 20:45:53,404 - INFO - root - Page:3, Index:14, ICQuant: Index Coding enables Low-bit LLM Quantization, https://arxiv.org/pdf/2505.00850, 2025-08-24
2025-11-09 20:45:53,404 - INFO - root - Page:3, Index:15, Enhancing Ultra-Low-Bit Quantization of Large Language Models Through Saliency-Aware Partial Retraining, https://arxiv.org/pdf/2504.13932, 2025-07-30
2025-11-09 20:45:53,405 - INFO - root - Page:3, Index:16, Achieving binary weight and activation for LLMs using Post-Training Quantization, https://arxiv.org/pdf/2504.05352, 2025-06-30
2025-11-09 20:45:53,423 - INFO - root - Page:3, Index:17, Wireless Hearables With Programmable Speech AI Accelerators, https://arxiv.org/pdf/2503.18698, 2025-10-21
2025-11-09 20:45:53,424 - INFO - root - Page:3, Index:18, GranQ: Efficient Channel-wise Quantization via Vectorized Pre-Scaling for Zero-Shot QAT, https://arxiv.org/pdf/2503.18339, 2025-10-15
2025-11-09 20:45:53,425 - INFO - root - Page:3, Index:19, CompMarkGS: Robust Watermarking for Compressed 3D Gaussian Splatting, https://arxiv.org/pdf/2503.12836, 2025-09-29
2025-11-09 20:45:53,426 - INFO - root - Page:3, Index:20, AHCPTQ: Accurate and Hardware-Compatible Post-Training Quantization for Segment Anything Model, https://arxiv.org/pdf/2503.03088, 2025-07-11
2025-11-09 20:45:53,427 - INFO - root - Page:3, Index:21, Teaching Metric Distance to Discrete Autoregressive Language Models, https://arxiv.org/pdf/2503.02379, 2025-10-07
2025-11-09 20:45:53,428 - INFO - root - Page:3, Index:22, Regularization-based Framework for Quantization-, Fault- and Variability-Aware Training, https://arxiv.org/pdf/2503.01297, 2025-07-12
2025-11-09 20:45:53,428 - INFO - root - Fetching page 5 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=200
2025-11-09 20:45:59,869 - INFO - root - get_all_titles_from_web 
2025-11-09 20:45:59,869 - INFO - root - Page:4, Index:0, Investigating the Impact of Quantization Methods on the Safety and Reliability of Large Language Models, https://arxiv.org/pdf/2502.15799, 2025-06-29
2025-11-09 20:45:59,872 - INFO - root - Page:4, Index:1, Rotate, Clip, and Partition: Towards W2A4KV4 Quantization by Integrating Rotation and Learnable Non-uniform Quantizer, https://arxiv.org/pdf/2502.15779, 2025-09-01
2025-11-09 20:45:59,872 - INFO - root - Page:4, Index:2, RoSTE: An Efficient Quantization-Aware Supervised Fine-Tuning Approach for Large Language Models, https://arxiv.org/pdf/2502.09003, 2025-06-05
2025-11-09 20:45:59,873 - INFO - root - Page:4, Index:3, Spatial Degradation-Aware and Temporal Consistent Diffusion Model for Compressed Video Super-Resolution, https://arxiv.org/pdf/2502.07381, 2025-06-27
2025-11-09 20:45:59,873 - INFO - root - Page:4, Index:4, QuEST: Stable Training of LLMs with 1-Bit Weights and Activations, https://arxiv.org/pdf/2502.05003, 2025-06-10
2025-11-09 20:45:59,873 - INFO - root - Page:4, Index:5, HALO: Hadamard-Assisted Lower-Precision Optimization for LLMs, https://arxiv.org/pdf/2501.02625, 2025-11-05
2025-11-09 20:45:59,874 - INFO - root - Page:4, Index:6, TAR3D: Creating High-Quality 3D Assets via Next-Part Prediction, https://arxiv.org/pdf/2412.16919, 2025-08-08
2025-11-09 20:45:59,875 - INFO - root - Page:4, Index:7, Training Multi-Layer Binary Neural Networks With Local Binary Error Signals, https://arxiv.org/pdf/2412.00119, 2025-08-05
2025-11-09 20:45:59,876 - INFO - root - Page:4, Index:8, Scaling Large-scale GNN Training to Thousands of Processors on CPU-based Supercomputers, https://arxiv.org/pdf/2411.16025, 2025-05-26
2025-11-09 20:45:59,877 - INFO - root - Page:4, Index:9, HAFLQ: Heterogeneous Adaptive Federated LoRA Fine-tuned LLM with Quantization, https://arxiv.org/pdf/2411.06581, 2025-05-16
2025-11-09 20:45:59,877 - INFO - root - Fetching page 6 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=250
2025-11-09 20:46:06,656 - INFO - root - get_all_titles_from_web 
2025-11-09 20:46:06,657 - INFO - root - Page:5, Index:0, Gradient-Free Training of Quantized Neural Networks, https://arxiv.org/pdf/2410.09734, 2025-09-29
2025-11-09 20:46:06,657 - INFO - root - Page:5, Index:1, QT-DoG: Quantization-aware Training for Domain Generalization, https://arxiv.org/pdf/2410.06020, 2025-06-26
2025-11-09 20:46:06,657 - INFO - root - Page:5, Index:2, Constraint Guided Model Quantization of Neural Networks, https://arxiv.org/pdf/2409.20138, 2025-09-12
2025-11-09 20:46:06,657 - INFO - root - Page:5, Index:3, Accumulator-Aware Post-Training Quantization for Large Language Models, https://arxiv.org/pdf/2409.17092, 2025-07-30
2025-11-09 20:46:06,658 - INFO - root - Page:5, Index:4, DilateQuant: Accurate and Efficient Diffusion Quantization via Weight Dilation, https://arxiv.org/pdf/2409.14307, 2025-07-09
2025-11-09 20:46:06,658 - INFO - root - Page:5, Index:5, Robust Training of Neural Networks at Arbitrary Precision and Sparsity, https://arxiv.org/pdf/2409.09245, 2025-09-23
2025-11-09 20:46:06,658 - INFO - root - Page:5, Index:6, VQ-CTAP: Cross-Modal Fine-Grained Sequence Representation Learning for Speech Processing, https://arxiv.org/pdf/2408.05758, 2025-05-27
2025-11-09 20:46:06,659 - INFO - root - Page:5, Index:7, DopQ-ViT: Towards Distribution-Friendly and Outlier-Aware Post-Training Quantization for Vision Transformers, https://arxiv.org/pdf/2408.03291, 2025-06-19
2025-11-09 20:46:06,659 - INFO - root - Page:5, Index:8, Temporal Feature Matters: A Framework for Diffusion Model Quantization, https://arxiv.org/pdf/2407.19547, 2025-07-11
2025-11-09 20:46:06,659 - INFO - root - Page:5, Index:9, EfficientQAT: Efficient Quantization-Aware Training for Large Language Models, https://arxiv.org/pdf/2407.11062, 2025-05-19
2025-11-09 20:46:06,660 - INFO - root - Page:5, Index:10, Integer-only Quantized Transformers for Embedded FPGA-based Time-series Forecasting in AIoT, https://arxiv.org/pdf/2407.11041, 2025-10-31
2025-11-09 20:46:06,661 - INFO - root - Fetching page 7 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=300
2025-11-09 20:46:14,365 - INFO - root - get_all_titles_from_web 
2025-11-09 20:46:14,365 - INFO - root - Page:6, Index:0, BoA: Attention-aware Post-training Quantization without Backpropagation, https://arxiv.org/pdf/2406.13474, 2025-06-06
2025-11-09 20:46:14,366 - INFO - root - Page:6, Index:1, A Rescaling-Invariant Lipschitz Bound Based on Path-Metrics for Modern ReLU Network Parameterizations, https://arxiv.org/pdf/2405.15006, 2025-06-13
2025-11-09 20:46:14,366 - INFO - root - Page:6, Index:2, Scheduling Weight Transitions for Quantization-Aware Training, https://arxiv.org/pdf/2404.19248, 2025-10-01
2025-11-09 20:46:14,366 - INFO - root - Page:6, Index:3, GPTVQ: The Blessing of Dimensionality for LLM Quantization, https://arxiv.org/pdf/2402.15319, 2025-06-03
2025-11-09 20:46:14,367 - INFO - root - Fetching page 8 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=350
2025-11-09 20:46:20,769 - INFO - root - get_all_titles_from_web 
2025-11-09 20:46:20,769 - INFO - root - Page:7, Index:0, Squat: Quant Small Language Models on the Edge, https://arxiv.org/pdf/2402.10787, 2025-07-01
2025-11-09 20:46:20,770 - INFO - root - Page:7, Index:1, L4Q: Parameter Efficient Quantization-Aware Fine-Tuning on Large Language Models, https://arxiv.org/pdf/2402.04902, 2025-07-21
2025-11-09 20:46:20,770 - INFO - root - Fetching page 9 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=400
2025-11-09 20:46:27,236 - INFO - root - ------------------------------------------------------------------------------------------------------------------------
2025-11-09 20:46:27,237 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\A Quantized VAE-MLP Botnet Detection Model_ A Systematic Evaluation of Quantizat.pdf
2025-11-09 20:46:27,244 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\FP8-Flow-MoE_ A Casting-Free FP8 Recipe without Double Quantization Error.pdf
2025-11-09 20:46:27,245 - INFO - root - 跳过已处理论文 A Quantized VAE-MLP Botnet Detection Model: A Systematic Evaluation of Quantization-Aware Training and Post-Training Quantization Strategies：d:\ChatPaper\academic Papers\Quantization-Aware-Training\A Quantized VAE-MLP Botnet Detection Model_ A Systematic Evaluation of Quantizat.pdf
2025-11-09 20:46:27,246 - INFO - root - 跳过已处理论文 FP8-Flow-MoE: A Casting-Free FP8 Recipe without Double Quantization Error：d:\ChatPaper\academic Papers\Quantization-Aware-Training\FP8-Flow-MoE_ A Casting-Free FP8 Recipe without Double Quantization Error.pdf
2025-11-09 20:46:27,247 - INFO - root - summary time: 72.68 seconds
2025-11-09 20:46:45,952 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-09 20:46:45,953 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-09 20:46:45,954 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-09 20:46:46,795 - INFO - root - LLMClientManager: 指定使用客户端: DeepSeek
2025-11-09 20:46:46,796 - WARNING - root - DeepSeekClient: API key not provided. LLM disabled.
2025-11-09 20:46:46,796 - ERROR - root - LLMClientManager: 指定的客户端 DeepSeek 初始化失败
2025-11-09 20:46:46,796 - WARNING - root - LLMClientManager: 指定的客户端 DeepSeek 不可用，将尝试其他客户端
2025-11-09 20:46:47,623 - INFO - root - GeminiClient: trying model gemini-2.5-flash
2025-11-09 20:46:49,542 - INFO - root - GeminiClient: initialized model gemini-2.5-flash
2025-11-09 20:46:49,542 - INFO - root - LLMClientManager: Gemini client initialized successfully
2025-11-09 20:46:49,543 - INFO - root - LLMClientManager: using Gemini as default client
2025-11-09 20:46:49,543 - WARNING - root - KimiClient: API key not provided. LLM disabled.
2025-11-09 20:46:49,543 - WARNING - root - LLMClientManager: Kimi client initialization failed
2025-11-09 20:46:49,543 - WARNING - root - QwenClient: API key not provided. LLM disabled.
2025-11-09 20:46:49,544 - WARNING - root - LLMClientManager: Qwen client initialization failed
2025-11-09 20:46:49,544 - INFO - root - DoubaoClient: API key found: 9f9e270e-b...
2025-11-09 20:46:54,056 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 20:46:54,066 - INFO - root - DoubaoClient: initialized successfully with model doubao-seed-1-6-lite-251015
2025-11-09 20:46:54,066 - INFO - root - LLMClientManager: Doubao client initialized successfully
2025-11-09 20:46:54,068 - WARNING - root - LLMClientManager: client DeepSeek not available
2025-11-09 20:46:54,068 - WARNING - root - 无法切换到指定的客户端 DeepSeek，将使用默认客户端
2025-11-09 20:46:54,068 - INFO - root - 可用客户端: ['Gemini', 'Doubao']
2025-11-09 20:46:54,069 - INFO - root - 使用 LLM 模型: gemini-2.5-flash
2025-11-09 20:46:54,069 - INFO - root - 可用客户端: ['Gemini', 'Doubao']
2025-11-09 20:46:54,069 - INFO - root - === 运行配置 ===
2025-11-09 20:46:54,070 - INFO - root - 处理模式: arxiv在线搜索
2025-11-09 20:46:54,070 - INFO - root - 关键词: QAT
2025-11-09 20:46:54,070 - INFO - root - 查询: Quantization-Aware-Training
2025-11-09 20:46:54,070 - INFO - root - 排序: None
2025-11-09 20:46:54,071 - INFO - root - 最近天数: 180
2025-11-09 20:46:54,071 - INFO - root - 最大处理数量: 2
2025-11-09 20:46:54,071 - INFO - root - 保存图片: 是
2025-11-09 20:46:54,072 - INFO - root - 输出语言: 中文
2025-11-09 20:46:54,072 - INFO - root - 强制重新处理: 否
2025-11-09 20:46:54,072 - INFO - root - ====================
2025-11-09 20:46:54,072 - INFO - root - 使用 arXiv 搜索模式（通过 chat_arxiv 模块获取）
2025-11-09 20:46:54,073 - INFO - root - Fetching page 1 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50
2025-11-09 20:47:01,095 - INFO - root - get_all_titles_from_web 
2025-11-09 20:47:01,095 - INFO - root - Page:0, Index:0, A Quantized VAE-MLP Botnet Detection Model: A Systematic Evaluation of Quantization-Aware Training and Post-Training Quantization Strategies, https://arxiv.org/pdf/2511.03201, 2025-11-05
2025-11-09 20:47:01,096 - INFO - root - Page:0, Index:1, FP8-Flow-MoE: A Casting-Free FP8 Recipe without Double Quantization Error, https://arxiv.org/pdf/2511.02302, 2025-11-04
2025-11-09 20:47:01,096 - INFO - root - Page:0, Index:2, Outlier-Aware Post-Training Quantization for Image Super-Resolution, https://arxiv.org/pdf/2511.00682, 2025-11-01
2025-11-09 20:47:01,096 - INFO - root - Page:0, Index:3, Evaluation of Wafer-Scale SOT-MRAM for Analog Crossbar Array Applications, https://arxiv.org/pdf/2510.25853, 2025-11-03
2025-11-09 20:47:01,097 - INFO - root - Page:0, Index:4, Improving the Straight-Through Estimator with Zeroth-Order Information, https://arxiv.org/pdf/2510.23926, 2025-10-27
2025-11-09 20:47:01,097 - INFO - root - Page:0, Index:5, Real-Time Semantic Segmentation on FPGA for Autonomous Vehicles Using LMIINet with the CGRA4ML Framework, https://arxiv.org/pdf/2510.22243, 2025-10-25
2025-11-09 20:47:01,097 - INFO - root - Page:0, Index:6, TernaryCLIP: Efficiently Compressing Vision-Language Models with Ternary Weights and Distilled Knowledge, https://arxiv.org/pdf/2510.21879, 2025-10-23
2025-11-09 20:47:01,097 - INFO - root - Page:0, Index:7, KARIPAP: Quantum-Inspired Tensor Network Compression of Large Language Models Using Infinite Projected Entangled Pair States and Tensor Renormalization Group, https://arxiv.org/pdf/2510.21844, 2025-10-22
2025-11-09 20:47:01,098 - INFO - root - Page:0, Index:8, A Convergence Analysis of Adaptive Optimizers under Floating-point Quantization, https://arxiv.org/pdf/2510.21314, 2025-10-24
2025-11-09 20:47:01,099 - INFO - root - Page:0, Index:9, Adaptive Distribution-aware Quantization for Mixed-Precision Neural Networks, https://arxiv.org/pdf/2510.19760, 2025-10-22
2025-11-09 20:47:01,099 - INFO - root - Page:0, Index:10, CAGE: Curvature-Aware Gradient Estimation For Accurate Quantization-Aware Training, https://arxiv.org/pdf/2510.18784, 2025-10-21
2025-11-09 20:47:01,099 - INFO - root - Page:0, Index:11, Mixed-Precision Quantization for Language Models: Techniques and Prospects, https://arxiv.org/pdf/2510.16805, 2025-10-19
2025-11-09 20:47:01,101 - INFO - root - Page:0, Index:12, SPLite Hand: Sparsity-Aware Lightweight 3D Hand Pose Estimation, https://arxiv.org/pdf/2510.16396, 2025-10-30
2025-11-09 20:47:01,102 - INFO - root - Page:0, Index:13, CTR-LoRA: Curvature-Aware and Trust-Region Guided Low-Rank Adaptation for Large Language Models, https://arxiv.org/pdf/2510.15962, 2025-10-11
2025-11-09 20:47:01,102 - INFO - root - Page:0, Index:14, SANR: Scene-Aware Neural Representation for Light Field Image Compression with Rate-Distortion Optimization, https://arxiv.org/pdf/2510.15775, 2025-10-17
2025-11-09 20:47:01,102 - INFO - root - Page:0, Index:15, SpikeFit: Towards Optimal Deployment of Spiking Networks on Neuromorphic Hardware, https://arxiv.org/pdf/2510.15542, 2025-10-31
2025-11-09 20:47:01,103 - INFO - root - Page:0, Index:16, GRank: Towards Target-Aware and Streamlined Industrial Retrieval with a Generate-Rank Framework, https://arxiv.org/pdf/2510.15299, 2025-10-17
2025-11-09 20:47:01,103 - INFO - root - Page:0, Index:17, SaLon3R: Structure-aware Long-term Generalizable 3D Reconstruction from Unposed Images, https://arxiv.org/pdf/2510.15072, 2025-10-16
2025-11-09 20:47:01,103 - INFO - root - Page:0, Index:18, FraQAT: Quantization Aware Training with Fractional bits, https://arxiv.org/pdf/2510.14823, 2025-10-16
2025-11-09 20:47:01,104 - INFO - root - Page:0, Index:19, Computing-In-Memory Aware Model Adaption For Edge Devices, https://arxiv.org/pdf/2510.14379, 2025-10-16
2025-11-09 20:47:01,104 - INFO - root - Page:0, Index:20, Invited Paper: BitMedViT: Ternary-Quantized Vision Transformer for Medical AI Assistants on the Edge, https://arxiv.org/pdf/2510.13760, 2025-11-04
2025-11-09 20:47:01,104 - INFO - root - Page:0, Index:21, NeuroRVQ: Multi-Scale EEG Tokenization for Generative Large Brainwave Models, https://arxiv.org/pdf/2510.13068, 2025-10-14
2025-11-09 20:47:01,105 - INFO - root - Page:0, Index:22, Detect Anything via Next Point Prediction, https://arxiv.org/pdf/2510.12798, 2025-10-14
2025-11-09 20:47:01,105 - INFO - root - Page:0, Index:23, AndesVL Technical Report: An Efficient Mobile-side Multimodal Large Language Model, https://arxiv.org/pdf/2510.11496, 2025-10-14
2025-11-09 20:47:01,105 - INFO - root - Page:0, Index:24, Rescaling-Aware Training for Efficient Deployment of Deep Learning Models on Full-Integer Hardware, https://arxiv.org/pdf/2510.11484, 2025-10-13
2025-11-09 20:47:01,106 - INFO - root - Page:0, Index:25, SASER: Stego attacks on open-source LLMs, https://arxiv.org/pdf/2510.10486, 2025-10-12
2025-11-09 20:47:01,106 - INFO - root - Page:0, Index:26, Ultralytics YOLO Evolution: An Overview of YOLO26, YOLO11, YOLOv8 and YOLOv5 Object Detectors for Computer Vision and Pattern Recognition, https://arxiv.org/pdf/2510.09653, 2025-10-15
2025-11-09 20:47:01,106 - INFO - root - Page:0, Index:27, A Theoretically-Grounded Codebook for Digital Semantic Communications, https://arxiv.org/pdf/2510.07108, 2025-10-14
2025-11-09 20:47:01,107 - INFO - root - Page:0, Index:28, QuantDemoire: Quantization with Outlier Aware for Image Demoiréing, https://arxiv.org/pdf/2510.04066, 2025-10-05
2025-11-09 20:47:01,108 - INFO - root - Page:0, Index:29, Adaptively Sampling-Reusing-Mixing Decomposed Gradients to Speed Up Sharpness Aware Minimization, https://arxiv.org/pdf/2510.03763, 2025-10-04
2025-11-09 20:47:01,109 - INFO - root - Page:0, Index:30, Quant-dLLM: Post-Training Extreme Low-Bit Quantization for Diffusion Large Language Models, https://arxiv.org/pdf/2510.03274, 2025-09-27
2025-11-09 20:47:01,110 - INFO - root - Page:0, Index:31, PT$^2$-LLM: Post-Training Ternarization for Large Language Models, https://arxiv.org/pdf/2510.03267, 2025-09-26
2025-11-09 20:47:01,110 - INFO - root - Page:0, Index:32, Purrception: Variational Flow Matching for Vector-Quantized Image Generation, https://arxiv.org/pdf/2510.01478, 2025-10-01
2025-11-09 20:47:01,110 - INFO - root - Page:0, Index:33, Post-Training Quantization for Audio Diffusion Transformers, https://arxiv.org/pdf/2510.00313, 2025-09-30
2025-11-09 20:47:01,111 - INFO - root - Page:0, Index:34, Rethinking RoPE Scaling in Quantized LLM: Theory, Outlier, and Channel-Band Analysis with Weight Rescaling, https://arxiv.org/pdf/2510.00028, 2025-09-25
2025-11-09 20:47:01,111 - INFO - root - Page:0, Index:35, Post-Training Quantization via Residual Truncation and Zero Suppression for Diffusion Models, https://arxiv.org/pdf/2509.26436, 2025-09-30
2025-11-09 20:47:01,111 - INFO - root - Page:0, Index:36, Cat: Post-Training Quantization Error Reduction via Cluster-based Affine Transformation, https://arxiv.org/pdf/2509.26277, 2025-10-07
2025-11-09 20:47:01,112 - INFO - root - Page:0, Index:37, CAST: Continuous and Differentiable Semi-Structured Sparsity-Aware Training for Large Language Models, https://arxiv.org/pdf/2509.25996, 2025-09-30
2025-11-09 20:47:01,112 - INFO - root - Page:0, Index:38, Norm-Q: Effective Compression Method for Hidden Markov Models in Neuro-Symbolic Applications, https://arxiv.org/pdf/2509.25439, 2025-09-29
2025-11-09 20:47:01,112 - INFO - root - Page:0, Index:39, On-the-Fly Adaptation to Quantization: Configuration-Aware LoRA for Efficient Fine-Tuning of Quantized LLMs, https://arxiv.org/pdf/2509.25214, 2025-09-22
2025-11-09 20:47:01,114 - INFO - root - Page:0, Index:40, VoxCPM: Tokenizer-Free TTS for Context-Aware Speech Generation and True-to-Life Voice Cloning, https://arxiv.org/pdf/2509.24650, 2025-09-29
2025-11-09 20:47:01,114 - INFO - root - Page:0, Index:41, S$^2$NN: Sub-bit Spiking Neural Networks, https://arxiv.org/pdf/2509.24266, 2025-10-24
2025-11-09 20:47:01,114 - INFO - root - Page:0, Index:42, Tequila: Trapping-free Ternary Quantization for Large Language Models, https://arxiv.org/pdf/2509.23809, 2025-10-17
2025-11-09 20:47:01,114 - INFO - root - Page:0, Index:43, Texture Vector-Quantization and Reconstruction Aware Prediction for Generative Super-Resolution, https://arxiv.org/pdf/2509.23774, 2025-09-30
2025-11-09 20:47:01,116 - INFO - root - Page:0, Index:44, RobuQ: Pushing DiTs to W1.58A2 via Robust Activation Quantization, https://arxiv.org/pdf/2509.23582, 2025-09-27
2025-11-09 20:47:01,117 - INFO - root - Page:0, Index:45, Beyond Outliers: A Study of Optimizers Under Quantization, https://arxiv.org/pdf/2509.23500, 2025-10-02
2025-11-09 20:47:01,117 - INFO - root - Page:0, Index:46, Compute-Optimal Quantization-Aware Training, https://arxiv.org/pdf/2509.22935, 2025-09-26
2025-11-09 20:47:01,117 - INFO - root - Page:0, Index:47, COSPADI: Compressing LLMs via Calibration-Guided Sparse Dictionary Learning, https://arxiv.org/pdf/2509.22075, 2025-10-06
2025-11-09 20:47:01,117 - INFO - root - Page:0, Index:48, SlimDiff: Training-Free, Activation-Guided Hands-free Slimming of Diffusion Models, https://arxiv.org/pdf/2509.21498, 2025-09-25
2025-11-09 20:47:01,119 - INFO - root - Page:0, Index:49, Quantized Visual Geometry Grounded Transformer, https://arxiv.org/pdf/2509.21302, 2025-09-29
2025-11-09 20:47:01,119 - INFO - root - Fetching page 2 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=50
2025-11-09 20:47:07,965 - INFO - root - get_all_titles_from_web 
2025-11-09 20:47:07,965 - INFO - root - Page:1, Index:0, Can Less Precise Be More Reliable? A Systematic Evaluation of Quantization's Impact on CLIP Beyond Accuracy, https://arxiv.org/pdf/2509.21173, 2025-10-27
2025-11-09 20:47:07,967 - INFO - root - Page:1, Index:1, Punching Above Precision: Small Quantized Model Distillation with Learnable Regularizer, https://arxiv.org/pdf/2509.20854, 2025-09-25
2025-11-09 20:47:07,967 - INFO - root - Page:1, Index:2, TinyEcoWeedNet: Edge Efficient Real-Time Aerial Agricultural Weed Detection, https://arxiv.org/pdf/2509.18193, 2025-09-19
2025-11-09 20:47:07,967 - INFO - root - Page:1, Index:3, SBVR: Summation of BitVector Representation for Efficient LLM Quantization, https://arxiv.org/pdf/2509.18172, 2025-09-17
2025-11-09 20:47:07,967 - INFO - root - Page:1, Index:4, QWHA: Quantization-Aware Walsh-Hadamard Adaptation for Parameter-Efficient Fine-Tuning on Large Language Models, https://arxiv.org/pdf/2509.17428, 2025-09-26
2025-11-09 20:47:07,968 - INFO - root - Page:1, Index:5, PTQTP: Post-Training Quantization to Trit-Planes for Large Language Models, https://arxiv.org/pdf/2509.16989, 2025-10-28
2025-11-09 20:47:07,968 - INFO - root - Page:1, Index:6, MEC-Quant: Maximum Entropy Coding for Extremely Low Bit Quantization-Aware Training, https://arxiv.org/pdf/2509.15514, 2025-09-18
2025-11-09 20:47:07,968 - INFO - root - Page:1, Index:7, Q-ROAR: Outlier-Aware Rescaling for RoPE Position Interpolation in Quantized Long-Context LLMs, https://arxiv.org/pdf/2509.14391, 2025-09-17
2025-11-09 20:47:07,969 - INFO - root - Page:1, Index:8, Efficient Quantization-Aware Neural Receivers: Beyond Post-Training Quantization, https://arxiv.org/pdf/2509.13786, 2025-09-19
2025-11-09 20:47:07,969 - INFO - root - Page:1, Index:9, Rate-Distortion Limits for Multimodal Retrieval: Theory, Optimal Codes, and Finite-Sample Guarantees, https://arxiv.org/pdf/2509.11054, 2025-09-13
2025-11-09 20:47:07,969 - INFO - root - Page:1, Index:10, SQAP-VLA: A Synergistic Quantization-Aware Pruning Framework for High-Performance Vision-Language-Action Models, https://arxiv.org/pdf/2509.09090, 2025-09-10
2025-11-09 20:47:07,970 - INFO - root - Page:1, Index:11, CSI Compression Beyond Latents: End-to-End Hybrid Attention-CNN Networks with Entropy Regularization, https://arxiv.org/pdf/2509.08776, 2025-09-10
2025-11-09 20:47:07,970 - INFO - root - Page:1, Index:12, Explaining How Quantization Disparately Skews a Model, https://arxiv.org/pdf/2509.07222, 2025-09-08
2025-11-09 20:47:07,970 - INFO - root - Page:1, Index:13, LoaQ: Layer-wise Output Approximation Quantization, https://arxiv.org/pdf/2509.06297, 2025-09-07
2025-11-09 20:47:07,970 - INFO - root - Page:1, Index:14, FineServe: Precision-Aware KV Slab and Two-Level Scheduling for Heterogeneous Precision LLM Serving, https://arxiv.org/pdf/2509.06261, 2025-09-14
2025-11-09 20:47:07,971 - INFO - root - Page:1, Index:15, Sensitivity-Aware Post-Training Quantization for Deep Neural Networks, https://arxiv.org/pdf/2509.05576, 2025-09-05
2025-11-09 20:47:07,971 - INFO - root - Page:1, Index:16, SuperSNN: A Hardware-Aware Framework for Physically Realizable, High-Performance Superconducting Spiking Neural Network Chips, https://arxiv.org/pdf/2509.05532, 2025-09-05
2025-11-09 20:47:07,973 - INFO - root - Page:1, Index:17, Data-Augmented Quantization-Aware Knowledge Distillation, https://arxiv.org/pdf/2509.03850, 2025-09-03
2025-11-09 20:47:07,975 - INFO - root - Page:1, Index:18, DPQuant: Efficient and Differentially-Private Model Training via Dynamic Quantization Scheduling, https://arxiv.org/pdf/2509.03472, 2025-09-03
2025-11-09 20:47:07,976 - INFO - root - Page:1, Index:19, Empowering Large Language Model for Sequential Recommendation via Multimodal Embeddings and Semantic IDs, https://arxiv.org/pdf/2509.02017, 2025-09-02
2025-11-09 20:47:07,977 - INFO - root - Page:1, Index:20, Q-Sched: Pushing the Boundaries of Few-Step Diffusion Models with Quantization-Aware Scheduling, https://arxiv.org/pdf/2509.01624, 2025-09-01
2025-11-09 20:47:07,977 - INFO - root - Page:1, Index:21, Quantization Meets OOD: Generalizable Quantization-aware Training from a Flatness Perspective, https://arxiv.org/pdf/2509.00859, 2025-08-31
2025-11-09 20:47:07,978 - INFO - root - Page:1, Index:22, Progressive Element-wise Gradient Estimation for Neural Network Quantization, https://arxiv.org/pdf/2509.00097, 2025-08-27
2025-11-09 20:47:07,978 - INFO - root - Page:1, Index:23, End-to-End On-Device Quantization-Aware Training for LLMs at Inference Cost, https://arxiv.org/pdf/2509.00031, 2025-09-29
2025-11-09 20:47:07,978 - INFO - root - Page:1, Index:24, Quantization Robustness to Input Degradations for Object Detection, https://arxiv.org/pdf/2508.19600, 2025-08-27
2025-11-09 20:47:07,978 - INFO - root - Page:1, Index:25, Scaling Laws for Task-Stratified Knowledge in Post-Training Quantized Large Language Models, https://arxiv.org/pdf/2508.18609, 2025-08-27
2025-11-09 20:47:07,979 - INFO - root - Page:1, Index:26, AQ-PCDSys: An Adaptive Quantized Planetary Crater Detection System for Autonomous Space Exploration, https://arxiv.org/pdf/2508.18025, 2025-08-25
2025-11-09 20:47:07,979 - INFO - root - Page:1, Index:27, TaDiCodec: Text-aware Diffusion Speech Tokenizer for Speech Language Modeling, https://arxiv.org/pdf/2508.16790, 2025-08-22
2025-11-09 20:47:07,979 - INFO - root - Page:1, Index:28, A Node-Aware Dynamic Quantization Approach for Graph Collaborative Filtering, https://arxiv.org/pdf/2508.16516, 2025-08-22
2025-11-09 20:47:07,979 - INFO - root - Page:1, Index:29, JEDI-linear: Fast and Efficient Graph Neural Networks for Jet Tagging on FPGAs, https://arxiv.org/pdf/2508.15468, 2025-08-21
2025-11-09 20:47:07,980 - INFO - root - Page:1, Index:30, MMQ: Multimodal Mixture-of-Quantization Tokenization for Semantic ID Generation and User Behavioral Adaptation, https://arxiv.org/pdf/2508.15281, 2025-08-21
2025-11-09 20:47:07,980 - INFO - root - Page:1, Index:31, DLLMQuant: Quantizing Diffusion-based Large Language Models, https://arxiv.org/pdf/2508.14090, 2025-08-25
2025-11-09 20:47:07,980 - INFO - root - Page:1, Index:32, Automated Energy-Aware Time-Series Model Deployment on Embedded FPGAs for Resilient Combined Sewer Overflow Management, https://arxiv.org/pdf/2508.13905, 2025-08-19
2025-11-09 20:47:07,980 - INFO - root - Page:1, Index:33, XR-NPE: High-Throughput Mixed-precision SIMD Neural Processing Engine for Extended Reality Perception Workloads, https://arxiv.org/pdf/2508.13049, 2025-08-18
2025-11-09 20:47:07,981 - INFO - root - Page:1, Index:34, Exploring Self-Supervised Audio Models for Generalized Anomalous Sound Detection, https://arxiv.org/pdf/2508.12230, 2025-08-17
2025-11-09 20:47:07,981 - INFO - root - Page:1, Index:35, TriQDef: Disrupting Semantic and Gradient Alignment to Prevent Adversarial Patch Transferability in Quantized Neural Networks, https://arxiv.org/pdf/2508.12132, 2025-08-16
2025-11-09 20:47:07,981 - INFO - root - Page:1, Index:36, Error Propagation Mechanisms and Compensation Strategies for Quantized Diffusion, https://arxiv.org/pdf/2508.12094, 2025-10-13
2025-11-09 20:47:07,983 - INFO - root - Page:1, Index:37, Extending Straight-Through Estimation for Robust Neural Networks on Analog CIM Hardware, https://arxiv.org/pdf/2508.11940, 2025-08-16
2025-11-09 20:47:07,983 - INFO - root - Page:1, Index:38, PTQAT: A Hybrid Parameter-Efficient Quantization Algorithm for 3D Perception Tasks, https://arxiv.org/pdf/2508.10557, 2025-08-15
2025-11-09 20:47:07,983 - INFO - root - Page:1, Index:39, MiCo: End-to-End Mixed Precision Neural Network Co-Exploration Framework for Edge AI, https://arxiv.org/pdf/2508.09500, 2025-08-13
2025-11-09 20:47:07,985 - INFO - root - Page:1, Index:40, SPARC: Soft Probabilistic Adaptive multi-interest Retrieval Model via Codebooks for recommender system, https://arxiv.org/pdf/2508.09090, 2025-08-12
2025-11-09 20:47:07,985 - INFO - root - Page:1, Index:41, Rethinking 1-bit Optimization Leveraging Pre-trained Large Language Models, https://arxiv.org/pdf/2508.06974, 2025-08-09
2025-11-09 20:47:07,985 - INFO - root - Page:1, Index:42, Efficient Deep Neural Receiver with Post-Training Quantization, https://arxiv.org/pdf/2508.06275, 2025-08-08
2025-11-09 20:47:07,985 - INFO - root - Page:1, Index:43, iFairy: the First 2-bit Complex LLM with All Parameters in $\{\pm1, \pm i\}$, https://arxiv.org/pdf/2508.05571, 2025-08-16
2025-11-09 20:47:07,986 - INFO - root - Page:1, Index:44, S$^2$Q-VDiT: Accurate Quantized Video Diffusion Transformer with Salient Data and Sparse Token Distillation, https://arxiv.org/pdf/2508.04016, 2025-10-27
2025-11-09 20:47:07,986 - INFO - root - Page:1, Index:45, LRQ-DiT: Log-Rotation Post-Training Quantization of Diffusion Transformers for Image and Video Generation, https://arxiv.org/pdf/2508.03485, 2025-09-23
2025-11-09 20:47:07,986 - INFO - root - Page:1, Index:46, VLMQ: Efficient Post-Training Quantization for Large Vision-Language Models via Hessian Augmentation, https://arxiv.org/pdf/2508.03351, 2025-08-05
2025-11-09 20:47:07,986 - INFO - root - Page:1, Index:47, TF-MLPNet: Tiny Real-Time Neural Speech Separation, https://arxiv.org/pdf/2508.03047, 2025-08-04
2025-11-09 20:47:07,987 - INFO - root - Page:1, Index:48, SaviorRec: Semantic-Behavior Alignment for Cold-Start Recommendation, https://arxiv.org/pdf/2508.01375, 2025-08-02
2025-11-09 20:47:07,987 - INFO - root - Page:1, Index:49, MixA-Q: Revisiting Activation Sparsity for Vision Transformers from a Mixed-Precision Quantization Perspective, https://arxiv.org/pdf/2507.19131, 2025-07-25
2025-11-09 20:47:07,989 - INFO - root - Fetching page 3 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=100
2025-11-09 20:47:14,670 - INFO - root - get_all_titles_from_web 
2025-11-09 20:47:14,670 - INFO - root - Page:2, Index:0, Enhancing Quantization-Aware Training on Edge Devices via Relative Entropy Coreset Selection and Cascaded Layer Correction, https://arxiv.org/pdf/2507.17768, 2025-07-16
2025-11-09 20:47:14,671 - INFO - root - Page:2, Index:1, SiLQ: Simple Large Language Model Quantization-Aware Training, https://arxiv.org/pdf/2507.16933, 2025-07-22
2025-11-09 20:47:14,671 - INFO - root - Page:2, Index:2, Task-Specific Zero-shot Quantization-Aware Training for Object Detection, https://arxiv.org/pdf/2507.16782, 2025-07-22
2025-11-09 20:47:14,671 - INFO - root - Page:2, Index:3, TorchAO: PyTorch-Native Training-to-Serving Model Optimization, https://arxiv.org/pdf/2507.16099, 2025-07-21
2025-11-09 20:47:14,672 - INFO - root - Page:2, Index:4, SegQuant: A Semantics-Aware and Generalizable Quantization Framework for Diffusion Models, https://arxiv.org/pdf/2507.14811, 2025-08-27
2025-11-09 20:47:14,672 - INFO - root - Page:2, Index:5, Apple Intelligence Foundation Language Models: Tech Report 2025, https://arxiv.org/pdf/2507.13575, 2025-08-27
2025-11-09 20:47:14,672 - INFO - root - Page:2, Index:6, Generative Multi-Target Cross-Domain Recommendation, https://arxiv.org/pdf/2507.12871, 2025-08-07
2025-11-09 20:47:14,672 - INFO - root - Page:2, Index:7, DAF: An Efficient End-to-End Dynamic Activation Framework for on-Device DNN Training, https://arxiv.org/pdf/2507.07149, 2025-07-09
2025-11-09 20:47:14,673 - INFO - root - Page:2, Index:8, Opto-ViT: Architecting a Near-Sensor Region of Interest-Aware Vision Transformer Accelerator with Silicon Photonics, https://arxiv.org/pdf/2507.07044, 2025-07-15
2025-11-09 20:47:14,673 - INFO - root - Page:2, Index:9, QS4D: Quantization-aware training for efficient hardware deployment of structured state-space sequential models, https://arxiv.org/pdf/2507.06079, 2025-07-08
2025-11-09 20:47:14,673 - INFO - root - Page:2, Index:10, GSVR: 2D Gaussian-based Video Representation for 800+ FPS with Hybrid Deformation Field, https://arxiv.org/pdf/2507.05594, 2025-07-07
2025-11-09 20:47:14,674 - INFO - root - Page:2, Index:11, Hita: Holistic Tokenizer for Autoregressive Image Generation, https://arxiv.org/pdf/2507.02358, 2025-07-11
2025-11-09 20:47:14,674 - INFO - root - Page:2, Index:12, QPART: Adaptive Model Quantization and Dynamic Workload Balancing for Accuracy-aware Edge Inference, https://arxiv.org/pdf/2506.23934, 2025-06-30
2025-11-09 20:47:14,674 - INFO - root - Page:2, Index:13, FedWSQ: Efficient Federated Learning with Weight Standardization and Distribution-Aware Non-Uniform Quantization, https://arxiv.org/pdf/2506.23516, 2025-07-21
2025-11-09 20:47:14,674 - INFO - root - Page:2, Index:14, Spectra 1.1: Scaling Laws and Efficient Inference for Ternary Language Models, https://arxiv.org/pdf/2506.23025, 2025-06-28
2025-11-09 20:47:14,675 - INFO - root - Page:2, Index:15, Joint Quantization and Pruning Neural Networks Approach: A Case Study on FSO Receivers, https://arxiv.org/pdf/2506.20084, 2025-06-24
2025-11-09 20:47:14,675 - INFO - root - Page:2, Index:16, Single-step Diffusion for Image Compression at Ultra-Low Bitrates, https://arxiv.org/pdf/2506.16572, 2025-09-22
2025-11-09 20:47:14,675 - INFO - root - Page:2, Index:17, LittleBit: Ultra Low-Bit Quantization via Latent Factorization, https://arxiv.org/pdf/2506.13771, 2025-10-28
2025-11-09 20:47:14,676 - INFO - root - Page:2, Index:18, MARCO: Hardware-Aware Neural Architecture Search for Edge Devices with Multi-Agent Reinforcement Learning and Conformal Prediction Filtering, https://arxiv.org/pdf/2506.13755, 2025-06-16
2025-11-09 20:47:14,676 - INFO - root - Page:2, Index:19, EAQuant: Enhancing Post-Training Quantization for MoE Models via Expert-Aware Optimization, https://arxiv.org/pdf/2506.13329, 2025-07-04
2025-11-09 20:47:14,677 - INFO - root - Page:2, Index:20, Towards Neural Audio Codec Source Parsing, https://arxiv.org/pdf/2506.12627, 2025-06-14
2025-11-09 20:47:14,677 - INFO - root - Page:2, Index:21, Quantizing Small-Scale State-Space Models for Edge AI, https://arxiv.org/pdf/2506.12480, 2025-06-14
2025-11-09 20:47:14,677 - INFO - root - Page:2, Index:22, EMLoC: Emulator-based Memory-efficient Fine-tuning with LoRA Correction, https://arxiv.org/pdf/2506.12015, 2025-06-13
2025-11-09 20:47:14,678 - INFO - root - Page:2, Index:23, Compression Aware Certified Training, https://arxiv.org/pdf/2506.11992, 2025-06-13
2025-11-09 20:47:14,678 - INFO - root - Page:2, Index:24, GPLQ: A General, Practical, and Lightning QAT Method for Vision Transformers, https://arxiv.org/pdf/2506.11784, 2025-06-13
2025-11-09 20:47:14,680 - INFO - root - Page:2, Index:25, TruncQuant: Truncation-Ready Quantization for DNNs with Flexible Weight Bit Precision, https://arxiv.org/pdf/2506.11431, 2025-06-12
2025-11-09 20:47:14,680 - INFO - root - Page:2, Index:26, EfficientQuant: An Efficient Post-Training Quantization for CNN-Transformer Hybrid Models on Edge Devices, https://arxiv.org/pdf/2506.11093, 2025-06-05
2025-11-09 20:47:14,681 - INFO - root - Page:2, Index:27, Starting Positions Matter: A Study on Better Weight Initialization for Neural Network Quantization, https://arxiv.org/pdf/2506.10463, 2025-06-12
2025-11-09 20:47:14,682 - INFO - root - Page:2, Index:28, AWP: Activation-Aware Weight Pruning and Quantization with Projected Gradient Descent, https://arxiv.org/pdf/2506.10205, 2025-06-11
2025-11-09 20:47:14,682 - INFO - root - Page:2, Index:29, Q-SAM2: Accurate Quantization for Segment Anything Model 2, https://arxiv.org/pdf/2506.09782, 2025-06-11
2025-11-09 20:47:14,682 - INFO - root - Page:2, Index:30, Unifying Block-wise PTQ and Distillation-based QAT for Progressive Quantization toward 2-bit Instruction-Tuned LLMs, https://arxiv.org/pdf/2506.09104, 2025-06-10
2025-11-09 20:47:14,683 - INFO - root - Page:2, Index:31, Implementing Keyword Spotting on the MCUX947 Microcontroller with Integrated NPU, https://arxiv.org/pdf/2506.08911, 2025-06-10
2025-11-09 20:47:14,683 - INFO - root - Page:2, Index:32, POLARON: Precision-aware On-device Learning and Adaptive Runtime-cONfigurable AI acceleration, https://arxiv.org/pdf/2506.08785, 2025-06-10
2025-11-09 20:47:14,683 - INFO - root - Page:2, Index:33, MoQAE: Mixed-Precision Quantization for Long-Context LLM Inference via Mixture of Quantization-Aware Experts, https://arxiv.org/pdf/2506.07533, 2025-06-09
2025-11-09 20:47:14,683 - INFO - root - Page:2, Index:34, BitVLA: 1-bit Vision-Language-Action Models for Robotics Manipulation, https://arxiv.org/pdf/2506.07530, 2025-06-09
2025-11-09 20:47:14,684 - INFO - root - Page:2, Index:35, RecGPT: A Foundation Model for Sequential Recommendation, https://arxiv.org/pdf/2506.06270, 2025-06-12
2025-11-09 20:47:14,687 - INFO - root - Page:2, Index:36, FPSAttention: Training-Aware FP8 and Sparsity Co-Design for Fast Video Diffusion, https://arxiv.org/pdf/2506.04648, 2025-06-05
2025-11-09 20:47:14,688 - INFO - root - Page:2, Index:37, BitTTS: Highly Compact Text-to-Speech Using 1.58-bit Quantization and Weight Indexing, https://arxiv.org/pdf/2506.03515, 2025-06-03
2025-11-09 20:47:14,689 - INFO - root - Page:2, Index:38, ShapeLLM-Omni: A Native Multimodal LLM for 3D Generation and Understanding, https://arxiv.org/pdf/2506.01853, 2025-06-02
2025-11-09 20:47:14,689 - INFO - root - Page:2, Index:39, Movable Antenna Enhanced Federated Fine-Tuning of Large Language Models via Hybrid Client Selection Optimization, https://arxiv.org/pdf/2506.00011, 2025-10-26
2025-11-09 20:47:14,690 - INFO - root - Page:2, Index:40, Running Conventional Automatic Speech Recognition on Memristor Hardware: A Simulated Approach, https://arxiv.org/pdf/2505.24721, 2025-05-30
2025-11-09 20:47:14,690 - INFO - root - Page:2, Index:41, GARLIC: GAussian Representation LearnIng for spaCe partitioning, https://arxiv.org/pdf/2505.24608, 2025-10-02
2025-11-09 20:47:14,690 - INFO - root - Page:2, Index:42, AutoChemSchematic AI: Agentic Physics-Aware Automation for Chemical Manufacturing Scale-Up, https://arxiv.org/pdf/2505.24584, 2025-08-18
2025-11-09 20:47:14,691 - INFO - root - Page:2, Index:43, Model-Preserving Adaptive Rounding, https://arxiv.org/pdf/2505.22988, 2025-09-25
2025-11-09 20:47:14,691 - INFO - root - Page:2, Index:44, Highly Efficient and Effective LLMs with Multi-Boolean Architectures, https://arxiv.org/pdf/2505.22811, 2025-10-03
2025-11-09 20:47:14,691 - INFO - root - Page:2, Index:45, Pioneering 4-Bit FP Quantization for Diffusion Models: Mixup-Sign Quantization and Timestep-Aware Fine-Tuning, https://arxiv.org/pdf/2505.21591, 2025-05-27
2025-11-09 20:47:14,692 - INFO - root - Page:2, Index:46, Frequency Composition for Compressed and Domain-Adaptive Neural Networks, https://arxiv.org/pdf/2505.20890, 2025-05-27
2025-11-09 20:47:14,693 - INFO - root - Page:2, Index:47, MoPFormer: Motion-Primitive Transformer for Wearable-Sensor Activity Recognition, https://arxiv.org/pdf/2505.20744, 2025-10-27
2025-11-09 20:47:14,693 - INFO - root - Page:2, Index:48, Optimizing edge AI models on HPC systems with the edge in the loop, https://arxiv.org/pdf/2505.19995, 2025-05-26
2025-11-09 20:47:14,694 - INFO - root - Fetching page 4 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=150
2025-11-09 20:47:21,165 - INFO - root - get_all_titles_from_web 
2025-11-09 20:47:21,165 - INFO - root - Page:3, Index:0, DPASyn: Mechanism-Aware Drug Synergy Prediction via Dual Attention and Precision-Aware Quantization, https://arxiv.org/pdf/2505.19144, 2025-09-20
2025-11-09 20:47:21,166 - INFO - root - Page:3, Index:1, Reducing Storage of Pretrained Neural Networks by Rate-Constrained Quantization and Entropy Coding, https://arxiv.org/pdf/2505.18758, 2025-05-24
2025-11-09 20:47:21,166 - INFO - root - Page:3, Index:2, Beyond Discreteness: Finite-Sample Analysis of Straight-Through Estimator for Quantization, https://arxiv.org/pdf/2505.18113, 2025-05-23
2025-11-09 20:47:21,166 - INFO - root - Page:3, Index:3, Automating Versatile Time-Series Analysis with Tiny Transformers on Embedded FPGAs, https://arxiv.org/pdf/2505.17662, 2025-09-19
2025-11-09 20:47:21,167 - INFO - root - Page:3, Index:4, FPQVAR: Floating Point Quantization for Visual Autoregressive Model with FPGA Hardware Co-design, https://arxiv.org/pdf/2505.16335, 2025-05-22
2025-11-09 20:47:21,167 - INFO - root - Page:3, Index:5, Saliency-Aware Quantized Imitation Learning for Efficient Robotic Control, https://arxiv.org/pdf/2505.15304, 2025-05-30
2025-11-09 20:47:21,167 - INFO - root - Page:3, Index:6, Scaling Law for Quantization-Aware Training, https://arxiv.org/pdf/2505.14302, 2025-05-20
2025-11-09 20:47:21,167 - INFO - root - Page:3, Index:7, Automatic mixed precision for optimizing gained time with constrained loss mean-squared-error based on model partition to sequential sub-graphs, https://arxiv.org/pdf/2505.13060, 2025-05-19
2025-11-09 20:47:21,168 - INFO - root - Page:3, Index:8, Deep Unfolding with Kernel-based Quantization in MIMO Detection, https://arxiv.org/pdf/2505.12736, 2025-05-19
2025-11-09 20:47:21,168 - INFO - root - Page:3, Index:9, FedHQ: Hybrid Runtime Quantization for Federated Learning, https://arxiv.org/pdf/2505.11982, 2025-05-17
2025-11-09 20:47:21,169 - INFO - root - Page:3, Index:10, QVGen: Pushing the Limit of Quantized Video Generative Models, https://arxiv.org/pdf/2505.11497, 2025-09-27
2025-11-09 20:47:21,169 - INFO - root - Page:3, Index:11, EA-3DGS: Efficient and Adaptive 3D Gaussians with Highly Enhanced Quality for outdoor scenes, https://arxiv.org/pdf/2505.10787, 2025-05-15
2025-11-09 20:47:21,169 - INFO - root - Page:3, Index:12, ITERA-LLM: Boosting Sub-8-Bit Large Language Model Inference via Iterative Tensor Decomposition, https://arxiv.org/pdf/2505.08981, 2025-05-13
2025-11-09 20:47:21,170 - INFO - root - Page:3, Index:13, PROM: Prioritize Reduction of Multiplications Over Lower Bit-Widths for Efficient CNNs, https://arxiv.org/pdf/2505.03254, 2025-08-06
2025-11-09 20:47:21,170 - INFO - root - Page:3, Index:14, ICQuant: Index Coding enables Low-bit LLM Quantization, https://arxiv.org/pdf/2505.00850, 2025-08-24
2025-11-09 20:47:21,170 - INFO - root - Page:3, Index:15, Enhancing Ultra-Low-Bit Quantization of Large Language Models Through Saliency-Aware Partial Retraining, https://arxiv.org/pdf/2504.13932, 2025-07-30
2025-11-09 20:47:21,171 - INFO - root - Page:3, Index:16, Achieving binary weight and activation for LLMs using Post-Training Quantization, https://arxiv.org/pdf/2504.05352, 2025-06-30
2025-11-09 20:47:21,171 - INFO - root - Page:3, Index:17, Wireless Hearables With Programmable Speech AI Accelerators, https://arxiv.org/pdf/2503.18698, 2025-10-21
2025-11-09 20:47:21,171 - INFO - root - Page:3, Index:18, GranQ: Efficient Channel-wise Quantization via Vectorized Pre-Scaling for Zero-Shot QAT, https://arxiv.org/pdf/2503.18339, 2025-10-15
2025-11-09 20:47:21,173 - INFO - root - Page:3, Index:19, CompMarkGS: Robust Watermarking for Compressed 3D Gaussian Splatting, https://arxiv.org/pdf/2503.12836, 2025-09-29
2025-11-09 20:47:21,173 - INFO - root - Page:3, Index:20, AHCPTQ: Accurate and Hardware-Compatible Post-Training Quantization for Segment Anything Model, https://arxiv.org/pdf/2503.03088, 2025-07-11
2025-11-09 20:47:21,173 - INFO - root - Page:3, Index:21, Teaching Metric Distance to Discrete Autoregressive Language Models, https://arxiv.org/pdf/2503.02379, 2025-10-07
2025-11-09 20:47:21,173 - INFO - root - Page:3, Index:22, Regularization-based Framework for Quantization-, Fault- and Variability-Aware Training, https://arxiv.org/pdf/2503.01297, 2025-07-12
2025-11-09 20:47:21,174 - INFO - root - Fetching page 5 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=200
2025-11-09 20:47:28,424 - INFO - root - get_all_titles_from_web 
2025-11-09 20:47:28,424 - INFO - root - Page:4, Index:0, Investigating the Impact of Quantization Methods on the Safety and Reliability of Large Language Models, https://arxiv.org/pdf/2502.15799, 2025-06-29
2025-11-09 20:47:28,425 - INFO - root - Page:4, Index:1, Rotate, Clip, and Partition: Towards W2A4KV4 Quantization by Integrating Rotation and Learnable Non-uniform Quantizer, https://arxiv.org/pdf/2502.15779, 2025-09-01
2025-11-09 20:47:28,425 - INFO - root - Page:4, Index:2, RoSTE: An Efficient Quantization-Aware Supervised Fine-Tuning Approach for Large Language Models, https://arxiv.org/pdf/2502.09003, 2025-06-05
2025-11-09 20:47:28,425 - INFO - root - Page:4, Index:3, Spatial Degradation-Aware and Temporal Consistent Diffusion Model for Compressed Video Super-Resolution, https://arxiv.org/pdf/2502.07381, 2025-06-27
2025-11-09 20:47:28,426 - INFO - root - Page:4, Index:4, QuEST: Stable Training of LLMs with 1-Bit Weights and Activations, https://arxiv.org/pdf/2502.05003, 2025-06-10
2025-11-09 20:47:28,426 - INFO - root - Page:4, Index:5, HALO: Hadamard-Assisted Lower-Precision Optimization for LLMs, https://arxiv.org/pdf/2501.02625, 2025-11-05
2025-11-09 20:47:28,427 - INFO - root - Page:4, Index:6, TAR3D: Creating High-Quality 3D Assets via Next-Part Prediction, https://arxiv.org/pdf/2412.16919, 2025-08-08
2025-11-09 20:47:28,427 - INFO - root - Page:4, Index:7, Training Multi-Layer Binary Neural Networks With Local Binary Error Signals, https://arxiv.org/pdf/2412.00119, 2025-08-05
2025-11-09 20:47:28,428 - INFO - root - Page:4, Index:8, Scaling Large-scale GNN Training to Thousands of Processors on CPU-based Supercomputers, https://arxiv.org/pdf/2411.16025, 2025-05-26
2025-11-09 20:47:28,428 - INFO - root - Page:4, Index:9, HAFLQ: Heterogeneous Adaptive Federated LoRA Fine-tuned LLM with Quantization, https://arxiv.org/pdf/2411.06581, 2025-05-16
2025-11-09 20:47:28,428 - INFO - root - Fetching page 6 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=250
2025-11-09 20:47:34,860 - INFO - root - get_all_titles_from_web 
2025-11-09 20:47:34,860 - INFO - root - Page:5, Index:0, Gradient-Free Training of Quantized Neural Networks, https://arxiv.org/pdf/2410.09734, 2025-09-29
2025-11-09 20:47:34,861 - INFO - root - Page:5, Index:1, QT-DoG: Quantization-aware Training for Domain Generalization, https://arxiv.org/pdf/2410.06020, 2025-06-26
2025-11-09 20:47:34,861 - INFO - root - Page:5, Index:2, Constraint Guided Model Quantization of Neural Networks, https://arxiv.org/pdf/2409.20138, 2025-09-12
2025-11-09 20:47:34,861 - INFO - root - Page:5, Index:3, Accumulator-Aware Post-Training Quantization for Large Language Models, https://arxiv.org/pdf/2409.17092, 2025-07-30
2025-11-09 20:47:34,861 - INFO - root - Page:5, Index:4, DilateQuant: Accurate and Efficient Diffusion Quantization via Weight Dilation, https://arxiv.org/pdf/2409.14307, 2025-07-09
2025-11-09 20:47:34,862 - INFO - root - Page:5, Index:5, Robust Training of Neural Networks at Arbitrary Precision and Sparsity, https://arxiv.org/pdf/2409.09245, 2025-09-23
2025-11-09 20:47:34,862 - INFO - root - Page:5, Index:6, VQ-CTAP: Cross-Modal Fine-Grained Sequence Representation Learning for Speech Processing, https://arxiv.org/pdf/2408.05758, 2025-05-27
2025-11-09 20:47:34,862 - INFO - root - Page:5, Index:7, DopQ-ViT: Towards Distribution-Friendly and Outlier-Aware Post-Training Quantization for Vision Transformers, https://arxiv.org/pdf/2408.03291, 2025-06-19
2025-11-09 20:47:34,862 - INFO - root - Page:5, Index:8, Temporal Feature Matters: A Framework for Diffusion Model Quantization, https://arxiv.org/pdf/2407.19547, 2025-07-11
2025-11-09 20:47:34,863 - INFO - root - Page:5, Index:9, EfficientQAT: Efficient Quantization-Aware Training for Large Language Models, https://arxiv.org/pdf/2407.11062, 2025-05-19
2025-11-09 20:47:34,863 - INFO - root - Page:5, Index:10, Integer-only Quantized Transformers for Embedded FPGA-based Time-series Forecasting in AIoT, https://arxiv.org/pdf/2407.11041, 2025-10-31
2025-11-09 20:47:34,863 - INFO - root - Fetching page 7 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=300
2025-11-09 20:47:41,801 - INFO - root - get_all_titles_from_web 
2025-11-09 20:47:41,801 - INFO - root - Page:6, Index:0, BoA: Attention-aware Post-training Quantization without Backpropagation, https://arxiv.org/pdf/2406.13474, 2025-06-06
2025-11-09 20:47:41,802 - INFO - root - Page:6, Index:1, A Rescaling-Invariant Lipschitz Bound Based on Path-Metrics for Modern ReLU Network Parameterizations, https://arxiv.org/pdf/2405.15006, 2025-06-13
2025-11-09 20:47:41,802 - INFO - root - Page:6, Index:2, Scheduling Weight Transitions for Quantization-Aware Training, https://arxiv.org/pdf/2404.19248, 2025-10-01
2025-11-09 20:47:41,802 - INFO - root - Page:6, Index:3, GPTVQ: The Blessing of Dimensionality for LLM Quantization, https://arxiv.org/pdf/2402.15319, 2025-06-03
2025-11-09 20:47:41,802 - INFO - root - Fetching page 8 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=350
2025-11-09 20:47:49,075 - INFO - root - get_all_titles_from_web 
2025-11-09 20:47:49,075 - INFO - root - Page:7, Index:0, Squat: Quant Small Language Models on the Edge, https://arxiv.org/pdf/2402.10787, 2025-07-01
2025-11-09 20:47:49,075 - INFO - root - Page:7, Index:1, L4Q: Parameter Efficient Quantization-Aware Fine-Tuning on Large Language Models, https://arxiv.org/pdf/2402.04902, 2025-07-21
2025-11-09 20:47:49,076 - INFO - root - Fetching page 9 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=400
2025-11-09 20:47:55,416 - INFO - root - ------------------------------------------------------------------------------------------------------------------------
2025-11-09 20:47:55,417 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\A Quantized VAE-MLP Botnet Detection Model_ A Systematic Evaluation of Quantizat.pdf
2025-11-09 20:47:55,418 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\FP8-Flow-MoE_ A Casting-Free FP8 Recipe without Double Quantization Error.pdf
2025-11-09 20:47:55,421 - INFO - root - 跳过已处理论文 A Quantized VAE-MLP Botnet Detection Model: A Systematic Evaluation of Quantization-Aware Training and Post-Training Quantization Strategies：d:\ChatPaper\academic Papers\Quantization-Aware-Training\A Quantized VAE-MLP Botnet Detection Model_ A Systematic Evaluation of Quantizat.pdf
2025-11-09 20:47:55,421 - INFO - root - 跳过已处理论文 FP8-Flow-MoE: A Casting-Free FP8 Recipe without Double Quantization Error：d:\ChatPaper\academic Papers\Quantization-Aware-Training\FP8-Flow-MoE_ A Casting-Free FP8 Recipe without Double Quantization Error.pdf
2025-11-09 20:47:55,421 - INFO - root - summary time: 69.47 seconds
2025-11-09 20:51:41,855 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-09 20:51:41,857 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-09 20:51:41,858 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-09 20:51:42,908 - INFO - root - LLMClientManager: 指定使用客户端: DeepSeek
2025-11-09 20:51:42,908 - INFO - root - DeepSeekClient: API key found: 9f9e270e-b...
2025-11-09 20:51:42,909 - INFO - root - DeepSeekClient: 使用模式: 火山引擎
2025-11-09 20:51:42,909 - INFO - root - DeepSeekClient: 模型名称: deepseek-v3-1-terminus
2025-11-09 20:51:47,545 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 20:51:47,574 - INFO - root - DeepSeekClient: initialized successfully with model deepseek-v3-1-terminus
2025-11-09 20:51:47,574 - INFO - root - LLMClientManager: DeepSeek 客户端初始化成功
2025-11-09 20:51:47,576 - INFO - root - LLMClientManager: switched to DeepSeek client
2025-11-09 20:51:47,577 - INFO - root - 已手动切换到 LLM 客户端: DeepSeek
2025-11-09 20:51:47,578 - INFO - root - 使用 LLM 模型: deepseek-v3-1-terminus
2025-11-09 20:51:47,579 - INFO - root - 可用客户端: ['DeepSeek']
2025-11-09 20:51:47,579 - INFO - root - === 运行配置 ===
2025-11-09 20:51:47,581 - INFO - root - 处理模式: arxiv在线搜索
2025-11-09 20:51:47,583 - INFO - root - 关键词: QAT
2025-11-09 20:51:47,583 - INFO - root - 查询: Quantization-Aware-Training
2025-11-09 20:51:47,583 - INFO - root - 排序: None
2025-11-09 20:51:47,584 - INFO - root - 最近天数: 180
2025-11-09 20:51:47,584 - INFO - root - 最大处理数量: 2
2025-11-09 20:51:47,584 - INFO - root - 保存图片: 是
2025-11-09 20:51:47,591 - INFO - root - 输出语言: 中文
2025-11-09 20:51:47,591 - INFO - root - 强制重新处理: 否
2025-11-09 20:51:47,591 - INFO - root - ====================
2025-11-09 20:51:47,592 - INFO - root - 使用 arXiv 搜索模式（通过 chat_arxiv 模块获取）
2025-11-09 20:51:47,592 - INFO - root - Fetching page 1 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50
2025-11-09 20:51:54,182 - INFO - root - get_all_titles_from_web 
2025-11-09 20:51:54,183 - INFO - root - Page:0, Index:0, A Quantized VAE-MLP Botnet Detection Model: A Systematic Evaluation of Quantization-Aware Training and Post-Training Quantization Strategies, https://arxiv.org/pdf/2511.03201, 2025-11-05
2025-11-09 20:51:54,183 - INFO - root - Page:0, Index:1, FP8-Flow-MoE: A Casting-Free FP8 Recipe without Double Quantization Error, https://arxiv.org/pdf/2511.02302, 2025-11-04
2025-11-09 20:51:54,183 - INFO - root - Page:0, Index:2, Outlier-Aware Post-Training Quantization for Image Super-Resolution, https://arxiv.org/pdf/2511.00682, 2025-11-01
2025-11-09 20:51:54,183 - INFO - root - Page:0, Index:3, Evaluation of Wafer-Scale SOT-MRAM for Analog Crossbar Array Applications, https://arxiv.org/pdf/2510.25853, 2025-11-03
2025-11-09 20:51:54,184 - INFO - root - Page:0, Index:4, Improving the Straight-Through Estimator with Zeroth-Order Information, https://arxiv.org/pdf/2510.23926, 2025-10-27
2025-11-09 20:51:54,184 - INFO - root - Page:0, Index:5, Real-Time Semantic Segmentation on FPGA for Autonomous Vehicles Using LMIINet with the CGRA4ML Framework, https://arxiv.org/pdf/2510.22243, 2025-10-25
2025-11-09 20:51:54,184 - INFO - root - Page:0, Index:6, TernaryCLIP: Efficiently Compressing Vision-Language Models with Ternary Weights and Distilled Knowledge, https://arxiv.org/pdf/2510.21879, 2025-10-23
2025-11-09 20:51:54,185 - INFO - root - Page:0, Index:7, KARIPAP: Quantum-Inspired Tensor Network Compression of Large Language Models Using Infinite Projected Entangled Pair States and Tensor Renormalization Group, https://arxiv.org/pdf/2510.21844, 2025-10-22
2025-11-09 20:51:54,185 - INFO - root - Page:0, Index:8, A Convergence Analysis of Adaptive Optimizers under Floating-point Quantization, https://arxiv.org/pdf/2510.21314, 2025-10-24
2025-11-09 20:51:54,185 - INFO - root - Page:0, Index:9, Adaptive Distribution-aware Quantization for Mixed-Precision Neural Networks, https://arxiv.org/pdf/2510.19760, 2025-10-22
2025-11-09 20:51:54,185 - INFO - root - Page:0, Index:10, CAGE: Curvature-Aware Gradient Estimation For Accurate Quantization-Aware Training, https://arxiv.org/pdf/2510.18784, 2025-10-21
2025-11-09 20:51:54,186 - INFO - root - Page:0, Index:11, Mixed-Precision Quantization for Language Models: Techniques and Prospects, https://arxiv.org/pdf/2510.16805, 2025-10-19
2025-11-09 20:51:54,186 - INFO - root - Page:0, Index:12, SPLite Hand: Sparsity-Aware Lightweight 3D Hand Pose Estimation, https://arxiv.org/pdf/2510.16396, 2025-10-30
2025-11-09 20:51:54,186 - INFO - root - Page:0, Index:13, CTR-LoRA: Curvature-Aware and Trust-Region Guided Low-Rank Adaptation for Large Language Models, https://arxiv.org/pdf/2510.15962, 2025-10-11
2025-11-09 20:51:54,186 - INFO - root - Page:0, Index:14, SANR: Scene-Aware Neural Representation for Light Field Image Compression with Rate-Distortion Optimization, https://arxiv.org/pdf/2510.15775, 2025-10-17
2025-11-09 20:51:54,186 - INFO - root - Page:0, Index:15, SpikeFit: Towards Optimal Deployment of Spiking Networks on Neuromorphic Hardware, https://arxiv.org/pdf/2510.15542, 2025-10-31
2025-11-09 20:51:54,187 - INFO - root - Page:0, Index:16, GRank: Towards Target-Aware and Streamlined Industrial Retrieval with a Generate-Rank Framework, https://arxiv.org/pdf/2510.15299, 2025-10-17
2025-11-09 20:51:54,187 - INFO - root - Page:0, Index:17, SaLon3R: Structure-aware Long-term Generalizable 3D Reconstruction from Unposed Images, https://arxiv.org/pdf/2510.15072, 2025-10-16
2025-11-09 20:51:54,187 - INFO - root - Page:0, Index:18, FraQAT: Quantization Aware Training with Fractional bits, https://arxiv.org/pdf/2510.14823, 2025-10-16
2025-11-09 20:51:54,188 - INFO - root - Page:0, Index:19, Computing-In-Memory Aware Model Adaption For Edge Devices, https://arxiv.org/pdf/2510.14379, 2025-10-16
2025-11-09 20:51:54,189 - INFO - root - Page:0, Index:20, Invited Paper: BitMedViT: Ternary-Quantized Vision Transformer for Medical AI Assistants on the Edge, https://arxiv.org/pdf/2510.13760, 2025-11-04
2025-11-09 20:51:54,189 - INFO - root - Page:0, Index:21, NeuroRVQ: Multi-Scale EEG Tokenization for Generative Large Brainwave Models, https://arxiv.org/pdf/2510.13068, 2025-10-14
2025-11-09 20:51:54,189 - INFO - root - Page:0, Index:22, Detect Anything via Next Point Prediction, https://arxiv.org/pdf/2510.12798, 2025-10-14
2025-11-09 20:51:54,190 - INFO - root - Page:0, Index:23, AndesVL Technical Report: An Efficient Mobile-side Multimodal Large Language Model, https://arxiv.org/pdf/2510.11496, 2025-10-14
2025-11-09 20:51:54,190 - INFO - root - Page:0, Index:24, Rescaling-Aware Training for Efficient Deployment of Deep Learning Models on Full-Integer Hardware, https://arxiv.org/pdf/2510.11484, 2025-10-13
2025-11-09 20:51:54,190 - INFO - root - Page:0, Index:25, SASER: Stego attacks on open-source LLMs, https://arxiv.org/pdf/2510.10486, 2025-10-12
2025-11-09 20:51:54,195 - INFO - root - Page:0, Index:26, Ultralytics YOLO Evolution: An Overview of YOLO26, YOLO11, YOLOv8 and YOLOv5 Object Detectors for Computer Vision and Pattern Recognition, https://arxiv.org/pdf/2510.09653, 2025-10-15
2025-11-09 20:51:54,196 - INFO - root - Page:0, Index:27, A Theoretically-Grounded Codebook for Digital Semantic Communications, https://arxiv.org/pdf/2510.07108, 2025-10-14
2025-11-09 20:51:54,198 - INFO - root - Page:0, Index:28, QuantDemoire: Quantization with Outlier Aware for Image Demoiréing, https://arxiv.org/pdf/2510.04066, 2025-10-05
2025-11-09 20:51:54,198 - INFO - root - Page:0, Index:29, Adaptively Sampling-Reusing-Mixing Decomposed Gradients to Speed Up Sharpness Aware Minimization, https://arxiv.org/pdf/2510.03763, 2025-10-04
2025-11-09 20:51:54,199 - INFO - root - Page:0, Index:30, Quant-dLLM: Post-Training Extreme Low-Bit Quantization for Diffusion Large Language Models, https://arxiv.org/pdf/2510.03274, 2025-09-27
2025-11-09 20:51:54,199 - INFO - root - Page:0, Index:31, PT$^2$-LLM: Post-Training Ternarization for Large Language Models, https://arxiv.org/pdf/2510.03267, 2025-09-26
2025-11-09 20:51:54,199 - INFO - root - Page:0, Index:32, Purrception: Variational Flow Matching for Vector-Quantized Image Generation, https://arxiv.org/pdf/2510.01478, 2025-10-01
2025-11-09 20:51:54,199 - INFO - root - Page:0, Index:33, Post-Training Quantization for Audio Diffusion Transformers, https://arxiv.org/pdf/2510.00313, 2025-09-30
2025-11-09 20:51:54,200 - INFO - root - Page:0, Index:34, Rethinking RoPE Scaling in Quantized LLM: Theory, Outlier, and Channel-Band Analysis with Weight Rescaling, https://arxiv.org/pdf/2510.00028, 2025-09-25
2025-11-09 20:51:54,200 - INFO - root - Page:0, Index:35, Post-Training Quantization via Residual Truncation and Zero Suppression for Diffusion Models, https://arxiv.org/pdf/2509.26436, 2025-09-30
2025-11-09 20:51:54,200 - INFO - root - Page:0, Index:36, Cat: Post-Training Quantization Error Reduction via Cluster-based Affine Transformation, https://arxiv.org/pdf/2509.26277, 2025-10-07
2025-11-09 20:51:54,200 - INFO - root - Page:0, Index:37, CAST: Continuous and Differentiable Semi-Structured Sparsity-Aware Training for Large Language Models, https://arxiv.org/pdf/2509.25996, 2025-09-30
2025-11-09 20:51:54,201 - INFO - root - Page:0, Index:38, Norm-Q: Effective Compression Method for Hidden Markov Models in Neuro-Symbolic Applications, https://arxiv.org/pdf/2509.25439, 2025-09-29
2025-11-09 20:51:54,201 - INFO - root - Page:0, Index:39, On-the-Fly Adaptation to Quantization: Configuration-Aware LoRA for Efficient Fine-Tuning of Quantized LLMs, https://arxiv.org/pdf/2509.25214, 2025-09-22
2025-11-09 20:51:54,201 - INFO - root - Page:0, Index:40, VoxCPM: Tokenizer-Free TTS for Context-Aware Speech Generation and True-to-Life Voice Cloning, https://arxiv.org/pdf/2509.24650, 2025-09-29
2025-11-09 20:51:54,202 - INFO - root - Page:0, Index:41, S$^2$NN: Sub-bit Spiking Neural Networks, https://arxiv.org/pdf/2509.24266, 2025-10-24
2025-11-09 20:51:54,202 - INFO - root - Page:0, Index:42, Tequila: Trapping-free Ternary Quantization for Large Language Models, https://arxiv.org/pdf/2509.23809, 2025-10-17
2025-11-09 20:51:54,202 - INFO - root - Page:0, Index:43, Texture Vector-Quantization and Reconstruction Aware Prediction for Generative Super-Resolution, https://arxiv.org/pdf/2509.23774, 2025-09-30
2025-11-09 20:51:54,203 - INFO - root - Page:0, Index:44, RobuQ: Pushing DiTs to W1.58A2 via Robust Activation Quantization, https://arxiv.org/pdf/2509.23582, 2025-09-27
2025-11-09 20:51:54,203 - INFO - root - Page:0, Index:45, Beyond Outliers: A Study of Optimizers Under Quantization, https://arxiv.org/pdf/2509.23500, 2025-10-02
2025-11-09 20:51:54,203 - INFO - root - Page:0, Index:46, Compute-Optimal Quantization-Aware Training, https://arxiv.org/pdf/2509.22935, 2025-09-26
2025-11-09 20:51:54,203 - INFO - root - Page:0, Index:47, COSPADI: Compressing LLMs via Calibration-Guided Sparse Dictionary Learning, https://arxiv.org/pdf/2509.22075, 2025-10-06
2025-11-09 20:51:54,204 - INFO - root - Page:0, Index:48, SlimDiff: Training-Free, Activation-Guided Hands-free Slimming of Diffusion Models, https://arxiv.org/pdf/2509.21498, 2025-09-25
2025-11-09 20:51:54,205 - INFO - root - Page:0, Index:49, Quantized Visual Geometry Grounded Transformer, https://arxiv.org/pdf/2509.21302, 2025-09-29
2025-11-09 20:51:54,205 - INFO - root - Fetching page 2 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=50
2025-11-09 20:52:01,885 - INFO - root - get_all_titles_from_web 
2025-11-09 20:52:01,886 - INFO - root - Page:1, Index:0, Can Less Precise Be More Reliable? A Systematic Evaluation of Quantization's Impact on CLIP Beyond Accuracy, https://arxiv.org/pdf/2509.21173, 2025-10-27
2025-11-09 20:52:01,886 - INFO - root - Page:1, Index:1, Punching Above Precision: Small Quantized Model Distillation with Learnable Regularizer, https://arxiv.org/pdf/2509.20854, 2025-09-25
2025-11-09 20:52:01,886 - INFO - root - Page:1, Index:2, TinyEcoWeedNet: Edge Efficient Real-Time Aerial Agricultural Weed Detection, https://arxiv.org/pdf/2509.18193, 2025-09-19
2025-11-09 20:52:01,886 - INFO - root - Page:1, Index:3, SBVR: Summation of BitVector Representation for Efficient LLM Quantization, https://arxiv.org/pdf/2509.18172, 2025-09-17
2025-11-09 20:52:01,888 - INFO - root - Page:1, Index:4, QWHA: Quantization-Aware Walsh-Hadamard Adaptation for Parameter-Efficient Fine-Tuning on Large Language Models, https://arxiv.org/pdf/2509.17428, 2025-09-26
2025-11-09 20:52:01,888 - INFO - root - Page:1, Index:5, PTQTP: Post-Training Quantization to Trit-Planes for Large Language Models, https://arxiv.org/pdf/2509.16989, 2025-10-28
2025-11-09 20:52:01,888 - INFO - root - Page:1, Index:6, MEC-Quant: Maximum Entropy Coding for Extremely Low Bit Quantization-Aware Training, https://arxiv.org/pdf/2509.15514, 2025-09-18
2025-11-09 20:52:01,888 - INFO - root - Page:1, Index:7, Q-ROAR: Outlier-Aware Rescaling for RoPE Position Interpolation in Quantized Long-Context LLMs, https://arxiv.org/pdf/2509.14391, 2025-09-17
2025-11-09 20:52:01,888 - INFO - root - Page:1, Index:8, Efficient Quantization-Aware Neural Receivers: Beyond Post-Training Quantization, https://arxiv.org/pdf/2509.13786, 2025-09-19
2025-11-09 20:52:01,889 - INFO - root - Page:1, Index:9, Rate-Distortion Limits for Multimodal Retrieval: Theory, Optimal Codes, and Finite-Sample Guarantees, https://arxiv.org/pdf/2509.11054, 2025-09-13
2025-11-09 20:52:01,890 - INFO - root - Page:1, Index:10, SQAP-VLA: A Synergistic Quantization-Aware Pruning Framework for High-Performance Vision-Language-Action Models, https://arxiv.org/pdf/2509.09090, 2025-09-10
2025-11-09 20:52:01,890 - INFO - root - Page:1, Index:11, CSI Compression Beyond Latents: End-to-End Hybrid Attention-CNN Networks with Entropy Regularization, https://arxiv.org/pdf/2509.08776, 2025-09-10
2025-11-09 20:52:01,890 - INFO - root - Page:1, Index:12, Explaining How Quantization Disparately Skews a Model, https://arxiv.org/pdf/2509.07222, 2025-09-08
2025-11-09 20:52:01,890 - INFO - root - Page:1, Index:13, LoaQ: Layer-wise Output Approximation Quantization, https://arxiv.org/pdf/2509.06297, 2025-09-07
2025-11-09 20:52:01,891 - INFO - root - Page:1, Index:14, FineServe: Precision-Aware KV Slab and Two-Level Scheduling for Heterogeneous Precision LLM Serving, https://arxiv.org/pdf/2509.06261, 2025-09-14
2025-11-09 20:52:01,891 - INFO - root - Page:1, Index:15, Sensitivity-Aware Post-Training Quantization for Deep Neural Networks, https://arxiv.org/pdf/2509.05576, 2025-09-05
2025-11-09 20:52:01,892 - INFO - root - Page:1, Index:16, SuperSNN: A Hardware-Aware Framework for Physically Realizable, High-Performance Superconducting Spiking Neural Network Chips, https://arxiv.org/pdf/2509.05532, 2025-09-05
2025-11-09 20:52:01,892 - INFO - root - Page:1, Index:17, Data-Augmented Quantization-Aware Knowledge Distillation, https://arxiv.org/pdf/2509.03850, 2025-09-03
2025-11-09 20:52:01,893 - INFO - root - Page:1, Index:18, DPQuant: Efficient and Differentially-Private Model Training via Dynamic Quantization Scheduling, https://arxiv.org/pdf/2509.03472, 2025-09-03
2025-11-09 20:52:01,893 - INFO - root - Page:1, Index:19, Empowering Large Language Model for Sequential Recommendation via Multimodal Embeddings and Semantic IDs, https://arxiv.org/pdf/2509.02017, 2025-09-02
2025-11-09 20:52:01,893 - INFO - root - Page:1, Index:20, Q-Sched: Pushing the Boundaries of Few-Step Diffusion Models with Quantization-Aware Scheduling, https://arxiv.org/pdf/2509.01624, 2025-09-01
2025-11-09 20:52:01,893 - INFO - root - Page:1, Index:21, Quantization Meets OOD: Generalizable Quantization-aware Training from a Flatness Perspective, https://arxiv.org/pdf/2509.00859, 2025-08-31
2025-11-09 20:52:01,894 - INFO - root - Page:1, Index:22, Progressive Element-wise Gradient Estimation for Neural Network Quantization, https://arxiv.org/pdf/2509.00097, 2025-08-27
2025-11-09 20:52:01,894 - INFO - root - Page:1, Index:23, End-to-End On-Device Quantization-Aware Training for LLMs at Inference Cost, https://arxiv.org/pdf/2509.00031, 2025-09-29
2025-11-09 20:52:01,894 - INFO - root - Page:1, Index:24, Quantization Robustness to Input Degradations for Object Detection, https://arxiv.org/pdf/2508.19600, 2025-08-27
2025-11-09 20:52:01,894 - INFO - root - Page:1, Index:25, Scaling Laws for Task-Stratified Knowledge in Post-Training Quantized Large Language Models, https://arxiv.org/pdf/2508.18609, 2025-08-27
2025-11-09 20:52:01,896 - INFO - root - Page:1, Index:26, AQ-PCDSys: An Adaptive Quantized Planetary Crater Detection System for Autonomous Space Exploration, https://arxiv.org/pdf/2508.18025, 2025-08-25
2025-11-09 20:52:01,896 - INFO - root - Page:1, Index:27, TaDiCodec: Text-aware Diffusion Speech Tokenizer for Speech Language Modeling, https://arxiv.org/pdf/2508.16790, 2025-08-22
2025-11-09 20:52:01,896 - INFO - root - Page:1, Index:28, A Node-Aware Dynamic Quantization Approach for Graph Collaborative Filtering, https://arxiv.org/pdf/2508.16516, 2025-08-22
2025-11-09 20:52:01,897 - INFO - root - Page:1, Index:29, JEDI-linear: Fast and Efficient Graph Neural Networks for Jet Tagging on FPGAs, https://arxiv.org/pdf/2508.15468, 2025-08-21
2025-11-09 20:52:01,897 - INFO - root - Page:1, Index:30, MMQ: Multimodal Mixture-of-Quantization Tokenization for Semantic ID Generation and User Behavioral Adaptation, https://arxiv.org/pdf/2508.15281, 2025-08-21
2025-11-09 20:52:01,897 - INFO - root - Page:1, Index:31, DLLMQuant: Quantizing Diffusion-based Large Language Models, https://arxiv.org/pdf/2508.14090, 2025-08-25
2025-11-09 20:52:01,897 - INFO - root - Page:1, Index:32, Automated Energy-Aware Time-Series Model Deployment on Embedded FPGAs for Resilient Combined Sewer Overflow Management, https://arxiv.org/pdf/2508.13905, 2025-08-19
2025-11-09 20:52:01,909 - INFO - root - Page:1, Index:33, XR-NPE: High-Throughput Mixed-precision SIMD Neural Processing Engine for Extended Reality Perception Workloads, https://arxiv.org/pdf/2508.13049, 2025-08-18
2025-11-09 20:52:01,909 - INFO - root - Page:1, Index:34, Exploring Self-Supervised Audio Models for Generalized Anomalous Sound Detection, https://arxiv.org/pdf/2508.12230, 2025-08-17
2025-11-09 20:52:01,910 - INFO - root - Page:1, Index:35, TriQDef: Disrupting Semantic and Gradient Alignment to Prevent Adversarial Patch Transferability in Quantized Neural Networks, https://arxiv.org/pdf/2508.12132, 2025-08-16
2025-11-09 20:52:01,911 - INFO - root - Page:1, Index:36, Error Propagation Mechanisms and Compensation Strategies for Quantized Diffusion, https://arxiv.org/pdf/2508.12094, 2025-10-13
2025-11-09 20:52:01,912 - INFO - root - Page:1, Index:37, Extending Straight-Through Estimation for Robust Neural Networks on Analog CIM Hardware, https://arxiv.org/pdf/2508.11940, 2025-08-16
2025-11-09 20:52:01,912 - INFO - root - Page:1, Index:38, PTQAT: A Hybrid Parameter-Efficient Quantization Algorithm for 3D Perception Tasks, https://arxiv.org/pdf/2508.10557, 2025-08-15
2025-11-09 20:52:01,912 - INFO - root - Page:1, Index:39, MiCo: End-to-End Mixed Precision Neural Network Co-Exploration Framework for Edge AI, https://arxiv.org/pdf/2508.09500, 2025-08-13
2025-11-09 20:52:01,912 - INFO - root - Page:1, Index:40, SPARC: Soft Probabilistic Adaptive multi-interest Retrieval Model via Codebooks for recommender system, https://arxiv.org/pdf/2508.09090, 2025-08-12
2025-11-09 20:52:01,914 - INFO - root - Page:1, Index:41, Rethinking 1-bit Optimization Leveraging Pre-trained Large Language Models, https://arxiv.org/pdf/2508.06974, 2025-08-09
2025-11-09 20:52:01,915 - INFO - root - Page:1, Index:42, Efficient Deep Neural Receiver with Post-Training Quantization, https://arxiv.org/pdf/2508.06275, 2025-08-08
2025-11-09 20:52:01,915 - INFO - root - Page:1, Index:43, iFairy: the First 2-bit Complex LLM with All Parameters in $\{\pm1, \pm i\}$, https://arxiv.org/pdf/2508.05571, 2025-08-16
2025-11-09 20:52:01,915 - INFO - root - Page:1, Index:44, S$^2$Q-VDiT: Accurate Quantized Video Diffusion Transformer with Salient Data and Sparse Token Distillation, https://arxiv.org/pdf/2508.04016, 2025-10-27
2025-11-09 20:52:01,920 - INFO - root - Page:1, Index:45, LRQ-DiT: Log-Rotation Post-Training Quantization of Diffusion Transformers for Image and Video Generation, https://arxiv.org/pdf/2508.03485, 2025-09-23
2025-11-09 20:52:01,920 - INFO - root - Page:1, Index:46, VLMQ: Efficient Post-Training Quantization for Large Vision-Language Models via Hessian Augmentation, https://arxiv.org/pdf/2508.03351, 2025-08-05
2025-11-09 20:52:01,920 - INFO - root - Page:1, Index:47, TF-MLPNet: Tiny Real-Time Neural Speech Separation, https://arxiv.org/pdf/2508.03047, 2025-08-04
2025-11-09 20:52:01,922 - INFO - root - Page:1, Index:48, SaviorRec: Semantic-Behavior Alignment for Cold-Start Recommendation, https://arxiv.org/pdf/2508.01375, 2025-08-02
2025-11-09 20:52:01,922 - INFO - root - Page:1, Index:49, MixA-Q: Revisiting Activation Sparsity for Vision Transformers from a Mixed-Precision Quantization Perspective, https://arxiv.org/pdf/2507.19131, 2025-07-25
2025-11-09 20:52:01,923 - INFO - root - Fetching page 3 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=100
2025-11-09 20:52:08,418 - INFO - root - get_all_titles_from_web 
2025-11-09 20:52:08,418 - INFO - root - Page:2, Index:0, Enhancing Quantization-Aware Training on Edge Devices via Relative Entropy Coreset Selection and Cascaded Layer Correction, https://arxiv.org/pdf/2507.17768, 2025-07-16
2025-11-09 20:52:08,419 - INFO - root - Page:2, Index:1, SiLQ: Simple Large Language Model Quantization-Aware Training, https://arxiv.org/pdf/2507.16933, 2025-07-22
2025-11-09 20:52:08,419 - INFO - root - Page:2, Index:2, Task-Specific Zero-shot Quantization-Aware Training for Object Detection, https://arxiv.org/pdf/2507.16782, 2025-07-22
2025-11-09 20:52:08,419 - INFO - root - Page:2, Index:3, TorchAO: PyTorch-Native Training-to-Serving Model Optimization, https://arxiv.org/pdf/2507.16099, 2025-07-21
2025-11-09 20:52:08,420 - INFO - root - Page:2, Index:4, SegQuant: A Semantics-Aware and Generalizable Quantization Framework for Diffusion Models, https://arxiv.org/pdf/2507.14811, 2025-08-27
2025-11-09 20:52:08,420 - INFO - root - Page:2, Index:5, Apple Intelligence Foundation Language Models: Tech Report 2025, https://arxiv.org/pdf/2507.13575, 2025-08-27
2025-11-09 20:52:08,420 - INFO - root - Page:2, Index:6, Generative Multi-Target Cross-Domain Recommendation, https://arxiv.org/pdf/2507.12871, 2025-08-07
2025-11-09 20:52:08,420 - INFO - root - Page:2, Index:7, DAF: An Efficient End-to-End Dynamic Activation Framework for on-Device DNN Training, https://arxiv.org/pdf/2507.07149, 2025-07-09
2025-11-09 20:52:08,422 - INFO - root - Page:2, Index:8, Opto-ViT: Architecting a Near-Sensor Region of Interest-Aware Vision Transformer Accelerator with Silicon Photonics, https://arxiv.org/pdf/2507.07044, 2025-07-15
2025-11-09 20:52:08,423 - INFO - root - Page:2, Index:9, QS4D: Quantization-aware training for efficient hardware deployment of structured state-space sequential models, https://arxiv.org/pdf/2507.06079, 2025-07-08
2025-11-09 20:52:08,423 - INFO - root - Page:2, Index:10, GSVR: 2D Gaussian-based Video Representation for 800+ FPS with Hybrid Deformation Field, https://arxiv.org/pdf/2507.05594, 2025-07-07
2025-11-09 20:52:08,425 - INFO - root - Page:2, Index:11, Hita: Holistic Tokenizer for Autoregressive Image Generation, https://arxiv.org/pdf/2507.02358, 2025-07-11
2025-11-09 20:52:08,425 - INFO - root - Page:2, Index:12, QPART: Adaptive Model Quantization and Dynamic Workload Balancing for Accuracy-aware Edge Inference, https://arxiv.org/pdf/2506.23934, 2025-06-30
2025-11-09 20:52:08,426 - INFO - root - Page:2, Index:13, FedWSQ: Efficient Federated Learning with Weight Standardization and Distribution-Aware Non-Uniform Quantization, https://arxiv.org/pdf/2506.23516, 2025-07-21
2025-11-09 20:52:08,426 - INFO - root - Page:2, Index:14, Spectra 1.1: Scaling Laws and Efficient Inference for Ternary Language Models, https://arxiv.org/pdf/2506.23025, 2025-06-28
2025-11-09 20:52:08,426 - INFO - root - Page:2, Index:15, Joint Quantization and Pruning Neural Networks Approach: A Case Study on FSO Receivers, https://arxiv.org/pdf/2506.20084, 2025-06-24
2025-11-09 20:52:08,427 - INFO - root - Page:2, Index:16, Single-step Diffusion for Image Compression at Ultra-Low Bitrates, https://arxiv.org/pdf/2506.16572, 2025-09-22
2025-11-09 20:52:08,427 - INFO - root - Page:2, Index:17, LittleBit: Ultra Low-Bit Quantization via Latent Factorization, https://arxiv.org/pdf/2506.13771, 2025-10-28
2025-11-09 20:52:08,427 - INFO - root - Page:2, Index:18, MARCO: Hardware-Aware Neural Architecture Search for Edge Devices with Multi-Agent Reinforcement Learning and Conformal Prediction Filtering, https://arxiv.org/pdf/2506.13755, 2025-06-16
2025-11-09 20:52:08,427 - INFO - root - Page:2, Index:19, EAQuant: Enhancing Post-Training Quantization for MoE Models via Expert-Aware Optimization, https://arxiv.org/pdf/2506.13329, 2025-07-04
2025-11-09 20:52:08,427 - INFO - root - Page:2, Index:20, Towards Neural Audio Codec Source Parsing, https://arxiv.org/pdf/2506.12627, 2025-06-14
2025-11-09 20:52:08,429 - INFO - root - Page:2, Index:21, Quantizing Small-Scale State-Space Models for Edge AI, https://arxiv.org/pdf/2506.12480, 2025-06-14
2025-11-09 20:52:08,429 - INFO - root - Page:2, Index:22, EMLoC: Emulator-based Memory-efficient Fine-tuning with LoRA Correction, https://arxiv.org/pdf/2506.12015, 2025-06-13
2025-11-09 20:52:08,429 - INFO - root - Page:2, Index:23, Compression Aware Certified Training, https://arxiv.org/pdf/2506.11992, 2025-06-13
2025-11-09 20:52:08,430 - INFO - root - Page:2, Index:24, GPLQ: A General, Practical, and Lightning QAT Method for Vision Transformers, https://arxiv.org/pdf/2506.11784, 2025-06-13
2025-11-09 20:52:08,430 - INFO - root - Page:2, Index:25, TruncQuant: Truncation-Ready Quantization for DNNs with Flexible Weight Bit Precision, https://arxiv.org/pdf/2506.11431, 2025-06-12
2025-11-09 20:52:08,431 - INFO - root - Page:2, Index:26, EfficientQuant: An Efficient Post-Training Quantization for CNN-Transformer Hybrid Models on Edge Devices, https://arxiv.org/pdf/2506.11093, 2025-06-05
2025-11-09 20:52:08,431 - INFO - root - Page:2, Index:27, Starting Positions Matter: A Study on Better Weight Initialization for Neural Network Quantization, https://arxiv.org/pdf/2506.10463, 2025-06-12
2025-11-09 20:52:08,431 - INFO - root - Page:2, Index:28, AWP: Activation-Aware Weight Pruning and Quantization with Projected Gradient Descent, https://arxiv.org/pdf/2506.10205, 2025-06-11
2025-11-09 20:52:08,431 - INFO - root - Page:2, Index:29, Q-SAM2: Accurate Quantization for Segment Anything Model 2, https://arxiv.org/pdf/2506.09782, 2025-06-11
2025-11-09 20:52:08,432 - INFO - root - Page:2, Index:30, Unifying Block-wise PTQ and Distillation-based QAT for Progressive Quantization toward 2-bit Instruction-Tuned LLMs, https://arxiv.org/pdf/2506.09104, 2025-06-10
2025-11-09 20:52:08,432 - INFO - root - Page:2, Index:31, Implementing Keyword Spotting on the MCUX947 Microcontroller with Integrated NPU, https://arxiv.org/pdf/2506.08911, 2025-06-10
2025-11-09 20:52:08,432 - INFO - root - Page:2, Index:32, POLARON: Precision-aware On-device Learning and Adaptive Runtime-cONfigurable AI acceleration, https://arxiv.org/pdf/2506.08785, 2025-06-10
2025-11-09 20:52:08,433 - INFO - root - Page:2, Index:33, MoQAE: Mixed-Precision Quantization for Long-Context LLM Inference via Mixture of Quantization-Aware Experts, https://arxiv.org/pdf/2506.07533, 2025-06-09
2025-11-09 20:52:08,433 - INFO - root - Page:2, Index:34, BitVLA: 1-bit Vision-Language-Action Models for Robotics Manipulation, https://arxiv.org/pdf/2506.07530, 2025-06-09
2025-11-09 20:52:08,433 - INFO - root - Page:2, Index:35, RecGPT: A Foundation Model for Sequential Recommendation, https://arxiv.org/pdf/2506.06270, 2025-06-12
2025-11-09 20:52:08,433 - INFO - root - Page:2, Index:36, FPSAttention: Training-Aware FP8 and Sparsity Co-Design for Fast Video Diffusion, https://arxiv.org/pdf/2506.04648, 2025-06-05
2025-11-09 20:52:08,434 - INFO - root - Page:2, Index:37, BitTTS: Highly Compact Text-to-Speech Using 1.58-bit Quantization and Weight Indexing, https://arxiv.org/pdf/2506.03515, 2025-06-03
2025-11-09 20:52:08,434 - INFO - root - Page:2, Index:38, ShapeLLM-Omni: A Native Multimodal LLM for 3D Generation and Understanding, https://arxiv.org/pdf/2506.01853, 2025-06-02
2025-11-09 20:52:08,434 - INFO - root - Page:2, Index:39, Movable Antenna Enhanced Federated Fine-Tuning of Large Language Models via Hybrid Client Selection Optimization, https://arxiv.org/pdf/2506.00011, 2025-10-26
2025-11-09 20:52:08,434 - INFO - root - Page:2, Index:40, Running Conventional Automatic Speech Recognition on Memristor Hardware: A Simulated Approach, https://arxiv.org/pdf/2505.24721, 2025-05-30
2025-11-09 20:52:08,434 - INFO - root - Page:2, Index:41, GARLIC: GAussian Representation LearnIng for spaCe partitioning, https://arxiv.org/pdf/2505.24608, 2025-10-02
2025-11-09 20:52:08,435 - INFO - root - Page:2, Index:42, AutoChemSchematic AI: Agentic Physics-Aware Automation for Chemical Manufacturing Scale-Up, https://arxiv.org/pdf/2505.24584, 2025-08-18
2025-11-09 20:52:08,435 - INFO - root - Page:2, Index:43, Model-Preserving Adaptive Rounding, https://arxiv.org/pdf/2505.22988, 2025-09-25
2025-11-09 20:52:08,435 - INFO - root - Page:2, Index:44, Highly Efficient and Effective LLMs with Multi-Boolean Architectures, https://arxiv.org/pdf/2505.22811, 2025-10-03
2025-11-09 20:52:08,435 - INFO - root - Page:2, Index:45, Pioneering 4-Bit FP Quantization for Diffusion Models: Mixup-Sign Quantization and Timestep-Aware Fine-Tuning, https://arxiv.org/pdf/2505.21591, 2025-05-27
2025-11-09 20:52:08,435 - INFO - root - Page:2, Index:46, Frequency Composition for Compressed and Domain-Adaptive Neural Networks, https://arxiv.org/pdf/2505.20890, 2025-05-27
2025-11-09 20:52:08,437 - INFO - root - Page:2, Index:47, MoPFormer: Motion-Primitive Transformer for Wearable-Sensor Activity Recognition, https://arxiv.org/pdf/2505.20744, 2025-10-27
2025-11-09 20:52:08,438 - INFO - root - Page:2, Index:48, Optimizing edge AI models on HPC systems with the edge in the loop, https://arxiv.org/pdf/2505.19995, 2025-05-26
2025-11-09 20:52:08,438 - INFO - root - Fetching page 4 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=150
2025-11-09 20:52:15,383 - INFO - root - get_all_titles_from_web 
2025-11-09 20:52:15,383 - INFO - root - Page:3, Index:0, DPASyn: Mechanism-Aware Drug Synergy Prediction via Dual Attention and Precision-Aware Quantization, https://arxiv.org/pdf/2505.19144, 2025-09-20
2025-11-09 20:52:15,383 - INFO - root - Page:3, Index:1, Reducing Storage of Pretrained Neural Networks by Rate-Constrained Quantization and Entropy Coding, https://arxiv.org/pdf/2505.18758, 2025-05-24
2025-11-09 20:52:15,385 - INFO - root - Page:3, Index:2, Beyond Discreteness: Finite-Sample Analysis of Straight-Through Estimator for Quantization, https://arxiv.org/pdf/2505.18113, 2025-05-23
2025-11-09 20:52:15,385 - INFO - root - Page:3, Index:3, Automating Versatile Time-Series Analysis with Tiny Transformers on Embedded FPGAs, https://arxiv.org/pdf/2505.17662, 2025-09-19
2025-11-09 20:52:15,385 - INFO - root - Page:3, Index:4, FPQVAR: Floating Point Quantization for Visual Autoregressive Model with FPGA Hardware Co-design, https://arxiv.org/pdf/2505.16335, 2025-05-22
2025-11-09 20:52:15,385 - INFO - root - Page:3, Index:5, Saliency-Aware Quantized Imitation Learning for Efficient Robotic Control, https://arxiv.org/pdf/2505.15304, 2025-05-30
2025-11-09 20:52:15,386 - INFO - root - Page:3, Index:6, Scaling Law for Quantization-Aware Training, https://arxiv.org/pdf/2505.14302, 2025-05-20
2025-11-09 20:52:15,386 - INFO - root - Page:3, Index:7, Automatic mixed precision for optimizing gained time with constrained loss mean-squared-error based on model partition to sequential sub-graphs, https://arxiv.org/pdf/2505.13060, 2025-05-19
2025-11-09 20:52:15,386 - INFO - root - Page:3, Index:8, Deep Unfolding with Kernel-based Quantization in MIMO Detection, https://arxiv.org/pdf/2505.12736, 2025-05-19
2025-11-09 20:52:15,386 - INFO - root - Page:3, Index:9, FedHQ: Hybrid Runtime Quantization for Federated Learning, https://arxiv.org/pdf/2505.11982, 2025-05-17
2025-11-09 20:52:15,386 - INFO - root - Page:3, Index:10, QVGen: Pushing the Limit of Quantized Video Generative Models, https://arxiv.org/pdf/2505.11497, 2025-09-27
2025-11-09 20:52:15,387 - INFO - root - Page:3, Index:11, EA-3DGS: Efficient and Adaptive 3D Gaussians with Highly Enhanced Quality for outdoor scenes, https://arxiv.org/pdf/2505.10787, 2025-05-15
2025-11-09 20:52:15,387 - INFO - root - Page:3, Index:12, ITERA-LLM: Boosting Sub-8-Bit Large Language Model Inference via Iterative Tensor Decomposition, https://arxiv.org/pdf/2505.08981, 2025-05-13
2025-11-09 20:52:15,387 - INFO - root - Page:3, Index:13, PROM: Prioritize Reduction of Multiplications Over Lower Bit-Widths for Efficient CNNs, https://arxiv.org/pdf/2505.03254, 2025-08-06
2025-11-09 20:52:15,387 - INFO - root - Page:3, Index:14, ICQuant: Index Coding enables Low-bit LLM Quantization, https://arxiv.org/pdf/2505.00850, 2025-08-24
2025-11-09 20:52:15,388 - INFO - root - Page:3, Index:15, Enhancing Ultra-Low-Bit Quantization of Large Language Models Through Saliency-Aware Partial Retraining, https://arxiv.org/pdf/2504.13932, 2025-07-30
2025-11-09 20:52:15,388 - INFO - root - Page:3, Index:16, Achieving binary weight and activation for LLMs using Post-Training Quantization, https://arxiv.org/pdf/2504.05352, 2025-06-30
2025-11-09 20:52:15,388 - INFO - root - Page:3, Index:17, Wireless Hearables With Programmable Speech AI Accelerators, https://arxiv.org/pdf/2503.18698, 2025-10-21
2025-11-09 20:52:15,388 - INFO - root - Page:3, Index:18, GranQ: Efficient Channel-wise Quantization via Vectorized Pre-Scaling for Zero-Shot QAT, https://arxiv.org/pdf/2503.18339, 2025-10-15
2025-11-09 20:52:15,390 - INFO - root - Page:3, Index:19, CompMarkGS: Robust Watermarking for Compressed 3D Gaussian Splatting, https://arxiv.org/pdf/2503.12836, 2025-09-29
2025-11-09 20:52:15,390 - INFO - root - Page:3, Index:20, AHCPTQ: Accurate and Hardware-Compatible Post-Training Quantization for Segment Anything Model, https://arxiv.org/pdf/2503.03088, 2025-07-11
2025-11-09 20:52:15,390 - INFO - root - Page:3, Index:21, Teaching Metric Distance to Discrete Autoregressive Language Models, https://arxiv.org/pdf/2503.02379, 2025-10-07
2025-11-09 20:52:15,391 - INFO - root - Page:3, Index:22, Regularization-based Framework for Quantization-, Fault- and Variability-Aware Training, https://arxiv.org/pdf/2503.01297, 2025-07-12
2025-11-09 20:52:15,391 - INFO - root - Fetching page 5 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=200
2025-11-09 20:52:21,697 - INFO - root - get_all_titles_from_web 
2025-11-09 20:52:21,697 - INFO - root - Page:4, Index:0, Investigating the Impact of Quantization Methods on the Safety and Reliability of Large Language Models, https://arxiv.org/pdf/2502.15799, 2025-06-29
2025-11-09 20:52:21,697 - INFO - root - Page:4, Index:1, Rotate, Clip, and Partition: Towards W2A4KV4 Quantization by Integrating Rotation and Learnable Non-uniform Quantizer, https://arxiv.org/pdf/2502.15779, 2025-09-01
2025-11-09 20:52:21,697 - INFO - root - Page:4, Index:2, RoSTE: An Efficient Quantization-Aware Supervised Fine-Tuning Approach for Large Language Models, https://arxiv.org/pdf/2502.09003, 2025-06-05
2025-11-09 20:52:21,697 - INFO - root - Page:4, Index:3, Spatial Degradation-Aware and Temporal Consistent Diffusion Model for Compressed Video Super-Resolution, https://arxiv.org/pdf/2502.07381, 2025-06-27
2025-11-09 20:52:21,699 - INFO - root - Page:4, Index:4, QuEST: Stable Training of LLMs with 1-Bit Weights and Activations, https://arxiv.org/pdf/2502.05003, 2025-06-10
2025-11-09 20:52:21,699 - INFO - root - Page:4, Index:5, HALO: Hadamard-Assisted Lower-Precision Optimization for LLMs, https://arxiv.org/pdf/2501.02625, 2025-11-05
2025-11-09 20:52:21,699 - INFO - root - Page:4, Index:6, TAR3D: Creating High-Quality 3D Assets via Next-Part Prediction, https://arxiv.org/pdf/2412.16919, 2025-08-08
2025-11-09 20:52:21,699 - INFO - root - Page:4, Index:7, Training Multi-Layer Binary Neural Networks With Local Binary Error Signals, https://arxiv.org/pdf/2412.00119, 2025-08-05
2025-11-09 20:52:21,700 - INFO - root - Page:4, Index:8, Scaling Large-scale GNN Training to Thousands of Processors on CPU-based Supercomputers, https://arxiv.org/pdf/2411.16025, 2025-05-26
2025-11-09 20:52:21,700 - INFO - root - Page:4, Index:9, HAFLQ: Heterogeneous Adaptive Federated LoRA Fine-tuned LLM with Quantization, https://arxiv.org/pdf/2411.06581, 2025-05-16
2025-11-09 20:52:21,700 - INFO - root - Fetching page 6 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=250
2025-11-09 20:52:29,866 - INFO - root - get_all_titles_from_web 
2025-11-09 20:52:29,867 - INFO - root - Page:5, Index:0, Gradient-Free Training of Quantized Neural Networks, https://arxiv.org/pdf/2410.09734, 2025-09-29
2025-11-09 20:52:29,867 - INFO - root - Page:5, Index:1, QT-DoG: Quantization-aware Training for Domain Generalization, https://arxiv.org/pdf/2410.06020, 2025-06-26
2025-11-09 20:52:29,867 - INFO - root - Page:5, Index:2, Constraint Guided Model Quantization of Neural Networks, https://arxiv.org/pdf/2409.20138, 2025-09-12
2025-11-09 20:52:29,868 - INFO - root - Page:5, Index:3, Accumulator-Aware Post-Training Quantization for Large Language Models, https://arxiv.org/pdf/2409.17092, 2025-07-30
2025-11-09 20:52:29,868 - INFO - root - Page:5, Index:4, DilateQuant: Accurate and Efficient Diffusion Quantization via Weight Dilation, https://arxiv.org/pdf/2409.14307, 2025-07-09
2025-11-09 20:52:29,868 - INFO - root - Page:5, Index:5, Robust Training of Neural Networks at Arbitrary Precision and Sparsity, https://arxiv.org/pdf/2409.09245, 2025-09-23
2025-11-09 20:52:29,868 - INFO - root - Page:5, Index:6, VQ-CTAP: Cross-Modal Fine-Grained Sequence Representation Learning for Speech Processing, https://arxiv.org/pdf/2408.05758, 2025-05-27
2025-11-09 20:52:29,873 - INFO - root - Page:5, Index:7, DopQ-ViT: Towards Distribution-Friendly and Outlier-Aware Post-Training Quantization for Vision Transformers, https://arxiv.org/pdf/2408.03291, 2025-06-19
2025-11-09 20:52:29,874 - INFO - root - Page:5, Index:8, Temporal Feature Matters: A Framework for Diffusion Model Quantization, https://arxiv.org/pdf/2407.19547, 2025-07-11
2025-11-09 20:52:29,874 - INFO - root - Page:5, Index:9, EfficientQAT: Efficient Quantization-Aware Training for Large Language Models, https://arxiv.org/pdf/2407.11062, 2025-05-19
2025-11-09 20:52:29,874 - INFO - root - Page:5, Index:10, Integer-only Quantized Transformers for Embedded FPGA-based Time-series Forecasting in AIoT, https://arxiv.org/pdf/2407.11041, 2025-10-31
2025-11-09 20:52:29,875 - INFO - root - Fetching page 7 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=300
2025-11-09 20:52:36,995 - INFO - root - get_all_titles_from_web 
2025-11-09 20:52:36,995 - INFO - root - Page:6, Index:0, BoA: Attention-aware Post-training Quantization without Backpropagation, https://arxiv.org/pdf/2406.13474, 2025-06-06
2025-11-09 20:52:36,995 - INFO - root - Page:6, Index:1, A Rescaling-Invariant Lipschitz Bound Based on Path-Metrics for Modern ReLU Network Parameterizations, https://arxiv.org/pdf/2405.15006, 2025-06-13
2025-11-09 20:52:36,996 - INFO - root - Page:6, Index:2, Scheduling Weight Transitions for Quantization-Aware Training, https://arxiv.org/pdf/2404.19248, 2025-10-01
2025-11-09 20:52:36,996 - INFO - root - Page:6, Index:3, GPTVQ: The Blessing of Dimensionality for LLM Quantization, https://arxiv.org/pdf/2402.15319, 2025-06-03
2025-11-09 20:52:36,997 - INFO - root - Fetching page 8 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=350
2025-11-09 20:52:43,870 - INFO - root - get_all_titles_from_web 
2025-11-09 20:52:43,870 - INFO - root - Page:7, Index:0, Squat: Quant Small Language Models on the Edge, https://arxiv.org/pdf/2402.10787, 2025-07-01
2025-11-09 20:52:43,871 - INFO - root - Page:7, Index:1, L4Q: Parameter Efficient Quantization-Aware Fine-Tuning on Large Language Models, https://arxiv.org/pdf/2402.04902, 2025-07-21
2025-11-09 20:52:43,871 - INFO - root - Fetching page 9 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=400
2025-11-09 20:52:50,584 - INFO - root - ------------------------------------------------------------------------------------------------------------------------
2025-11-09 20:52:50,585 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\A Quantized VAE-MLP Botnet Detection Model_ A Systematic Evaluation of Quantizat.pdf
2025-11-09 20:52:50,592 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\FP8-Flow-MoE_ A Casting-Free FP8 Recipe without Double Quantization Error.pdf
2025-11-09 20:52:50,593 - INFO - root - 跳过已处理论文 A Quantized VAE-MLP Botnet Detection Model: A Systematic Evaluation of Quantization-Aware Training and Post-Training Quantization Strategies：d:\ChatPaper\academic Papers\Quantization-Aware-Training\A Quantized VAE-MLP Botnet Detection Model_ A Systematic Evaluation of Quantizat.pdf
2025-11-09 20:52:50,593 - INFO - root - 跳过已处理论文 FP8-Flow-MoE: A Casting-Free FP8 Recipe without Double Quantization Error：d:\ChatPaper\academic Papers\Quantization-Aware-Training\FP8-Flow-MoE_ A Casting-Free FP8 Recipe without Double Quantization Error.pdf
2025-11-09 20:52:50,595 - INFO - root - summary time: 68.74 seconds
2025-11-09 20:53:28,383 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-09 20:53:28,385 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-09 20:53:28,391 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-09 20:53:29,228 - INFO - root - LLMClientManager: 指定使用客户端: DeepSeek
2025-11-09 20:53:29,229 - INFO - root - DeepSeekClient: API key found: 9f9e270e-b...
2025-11-09 20:53:29,229 - INFO - root - DeepSeekClient: 使用模式: 火山引擎
2025-11-09 20:53:29,230 - INFO - root - DeepSeekClient: 模型名称: deepseek-v3-1-terminus
2025-11-09 20:53:32,466 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 20:53:32,475 - INFO - root - DeepSeekClient: initialized successfully with model deepseek-v3-1-terminus
2025-11-09 20:53:32,477 - INFO - root - LLMClientManager: DeepSeek 客户端初始化成功
2025-11-09 20:53:32,477 - INFO - root - LLMClientManager: switched to DeepSeek client
2025-11-09 20:53:32,477 - INFO - root - 已手动切换到 LLM 客户端: DeepSeek
2025-11-09 20:53:32,478 - INFO - root - 使用 LLM 模型: deepseek-v3-1-terminus
2025-11-09 20:53:32,478 - INFO - root - 可用客户端: ['DeepSeek']
2025-11-09 20:53:32,478 - INFO - root - === 运行配置 ===
2025-11-09 20:53:32,479 - INFO - root - 处理模式: arxiv在线搜索
2025-11-09 20:53:32,479 - INFO - root - 关键词: QAT
2025-11-09 20:53:32,479 - INFO - root - 查询: Quantization-Aware-Training
2025-11-09 20:53:32,479 - INFO - root - 排序: None
2025-11-09 20:53:32,480 - INFO - root - 最近天数: 180
2025-11-09 20:53:32,480 - INFO - root - 最大处理数量: 2
2025-11-09 20:53:32,481 - INFO - root - 保存图片: 是
2025-11-09 20:53:32,481 - INFO - root - 输出语言: 中文
2025-11-09 20:53:32,482 - INFO - root - 强制重新处理: 否
2025-11-09 20:53:32,482 - INFO - root - ====================
2025-11-09 20:53:32,483 - INFO - root - 使用 arXiv 搜索模式（通过 chat_arxiv 模块获取）
2025-11-09 20:53:32,483 - INFO - root - Fetching page 1 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50
2025-11-09 20:53:59,745 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-09 20:53:59,747 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-09 20:53:59,748 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-09 20:54:00,555 - INFO - root - LLMClientManager: 指定使用客户端: Gemini
2025-11-09 20:54:01,669 - INFO - root - GeminiClient: trying model gemini-2.5-flash
2025-11-09 20:54:04,999 - INFO - root - GeminiClient: initialized model gemini-2.5-flash
2025-11-09 20:54:04,999 - INFO - root - LLMClientManager: Gemini 客户端初始化成功
2025-11-09 20:54:04,999 - INFO - root - LLMClientManager: switched to Gemini client
2025-11-09 20:54:05,000 - INFO - root - 已手动切换到 LLM 客户端: Gemini
2025-11-09 20:54:05,000 - INFO - root - 使用 LLM 模型: gemini-2.5-flash
2025-11-09 20:54:05,000 - INFO - root - 可用客户端: ['Gemini']
2025-11-09 20:54:05,001 - INFO - root - === 运行配置 ===
2025-11-09 20:54:05,001 - INFO - root - 处理模式: arxiv在线搜索
2025-11-09 20:54:05,001 - INFO - root - 关键词: QAT
2025-11-09 20:54:05,001 - INFO - root - 查询: Quantization-Aware-Training
2025-11-09 20:54:05,002 - INFO - root - 排序: None
2025-11-09 20:54:05,003 - INFO - root - 最近天数: 180
2025-11-09 20:54:05,003 - INFO - root - 最大处理数量: 2
2025-11-09 20:54:05,003 - INFO - root - 保存图片: 是
2025-11-09 20:54:05,003 - INFO - root - 输出语言: 中文
2025-11-09 20:54:05,004 - INFO - root - 强制重新处理: 否
2025-11-09 20:54:05,004 - INFO - root - ====================
2025-11-09 20:54:05,004 - INFO - root - 使用 arXiv 搜索模式（通过 chat_arxiv 模块获取）
2025-11-09 20:54:05,005 - INFO - root - Fetching page 1 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50
2025-11-09 20:54:12,438 - INFO - root - get_all_titles_from_web 
2025-11-09 20:54:12,440 - INFO - root - Page:0, Index:0, A Quantized VAE-MLP Botnet Detection Model: A Systematic Evaluation of Quantization-Aware Training and Post-Training Quantization Strategies, https://arxiv.org/pdf/2511.03201, 2025-11-05
2025-11-09 20:54:12,440 - INFO - root - Page:0, Index:1, FP8-Flow-MoE: A Casting-Free FP8 Recipe without Double Quantization Error, https://arxiv.org/pdf/2511.02302, 2025-11-04
2025-11-09 20:54:12,440 - INFO - root - Page:0, Index:2, Outlier-Aware Post-Training Quantization for Image Super-Resolution, https://arxiv.org/pdf/2511.00682, 2025-11-01
2025-11-09 20:54:12,442 - INFO - root - Page:0, Index:3, Evaluation of Wafer-Scale SOT-MRAM for Analog Crossbar Array Applications, https://arxiv.org/pdf/2510.25853, 2025-11-03
2025-11-09 20:54:12,443 - INFO - root - Page:0, Index:4, Improving the Straight-Through Estimator with Zeroth-Order Information, https://arxiv.org/pdf/2510.23926, 2025-10-27
2025-11-09 20:54:12,444 - INFO - root - Page:0, Index:5, Real-Time Semantic Segmentation on FPGA for Autonomous Vehicles Using LMIINet with the CGRA4ML Framework, https://arxiv.org/pdf/2510.22243, 2025-10-25
2025-11-09 20:54:12,445 - INFO - root - Page:0, Index:6, TernaryCLIP: Efficiently Compressing Vision-Language Models with Ternary Weights and Distilled Knowledge, https://arxiv.org/pdf/2510.21879, 2025-10-23
2025-11-09 20:54:12,446 - INFO - root - Page:0, Index:7, KARIPAP: Quantum-Inspired Tensor Network Compression of Large Language Models Using Infinite Projected Entangled Pair States and Tensor Renormalization Group, https://arxiv.org/pdf/2510.21844, 2025-10-22
2025-11-09 20:54:12,452 - INFO - root - Page:0, Index:8, A Convergence Analysis of Adaptive Optimizers under Floating-point Quantization, https://arxiv.org/pdf/2510.21314, 2025-10-24
2025-11-09 20:54:12,452 - INFO - root - Page:0, Index:9, Adaptive Distribution-aware Quantization for Mixed-Precision Neural Networks, https://arxiv.org/pdf/2510.19760, 2025-10-22
2025-11-09 20:54:12,454 - INFO - root - Page:0, Index:10, CAGE: Curvature-Aware Gradient Estimation For Accurate Quantization-Aware Training, https://arxiv.org/pdf/2510.18784, 2025-10-21
2025-11-09 20:54:12,455 - INFO - root - Page:0, Index:11, Mixed-Precision Quantization for Language Models: Techniques and Prospects, https://arxiv.org/pdf/2510.16805, 2025-10-19
2025-11-09 20:54:12,455 - INFO - root - Page:0, Index:12, SPLite Hand: Sparsity-Aware Lightweight 3D Hand Pose Estimation, https://arxiv.org/pdf/2510.16396, 2025-10-30
2025-11-09 20:54:12,455 - INFO - root - Page:0, Index:13, CTR-LoRA: Curvature-Aware and Trust-Region Guided Low-Rank Adaptation for Large Language Models, https://arxiv.org/pdf/2510.15962, 2025-10-11
2025-11-09 20:54:12,456 - INFO - root - Page:0, Index:14, SANR: Scene-Aware Neural Representation for Light Field Image Compression with Rate-Distortion Optimization, https://arxiv.org/pdf/2510.15775, 2025-10-17
2025-11-09 20:54:12,456 - INFO - root - Page:0, Index:15, SpikeFit: Towards Optimal Deployment of Spiking Networks on Neuromorphic Hardware, https://arxiv.org/pdf/2510.15542, 2025-10-31
2025-11-09 20:54:12,458 - INFO - root - Page:0, Index:16, GRank: Towards Target-Aware and Streamlined Industrial Retrieval with a Generate-Rank Framework, https://arxiv.org/pdf/2510.15299, 2025-10-17
2025-11-09 20:54:12,460 - INFO - root - Page:0, Index:17, SaLon3R: Structure-aware Long-term Generalizable 3D Reconstruction from Unposed Images, https://arxiv.org/pdf/2510.15072, 2025-10-16
2025-11-09 20:54:12,461 - INFO - root - Page:0, Index:18, FraQAT: Quantization Aware Training with Fractional bits, https://arxiv.org/pdf/2510.14823, 2025-10-16
2025-11-09 20:54:12,462 - INFO - root - Page:0, Index:19, Computing-In-Memory Aware Model Adaption For Edge Devices, https://arxiv.org/pdf/2510.14379, 2025-10-16
2025-11-09 20:54:12,463 - INFO - root - Page:0, Index:20, Invited Paper: BitMedViT: Ternary-Quantized Vision Transformer for Medical AI Assistants on the Edge, https://arxiv.org/pdf/2510.13760, 2025-11-04
2025-11-09 20:54:12,467 - INFO - root - Page:0, Index:21, NeuroRVQ: Multi-Scale EEG Tokenization for Generative Large Brainwave Models, https://arxiv.org/pdf/2510.13068, 2025-10-14
2025-11-09 20:54:12,467 - INFO - root - Page:0, Index:22, Detect Anything via Next Point Prediction, https://arxiv.org/pdf/2510.12798, 2025-10-14
2025-11-09 20:54:12,469 - INFO - root - Page:0, Index:23, AndesVL Technical Report: An Efficient Mobile-side Multimodal Large Language Model, https://arxiv.org/pdf/2510.11496, 2025-10-14
2025-11-09 20:54:12,469 - INFO - root - Page:0, Index:24, Rescaling-Aware Training for Efficient Deployment of Deep Learning Models on Full-Integer Hardware, https://arxiv.org/pdf/2510.11484, 2025-10-13
2025-11-09 20:54:12,471 - INFO - root - Page:0, Index:25, SASER: Stego attacks on open-source LLMs, https://arxiv.org/pdf/2510.10486, 2025-10-12
2025-11-09 20:54:12,472 - INFO - root - Page:0, Index:26, Ultralytics YOLO Evolution: An Overview of YOLO26, YOLO11, YOLOv8 and YOLOv5 Object Detectors for Computer Vision and Pattern Recognition, https://arxiv.org/pdf/2510.09653, 2025-10-15
2025-11-09 20:54:12,472 - INFO - root - Page:0, Index:27, A Theoretically-Grounded Codebook for Digital Semantic Communications, https://arxiv.org/pdf/2510.07108, 2025-10-14
2025-11-09 20:54:12,472 - INFO - root - Page:0, Index:28, QuantDemoire: Quantization with Outlier Aware for Image Demoiréing, https://arxiv.org/pdf/2510.04066, 2025-10-05
2025-11-09 20:54:12,473 - INFO - root - Page:0, Index:29, Adaptively Sampling-Reusing-Mixing Decomposed Gradients to Speed Up Sharpness Aware Minimization, https://arxiv.org/pdf/2510.03763, 2025-10-04
2025-11-09 20:54:12,474 - INFO - root - Page:0, Index:30, Quant-dLLM: Post-Training Extreme Low-Bit Quantization for Diffusion Large Language Models, https://arxiv.org/pdf/2510.03274, 2025-09-27
2025-11-09 20:54:12,474 - INFO - root - Page:0, Index:31, PT$^2$-LLM: Post-Training Ternarization for Large Language Models, https://arxiv.org/pdf/2510.03267, 2025-09-26
2025-11-09 20:54:12,475 - INFO - root - Page:0, Index:32, Purrception: Variational Flow Matching for Vector-Quantized Image Generation, https://arxiv.org/pdf/2510.01478, 2025-10-01
2025-11-09 20:54:12,479 - INFO - root - Page:0, Index:33, Post-Training Quantization for Audio Diffusion Transformers, https://arxiv.org/pdf/2510.00313, 2025-09-30
2025-11-09 20:54:12,488 - INFO - root - Page:0, Index:34, Rethinking RoPE Scaling in Quantized LLM: Theory, Outlier, and Channel-Band Analysis with Weight Rescaling, https://arxiv.org/pdf/2510.00028, 2025-09-25
2025-11-09 20:54:12,488 - INFO - root - Page:0, Index:35, Post-Training Quantization via Residual Truncation and Zero Suppression for Diffusion Models, https://arxiv.org/pdf/2509.26436, 2025-09-30
2025-11-09 20:54:12,489 - INFO - root - Page:0, Index:36, Cat: Post-Training Quantization Error Reduction via Cluster-based Affine Transformation, https://arxiv.org/pdf/2509.26277, 2025-10-07
2025-11-09 20:54:12,489 - INFO - root - Page:0, Index:37, CAST: Continuous and Differentiable Semi-Structured Sparsity-Aware Training for Large Language Models, https://arxiv.org/pdf/2509.25996, 2025-09-30
2025-11-09 20:54:12,490 - INFO - root - Page:0, Index:38, Norm-Q: Effective Compression Method for Hidden Markov Models in Neuro-Symbolic Applications, https://arxiv.org/pdf/2509.25439, 2025-09-29
2025-11-09 20:54:12,491 - INFO - root - Page:0, Index:39, On-the-Fly Adaptation to Quantization: Configuration-Aware LoRA for Efficient Fine-Tuning of Quantized LLMs, https://arxiv.org/pdf/2509.25214, 2025-09-22
2025-11-09 20:54:12,494 - INFO - root - Page:0, Index:40, VoxCPM: Tokenizer-Free TTS for Context-Aware Speech Generation and True-to-Life Voice Cloning, https://arxiv.org/pdf/2509.24650, 2025-09-29
2025-11-09 20:54:12,496 - INFO - root - Page:0, Index:41, S$^2$NN: Sub-bit Spiking Neural Networks, https://arxiv.org/pdf/2509.24266, 2025-10-24
2025-11-09 20:54:12,503 - INFO - root - Page:0, Index:42, Tequila: Trapping-free Ternary Quantization for Large Language Models, https://arxiv.org/pdf/2509.23809, 2025-10-17
2025-11-09 20:54:12,503 - INFO - root - Page:0, Index:43, Texture Vector-Quantization and Reconstruction Aware Prediction for Generative Super-Resolution, https://arxiv.org/pdf/2509.23774, 2025-09-30
2025-11-09 20:54:12,504 - INFO - root - Page:0, Index:44, RobuQ: Pushing DiTs to W1.58A2 via Robust Activation Quantization, https://arxiv.org/pdf/2509.23582, 2025-09-27
2025-11-09 20:54:12,507 - INFO - root - Page:0, Index:45, Beyond Outliers: A Study of Optimizers Under Quantization, https://arxiv.org/pdf/2509.23500, 2025-10-02
2025-11-09 20:54:12,529 - INFO - root - Page:0, Index:46, Compute-Optimal Quantization-Aware Training, https://arxiv.org/pdf/2509.22935, 2025-09-26
2025-11-09 20:54:12,538 - INFO - root - Page:0, Index:47, COSPADI: Compressing LLMs via Calibration-Guided Sparse Dictionary Learning, https://arxiv.org/pdf/2509.22075, 2025-10-06
2025-11-09 20:54:12,538 - INFO - root - Page:0, Index:48, SlimDiff: Training-Free, Activation-Guided Hands-free Slimming of Diffusion Models, https://arxiv.org/pdf/2509.21498, 2025-09-25
2025-11-09 20:54:12,539 - INFO - root - Page:0, Index:49, Quantized Visual Geometry Grounded Transformer, https://arxiv.org/pdf/2509.21302, 2025-09-29
2025-11-09 20:54:12,540 - INFO - root - Fetching page 2 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=50
2025-11-09 20:54:19,046 - INFO - root - get_all_titles_from_web 
2025-11-09 20:54:19,046 - INFO - root - Page:1, Index:0, Can Less Precise Be More Reliable? A Systematic Evaluation of Quantization's Impact on CLIP Beyond Accuracy, https://arxiv.org/pdf/2509.21173, 2025-10-27
2025-11-09 20:54:19,046 - INFO - root - Page:1, Index:1, Punching Above Precision: Small Quantized Model Distillation with Learnable Regularizer, https://arxiv.org/pdf/2509.20854, 2025-09-25
2025-11-09 20:54:19,046 - INFO - root - Page:1, Index:2, TinyEcoWeedNet: Edge Efficient Real-Time Aerial Agricultural Weed Detection, https://arxiv.org/pdf/2509.18193, 2025-09-19
2025-11-09 20:54:19,048 - INFO - root - Page:1, Index:3, SBVR: Summation of BitVector Representation for Efficient LLM Quantization, https://arxiv.org/pdf/2509.18172, 2025-09-17
2025-11-09 20:54:19,048 - INFO - root - Page:1, Index:4, QWHA: Quantization-Aware Walsh-Hadamard Adaptation for Parameter-Efficient Fine-Tuning on Large Language Models, https://arxiv.org/pdf/2509.17428, 2025-09-26
2025-11-09 20:54:19,048 - INFO - root - Page:1, Index:5, PTQTP: Post-Training Quantization to Trit-Planes for Large Language Models, https://arxiv.org/pdf/2509.16989, 2025-10-28
2025-11-09 20:54:19,048 - INFO - root - Page:1, Index:6, MEC-Quant: Maximum Entropy Coding for Extremely Low Bit Quantization-Aware Training, https://arxiv.org/pdf/2509.15514, 2025-09-18
2025-11-09 20:54:19,048 - INFO - root - Page:1, Index:7, Q-ROAR: Outlier-Aware Rescaling for RoPE Position Interpolation in Quantized Long-Context LLMs, https://arxiv.org/pdf/2509.14391, 2025-09-17
2025-11-09 20:54:19,049 - INFO - root - Page:1, Index:8, Efficient Quantization-Aware Neural Receivers: Beyond Post-Training Quantization, https://arxiv.org/pdf/2509.13786, 2025-09-19
2025-11-09 20:54:19,049 - INFO - root - Page:1, Index:9, Rate-Distortion Limits for Multimodal Retrieval: Theory, Optimal Codes, and Finite-Sample Guarantees, https://arxiv.org/pdf/2509.11054, 2025-09-13
2025-11-09 20:54:19,049 - INFO - root - Page:1, Index:10, SQAP-VLA: A Synergistic Quantization-Aware Pruning Framework for High-Performance Vision-Language-Action Models, https://arxiv.org/pdf/2509.09090, 2025-09-10
2025-11-09 20:54:19,049 - INFO - root - Page:1, Index:11, CSI Compression Beyond Latents: End-to-End Hybrid Attention-CNN Networks with Entropy Regularization, https://arxiv.org/pdf/2509.08776, 2025-09-10
2025-11-09 20:54:19,050 - INFO - root - Page:1, Index:12, Explaining How Quantization Disparately Skews a Model, https://arxiv.org/pdf/2509.07222, 2025-09-08
2025-11-09 20:54:19,050 - INFO - root - Page:1, Index:13, LoaQ: Layer-wise Output Approximation Quantization, https://arxiv.org/pdf/2509.06297, 2025-09-07
2025-11-09 20:54:19,050 - INFO - root - Page:1, Index:14, FineServe: Precision-Aware KV Slab and Two-Level Scheduling for Heterogeneous Precision LLM Serving, https://arxiv.org/pdf/2509.06261, 2025-09-14
2025-11-09 20:54:19,051 - INFO - root - Page:1, Index:15, Sensitivity-Aware Post-Training Quantization for Deep Neural Networks, https://arxiv.org/pdf/2509.05576, 2025-09-05
2025-11-09 20:54:19,051 - INFO - root - Page:1, Index:16, SuperSNN: A Hardware-Aware Framework for Physically Realizable, High-Performance Superconducting Spiking Neural Network Chips, https://arxiv.org/pdf/2509.05532, 2025-09-05
2025-11-09 20:54:19,051 - INFO - root - Page:1, Index:17, Data-Augmented Quantization-Aware Knowledge Distillation, https://arxiv.org/pdf/2509.03850, 2025-09-03
2025-11-09 20:54:19,051 - INFO - root - Page:1, Index:18, DPQuant: Efficient and Differentially-Private Model Training via Dynamic Quantization Scheduling, https://arxiv.org/pdf/2509.03472, 2025-09-03
2025-11-09 20:54:19,052 - INFO - root - Page:1, Index:19, Empowering Large Language Model for Sequential Recommendation via Multimodal Embeddings and Semantic IDs, https://arxiv.org/pdf/2509.02017, 2025-09-02
2025-11-09 20:54:19,052 - INFO - root - Page:1, Index:20, Q-Sched: Pushing the Boundaries of Few-Step Diffusion Models with Quantization-Aware Scheduling, https://arxiv.org/pdf/2509.01624, 2025-09-01
2025-11-09 20:54:19,052 - INFO - root - Page:1, Index:21, Quantization Meets OOD: Generalizable Quantization-aware Training from a Flatness Perspective, https://arxiv.org/pdf/2509.00859, 2025-08-31
2025-11-09 20:54:19,054 - INFO - root - Page:1, Index:22, Progressive Element-wise Gradient Estimation for Neural Network Quantization, https://arxiv.org/pdf/2509.00097, 2025-08-27
2025-11-09 20:54:19,056 - INFO - root - Page:1, Index:23, End-to-End On-Device Quantization-Aware Training for LLMs at Inference Cost, https://arxiv.org/pdf/2509.00031, 2025-09-29
2025-11-09 20:54:19,056 - INFO - root - Page:1, Index:24, Quantization Robustness to Input Degradations for Object Detection, https://arxiv.org/pdf/2508.19600, 2025-08-27
2025-11-09 20:54:19,056 - INFO - root - Page:1, Index:25, Scaling Laws for Task-Stratified Knowledge in Post-Training Quantized Large Language Models, https://arxiv.org/pdf/2508.18609, 2025-08-27
2025-11-09 20:54:19,057 - INFO - root - Page:1, Index:26, AQ-PCDSys: An Adaptive Quantized Planetary Crater Detection System for Autonomous Space Exploration, https://arxiv.org/pdf/2508.18025, 2025-08-25
2025-11-09 20:54:19,059 - INFO - root - Page:1, Index:27, TaDiCodec: Text-aware Diffusion Speech Tokenizer for Speech Language Modeling, https://arxiv.org/pdf/2508.16790, 2025-08-22
2025-11-09 20:54:19,060 - INFO - root - Page:1, Index:28, A Node-Aware Dynamic Quantization Approach for Graph Collaborative Filtering, https://arxiv.org/pdf/2508.16516, 2025-08-22
2025-11-09 20:54:19,061 - INFO - root - Page:1, Index:29, JEDI-linear: Fast and Efficient Graph Neural Networks for Jet Tagging on FPGAs, https://arxiv.org/pdf/2508.15468, 2025-08-21
2025-11-09 20:54:19,061 - INFO - root - Page:1, Index:30, MMQ: Multimodal Mixture-of-Quantization Tokenization for Semantic ID Generation and User Behavioral Adaptation, https://arxiv.org/pdf/2508.15281, 2025-08-21
2025-11-09 20:54:19,062 - INFO - root - Page:1, Index:31, DLLMQuant: Quantizing Diffusion-based Large Language Models, https://arxiv.org/pdf/2508.14090, 2025-08-25
2025-11-09 20:54:19,062 - INFO - root - Page:1, Index:32, Automated Energy-Aware Time-Series Model Deployment on Embedded FPGAs for Resilient Combined Sewer Overflow Management, https://arxiv.org/pdf/2508.13905, 2025-08-19
2025-11-09 20:54:19,062 - INFO - root - Page:1, Index:33, XR-NPE: High-Throughput Mixed-precision SIMD Neural Processing Engine for Extended Reality Perception Workloads, https://arxiv.org/pdf/2508.13049, 2025-08-18
2025-11-09 20:54:19,064 - INFO - root - Page:1, Index:34, Exploring Self-Supervised Audio Models for Generalized Anomalous Sound Detection, https://arxiv.org/pdf/2508.12230, 2025-08-17
2025-11-09 20:54:19,064 - INFO - root - Page:1, Index:35, TriQDef: Disrupting Semantic and Gradient Alignment to Prevent Adversarial Patch Transferability in Quantized Neural Networks, https://arxiv.org/pdf/2508.12132, 2025-08-16
2025-11-09 20:54:19,064 - INFO - root - Page:1, Index:36, Error Propagation Mechanisms and Compensation Strategies for Quantized Diffusion, https://arxiv.org/pdf/2508.12094, 2025-10-13
2025-11-09 20:54:19,064 - INFO - root - Page:1, Index:37, Extending Straight-Through Estimation for Robust Neural Networks on Analog CIM Hardware, https://arxiv.org/pdf/2508.11940, 2025-08-16
2025-11-09 20:54:19,064 - INFO - root - Page:1, Index:38, PTQAT: A Hybrid Parameter-Efficient Quantization Algorithm for 3D Perception Tasks, https://arxiv.org/pdf/2508.10557, 2025-08-15
2025-11-09 20:54:19,065 - INFO - root - Page:1, Index:39, MiCo: End-to-End Mixed Precision Neural Network Co-Exploration Framework for Edge AI, https://arxiv.org/pdf/2508.09500, 2025-08-13
2025-11-09 20:54:19,065 - INFO - root - Page:1, Index:40, SPARC: Soft Probabilistic Adaptive multi-interest Retrieval Model via Codebooks for recommender system, https://arxiv.org/pdf/2508.09090, 2025-08-12
2025-11-09 20:54:19,066 - INFO - root - Page:1, Index:41, Rethinking 1-bit Optimization Leveraging Pre-trained Large Language Models, https://arxiv.org/pdf/2508.06974, 2025-08-09
2025-11-09 20:54:19,066 - INFO - root - Page:1, Index:42, Efficient Deep Neural Receiver with Post-Training Quantization, https://arxiv.org/pdf/2508.06275, 2025-08-08
2025-11-09 20:54:19,066 - INFO - root - Page:1, Index:43, iFairy: the First 2-bit Complex LLM with All Parameters in $\{\pm1, \pm i\}$, https://arxiv.org/pdf/2508.05571, 2025-08-16
2025-11-09 20:54:19,067 - INFO - root - Page:1, Index:44, S$^2$Q-VDiT: Accurate Quantized Video Diffusion Transformer with Salient Data and Sparse Token Distillation, https://arxiv.org/pdf/2508.04016, 2025-10-27
2025-11-09 20:54:19,067 - INFO - root - Page:1, Index:45, LRQ-DiT: Log-Rotation Post-Training Quantization of Diffusion Transformers for Image and Video Generation, https://arxiv.org/pdf/2508.03485, 2025-09-23
2025-11-09 20:54:19,067 - INFO - root - Page:1, Index:46, VLMQ: Efficient Post-Training Quantization for Large Vision-Language Models via Hessian Augmentation, https://arxiv.org/pdf/2508.03351, 2025-08-05
2025-11-09 20:54:19,068 - INFO - root - Page:1, Index:47, TF-MLPNet: Tiny Real-Time Neural Speech Separation, https://arxiv.org/pdf/2508.03047, 2025-08-04
2025-11-09 20:54:19,068 - INFO - root - Page:1, Index:48, SaviorRec: Semantic-Behavior Alignment for Cold-Start Recommendation, https://arxiv.org/pdf/2508.01375, 2025-08-02
2025-11-09 20:54:19,069 - INFO - root - Page:1, Index:49, MixA-Q: Revisiting Activation Sparsity for Vision Transformers from a Mixed-Precision Quantization Perspective, https://arxiv.org/pdf/2507.19131, 2025-07-25
2025-11-09 20:54:19,069 - INFO - root - Fetching page 3 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=100
2025-11-09 20:54:25,722 - INFO - root - get_all_titles_from_web 
2025-11-09 20:54:25,722 - INFO - root - Page:2, Index:0, Enhancing Quantization-Aware Training on Edge Devices via Relative Entropy Coreset Selection and Cascaded Layer Correction, https://arxiv.org/pdf/2507.17768, 2025-07-16
2025-11-09 20:54:25,724 - INFO - root - Page:2, Index:1, SiLQ: Simple Large Language Model Quantization-Aware Training, https://arxiv.org/pdf/2507.16933, 2025-07-22
2025-11-09 20:54:25,724 - INFO - root - Page:2, Index:2, Task-Specific Zero-shot Quantization-Aware Training for Object Detection, https://arxiv.org/pdf/2507.16782, 2025-07-22
2025-11-09 20:54:25,724 - INFO - root - Page:2, Index:3, TorchAO: PyTorch-Native Training-to-Serving Model Optimization, https://arxiv.org/pdf/2507.16099, 2025-07-21
2025-11-09 20:54:25,725 - INFO - root - Page:2, Index:4, SegQuant: A Semantics-Aware and Generalizable Quantization Framework for Diffusion Models, https://arxiv.org/pdf/2507.14811, 2025-08-27
2025-11-09 20:54:25,725 - INFO - root - Page:2, Index:5, Apple Intelligence Foundation Language Models: Tech Report 2025, https://arxiv.org/pdf/2507.13575, 2025-08-27
2025-11-09 20:54:25,725 - INFO - root - Page:2, Index:6, Generative Multi-Target Cross-Domain Recommendation, https://arxiv.org/pdf/2507.12871, 2025-08-07
2025-11-09 20:54:25,725 - INFO - root - Page:2, Index:7, DAF: An Efficient End-to-End Dynamic Activation Framework for on-Device DNN Training, https://arxiv.org/pdf/2507.07149, 2025-07-09
2025-11-09 20:54:25,726 - INFO - root - Page:2, Index:8, Opto-ViT: Architecting a Near-Sensor Region of Interest-Aware Vision Transformer Accelerator with Silicon Photonics, https://arxiv.org/pdf/2507.07044, 2025-07-15
2025-11-09 20:54:25,727 - INFO - root - Page:2, Index:9, QS4D: Quantization-aware training for efficient hardware deployment of structured state-space sequential models, https://arxiv.org/pdf/2507.06079, 2025-07-08
2025-11-09 20:54:25,729 - INFO - root - Page:2, Index:10, GSVR: 2D Gaussian-based Video Representation for 800+ FPS with Hybrid Deformation Field, https://arxiv.org/pdf/2507.05594, 2025-07-07
2025-11-09 20:54:25,732 - INFO - root - Page:2, Index:11, Hita: Holistic Tokenizer for Autoregressive Image Generation, https://arxiv.org/pdf/2507.02358, 2025-07-11
2025-11-09 20:54:25,733 - INFO - root - Page:2, Index:12, QPART: Adaptive Model Quantization and Dynamic Workload Balancing for Accuracy-aware Edge Inference, https://arxiv.org/pdf/2506.23934, 2025-06-30
2025-11-09 20:54:25,733 - INFO - root - Page:2, Index:13, FedWSQ: Efficient Federated Learning with Weight Standardization and Distribution-Aware Non-Uniform Quantization, https://arxiv.org/pdf/2506.23516, 2025-07-21
2025-11-09 20:54:25,735 - INFO - root - Page:2, Index:14, Spectra 1.1: Scaling Laws and Efficient Inference for Ternary Language Models, https://arxiv.org/pdf/2506.23025, 2025-06-28
2025-11-09 20:54:25,735 - INFO - root - Page:2, Index:15, Joint Quantization and Pruning Neural Networks Approach: A Case Study on FSO Receivers, https://arxiv.org/pdf/2506.20084, 2025-06-24
2025-11-09 20:54:25,736 - INFO - root - Page:2, Index:16, Single-step Diffusion for Image Compression at Ultra-Low Bitrates, https://arxiv.org/pdf/2506.16572, 2025-09-22
2025-11-09 20:54:25,736 - INFO - root - Page:2, Index:17, LittleBit: Ultra Low-Bit Quantization via Latent Factorization, https://arxiv.org/pdf/2506.13771, 2025-10-28
2025-11-09 20:54:25,736 - INFO - root - Page:2, Index:18, MARCO: Hardware-Aware Neural Architecture Search for Edge Devices with Multi-Agent Reinforcement Learning and Conformal Prediction Filtering, https://arxiv.org/pdf/2506.13755, 2025-06-16
2025-11-09 20:54:25,737 - INFO - root - Page:2, Index:19, EAQuant: Enhancing Post-Training Quantization for MoE Models via Expert-Aware Optimization, https://arxiv.org/pdf/2506.13329, 2025-07-04
2025-11-09 20:54:25,737 - INFO - root - Page:2, Index:20, Towards Neural Audio Codec Source Parsing, https://arxiv.org/pdf/2506.12627, 2025-06-14
2025-11-09 20:54:25,737 - INFO - root - Page:2, Index:21, Quantizing Small-Scale State-Space Models for Edge AI, https://arxiv.org/pdf/2506.12480, 2025-06-14
2025-11-09 20:54:25,738 - INFO - root - Page:2, Index:22, EMLoC: Emulator-based Memory-efficient Fine-tuning with LoRA Correction, https://arxiv.org/pdf/2506.12015, 2025-06-13
2025-11-09 20:54:25,738 - INFO - root - Page:2, Index:23, Compression Aware Certified Training, https://arxiv.org/pdf/2506.11992, 2025-06-13
2025-11-09 20:54:25,738 - INFO - root - Page:2, Index:24, GPLQ: A General, Practical, and Lightning QAT Method for Vision Transformers, https://arxiv.org/pdf/2506.11784, 2025-06-13
2025-11-09 20:54:25,738 - INFO - root - Page:2, Index:25, TruncQuant: Truncation-Ready Quantization for DNNs with Flexible Weight Bit Precision, https://arxiv.org/pdf/2506.11431, 2025-06-12
2025-11-09 20:54:25,739 - INFO - root - Page:2, Index:26, EfficientQuant: An Efficient Post-Training Quantization for CNN-Transformer Hybrid Models on Edge Devices, https://arxiv.org/pdf/2506.11093, 2025-06-05
2025-11-09 20:54:25,739 - INFO - root - Page:2, Index:27, Starting Positions Matter: A Study on Better Weight Initialization for Neural Network Quantization, https://arxiv.org/pdf/2506.10463, 2025-06-12
2025-11-09 20:54:25,741 - INFO - root - Page:2, Index:28, AWP: Activation-Aware Weight Pruning and Quantization with Projected Gradient Descent, https://arxiv.org/pdf/2506.10205, 2025-06-11
2025-11-09 20:54:25,741 - INFO - root - Page:2, Index:29, Q-SAM2: Accurate Quantization for Segment Anything Model 2, https://arxiv.org/pdf/2506.09782, 2025-06-11
2025-11-09 20:54:25,741 - INFO - root - Page:2, Index:30, Unifying Block-wise PTQ and Distillation-based QAT for Progressive Quantization toward 2-bit Instruction-Tuned LLMs, https://arxiv.org/pdf/2506.09104, 2025-06-10
2025-11-09 20:54:25,742 - INFO - root - Page:2, Index:31, Implementing Keyword Spotting on the MCUX947 Microcontroller with Integrated NPU, https://arxiv.org/pdf/2506.08911, 2025-06-10
2025-11-09 20:54:25,742 - INFO - root - Page:2, Index:32, POLARON: Precision-aware On-device Learning and Adaptive Runtime-cONfigurable AI acceleration, https://arxiv.org/pdf/2506.08785, 2025-06-10
2025-11-09 20:54:25,743 - INFO - root - Page:2, Index:33, MoQAE: Mixed-Precision Quantization for Long-Context LLM Inference via Mixture of Quantization-Aware Experts, https://arxiv.org/pdf/2506.07533, 2025-06-09
2025-11-09 20:54:25,743 - INFO - root - Page:2, Index:34, BitVLA: 1-bit Vision-Language-Action Models for Robotics Manipulation, https://arxiv.org/pdf/2506.07530, 2025-06-09
2025-11-09 20:54:25,744 - INFO - root - Page:2, Index:35, RecGPT: A Foundation Model for Sequential Recommendation, https://arxiv.org/pdf/2506.06270, 2025-06-12
2025-11-09 20:54:25,748 - INFO - root - Page:2, Index:36, FPSAttention: Training-Aware FP8 and Sparsity Co-Design for Fast Video Diffusion, https://arxiv.org/pdf/2506.04648, 2025-06-05
2025-11-09 20:54:25,748 - INFO - root - Page:2, Index:37, BitTTS: Highly Compact Text-to-Speech Using 1.58-bit Quantization and Weight Indexing, https://arxiv.org/pdf/2506.03515, 2025-06-03
2025-11-09 20:54:25,749 - INFO - root - Page:2, Index:38, ShapeLLM-Omni: A Native Multimodal LLM for 3D Generation and Understanding, https://arxiv.org/pdf/2506.01853, 2025-06-02
2025-11-09 20:54:25,749 - INFO - root - Page:2, Index:39, Movable Antenna Enhanced Federated Fine-Tuning of Large Language Models via Hybrid Client Selection Optimization, https://arxiv.org/pdf/2506.00011, 2025-10-26
2025-11-09 20:54:25,750 - INFO - root - Page:2, Index:40, Running Conventional Automatic Speech Recognition on Memristor Hardware: A Simulated Approach, https://arxiv.org/pdf/2505.24721, 2025-05-30
2025-11-09 20:54:25,750 - INFO - root - Page:2, Index:41, GARLIC: GAussian Representation LearnIng for spaCe partitioning, https://arxiv.org/pdf/2505.24608, 2025-10-02
2025-11-09 20:54:25,751 - INFO - root - Page:2, Index:42, AutoChemSchematic AI: Agentic Physics-Aware Automation for Chemical Manufacturing Scale-Up, https://arxiv.org/pdf/2505.24584, 2025-08-18
2025-11-09 20:54:25,751 - INFO - root - Page:2, Index:43, Model-Preserving Adaptive Rounding, https://arxiv.org/pdf/2505.22988, 2025-09-25
2025-11-09 20:54:25,753 - INFO - root - Page:2, Index:44, Highly Efficient and Effective LLMs with Multi-Boolean Architectures, https://arxiv.org/pdf/2505.22811, 2025-10-03
2025-11-09 20:54:25,774 - INFO - root - Page:2, Index:45, Pioneering 4-Bit FP Quantization for Diffusion Models: Mixup-Sign Quantization and Timestep-Aware Fine-Tuning, https://arxiv.org/pdf/2505.21591, 2025-05-27
2025-11-09 20:54:25,774 - INFO - root - Page:2, Index:46, Frequency Composition for Compressed and Domain-Adaptive Neural Networks, https://arxiv.org/pdf/2505.20890, 2025-05-27
2025-11-09 20:54:25,774 - INFO - root - Page:2, Index:47, MoPFormer: Motion-Primitive Transformer for Wearable-Sensor Activity Recognition, https://arxiv.org/pdf/2505.20744, 2025-10-27
2025-11-09 20:54:25,775 - INFO - root - Page:2, Index:48, Optimizing edge AI models on HPC systems with the edge in the loop, https://arxiv.org/pdf/2505.19995, 2025-05-26
2025-11-09 20:54:25,775 - INFO - root - Fetching page 4 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=150
2025-11-09 20:54:33,499 - INFO - root - get_all_titles_from_web 
2025-11-09 20:54:33,500 - INFO - root - Page:3, Index:0, DPASyn: Mechanism-Aware Drug Synergy Prediction via Dual Attention and Precision-Aware Quantization, https://arxiv.org/pdf/2505.19144, 2025-09-20
2025-11-09 20:54:33,500 - INFO - root - Page:3, Index:1, Reducing Storage of Pretrained Neural Networks by Rate-Constrained Quantization and Entropy Coding, https://arxiv.org/pdf/2505.18758, 2025-05-24
2025-11-09 20:54:33,500 - INFO - root - Page:3, Index:2, Beyond Discreteness: Finite-Sample Analysis of Straight-Through Estimator for Quantization, https://arxiv.org/pdf/2505.18113, 2025-05-23
2025-11-09 20:54:33,501 - INFO - root - Page:3, Index:3, Automating Versatile Time-Series Analysis with Tiny Transformers on Embedded FPGAs, https://arxiv.org/pdf/2505.17662, 2025-09-19
2025-11-09 20:54:33,501 - INFO - root - Page:3, Index:4, FPQVAR: Floating Point Quantization for Visual Autoregressive Model with FPGA Hardware Co-design, https://arxiv.org/pdf/2505.16335, 2025-05-22
2025-11-09 20:54:33,501 - INFO - root - Page:3, Index:5, Saliency-Aware Quantized Imitation Learning for Efficient Robotic Control, https://arxiv.org/pdf/2505.15304, 2025-05-30
2025-11-09 20:54:33,502 - INFO - root - Page:3, Index:6, Scaling Law for Quantization-Aware Training, https://arxiv.org/pdf/2505.14302, 2025-05-20
2025-11-09 20:54:33,503 - INFO - root - Page:3, Index:7, Automatic mixed precision for optimizing gained time with constrained loss mean-squared-error based on model partition to sequential sub-graphs, https://arxiv.org/pdf/2505.13060, 2025-05-19
2025-11-09 20:54:33,503 - INFO - root - Page:3, Index:8, Deep Unfolding with Kernel-based Quantization in MIMO Detection, https://arxiv.org/pdf/2505.12736, 2025-05-19
2025-11-09 20:54:33,504 - INFO - root - Page:3, Index:9, FedHQ: Hybrid Runtime Quantization for Federated Learning, https://arxiv.org/pdf/2505.11982, 2025-05-17
2025-11-09 20:54:33,504 - INFO - root - Page:3, Index:10, QVGen: Pushing the Limit of Quantized Video Generative Models, https://arxiv.org/pdf/2505.11497, 2025-09-27
2025-11-09 20:54:33,504 - INFO - root - Page:3, Index:11, EA-3DGS: Efficient and Adaptive 3D Gaussians with Highly Enhanced Quality for outdoor scenes, https://arxiv.org/pdf/2505.10787, 2025-05-15
2025-11-09 20:54:33,505 - INFO - root - Page:3, Index:12, ITERA-LLM: Boosting Sub-8-Bit Large Language Model Inference via Iterative Tensor Decomposition, https://arxiv.org/pdf/2505.08981, 2025-05-13
2025-11-09 20:54:33,505 - INFO - root - Page:3, Index:13, PROM: Prioritize Reduction of Multiplications Over Lower Bit-Widths for Efficient CNNs, https://arxiv.org/pdf/2505.03254, 2025-08-06
2025-11-09 20:54:33,505 - INFO - root - Page:3, Index:14, ICQuant: Index Coding enables Low-bit LLM Quantization, https://arxiv.org/pdf/2505.00850, 2025-08-24
2025-11-09 20:54:33,507 - INFO - root - Page:3, Index:15, Enhancing Ultra-Low-Bit Quantization of Large Language Models Through Saliency-Aware Partial Retraining, https://arxiv.org/pdf/2504.13932, 2025-07-30
2025-11-09 20:54:33,508 - INFO - root - Page:3, Index:16, Achieving binary weight and activation for LLMs using Post-Training Quantization, https://arxiv.org/pdf/2504.05352, 2025-06-30
2025-11-09 20:54:33,508 - INFO - root - Page:3, Index:17, Wireless Hearables With Programmable Speech AI Accelerators, https://arxiv.org/pdf/2503.18698, 2025-10-21
2025-11-09 20:54:33,509 - INFO - root - Page:3, Index:18, GranQ: Efficient Channel-wise Quantization via Vectorized Pre-Scaling for Zero-Shot QAT, https://arxiv.org/pdf/2503.18339, 2025-10-15
2025-11-09 20:54:33,509 - INFO - root - Page:3, Index:19, CompMarkGS: Robust Watermarking for Compressed 3D Gaussian Splatting, https://arxiv.org/pdf/2503.12836, 2025-09-29
2025-11-09 20:54:33,509 - INFO - root - Page:3, Index:20, AHCPTQ: Accurate and Hardware-Compatible Post-Training Quantization for Segment Anything Model, https://arxiv.org/pdf/2503.03088, 2025-07-11
2025-11-09 20:54:33,510 - INFO - root - Page:3, Index:21, Teaching Metric Distance to Discrete Autoregressive Language Models, https://arxiv.org/pdf/2503.02379, 2025-10-07
2025-11-09 20:54:33,512 - INFO - root - Page:3, Index:22, Regularization-based Framework for Quantization-, Fault- and Variability-Aware Training, https://arxiv.org/pdf/2503.01297, 2025-07-12
2025-11-09 20:54:33,513 - INFO - root - Fetching page 5 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=200
2025-11-09 20:54:39,936 - INFO - root - get_all_titles_from_web 
2025-11-09 20:54:39,937 - INFO - root - Page:4, Index:0, Investigating the Impact of Quantization Methods on the Safety and Reliability of Large Language Models, https://arxiv.org/pdf/2502.15799, 2025-06-29
2025-11-09 20:54:39,937 - INFO - root - Page:4, Index:1, Rotate, Clip, and Partition: Towards W2A4KV4 Quantization by Integrating Rotation and Learnable Non-uniform Quantizer, https://arxiv.org/pdf/2502.15779, 2025-09-01
2025-11-09 20:54:39,937 - INFO - root - Page:4, Index:2, RoSTE: An Efficient Quantization-Aware Supervised Fine-Tuning Approach for Large Language Models, https://arxiv.org/pdf/2502.09003, 2025-06-05
2025-11-09 20:54:39,937 - INFO - root - Page:4, Index:3, Spatial Degradation-Aware and Temporal Consistent Diffusion Model for Compressed Video Super-Resolution, https://arxiv.org/pdf/2502.07381, 2025-06-27
2025-11-09 20:54:39,938 - INFO - root - Page:4, Index:4, QuEST: Stable Training of LLMs with 1-Bit Weights and Activations, https://arxiv.org/pdf/2502.05003, 2025-06-10
2025-11-09 20:54:39,938 - INFO - root - Page:4, Index:5, HALO: Hadamard-Assisted Lower-Precision Optimization for LLMs, https://arxiv.org/pdf/2501.02625, 2025-11-05
2025-11-09 20:54:39,938 - INFO - root - Page:4, Index:6, TAR3D: Creating High-Quality 3D Assets via Next-Part Prediction, https://arxiv.org/pdf/2412.16919, 2025-08-08
2025-11-09 20:54:39,939 - INFO - root - Page:4, Index:7, Training Multi-Layer Binary Neural Networks With Local Binary Error Signals, https://arxiv.org/pdf/2412.00119, 2025-08-05
2025-11-09 20:54:39,939 - INFO - root - Page:4, Index:8, Scaling Large-scale GNN Training to Thousands of Processors on CPU-based Supercomputers, https://arxiv.org/pdf/2411.16025, 2025-05-26
2025-11-09 20:54:39,939 - INFO - root - Page:4, Index:9, HAFLQ: Heterogeneous Adaptive Federated LoRA Fine-tuned LLM with Quantization, https://arxiv.org/pdf/2411.06581, 2025-05-16
2025-11-09 20:54:39,939 - INFO - root - Fetching page 6 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=250
2025-11-09 20:54:47,345 - INFO - root - get_all_titles_from_web 
2025-11-09 20:54:47,345 - INFO - root - Page:5, Index:0, Gradient-Free Training of Quantized Neural Networks, https://arxiv.org/pdf/2410.09734, 2025-09-29
2025-11-09 20:54:47,346 - INFO - root - Page:5, Index:1, QT-DoG: Quantization-aware Training for Domain Generalization, https://arxiv.org/pdf/2410.06020, 2025-06-26
2025-11-09 20:54:47,346 - INFO - root - Page:5, Index:2, Constraint Guided Model Quantization of Neural Networks, https://arxiv.org/pdf/2409.20138, 2025-09-12
2025-11-09 20:54:47,347 - INFO - root - Page:5, Index:3, Accumulator-Aware Post-Training Quantization for Large Language Models, https://arxiv.org/pdf/2409.17092, 2025-07-30
2025-11-09 20:54:47,347 - INFO - root - Page:5, Index:4, DilateQuant: Accurate and Efficient Diffusion Quantization via Weight Dilation, https://arxiv.org/pdf/2409.14307, 2025-07-09
2025-11-09 20:54:47,347 - INFO - root - Page:5, Index:5, Robust Training of Neural Networks at Arbitrary Precision and Sparsity, https://arxiv.org/pdf/2409.09245, 2025-09-23
2025-11-09 20:54:47,347 - INFO - root - Page:5, Index:6, VQ-CTAP: Cross-Modal Fine-Grained Sequence Representation Learning for Speech Processing, https://arxiv.org/pdf/2408.05758, 2025-05-27
2025-11-09 20:54:47,348 - INFO - root - Page:5, Index:7, DopQ-ViT: Towards Distribution-Friendly and Outlier-Aware Post-Training Quantization for Vision Transformers, https://arxiv.org/pdf/2408.03291, 2025-06-19
2025-11-09 20:54:47,349 - INFO - root - Page:5, Index:8, Temporal Feature Matters: A Framework for Diffusion Model Quantization, https://arxiv.org/pdf/2407.19547, 2025-07-11
2025-11-09 20:54:47,351 - INFO - root - Page:5, Index:9, EfficientQAT: Efficient Quantization-Aware Training for Large Language Models, https://arxiv.org/pdf/2407.11062, 2025-05-19
2025-11-09 20:54:47,351 - INFO - root - Page:5, Index:10, Integer-only Quantized Transformers for Embedded FPGA-based Time-series Forecasting in AIoT, https://arxiv.org/pdf/2407.11041, 2025-10-31
2025-11-09 20:54:47,352 - INFO - root - Fetching page 7 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=300
2025-11-09 20:54:53,912 - INFO - root - get_all_titles_from_web 
2025-11-09 20:54:53,912 - INFO - root - Page:6, Index:0, BoA: Attention-aware Post-training Quantization without Backpropagation, https://arxiv.org/pdf/2406.13474, 2025-06-06
2025-11-09 20:54:53,913 - INFO - root - Page:6, Index:1, A Rescaling-Invariant Lipschitz Bound Based on Path-Metrics for Modern ReLU Network Parameterizations, https://arxiv.org/pdf/2405.15006, 2025-06-13
2025-11-09 20:54:53,913 - INFO - root - Page:6, Index:2, Scheduling Weight Transitions for Quantization-Aware Training, https://arxiv.org/pdf/2404.19248, 2025-10-01
2025-11-09 20:54:53,913 - INFO - root - Page:6, Index:3, GPTVQ: The Blessing of Dimensionality for LLM Quantization, https://arxiv.org/pdf/2402.15319, 2025-06-03
2025-11-09 20:54:53,913 - INFO - root - Fetching page 8 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=350
2025-11-09 20:55:01,153 - INFO - root - get_all_titles_from_web 
2025-11-09 20:55:01,153 - INFO - root - Page:7, Index:0, Squat: Quant Small Language Models on the Edge, https://arxiv.org/pdf/2402.10787, 2025-07-01
2025-11-09 20:55:01,154 - INFO - root - Page:7, Index:1, L4Q: Parameter Efficient Quantization-Aware Fine-Tuning on Large Language Models, https://arxiv.org/pdf/2402.04902, 2025-07-21
2025-11-09 20:55:01,154 - INFO - root - Fetching page 9 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=400
2025-11-09 20:55:07,954 - INFO - root - ------------------------------------------------------------------------------------------------------------------------
2025-11-09 20:55:07,955 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\A Quantized VAE-MLP Botnet Detection Model_ A Systematic Evaluation of Quantizat.pdf
2025-11-09 20:55:07,958 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\FP8-Flow-MoE_ A Casting-Free FP8 Recipe without Double Quantization Error.pdf
2025-11-09 20:55:07,959 - INFO - root - 跳过已处理论文 A Quantized VAE-MLP Botnet Detection Model: A Systematic Evaluation of Quantization-Aware Training and Post-Training Quantization Strategies：d:\ChatPaper\academic Papers\Quantization-Aware-Training\A Quantized VAE-MLP Botnet Detection Model_ A Systematic Evaluation of Quantizat.pdf
2025-11-09 20:55:07,959 - INFO - root - 跳过已处理论文 FP8-Flow-MoE: A Casting-Free FP8 Recipe without Double Quantization Error：d:\ChatPaper\academic Papers\Quantization-Aware-Training\FP8-Flow-MoE_ A Casting-Free FP8 Recipe without Double Quantization Error.pdf
2025-11-09 20:55:07,960 - INFO - root - summary time: 68.21 seconds
2025-11-09 20:58:06,281 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-09 20:58:06,283 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-09 20:58:06,286 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-09 20:58:07,080 - INFO - root - LLMClientManager: 指定使用客户端: Gemini
2025-11-09 20:58:08,427 - INFO - root - GeminiClient: trying model gemini-2.5-flash
2025-11-09 20:58:11,567 - INFO - root - GeminiClient: initialized model gemini-2.5-flash
2025-11-09 20:58:11,568 - INFO - root - LLMClientManager: Gemini 客户端初始化成功
2025-11-09 20:58:11,568 - INFO - root - LLMClientManager: switched to Gemini client
2025-11-09 20:58:11,568 - INFO - root - 已手动切换到 LLM 客户端: Gemini
2025-11-09 20:58:11,569 - INFO - root - 使用 LLM 模型: gemini-2.5-flash
2025-11-09 20:58:11,569 - INFO - root - 可用客户端: ['Gemini']
2025-11-09 20:58:11,570 - INFO - root - === 运行配置 ===
2025-11-09 20:58:11,570 - INFO - root - 处理模式: arxiv在线搜索
2025-11-09 20:58:11,570 - INFO - root - 关键词: QAT
2025-11-09 20:58:11,570 - INFO - root - 查询: Quantization-Aware-Training
2025-11-09 20:58:11,571 - INFO - root - 排序: None
2025-11-09 20:58:11,572 - INFO - root - 最近天数: 180
2025-11-09 20:58:11,573 - INFO - root - 最大处理数量: 40
2025-11-09 20:58:11,573 - INFO - root - 保存图片: 是
2025-11-09 20:58:11,573 - INFO - root - 输出语言: 中文
2025-11-09 20:58:11,574 - INFO - root - 强制重新处理: 否
2025-11-09 20:58:11,575 - INFO - root - ====================
2025-11-09 20:58:11,575 - INFO - root - 使用 arXiv 搜索模式（通过 chat_arxiv 模块获取）
2025-11-09 20:58:11,575 - INFO - root - Fetching page 1 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50
2025-11-09 20:58:18,450 - INFO - root - get_all_titles_from_web 
2025-11-09 20:58:18,450 - INFO - root - Page:0, Index:0, A Quantized VAE-MLP Botnet Detection Model: A Systematic Evaluation of Quantization-Aware Training and Post-Training Quantization Strategies, https://arxiv.org/pdf/2511.03201, 2025-11-05
2025-11-09 20:58:18,451 - INFO - root - Page:0, Index:1, FP8-Flow-MoE: A Casting-Free FP8 Recipe without Double Quantization Error, https://arxiv.org/pdf/2511.02302, 2025-11-04
2025-11-09 20:58:18,451 - INFO - root - Page:0, Index:2, Outlier-Aware Post-Training Quantization for Image Super-Resolution, https://arxiv.org/pdf/2511.00682, 2025-11-01
2025-11-09 20:58:18,451 - INFO - root - Page:0, Index:3, Evaluation of Wafer-Scale SOT-MRAM for Analog Crossbar Array Applications, https://arxiv.org/pdf/2510.25853, 2025-11-03
2025-11-09 20:58:18,452 - INFO - root - Page:0, Index:4, Improving the Straight-Through Estimator with Zeroth-Order Information, https://arxiv.org/pdf/2510.23926, 2025-10-27
2025-11-09 20:58:18,452 - INFO - root - Page:0, Index:5, Real-Time Semantic Segmentation on FPGA for Autonomous Vehicles Using LMIINet with the CGRA4ML Framework, https://arxiv.org/pdf/2510.22243, 2025-10-25
2025-11-09 20:58:18,453 - INFO - root - Page:0, Index:6, TernaryCLIP: Efficiently Compressing Vision-Language Models with Ternary Weights and Distilled Knowledge, https://arxiv.org/pdf/2510.21879, 2025-10-23
2025-11-09 20:58:18,453 - INFO - root - Page:0, Index:7, KARIPAP: Quantum-Inspired Tensor Network Compression of Large Language Models Using Infinite Projected Entangled Pair States and Tensor Renormalization Group, https://arxiv.org/pdf/2510.21844, 2025-10-22
2025-11-09 20:58:18,453 - INFO - root - Page:0, Index:8, A Convergence Analysis of Adaptive Optimizers under Floating-point Quantization, https://arxiv.org/pdf/2510.21314, 2025-10-24
2025-11-09 20:58:18,455 - INFO - root - Page:0, Index:9, Adaptive Distribution-aware Quantization for Mixed-Precision Neural Networks, https://arxiv.org/pdf/2510.19760, 2025-10-22
2025-11-09 20:58:18,455 - INFO - root - Page:0, Index:10, CAGE: Curvature-Aware Gradient Estimation For Accurate Quantization-Aware Training, https://arxiv.org/pdf/2510.18784, 2025-10-21
2025-11-09 20:58:18,455 - INFO - root - Page:0, Index:11, Mixed-Precision Quantization for Language Models: Techniques and Prospects, https://arxiv.org/pdf/2510.16805, 2025-10-19
2025-11-09 20:58:18,456 - INFO - root - Page:0, Index:12, SPLite Hand: Sparsity-Aware Lightweight 3D Hand Pose Estimation, https://arxiv.org/pdf/2510.16396, 2025-10-30
2025-11-09 20:58:18,456 - INFO - root - Page:0, Index:13, CTR-LoRA: Curvature-Aware and Trust-Region Guided Low-Rank Adaptation for Large Language Models, https://arxiv.org/pdf/2510.15962, 2025-10-11
2025-11-09 20:58:18,457 - INFO - root - Page:0, Index:14, SANR: Scene-Aware Neural Representation for Light Field Image Compression with Rate-Distortion Optimization, https://arxiv.org/pdf/2510.15775, 2025-10-17
2025-11-09 20:58:18,457 - INFO - root - Page:0, Index:15, SpikeFit: Towards Optimal Deployment of Spiking Networks on Neuromorphic Hardware, https://arxiv.org/pdf/2510.15542, 2025-10-31
2025-11-09 20:58:18,458 - INFO - root - Page:0, Index:16, GRank: Towards Target-Aware and Streamlined Industrial Retrieval with a Generate-Rank Framework, https://arxiv.org/pdf/2510.15299, 2025-10-17
2025-11-09 20:58:18,458 - INFO - root - Page:0, Index:17, SaLon3R: Structure-aware Long-term Generalizable 3D Reconstruction from Unposed Images, https://arxiv.org/pdf/2510.15072, 2025-10-16
2025-11-09 20:58:18,459 - INFO - root - Page:0, Index:18, FraQAT: Quantization Aware Training with Fractional bits, https://arxiv.org/pdf/2510.14823, 2025-10-16
2025-11-09 20:58:18,459 - INFO - root - Page:0, Index:19, Computing-In-Memory Aware Model Adaption For Edge Devices, https://arxiv.org/pdf/2510.14379, 2025-10-16
2025-11-09 20:58:18,461 - INFO - root - Page:0, Index:20, Invited Paper: BitMedViT: Ternary-Quantized Vision Transformer for Medical AI Assistants on the Edge, https://arxiv.org/pdf/2510.13760, 2025-11-04
2025-11-09 20:58:18,462 - INFO - root - Page:0, Index:21, NeuroRVQ: Multi-Scale EEG Tokenization for Generative Large Brainwave Models, https://arxiv.org/pdf/2510.13068, 2025-10-14
2025-11-09 20:58:18,463 - INFO - root - Page:0, Index:22, Detect Anything via Next Point Prediction, https://arxiv.org/pdf/2510.12798, 2025-10-14
2025-11-09 20:58:18,464 - INFO - root - Page:0, Index:23, AndesVL Technical Report: An Efficient Mobile-side Multimodal Large Language Model, https://arxiv.org/pdf/2510.11496, 2025-10-14
2025-11-09 20:58:18,464 - INFO - root - Page:0, Index:24, Rescaling-Aware Training for Efficient Deployment of Deep Learning Models on Full-Integer Hardware, https://arxiv.org/pdf/2510.11484, 2025-10-13
2025-11-09 20:58:18,464 - INFO - root - Page:0, Index:25, SASER: Stego attacks on open-source LLMs, https://arxiv.org/pdf/2510.10486, 2025-10-12
2025-11-09 20:58:18,466 - INFO - root - Page:0, Index:26, Ultralytics YOLO Evolution: An Overview of YOLO26, YOLO11, YOLOv8 and YOLOv5 Object Detectors for Computer Vision and Pattern Recognition, https://arxiv.org/pdf/2510.09653, 2025-10-15
2025-11-09 20:58:18,466 - INFO - root - Page:0, Index:27, A Theoretically-Grounded Codebook for Digital Semantic Communications, https://arxiv.org/pdf/2510.07108, 2025-10-14
2025-11-09 20:58:18,467 - INFO - root - Page:0, Index:28, QuantDemoire: Quantization with Outlier Aware for Image Demoiréing, https://arxiv.org/pdf/2510.04066, 2025-10-05
2025-11-09 20:58:18,469 - INFO - root - Page:0, Index:29, Adaptively Sampling-Reusing-Mixing Decomposed Gradients to Speed Up Sharpness Aware Minimization, https://arxiv.org/pdf/2510.03763, 2025-10-04
2025-11-09 20:58:18,474 - INFO - root - Page:0, Index:30, Quant-dLLM: Post-Training Extreme Low-Bit Quantization for Diffusion Large Language Models, https://arxiv.org/pdf/2510.03274, 2025-09-27
2025-11-09 20:58:18,474 - INFO - root - Page:0, Index:31, PT$^2$-LLM: Post-Training Ternarization for Large Language Models, https://arxiv.org/pdf/2510.03267, 2025-09-26
2025-11-09 20:58:18,475 - INFO - root - Page:0, Index:32, Purrception: Variational Flow Matching for Vector-Quantized Image Generation, https://arxiv.org/pdf/2510.01478, 2025-10-01
2025-11-09 20:58:18,476 - INFO - root - Page:0, Index:33, Post-Training Quantization for Audio Diffusion Transformers, https://arxiv.org/pdf/2510.00313, 2025-09-30
2025-11-09 20:58:18,477 - INFO - root - Page:0, Index:34, Rethinking RoPE Scaling in Quantized LLM: Theory, Outlier, and Channel-Band Analysis with Weight Rescaling, https://arxiv.org/pdf/2510.00028, 2025-09-25
2025-11-09 20:58:18,477 - INFO - root - Page:0, Index:35, Post-Training Quantization via Residual Truncation and Zero Suppression for Diffusion Models, https://arxiv.org/pdf/2509.26436, 2025-09-30
2025-11-09 20:58:18,483 - INFO - root - Page:0, Index:36, Cat: Post-Training Quantization Error Reduction via Cluster-based Affine Transformation, https://arxiv.org/pdf/2509.26277, 2025-10-07
2025-11-09 20:58:18,484 - INFO - root - Page:0, Index:37, CAST: Continuous and Differentiable Semi-Structured Sparsity-Aware Training for Large Language Models, https://arxiv.org/pdf/2509.25996, 2025-09-30
2025-11-09 20:58:18,484 - INFO - root - Page:0, Index:38, Norm-Q: Effective Compression Method for Hidden Markov Models in Neuro-Symbolic Applications, https://arxiv.org/pdf/2509.25439, 2025-09-29
2025-11-09 20:58:18,484 - INFO - root - Page:0, Index:39, On-the-Fly Adaptation to Quantization: Configuration-Aware LoRA for Efficient Fine-Tuning of Quantized LLMs, https://arxiv.org/pdf/2509.25214, 2025-09-22
2025-11-09 20:58:18,485 - INFO - root - Page:0, Index:40, VoxCPM: Tokenizer-Free TTS for Context-Aware Speech Generation and True-to-Life Voice Cloning, https://arxiv.org/pdf/2509.24650, 2025-09-29
2025-11-09 20:58:18,485 - INFO - root - Page:0, Index:41, S$^2$NN: Sub-bit Spiking Neural Networks, https://arxiv.org/pdf/2509.24266, 2025-10-24
2025-11-09 20:58:18,486 - INFO - root - Page:0, Index:42, Tequila: Trapping-free Ternary Quantization for Large Language Models, https://arxiv.org/pdf/2509.23809, 2025-10-17
2025-11-09 20:58:18,486 - INFO - root - Page:0, Index:43, Texture Vector-Quantization and Reconstruction Aware Prediction for Generative Super-Resolution, https://arxiv.org/pdf/2509.23774, 2025-09-30
2025-11-09 20:58:18,486 - INFO - root - Page:0, Index:44, RobuQ: Pushing DiTs to W1.58A2 via Robust Activation Quantization, https://arxiv.org/pdf/2509.23582, 2025-09-27
2025-11-09 20:58:18,487 - INFO - root - Page:0, Index:45, Beyond Outliers: A Study of Optimizers Under Quantization, https://arxiv.org/pdf/2509.23500, 2025-10-02
2025-11-09 20:58:18,487 - INFO - root - Page:0, Index:46, Compute-Optimal Quantization-Aware Training, https://arxiv.org/pdf/2509.22935, 2025-09-26
2025-11-09 20:58:18,487 - INFO - root - Page:0, Index:47, COSPADI: Compressing LLMs via Calibration-Guided Sparse Dictionary Learning, https://arxiv.org/pdf/2509.22075, 2025-10-06
2025-11-09 20:58:18,488 - INFO - root - Page:0, Index:48, SlimDiff: Training-Free, Activation-Guided Hands-free Slimming of Diffusion Models, https://arxiv.org/pdf/2509.21498, 2025-09-25
2025-11-09 20:58:18,489 - INFO - root - Page:0, Index:49, Quantized Visual Geometry Grounded Transformer, https://arxiv.org/pdf/2509.21302, 2025-09-29
2025-11-09 20:58:18,492 - INFO - root - Fetching page 2 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=50
2025-11-09 20:58:25,321 - INFO - root - get_all_titles_from_web 
2025-11-09 20:58:25,323 - INFO - root - Page:1, Index:0, Can Less Precise Be More Reliable? A Systematic Evaluation of Quantization's Impact on CLIP Beyond Accuracy, https://arxiv.org/pdf/2509.21173, 2025-10-27
2025-11-09 20:58:25,324 - INFO - root - Page:1, Index:1, Punching Above Precision: Small Quantized Model Distillation with Learnable Regularizer, https://arxiv.org/pdf/2509.20854, 2025-09-25
2025-11-09 20:58:25,325 - INFO - root - Page:1, Index:2, TinyEcoWeedNet: Edge Efficient Real-Time Aerial Agricultural Weed Detection, https://arxiv.org/pdf/2509.18193, 2025-09-19
2025-11-09 20:58:25,325 - INFO - root - Page:1, Index:3, SBVR: Summation of BitVector Representation for Efficient LLM Quantization, https://arxiv.org/pdf/2509.18172, 2025-09-17
2025-11-09 20:58:25,326 - INFO - root - Page:1, Index:4, QWHA: Quantization-Aware Walsh-Hadamard Adaptation for Parameter-Efficient Fine-Tuning on Large Language Models, https://arxiv.org/pdf/2509.17428, 2025-09-26
2025-11-09 20:58:25,327 - INFO - root - Page:1, Index:5, PTQTP: Post-Training Quantization to Trit-Planes for Large Language Models, https://arxiv.org/pdf/2509.16989, 2025-10-28
2025-11-09 20:58:25,329 - INFO - root - Page:1, Index:6, MEC-Quant: Maximum Entropy Coding for Extremely Low Bit Quantization-Aware Training, https://arxiv.org/pdf/2509.15514, 2025-09-18
2025-11-09 20:58:25,330 - INFO - root - Page:1, Index:7, Q-ROAR: Outlier-Aware Rescaling for RoPE Position Interpolation in Quantized Long-Context LLMs, https://arxiv.org/pdf/2509.14391, 2025-09-17
2025-11-09 20:58:25,332 - INFO - root - Page:1, Index:8, Efficient Quantization-Aware Neural Receivers: Beyond Post-Training Quantization, https://arxiv.org/pdf/2509.13786, 2025-09-19
2025-11-09 20:58:25,341 - INFO - root - Page:1, Index:9, Rate-Distortion Limits for Multimodal Retrieval: Theory, Optimal Codes, and Finite-Sample Guarantees, https://arxiv.org/pdf/2509.11054, 2025-09-13
2025-11-09 20:58:25,345 - INFO - root - Page:1, Index:10, SQAP-VLA: A Synergistic Quantization-Aware Pruning Framework for High-Performance Vision-Language-Action Models, https://arxiv.org/pdf/2509.09090, 2025-09-10
2025-11-09 20:58:25,347 - INFO - root - Page:1, Index:11, CSI Compression Beyond Latents: End-to-End Hybrid Attention-CNN Networks with Entropy Regularization, https://arxiv.org/pdf/2509.08776, 2025-09-10
2025-11-09 20:58:25,348 - INFO - root - Page:1, Index:12, Explaining How Quantization Disparately Skews a Model, https://arxiv.org/pdf/2509.07222, 2025-09-08
2025-11-09 20:58:25,348 - INFO - root - Page:1, Index:13, LoaQ: Layer-wise Output Approximation Quantization, https://arxiv.org/pdf/2509.06297, 2025-09-07
2025-11-09 20:58:25,350 - INFO - root - Page:1, Index:14, FineServe: Precision-Aware KV Slab and Two-Level Scheduling for Heterogeneous Precision LLM Serving, https://arxiv.org/pdf/2509.06261, 2025-09-14
2025-11-09 20:58:25,350 - INFO - root - Page:1, Index:15, Sensitivity-Aware Post-Training Quantization for Deep Neural Networks, https://arxiv.org/pdf/2509.05576, 2025-09-05
2025-11-09 20:58:25,351 - INFO - root - Page:1, Index:16, SuperSNN: A Hardware-Aware Framework for Physically Realizable, High-Performance Superconducting Spiking Neural Network Chips, https://arxiv.org/pdf/2509.05532, 2025-09-05
2025-11-09 20:58:25,351 - INFO - root - Page:1, Index:17, Data-Augmented Quantization-Aware Knowledge Distillation, https://arxiv.org/pdf/2509.03850, 2025-09-03
2025-11-09 20:58:25,353 - INFO - root - Page:1, Index:18, DPQuant: Efficient and Differentially-Private Model Training via Dynamic Quantization Scheduling, https://arxiv.org/pdf/2509.03472, 2025-09-03
2025-11-09 20:58:25,356 - INFO - root - Page:1, Index:19, Empowering Large Language Model for Sequential Recommendation via Multimodal Embeddings and Semantic IDs, https://arxiv.org/pdf/2509.02017, 2025-09-02
2025-11-09 20:58:25,357 - INFO - root - Page:1, Index:20, Q-Sched: Pushing the Boundaries of Few-Step Diffusion Models with Quantization-Aware Scheduling, https://arxiv.org/pdf/2509.01624, 2025-09-01
2025-11-09 20:58:25,357 - INFO - root - Page:1, Index:21, Quantization Meets OOD: Generalizable Quantization-aware Training from a Flatness Perspective, https://arxiv.org/pdf/2509.00859, 2025-08-31
2025-11-09 20:58:25,357 - INFO - root - Page:1, Index:22, Progressive Element-wise Gradient Estimation for Neural Network Quantization, https://arxiv.org/pdf/2509.00097, 2025-08-27
2025-11-09 20:58:25,359 - INFO - root - Page:1, Index:23, End-to-End On-Device Quantization-Aware Training for LLMs at Inference Cost, https://arxiv.org/pdf/2509.00031, 2025-09-29
2025-11-09 20:58:25,359 - INFO - root - Page:1, Index:24, Quantization Robustness to Input Degradations for Object Detection, https://arxiv.org/pdf/2508.19600, 2025-08-27
2025-11-09 20:58:25,359 - INFO - root - Page:1, Index:25, Scaling Laws for Task-Stratified Knowledge in Post-Training Quantized Large Language Models, https://arxiv.org/pdf/2508.18609, 2025-08-27
2025-11-09 20:58:25,360 - INFO - root - Page:1, Index:26, AQ-PCDSys: An Adaptive Quantized Planetary Crater Detection System for Autonomous Space Exploration, https://arxiv.org/pdf/2508.18025, 2025-08-25
2025-11-09 20:58:25,361 - INFO - root - Page:1, Index:27, TaDiCodec: Text-aware Diffusion Speech Tokenizer for Speech Language Modeling, https://arxiv.org/pdf/2508.16790, 2025-08-22
2025-11-09 20:58:25,362 - INFO - root - Page:1, Index:28, A Node-Aware Dynamic Quantization Approach for Graph Collaborative Filtering, https://arxiv.org/pdf/2508.16516, 2025-08-22
2025-11-09 20:58:25,365 - INFO - root - Page:1, Index:29, JEDI-linear: Fast and Efficient Graph Neural Networks for Jet Tagging on FPGAs, https://arxiv.org/pdf/2508.15468, 2025-08-21
2025-11-09 20:58:25,366 - INFO - root - Page:1, Index:30, MMQ: Multimodal Mixture-of-Quantization Tokenization for Semantic ID Generation and User Behavioral Adaptation, https://arxiv.org/pdf/2508.15281, 2025-08-21
2025-11-09 20:58:25,366 - INFO - root - Page:1, Index:31, DLLMQuant: Quantizing Diffusion-based Large Language Models, https://arxiv.org/pdf/2508.14090, 2025-08-25
2025-11-09 20:58:25,366 - INFO - root - Page:1, Index:32, Automated Energy-Aware Time-Series Model Deployment on Embedded FPGAs for Resilient Combined Sewer Overflow Management, https://arxiv.org/pdf/2508.13905, 2025-08-19
2025-11-09 20:58:25,368 - INFO - root - Page:1, Index:33, XR-NPE: High-Throughput Mixed-precision SIMD Neural Processing Engine for Extended Reality Perception Workloads, https://arxiv.org/pdf/2508.13049, 2025-08-18
2025-11-09 20:58:25,368 - INFO - root - Page:1, Index:34, Exploring Self-Supervised Audio Models for Generalized Anomalous Sound Detection, https://arxiv.org/pdf/2508.12230, 2025-08-17
2025-11-09 20:58:25,370 - INFO - root - Page:1, Index:35, TriQDef: Disrupting Semantic and Gradient Alignment to Prevent Adversarial Patch Transferability in Quantized Neural Networks, https://arxiv.org/pdf/2508.12132, 2025-08-16
2025-11-09 20:58:25,373 - INFO - root - Page:1, Index:36, Error Propagation Mechanisms and Compensation Strategies for Quantized Diffusion, https://arxiv.org/pdf/2508.12094, 2025-10-13
2025-11-09 20:58:25,375 - INFO - root - Page:1, Index:37, Extending Straight-Through Estimation for Robust Neural Networks on Analog CIM Hardware, https://arxiv.org/pdf/2508.11940, 2025-08-16
2025-11-09 20:58:25,375 - INFO - root - Page:1, Index:38, PTQAT: A Hybrid Parameter-Efficient Quantization Algorithm for 3D Perception Tasks, https://arxiv.org/pdf/2508.10557, 2025-08-15
2025-11-09 20:58:25,377 - INFO - root - Page:1, Index:39, MiCo: End-to-End Mixed Precision Neural Network Co-Exploration Framework for Edge AI, https://arxiv.org/pdf/2508.09500, 2025-08-13
2025-11-09 20:58:25,378 - INFO - root - Page:1, Index:40, SPARC: Soft Probabilistic Adaptive multi-interest Retrieval Model via Codebooks for recommender system, https://arxiv.org/pdf/2508.09090, 2025-08-12
2025-11-09 20:58:25,379 - INFO - root - Page:1, Index:41, Rethinking 1-bit Optimization Leveraging Pre-trained Large Language Models, https://arxiv.org/pdf/2508.06974, 2025-08-09
2025-11-09 20:58:25,380 - INFO - root - Page:1, Index:42, Efficient Deep Neural Receiver with Post-Training Quantization, https://arxiv.org/pdf/2508.06275, 2025-08-08
2025-11-09 20:58:25,381 - INFO - root - Page:1, Index:43, iFairy: the First 2-bit Complex LLM with All Parameters in $\{\pm1, \pm i\}$, https://arxiv.org/pdf/2508.05571, 2025-08-16
2025-11-09 20:58:25,381 - INFO - root - Page:1, Index:44, S$^2$Q-VDiT: Accurate Quantized Video Diffusion Transformer with Salient Data and Sparse Token Distillation, https://arxiv.org/pdf/2508.04016, 2025-10-27
2025-11-09 20:58:25,381 - INFO - root - Page:1, Index:45, LRQ-DiT: Log-Rotation Post-Training Quantization of Diffusion Transformers for Image and Video Generation, https://arxiv.org/pdf/2508.03485, 2025-09-23
2025-11-09 20:58:25,383 - INFO - root - Page:1, Index:46, VLMQ: Efficient Post-Training Quantization for Large Vision-Language Models via Hessian Augmentation, https://arxiv.org/pdf/2508.03351, 2025-08-05
2025-11-09 20:58:25,383 - INFO - root - Page:1, Index:47, TF-MLPNet: Tiny Real-Time Neural Speech Separation, https://arxiv.org/pdf/2508.03047, 2025-08-04
2025-11-09 20:58:25,384 - INFO - root - Page:1, Index:48, SaviorRec: Semantic-Behavior Alignment for Cold-Start Recommendation, https://arxiv.org/pdf/2508.01375, 2025-08-02
2025-11-09 20:58:25,384 - INFO - root - Page:1, Index:49, MixA-Q: Revisiting Activation Sparsity for Vision Transformers from a Mixed-Precision Quantization Perspective, https://arxiv.org/pdf/2507.19131, 2025-07-25
2025-11-09 20:58:25,384 - INFO - root - Fetching page 3 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=100
2025-11-09 20:58:32,730 - INFO - root - get_all_titles_from_web 
2025-11-09 20:58:32,730 - INFO - root - Page:2, Index:0, Enhancing Quantization-Aware Training on Edge Devices via Relative Entropy Coreset Selection and Cascaded Layer Correction, https://arxiv.org/pdf/2507.17768, 2025-07-16
2025-11-09 20:58:32,731 - INFO - root - Page:2, Index:1, SiLQ: Simple Large Language Model Quantization-Aware Training, https://arxiv.org/pdf/2507.16933, 2025-07-22
2025-11-09 20:58:32,731 - INFO - root - Page:2, Index:2, Task-Specific Zero-shot Quantization-Aware Training for Object Detection, https://arxiv.org/pdf/2507.16782, 2025-07-22
2025-11-09 20:58:32,731 - INFO - root - Page:2, Index:3, TorchAO: PyTorch-Native Training-to-Serving Model Optimization, https://arxiv.org/pdf/2507.16099, 2025-07-21
2025-11-09 20:58:32,731 - INFO - root - Page:2, Index:4, SegQuant: A Semantics-Aware and Generalizable Quantization Framework for Diffusion Models, https://arxiv.org/pdf/2507.14811, 2025-08-27
2025-11-09 20:58:32,732 - INFO - root - Page:2, Index:5, Apple Intelligence Foundation Language Models: Tech Report 2025, https://arxiv.org/pdf/2507.13575, 2025-08-27
2025-11-09 20:58:32,732 - INFO - root - Page:2, Index:6, Generative Multi-Target Cross-Domain Recommendation, https://arxiv.org/pdf/2507.12871, 2025-08-07
2025-11-09 20:58:32,732 - INFO - root - Page:2, Index:7, DAF: An Efficient End-to-End Dynamic Activation Framework for on-Device DNN Training, https://arxiv.org/pdf/2507.07149, 2025-07-09
2025-11-09 20:58:32,732 - INFO - root - Page:2, Index:8, Opto-ViT: Architecting a Near-Sensor Region of Interest-Aware Vision Transformer Accelerator with Silicon Photonics, https://arxiv.org/pdf/2507.07044, 2025-07-15
2025-11-09 20:58:32,733 - INFO - root - Page:2, Index:9, QS4D: Quantization-aware training for efficient hardware deployment of structured state-space sequential models, https://arxiv.org/pdf/2507.06079, 2025-07-08
2025-11-09 20:58:32,733 - INFO - root - Page:2, Index:10, GSVR: 2D Gaussian-based Video Representation for 800+ FPS with Hybrid Deformation Field, https://arxiv.org/pdf/2507.05594, 2025-07-07
2025-11-09 20:58:32,733 - INFO - root - Page:2, Index:11, Hita: Holistic Tokenizer for Autoregressive Image Generation, https://arxiv.org/pdf/2507.02358, 2025-07-11
2025-11-09 20:58:32,734 - INFO - root - Page:2, Index:12, QPART: Adaptive Model Quantization and Dynamic Workload Balancing for Accuracy-aware Edge Inference, https://arxiv.org/pdf/2506.23934, 2025-06-30
2025-11-09 20:58:32,734 - INFO - root - Page:2, Index:13, FedWSQ: Efficient Federated Learning with Weight Standardization and Distribution-Aware Non-Uniform Quantization, https://arxiv.org/pdf/2506.23516, 2025-07-21
2025-11-09 20:58:32,734 - INFO - root - Page:2, Index:14, Spectra 1.1: Scaling Laws and Efficient Inference for Ternary Language Models, https://arxiv.org/pdf/2506.23025, 2025-06-28
2025-11-09 20:58:32,734 - INFO - root - Page:2, Index:15, Joint Quantization and Pruning Neural Networks Approach: A Case Study on FSO Receivers, https://arxiv.org/pdf/2506.20084, 2025-06-24
2025-11-09 20:58:32,734 - INFO - root - Page:2, Index:16, Single-step Diffusion for Image Compression at Ultra-Low Bitrates, https://arxiv.org/pdf/2506.16572, 2025-09-22
2025-11-09 20:58:32,735 - INFO - root - Page:2, Index:17, LittleBit: Ultra Low-Bit Quantization via Latent Factorization, https://arxiv.org/pdf/2506.13771, 2025-10-28
2025-11-09 20:58:32,736 - INFO - root - Page:2, Index:18, MARCO: Hardware-Aware Neural Architecture Search for Edge Devices with Multi-Agent Reinforcement Learning and Conformal Prediction Filtering, https://arxiv.org/pdf/2506.13755, 2025-06-16
2025-11-09 20:58:32,736 - INFO - root - Page:2, Index:19, EAQuant: Enhancing Post-Training Quantization for MoE Models via Expert-Aware Optimization, https://arxiv.org/pdf/2506.13329, 2025-07-04
2025-11-09 20:58:32,737 - INFO - root - Page:2, Index:20, Towards Neural Audio Codec Source Parsing, https://arxiv.org/pdf/2506.12627, 2025-06-14
2025-11-09 20:58:32,746 - INFO - root - Page:2, Index:21, Quantizing Small-Scale State-Space Models for Edge AI, https://arxiv.org/pdf/2506.12480, 2025-06-14
2025-11-09 20:58:32,748 - INFO - root - Page:2, Index:22, EMLoC: Emulator-based Memory-efficient Fine-tuning with LoRA Correction, https://arxiv.org/pdf/2506.12015, 2025-06-13
2025-11-09 20:58:32,749 - INFO - root - Page:2, Index:23, Compression Aware Certified Training, https://arxiv.org/pdf/2506.11992, 2025-06-13
2025-11-09 20:58:32,750 - INFO - root - Page:2, Index:24, GPLQ: A General, Practical, and Lightning QAT Method for Vision Transformers, https://arxiv.org/pdf/2506.11784, 2025-06-13
2025-11-09 20:58:32,750 - INFO - root - Page:2, Index:25, TruncQuant: Truncation-Ready Quantization for DNNs with Flexible Weight Bit Precision, https://arxiv.org/pdf/2506.11431, 2025-06-12
2025-11-09 20:58:32,750 - INFO - root - Page:2, Index:26, EfficientQuant: An Efficient Post-Training Quantization for CNN-Transformer Hybrid Models on Edge Devices, https://arxiv.org/pdf/2506.11093, 2025-06-05
2025-11-09 20:58:32,751 - INFO - root - Page:2, Index:27, Starting Positions Matter: A Study on Better Weight Initialization for Neural Network Quantization, https://arxiv.org/pdf/2506.10463, 2025-06-12
2025-11-09 20:58:32,751 - INFO - root - Page:2, Index:28, AWP: Activation-Aware Weight Pruning and Quantization with Projected Gradient Descent, https://arxiv.org/pdf/2506.10205, 2025-06-11
2025-11-09 20:58:32,752 - INFO - root - Page:2, Index:29, Q-SAM2: Accurate Quantization for Segment Anything Model 2, https://arxiv.org/pdf/2506.09782, 2025-06-11
2025-11-09 20:58:32,752 - INFO - root - Page:2, Index:30, Unifying Block-wise PTQ and Distillation-based QAT for Progressive Quantization toward 2-bit Instruction-Tuned LLMs, https://arxiv.org/pdf/2506.09104, 2025-06-10
2025-11-09 20:58:32,752 - INFO - root - Page:2, Index:31, Implementing Keyword Spotting on the MCUX947 Microcontroller with Integrated NPU, https://arxiv.org/pdf/2506.08911, 2025-06-10
2025-11-09 20:58:32,755 - INFO - root - Page:2, Index:32, POLARON: Precision-aware On-device Learning and Adaptive Runtime-cONfigurable AI acceleration, https://arxiv.org/pdf/2506.08785, 2025-06-10
2025-11-09 20:58:32,758 - INFO - root - Page:2, Index:33, MoQAE: Mixed-Precision Quantization for Long-Context LLM Inference via Mixture of Quantization-Aware Experts, https://arxiv.org/pdf/2506.07533, 2025-06-09
2025-11-09 20:58:32,761 - INFO - root - Page:2, Index:34, BitVLA: 1-bit Vision-Language-Action Models for Robotics Manipulation, https://arxiv.org/pdf/2506.07530, 2025-06-09
2025-11-09 20:58:32,762 - INFO - root - Page:2, Index:35, RecGPT: A Foundation Model for Sequential Recommendation, https://arxiv.org/pdf/2506.06270, 2025-06-12
2025-11-09 20:58:32,762 - INFO - root - Page:2, Index:36, FPSAttention: Training-Aware FP8 and Sparsity Co-Design for Fast Video Diffusion, https://arxiv.org/pdf/2506.04648, 2025-06-05
2025-11-09 20:58:32,763 - INFO - root - Page:2, Index:37, BitTTS: Highly Compact Text-to-Speech Using 1.58-bit Quantization and Weight Indexing, https://arxiv.org/pdf/2506.03515, 2025-06-03
2025-11-09 20:58:32,763 - INFO - root - Page:2, Index:38, ShapeLLM-Omni: A Native Multimodal LLM for 3D Generation and Understanding, https://arxiv.org/pdf/2506.01853, 2025-06-02
2025-11-09 20:58:32,763 - INFO - root - Page:2, Index:39, Movable Antenna Enhanced Federated Fine-Tuning of Large Language Models via Hybrid Client Selection Optimization, https://arxiv.org/pdf/2506.00011, 2025-10-26
2025-11-09 20:58:32,763 - INFO - root - Page:2, Index:40, Running Conventional Automatic Speech Recognition on Memristor Hardware: A Simulated Approach, https://arxiv.org/pdf/2505.24721, 2025-05-30
2025-11-09 20:58:32,765 - INFO - root - Page:2, Index:41, GARLIC: GAussian Representation LearnIng for spaCe partitioning, https://arxiv.org/pdf/2505.24608, 2025-10-02
2025-11-09 20:58:32,765 - INFO - root - Page:2, Index:42, AutoChemSchematic AI: Agentic Physics-Aware Automation for Chemical Manufacturing Scale-Up, https://arxiv.org/pdf/2505.24584, 2025-08-18
2025-11-09 20:58:32,765 - INFO - root - Page:2, Index:43, Model-Preserving Adaptive Rounding, https://arxiv.org/pdf/2505.22988, 2025-09-25
2025-11-09 20:58:32,766 - INFO - root - Page:2, Index:44, Highly Efficient and Effective LLMs with Multi-Boolean Architectures, https://arxiv.org/pdf/2505.22811, 2025-10-03
2025-11-09 20:58:32,766 - INFO - root - Page:2, Index:45, Pioneering 4-Bit FP Quantization for Diffusion Models: Mixup-Sign Quantization and Timestep-Aware Fine-Tuning, https://arxiv.org/pdf/2505.21591, 2025-05-27
2025-11-09 20:58:32,768 - INFO - root - Page:2, Index:46, Frequency Composition for Compressed and Domain-Adaptive Neural Networks, https://arxiv.org/pdf/2505.20890, 2025-05-27
2025-11-09 20:58:32,768 - INFO - root - Page:2, Index:47, MoPFormer: Motion-Primitive Transformer for Wearable-Sensor Activity Recognition, https://arxiv.org/pdf/2505.20744, 2025-10-27
2025-11-09 20:58:32,770 - INFO - root - Page:2, Index:48, Optimizing edge AI models on HPC systems with the edge in the loop, https://arxiv.org/pdf/2505.19995, 2025-05-26
2025-11-09 20:58:32,789 - INFO - root - Fetching page 4 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=150
2025-11-09 20:58:39,412 - INFO - root - get_all_titles_from_web 
2025-11-09 20:58:39,412 - INFO - root - Page:3, Index:0, DPASyn: Mechanism-Aware Drug Synergy Prediction via Dual Attention and Precision-Aware Quantization, https://arxiv.org/pdf/2505.19144, 2025-09-20
2025-11-09 20:58:39,413 - INFO - root - Page:3, Index:1, Reducing Storage of Pretrained Neural Networks by Rate-Constrained Quantization and Entropy Coding, https://arxiv.org/pdf/2505.18758, 2025-05-24
2025-11-09 20:58:39,413 - INFO - root - Page:3, Index:2, Beyond Discreteness: Finite-Sample Analysis of Straight-Through Estimator for Quantization, https://arxiv.org/pdf/2505.18113, 2025-05-23
2025-11-09 20:58:39,413 - INFO - root - Page:3, Index:3, Automating Versatile Time-Series Analysis with Tiny Transformers on Embedded FPGAs, https://arxiv.org/pdf/2505.17662, 2025-09-19
2025-11-09 20:58:39,413 - INFO - root - Page:3, Index:4, FPQVAR: Floating Point Quantization for Visual Autoregressive Model with FPGA Hardware Co-design, https://arxiv.org/pdf/2505.16335, 2025-05-22
2025-11-09 20:58:39,414 - INFO - root - Page:3, Index:5, Saliency-Aware Quantized Imitation Learning for Efficient Robotic Control, https://arxiv.org/pdf/2505.15304, 2025-05-30
2025-11-09 20:58:39,414 - INFO - root - Page:3, Index:6, Scaling Law for Quantization-Aware Training, https://arxiv.org/pdf/2505.14302, 2025-05-20
2025-11-09 20:58:39,414 - INFO - root - Page:3, Index:7, Automatic mixed precision for optimizing gained time with constrained loss mean-squared-error based on model partition to sequential sub-graphs, https://arxiv.org/pdf/2505.13060, 2025-05-19
2025-11-09 20:58:39,415 - INFO - root - Page:3, Index:8, Deep Unfolding with Kernel-based Quantization in MIMO Detection, https://arxiv.org/pdf/2505.12736, 2025-05-19
2025-11-09 20:58:39,415 - INFO - root - Page:3, Index:9, FedHQ: Hybrid Runtime Quantization for Federated Learning, https://arxiv.org/pdf/2505.11982, 2025-05-17
2025-11-09 20:58:39,415 - INFO - root - Page:3, Index:10, QVGen: Pushing the Limit of Quantized Video Generative Models, https://arxiv.org/pdf/2505.11497, 2025-09-27
2025-11-09 20:58:39,415 - INFO - root - Page:3, Index:11, EA-3DGS: Efficient and Adaptive 3D Gaussians with Highly Enhanced Quality for outdoor scenes, https://arxiv.org/pdf/2505.10787, 2025-05-15
2025-11-09 20:58:39,416 - INFO - root - Page:3, Index:12, ITERA-LLM: Boosting Sub-8-Bit Large Language Model Inference via Iterative Tensor Decomposition, https://arxiv.org/pdf/2505.08981, 2025-05-13
2025-11-09 20:58:39,417 - INFO - root - Page:3, Index:13, PROM: Prioritize Reduction of Multiplications Over Lower Bit-Widths for Efficient CNNs, https://arxiv.org/pdf/2505.03254, 2025-08-06
2025-11-09 20:58:39,417 - INFO - root - Page:3, Index:14, ICQuant: Index Coding enables Low-bit LLM Quantization, https://arxiv.org/pdf/2505.00850, 2025-08-24
2025-11-09 20:58:39,417 - INFO - root - Page:3, Index:15, Enhancing Ultra-Low-Bit Quantization of Large Language Models Through Saliency-Aware Partial Retraining, https://arxiv.org/pdf/2504.13932, 2025-07-30
2025-11-09 20:58:39,418 - INFO - root - Page:3, Index:16, Achieving binary weight and activation for LLMs using Post-Training Quantization, https://arxiv.org/pdf/2504.05352, 2025-06-30
2025-11-09 20:58:39,418 - INFO - root - Page:3, Index:17, Wireless Hearables With Programmable Speech AI Accelerators, https://arxiv.org/pdf/2503.18698, 2025-10-21
2025-11-09 20:58:39,420 - INFO - root - Page:3, Index:18, GranQ: Efficient Channel-wise Quantization via Vectorized Pre-Scaling for Zero-Shot QAT, https://arxiv.org/pdf/2503.18339, 2025-10-15
2025-11-09 20:58:39,420 - INFO - root - Page:3, Index:19, CompMarkGS: Robust Watermarking for Compressed 3D Gaussian Splatting, https://arxiv.org/pdf/2503.12836, 2025-09-29
2025-11-09 20:58:39,421 - INFO - root - Page:3, Index:20, AHCPTQ: Accurate and Hardware-Compatible Post-Training Quantization for Segment Anything Model, https://arxiv.org/pdf/2503.03088, 2025-07-11
2025-11-09 20:58:39,421 - INFO - root - Page:3, Index:21, Teaching Metric Distance to Discrete Autoregressive Language Models, https://arxiv.org/pdf/2503.02379, 2025-10-07
2025-11-09 20:58:39,421 - INFO - root - Page:3, Index:22, Regularization-based Framework for Quantization-, Fault- and Variability-Aware Training, https://arxiv.org/pdf/2503.01297, 2025-07-12
2025-11-09 20:58:39,422 - INFO - root - Fetching page 5 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=200
2025-11-09 20:58:46,111 - INFO - root - get_all_titles_from_web 
2025-11-09 20:58:46,111 - INFO - root - Page:4, Index:0, Investigating the Impact of Quantization Methods on the Safety and Reliability of Large Language Models, https://arxiv.org/pdf/2502.15799, 2025-06-29
2025-11-09 20:58:46,111 - INFO - root - Page:4, Index:1, Rotate, Clip, and Partition: Towards W2A4KV4 Quantization by Integrating Rotation and Learnable Non-uniform Quantizer, https://arxiv.org/pdf/2502.15779, 2025-09-01
2025-11-09 20:58:46,111 - INFO - root - Page:4, Index:2, RoSTE: An Efficient Quantization-Aware Supervised Fine-Tuning Approach for Large Language Models, https://arxiv.org/pdf/2502.09003, 2025-06-05
2025-11-09 20:58:46,111 - INFO - root - Page:4, Index:3, Spatial Degradation-Aware and Temporal Consistent Diffusion Model for Compressed Video Super-Resolution, https://arxiv.org/pdf/2502.07381, 2025-06-27
2025-11-09 20:58:46,112 - INFO - root - Page:4, Index:4, QuEST: Stable Training of LLMs with 1-Bit Weights and Activations, https://arxiv.org/pdf/2502.05003, 2025-06-10
2025-11-09 20:58:46,112 - INFO - root - Page:4, Index:5, HALO: Hadamard-Assisted Lower-Precision Optimization for LLMs, https://arxiv.org/pdf/2501.02625, 2025-11-05
2025-11-09 20:58:46,112 - INFO - root - Page:4, Index:6, TAR3D: Creating High-Quality 3D Assets via Next-Part Prediction, https://arxiv.org/pdf/2412.16919, 2025-08-08
2025-11-09 20:58:46,112 - INFO - root - Page:4, Index:7, Training Multi-Layer Binary Neural Networks With Local Binary Error Signals, https://arxiv.org/pdf/2412.00119, 2025-08-05
2025-11-09 20:58:46,113 - INFO - root - Page:4, Index:8, Scaling Large-scale GNN Training to Thousands of Processors on CPU-based Supercomputers, https://arxiv.org/pdf/2411.16025, 2025-05-26
2025-11-09 20:58:46,113 - INFO - root - Page:4, Index:9, HAFLQ: Heterogeneous Adaptive Federated LoRA Fine-tuned LLM with Quantization, https://arxiv.org/pdf/2411.06581, 2025-05-16
2025-11-09 20:58:46,113 - INFO - root - Fetching page 6 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=250
2025-11-09 20:58:51,485 - INFO - root - get_all_titles_from_web 
2025-11-09 20:58:51,486 - INFO - root - Page:5, Index:0, Gradient-Free Training of Quantized Neural Networks, https://arxiv.org/pdf/2410.09734, 2025-09-29
2025-11-09 20:58:51,486 - INFO - root - Page:5, Index:1, QT-DoG: Quantization-aware Training for Domain Generalization, https://arxiv.org/pdf/2410.06020, 2025-06-26
2025-11-09 20:58:51,486 - INFO - root - Page:5, Index:2, Constraint Guided Model Quantization of Neural Networks, https://arxiv.org/pdf/2409.20138, 2025-09-12
2025-11-09 20:58:51,486 - INFO - root - Page:5, Index:3, Accumulator-Aware Post-Training Quantization for Large Language Models, https://arxiv.org/pdf/2409.17092, 2025-07-30
2025-11-09 20:58:51,487 - INFO - root - Page:5, Index:4, DilateQuant: Accurate and Efficient Diffusion Quantization via Weight Dilation, https://arxiv.org/pdf/2409.14307, 2025-07-09
2025-11-09 20:58:51,487 - INFO - root - Page:5, Index:5, Robust Training of Neural Networks at Arbitrary Precision and Sparsity, https://arxiv.org/pdf/2409.09245, 2025-09-23
2025-11-09 20:58:51,487 - INFO - root - Page:5, Index:6, VQ-CTAP: Cross-Modal Fine-Grained Sequence Representation Learning for Speech Processing, https://arxiv.org/pdf/2408.05758, 2025-05-27
2025-11-09 20:58:51,487 - INFO - root - Page:5, Index:7, DopQ-ViT: Towards Distribution-Friendly and Outlier-Aware Post-Training Quantization for Vision Transformers, https://arxiv.org/pdf/2408.03291, 2025-06-19
2025-11-09 20:58:51,488 - INFO - root - Page:5, Index:8, Temporal Feature Matters: A Framework for Diffusion Model Quantization, https://arxiv.org/pdf/2407.19547, 2025-07-11
2025-11-09 20:58:51,488 - INFO - root - Page:5, Index:9, EfficientQAT: Efficient Quantization-Aware Training for Large Language Models, https://arxiv.org/pdf/2407.11062, 2025-05-19
2025-11-09 20:58:51,488 - INFO - root - Page:5, Index:10, Integer-only Quantized Transformers for Embedded FPGA-based Time-series Forecasting in AIoT, https://arxiv.org/pdf/2407.11041, 2025-10-31
2025-11-09 20:58:51,489 - INFO - root - Fetching page 7 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=300
2025-11-09 20:58:59,088 - INFO - root - get_all_titles_from_web 
2025-11-09 20:58:59,088 - INFO - root - Page:6, Index:0, BoA: Attention-aware Post-training Quantization without Backpropagation, https://arxiv.org/pdf/2406.13474, 2025-06-06
2025-11-09 20:58:59,089 - INFO - root - Page:6, Index:1, A Rescaling-Invariant Lipschitz Bound Based on Path-Metrics for Modern ReLU Network Parameterizations, https://arxiv.org/pdf/2405.15006, 2025-06-13
2025-11-09 20:58:59,089 - INFO - root - Page:6, Index:2, Scheduling Weight Transitions for Quantization-Aware Training, https://arxiv.org/pdf/2404.19248, 2025-10-01
2025-11-09 20:58:59,089 - INFO - root - Page:6, Index:3, GPTVQ: The Blessing of Dimensionality for LLM Quantization, https://arxiv.org/pdf/2402.15319, 2025-06-03
2025-11-09 20:58:59,090 - INFO - root - Fetching page 8 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=350
2025-11-09 20:59:05,602 - INFO - root - get_all_titles_from_web 
2025-11-09 20:59:05,602 - INFO - root - Page:7, Index:0, Squat: Quant Small Language Models on the Edge, https://arxiv.org/pdf/2402.10787, 2025-07-01
2025-11-09 20:59:05,603 - INFO - root - Page:7, Index:1, L4Q: Parameter Efficient Quantization-Aware Fine-Tuning on Large Language Models, https://arxiv.org/pdf/2402.04902, 2025-07-21
2025-11-09 20:59:05,603 - INFO - root - Fetching page 9 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=400
2025-11-09 20:59:12,042 - INFO - root - ------------------------------------------------------------------------------------------------------------------------
2025-11-09 21:05:14,531 - INFO - root - 正在总结论文 1/40: A Quantized VAE-MLP Botnet Detection Model: A Systematic Evaluation of Quantization-Aware Training and Post-Training Quantization Strategies
2025-11-09 21:05:56,734 - INFO - root - LLMClient: rate limit reached, sleeping 17.8s
2025-11-09 21:06:34,404 - INFO - root - 正在提取论文图片...
2025-11-09 21:06:34,576 - INFO - root - 已保存图片 1/10：./export\images_A Quantized VAE-MLP Botnet Detection Model_ A Systematic Evaluation of Quantizat\figure_1_page4.png
2025-11-09 21:06:34,640 - INFO - root - 已保存图片 2/10：./export\images_A Quantized VAE-MLP Botnet Detection Model_ A Systematic Evaluation of Quantizat\figure_2_page4.png
2025-11-09 21:06:34,701 - INFO - root - 已保存图片 3/10：./export\images_A Quantized VAE-MLP Botnet Detection Model_ A Systematic Evaluation of Quantizat\figure_3_page4.png
2025-11-09 21:06:34,831 - INFO - root - 已保存图片 4/10：./export\images_A Quantized VAE-MLP Botnet Detection Model_ A Systematic Evaluation of Quantizat\figure_4_page5.png
2025-11-09 21:06:34,908 - INFO - root - 已保存图片 5/10：./export\images_A Quantized VAE-MLP Botnet Detection Model_ A Systematic Evaluation of Quantizat\figure_5_page3.png
2025-11-09 21:06:34,998 - INFO - root - 已保存图片 6/10：./export\images_A Quantized VAE-MLP Botnet Detection Model_ A Systematic Evaluation of Quantizat\figure_6_page4.png
2025-11-09 21:06:35,000 - INFO - root - 成功添加图片 1：./export\images_A Quantized VAE-MLP Botnet Detection Model_ A Systematic Evaluation of Quantizat\figure_1_page4.png
2025-11-09 21:06:35,001 - INFO - root - 成功添加图片 2：./export\images_A Quantized VAE-MLP Botnet Detection Model_ A Systematic Evaluation of Quantizat\figure_2_page4.png
2025-11-09 21:06:35,001 - INFO - root - 成功添加图片 3：./export\images_A Quantized VAE-MLP Botnet Detection Model_ A Systematic Evaluation of Quantizat\figure_3_page4.png
2025-11-09 21:06:35,002 - INFO - root - 成功添加图片 4：./export\images_A Quantized VAE-MLP Botnet Detection Model_ A Systematic Evaluation of Quantizat\figure_4_page5.png
2025-11-09 21:06:35,002 - INFO - root - 成功添加图片 5：./export\images_A Quantized VAE-MLP Botnet Detection Model_ A Systematic Evaluation of Quantizat\figure_5_page3.png
2025-11-09 21:06:35,003 - INFO - root - 成功添加图片 6：./export\images_A Quantized VAE-MLP Botnet Detection Model_ A Systematic Evaluation of Quantizat\figure_6_page4.png
2025-11-09 21:06:35,013 - INFO - root - 论文《A Quantized VAE-MLP Botnet Detection Model: A Systematic Evaluation of Quantization-Aware Training and Post-Training Quantization Strategies》的分析已保存到 ./export\A Quantized VAE-MLP Botnet Detection Model_ A Systematic Evaluation of Quantizat.md
2025-11-09 21:06:35,034 - INFO - root - 正在总结论文 2/40: FP8-Flow-MoE: A Casting-Free FP8 Recipe without Double Quantization Error
2025-11-09 21:06:46,076 - INFO - root - LLMClient: rate limit reached, sleeping 28.5s
2025-11-09 21:08:01,934 - INFO - root - 正在提取论文图片...
2025-11-09 21:08:05,846 - INFO - root - 已保存图片 1/10：./export\images_FP8-Flow-MoE_ A Casting-Free FP8 Recipe without Double Quantization Error\figure_1_page6.png
2025-11-09 21:08:06,250 - INFO - root - 已保存图片 2/10：./export\images_FP8-Flow-MoE_ A Casting-Free FP8 Recipe without Double Quantization Error\figure_2_page6.png
2025-11-09 21:08:06,570 - INFO - root - 已保存图片 3/10：./export\images_FP8-Flow-MoE_ A Casting-Free FP8 Recipe without Double Quantization Error\figure_3_page6.png
2025-11-09 21:08:06,923 - INFO - root - 已保存图片 4/10：./export\images_FP8-Flow-MoE_ A Casting-Free FP8 Recipe without Double Quantization Error\figure_4_page6.png
2025-11-09 21:08:06,981 - INFO - root - 成功添加图片 1：./export\images_FP8-Flow-MoE_ A Casting-Free FP8 Recipe without Double Quantization Error\figure_1_page6.png
2025-11-09 21:08:06,982 - INFO - root - 成功添加图片 2：./export\images_FP8-Flow-MoE_ A Casting-Free FP8 Recipe without Double Quantization Error\figure_2_page6.png
2025-11-09 21:08:06,982 - INFO - root - 成功添加图片 3：./export\images_FP8-Flow-MoE_ A Casting-Free FP8 Recipe without Double Quantization Error\figure_3_page6.png
2025-11-09 21:08:06,982 - INFO - root - 成功添加图片 4：./export\images_FP8-Flow-MoE_ A Casting-Free FP8 Recipe without Double Quantization Error\figure_4_page6.png
2025-11-09 21:08:06,993 - INFO - root - 论文《FP8-Flow-MoE: A Casting-Free FP8 Recipe without Double Quantization Error》的分析已保存到 ./export\FP8-Flow-MoE_ A Casting-Free FP8 Recipe without Double Quantization Error.md
2025-11-09 21:08:07,043 - INFO - root - 正在总结论文 3/40: Outlier-Aware Post-Training Quantization for Image Super-Resolution
2025-11-09 21:08:07,051 - INFO - root - LLMClient: rate limit reached, sleeping 7.5s
2025-11-09 21:08:25,249 - INFO - root - LLMClient: rate limit reached, sleeping 16.9s
2025-11-09 21:09:12,054 - INFO - root - LLMClient: rate limit reached, sleeping 2.5s
2025-11-09 21:09:31,067 - INFO - root - 正在提取论文图片...
2025-11-09 21:09:31,978 - INFO - root - 已保存图片 1/10：./export\images_Outlier-Aware Post-Training Quantization for Image Super-Resolution\figure_1_page7.jpeg
2025-11-09 21:09:32,111 - INFO - root - 已保存图片 2/10：./export\images_Outlier-Aware Post-Training Quantization for Image Super-Resolution\figure_2_page4.png
2025-11-09 21:09:32,115 - INFO - root - 成功添加图片 1：./export\images_Outlier-Aware Post-Training Quantization for Image Super-Resolution\figure_1_page7.jpeg
2025-11-09 21:09:32,117 - INFO - root - 成功添加图片 2：./export\images_Outlier-Aware Post-Training Quantization for Image Super-Resolution\figure_2_page4.png
2025-11-09 21:09:32,121 - INFO - root - 论文《Outlier-Aware Post-Training Quantization for Image Super-Resolution》的分析已保存到 ./export\Outlier-Aware Post-Training Quantization for Image Super-Resolution.md
2025-11-09 21:09:32,134 - INFO - root - 正在总结论文 4/40: Evaluation of Wafer-Scale SOT-MRAM for Analog Crossbar Array Applications
2025-11-09 21:09:32,138 - INFO - root - LLMClient: rate limit reached, sleeping 10.0s
2025-11-09 21:09:54,523 - INFO - root - LLMClient: rate limit reached, sleeping 20.0s
2025-11-09 21:11:08,565 - INFO - root - 正在提取论文图片...
2025-11-09 21:11:09,565 - INFO - root - 已保存图片 1/10：./export\images_Evaluation of Wafer-Scale SOT-MRAM for Analog Crossbar Array Applications\figure_1_page4.png
2025-11-09 21:11:09,674 - INFO - root - 已保存图片 2/10：./export\images_Evaluation of Wafer-Scale SOT-MRAM for Analog Crossbar Array Applications\figure_2_page6.png
2025-11-09 21:11:09,754 - INFO - root - 已保存图片 3/10：./export\images_Evaluation of Wafer-Scale SOT-MRAM for Analog Crossbar Array Applications\figure_3_page6.png
2025-11-09 21:11:09,820 - INFO - root - 已保存图片 4/10：./export\images_Evaluation of Wafer-Scale SOT-MRAM for Analog Crossbar Array Applications\figure_4_page6.png
2025-11-09 21:11:09,885 - INFO - root - 已保存图片 5/10：./export\images_Evaluation of Wafer-Scale SOT-MRAM for Analog Crossbar Array Applications\figure_5_page6.png
2025-11-09 21:11:09,964 - INFO - root - 已保存图片 6/10：./export\images_Evaluation of Wafer-Scale SOT-MRAM for Analog Crossbar Array Applications\figure_6_page6.png
2025-11-09 21:11:10,013 - INFO - root - 已保存图片 7/10：./export\images_Evaluation of Wafer-Scale SOT-MRAM for Analog Crossbar Array Applications\figure_7_page6.png
2025-11-09 21:11:10,069 - INFO - root - 已保存图片 8/10：./export\images_Evaluation of Wafer-Scale SOT-MRAM for Analog Crossbar Array Applications\figure_8_page6.png
2025-11-09 21:11:10,125 - INFO - root - 已保存图片 9/10：./export\images_Evaluation of Wafer-Scale SOT-MRAM for Analog Crossbar Array Applications\figure_9_page6.png
2025-11-09 21:11:10,171 - INFO - root - 已保存图片 10/10：./export\images_Evaluation of Wafer-Scale SOT-MRAM for Analog Crossbar Array Applications\figure_10_page6.png
2025-11-09 21:11:10,176 - INFO - root - 成功添加图片 1：./export\images_Evaluation of Wafer-Scale SOT-MRAM for Analog Crossbar Array Applications\figure_1_page4.png
2025-11-09 21:11:10,176 - INFO - root - 成功添加图片 2：./export\images_Evaluation of Wafer-Scale SOT-MRAM for Analog Crossbar Array Applications\figure_2_page6.png
2025-11-09 21:11:10,177 - INFO - root - 成功添加图片 3：./export\images_Evaluation of Wafer-Scale SOT-MRAM for Analog Crossbar Array Applications\figure_3_page6.png
2025-11-09 21:11:10,177 - INFO - root - 成功添加图片 4：./export\images_Evaluation of Wafer-Scale SOT-MRAM for Analog Crossbar Array Applications\figure_4_page6.png
2025-11-09 21:11:10,177 - INFO - root - 成功添加图片 5：./export\images_Evaluation of Wafer-Scale SOT-MRAM for Analog Crossbar Array Applications\figure_5_page6.png
2025-11-09 21:11:10,177 - INFO - root - 成功添加图片 6：./export\images_Evaluation of Wafer-Scale SOT-MRAM for Analog Crossbar Array Applications\figure_6_page6.png
2025-11-09 21:11:10,179 - INFO - root - 成功添加图片 7：./export\images_Evaluation of Wafer-Scale SOT-MRAM for Analog Crossbar Array Applications\figure_7_page6.png
2025-11-09 21:11:10,179 - INFO - root - 成功添加图片 8：./export\images_Evaluation of Wafer-Scale SOT-MRAM for Analog Crossbar Array Applications\figure_8_page6.png
2025-11-09 21:11:10,179 - INFO - root - 成功添加图片 9：./export\images_Evaluation of Wafer-Scale SOT-MRAM for Analog Crossbar Array Applications\figure_9_page6.png
2025-11-09 21:11:10,180 - INFO - root - 成功添加图片 10：./export\images_Evaluation of Wafer-Scale SOT-MRAM for Analog Crossbar Array Applications\figure_10_page6.png
2025-11-09 21:11:10,185 - INFO - root - 论文《Evaluation of Wafer-Scale SOT-MRAM for Analog Crossbar Array Applications》的分析已保存到 ./export\Evaluation of Wafer-Scale SOT-MRAM for Analog Crossbar Array Applications.md
2025-11-09 21:11:10,194 - INFO - root - 正在总结论文 5/40: Improving the Straight-Through Estimator with Zeroth-Order Information
2025-11-09 21:11:10,194 - INFO - root - LLMClient: rate limit reached, sleeping 4.3s
2025-11-09 21:11:24,951 - INFO - root - LLMClient: rate limit reached, sleeping 18.8s
2025-11-09 21:12:07,988 - INFO - root - LLMClient: rate limit reached, sleeping 6.6s
2025-11-09 21:12:32,927 - INFO - root - 正在提取论文图片...
2025-11-09 21:12:34,064 - INFO - root - 已保存图片 1/10：./export\images_Improving the Straight-Through Estimator with Zeroth-Order Information\figure_1_page8.png
2025-11-09 21:12:34,128 - INFO - root - 已保存图片 2/10：./export\images_Improving the Straight-Through Estimator with Zeroth-Order Information\figure_2_page9.png
2025-11-09 21:12:34,177 - INFO - root - 已保存图片 3/10：./export\images_Improving the Straight-Through Estimator with Zeroth-Order Information\figure_3_page7.png
2025-11-09 21:12:34,264 - INFO - root - 已保存图片 4/10：./export\images_Improving the Straight-Through Estimator with Zeroth-Order Information\figure_4_page23.png
2025-11-09 21:12:34,379 - INFO - root - 已保存图片 5/10：./export\images_Improving the Straight-Through Estimator with Zeroth-Order Information\figure_5_page25.png
2025-11-09 21:12:34,447 - INFO - root - 已保存图片 6/10：./export\images_Improving the Straight-Through Estimator with Zeroth-Order Information\figure_6_page25.png
2025-11-09 21:12:34,524 - INFO - root - 已保存图片 7/10：./export\images_Improving the Straight-Through Estimator with Zeroth-Order Information\figure_7_page25.png
2025-11-09 21:12:34,598 - INFO - root - 已保存图片 8/10：./export\images_Improving the Straight-Through Estimator with Zeroth-Order Information\figure_8_page26.png
2025-11-09 21:12:34,672 - INFO - root - 已保存图片 9/10：./export\images_Improving the Straight-Through Estimator with Zeroth-Order Information\figure_9_page26.png
2025-11-09 21:12:34,720 - INFO - root - 已保存图片 10/10：./export\images_Improving the Straight-Through Estimator with Zeroth-Order Information\figure_10_page26.png
2025-11-09 21:12:34,723 - INFO - root - 成功添加图片 1：./export\images_Improving the Straight-Through Estimator with Zeroth-Order Information\figure_1_page8.png
2025-11-09 21:12:34,723 - INFO - root - 成功添加图片 2：./export\images_Improving the Straight-Through Estimator with Zeroth-Order Information\figure_2_page9.png
2025-11-09 21:12:34,724 - INFO - root - 成功添加图片 3：./export\images_Improving the Straight-Through Estimator with Zeroth-Order Information\figure_3_page7.png
2025-11-09 21:12:34,724 - INFO - root - 成功添加图片 4：./export\images_Improving the Straight-Through Estimator with Zeroth-Order Information\figure_4_page23.png
2025-11-09 21:12:34,725 - INFO - root - 成功添加图片 5：./export\images_Improving the Straight-Through Estimator with Zeroth-Order Information\figure_5_page25.png
2025-11-09 21:12:34,725 - INFO - root - 成功添加图片 6：./export\images_Improving the Straight-Through Estimator with Zeroth-Order Information\figure_6_page25.png
2025-11-09 21:12:34,726 - INFO - root - 成功添加图片 7：./export\images_Improving the Straight-Through Estimator with Zeroth-Order Information\figure_7_page25.png
2025-11-09 21:12:34,726 - INFO - root - 成功添加图片 8：./export\images_Improving the Straight-Through Estimator with Zeroth-Order Information\figure_8_page26.png
2025-11-09 21:12:34,726 - INFO - root - 成功添加图片 9：./export\images_Improving the Straight-Through Estimator with Zeroth-Order Information\figure_9_page26.png
2025-11-09 21:12:34,727 - INFO - root - 成功添加图片 10：./export\images_Improving the Straight-Through Estimator with Zeroth-Order Information\figure_10_page26.png
2025-11-09 21:12:34,729 - INFO - root - 论文《Improving the Straight-Through Estimator with Zeroth-Order Information》的分析已保存到 ./export\Improving the Straight-Through Estimator with Zeroth-Order Information.md
2025-11-09 21:12:34,734 - INFO - root - 正在总结论文 6/40: Real-Time Semantic Segmentation on FPGA for Autonomous Vehicles Using LMIINet with the CGRA4ML Framework
2025-11-09 21:12:34,736 - INFO - root - LLMClient: rate limit reached, sleeping 9.1s
2025-11-09 21:12:53,598 - INFO - root - LLMClient: rate limit reached, sleeping 20.9s
2025-11-09 21:13:39,268 - INFO - root - LLMClient: rate limit reached, sleeping 4.5s
2025-11-09 21:14:06,878 - INFO - root - 正在提取论文图片...
2025-11-09 21:14:10,482 - INFO - root - 已保存图片 1/10：./export\images_Real-Time Semantic Segmentation on FPGA for Autonomous Vehicles Using LMIINet wi\figure_1_page5.png
2025-11-09 21:14:10,841 - INFO - root - 已保存图片 2/10：./export\images_Real-Time Semantic Segmentation on FPGA for Autonomous Vehicles Using LMIINet wi\figure_2_page5.png
2025-11-09 21:14:10,967 - INFO - root - 已保存图片 3/10：./export\images_Real-Time Semantic Segmentation on FPGA for Autonomous Vehicles Using LMIINet wi\figure_3_page4.png
2025-11-09 21:14:11,122 - INFO - root - 已保存图片 4/10：./export\images_Real-Time Semantic Segmentation on FPGA for Autonomous Vehicles Using LMIINet wi\figure_4_page4.png
2025-11-09 21:14:11,237 - INFO - root - 已保存图片 5/10：./export\images_Real-Time Semantic Segmentation on FPGA for Autonomous Vehicles Using LMIINet wi\figure_5_page8.png
2025-11-09 21:14:11,529 - INFO - root - 已保存图片 6/10：./export\images_Real-Time Semantic Segmentation on FPGA for Autonomous Vehicles Using LMIINet wi\figure_6_page8.png
2025-11-09 21:14:11,866 - INFO - root - 已保存图片 7/10：./export\images_Real-Time Semantic Segmentation on FPGA for Autonomous Vehicles Using LMIINet wi\figure_7_page8.png
2025-11-09 21:14:11,924 - INFO - root - 已保存图片 8/10：./export\images_Real-Time Semantic Segmentation on FPGA for Autonomous Vehicles Using LMIINet wi\figure_8_page7.png
2025-11-09 21:14:12,003 - INFO - root - 已保存图片 9/10：./export\images_Real-Time Semantic Segmentation on FPGA for Autonomous Vehicles Using LMIINet wi\figure_9_page7.png
2025-11-09 21:14:12,162 - INFO - root - 已保存图片 10/10：./export\images_Real-Time Semantic Segmentation on FPGA for Autonomous Vehicles Using LMIINet wi\figure_10_page7.png
2025-11-09 21:14:12,199 - INFO - root - 成功添加图片 1：./export\images_Real-Time Semantic Segmentation on FPGA for Autonomous Vehicles Using LMIINet wi\figure_1_page5.png
2025-11-09 21:14:12,202 - INFO - root - 成功添加图片 2：./export\images_Real-Time Semantic Segmentation on FPGA for Autonomous Vehicles Using LMIINet wi\figure_2_page5.png
2025-11-09 21:14:12,204 - INFO - root - 成功添加图片 3：./export\images_Real-Time Semantic Segmentation on FPGA for Autonomous Vehicles Using LMIINet wi\figure_3_page4.png
2025-11-09 21:14:12,207 - INFO - root - 成功添加图片 4：./export\images_Real-Time Semantic Segmentation on FPGA for Autonomous Vehicles Using LMIINet wi\figure_4_page4.png
2025-11-09 21:14:12,209 - INFO - root - 成功添加图片 5：./export\images_Real-Time Semantic Segmentation on FPGA for Autonomous Vehicles Using LMIINet wi\figure_5_page8.png
2025-11-09 21:14:12,211 - INFO - root - 成功添加图片 6：./export\images_Real-Time Semantic Segmentation on FPGA for Autonomous Vehicles Using LMIINet wi\figure_6_page8.png
2025-11-09 21:14:12,212 - INFO - root - 成功添加图片 7：./export\images_Real-Time Semantic Segmentation on FPGA for Autonomous Vehicles Using LMIINet wi\figure_7_page8.png
2025-11-09 21:14:12,215 - INFO - root - 成功添加图片 8：./export\images_Real-Time Semantic Segmentation on FPGA for Autonomous Vehicles Using LMIINet wi\figure_8_page7.png
2025-11-09 21:14:12,218 - INFO - root - 成功添加图片 9：./export\images_Real-Time Semantic Segmentation on FPGA for Autonomous Vehicles Using LMIINet wi\figure_9_page7.png
2025-11-09 21:14:12,222 - INFO - root - 成功添加图片 10：./export\images_Real-Time Semantic Segmentation on FPGA for Autonomous Vehicles Using LMIINet wi\figure_10_page7.png
2025-11-09 21:14:12,239 - INFO - root - 论文《Real-Time Semantic Segmentation on FPGA for Autonomous Vehicles Using LMIINet with the CGRA4ML Framework》的分析已保存到 ./export\Real-Time Semantic Segmentation on FPGA for Autonomous Vehicles Using LMIINet wi.md
2025-11-09 21:14:12,259 - INFO - root - 正在总结论文 7/40: TernaryCLIP: Efficiently Compressing Vision-Language Models with Ternary Weights and Distilled Knowledge
2025-11-09 21:14:12,265 - INFO - root - LLMClient: rate limit reached, sleeping 2.3s
2025-11-09 21:14:24,786 - INFO - root - LLMClient: rate limit reached, sleeping 19.0s
2025-11-09 21:15:10,252 - INFO - root - LLMClient: rate limit reached, sleeping 4.3s
2025-11-09 21:15:34,652 - INFO - root - 正在提取论文图片...
2025-11-09 21:15:38,659 - INFO - root - 已保存图片 1/10：./export\images_TernaryCLIP_ Efficiently Compressing Vision-Language Models with Ternary Weights\figure_1_page1.png
2025-11-09 21:15:38,945 - INFO - root - 已保存图片 2/10：./export\images_TernaryCLIP_ Efficiently Compressing Vision-Language Models with Ternary Weights\figure_2_page22.png
2025-11-09 21:15:39,102 - INFO - root - 已保存图片 3/10：./export\images_TernaryCLIP_ Efficiently Compressing Vision-Language Models with Ternary Weights\figure_3_page9.png
2025-11-09 21:15:39,255 - INFO - root - 已保存图片 4/10：./export\images_TernaryCLIP_ Efficiently Compressing Vision-Language Models with Ternary Weights\figure_4_page9.png
2025-11-09 21:15:39,405 - INFO - root - 已保存图片 5/10：./export\images_TernaryCLIP_ Efficiently Compressing Vision-Language Models with Ternary Weights\figure_5_page11.png
2025-11-09 21:15:39,552 - INFO - root - 已保存图片 6/10：./export\images_TernaryCLIP_ Efficiently Compressing Vision-Language Models with Ternary Weights\figure_6_page11.png
2025-11-09 21:15:39,703 - INFO - root - 已保存图片 7/10：./export\images_TernaryCLIP_ Efficiently Compressing Vision-Language Models with Ternary Weights\figure_7_page26.png
2025-11-09 21:15:39,887 - INFO - root - 已保存图片 8/10：./export\images_TernaryCLIP_ Efficiently Compressing Vision-Language Models with Ternary Weights\figure_8_page28.png
2025-11-09 21:15:40,064 - INFO - root - 已保存图片 9/10：./export\images_TernaryCLIP_ Efficiently Compressing Vision-Language Models with Ternary Weights\figure_9_page27.png
2025-11-09 21:15:40,140 - INFO - root - 已保存图片 10/10：./export\images_TernaryCLIP_ Efficiently Compressing Vision-Language Models with Ternary Weights\figure_10_page21.png
2025-11-09 21:15:40,164 - INFO - root - 成功添加图片 1：./export\images_TernaryCLIP_ Efficiently Compressing Vision-Language Models with Ternary Weights\figure_1_page1.png
2025-11-09 21:15:40,165 - INFO - root - 成功添加图片 2：./export\images_TernaryCLIP_ Efficiently Compressing Vision-Language Models with Ternary Weights\figure_2_page22.png
2025-11-09 21:15:40,165 - INFO - root - 成功添加图片 3：./export\images_TernaryCLIP_ Efficiently Compressing Vision-Language Models with Ternary Weights\figure_3_page9.png
2025-11-09 21:15:40,165 - INFO - root - 成功添加图片 4：./export\images_TernaryCLIP_ Efficiently Compressing Vision-Language Models with Ternary Weights\figure_4_page9.png
2025-11-09 21:15:40,165 - INFO - root - 成功添加图片 5：./export\images_TernaryCLIP_ Efficiently Compressing Vision-Language Models with Ternary Weights\figure_5_page11.png
2025-11-09 21:15:40,166 - INFO - root - 成功添加图片 6：./export\images_TernaryCLIP_ Efficiently Compressing Vision-Language Models with Ternary Weights\figure_6_page11.png
2025-11-09 21:15:40,166 - INFO - root - 成功添加图片 7：./export\images_TernaryCLIP_ Efficiently Compressing Vision-Language Models with Ternary Weights\figure_7_page26.png
2025-11-09 21:15:40,166 - INFO - root - 成功添加图片 8：./export\images_TernaryCLIP_ Efficiently Compressing Vision-Language Models with Ternary Weights\figure_8_page28.png
2025-11-09 21:15:40,167 - INFO - root - 成功添加图片 9：./export\images_TernaryCLIP_ Efficiently Compressing Vision-Language Models with Ternary Weights\figure_9_page27.png
2025-11-09 21:15:40,167 - INFO - root - 成功添加图片 10：./export\images_TernaryCLIP_ Efficiently Compressing Vision-Language Models with Ternary Weights\figure_10_page21.png
2025-11-09 21:15:40,171 - INFO - root - 论文《TernaryCLIP: Efficiently Compressing Vision-Language Models with Ternary Weights and Distilled Knowledge》的分析已保存到 ./export\TernaryCLIP_ Efficiently Compressing Vision-Language Models with Ternary Weights.md
2025-11-09 21:15:40,174 - INFO - root - 正在总结论文 8/40: KARIPAP: Quantum-Inspired Tensor Network Compression of Large Language Models Using Infinite Projected Entangled Pair States and Tensor Renormalization Group
2025-11-09 21:15:40,174 - INFO - root - LLMClient: rate limit reached, sleeping 3.6s
2025-11-09 21:15:52,700 - INFO - root - LLMClient: rate limit reached, sleeping 21.9s
2025-11-09 21:16:39,943 - INFO - root - LLMClient: rate limit reached, sleeping 3.9s
2025-11-09 21:17:52,194 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-09 21:17:52,196 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-09 21:17:52,199 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-09 21:17:53,700 - INFO - root - LLMClientManager: 指定使用客户端: Gemini
2025-11-09 21:17:55,425 - INFO - root - GeminiClient: trying model models/gemini-2.5-flash
2025-11-09 21:17:57,334 - INFO - root - GeminiClient: initialized model gemini-2.5-flash
2025-11-09 21:17:57,334 - INFO - root - LLMClientManager: Gemini 客户端初始化成功
2025-11-09 21:17:57,334 - INFO - root - LLMClientManager: switched to Gemini client
2025-11-09 21:17:57,334 - INFO - root - 已手动切换到 LLM 客户端: Gemini
2025-11-09 21:17:57,334 - INFO - root - 使用 LLM 模型: gemini-2.5-flash
2025-11-09 21:17:57,336 - INFO - root - 可用客户端: ['Gemini']
2025-11-09 21:17:57,337 - INFO - root - === 运行配置 ===
2025-11-09 21:17:57,337 - INFO - root - 处理模式: arxiv在线搜索
2025-11-09 21:17:57,338 - INFO - root - 关键词: QAT
2025-11-09 21:17:57,338 - INFO - root - 查询: Quantization-Aware-Training
2025-11-09 21:17:57,339 - INFO - root - 排序: None
2025-11-09 21:17:57,354 - INFO - root - 最近天数: 180
2025-11-09 21:17:57,355 - INFO - root - 最大处理数量: 40
2025-11-09 21:17:57,356 - INFO - root - 保存图片: 是
2025-11-09 21:17:57,357 - INFO - root - 输出语言: 中文
2025-11-09 21:17:57,357 - INFO - root - 强制重新处理: 否
2025-11-09 21:17:57,358 - INFO - root - ====================
2025-11-09 21:17:57,358 - INFO - root - 使用 arXiv 搜索模式（通过 chat_arxiv 模块获取）
2025-11-09 21:17:57,358 - INFO - root - Fetching page 1 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50
2025-11-09 21:18:04,307 - INFO - root - get_all_titles_from_web 
2025-11-09 21:18:04,310 - INFO - root - Page:0, Index:0, A Quantized VAE-MLP Botnet Detection Model: A Systematic Evaluation of Quantization-Aware Training and Post-Training Quantization Strategies, https://arxiv.org/pdf/2511.03201, 2025-11-05
2025-11-09 21:18:04,311 - INFO - root - Page:0, Index:1, FP8-Flow-MoE: A Casting-Free FP8 Recipe without Double Quantization Error, https://arxiv.org/pdf/2511.02302, 2025-11-04
2025-11-09 21:18:04,312 - INFO - root - Page:0, Index:2, Outlier-Aware Post-Training Quantization for Image Super-Resolution, https://arxiv.org/pdf/2511.00682, 2025-11-01
2025-11-09 21:18:04,313 - INFO - root - Page:0, Index:3, Evaluation of Wafer-Scale SOT-MRAM for Analog Crossbar Array Applications, https://arxiv.org/pdf/2510.25853, 2025-11-03
2025-11-09 21:18:04,331 - INFO - root - Page:0, Index:4, Improving the Straight-Through Estimator with Zeroth-Order Information, https://arxiv.org/pdf/2510.23926, 2025-10-27
2025-11-09 21:18:04,339 - INFO - root - Page:0, Index:5, Real-Time Semantic Segmentation on FPGA for Autonomous Vehicles Using LMIINet with the CGRA4ML Framework, https://arxiv.org/pdf/2510.22243, 2025-10-25
2025-11-09 21:18:04,343 - INFO - root - Page:0, Index:6, TernaryCLIP: Efficiently Compressing Vision-Language Models with Ternary Weights and Distilled Knowledge, https://arxiv.org/pdf/2510.21879, 2025-10-23
2025-11-09 21:18:04,347 - INFO - root - Page:0, Index:7, KARIPAP: Quantum-Inspired Tensor Network Compression of Large Language Models Using Infinite Projected Entangled Pair States and Tensor Renormalization Group, https://arxiv.org/pdf/2510.21844, 2025-10-22
2025-11-09 21:18:04,349 - INFO - root - Page:0, Index:8, A Convergence Analysis of Adaptive Optimizers under Floating-point Quantization, https://arxiv.org/pdf/2510.21314, 2025-10-24
2025-11-09 21:18:04,351 - INFO - root - Page:0, Index:9, Adaptive Distribution-aware Quantization for Mixed-Precision Neural Networks, https://arxiv.org/pdf/2510.19760, 2025-10-22
2025-11-09 21:18:04,352 - INFO - root - Page:0, Index:10, CAGE: Curvature-Aware Gradient Estimation For Accurate Quantization-Aware Training, https://arxiv.org/pdf/2510.18784, 2025-10-21
2025-11-09 21:18:04,353 - INFO - root - Page:0, Index:11, Mixed-Precision Quantization for Language Models: Techniques and Prospects, https://arxiv.org/pdf/2510.16805, 2025-10-19
2025-11-09 21:18:04,373 - INFO - root - Page:0, Index:12, SPLite Hand: Sparsity-Aware Lightweight 3D Hand Pose Estimation, https://arxiv.org/pdf/2510.16396, 2025-10-30
2025-11-09 21:18:04,378 - INFO - root - Page:0, Index:13, CTR-LoRA: Curvature-Aware and Trust-Region Guided Low-Rank Adaptation for Large Language Models, https://arxiv.org/pdf/2510.15962, 2025-10-11
2025-11-09 21:18:04,380 - INFO - root - Page:0, Index:14, SANR: Scene-Aware Neural Representation for Light Field Image Compression with Rate-Distortion Optimization, https://arxiv.org/pdf/2510.15775, 2025-10-17
2025-11-09 21:18:04,380 - INFO - root - Page:0, Index:15, SpikeFit: Towards Optimal Deployment of Spiking Networks on Neuromorphic Hardware, https://arxiv.org/pdf/2510.15542, 2025-10-31
2025-11-09 21:18:04,380 - INFO - root - Page:0, Index:16, GRank: Towards Target-Aware and Streamlined Industrial Retrieval with a Generate-Rank Framework, https://arxiv.org/pdf/2510.15299, 2025-10-17
2025-11-09 21:18:04,381 - INFO - root - Page:0, Index:17, SaLon3R: Structure-aware Long-term Generalizable 3D Reconstruction from Unposed Images, https://arxiv.org/pdf/2510.15072, 2025-10-16
2025-11-09 21:18:04,381 - INFO - root - Page:0, Index:18, FraQAT: Quantization Aware Training with Fractional bits, https://arxiv.org/pdf/2510.14823, 2025-10-16
2025-11-09 21:18:04,382 - INFO - root - Page:0, Index:19, Computing-In-Memory Aware Model Adaption For Edge Devices, https://arxiv.org/pdf/2510.14379, 2025-10-16
2025-11-09 21:18:04,382 - INFO - root - Page:0, Index:20, Invited Paper: BitMedViT: Ternary-Quantized Vision Transformer for Medical AI Assistants on the Edge, https://arxiv.org/pdf/2510.13760, 2025-11-04
2025-11-09 21:18:04,383 - INFO - root - Page:0, Index:21, NeuroRVQ: Multi-Scale EEG Tokenization for Generative Large Brainwave Models, https://arxiv.org/pdf/2510.13068, 2025-10-14
2025-11-09 21:18:04,383 - INFO - root - Page:0, Index:22, Detect Anything via Next Point Prediction, https://arxiv.org/pdf/2510.12798, 2025-10-14
2025-11-09 21:18:04,393 - INFO - root - Page:0, Index:23, AndesVL Technical Report: An Efficient Mobile-side Multimodal Large Language Model, https://arxiv.org/pdf/2510.11496, 2025-10-14
2025-11-09 21:18:04,396 - INFO - root - Page:0, Index:24, Rescaling-Aware Training for Efficient Deployment of Deep Learning Models on Full-Integer Hardware, https://arxiv.org/pdf/2510.11484, 2025-10-13
2025-11-09 21:18:04,398 - INFO - root - Page:0, Index:25, SASER: Stego attacks on open-source LLMs, https://arxiv.org/pdf/2510.10486, 2025-10-12
2025-11-09 21:18:04,398 - INFO - root - Page:0, Index:26, Ultralytics YOLO Evolution: An Overview of YOLO26, YOLO11, YOLOv8 and YOLOv5 Object Detectors for Computer Vision and Pattern Recognition, https://arxiv.org/pdf/2510.09653, 2025-10-15
2025-11-09 21:18:04,398 - INFO - root - Page:0, Index:27, A Theoretically-Grounded Codebook for Digital Semantic Communications, https://arxiv.org/pdf/2510.07108, 2025-10-14
2025-11-09 21:18:04,398 - INFO - root - Page:0, Index:28, QuantDemoire: Quantization with Outlier Aware for Image Demoiréing, https://arxiv.org/pdf/2510.04066, 2025-10-05
2025-11-09 21:18:04,399 - INFO - root - Page:0, Index:29, Adaptively Sampling-Reusing-Mixing Decomposed Gradients to Speed Up Sharpness Aware Minimization, https://arxiv.org/pdf/2510.03763, 2025-10-04
2025-11-09 21:18:04,399 - INFO - root - Page:0, Index:30, Quant-dLLM: Post-Training Extreme Low-Bit Quantization for Diffusion Large Language Models, https://arxiv.org/pdf/2510.03274, 2025-09-27
2025-11-09 21:18:04,399 - INFO - root - Page:0, Index:31, PT$^2$-LLM: Post-Training Ternarization for Large Language Models, https://arxiv.org/pdf/2510.03267, 2025-09-26
2025-11-09 21:18:04,401 - INFO - root - Page:0, Index:32, Purrception: Variational Flow Matching for Vector-Quantized Image Generation, https://arxiv.org/pdf/2510.01478, 2025-10-01
2025-11-09 21:18:04,401 - INFO - root - Page:0, Index:33, Post-Training Quantization for Audio Diffusion Transformers, https://arxiv.org/pdf/2510.00313, 2025-09-30
2025-11-09 21:18:04,403 - INFO - root - Page:0, Index:34, Rethinking RoPE Scaling in Quantized LLM: Theory, Outlier, and Channel-Band Analysis with Weight Rescaling, https://arxiv.org/pdf/2510.00028, 2025-09-25
2025-11-09 21:18:04,414 - INFO - root - Page:0, Index:35, Post-Training Quantization via Residual Truncation and Zero Suppression for Diffusion Models, https://arxiv.org/pdf/2509.26436, 2025-09-30
2025-11-09 21:18:04,415 - INFO - root - Page:0, Index:36, Cat: Post-Training Quantization Error Reduction via Cluster-based Affine Transformation, https://arxiv.org/pdf/2509.26277, 2025-10-07
2025-11-09 21:18:04,415 - INFO - root - Page:0, Index:37, CAST: Continuous and Differentiable Semi-Structured Sparsity-Aware Training for Large Language Models, https://arxiv.org/pdf/2509.25996, 2025-09-30
2025-11-09 21:18:04,415 - INFO - root - Page:0, Index:38, Norm-Q: Effective Compression Method for Hidden Markov Models in Neuro-Symbolic Applications, https://arxiv.org/pdf/2509.25439, 2025-09-29
2025-11-09 21:18:04,416 - INFO - root - Page:0, Index:39, On-the-Fly Adaptation to Quantization: Configuration-Aware LoRA for Efficient Fine-Tuning of Quantized LLMs, https://arxiv.org/pdf/2509.25214, 2025-09-22
2025-11-09 21:18:04,416 - INFO - root - Page:0, Index:40, VoxCPM: Tokenizer-Free TTS for Context-Aware Speech Generation and True-to-Life Voice Cloning, https://arxiv.org/pdf/2509.24650, 2025-09-29
2025-11-09 21:18:04,416 - INFO - root - Page:0, Index:41, S$^2$NN: Sub-bit Spiking Neural Networks, https://arxiv.org/pdf/2509.24266, 2025-10-24
2025-11-09 21:18:04,418 - INFO - root - Page:0, Index:42, Tequila: Trapping-free Ternary Quantization for Large Language Models, https://arxiv.org/pdf/2509.23809, 2025-10-17
2025-11-09 21:18:04,418 - INFO - root - Page:0, Index:43, Texture Vector-Quantization and Reconstruction Aware Prediction for Generative Super-Resolution, https://arxiv.org/pdf/2509.23774, 2025-09-30
2025-11-09 21:18:04,420 - INFO - root - Page:0, Index:44, RobuQ: Pushing DiTs to W1.58A2 via Robust Activation Quantization, https://arxiv.org/pdf/2509.23582, 2025-09-27
2025-11-09 21:18:04,434 - INFO - root - Page:0, Index:45, Beyond Outliers: A Study of Optimizers Under Quantization, https://arxiv.org/pdf/2509.23500, 2025-10-02
2025-11-09 21:18:04,435 - INFO - root - Page:0, Index:46, Compute-Optimal Quantization-Aware Training, https://arxiv.org/pdf/2509.22935, 2025-09-26
2025-11-09 21:18:04,435 - INFO - root - Page:0, Index:47, COSPADI: Compressing LLMs via Calibration-Guided Sparse Dictionary Learning, https://arxiv.org/pdf/2509.22075, 2025-10-06
2025-11-09 21:18:04,436 - INFO - root - Page:0, Index:48, SlimDiff: Training-Free, Activation-Guided Hands-free Slimming of Diffusion Models, https://arxiv.org/pdf/2509.21498, 2025-09-25
2025-11-09 21:18:04,448 - INFO - root - Page:0, Index:49, Quantized Visual Geometry Grounded Transformer, https://arxiv.org/pdf/2509.21302, 2025-09-29
2025-11-09 21:18:04,449 - INFO - root - Fetching page 2 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=50
2025-11-09 21:18:11,158 - INFO - root - get_all_titles_from_web 
2025-11-09 21:18:11,159 - INFO - root - Page:1, Index:0, Can Less Precise Be More Reliable? A Systematic Evaluation of Quantization's Impact on CLIP Beyond Accuracy, https://arxiv.org/pdf/2509.21173, 2025-10-27
2025-11-09 21:18:11,159 - INFO - root - Page:1, Index:1, Punching Above Precision: Small Quantized Model Distillation with Learnable Regularizer, https://arxiv.org/pdf/2509.20854, 2025-09-25
2025-11-09 21:18:11,159 - INFO - root - Page:1, Index:2, TinyEcoWeedNet: Edge Efficient Real-Time Aerial Agricultural Weed Detection, https://arxiv.org/pdf/2509.18193, 2025-09-19
2025-11-09 21:18:11,161 - INFO - root - Page:1, Index:3, SBVR: Summation of BitVector Representation for Efficient LLM Quantization, https://arxiv.org/pdf/2509.18172, 2025-09-17
2025-11-09 21:18:11,162 - INFO - root - Page:1, Index:4, QWHA: Quantization-Aware Walsh-Hadamard Adaptation for Parameter-Efficient Fine-Tuning on Large Language Models, https://arxiv.org/pdf/2509.17428, 2025-09-26
2025-11-09 21:18:11,163 - INFO - root - Page:1, Index:5, PTQTP: Post-Training Quantization to Trit-Planes for Large Language Models, https://arxiv.org/pdf/2509.16989, 2025-10-28
2025-11-09 21:18:11,164 - INFO - root - Page:1, Index:6, MEC-Quant: Maximum Entropy Coding for Extremely Low Bit Quantization-Aware Training, https://arxiv.org/pdf/2509.15514, 2025-09-18
2025-11-09 21:18:11,164 - INFO - root - Page:1, Index:7, Q-ROAR: Outlier-Aware Rescaling for RoPE Position Interpolation in Quantized Long-Context LLMs, https://arxiv.org/pdf/2509.14391, 2025-09-17
2025-11-09 21:18:11,165 - INFO - root - Page:1, Index:8, Efficient Quantization-Aware Neural Receivers: Beyond Post-Training Quantization, https://arxiv.org/pdf/2509.13786, 2025-09-19
2025-11-09 21:18:11,166 - INFO - root - Page:1, Index:9, Rate-Distortion Limits for Multimodal Retrieval: Theory, Optimal Codes, and Finite-Sample Guarantees, https://arxiv.org/pdf/2509.11054, 2025-09-13
2025-11-09 21:18:11,166 - INFO - root - Page:1, Index:10, SQAP-VLA: A Synergistic Quantization-Aware Pruning Framework for High-Performance Vision-Language-Action Models, https://arxiv.org/pdf/2509.09090, 2025-09-10
2025-11-09 21:18:11,167 - INFO - root - Page:1, Index:11, CSI Compression Beyond Latents: End-to-End Hybrid Attention-CNN Networks with Entropy Regularization, https://arxiv.org/pdf/2509.08776, 2025-09-10
2025-11-09 21:18:11,167 - INFO - root - Page:1, Index:12, Explaining How Quantization Disparately Skews a Model, https://arxiv.org/pdf/2509.07222, 2025-09-08
2025-11-09 21:18:11,168 - INFO - root - Page:1, Index:13, LoaQ: Layer-wise Output Approximation Quantization, https://arxiv.org/pdf/2509.06297, 2025-09-07
2025-11-09 21:18:11,168 - INFO - root - Page:1, Index:14, FineServe: Precision-Aware KV Slab and Two-Level Scheduling for Heterogeneous Precision LLM Serving, https://arxiv.org/pdf/2509.06261, 2025-09-14
2025-11-09 21:18:11,168 - INFO - root - Page:1, Index:15, Sensitivity-Aware Post-Training Quantization for Deep Neural Networks, https://arxiv.org/pdf/2509.05576, 2025-09-05
2025-11-09 21:18:11,170 - INFO - root - Page:1, Index:16, SuperSNN: A Hardware-Aware Framework for Physically Realizable, High-Performance Superconducting Spiking Neural Network Chips, https://arxiv.org/pdf/2509.05532, 2025-09-05
2025-11-09 21:18:11,173 - INFO - root - Page:1, Index:17, Data-Augmented Quantization-Aware Knowledge Distillation, https://arxiv.org/pdf/2509.03850, 2025-09-03
2025-11-09 21:18:11,173 - INFO - root - Page:1, Index:18, DPQuant: Efficient and Differentially-Private Model Training via Dynamic Quantization Scheduling, https://arxiv.org/pdf/2509.03472, 2025-09-03
2025-11-09 21:18:11,174 - INFO - root - Page:1, Index:19, Empowering Large Language Model for Sequential Recommendation via Multimodal Embeddings and Semantic IDs, https://arxiv.org/pdf/2509.02017, 2025-09-02
2025-11-09 21:18:11,174 - INFO - root - Page:1, Index:20, Q-Sched: Pushing the Boundaries of Few-Step Diffusion Models with Quantization-Aware Scheduling, https://arxiv.org/pdf/2509.01624, 2025-09-01
2025-11-09 21:18:11,174 - INFO - root - Page:1, Index:21, Quantization Meets OOD: Generalizable Quantization-aware Training from a Flatness Perspective, https://arxiv.org/pdf/2509.00859, 2025-08-31
2025-11-09 21:18:11,174 - INFO - root - Page:1, Index:22, Progressive Element-wise Gradient Estimation for Neural Network Quantization, https://arxiv.org/pdf/2509.00097, 2025-08-27
2025-11-09 21:18:11,175 - INFO - root - Page:1, Index:23, End-to-End On-Device Quantization-Aware Training for LLMs at Inference Cost, https://arxiv.org/pdf/2509.00031, 2025-09-29
2025-11-09 21:18:11,175 - INFO - root - Page:1, Index:24, Quantization Robustness to Input Degradations for Object Detection, https://arxiv.org/pdf/2508.19600, 2025-08-27
2025-11-09 21:18:11,175 - INFO - root - Page:1, Index:25, Scaling Laws for Task-Stratified Knowledge in Post-Training Quantized Large Language Models, https://arxiv.org/pdf/2508.18609, 2025-08-27
2025-11-09 21:18:11,176 - INFO - root - Page:1, Index:26, AQ-PCDSys: An Adaptive Quantized Planetary Crater Detection System for Autonomous Space Exploration, https://arxiv.org/pdf/2508.18025, 2025-08-25
2025-11-09 21:18:11,180 - INFO - root - Page:1, Index:27, TaDiCodec: Text-aware Diffusion Speech Tokenizer for Speech Language Modeling, https://arxiv.org/pdf/2508.16790, 2025-08-22
2025-11-09 21:18:11,180 - INFO - root - Page:1, Index:28, A Node-Aware Dynamic Quantization Approach for Graph Collaborative Filtering, https://arxiv.org/pdf/2508.16516, 2025-08-22
2025-11-09 21:18:11,180 - INFO - root - Page:1, Index:29, JEDI-linear: Fast and Efficient Graph Neural Networks for Jet Tagging on FPGAs, https://arxiv.org/pdf/2508.15468, 2025-08-21
2025-11-09 21:18:11,183 - INFO - root - Page:1, Index:30, MMQ: Multimodal Mixture-of-Quantization Tokenization for Semantic ID Generation and User Behavioral Adaptation, https://arxiv.org/pdf/2508.15281, 2025-08-21
2025-11-09 21:18:11,183 - INFO - root - Page:1, Index:31, DLLMQuant: Quantizing Diffusion-based Large Language Models, https://arxiv.org/pdf/2508.14090, 2025-08-25
2025-11-09 21:18:11,184 - INFO - root - Page:1, Index:32, Automated Energy-Aware Time-Series Model Deployment on Embedded FPGAs for Resilient Combined Sewer Overflow Management, https://arxiv.org/pdf/2508.13905, 2025-08-19
2025-11-09 21:18:11,184 - INFO - root - Page:1, Index:33, XR-NPE: High-Throughput Mixed-precision SIMD Neural Processing Engine for Extended Reality Perception Workloads, https://arxiv.org/pdf/2508.13049, 2025-08-18
2025-11-09 21:18:11,184 - INFO - root - Page:1, Index:34, Exploring Self-Supervised Audio Models for Generalized Anomalous Sound Detection, https://arxiv.org/pdf/2508.12230, 2025-08-17
2025-11-09 21:18:11,185 - INFO - root - Page:1, Index:35, TriQDef: Disrupting Semantic and Gradient Alignment to Prevent Adversarial Patch Transferability in Quantized Neural Networks, https://arxiv.org/pdf/2508.12132, 2025-08-16
2025-11-09 21:18:11,185 - INFO - root - Page:1, Index:36, Error Propagation Mechanisms and Compensation Strategies for Quantized Diffusion, https://arxiv.org/pdf/2508.12094, 2025-10-13
2025-11-09 21:18:11,186 - INFO - root - Page:1, Index:37, Extending Straight-Through Estimation for Robust Neural Networks on Analog CIM Hardware, https://arxiv.org/pdf/2508.11940, 2025-08-16
2025-11-09 21:18:11,186 - INFO - root - Page:1, Index:38, PTQAT: A Hybrid Parameter-Efficient Quantization Algorithm for 3D Perception Tasks, https://arxiv.org/pdf/2508.10557, 2025-08-15
2025-11-09 21:18:11,187 - INFO - root - Page:1, Index:39, MiCo: End-to-End Mixed Precision Neural Network Co-Exploration Framework for Edge AI, https://arxiv.org/pdf/2508.09500, 2025-08-13
2025-11-09 21:18:11,187 - INFO - root - Page:1, Index:40, SPARC: Soft Probabilistic Adaptive multi-interest Retrieval Model via Codebooks for recommender system, https://arxiv.org/pdf/2508.09090, 2025-08-12
2025-11-09 21:18:11,187 - INFO - root - Page:1, Index:41, Rethinking 1-bit Optimization Leveraging Pre-trained Large Language Models, https://arxiv.org/pdf/2508.06974, 2025-08-09
2025-11-09 21:18:11,188 - INFO - root - Page:1, Index:42, Efficient Deep Neural Receiver with Post-Training Quantization, https://arxiv.org/pdf/2508.06275, 2025-08-08
2025-11-09 21:18:11,188 - INFO - root - Page:1, Index:43, iFairy: the First 2-bit Complex LLM with All Parameters in $\{\pm1, \pm i\}$, https://arxiv.org/pdf/2508.05571, 2025-08-16
2025-11-09 21:18:11,188 - INFO - root - Page:1, Index:44, S$^2$Q-VDiT: Accurate Quantized Video Diffusion Transformer with Salient Data and Sparse Token Distillation, https://arxiv.org/pdf/2508.04016, 2025-10-27
2025-11-09 21:18:11,189 - INFO - root - Page:1, Index:45, LRQ-DiT: Log-Rotation Post-Training Quantization of Diffusion Transformers for Image and Video Generation, https://arxiv.org/pdf/2508.03485, 2025-09-23
2025-11-09 21:18:11,189 - INFO - root - Page:1, Index:46, VLMQ: Efficient Post-Training Quantization for Large Vision-Language Models via Hessian Augmentation, https://arxiv.org/pdf/2508.03351, 2025-08-05
2025-11-09 21:18:11,189 - INFO - root - Page:1, Index:47, TF-MLPNet: Tiny Real-Time Neural Speech Separation, https://arxiv.org/pdf/2508.03047, 2025-08-04
2025-11-09 21:18:11,191 - INFO - root - Page:1, Index:48, SaviorRec: Semantic-Behavior Alignment for Cold-Start Recommendation, https://arxiv.org/pdf/2508.01375, 2025-08-02
2025-11-09 21:18:11,191 - INFO - root - Page:1, Index:49, MixA-Q: Revisiting Activation Sparsity for Vision Transformers from a Mixed-Precision Quantization Perspective, https://arxiv.org/pdf/2507.19131, 2025-07-25
2025-11-09 21:18:11,192 - INFO - root - Fetching page 3 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=100
2025-11-09 21:18:18,230 - INFO - root - get_all_titles_from_web 
2025-11-09 21:18:18,238 - INFO - root - Page:2, Index:0, Enhancing Quantization-Aware Training on Edge Devices via Relative Entropy Coreset Selection and Cascaded Layer Correction, https://arxiv.org/pdf/2507.17768, 2025-07-16
2025-11-09 21:18:18,239 - INFO - root - Page:2, Index:1, SiLQ: Simple Large Language Model Quantization-Aware Training, https://arxiv.org/pdf/2507.16933, 2025-07-22
2025-11-09 21:18:18,240 - INFO - root - Page:2, Index:2, Task-Specific Zero-shot Quantization-Aware Training for Object Detection, https://arxiv.org/pdf/2507.16782, 2025-07-22
2025-11-09 21:18:18,244 - INFO - root - Page:2, Index:3, TorchAO: PyTorch-Native Training-to-Serving Model Optimization, https://arxiv.org/pdf/2507.16099, 2025-07-21
2025-11-09 21:18:18,245 - INFO - root - Page:2, Index:4, SegQuant: A Semantics-Aware and Generalizable Quantization Framework for Diffusion Models, https://arxiv.org/pdf/2507.14811, 2025-08-27
2025-11-09 21:18:18,245 - INFO - root - Page:2, Index:5, Apple Intelligence Foundation Language Models: Tech Report 2025, https://arxiv.org/pdf/2507.13575, 2025-08-27
2025-11-09 21:18:18,245 - INFO - root - Page:2, Index:6, Generative Multi-Target Cross-Domain Recommendation, https://arxiv.org/pdf/2507.12871, 2025-08-07
2025-11-09 21:18:18,246 - INFO - root - Page:2, Index:7, DAF: An Efficient End-to-End Dynamic Activation Framework for on-Device DNN Training, https://arxiv.org/pdf/2507.07149, 2025-07-09
2025-11-09 21:18:18,247 - INFO - root - Page:2, Index:8, Opto-ViT: Architecting a Near-Sensor Region of Interest-Aware Vision Transformer Accelerator with Silicon Photonics, https://arxiv.org/pdf/2507.07044, 2025-07-15
2025-11-09 21:18:18,249 - INFO - root - Page:2, Index:9, QS4D: Quantization-aware training for efficient hardware deployment of structured state-space sequential models, https://arxiv.org/pdf/2507.06079, 2025-07-08
2025-11-09 21:18:18,249 - INFO - root - Page:2, Index:10, GSVR: 2D Gaussian-based Video Representation for 800+ FPS with Hybrid Deformation Field, https://arxiv.org/pdf/2507.05594, 2025-07-07
2025-11-09 21:18:18,250 - INFO - root - Page:2, Index:11, Hita: Holistic Tokenizer for Autoregressive Image Generation, https://arxiv.org/pdf/2507.02358, 2025-07-11
2025-11-09 21:18:18,250 - INFO - root - Page:2, Index:12, QPART: Adaptive Model Quantization and Dynamic Workload Balancing for Accuracy-aware Edge Inference, https://arxiv.org/pdf/2506.23934, 2025-06-30
2025-11-09 21:18:18,257 - INFO - root - Page:2, Index:13, FedWSQ: Efficient Federated Learning with Weight Standardization and Distribution-Aware Non-Uniform Quantization, https://arxiv.org/pdf/2506.23516, 2025-07-21
2025-11-09 21:18:18,269 - INFO - root - Page:2, Index:14, Spectra 1.1: Scaling Laws and Efficient Inference for Ternary Language Models, https://arxiv.org/pdf/2506.23025, 2025-06-28
2025-11-09 21:18:18,344 - INFO - root - Page:2, Index:15, Joint Quantization and Pruning Neural Networks Approach: A Case Study on FSO Receivers, https://arxiv.org/pdf/2506.20084, 2025-06-24
2025-11-09 21:18:18,375 - INFO - root - Page:2, Index:16, Single-step Diffusion for Image Compression at Ultra-Low Bitrates, https://arxiv.org/pdf/2506.16572, 2025-09-22
2025-11-09 21:18:18,391 - INFO - root - Page:2, Index:17, LittleBit: Ultra Low-Bit Quantization via Latent Factorization, https://arxiv.org/pdf/2506.13771, 2025-10-28
2025-11-09 21:18:18,407 - INFO - root - Page:2, Index:18, MARCO: Hardware-Aware Neural Architecture Search for Edge Devices with Multi-Agent Reinforcement Learning and Conformal Prediction Filtering, https://arxiv.org/pdf/2506.13755, 2025-06-16
2025-11-09 21:18:18,410 - INFO - root - Page:2, Index:19, EAQuant: Enhancing Post-Training Quantization for MoE Models via Expert-Aware Optimization, https://arxiv.org/pdf/2506.13329, 2025-07-04
2025-11-09 21:18:18,413 - INFO - root - Page:2, Index:20, Towards Neural Audio Codec Source Parsing, https://arxiv.org/pdf/2506.12627, 2025-06-14
2025-11-09 21:18:18,416 - INFO - root - Page:2, Index:21, Quantizing Small-Scale State-Space Models for Edge AI, https://arxiv.org/pdf/2506.12480, 2025-06-14
2025-11-09 21:18:18,420 - INFO - root - Page:2, Index:22, EMLoC: Emulator-based Memory-efficient Fine-tuning with LoRA Correction, https://arxiv.org/pdf/2506.12015, 2025-06-13
2025-11-09 21:18:18,426 - INFO - root - Page:2, Index:23, Compression Aware Certified Training, https://arxiv.org/pdf/2506.11992, 2025-06-13
2025-11-09 21:18:18,429 - INFO - root - Page:2, Index:24, GPLQ: A General, Practical, and Lightning QAT Method for Vision Transformers, https://arxiv.org/pdf/2506.11784, 2025-06-13
2025-11-09 21:18:18,433 - INFO - root - Page:2, Index:25, TruncQuant: Truncation-Ready Quantization for DNNs with Flexible Weight Bit Precision, https://arxiv.org/pdf/2506.11431, 2025-06-12
2025-11-09 21:18:18,441 - INFO - root - Page:2, Index:26, EfficientQuant: An Efficient Post-Training Quantization for CNN-Transformer Hybrid Models on Edge Devices, https://arxiv.org/pdf/2506.11093, 2025-06-05
2025-11-09 21:18:18,443 - INFO - root - Page:2, Index:27, Starting Positions Matter: A Study on Better Weight Initialization for Neural Network Quantization, https://arxiv.org/pdf/2506.10463, 2025-06-12
2025-11-09 21:18:18,451 - INFO - root - Page:2, Index:28, AWP: Activation-Aware Weight Pruning and Quantization with Projected Gradient Descent, https://arxiv.org/pdf/2506.10205, 2025-06-11
2025-11-09 21:18:18,458 - INFO - root - Page:2, Index:29, Q-SAM2: Accurate Quantization for Segment Anything Model 2, https://arxiv.org/pdf/2506.09782, 2025-06-11
2025-11-09 21:18:18,460 - INFO - root - Page:2, Index:30, Unifying Block-wise PTQ and Distillation-based QAT for Progressive Quantization toward 2-bit Instruction-Tuned LLMs, https://arxiv.org/pdf/2506.09104, 2025-06-10
2025-11-09 21:18:18,462 - INFO - root - Page:2, Index:31, Implementing Keyword Spotting on the MCUX947 Microcontroller with Integrated NPU, https://arxiv.org/pdf/2506.08911, 2025-06-10
2025-11-09 21:18:18,469 - INFO - root - Page:2, Index:32, POLARON: Precision-aware On-device Learning and Adaptive Runtime-cONfigurable AI acceleration, https://arxiv.org/pdf/2506.08785, 2025-06-10
2025-11-09 21:18:18,477 - INFO - root - Page:2, Index:33, MoQAE: Mixed-Precision Quantization for Long-Context LLM Inference via Mixture of Quantization-Aware Experts, https://arxiv.org/pdf/2506.07533, 2025-06-09
2025-11-09 21:18:18,483 - INFO - root - Page:2, Index:34, BitVLA: 1-bit Vision-Language-Action Models for Robotics Manipulation, https://arxiv.org/pdf/2506.07530, 2025-06-09
2025-11-09 21:18:18,487 - INFO - root - Page:2, Index:35, RecGPT: A Foundation Model for Sequential Recommendation, https://arxiv.org/pdf/2506.06270, 2025-06-12
2025-11-09 21:18:18,492 - INFO - root - Page:2, Index:36, FPSAttention: Training-Aware FP8 and Sparsity Co-Design for Fast Video Diffusion, https://arxiv.org/pdf/2506.04648, 2025-06-05
2025-11-09 21:18:18,494 - INFO - root - Page:2, Index:37, BitTTS: Highly Compact Text-to-Speech Using 1.58-bit Quantization and Weight Indexing, https://arxiv.org/pdf/2506.03515, 2025-06-03
2025-11-09 21:18:18,495 - INFO - root - Page:2, Index:38, ShapeLLM-Omni: A Native Multimodal LLM for 3D Generation and Understanding, https://arxiv.org/pdf/2506.01853, 2025-06-02
2025-11-09 21:18:18,495 - INFO - root - Page:2, Index:39, Movable Antenna Enhanced Federated Fine-Tuning of Large Language Models via Hybrid Client Selection Optimization, https://arxiv.org/pdf/2506.00011, 2025-10-26
2025-11-09 21:18:18,496 - INFO - root - Page:2, Index:40, Running Conventional Automatic Speech Recognition on Memristor Hardware: A Simulated Approach, https://arxiv.org/pdf/2505.24721, 2025-05-30
2025-11-09 21:18:18,496 - INFO - root - Page:2, Index:41, GARLIC: GAussian Representation LearnIng for spaCe partitioning, https://arxiv.org/pdf/2505.24608, 2025-10-02
2025-11-09 21:18:18,496 - INFO - root - Page:2, Index:42, AutoChemSchematic AI: Agentic Physics-Aware Automation for Chemical Manufacturing Scale-Up, https://arxiv.org/pdf/2505.24584, 2025-08-18
2025-11-09 21:18:18,498 - INFO - root - Page:2, Index:43, Model-Preserving Adaptive Rounding, https://arxiv.org/pdf/2505.22988, 2025-09-25
2025-11-09 21:18:18,498 - INFO - root - Page:2, Index:44, Highly Efficient and Effective LLMs with Multi-Boolean Architectures, https://arxiv.org/pdf/2505.22811, 2025-10-03
2025-11-09 21:18:18,498 - INFO - root - Page:2, Index:45, Pioneering 4-Bit FP Quantization for Diffusion Models: Mixup-Sign Quantization and Timestep-Aware Fine-Tuning, https://arxiv.org/pdf/2505.21591, 2025-05-27
2025-11-09 21:18:18,498 - INFO - root - Page:2, Index:46, Frequency Composition for Compressed and Domain-Adaptive Neural Networks, https://arxiv.org/pdf/2505.20890, 2025-05-27
2025-11-09 21:18:18,500 - INFO - root - Page:2, Index:47, MoPFormer: Motion-Primitive Transformer for Wearable-Sensor Activity Recognition, https://arxiv.org/pdf/2505.20744, 2025-10-27
2025-11-09 21:18:18,500 - INFO - root - Page:2, Index:48, Optimizing edge AI models on HPC systems with the edge in the loop, https://arxiv.org/pdf/2505.19995, 2025-05-26
2025-11-09 21:18:18,501 - INFO - root - Fetching page 4 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=150
2025-11-09 21:18:24,851 - INFO - root - get_all_titles_from_web 
2025-11-09 21:18:24,852 - INFO - root - Page:3, Index:0, DPASyn: Mechanism-Aware Drug Synergy Prediction via Dual Attention and Precision-Aware Quantization, https://arxiv.org/pdf/2505.19144, 2025-09-20
2025-11-09 21:18:24,852 - INFO - root - Page:3, Index:1, Reducing Storage of Pretrained Neural Networks by Rate-Constrained Quantization and Entropy Coding, https://arxiv.org/pdf/2505.18758, 2025-05-24
2025-11-09 21:18:24,852 - INFO - root - Page:3, Index:2, Beyond Discreteness: Finite-Sample Analysis of Straight-Through Estimator for Quantization, https://arxiv.org/pdf/2505.18113, 2025-05-23
2025-11-09 21:18:24,852 - INFO - root - Page:3, Index:3, Automating Versatile Time-Series Analysis with Tiny Transformers on Embedded FPGAs, https://arxiv.org/pdf/2505.17662, 2025-09-19
2025-11-09 21:18:24,854 - INFO - root - Page:3, Index:4, FPQVAR: Floating Point Quantization for Visual Autoregressive Model with FPGA Hardware Co-design, https://arxiv.org/pdf/2505.16335, 2025-05-22
2025-11-09 21:18:24,854 - INFO - root - Page:3, Index:5, Saliency-Aware Quantized Imitation Learning for Efficient Robotic Control, https://arxiv.org/pdf/2505.15304, 2025-05-30
2025-11-09 21:18:24,854 - INFO - root - Page:3, Index:6, Scaling Law for Quantization-Aware Training, https://arxiv.org/pdf/2505.14302, 2025-05-20
2025-11-09 21:18:24,854 - INFO - root - Page:3, Index:7, Automatic mixed precision for optimizing gained time with constrained loss mean-squared-error based on model partition to sequential sub-graphs, https://arxiv.org/pdf/2505.13060, 2025-05-19
2025-11-09 21:18:24,855 - INFO - root - Page:3, Index:8, Deep Unfolding with Kernel-based Quantization in MIMO Detection, https://arxiv.org/pdf/2505.12736, 2025-05-19
2025-11-09 21:18:24,855 - INFO - root - Page:3, Index:9, FedHQ: Hybrid Runtime Quantization for Federated Learning, https://arxiv.org/pdf/2505.11982, 2025-05-17
2025-11-09 21:18:24,855 - INFO - root - Page:3, Index:10, QVGen: Pushing the Limit of Quantized Video Generative Models, https://arxiv.org/pdf/2505.11497, 2025-09-27
2025-11-09 21:18:24,855 - INFO - root - Page:3, Index:11, EA-3DGS: Efficient and Adaptive 3D Gaussians with Highly Enhanced Quality for outdoor scenes, https://arxiv.org/pdf/2505.10787, 2025-05-15
2025-11-09 21:18:24,856 - INFO - root - Page:3, Index:12, ITERA-LLM: Boosting Sub-8-Bit Large Language Model Inference via Iterative Tensor Decomposition, https://arxiv.org/pdf/2505.08981, 2025-05-13
2025-11-09 21:18:24,856 - INFO - root - Page:3, Index:13, PROM: Prioritize Reduction of Multiplications Over Lower Bit-Widths for Efficient CNNs, https://arxiv.org/pdf/2505.03254, 2025-08-06
2025-11-09 21:18:24,857 - INFO - root - Page:3, Index:14, ICQuant: Index Coding enables Low-bit LLM Quantization, https://arxiv.org/pdf/2505.00850, 2025-08-24
2025-11-09 21:18:24,862 - INFO - root - Page:3, Index:15, Enhancing Ultra-Low-Bit Quantization of Large Language Models Through Saliency-Aware Partial Retraining, https://arxiv.org/pdf/2504.13932, 2025-07-30
2025-11-09 21:18:24,864 - INFO - root - Page:3, Index:16, Achieving binary weight and activation for LLMs using Post-Training Quantization, https://arxiv.org/pdf/2504.05352, 2025-06-30
2025-11-09 21:18:24,864 - INFO - root - Page:3, Index:17, Wireless Hearables With Programmable Speech AI Accelerators, https://arxiv.org/pdf/2503.18698, 2025-10-21
2025-11-09 21:18:24,865 - INFO - root - Page:3, Index:18, GranQ: Efficient Channel-wise Quantization via Vectorized Pre-Scaling for Zero-Shot QAT, https://arxiv.org/pdf/2503.18339, 2025-10-15
2025-11-09 21:18:24,865 - INFO - root - Page:3, Index:19, CompMarkGS: Robust Watermarking for Compressed 3D Gaussian Splatting, https://arxiv.org/pdf/2503.12836, 2025-09-29
2025-11-09 21:18:24,866 - INFO - root - Page:3, Index:20, AHCPTQ: Accurate and Hardware-Compatible Post-Training Quantization for Segment Anything Model, https://arxiv.org/pdf/2503.03088, 2025-07-11
2025-11-09 21:18:24,866 - INFO - root - Page:3, Index:21, Teaching Metric Distance to Discrete Autoregressive Language Models, https://arxiv.org/pdf/2503.02379, 2025-10-07
2025-11-09 21:18:24,866 - INFO - root - Page:3, Index:22, Regularization-based Framework for Quantization-, Fault- and Variability-Aware Training, https://arxiv.org/pdf/2503.01297, 2025-07-12
2025-11-09 21:18:24,867 - INFO - root - Fetching page 5 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=200
2025-11-09 21:18:31,718 - INFO - root - get_all_titles_from_web 
2025-11-09 21:18:31,718 - INFO - root - Page:4, Index:0, Investigating the Impact of Quantization Methods on the Safety and Reliability of Large Language Models, https://arxiv.org/pdf/2502.15799, 2025-06-29
2025-11-09 21:18:31,719 - INFO - root - Page:4, Index:1, Rotate, Clip, and Partition: Towards W2A4KV4 Quantization by Integrating Rotation and Learnable Non-uniform Quantizer, https://arxiv.org/pdf/2502.15779, 2025-09-01
2025-11-09 21:18:31,719 - INFO - root - Page:4, Index:2, RoSTE: An Efficient Quantization-Aware Supervised Fine-Tuning Approach for Large Language Models, https://arxiv.org/pdf/2502.09003, 2025-06-05
2025-11-09 21:18:31,719 - INFO - root - Page:4, Index:3, Spatial Degradation-Aware and Temporal Consistent Diffusion Model for Compressed Video Super-Resolution, https://arxiv.org/pdf/2502.07381, 2025-06-27
2025-11-09 21:18:31,719 - INFO - root - Page:4, Index:4, QuEST: Stable Training of LLMs with 1-Bit Weights and Activations, https://arxiv.org/pdf/2502.05003, 2025-06-10
2025-11-09 21:18:31,720 - INFO - root - Page:4, Index:5, HALO: Hadamard-Assisted Lower-Precision Optimization for LLMs, https://arxiv.org/pdf/2501.02625, 2025-11-05
2025-11-09 21:18:31,720 - INFO - root - Page:4, Index:6, TAR3D: Creating High-Quality 3D Assets via Next-Part Prediction, https://arxiv.org/pdf/2412.16919, 2025-08-08
2025-11-09 21:18:31,720 - INFO - root - Page:4, Index:7, Training Multi-Layer Binary Neural Networks With Local Binary Error Signals, https://arxiv.org/pdf/2412.00119, 2025-08-05
2025-11-09 21:18:31,721 - INFO - root - Page:4, Index:8, Scaling Large-scale GNN Training to Thousands of Processors on CPU-based Supercomputers, https://arxiv.org/pdf/2411.16025, 2025-05-26
2025-11-09 21:18:31,721 - INFO - root - Page:4, Index:9, HAFLQ: Heterogeneous Adaptive Federated LoRA Fine-tuned LLM with Quantization, https://arxiv.org/pdf/2411.06581, 2025-05-16
2025-11-09 21:18:31,721 - INFO - root - Fetching page 6 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=250
2025-11-09 21:18:38,692 - INFO - root - get_all_titles_from_web 
2025-11-09 21:18:38,692 - INFO - root - Page:5, Index:0, Gradient-Free Training of Quantized Neural Networks, https://arxiv.org/pdf/2410.09734, 2025-09-29
2025-11-09 21:18:38,693 - INFO - root - Page:5, Index:1, QT-DoG: Quantization-aware Training for Domain Generalization, https://arxiv.org/pdf/2410.06020, 2025-06-26
2025-11-09 21:18:38,693 - INFO - root - Page:5, Index:2, Constraint Guided Model Quantization of Neural Networks, https://arxiv.org/pdf/2409.20138, 2025-09-12
2025-11-09 21:18:38,693 - INFO - root - Page:5, Index:3, Accumulator-Aware Post-Training Quantization for Large Language Models, https://arxiv.org/pdf/2409.17092, 2025-07-30
2025-11-09 21:18:38,693 - INFO - root - Page:5, Index:4, DilateQuant: Accurate and Efficient Diffusion Quantization via Weight Dilation, https://arxiv.org/pdf/2409.14307, 2025-07-09
2025-11-09 21:18:38,693 - INFO - root - Page:5, Index:5, Robust Training of Neural Networks at Arbitrary Precision and Sparsity, https://arxiv.org/pdf/2409.09245, 2025-09-23
2025-11-09 21:18:38,694 - INFO - root - Page:5, Index:6, VQ-CTAP: Cross-Modal Fine-Grained Sequence Representation Learning for Speech Processing, https://arxiv.org/pdf/2408.05758, 2025-05-27
2025-11-09 21:18:38,694 - INFO - root - Page:5, Index:7, DopQ-ViT: Towards Distribution-Friendly and Outlier-Aware Post-Training Quantization for Vision Transformers, https://arxiv.org/pdf/2408.03291, 2025-06-19
2025-11-09 21:18:38,694 - INFO - root - Page:5, Index:8, Temporal Feature Matters: A Framework for Diffusion Model Quantization, https://arxiv.org/pdf/2407.19547, 2025-07-11
2025-11-09 21:18:38,694 - INFO - root - Page:5, Index:9, EfficientQAT: Efficient Quantization-Aware Training for Large Language Models, https://arxiv.org/pdf/2407.11062, 2025-05-19
2025-11-09 21:18:38,694 - INFO - root - Page:5, Index:10, Integer-only Quantized Transformers for Embedded FPGA-based Time-series Forecasting in AIoT, https://arxiv.org/pdf/2407.11041, 2025-10-31
2025-11-09 21:18:38,695 - INFO - root - Fetching page 7 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=300
2025-11-09 21:18:45,887 - INFO - root - get_all_titles_from_web 
2025-11-09 21:18:45,889 - INFO - root - Page:6, Index:0, BoA: Attention-aware Post-training Quantization without Backpropagation, https://arxiv.org/pdf/2406.13474, 2025-06-06
2025-11-09 21:18:45,889 - INFO - root - Page:6, Index:1, A Rescaling-Invariant Lipschitz Bound Based on Path-Metrics for Modern ReLU Network Parameterizations, https://arxiv.org/pdf/2405.15006, 2025-06-13
2025-11-09 21:18:45,891 - INFO - root - Page:6, Index:2, Scheduling Weight Transitions for Quantization-Aware Training, https://arxiv.org/pdf/2404.19248, 2025-10-01
2025-11-09 21:18:45,891 - INFO - root - Page:6, Index:3, GPTVQ: The Blessing of Dimensionality for LLM Quantization, https://arxiv.org/pdf/2402.15319, 2025-06-03
2025-11-09 21:18:45,893 - INFO - root - Fetching page 8 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=350
2025-11-09 21:18:53,552 - INFO - root - get_all_titles_from_web 
2025-11-09 21:18:53,559 - INFO - root - Page:7, Index:0, Squat: Quant Small Language Models on the Edge, https://arxiv.org/pdf/2402.10787, 2025-07-01
2025-11-09 21:18:53,562 - INFO - root - Page:7, Index:1, L4Q: Parameter Efficient Quantization-Aware Fine-Tuning on Large Language Models, https://arxiv.org/pdf/2402.04902, 2025-07-21
2025-11-09 21:18:53,563 - INFO - root - Fetching page 9 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=400
2025-11-09 21:19:00,507 - INFO - root - ------------------------------------------------------------------------------------------------------------------------
2025-11-09 21:19:00,508 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\A Quantized VAE-MLP Botnet Detection Model_ A Systematic Evaluation of Quantizat.pdf
2025-11-09 21:19:00,514 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\FP8-Flow-MoE_ A Casting-Free FP8 Recipe without Double Quantization Error.pdf
2025-11-09 21:19:00,516 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\Outlier-Aware Post-Training Quantization for Image Super-Resolution.pdf
2025-11-09 21:19:00,517 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\Evaluation of Wafer-Scale SOT-MRAM for Analog Crossbar Array Applications.pdf
2025-11-09 21:19:00,517 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\Improving the Straight-Through Estimator with Zeroth-Order Information.pdf
2025-11-09 21:19:00,518 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\Real-Time Semantic Segmentation on FPGA for Autonomous Vehicles Using LMIINet wi.pdf
2025-11-09 21:19:00,519 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\TernaryCLIP_ Efficiently Compressing Vision-Language Models with Ternary Weights.pdf
2025-11-09 21:19:00,523 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\KARIPAP_ Quantum-Inspired Tensor Network Compression of Large Language Models Us.pdf
2025-11-09 21:19:00,524 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\A Convergence Analysis of Adaptive Optimizers under Floating-point Quantization.pdf
2025-11-09 21:19:00,525 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\Adaptive Distribution-aware Quantization for Mixed-Precision Neural Networks.pdf
2025-11-09 21:19:00,525 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\CAGE_ Curvature-Aware Gradient Estimation For Accurate Quantization-Aware Traini.pdf
2025-11-09 21:19:00,528 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\Mixed-Precision Quantization for Language Models_ Techniques and Prospects.pdf
2025-11-09 21:19:00,531 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\SPLite Hand_ Sparsity-Aware Lightweight 3D Hand Pose Estimation.pdf
2025-11-09 21:19:00,532 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\CTR-LoRA_ Curvature-Aware and Trust-Region Guided Low-Rank Adaptation for Large.pdf
2025-11-09 21:19:00,535 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\SANR_ Scene-Aware Neural Representation for Light Field Image Compression with R.pdf
2025-11-09 21:19:00,538 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\SpikeFit_ Towards Optimal Deployment of Spiking Networks on Neuromorphic Hardwar.pdf
2025-11-09 21:19:00,539 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\GRank_ Towards Target-Aware and Streamlined Industrial Retrieval with a Generate.pdf
2025-11-09 21:19:00,540 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\SaLon3R_ Structure-aware Long-term Generalizable 3D Reconstruction from Unposed.pdf
2025-11-09 21:19:00,542 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\FraQAT_ Quantization Aware Training with Fractional bits.pdf
2025-11-09 21:19:00,543 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\Computing-In-Memory Aware Model Adaption For Edge Devices.pdf
2025-11-09 21:19:00,547 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\Invited Paper_ BitMedViT_ Ternary-Quantized Vision Transformer for Medical AI As.pdf
2025-11-09 21:19:00,547 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\NeuroRVQ_ Multi-Scale EEG Tokenization for Generative Large Brainwave Models.pdf
2025-11-09 21:19:00,548 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\Detect Anything via Next Point Prediction.pdf
2025-11-09 21:19:00,550 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\AndesVL Technical Report_ An Efficient Mobile-side Multimodal Large Language Mod.pdf
2025-11-09 21:19:00,553 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\Rescaling-Aware Training for Efficient Deployment of Deep Learning Models on Ful.pdf
2025-11-09 21:19:00,555 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\SASER_ Stego attacks on open-source LLMs.pdf
2025-11-09 21:19:00,556 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\Ultralytics YOLO Evolution_ An Overview of YOLO26, YOLO11, YOLOv8 and YOLOv5 Obj.pdf
2025-11-09 21:19:00,556 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\A Theoretically-Grounded Codebook for Digital Semantic Communications.pdf
2025-11-09 21:19:00,557 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\QuantDemoire_ Quantization with Outlier Aware for Image Demoiréing.pdf
2025-11-09 21:19:00,558 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\Adaptively Sampling-Reusing-Mixing Decomposed Gradients to Speed Up Sharpness Aw.pdf
2025-11-09 21:19:00,563 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\Quant-dLLM_ Post-Training Extreme Low-Bit Quantization for Diffusion Large Langu.pdf
2025-11-09 21:19:00,564 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\PT$^2$-LLM_ Post-Training Ternarization for Large Language Models.pdf
2025-11-09 21:19:00,565 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\Purrception_ Variational Flow Matching for Vector-Quantized Image Generation.pdf
2025-11-09 21:19:00,570 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\Post-Training Quantization for Audio Diffusion Transformers.pdf
2025-11-09 21:19:00,572 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\Rethinking RoPE Scaling in Quantized LLM_ Theory, Outlier, and Channel-Band Anal.pdf
2025-11-09 21:19:00,573 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\Post-Training Quantization via Residual Truncation and Zero Suppression for Diff.pdf
2025-11-09 21:19:00,574 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\Cat_ Post-Training Quantization Error Reduction via Cluster-based Affine Transfo.pdf
2025-11-09 21:19:00,575 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\CAST_ Continuous and Differentiable Semi-Structured Sparsity-Aware Training for.pdf
2025-11-09 21:19:00,576 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\Norm-Q_ Effective Compression Method for Hidden Markov Models in Neuro-Symbolic.pdf
2025-11-09 21:19:00,580 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\On-the-Fly Adaptation to Quantization_ Configuration-Aware LoRA for Efficient Fi.pdf
2025-11-09 21:19:00,581 - INFO - root - 跳过已处理论文 A Quantized VAE-MLP Botnet Detection Model: A Systematic Evaluation of Quantization-Aware Training and Post-Training Quantization Strategies：d:\ChatPaper\academic Papers\Quantization-Aware-Training\A Quantized VAE-MLP Botnet Detection Model_ A Systematic Evaluation of Quantizat.pdf
2025-11-09 21:19:00,582 - INFO - root - 跳过已处理论文 FP8-Flow-MoE: A Casting-Free FP8 Recipe without Double Quantization Error：d:\ChatPaper\academic Papers\Quantization-Aware-Training\FP8-Flow-MoE_ A Casting-Free FP8 Recipe without Double Quantization Error.pdf
2025-11-09 21:19:00,585 - INFO - root - 跳过已处理论文 Outlier-Aware Post-Training Quantization for Image Super-Resolution：d:\ChatPaper\academic Papers\Quantization-Aware-Training\Outlier-Aware Post-Training Quantization for Image Super-Resolution.pdf
2025-11-09 21:19:00,585 - INFO - root - 跳过已处理论文 Evaluation of Wafer-Scale SOT-MRAM for Analog Crossbar Array Applications：d:\ChatPaper\academic Papers\Quantization-Aware-Training\Evaluation of Wafer-Scale SOT-MRAM for Analog Crossbar Array Applications.pdf
2025-11-09 21:19:00,586 - INFO - root - 跳过已处理论文 Improving the Straight-Through Estimator with Zeroth-Order Information：d:\ChatPaper\academic Papers\Quantization-Aware-Training\Improving the Straight-Through Estimator with Zeroth-Order Information.pdf
2025-11-09 21:19:00,587 - INFO - root - 跳过已处理论文 Real-Time Semantic Segmentation on FPGA for Autonomous Vehicles Using LMIINet with the CGRA4ML Framework：d:\ChatPaper\academic Papers\Quantization-Aware-Training\Real-Time Semantic Segmentation on FPGA for Autonomous Vehicles Using LMIINet wi.pdf
2025-11-09 21:19:00,587 - INFO - root - 跳过已处理论文 TernaryCLIP: Efficiently Compressing Vision-Language Models with Ternary Weights and Distilled Knowledge：d:\ChatPaper\academic Papers\Quantization-Aware-Training\TernaryCLIP_ Efficiently Compressing Vision-Language Models with Ternary Weights.pdf
2025-11-09 21:19:00,587 - INFO - root - 正在总结论文 8/40: KARIPAP: Quantum-Inspired Tensor Network Compression of Large Language Models Using Infinite Projected Entangled Pair States and Tensor Renormalization Group
2025-11-09 21:19:35,806 - INFO - root - LLMClient: rate limit reached, sleeping 24.8s
2025-11-09 21:20:21,177 - INFO - root - 正在提取论文图片...
2025-11-09 21:20:21,328 - INFO - root - 已保存图片 1/10：./export\images_KARIPAP_ Quantum-Inspired Tensor Network Compression of Large Language Models Us\figure_1_page3.jpeg
2025-11-09 21:20:21,403 - INFO - root - 已保存图片 2/10：./export\images_KARIPAP_ Quantum-Inspired Tensor Network Compression of Large Language Models Us\figure_2_page7.png
2025-11-09 21:20:21,472 - INFO - root - 已保存图片 3/10：./export\images_KARIPAP_ Quantum-Inspired Tensor Network Compression of Large Language Models Us\figure_3_page9.png
2025-11-09 21:20:21,550 - INFO - root - 已保存图片 4/10：./export\images_KARIPAP_ Quantum-Inspired Tensor Network Compression of Large Language Models Us\figure_4_page8.png
2025-11-09 21:20:21,552 - INFO - root - 成功添加图片 1：./export\images_KARIPAP_ Quantum-Inspired Tensor Network Compression of Large Language Models Us\figure_1_page3.jpeg
2025-11-09 21:20:21,552 - INFO - root - 成功添加图片 2：./export\images_KARIPAP_ Quantum-Inspired Tensor Network Compression of Large Language Models Us\figure_2_page7.png
2025-11-09 21:20:21,552 - INFO - root - 成功添加图片 3：./export\images_KARIPAP_ Quantum-Inspired Tensor Network Compression of Large Language Models Us\figure_3_page9.png
2025-11-09 21:20:21,553 - INFO - root - 成功添加图片 4：./export\images_KARIPAP_ Quantum-Inspired Tensor Network Compression of Large Language Models Us\figure_4_page8.png
2025-11-09 21:20:21,554 - INFO - root - 论文《KARIPAP: Quantum-Inspired Tensor Network Compression of Large Language Models Using Infinite Projected Entangled Pair States and Tensor Renormalization Group》的分析已保存到 ./export\KARIPAP_ Quantum-Inspired Tensor Network Compression of Large Language Models Us.md
2025-11-09 21:20:21,557 - INFO - root - 正在总结论文 9/40: A Convergence Analysis of Adaptive Optimizers under Floating-point Quantization
2025-11-09 21:20:31,698 - INFO - root - LLMClient: rate limit reached, sleeping 28.9s
2025-11-09 21:21:50,391 - INFO - root - 正在提取论文图片...
2025-11-09 21:21:50,458 - INFO - root - 论文《A Convergence Analysis of Adaptive Optimizers under Floating-point Quantization》的分析已保存到 ./export\A Convergence Analysis of Adaptive Optimizers under Floating-point Quantization.md
2025-11-09 21:21:50,460 - INFO - root - 正在总结论文 10/40: Adaptive Distribution-aware Quantization for Mixed-Precision Neural Networks
2025-11-09 21:21:50,460 - INFO - root - LLMClient: rate limit reached, sleeping 10.1s
2025-11-09 21:22:11,535 - INFO - root - LLMClient: rate limit reached, sleeping 17.7s
2025-11-09 21:22:56,386 - INFO - root - LLMClient: rate limit reached, sleeping 4.2s
2025-11-09 21:23:19,458 - INFO - root - 正在提取论文图片...
2025-11-09 21:23:19,622 - INFO - root - 已保存图片 1/10：./export\images_Adaptive Distribution-aware Quantization for Mixed-Precision Neural Networks\figure_1_page6.png
2025-11-09 21:23:19,678 - INFO - root - 已保存图片 2/10：./export\images_Adaptive Distribution-aware Quantization for Mixed-Precision Neural Networks\figure_2_page13.png
2025-11-09 21:23:19,735 - INFO - root - 已保存图片 3/10：./export\images_Adaptive Distribution-aware Quantization for Mixed-Precision Neural Networks\figure_3_page13.png
2025-11-09 21:23:19,750 - INFO - root - 已保存图片 4/10：./export\images_Adaptive Distribution-aware Quantization for Mixed-Precision Neural Networks\figure_4_page3.jpeg
2025-11-09 21:23:19,780 - INFO - root - 已保存图片 5/10：./export\images_Adaptive Distribution-aware Quantization for Mixed-Precision Neural Networks\figure_5_page3.jpeg
2025-11-09 21:23:19,808 - INFO - root - 已保存图片 6/10：./export\images_Adaptive Distribution-aware Quantization for Mixed-Precision Neural Networks\figure_6_page3.jpeg
2025-11-09 21:23:19,848 - INFO - root - 已保存图片 7/10：./export\images_Adaptive Distribution-aware Quantization for Mixed-Precision Neural Networks\figure_7_page3.jpeg
2025-11-09 21:23:20,010 - INFO - root - 已保存图片 8/10：./export\images_Adaptive Distribution-aware Quantization for Mixed-Precision Neural Networks\figure_8_page2.png
2025-11-09 21:23:20,123 - INFO - root - 已保存图片 9/10：./export\images_Adaptive Distribution-aware Quantization for Mixed-Precision Neural Networks\figure_9_page2.png
2025-11-09 21:23:20,230 - INFO - root - 已保存图片 10/10：./export\images_Adaptive Distribution-aware Quantization for Mixed-Precision Neural Networks\figure_10_page2.png
2025-11-09 21:23:20,233 - INFO - root - 成功添加图片 1：./export\images_Adaptive Distribution-aware Quantization for Mixed-Precision Neural Networks\figure_1_page6.png
2025-11-09 21:23:20,233 - INFO - root - 成功添加图片 2：./export\images_Adaptive Distribution-aware Quantization for Mixed-Precision Neural Networks\figure_2_page13.png
2025-11-09 21:23:20,234 - INFO - root - 成功添加图片 3：./export\images_Adaptive Distribution-aware Quantization for Mixed-Precision Neural Networks\figure_3_page13.png
2025-11-09 21:23:20,235 - INFO - root - 成功添加图片 4：./export\images_Adaptive Distribution-aware Quantization for Mixed-Precision Neural Networks\figure_4_page3.jpeg
2025-11-09 21:23:20,235 - INFO - root - 成功添加图片 5：./export\images_Adaptive Distribution-aware Quantization for Mixed-Precision Neural Networks\figure_5_page3.jpeg
2025-11-09 21:23:20,243 - INFO - root - 成功添加图片 6：./export\images_Adaptive Distribution-aware Quantization for Mixed-Precision Neural Networks\figure_6_page3.jpeg
2025-11-09 21:23:20,243 - INFO - root - 成功添加图片 7：./export\images_Adaptive Distribution-aware Quantization for Mixed-Precision Neural Networks\figure_7_page3.jpeg
2025-11-09 21:23:20,246 - INFO - root - 成功添加图片 8：./export\images_Adaptive Distribution-aware Quantization for Mixed-Precision Neural Networks\figure_8_page2.png
2025-11-09 21:23:20,247 - INFO - root - 成功添加图片 9：./export\images_Adaptive Distribution-aware Quantization for Mixed-Precision Neural Networks\figure_9_page2.png
2025-11-09 21:23:20,248 - INFO - root - 成功添加图片 10：./export\images_Adaptive Distribution-aware Quantization for Mixed-Precision Neural Networks\figure_10_page2.png
2025-11-09 21:23:20,266 - INFO - root - 论文《Adaptive Distribution-aware Quantization for Mixed-Precision Neural Networks》的分析已保存到 ./export\Adaptive Distribution-aware Quantization for Mixed-Precision Neural Networks.md
2025-11-09 21:23:20,280 - INFO - root - 正在总结论文 11/40: CAGE: Curvature-Aware Gradient Estimation For Accurate Quantization-Aware Training
2025-11-09 21:23:20,280 - INFO - root - LLMClient: rate limit reached, sleeping 8.9s
2025-11-09 21:23:39,801 - INFO - root - LLMClient: rate limit reached, sleeping 20.8s
2025-11-09 21:25:27,247 - INFO - root - 正在提取论文图片...
2025-11-09 21:25:27,274 - INFO - root - 已保存图片 1/10：./export\images_CAGE_ Curvature-Aware Gradient Estimation For Accurate Quantization-Aware Traini\figure_1_page8.png
2025-11-09 21:25:27,278 - INFO - root - 成功添加图片 1：./export\images_CAGE_ Curvature-Aware Gradient Estimation For Accurate Quantization-Aware Traini\figure_1_page8.png
2025-11-09 21:25:27,280 - INFO - root - 论文《CAGE: Curvature-Aware Gradient Estimation For Accurate Quantization-Aware Training》的分析已保存到 ./export\CAGE_ Curvature-Aware Gradient Estimation For Accurate Quantization-Aware Traini.md
2025-11-09 21:25:27,286 - INFO - root - 正在总结论文 12/40: Mixed-Precision Quantization for Language Models: Techniques and Prospects
2025-11-09 21:25:38,271 - INFO - root - LLMClient: rate limit reached, sleeping 23.1s
2025-11-09 21:26:26,869 - INFO - root - LLMClient: rate limit reached, sleeping 0.4s
2025-11-09 21:26:45,787 - INFO - root - 正在提取论文图片...
2025-11-09 21:26:50,900 - INFO - root - 已保存图片 1/10：./export\images_Mixed-Precision Quantization for Language Models_ Techniques and Prospects\figure_1_page28.png
2025-11-09 21:26:51,503 - INFO - root - 已保存图片 2/10：./export\images_Mixed-Precision Quantization for Language Models_ Techniques and Prospects\figure_2_page4.png
2025-11-09 21:26:51,627 - INFO - root - 已保存图片 3/10：./export\images_Mixed-Precision Quantization for Language Models_ Techniques and Prospects\figure_3_page6.png
2025-11-09 21:26:51,763 - INFO - root - 已保存图片 4/10：./export\images_Mixed-Precision Quantization for Language Models_ Techniques and Prospects\figure_4_page6.png
2025-11-09 21:26:51,901 - INFO - root - 已保存图片 5/10：./export\images_Mixed-Precision Quantization for Language Models_ Techniques and Prospects\figure_5_page6.png
2025-11-09 21:26:52,008 - INFO - root - 已保存图片 6/10：./export\images_Mixed-Precision Quantization for Language Models_ Techniques and Prospects\figure_6_page6.png
2025-11-09 21:26:52,028 - INFO - root - 成功添加图片 1：./export\images_Mixed-Precision Quantization for Language Models_ Techniques and Prospects\figure_1_page28.png
2025-11-09 21:26:52,029 - INFO - root - 成功添加图片 2：./export\images_Mixed-Precision Quantization for Language Models_ Techniques and Prospects\figure_2_page4.png
2025-11-09 21:26:52,029 - INFO - root - 成功添加图片 3：./export\images_Mixed-Precision Quantization for Language Models_ Techniques and Prospects\figure_3_page6.png
2025-11-09 21:26:52,032 - INFO - root - 成功添加图片 4：./export\images_Mixed-Precision Quantization for Language Models_ Techniques and Prospects\figure_4_page6.png
2025-11-09 21:26:52,038 - INFO - root - 成功添加图片 5：./export\images_Mixed-Precision Quantization for Language Models_ Techniques and Prospects\figure_5_page6.png
2025-11-09 21:26:52,038 - INFO - root - 成功添加图片 6：./export\images_Mixed-Precision Quantization for Language Models_ Techniques and Prospects\figure_6_page6.png
2025-11-09 21:26:52,060 - INFO - root - 论文《Mixed-Precision Quantization for Language Models: Techniques and Prospects》的分析已保存到 ./export\Mixed-Precision Quantization for Language Models_ Techniques and Prospects.md
2025-11-09 21:26:52,092 - INFO - root - 正在总结论文 13/40: SPLite Hand: Sparsity-Aware Lightweight 3D Hand Pose Estimation
2025-11-09 21:26:52,094 - INFO - root - LLMClient: rate limit reached, sleeping 9.4s
2025-11-09 21:27:11,444 - INFO - root - LLMClient: rate limit reached, sleeping 15.8s
2025-11-09 21:27:55,394 - INFO - root - LLMClient: rate limit reached, sleeping 6.1s
2025-11-09 21:28:20,315 - INFO - root - 正在提取论文图片...
2025-11-09 21:28:23,476 - INFO - root - 已保存图片 1/10：./export\images_SPLite Hand_ Sparsity-Aware Lightweight 3D Hand Pose Estimation\figure_1_page3.jpeg
2025-11-09 21:28:24,254 - INFO - root - 已保存图片 2/10：./export\images_SPLite Hand_ Sparsity-Aware Lightweight 3D Hand Pose Estimation\figure_2_page8.png
2025-11-09 21:28:24,571 - INFO - root - 已保存图片 3/10：./export\images_SPLite Hand_ Sparsity-Aware Lightweight 3D Hand Pose Estimation\figure_3_page8.png
2025-11-09 21:28:24,928 - INFO - root - 已保存图片 4/10：./export\images_SPLite Hand_ Sparsity-Aware Lightweight 3D Hand Pose Estimation\figure_4_page10.png
2025-11-09 21:28:25,221 - INFO - root - 已保存图片 5/10：./export\images_SPLite Hand_ Sparsity-Aware Lightweight 3D Hand Pose Estimation\figure_5_page9.png
2025-11-09 21:28:25,280 - INFO - root - 成功添加图片 1：./export\images_SPLite Hand_ Sparsity-Aware Lightweight 3D Hand Pose Estimation\figure_1_page3.jpeg
2025-11-09 21:28:25,290 - INFO - root - 成功添加图片 2：./export\images_SPLite Hand_ Sparsity-Aware Lightweight 3D Hand Pose Estimation\figure_2_page8.png
2025-11-09 21:28:25,301 - INFO - root - 成功添加图片 3：./export\images_SPLite Hand_ Sparsity-Aware Lightweight 3D Hand Pose Estimation\figure_3_page8.png
2025-11-09 21:28:25,316 - INFO - root - 成功添加图片 4：./export\images_SPLite Hand_ Sparsity-Aware Lightweight 3D Hand Pose Estimation\figure_4_page10.png
2025-11-09 21:28:25,366 - INFO - root - 成功添加图片 5：./export\images_SPLite Hand_ Sparsity-Aware Lightweight 3D Hand Pose Estimation\figure_5_page9.png
2025-11-09 21:28:25,380 - INFO - root - 论文《SPLite Hand: Sparsity-Aware Lightweight 3D Hand Pose Estimation》的分析已保存到 ./export\SPLite Hand_ Sparsity-Aware Lightweight 3D Hand Pose Estimation.md
2025-11-09 21:28:25,385 - INFO - root - 正在总结论文 14/40: CTR-LoRA: Curvature-Aware and Trust-Region Guided Low-Rank Adaptation for Large Language Models
2025-11-09 21:28:25,386 - INFO - root - LLMClient: rate limit reached, sleeping 1.9s
2025-11-09 21:28:38,613 - INFO - root - LLMClient: rate limit reached, sleeping 22.9s
2025-11-09 21:29:50,653 - INFO - root - 正在提取论文图片...
2025-11-09 21:29:51,070 - INFO - root - 已保存图片 1/10：./export\images_CTR-LoRA_ Curvature-Aware and Trust-Region Guided Low-Rank Adaptation for Large\figure_1_page3.png
2025-11-09 21:29:51,154 - INFO - root - 已保存图片 2/10：./export\images_CTR-LoRA_ Curvature-Aware and Trust-Region Guided Low-Rank Adaptation for Large\figure_2_page1.png
2025-11-09 21:29:51,158 - INFO - root - 成功添加图片 1：./export\images_CTR-LoRA_ Curvature-Aware and Trust-Region Guided Low-Rank Adaptation for Large\figure_1_page3.png
2025-11-09 21:29:51,159 - INFO - root - 成功添加图片 2：./export\images_CTR-LoRA_ Curvature-Aware and Trust-Region Guided Low-Rank Adaptation for Large\figure_2_page1.png
2025-11-09 21:29:51,168 - INFO - root - 论文《CTR-LoRA: Curvature-Aware and Trust-Region Guided Low-Rank Adaptation for Large Language Models》的分析已保存到 ./export\CTR-LoRA_ Curvature-Aware and Trust-Region Guided Low-Rank Adaptation for Large.md
2025-11-09 21:29:51,175 - INFO - root - 正在总结论文 15/40: SANR: Scene-Aware Neural Representation for Light Field Image Compression with Rate-Distortion Optimization
2025-11-09 21:29:51,175 - INFO - root - LLMClient: rate limit reached, sleeping 10.3s
2025-11-09 21:30:11,215 - INFO - root - LLMClient: rate limit reached, sleeping 20.7s
2025-11-09 21:32:00,506 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-09 21:32:00,508 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-09 21:32:00,512 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-09 21:32:01,688 - INFO - root - LLMClientManager: 指定使用客户端: Gemini
2025-11-09 21:32:02,454 - INFO - root - GeminiClient: trying model models/gemini-2.5-flash
2025-11-09 21:32:04,768 - INFO - root - GeminiClient: initialized model gemini-2.5-flash
2025-11-09 21:32:04,777 - INFO - root - LLMClientManager: Gemini 客户端初始化成功
2025-11-09 21:32:04,782 - INFO - root - LLMClientManager: switched to Gemini client
2025-11-09 21:32:04,785 - INFO - root - 已手动切换到 LLM 客户端: Gemini
2025-11-09 21:32:04,789 - INFO - root - 使用 LLM 模型: gemini-2.5-flash
2025-11-09 21:32:04,792 - INFO - root - 可用客户端: ['Gemini']
2025-11-09 21:32:04,794 - INFO - root - === 运行配置 ===
2025-11-09 21:32:04,799 - INFO - root - 处理模式: arxiv在线搜索
2025-11-09 21:32:04,803 - INFO - root - 关键词: QAT
2025-11-09 21:32:04,808 - INFO - root - 查询: Quantization-Aware-Training
2025-11-09 21:32:04,813 - INFO - root - 排序: None
2025-11-09 21:32:04,817 - INFO - root - 最近天数: 180
2025-11-09 21:32:04,819 - INFO - root - 最大处理数量: 40
2025-11-09 21:32:04,823 - INFO - root - 保存图片: 是
2025-11-09 21:32:04,825 - INFO - root - 输出语言: 中文
2025-11-09 21:32:04,828 - INFO - root - 强制重新处理: 否
2025-11-09 21:32:04,834 - INFO - root - ====================
2025-11-09 21:32:04,837 - INFO - root - 使用 arXiv 搜索模式（通过 chat_arxiv 模块获取）
2025-11-09 21:32:04,840 - INFO - root - Fetching page 1 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50
2025-11-09 21:32:12,412 - INFO - root - get_all_titles_from_web 
2025-11-09 21:32:12,413 - INFO - root - Page:0, Index:0, A Quantized VAE-MLP Botnet Detection Model: A Systematic Evaluation of Quantization-Aware Training and Post-Training Quantization Strategies, https://arxiv.org/pdf/2511.03201, 2025-11-05
2025-11-09 21:32:12,413 - INFO - root - Page:0, Index:1, FP8-Flow-MoE: A Casting-Free FP8 Recipe without Double Quantization Error, https://arxiv.org/pdf/2511.02302, 2025-11-04
2025-11-09 21:32:12,413 - INFO - root - Page:0, Index:2, Outlier-Aware Post-Training Quantization for Image Super-Resolution, https://arxiv.org/pdf/2511.00682, 2025-11-01
2025-11-09 21:32:12,413 - INFO - root - Page:0, Index:3, Evaluation of Wafer-Scale SOT-MRAM for Analog Crossbar Array Applications, https://arxiv.org/pdf/2510.25853, 2025-11-03
2025-11-09 21:32:12,414 - INFO - root - Page:0, Index:4, Improving the Straight-Through Estimator with Zeroth-Order Information, https://arxiv.org/pdf/2510.23926, 2025-10-27
2025-11-09 21:32:12,414 - INFO - root - Page:0, Index:5, Real-Time Semantic Segmentation on FPGA for Autonomous Vehicles Using LMIINet with the CGRA4ML Framework, https://arxiv.org/pdf/2510.22243, 2025-10-25
2025-11-09 21:32:12,414 - INFO - root - Page:0, Index:6, TernaryCLIP: Efficiently Compressing Vision-Language Models with Ternary Weights and Distilled Knowledge, https://arxiv.org/pdf/2510.21879, 2025-10-23
2025-11-09 21:32:12,415 - INFO - root - Page:0, Index:7, KARIPAP: Quantum-Inspired Tensor Network Compression of Large Language Models Using Infinite Projected Entangled Pair States and Tensor Renormalization Group, https://arxiv.org/pdf/2510.21844, 2025-10-22
2025-11-09 21:32:12,415 - INFO - root - Page:0, Index:8, A Convergence Analysis of Adaptive Optimizers under Floating-point Quantization, https://arxiv.org/pdf/2510.21314, 2025-10-24
2025-11-09 21:32:12,415 - INFO - root - Page:0, Index:9, Adaptive Distribution-aware Quantization for Mixed-Precision Neural Networks, https://arxiv.org/pdf/2510.19760, 2025-10-22
2025-11-09 21:32:12,415 - INFO - root - Page:0, Index:10, CAGE: Curvature-Aware Gradient Estimation For Accurate Quantization-Aware Training, https://arxiv.org/pdf/2510.18784, 2025-10-21
2025-11-09 21:32:12,416 - INFO - root - Page:0, Index:11, Mixed-Precision Quantization for Language Models: Techniques and Prospects, https://arxiv.org/pdf/2510.16805, 2025-10-19
2025-11-09 21:32:12,416 - INFO - root - Page:0, Index:12, SPLite Hand: Sparsity-Aware Lightweight 3D Hand Pose Estimation, https://arxiv.org/pdf/2510.16396, 2025-10-30
2025-11-09 21:32:12,416 - INFO - root - Page:0, Index:13, CTR-LoRA: Curvature-Aware and Trust-Region Guided Low-Rank Adaptation for Large Language Models, https://arxiv.org/pdf/2510.15962, 2025-10-11
2025-11-09 21:32:12,416 - INFO - root - Page:0, Index:14, SANR: Scene-Aware Neural Representation for Light Field Image Compression with Rate-Distortion Optimization, https://arxiv.org/pdf/2510.15775, 2025-10-17
2025-11-09 21:32:12,417 - INFO - root - Page:0, Index:15, SpikeFit: Towards Optimal Deployment of Spiking Networks on Neuromorphic Hardware, https://arxiv.org/pdf/2510.15542, 2025-10-31
2025-11-09 21:32:12,417 - INFO - root - Page:0, Index:16, GRank: Towards Target-Aware and Streamlined Industrial Retrieval with a Generate-Rank Framework, https://arxiv.org/pdf/2510.15299, 2025-10-17
2025-11-09 21:32:12,417 - INFO - root - Page:0, Index:17, SaLon3R: Structure-aware Long-term Generalizable 3D Reconstruction from Unposed Images, https://arxiv.org/pdf/2510.15072, 2025-10-16
2025-11-09 21:32:12,418 - INFO - root - Page:0, Index:18, FraQAT: Quantization Aware Training with Fractional bits, https://arxiv.org/pdf/2510.14823, 2025-10-16
2025-11-09 21:32:12,418 - INFO - root - Page:0, Index:19, Computing-In-Memory Aware Model Adaption For Edge Devices, https://arxiv.org/pdf/2510.14379, 2025-10-16
2025-11-09 21:32:12,418 - INFO - root - Page:0, Index:20, Invited Paper: BitMedViT: Ternary-Quantized Vision Transformer for Medical AI Assistants on the Edge, https://arxiv.org/pdf/2510.13760, 2025-11-04
2025-11-09 21:32:12,418 - INFO - root - Page:0, Index:21, NeuroRVQ: Multi-Scale EEG Tokenization for Generative Large Brainwave Models, https://arxiv.org/pdf/2510.13068, 2025-10-14
2025-11-09 21:32:12,419 - INFO - root - Page:0, Index:22, Detect Anything via Next Point Prediction, https://arxiv.org/pdf/2510.12798, 2025-10-14
2025-11-09 21:32:12,420 - INFO - root - Page:0, Index:23, AndesVL Technical Report: An Efficient Mobile-side Multimodal Large Language Model, https://arxiv.org/pdf/2510.11496, 2025-10-14
2025-11-09 21:32:12,420 - INFO - root - Page:0, Index:24, Rescaling-Aware Training for Efficient Deployment of Deep Learning Models on Full-Integer Hardware, https://arxiv.org/pdf/2510.11484, 2025-10-13
2025-11-09 21:32:12,421 - INFO - root - Page:0, Index:25, SASER: Stego attacks on open-source LLMs, https://arxiv.org/pdf/2510.10486, 2025-10-12
2025-11-09 21:32:12,421 - INFO - root - Page:0, Index:26, Ultralytics YOLO Evolution: An Overview of YOLO26, YOLO11, YOLOv8 and YOLOv5 Object Detectors for Computer Vision and Pattern Recognition, https://arxiv.org/pdf/2510.09653, 2025-10-15
2025-11-09 21:32:12,422 - INFO - root - Page:0, Index:27, A Theoretically-Grounded Codebook for Digital Semantic Communications, https://arxiv.org/pdf/2510.07108, 2025-10-14
2025-11-09 21:32:12,423 - INFO - root - Page:0, Index:28, QuantDemoire: Quantization with Outlier Aware for Image Demoiréing, https://arxiv.org/pdf/2510.04066, 2025-10-05
2025-11-09 21:32:12,423 - INFO - root - Page:0, Index:29, Adaptively Sampling-Reusing-Mixing Decomposed Gradients to Speed Up Sharpness Aware Minimization, https://arxiv.org/pdf/2510.03763, 2025-10-04
2025-11-09 21:32:12,424 - INFO - root - Page:0, Index:30, Quant-dLLM: Post-Training Extreme Low-Bit Quantization for Diffusion Large Language Models, https://arxiv.org/pdf/2510.03274, 2025-09-27
2025-11-09 21:32:12,424 - INFO - root - Page:0, Index:31, PT$^2$-LLM: Post-Training Ternarization for Large Language Models, https://arxiv.org/pdf/2510.03267, 2025-09-26
2025-11-09 21:32:12,424 - INFO - root - Page:0, Index:32, Purrception: Variational Flow Matching for Vector-Quantized Image Generation, https://arxiv.org/pdf/2510.01478, 2025-10-01
2025-11-09 21:32:12,426 - INFO - root - Page:0, Index:33, Post-Training Quantization for Audio Diffusion Transformers, https://arxiv.org/pdf/2510.00313, 2025-09-30
2025-11-09 21:32:12,426 - INFO - root - Page:0, Index:34, Rethinking RoPE Scaling in Quantized LLM: Theory, Outlier, and Channel-Band Analysis with Weight Rescaling, https://arxiv.org/pdf/2510.00028, 2025-09-25
2025-11-09 21:32:12,426 - INFO - root - Page:0, Index:35, Post-Training Quantization via Residual Truncation and Zero Suppression for Diffusion Models, https://arxiv.org/pdf/2509.26436, 2025-09-30
2025-11-09 21:32:12,427 - INFO - root - Page:0, Index:36, Cat: Post-Training Quantization Error Reduction via Cluster-based Affine Transformation, https://arxiv.org/pdf/2509.26277, 2025-10-07
2025-11-09 21:32:12,427 - INFO - root - Page:0, Index:37, CAST: Continuous and Differentiable Semi-Structured Sparsity-Aware Training for Large Language Models, https://arxiv.org/pdf/2509.25996, 2025-09-30
2025-11-09 21:32:12,427 - INFO - root - Page:0, Index:38, Norm-Q: Effective Compression Method for Hidden Markov Models in Neuro-Symbolic Applications, https://arxiv.org/pdf/2509.25439, 2025-09-29
2025-11-09 21:32:12,427 - INFO - root - Page:0, Index:39, On-the-Fly Adaptation to Quantization: Configuration-Aware LoRA for Efficient Fine-Tuning of Quantized LLMs, https://arxiv.org/pdf/2509.25214, 2025-09-22
2025-11-09 21:32:12,429 - INFO - root - Page:0, Index:40, VoxCPM: Tokenizer-Free TTS for Context-Aware Speech Generation and True-to-Life Voice Cloning, https://arxiv.org/pdf/2509.24650, 2025-09-29
2025-11-09 21:32:12,429 - INFO - root - Page:0, Index:41, S$^2$NN: Sub-bit Spiking Neural Networks, https://arxiv.org/pdf/2509.24266, 2025-10-24
2025-11-09 21:32:12,430 - INFO - root - Page:0, Index:42, Tequila: Trapping-free Ternary Quantization for Large Language Models, https://arxiv.org/pdf/2509.23809, 2025-10-17
2025-11-09 21:32:12,430 - INFO - root - Page:0, Index:43, Texture Vector-Quantization and Reconstruction Aware Prediction for Generative Super-Resolution, https://arxiv.org/pdf/2509.23774, 2025-09-30
2025-11-09 21:32:12,430 - INFO - root - Page:0, Index:44, RobuQ: Pushing DiTs to W1.58A2 via Robust Activation Quantization, https://arxiv.org/pdf/2509.23582, 2025-09-27
2025-11-09 21:32:12,430 - INFO - root - Page:0, Index:45, Beyond Outliers: A Study of Optimizers Under Quantization, https://arxiv.org/pdf/2509.23500, 2025-10-02
2025-11-09 21:32:12,431 - INFO - root - Page:0, Index:46, Compute-Optimal Quantization-Aware Training, https://arxiv.org/pdf/2509.22935, 2025-09-26
2025-11-09 21:32:12,431 - INFO - root - Page:0, Index:47, COSPADI: Compressing LLMs via Calibration-Guided Sparse Dictionary Learning, https://arxiv.org/pdf/2509.22075, 2025-10-06
2025-11-09 21:32:12,432 - INFO - root - Page:0, Index:48, SlimDiff: Training-Free, Activation-Guided Hands-free Slimming of Diffusion Models, https://arxiv.org/pdf/2509.21498, 2025-09-25
2025-11-09 21:32:12,432 - INFO - root - Page:0, Index:49, Quantized Visual Geometry Grounded Transformer, https://arxiv.org/pdf/2509.21302, 2025-09-29
2025-11-09 21:32:12,432 - INFO - root - Fetching page 2 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=50
2025-11-09 21:32:19,102 - INFO - root - get_all_titles_from_web 
2025-11-09 21:32:19,102 - INFO - root - Page:1, Index:0, Can Less Precise Be More Reliable? A Systematic Evaluation of Quantization's Impact on CLIP Beyond Accuracy, https://arxiv.org/pdf/2509.21173, 2025-10-27
2025-11-09 21:32:19,103 - INFO - root - Page:1, Index:1, Punching Above Precision: Small Quantized Model Distillation with Learnable Regularizer, https://arxiv.org/pdf/2509.20854, 2025-09-25
2025-11-09 21:32:19,103 - INFO - root - Page:1, Index:2, TinyEcoWeedNet: Edge Efficient Real-Time Aerial Agricultural Weed Detection, https://arxiv.org/pdf/2509.18193, 2025-09-19
2025-11-09 21:32:19,103 - INFO - root - Page:1, Index:3, SBVR: Summation of BitVector Representation for Efficient LLM Quantization, https://arxiv.org/pdf/2509.18172, 2025-09-17
2025-11-09 21:32:19,103 - INFO - root - Page:1, Index:4, QWHA: Quantization-Aware Walsh-Hadamard Adaptation for Parameter-Efficient Fine-Tuning on Large Language Models, https://arxiv.org/pdf/2509.17428, 2025-09-26
2025-11-09 21:32:19,104 - INFO - root - Page:1, Index:5, PTQTP: Post-Training Quantization to Trit-Planes for Large Language Models, https://arxiv.org/pdf/2509.16989, 2025-10-28
2025-11-09 21:32:19,104 - INFO - root - Page:1, Index:6, MEC-Quant: Maximum Entropy Coding for Extremely Low Bit Quantization-Aware Training, https://arxiv.org/pdf/2509.15514, 2025-09-18
2025-11-09 21:32:19,104 - INFO - root - Page:1, Index:7, Q-ROAR: Outlier-Aware Rescaling for RoPE Position Interpolation in Quantized Long-Context LLMs, https://arxiv.org/pdf/2509.14391, 2025-09-17
2025-11-09 21:32:19,104 - INFO - root - Page:1, Index:8, Efficient Quantization-Aware Neural Receivers: Beyond Post-Training Quantization, https://arxiv.org/pdf/2509.13786, 2025-09-19
2025-11-09 21:32:19,105 - INFO - root - Page:1, Index:9, Rate-Distortion Limits for Multimodal Retrieval: Theory, Optimal Codes, and Finite-Sample Guarantees, https://arxiv.org/pdf/2509.11054, 2025-09-13
2025-11-09 21:32:19,105 - INFO - root - Page:1, Index:10, SQAP-VLA: A Synergistic Quantization-Aware Pruning Framework for High-Performance Vision-Language-Action Models, https://arxiv.org/pdf/2509.09090, 2025-09-10
2025-11-09 21:32:19,105 - INFO - root - Page:1, Index:11, CSI Compression Beyond Latents: End-to-End Hybrid Attention-CNN Networks with Entropy Regularization, https://arxiv.org/pdf/2509.08776, 2025-09-10
2025-11-09 21:32:19,105 - INFO - root - Page:1, Index:12, Explaining How Quantization Disparately Skews a Model, https://arxiv.org/pdf/2509.07222, 2025-09-08
2025-11-09 21:32:19,106 - INFO - root - Page:1, Index:13, LoaQ: Layer-wise Output Approximation Quantization, https://arxiv.org/pdf/2509.06297, 2025-09-07
2025-11-09 21:32:19,106 - INFO - root - Page:1, Index:14, FineServe: Precision-Aware KV Slab and Two-Level Scheduling for Heterogeneous Precision LLM Serving, https://arxiv.org/pdf/2509.06261, 2025-09-14
2025-11-09 21:32:19,106 - INFO - root - Page:1, Index:15, Sensitivity-Aware Post-Training Quantization for Deep Neural Networks, https://arxiv.org/pdf/2509.05576, 2025-09-05
2025-11-09 21:32:19,106 - INFO - root - Page:1, Index:16, SuperSNN: A Hardware-Aware Framework for Physically Realizable, High-Performance Superconducting Spiking Neural Network Chips, https://arxiv.org/pdf/2509.05532, 2025-09-05
2025-11-09 21:32:19,107 - INFO - root - Page:1, Index:17, Data-Augmented Quantization-Aware Knowledge Distillation, https://arxiv.org/pdf/2509.03850, 2025-09-03
2025-11-09 21:32:19,107 - INFO - root - Page:1, Index:18, DPQuant: Efficient and Differentially-Private Model Training via Dynamic Quantization Scheduling, https://arxiv.org/pdf/2509.03472, 2025-09-03
2025-11-09 21:32:19,107 - INFO - root - Page:1, Index:19, Empowering Large Language Model for Sequential Recommendation via Multimodal Embeddings and Semantic IDs, https://arxiv.org/pdf/2509.02017, 2025-09-02
2025-11-09 21:32:19,108 - INFO - root - Page:1, Index:20, Q-Sched: Pushing the Boundaries of Few-Step Diffusion Models with Quantization-Aware Scheduling, https://arxiv.org/pdf/2509.01624, 2025-09-01
2025-11-09 21:32:19,108 - INFO - root - Page:1, Index:21, Quantization Meets OOD: Generalizable Quantization-aware Training from a Flatness Perspective, https://arxiv.org/pdf/2509.00859, 2025-08-31
2025-11-09 21:32:19,108 - INFO - root - Page:1, Index:22, Progressive Element-wise Gradient Estimation for Neural Network Quantization, https://arxiv.org/pdf/2509.00097, 2025-08-27
2025-11-09 21:32:19,109 - INFO - root - Page:1, Index:23, End-to-End On-Device Quantization-Aware Training for LLMs at Inference Cost, https://arxiv.org/pdf/2509.00031, 2025-09-29
2025-11-09 21:32:19,109 - INFO - root - Page:1, Index:24, Quantization Robustness to Input Degradations for Object Detection, https://arxiv.org/pdf/2508.19600, 2025-08-27
2025-11-09 21:32:19,109 - INFO - root - Page:1, Index:25, Scaling Laws for Task-Stratified Knowledge in Post-Training Quantized Large Language Models, https://arxiv.org/pdf/2508.18609, 2025-08-27
2025-11-09 21:32:19,110 - INFO - root - Page:1, Index:26, AQ-PCDSys: An Adaptive Quantized Planetary Crater Detection System for Autonomous Space Exploration, https://arxiv.org/pdf/2508.18025, 2025-08-25
2025-11-09 21:32:19,110 - INFO - root - Page:1, Index:27, TaDiCodec: Text-aware Diffusion Speech Tokenizer for Speech Language Modeling, https://arxiv.org/pdf/2508.16790, 2025-08-22
2025-11-09 21:32:19,112 - INFO - root - Page:1, Index:28, A Node-Aware Dynamic Quantization Approach for Graph Collaborative Filtering, https://arxiv.org/pdf/2508.16516, 2025-08-22
2025-11-09 21:32:19,113 - INFO - root - Page:1, Index:29, JEDI-linear: Fast and Efficient Graph Neural Networks for Jet Tagging on FPGAs, https://arxiv.org/pdf/2508.15468, 2025-08-21
2025-11-09 21:32:19,113 - INFO - root - Page:1, Index:30, MMQ: Multimodal Mixture-of-Quantization Tokenization for Semantic ID Generation and User Behavioral Adaptation, https://arxiv.org/pdf/2508.15281, 2025-08-21
2025-11-09 21:32:19,114 - INFO - root - Page:1, Index:31, DLLMQuant: Quantizing Diffusion-based Large Language Models, https://arxiv.org/pdf/2508.14090, 2025-08-25
2025-11-09 21:32:19,114 - INFO - root - Page:1, Index:32, Automated Energy-Aware Time-Series Model Deployment on Embedded FPGAs for Resilient Combined Sewer Overflow Management, https://arxiv.org/pdf/2508.13905, 2025-08-19
2025-11-09 21:32:19,115 - INFO - root - Page:1, Index:33, XR-NPE: High-Throughput Mixed-precision SIMD Neural Processing Engine for Extended Reality Perception Workloads, https://arxiv.org/pdf/2508.13049, 2025-08-18
2025-11-09 21:32:19,115 - INFO - root - Page:1, Index:34, Exploring Self-Supervised Audio Models for Generalized Anomalous Sound Detection, https://arxiv.org/pdf/2508.12230, 2025-08-17
2025-11-09 21:32:19,115 - INFO - root - Page:1, Index:35, TriQDef: Disrupting Semantic and Gradient Alignment to Prevent Adversarial Patch Transferability in Quantized Neural Networks, https://arxiv.org/pdf/2508.12132, 2025-08-16
2025-11-09 21:32:19,115 - INFO - root - Page:1, Index:36, Error Propagation Mechanisms and Compensation Strategies for Quantized Diffusion, https://arxiv.org/pdf/2508.12094, 2025-10-13
2025-11-09 21:32:19,116 - INFO - root - Page:1, Index:37, Extending Straight-Through Estimation for Robust Neural Networks on Analog CIM Hardware, https://arxiv.org/pdf/2508.11940, 2025-08-16
2025-11-09 21:32:19,116 - INFO - root - Page:1, Index:38, PTQAT: A Hybrid Parameter-Efficient Quantization Algorithm for 3D Perception Tasks, https://arxiv.org/pdf/2508.10557, 2025-08-15
2025-11-09 21:32:19,116 - INFO - root - Page:1, Index:39, MiCo: End-to-End Mixed Precision Neural Network Co-Exploration Framework for Edge AI, https://arxiv.org/pdf/2508.09500, 2025-08-13
2025-11-09 21:32:19,117 - INFO - root - Page:1, Index:40, SPARC: Soft Probabilistic Adaptive multi-interest Retrieval Model via Codebooks for recommender system, https://arxiv.org/pdf/2508.09090, 2025-08-12
2025-11-09 21:32:19,117 - INFO - root - Page:1, Index:41, Rethinking 1-bit Optimization Leveraging Pre-trained Large Language Models, https://arxiv.org/pdf/2508.06974, 2025-08-09
2025-11-09 21:32:19,118 - INFO - root - Page:1, Index:42, Efficient Deep Neural Receiver with Post-Training Quantization, https://arxiv.org/pdf/2508.06275, 2025-08-08
2025-11-09 21:32:19,118 - INFO - root - Page:1, Index:43, iFairy: the First 2-bit Complex LLM with All Parameters in $\{\pm1, \pm i\}$, https://arxiv.org/pdf/2508.05571, 2025-08-16
2025-11-09 21:32:19,119 - INFO - root - Page:1, Index:44, S$^2$Q-VDiT: Accurate Quantized Video Diffusion Transformer with Salient Data and Sparse Token Distillation, https://arxiv.org/pdf/2508.04016, 2025-10-27
2025-11-09 21:32:19,119 - INFO - root - Page:1, Index:45, LRQ-DiT: Log-Rotation Post-Training Quantization of Diffusion Transformers for Image and Video Generation, https://arxiv.org/pdf/2508.03485, 2025-09-23
2025-11-09 21:32:19,119 - INFO - root - Page:1, Index:46, VLMQ: Efficient Post-Training Quantization for Large Vision-Language Models via Hessian Augmentation, https://arxiv.org/pdf/2508.03351, 2025-08-05
2025-11-09 21:32:19,120 - INFO - root - Page:1, Index:47, TF-MLPNet: Tiny Real-Time Neural Speech Separation, https://arxiv.org/pdf/2508.03047, 2025-08-04
2025-11-09 21:32:19,120 - INFO - root - Page:1, Index:48, SaviorRec: Semantic-Behavior Alignment for Cold-Start Recommendation, https://arxiv.org/pdf/2508.01375, 2025-08-02
2025-11-09 21:32:19,120 - INFO - root - Page:1, Index:49, MixA-Q: Revisiting Activation Sparsity for Vision Transformers from a Mixed-Precision Quantization Perspective, https://arxiv.org/pdf/2507.19131, 2025-07-25
2025-11-09 21:32:19,121 - INFO - root - Fetching page 3 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=100
2025-11-09 21:32:26,679 - INFO - root - get_all_titles_from_web 
2025-11-09 21:32:26,680 - INFO - root - Page:2, Index:0, Enhancing Quantization-Aware Training on Edge Devices via Relative Entropy Coreset Selection and Cascaded Layer Correction, https://arxiv.org/pdf/2507.17768, 2025-07-16
2025-11-09 21:32:26,680 - INFO - root - Page:2, Index:1, SiLQ: Simple Large Language Model Quantization-Aware Training, https://arxiv.org/pdf/2507.16933, 2025-07-22
2025-11-09 21:32:26,680 - INFO - root - Page:2, Index:2, Task-Specific Zero-shot Quantization-Aware Training for Object Detection, https://arxiv.org/pdf/2507.16782, 2025-07-22
2025-11-09 21:32:26,681 - INFO - root - Page:2, Index:3, TorchAO: PyTorch-Native Training-to-Serving Model Optimization, https://arxiv.org/pdf/2507.16099, 2025-07-21
2025-11-09 21:32:26,681 - INFO - root - Page:2, Index:4, SegQuant: A Semantics-Aware and Generalizable Quantization Framework for Diffusion Models, https://arxiv.org/pdf/2507.14811, 2025-08-27
2025-11-09 21:32:26,681 - INFO - root - Page:2, Index:5, Apple Intelligence Foundation Language Models: Tech Report 2025, https://arxiv.org/pdf/2507.13575, 2025-08-27
2025-11-09 21:32:26,681 - INFO - root - Page:2, Index:6, Generative Multi-Target Cross-Domain Recommendation, https://arxiv.org/pdf/2507.12871, 2025-08-07
2025-11-09 21:32:26,681 - INFO - root - Page:2, Index:7, DAF: An Efficient End-to-End Dynamic Activation Framework for on-Device DNN Training, https://arxiv.org/pdf/2507.07149, 2025-07-09
2025-11-09 21:32:26,682 - INFO - root - Page:2, Index:8, Opto-ViT: Architecting a Near-Sensor Region of Interest-Aware Vision Transformer Accelerator with Silicon Photonics, https://arxiv.org/pdf/2507.07044, 2025-07-15
2025-11-09 21:32:26,682 - INFO - root - Page:2, Index:9, QS4D: Quantization-aware training for efficient hardware deployment of structured state-space sequential models, https://arxiv.org/pdf/2507.06079, 2025-07-08
2025-11-09 21:32:26,682 - INFO - root - Page:2, Index:10, GSVR: 2D Gaussian-based Video Representation for 800+ FPS with Hybrid Deformation Field, https://arxiv.org/pdf/2507.05594, 2025-07-07
2025-11-09 21:32:26,684 - INFO - root - Page:2, Index:11, Hita: Holistic Tokenizer for Autoregressive Image Generation, https://arxiv.org/pdf/2507.02358, 2025-07-11
2025-11-09 21:32:26,684 - INFO - root - Page:2, Index:12, QPART: Adaptive Model Quantization and Dynamic Workload Balancing for Accuracy-aware Edge Inference, https://arxiv.org/pdf/2506.23934, 2025-06-30
2025-11-09 21:32:26,685 - INFO - root - Page:2, Index:13, FedWSQ: Efficient Federated Learning with Weight Standardization and Distribution-Aware Non-Uniform Quantization, https://arxiv.org/pdf/2506.23516, 2025-07-21
2025-11-09 21:32:26,686 - INFO - root - Page:2, Index:14, Spectra 1.1: Scaling Laws and Efficient Inference for Ternary Language Models, https://arxiv.org/pdf/2506.23025, 2025-06-28
2025-11-09 21:32:26,687 - INFO - root - Page:2, Index:15, Joint Quantization and Pruning Neural Networks Approach: A Case Study on FSO Receivers, https://arxiv.org/pdf/2506.20084, 2025-06-24
2025-11-09 21:32:26,687 - INFO - root - Page:2, Index:16, Single-step Diffusion for Image Compression at Ultra-Low Bitrates, https://arxiv.org/pdf/2506.16572, 2025-09-22
2025-11-09 21:32:26,687 - INFO - root - Page:2, Index:17, LittleBit: Ultra Low-Bit Quantization via Latent Factorization, https://arxiv.org/pdf/2506.13771, 2025-10-28
2025-11-09 21:32:26,687 - INFO - root - Page:2, Index:18, MARCO: Hardware-Aware Neural Architecture Search for Edge Devices with Multi-Agent Reinforcement Learning and Conformal Prediction Filtering, https://arxiv.org/pdf/2506.13755, 2025-06-16
2025-11-09 21:32:26,688 - INFO - root - Page:2, Index:19, EAQuant: Enhancing Post-Training Quantization for MoE Models via Expert-Aware Optimization, https://arxiv.org/pdf/2506.13329, 2025-07-04
2025-11-09 21:32:26,688 - INFO - root - Page:2, Index:20, Towards Neural Audio Codec Source Parsing, https://arxiv.org/pdf/2506.12627, 2025-06-14
2025-11-09 21:32:26,688 - INFO - root - Page:2, Index:21, Quantizing Small-Scale State-Space Models for Edge AI, https://arxiv.org/pdf/2506.12480, 2025-06-14
2025-11-09 21:32:26,689 - INFO - root - Page:2, Index:22, EMLoC: Emulator-based Memory-efficient Fine-tuning with LoRA Correction, https://arxiv.org/pdf/2506.12015, 2025-06-13
2025-11-09 21:32:26,689 - INFO - root - Page:2, Index:23, Compression Aware Certified Training, https://arxiv.org/pdf/2506.11992, 2025-06-13
2025-11-09 21:32:26,689 - INFO - root - Page:2, Index:24, GPLQ: A General, Practical, and Lightning QAT Method for Vision Transformers, https://arxiv.org/pdf/2506.11784, 2025-06-13
2025-11-09 21:32:26,690 - INFO - root - Page:2, Index:25, TruncQuant: Truncation-Ready Quantization for DNNs with Flexible Weight Bit Precision, https://arxiv.org/pdf/2506.11431, 2025-06-12
2025-11-09 21:32:26,690 - INFO - root - Page:2, Index:26, EfficientQuant: An Efficient Post-Training Quantization for CNN-Transformer Hybrid Models on Edge Devices, https://arxiv.org/pdf/2506.11093, 2025-06-05
2025-11-09 21:32:26,690 - INFO - root - Page:2, Index:27, Starting Positions Matter: A Study on Better Weight Initialization for Neural Network Quantization, https://arxiv.org/pdf/2506.10463, 2025-06-12
2025-11-09 21:32:26,691 - INFO - root - Page:2, Index:28, AWP: Activation-Aware Weight Pruning and Quantization with Projected Gradient Descent, https://arxiv.org/pdf/2506.10205, 2025-06-11
2025-11-09 21:32:26,691 - INFO - root - Page:2, Index:29, Q-SAM2: Accurate Quantization for Segment Anything Model 2, https://arxiv.org/pdf/2506.09782, 2025-06-11
2025-11-09 21:32:26,692 - INFO - root - Page:2, Index:30, Unifying Block-wise PTQ and Distillation-based QAT for Progressive Quantization toward 2-bit Instruction-Tuned LLMs, https://arxiv.org/pdf/2506.09104, 2025-06-10
2025-11-09 21:32:26,692 - INFO - root - Page:2, Index:31, Implementing Keyword Spotting on the MCUX947 Microcontroller with Integrated NPU, https://arxiv.org/pdf/2506.08911, 2025-06-10
2025-11-09 21:32:26,692 - INFO - root - Page:2, Index:32, POLARON: Precision-aware On-device Learning and Adaptive Runtime-cONfigurable AI acceleration, https://arxiv.org/pdf/2506.08785, 2025-06-10
2025-11-09 21:32:26,693 - INFO - root - Page:2, Index:33, MoQAE: Mixed-Precision Quantization for Long-Context LLM Inference via Mixture of Quantization-Aware Experts, https://arxiv.org/pdf/2506.07533, 2025-06-09
2025-11-09 21:32:26,693 - INFO - root - Page:2, Index:34, BitVLA: 1-bit Vision-Language-Action Models for Robotics Manipulation, https://arxiv.org/pdf/2506.07530, 2025-06-09
2025-11-09 21:32:26,693 - INFO - root - Page:2, Index:35, RecGPT: A Foundation Model for Sequential Recommendation, https://arxiv.org/pdf/2506.06270, 2025-06-12
2025-11-09 21:32:26,693 - INFO - root - Page:2, Index:36, FPSAttention: Training-Aware FP8 and Sparsity Co-Design for Fast Video Diffusion, https://arxiv.org/pdf/2506.04648, 2025-06-05
2025-11-09 21:32:26,695 - INFO - root - Page:2, Index:37, BitTTS: Highly Compact Text-to-Speech Using 1.58-bit Quantization and Weight Indexing, https://arxiv.org/pdf/2506.03515, 2025-06-03
2025-11-09 21:32:26,695 - INFO - root - Page:2, Index:38, ShapeLLM-Omni: A Native Multimodal LLM for 3D Generation and Understanding, https://arxiv.org/pdf/2506.01853, 2025-06-02
2025-11-09 21:32:26,695 - INFO - root - Page:2, Index:39, Movable Antenna Enhanced Federated Fine-Tuning of Large Language Models via Hybrid Client Selection Optimization, https://arxiv.org/pdf/2506.00011, 2025-10-26
2025-11-09 21:32:26,695 - INFO - root - Page:2, Index:40, Running Conventional Automatic Speech Recognition on Memristor Hardware: A Simulated Approach, https://arxiv.org/pdf/2505.24721, 2025-05-30
2025-11-09 21:32:26,696 - INFO - root - Page:2, Index:41, GARLIC: GAussian Representation LearnIng for spaCe partitioning, https://arxiv.org/pdf/2505.24608, 2025-10-02
2025-11-09 21:32:26,696 - INFO - root - Page:2, Index:42, AutoChemSchematic AI: Agentic Physics-Aware Automation for Chemical Manufacturing Scale-Up, https://arxiv.org/pdf/2505.24584, 2025-08-18
2025-11-09 21:32:26,696 - INFO - root - Page:2, Index:43, Model-Preserving Adaptive Rounding, https://arxiv.org/pdf/2505.22988, 2025-09-25
2025-11-09 21:32:26,697 - INFO - root - Page:2, Index:44, Highly Efficient and Effective LLMs with Multi-Boolean Architectures, https://arxiv.org/pdf/2505.22811, 2025-10-03
2025-11-09 21:32:26,697 - INFO - root - Page:2, Index:45, Pioneering 4-Bit FP Quantization for Diffusion Models: Mixup-Sign Quantization and Timestep-Aware Fine-Tuning, https://arxiv.org/pdf/2505.21591, 2025-05-27
2025-11-09 21:32:26,697 - INFO - root - Page:2, Index:46, Frequency Composition for Compressed and Domain-Adaptive Neural Networks, https://arxiv.org/pdf/2505.20890, 2025-05-27
2025-11-09 21:32:26,698 - INFO - root - Page:2, Index:47, MoPFormer: Motion-Primitive Transformer for Wearable-Sensor Activity Recognition, https://arxiv.org/pdf/2505.20744, 2025-10-27
2025-11-09 21:32:26,698 - INFO - root - Page:2, Index:48, Optimizing edge AI models on HPC systems with the edge in the loop, https://arxiv.org/pdf/2505.19995, 2025-05-26
2025-11-09 21:32:26,698 - INFO - root - Fetching page 4 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=150
2025-11-09 21:32:33,070 - INFO - root - get_all_titles_from_web 
2025-11-09 21:32:33,070 - INFO - root - Page:3, Index:0, DPASyn: Mechanism-Aware Drug Synergy Prediction via Dual Attention and Precision-Aware Quantization, https://arxiv.org/pdf/2505.19144, 2025-09-20
2025-11-09 21:32:33,071 - INFO - root - Page:3, Index:1, Reducing Storage of Pretrained Neural Networks by Rate-Constrained Quantization and Entropy Coding, https://arxiv.org/pdf/2505.18758, 2025-05-24
2025-11-09 21:32:33,071 - INFO - root - Page:3, Index:2, Beyond Discreteness: Finite-Sample Analysis of Straight-Through Estimator for Quantization, https://arxiv.org/pdf/2505.18113, 2025-05-23
2025-11-09 21:32:33,071 - INFO - root - Page:3, Index:3, Automating Versatile Time-Series Analysis with Tiny Transformers on Embedded FPGAs, https://arxiv.org/pdf/2505.17662, 2025-09-19
2025-11-09 21:32:33,071 - INFO - root - Page:3, Index:4, FPQVAR: Floating Point Quantization for Visual Autoregressive Model with FPGA Hardware Co-design, https://arxiv.org/pdf/2505.16335, 2025-05-22
2025-11-09 21:32:33,073 - INFO - root - Page:3, Index:5, Saliency-Aware Quantized Imitation Learning for Efficient Robotic Control, https://arxiv.org/pdf/2505.15304, 2025-05-30
2025-11-09 21:32:33,073 - INFO - root - Page:3, Index:6, Scaling Law for Quantization-Aware Training, https://arxiv.org/pdf/2505.14302, 2025-05-20
2025-11-09 21:32:33,073 - INFO - root - Page:3, Index:7, Automatic mixed precision for optimizing gained time with constrained loss mean-squared-error based on model partition to sequential sub-graphs, https://arxiv.org/pdf/2505.13060, 2025-05-19
2025-11-09 21:32:33,073 - INFO - root - Page:3, Index:8, Deep Unfolding with Kernel-based Quantization in MIMO Detection, https://arxiv.org/pdf/2505.12736, 2025-05-19
2025-11-09 21:32:33,074 - INFO - root - Page:3, Index:9, FedHQ: Hybrid Runtime Quantization for Federated Learning, https://arxiv.org/pdf/2505.11982, 2025-05-17
2025-11-09 21:32:33,074 - INFO - root - Page:3, Index:10, QVGen: Pushing the Limit of Quantized Video Generative Models, https://arxiv.org/pdf/2505.11497, 2025-09-27
2025-11-09 21:32:33,074 - INFO - root - Page:3, Index:11, EA-3DGS: Efficient and Adaptive 3D Gaussians with Highly Enhanced Quality for outdoor scenes, https://arxiv.org/pdf/2505.10787, 2025-05-15
2025-11-09 21:32:33,076 - INFO - root - Page:3, Index:12, ITERA-LLM: Boosting Sub-8-Bit Large Language Model Inference via Iterative Tensor Decomposition, https://arxiv.org/pdf/2505.08981, 2025-05-13
2025-11-09 21:32:33,077 - INFO - root - Page:3, Index:13, PROM: Prioritize Reduction of Multiplications Over Lower Bit-Widths for Efficient CNNs, https://arxiv.org/pdf/2505.03254, 2025-08-06
2025-11-09 21:32:33,078 - INFO - root - Page:3, Index:14, ICQuant: Index Coding enables Low-bit LLM Quantization, https://arxiv.org/pdf/2505.00850, 2025-08-24
2025-11-09 21:32:33,078 - INFO - root - Page:3, Index:15, Enhancing Ultra-Low-Bit Quantization of Large Language Models Through Saliency-Aware Partial Retraining, https://arxiv.org/pdf/2504.13932, 2025-07-30
2025-11-09 21:32:33,079 - INFO - root - Page:3, Index:16, Achieving binary weight and activation for LLMs using Post-Training Quantization, https://arxiv.org/pdf/2504.05352, 2025-06-30
2025-11-09 21:32:33,079 - INFO - root - Page:3, Index:17, Wireless Hearables With Programmable Speech AI Accelerators, https://arxiv.org/pdf/2503.18698, 2025-10-21
2025-11-09 21:32:33,080 - INFO - root - Page:3, Index:18, GranQ: Efficient Channel-wise Quantization via Vectorized Pre-Scaling for Zero-Shot QAT, https://arxiv.org/pdf/2503.18339, 2025-10-15
2025-11-09 21:32:33,080 - INFO - root - Page:3, Index:19, CompMarkGS: Robust Watermarking for Compressed 3D Gaussian Splatting, https://arxiv.org/pdf/2503.12836, 2025-09-29
2025-11-09 21:32:33,080 - INFO - root - Page:3, Index:20, AHCPTQ: Accurate and Hardware-Compatible Post-Training Quantization for Segment Anything Model, https://arxiv.org/pdf/2503.03088, 2025-07-11
2025-11-09 21:32:33,081 - INFO - root - Page:3, Index:21, Teaching Metric Distance to Discrete Autoregressive Language Models, https://arxiv.org/pdf/2503.02379, 2025-10-07
2025-11-09 21:32:33,081 - INFO - root - Page:3, Index:22, Regularization-based Framework for Quantization-, Fault- and Variability-Aware Training, https://arxiv.org/pdf/2503.01297, 2025-07-12
2025-11-09 21:32:33,081 - INFO - root - Fetching page 5 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=200
2025-11-09 21:32:40,344 - INFO - root - get_all_titles_from_web 
2025-11-09 21:32:40,350 - INFO - root - Page:4, Index:0, Investigating the Impact of Quantization Methods on the Safety and Reliability of Large Language Models, https://arxiv.org/pdf/2502.15799, 2025-06-29
2025-11-09 21:32:40,351 - INFO - root - Page:4, Index:1, Rotate, Clip, and Partition: Towards W2A4KV4 Quantization by Integrating Rotation and Learnable Non-uniform Quantizer, https://arxiv.org/pdf/2502.15779, 2025-09-01
2025-11-09 21:32:40,352 - INFO - root - Page:4, Index:2, RoSTE: An Efficient Quantization-Aware Supervised Fine-Tuning Approach for Large Language Models, https://arxiv.org/pdf/2502.09003, 2025-06-05
2025-11-09 21:32:40,353 - INFO - root - Page:4, Index:3, Spatial Degradation-Aware and Temporal Consistent Diffusion Model for Compressed Video Super-Resolution, https://arxiv.org/pdf/2502.07381, 2025-06-27
2025-11-09 21:32:40,354 - INFO - root - Page:4, Index:4, QuEST: Stable Training of LLMs with 1-Bit Weights and Activations, https://arxiv.org/pdf/2502.05003, 2025-06-10
2025-11-09 21:32:40,355 - INFO - root - Page:4, Index:5, HALO: Hadamard-Assisted Lower-Precision Optimization for LLMs, https://arxiv.org/pdf/2501.02625, 2025-11-05
2025-11-09 21:32:40,356 - INFO - root - Page:4, Index:6, TAR3D: Creating High-Quality 3D Assets via Next-Part Prediction, https://arxiv.org/pdf/2412.16919, 2025-08-08
2025-11-09 21:32:40,357 - INFO - root - Page:4, Index:7, Training Multi-Layer Binary Neural Networks With Local Binary Error Signals, https://arxiv.org/pdf/2412.00119, 2025-08-05
2025-11-09 21:32:40,358 - INFO - root - Page:4, Index:8, Scaling Large-scale GNN Training to Thousands of Processors on CPU-based Supercomputers, https://arxiv.org/pdf/2411.16025, 2025-05-26
2025-11-09 21:32:40,359 - INFO - root - Page:4, Index:9, HAFLQ: Heterogeneous Adaptive Federated LoRA Fine-tuned LLM with Quantization, https://arxiv.org/pdf/2411.06581, 2025-05-16
2025-11-09 21:32:40,361 - INFO - root - Fetching page 6 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=250
2025-11-09 21:32:47,201 - INFO - root - get_all_titles_from_web 
2025-11-09 21:32:47,202 - INFO - root - Page:5, Index:0, Gradient-Free Training of Quantized Neural Networks, https://arxiv.org/pdf/2410.09734, 2025-09-29
2025-11-09 21:32:47,202 - INFO - root - Page:5, Index:1, QT-DoG: Quantization-aware Training for Domain Generalization, https://arxiv.org/pdf/2410.06020, 2025-06-26
2025-11-09 21:32:47,202 - INFO - root - Page:5, Index:2, Constraint Guided Model Quantization of Neural Networks, https://arxiv.org/pdf/2409.20138, 2025-09-12
2025-11-09 21:32:47,203 - INFO - root - Page:5, Index:3, Accumulator-Aware Post-Training Quantization for Large Language Models, https://arxiv.org/pdf/2409.17092, 2025-07-30
2025-11-09 21:32:47,203 - INFO - root - Page:5, Index:4, DilateQuant: Accurate and Efficient Diffusion Quantization via Weight Dilation, https://arxiv.org/pdf/2409.14307, 2025-07-09
2025-11-09 21:32:47,203 - INFO - root - Page:5, Index:5, Robust Training of Neural Networks at Arbitrary Precision and Sparsity, https://arxiv.org/pdf/2409.09245, 2025-09-23
2025-11-09 21:32:47,204 - INFO - root - Page:5, Index:6, VQ-CTAP: Cross-Modal Fine-Grained Sequence Representation Learning for Speech Processing, https://arxiv.org/pdf/2408.05758, 2025-05-27
2025-11-09 21:32:47,204 - INFO - root - Page:5, Index:7, DopQ-ViT: Towards Distribution-Friendly and Outlier-Aware Post-Training Quantization for Vision Transformers, https://arxiv.org/pdf/2408.03291, 2025-06-19
2025-11-09 21:32:47,205 - INFO - root - Page:5, Index:8, Temporal Feature Matters: A Framework for Diffusion Model Quantization, https://arxiv.org/pdf/2407.19547, 2025-07-11
2025-11-09 21:32:47,205 - INFO - root - Page:5, Index:9, EfficientQAT: Efficient Quantization-Aware Training for Large Language Models, https://arxiv.org/pdf/2407.11062, 2025-05-19
2025-11-09 21:32:47,206 - INFO - root - Page:5, Index:10, Integer-only Quantized Transformers for Embedded FPGA-based Time-series Forecasting in AIoT, https://arxiv.org/pdf/2407.11041, 2025-10-31
2025-11-09 21:32:47,206 - INFO - root - Fetching page 7 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=300
2025-11-09 21:32:54,890 - INFO - root - get_all_titles_from_web 
2025-11-09 21:32:54,890 - INFO - root - Page:6, Index:0, BoA: Attention-aware Post-training Quantization without Backpropagation, https://arxiv.org/pdf/2406.13474, 2025-06-06
2025-11-09 21:32:54,891 - INFO - root - Page:6, Index:1, A Rescaling-Invariant Lipschitz Bound Based on Path-Metrics for Modern ReLU Network Parameterizations, https://arxiv.org/pdf/2405.15006, 2025-06-13
2025-11-09 21:32:54,891 - INFO - root - Page:6, Index:2, Scheduling Weight Transitions for Quantization-Aware Training, https://arxiv.org/pdf/2404.19248, 2025-10-01
2025-11-09 21:32:54,891 - INFO - root - Page:6, Index:3, GPTVQ: The Blessing of Dimensionality for LLM Quantization, https://arxiv.org/pdf/2402.15319, 2025-06-03
2025-11-09 21:32:54,892 - INFO - root - Fetching page 8 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=350
2025-11-09 21:33:03,380 - INFO - root - get_all_titles_from_web 
2025-11-09 21:33:03,498 - INFO - root - Page:7, Index:0, Squat: Quant Small Language Models on the Edge, https://arxiv.org/pdf/2402.10787, 2025-07-01
2025-11-09 21:33:03,517 - INFO - root - Page:7, Index:1, L4Q: Parameter Efficient Quantization-Aware Fine-Tuning on Large Language Models, https://arxiv.org/pdf/2402.04902, 2025-07-21
2025-11-09 21:33:03,518 - INFO - root - Fetching page 9 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=400
2025-11-09 21:33:11,451 - INFO - root - ------------------------------------------------------------------------------------------------------------------------
2025-11-09 21:33:11,453 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\A Quantized VAE-MLP Botnet Detection Model_ A Systematic Evaluation of Quantizat.pdf
2025-11-09 21:33:11,489 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\FP8-Flow-MoE_ A Casting-Free FP8 Recipe without Double Quantization Error.pdf
2025-11-09 21:33:11,491 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\Outlier-Aware Post-Training Quantization for Image Super-Resolution.pdf
2025-11-09 21:33:11,493 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\Evaluation of Wafer-Scale SOT-MRAM for Analog Crossbar Array Applications.pdf
2025-11-09 21:33:11,494 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\Improving the Straight-Through Estimator with Zeroth-Order Information.pdf
2025-11-09 21:33:11,502 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\Real-Time Semantic Segmentation on FPGA for Autonomous Vehicles Using LMIINet wi.pdf
2025-11-09 21:33:11,505 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\TernaryCLIP_ Efficiently Compressing Vision-Language Models with Ternary Weights.pdf
2025-11-09 21:33:11,506 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\KARIPAP_ Quantum-Inspired Tensor Network Compression of Large Language Models Us.pdf
2025-11-09 21:33:11,509 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\A Convergence Analysis of Adaptive Optimizers under Floating-point Quantization.pdf
2025-11-09 21:33:11,511 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\Adaptive Distribution-aware Quantization for Mixed-Precision Neural Networks.pdf
2025-11-09 21:33:11,514 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\CAGE_ Curvature-Aware Gradient Estimation For Accurate Quantization-Aware Traini.pdf
2025-11-09 21:33:11,516 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\Mixed-Precision Quantization for Language Models_ Techniques and Prospects.pdf
2025-11-09 21:33:11,518 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\SPLite Hand_ Sparsity-Aware Lightweight 3D Hand Pose Estimation.pdf
2025-11-09 21:33:11,520 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\CTR-LoRA_ Curvature-Aware and Trust-Region Guided Low-Rank Adaptation for Large.pdf
2025-11-09 21:33:11,521 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\SANR_ Scene-Aware Neural Representation for Light Field Image Compression with R.pdf
2025-11-09 21:33:11,523 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\SpikeFit_ Towards Optimal Deployment of Spiking Networks on Neuromorphic Hardwar.pdf
2025-11-09 21:33:11,528 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\GRank_ Towards Target-Aware and Streamlined Industrial Retrieval with a Generate.pdf
2025-11-09 21:33:11,534 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\SaLon3R_ Structure-aware Long-term Generalizable 3D Reconstruction from Unposed.pdf
2025-11-09 21:33:11,535 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\FraQAT_ Quantization Aware Training with Fractional bits.pdf
2025-11-09 21:33:11,537 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\Computing-In-Memory Aware Model Adaption For Edge Devices.pdf
2025-11-09 21:33:11,542 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\Invited Paper_ BitMedViT_ Ternary-Quantized Vision Transformer for Medical AI As.pdf
2025-11-09 21:33:11,545 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\NeuroRVQ_ Multi-Scale EEG Tokenization for Generative Large Brainwave Models.pdf
2025-11-09 21:33:11,548 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\Detect Anything via Next Point Prediction.pdf
2025-11-09 21:33:11,550 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\AndesVL Technical Report_ An Efficient Mobile-side Multimodal Large Language Mod.pdf
2025-11-09 21:33:11,556 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\Rescaling-Aware Training for Efficient Deployment of Deep Learning Models on Ful.pdf
2025-11-09 21:33:11,558 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\SASER_ Stego attacks on open-source LLMs.pdf
2025-11-09 21:33:11,560 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\Ultralytics YOLO Evolution_ An Overview of YOLO26, YOLO11, YOLOv8 and YOLOv5 Obj.pdf
2025-11-09 21:33:11,566 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\A Theoretically-Grounded Codebook for Digital Semantic Communications.pdf
2025-11-09 21:33:11,567 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\QuantDemoire_ Quantization with Outlier Aware for Image Demoiréing.pdf
2025-11-09 21:33:11,568 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\Adaptively Sampling-Reusing-Mixing Decomposed Gradients to Speed Up Sharpness Aw.pdf
2025-11-09 21:33:11,571 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\Quant-dLLM_ Post-Training Extreme Low-Bit Quantization for Diffusion Large Langu.pdf
2025-11-09 21:33:11,573 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\PT$^2$-LLM_ Post-Training Ternarization for Large Language Models.pdf
2025-11-09 21:33:11,577 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\Purrception_ Variational Flow Matching for Vector-Quantized Image Generation.pdf
2025-11-09 21:33:11,581 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\Post-Training Quantization for Audio Diffusion Transformers.pdf
2025-11-09 21:33:11,582 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\Rethinking RoPE Scaling in Quantized LLM_ Theory, Outlier, and Channel-Band Anal.pdf
2025-11-09 21:33:11,584 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\Post-Training Quantization via Residual Truncation and Zero Suppression for Diff.pdf
2025-11-09 21:33:11,585 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\Cat_ Post-Training Quantization Error Reduction via Cluster-based Affine Transfo.pdf
2025-11-09 21:33:11,586 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\CAST_ Continuous and Differentiable Semi-Structured Sparsity-Aware Training for.pdf
2025-11-09 21:33:11,588 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\Norm-Q_ Effective Compression Method for Hidden Markov Models in Neuro-Symbolic.pdf
2025-11-09 21:33:11,590 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\On-the-Fly Adaptation to Quantization_ Configuration-Aware LoRA for Efficient Fi.pdf
2025-11-09 21:33:11,601 - INFO - root - 跳过已处理论文 A Quantized VAE-MLP Botnet Detection Model: A Systematic Evaluation of Quantization-Aware Training and Post-Training Quantization Strategies：d:\ChatPaper\academic Papers\Quantization-Aware-Training\A Quantized VAE-MLP Botnet Detection Model_ A Systematic Evaluation of Quantizat.pdf
2025-11-09 21:33:11,602 - INFO - root - 跳过已处理论文 FP8-Flow-MoE: A Casting-Free FP8 Recipe without Double Quantization Error：d:\ChatPaper\academic Papers\Quantization-Aware-Training\FP8-Flow-MoE_ A Casting-Free FP8 Recipe without Double Quantization Error.pdf
2025-11-09 21:33:11,611 - INFO - root - 跳过已处理论文 Outlier-Aware Post-Training Quantization for Image Super-Resolution：d:\ChatPaper\academic Papers\Quantization-Aware-Training\Outlier-Aware Post-Training Quantization for Image Super-Resolution.pdf
2025-11-09 21:33:11,612 - INFO - root - 跳过已处理论文 Evaluation of Wafer-Scale SOT-MRAM for Analog Crossbar Array Applications：d:\ChatPaper\academic Papers\Quantization-Aware-Training\Evaluation of Wafer-Scale SOT-MRAM for Analog Crossbar Array Applications.pdf
2025-11-09 21:33:11,616 - INFO - root - 跳过已处理论文 Improving the Straight-Through Estimator with Zeroth-Order Information：d:\ChatPaper\academic Papers\Quantization-Aware-Training\Improving the Straight-Through Estimator with Zeroth-Order Information.pdf
2025-11-09 21:33:11,616 - INFO - root - 跳过已处理论文 Real-Time Semantic Segmentation on FPGA for Autonomous Vehicles Using LMIINet with the CGRA4ML Framework：d:\ChatPaper\academic Papers\Quantization-Aware-Training\Real-Time Semantic Segmentation on FPGA for Autonomous Vehicles Using LMIINet wi.pdf
2025-11-09 21:33:11,617 - INFO - root - 跳过已处理论文 TernaryCLIP: Efficiently Compressing Vision-Language Models with Ternary Weights and Distilled Knowledge：d:\ChatPaper\academic Papers\Quantization-Aware-Training\TernaryCLIP_ Efficiently Compressing Vision-Language Models with Ternary Weights.pdf
2025-11-09 21:33:11,617 - INFO - root - 跳过已处理论文 KARIPAP: Quantum-Inspired Tensor Network Compression of Large Language Models Using Infinite Projected Entangled Pair States and Tensor Renormalization Group：d:\ChatPaper\academic Papers\Quantization-Aware-Training\KARIPAP_ Quantum-Inspired Tensor Network Compression of Large Language Models Us.pdf
2025-11-09 21:33:11,619 - INFO - root - 跳过已处理论文 A Convergence Analysis of Adaptive Optimizers under Floating-point Quantization：d:\ChatPaper\academic Papers\Quantization-Aware-Training\A Convergence Analysis of Adaptive Optimizers under Floating-point Quantization.pdf
2025-11-09 21:33:11,619 - INFO - root - 跳过已处理论文 Adaptive Distribution-aware Quantization for Mixed-Precision Neural Networks：d:\ChatPaper\academic Papers\Quantization-Aware-Training\Adaptive Distribution-aware Quantization for Mixed-Precision Neural Networks.pdf
2025-11-09 21:33:11,686 - INFO - root - 跳过已处理论文 CAGE: Curvature-Aware Gradient Estimation For Accurate Quantization-Aware Training：d:\ChatPaper\academic Papers\Quantization-Aware-Training\CAGE_ Curvature-Aware Gradient Estimation For Accurate Quantization-Aware Traini.pdf
2025-11-09 21:33:11,854 - INFO - root - 跳过已处理论文 Mixed-Precision Quantization for Language Models: Techniques and Prospects：d:\ChatPaper\academic Papers\Quantization-Aware-Training\Mixed-Precision Quantization for Language Models_ Techniques and Prospects.pdf
2025-11-09 21:33:11,868 - INFO - root - 跳过已处理论文 SPLite Hand: Sparsity-Aware Lightweight 3D Hand Pose Estimation：d:\ChatPaper\academic Papers\Quantization-Aware-Training\SPLite Hand_ Sparsity-Aware Lightweight 3D Hand Pose Estimation.pdf
2025-11-09 21:33:11,870 - INFO - root - 跳过已处理论文 CTR-LoRA: Curvature-Aware and Trust-Region Guided Low-Rank Adaptation for Large Language Models：d:\ChatPaper\academic Papers\Quantization-Aware-Training\CTR-LoRA_ Curvature-Aware and Trust-Region Guided Low-Rank Adaptation for Large.pdf
2025-11-09 21:33:11,872 - INFO - root - 正在总结论文 15/40: SANR: Scene-Aware Neural Representation for Light Field Image Compression with Rate-Distortion Optimization
2025-11-09 21:33:52,442 - INFO - root - LLMClient: rate limit reached, sleeping 19.4s
2025-11-09 21:34:31,622 - INFO - root - 正在提取论文图片...
2025-11-09 21:34:33,820 - INFO - root - 已保存图片 1/10：./export\images_SANR_ Scene-Aware Neural Representation for Light Field Image Compression with R\figure_1_page3.png
2025-11-09 21:34:34,007 - INFO - root - 已保存图片 2/10：./export\images_SANR_ Scene-Aware Neural Representation for Light Field Image Compression with R\figure_2_page8.png
2025-11-09 21:34:34,142 - INFO - root - 已保存图片 3/10：./export\images_SANR_ Scene-Aware Neural Representation for Light Field Image Compression with R\figure_3_page8.png
2025-11-09 21:34:34,239 - INFO - root - 已保存图片 4/10：./export\images_SANR_ Scene-Aware Neural Representation for Light Field Image Compression with R\figure_4_page8.png
2025-11-09 21:34:34,376 - INFO - root - 已保存图片 5/10：./export\images_SANR_ Scene-Aware Neural Representation for Light Field Image Compression with R\figure_5_page8.png
2025-11-09 21:34:34,477 - INFO - root - 已保存图片 6/10：./export\images_SANR_ Scene-Aware Neural Representation for Light Field Image Compression with R\figure_6_page8.png
2025-11-09 21:34:34,585 - INFO - root - 已保存图片 7/10：./export\images_SANR_ Scene-Aware Neural Representation for Light Field Image Compression with R\figure_7_page8.png
2025-11-09 21:34:34,696 - INFO - root - 已保存图片 8/10：./export\images_SANR_ Scene-Aware Neural Representation for Light Field Image Compression with R\figure_8_page8.png
2025-11-09 21:34:34,852 - INFO - root - 已保存图片 9/10：./export\images_SANR_ Scene-Aware Neural Representation for Light Field Image Compression with R\figure_9_page8.png
2025-11-09 21:34:34,936 - INFO - root - 已保存图片 10/10：./export\images_SANR_ Scene-Aware Neural Representation for Light Field Image Compression with R\figure_10_page10.png
2025-11-09 21:34:34,942 - INFO - root - 成功添加图片 1：./export\images_SANR_ Scene-Aware Neural Representation for Light Field Image Compression with R\figure_1_page3.png
2025-11-09 21:34:34,942 - INFO - root - 成功添加图片 2：./export\images_SANR_ Scene-Aware Neural Representation for Light Field Image Compression with R\figure_2_page8.png
2025-11-09 21:34:34,942 - INFO - root - 成功添加图片 3：./export\images_SANR_ Scene-Aware Neural Representation for Light Field Image Compression with R\figure_3_page8.png
2025-11-09 21:34:34,943 - INFO - root - 成功添加图片 4：./export\images_SANR_ Scene-Aware Neural Representation for Light Field Image Compression with R\figure_4_page8.png
2025-11-09 21:34:34,945 - INFO - root - 成功添加图片 5：./export\images_SANR_ Scene-Aware Neural Representation for Light Field Image Compression with R\figure_5_page8.png
2025-11-09 21:34:34,945 - INFO - root - 成功添加图片 6：./export\images_SANR_ Scene-Aware Neural Representation for Light Field Image Compression with R\figure_6_page8.png
2025-11-09 21:34:34,950 - INFO - root - 成功添加图片 7：./export\images_SANR_ Scene-Aware Neural Representation for Light Field Image Compression with R\figure_7_page8.png
2025-11-09 21:34:34,950 - INFO - root - 成功添加图片 8：./export\images_SANR_ Scene-Aware Neural Representation for Light Field Image Compression with R\figure_8_page8.png
2025-11-09 21:34:34,951 - INFO - root - 成功添加图片 9：./export\images_SANR_ Scene-Aware Neural Representation for Light Field Image Compression with R\figure_9_page8.png
2025-11-09 21:34:34,951 - INFO - root - 成功添加图片 10：./export\images_SANR_ Scene-Aware Neural Representation for Light Field Image Compression with R\figure_10_page10.png
2025-11-09 21:34:34,954 - INFO - root - 论文《SANR: Scene-Aware Neural Representation for Light Field Image Compression with Rate-Distortion Optimization》的分析已保存到 ./export\SANR_ Scene-Aware Neural Representation for Light Field Image Compression with R.md
2025-11-09 21:34:34,960 - INFO - root - 正在总结论文 16/40: SpikeFit: Towards Optimal Deployment of Spiking Networks on Neuromorphic Hardware
2025-11-09 21:34:44,556 - INFO - root - LLMClient: rate limit reached, sleeping 27.3s
2025-11-09 21:36:00,667 - INFO - root - 正在提取论文图片...
2025-11-09 21:36:00,708 - INFO - root - 论文《SpikeFit: Towards Optimal Deployment of Spiking Networks on Neuromorphic Hardware》的分析已保存到 ./export\SpikeFit_ Towards Optimal Deployment of Spiking Networks on Neuromorphic Hardwar.md
2025-11-09 21:36:00,713 - INFO - root - 正在总结论文 17/40: GRank: Towards Target-Aware and Streamlined Industrial Retrieval with a Generate-Rank Framework
2025-11-09 21:36:00,713 - INFO - root - LLMClient: rate limit reached, sleeping 11.2s
2025-11-09 21:36:23,920 - INFO - root - LLMClient: rate limit reached, sleeping 17.6s
2025-11-09 21:38:08,051 - INFO - root - 正在提取论文图片...
2025-11-09 21:38:09,983 - INFO - root - 已保存图片 1/10：./export\images_GRank_ Towards Target-Aware and Streamlined Industrial Retrieval with a Generate\figure_1_page7.png
2025-11-09 21:38:10,124 - INFO - root - 已保存图片 2/10：./export\images_GRank_ Towards Target-Aware and Streamlined Industrial Retrieval with a Generate\figure_2_page3.png
2025-11-09 21:38:10,276 - INFO - root - 已保存图片 3/10：./export\images_GRank_ Towards Target-Aware and Streamlined Industrial Retrieval with a Generate\figure_3_page4.png
2025-11-09 21:38:10,281 - INFO - root - 成功添加图片 1：./export\images_GRank_ Towards Target-Aware and Streamlined Industrial Retrieval with a Generate\figure_1_page7.png
2025-11-09 21:38:10,282 - INFO - root - 成功添加图片 2：./export\images_GRank_ Towards Target-Aware and Streamlined Industrial Retrieval with a Generate\figure_2_page3.png
2025-11-09 21:38:10,283 - INFO - root - 成功添加图片 3：./export\images_GRank_ Towards Target-Aware and Streamlined Industrial Retrieval with a Generate\figure_3_page4.png
2025-11-09 21:38:10,284 - INFO - root - 论文《GRank: Towards Target-Aware and Streamlined Industrial Retrieval with a Generate-Rank Framework》的分析已保存到 ./export\GRank_ Towards Target-Aware and Streamlined Industrial Retrieval with a Generate.md
2025-11-09 21:38:10,299 - INFO - root - 正在总结论文 18/40: SaLon3R: Structure-aware Long-term Generalizable 3D Reconstruction from Unposed Images
2025-11-09 21:38:22,479 - INFO - root - LLMClient: rate limit reached, sleeping 21.1s
2025-11-09 21:39:35,988 - INFO - root - 正在提取论文图片...
2025-11-09 21:39:41,895 - INFO - root - 已保存图片 1/10：./export\images_SaLon3R_ Structure-aware Long-term Generalizable 3D Reconstruction from Unposed\figure_1_page15.jpeg
2025-11-09 21:39:41,948 - INFO - root - 已保存图片 2/10：./export\images_SaLon3R_ Structure-aware Long-term Generalizable 3D Reconstruction from Unposed\figure_2_page15.jpeg
2025-11-09 21:39:42,005 - INFO - root - 已保存图片 3/10：./export\images_SaLon3R_ Structure-aware Long-term Generalizable 3D Reconstruction from Unposed\figure_3_page15.jpeg
2025-11-09 21:39:42,061 - INFO - root - 已保存图片 4/10：./export\images_SaLon3R_ Structure-aware Long-term Generalizable 3D Reconstruction from Unposed\figure_4_page15.jpeg
2025-11-09 21:39:42,125 - INFO - root - 已保存图片 5/10：./export\images_SaLon3R_ Structure-aware Long-term Generalizable 3D Reconstruction from Unposed\figure_5_page15.jpeg
2025-11-09 21:39:42,193 - INFO - root - 已保存图片 6/10：./export\images_SaLon3R_ Structure-aware Long-term Generalizable 3D Reconstruction from Unposed\figure_6_page15.jpeg
2025-11-09 21:39:42,271 - INFO - root - 已保存图片 7/10：./export\images_SaLon3R_ Structure-aware Long-term Generalizable 3D Reconstruction from Unposed\figure_7_page15.jpeg
2025-11-09 21:39:42,401 - INFO - root - 已保存图片 8/10：./export\images_SaLon3R_ Structure-aware Long-term Generalizable 3D Reconstruction from Unposed\figure_8_page15.jpeg
2025-11-09 21:39:42,479 - INFO - root - 已保存图片 9/10：./export\images_SaLon3R_ Structure-aware Long-term Generalizable 3D Reconstruction from Unposed\figure_9_page15.jpeg
2025-11-09 21:39:42,548 - INFO - root - 已保存图片 10/10：./export\images_SaLon3R_ Structure-aware Long-term Generalizable 3D Reconstruction from Unposed\figure_10_page15.jpeg
2025-11-09 21:39:42,566 - INFO - root - 成功添加图片 1：./export\images_SaLon3R_ Structure-aware Long-term Generalizable 3D Reconstruction from Unposed\figure_1_page15.jpeg
2025-11-09 21:39:42,566 - INFO - root - 成功添加图片 2：./export\images_SaLon3R_ Structure-aware Long-term Generalizable 3D Reconstruction from Unposed\figure_2_page15.jpeg
2025-11-09 21:39:42,567 - INFO - root - 成功添加图片 3：./export\images_SaLon3R_ Structure-aware Long-term Generalizable 3D Reconstruction from Unposed\figure_3_page15.jpeg
2025-11-09 21:39:42,568 - INFO - root - 成功添加图片 4：./export\images_SaLon3R_ Structure-aware Long-term Generalizable 3D Reconstruction from Unposed\figure_4_page15.jpeg
2025-11-09 21:39:42,579 - INFO - root - 成功添加图片 5：./export\images_SaLon3R_ Structure-aware Long-term Generalizable 3D Reconstruction from Unposed\figure_5_page15.jpeg
2025-11-09 21:39:42,583 - INFO - root - 成功添加图片 6：./export\images_SaLon3R_ Structure-aware Long-term Generalizable 3D Reconstruction from Unposed\figure_6_page15.jpeg
2025-11-09 21:39:42,584 - INFO - root - 成功添加图片 7：./export\images_SaLon3R_ Structure-aware Long-term Generalizable 3D Reconstruction from Unposed\figure_7_page15.jpeg
2025-11-09 21:39:42,586 - INFO - root - 成功添加图片 8：./export\images_SaLon3R_ Structure-aware Long-term Generalizable 3D Reconstruction from Unposed\figure_8_page15.jpeg
2025-11-09 21:39:42,591 - INFO - root - 成功添加图片 9：./export\images_SaLon3R_ Structure-aware Long-term Generalizable 3D Reconstruction from Unposed\figure_9_page15.jpeg
2025-11-09 21:39:42,592 - INFO - root - 成功添加图片 10：./export\images_SaLon3R_ Structure-aware Long-term Generalizable 3D Reconstruction from Unposed\figure_10_page15.jpeg
2025-11-09 21:39:42,602 - INFO - root - 论文《SaLon3R: Structure-aware Long-term Generalizable 3D Reconstruction from Unposed Images》的分析已保存到 ./export\SaLon3R_ Structure-aware Long-term Generalizable 3D Reconstruction from Unposed.md
2025-11-09 21:39:42,610 - INFO - root - 正在总结论文 19/40: FraQAT: Quantization Aware Training with Fractional bits
2025-11-09 21:39:42,611 - INFO - root - LLMClient: rate limit reached, sleeping 1.0s
2025-11-09 21:39:53,351 - INFO - root - LLMClient: rate limit reached, sleeping 24.2s
2025-11-09 21:41:12,276 - INFO - root - 正在提取论文图片...
2025-11-09 21:41:15,291 - INFO - root - 已保存图片 1/10：./export\images_FraQAT_ Quantization Aware Training with Fractional bits\figure_1_page4.png
2025-11-09 21:41:15,462 - INFO - root - 已保存图片 2/10：./export\images_FraQAT_ Quantization Aware Training with Fractional bits\figure_2_page1.png
2025-11-09 21:41:15,640 - INFO - root - 已保存图片 3/10：./export\images_FraQAT_ Quantization Aware Training with Fractional bits\figure_3_page1.png
2025-11-09 21:41:15,850 - INFO - root - 已保存图片 4/10：./export\images_FraQAT_ Quantization Aware Training with Fractional bits\figure_4_page1.png
2025-11-09 21:41:16,068 - INFO - root - 已保存图片 5/10：./export\images_FraQAT_ Quantization Aware Training with Fractional bits\figure_5_page1.png
2025-11-09 21:41:16,286 - INFO - root - 已保存图片 6/10：./export\images_FraQAT_ Quantization Aware Training with Fractional bits\figure_6_page1.png
2025-11-09 21:41:16,496 - INFO - root - 已保存图片 7/10：./export\images_FraQAT_ Quantization Aware Training with Fractional bits\figure_7_page1.png
2025-11-09 21:41:16,732 - INFO - root - 已保存图片 8/10：./export\images_FraQAT_ Quantization Aware Training with Fractional bits\figure_8_page8.png
2025-11-09 21:41:17,013 - INFO - root - 已保存图片 9/10：./export\images_FraQAT_ Quantization Aware Training with Fractional bits\figure_9_page8.png
2025-11-09 21:41:17,193 - INFO - root - 已保存图片 10/10：./export\images_FraQAT_ Quantization Aware Training with Fractional bits\figure_10_page8.png
2025-11-09 21:41:17,198 - INFO - root - 成功添加图片 1：./export\images_FraQAT_ Quantization Aware Training with Fractional bits\figure_1_page4.png
2025-11-09 21:41:17,198 - INFO - root - 成功添加图片 2：./export\images_FraQAT_ Quantization Aware Training with Fractional bits\figure_2_page1.png
2025-11-09 21:41:17,200 - INFO - root - 成功添加图片 3：./export\images_FraQAT_ Quantization Aware Training with Fractional bits\figure_3_page1.png
2025-11-09 21:41:17,200 - INFO - root - 成功添加图片 4：./export\images_FraQAT_ Quantization Aware Training with Fractional bits\figure_4_page1.png
2025-11-09 21:41:17,200 - INFO - root - 成功添加图片 5：./export\images_FraQAT_ Quantization Aware Training with Fractional bits\figure_5_page1.png
2025-11-09 21:41:17,201 - INFO - root - 成功添加图片 6：./export\images_FraQAT_ Quantization Aware Training with Fractional bits\figure_6_page1.png
2025-11-09 21:41:17,201 - INFO - root - 成功添加图片 7：./export\images_FraQAT_ Quantization Aware Training with Fractional bits\figure_7_page1.png
2025-11-09 21:41:17,203 - INFO - root - 成功添加图片 8：./export\images_FraQAT_ Quantization Aware Training with Fractional bits\figure_8_page8.png
2025-11-09 21:41:17,203 - INFO - root - 成功添加图片 9：./export\images_FraQAT_ Quantization Aware Training with Fractional bits\figure_9_page8.png
2025-11-09 21:41:17,204 - INFO - root - 成功添加图片 10：./export\images_FraQAT_ Quantization Aware Training with Fractional bits\figure_10_page8.png
2025-11-09 21:41:17,209 - INFO - root - 论文《FraQAT: Quantization Aware Training with Fractional bits》的分析已保存到 ./export\FraQAT_ Quantization Aware Training with Fractional bits.md
2025-11-09 21:41:17,213 - INFO - root - 正在总结论文 20/40: Computing-In-Memory Aware Model Adaption For Edge Devices
2025-11-09 21:41:17,213 - INFO - root - LLMClient: rate limit reached, sleeping 0.3s
2025-11-09 21:41:29,186 - INFO - root - LLMClient: rate limit reached, sleeping 23.2s
2025-11-09 21:42:37,435 - INFO - root - 正在提取论文图片...
2025-11-09 21:42:38,522 - INFO - root - 已保存图片 1/10：./export\images_Computing-In-Memory Aware Model Adaption For Edge Devices\figure_1_page2.png
2025-11-09 21:42:38,638 - INFO - root - 已保存图片 2/10：./export\images_Computing-In-Memory Aware Model Adaption For Edge Devices\figure_2_page2.png
2025-11-09 21:42:38,791 - INFO - root - 已保存图片 3/10：./export\images_Computing-In-Memory Aware Model Adaption For Edge Devices\figure_3_page4.png
2025-11-09 21:42:38,933 - INFO - root - 已保存图片 4/10：./export\images_Computing-In-Memory Aware Model Adaption For Edge Devices\figure_4_page2.png
2025-11-09 21:42:39,079 - INFO - root - 已保存图片 5/10：./export\images_Computing-In-Memory Aware Model Adaption For Edge Devices\figure_5_page2.png
2025-11-09 21:42:39,182 - INFO - root - 已保存图片 6/10：./export\images_Computing-In-Memory Aware Model Adaption For Edge Devices\figure_6_page5.png
2025-11-09 21:42:39,408 - INFO - root - 已保存图片 7/10：./export\images_Computing-In-Memory Aware Model Adaption For Edge Devices\figure_7_page5.png
2025-11-09 21:42:39,487 - INFO - root - 已保存图片 8/10：./export\images_Computing-In-Memory Aware Model Adaption For Edge Devices\figure_8_page9.jpeg
2025-11-09 21:42:39,551 - INFO - root - 已保存图片 9/10：./export\images_Computing-In-Memory Aware Model Adaption For Edge Devices\figure_9_page4.png
2025-11-09 21:42:39,662 - INFO - root - 已保存图片 10/10：./export\images_Computing-In-Memory Aware Model Adaption For Edge Devices\figure_10_page4.png
2025-11-09 21:42:39,669 - INFO - root - 成功添加图片 1：./export\images_Computing-In-Memory Aware Model Adaption For Edge Devices\figure_1_page2.png
2025-11-09 21:42:39,670 - INFO - root - 成功添加图片 2：./export\images_Computing-In-Memory Aware Model Adaption For Edge Devices\figure_2_page2.png
2025-11-09 21:42:39,671 - INFO - root - 成功添加图片 3：./export\images_Computing-In-Memory Aware Model Adaption For Edge Devices\figure_3_page4.png
2025-11-09 21:42:39,673 - INFO - root - 成功添加图片 4：./export\images_Computing-In-Memory Aware Model Adaption For Edge Devices\figure_4_page2.png
2025-11-09 21:42:39,675 - INFO - root - 成功添加图片 5：./export\images_Computing-In-Memory Aware Model Adaption For Edge Devices\figure_5_page2.png
2025-11-09 21:42:39,677 - INFO - root - 成功添加图片 6：./export\images_Computing-In-Memory Aware Model Adaption For Edge Devices\figure_6_page5.png
2025-11-09 21:42:39,680 - INFO - root - 成功添加图片 7：./export\images_Computing-In-Memory Aware Model Adaption For Edge Devices\figure_7_page5.png
2025-11-09 21:42:39,680 - INFO - root - 成功添加图片 8：./export\images_Computing-In-Memory Aware Model Adaption For Edge Devices\figure_8_page9.jpeg
2025-11-09 21:42:39,682 - INFO - root - 成功添加图片 9：./export\images_Computing-In-Memory Aware Model Adaption For Edge Devices\figure_9_page4.png
2025-11-09 21:42:39,688 - INFO - root - 成功添加图片 10：./export\images_Computing-In-Memory Aware Model Adaption For Edge Devices\figure_10_page4.png
2025-11-09 21:42:39,694 - INFO - root - 论文《Computing-In-Memory Aware Model Adaption For Edge Devices》的分析已保存到 ./export\Computing-In-Memory Aware Model Adaption For Edge Devices.md
2025-11-09 21:42:39,700 - INFO - root - 正在总结论文 21/40: Invited Paper: BitMedViT: Ternary-Quantized Vision Transformer for Medical AI Assistants on the Edge
2025-11-09 21:42:39,702 - INFO - root - LLMClient: rate limit reached, sleeping 12.7s
2025-11-09 21:43:02,670 - INFO - root - LLMClient: rate limit reached, sleeping 16.3s
2025-11-09 21:43:42,938 - INFO - root - LLMClient: rate limit reached, sleeping 9.4s
2025-11-09 21:44:11,552 - INFO - root - 正在提取论文图片...
2025-11-09 21:44:15,378 - INFO - root - 已保存图片 1/10：./export\images_Invited Paper_ BitMedViT_ Ternary-Quantized Vision Transformer for Medical AI As\figure_1_page6.png
2025-11-09 21:44:15,605 - INFO - root - 已保存图片 2/10：./export\images_Invited Paper_ BitMedViT_ Ternary-Quantized Vision Transformer for Medical AI As\figure_2_page5.png
2025-11-09 21:44:15,798 - INFO - root - 已保存图片 3/10：./export\images_Invited Paper_ BitMedViT_ Ternary-Quantized Vision Transformer for Medical AI As\figure_3_page3.png
2025-11-09 21:44:15,891 - INFO - root - 已保存图片 4/10：./export\images_Invited Paper_ BitMedViT_ Ternary-Quantized Vision Transformer for Medical AI As\figure_4_page4.png
2025-11-09 21:44:15,988 - INFO - root - 已保存图片 5/10：./export\images_Invited Paper_ BitMedViT_ Ternary-Quantized Vision Transformer for Medical AI As\figure_5_page1.png
2025-11-09 21:44:16,169 - INFO - root - 已保存图片 6/10：./export\images_Invited Paper_ BitMedViT_ Ternary-Quantized Vision Transformer for Medical AI As\figure_6_page5.png
2025-11-09 21:44:16,182 - INFO - root - 成功添加图片 1：./export\images_Invited Paper_ BitMedViT_ Ternary-Quantized Vision Transformer for Medical AI As\figure_1_page6.png
2025-11-09 21:44:16,184 - INFO - root - 成功添加图片 2：./export\images_Invited Paper_ BitMedViT_ Ternary-Quantized Vision Transformer for Medical AI As\figure_2_page5.png
2025-11-09 21:44:16,186 - INFO - root - 成功添加图片 3：./export\images_Invited Paper_ BitMedViT_ Ternary-Quantized Vision Transformer for Medical AI As\figure_3_page3.png
2025-11-09 21:44:16,186 - INFO - root - 成功添加图片 4：./export\images_Invited Paper_ BitMedViT_ Ternary-Quantized Vision Transformer for Medical AI As\figure_4_page4.png
2025-11-09 21:44:16,187 - INFO - root - 成功添加图片 5：./export\images_Invited Paper_ BitMedViT_ Ternary-Quantized Vision Transformer for Medical AI As\figure_5_page1.png
2025-11-09 21:44:16,188 - INFO - root - 成功添加图片 6：./export\images_Invited Paper_ BitMedViT_ Ternary-Quantized Vision Transformer for Medical AI As\figure_6_page5.png
2025-11-09 21:44:16,197 - INFO - root - 论文《Invited Paper: BitMedViT: Ternary-Quantized Vision Transformer for Medical AI Assistants on the Edge》的分析已保存到 ./export\Invited Paper_ BitMedViT_ Ternary-Quantized Vision Transformer for Medical AI As.md
2025-11-09 21:44:16,203 - INFO - root - 正在总结论文 22/40: NeuroRVQ: Multi-Scale EEG Tokenization for Generative Large Brainwave Models
2025-11-09 21:44:16,203 - INFO - root - LLMClient: rate limit reached, sleeping 2.8s
2025-11-09 21:44:29,913 - INFO - root - LLMClient: rate limit reached, sleeping 22.5s
2025-11-09 21:45:45,204 - INFO - root - 正在提取论文图片...
2025-11-09 21:45:46,089 - INFO - root - 已保存图片 1/10：./export\images_NeuroRVQ_ Multi-Scale EEG Tokenization for Generative Large Brainwave Models\figure_1_page3.png
2025-11-09 21:45:46,233 - INFO - root - 已保存图片 2/10：./export\images_NeuroRVQ_ Multi-Scale EEG Tokenization for Generative Large Brainwave Models\figure_2_page6.png
2025-11-09 21:45:46,344 - INFO - root - 已保存图片 3/10：./export\images_NeuroRVQ_ Multi-Scale EEG Tokenization for Generative Large Brainwave Models\figure_3_page5.png
2025-11-09 21:45:46,444 - INFO - root - 已保存图片 4/10：./export\images_NeuroRVQ_ Multi-Scale EEG Tokenization for Generative Large Brainwave Models\figure_4_page5.png
2025-11-09 21:45:46,559 - INFO - root - 已保存图片 5/10：./export\images_NeuroRVQ_ Multi-Scale EEG Tokenization for Generative Large Brainwave Models\figure_5_page7.png
2025-11-09 21:45:46,636 - INFO - root - 已保存图片 6/10：./export\images_NeuroRVQ_ Multi-Scale EEG Tokenization for Generative Large Brainwave Models\figure_6_page15.png
2025-11-09 21:45:46,762 - INFO - root - 已保存图片 7/10：./export\images_NeuroRVQ_ Multi-Scale EEG Tokenization for Generative Large Brainwave Models\figure_7_page17.png
2025-11-09 21:45:46,771 - INFO - root - 成功添加图片 1：./export\images_NeuroRVQ_ Multi-Scale EEG Tokenization for Generative Large Brainwave Models\figure_1_page3.png
2025-11-09 21:45:46,778 - INFO - root - 成功添加图片 2：./export\images_NeuroRVQ_ Multi-Scale EEG Tokenization for Generative Large Brainwave Models\figure_2_page6.png
2025-11-09 21:45:46,780 - INFO - root - 成功添加图片 3：./export\images_NeuroRVQ_ Multi-Scale EEG Tokenization for Generative Large Brainwave Models\figure_3_page5.png
2025-11-09 21:45:46,780 - INFO - root - 成功添加图片 4：./export\images_NeuroRVQ_ Multi-Scale EEG Tokenization for Generative Large Brainwave Models\figure_4_page5.png
2025-11-09 21:45:46,783 - INFO - root - 成功添加图片 5：./export\images_NeuroRVQ_ Multi-Scale EEG Tokenization for Generative Large Brainwave Models\figure_5_page7.png
2025-11-09 21:45:46,783 - INFO - root - 成功添加图片 6：./export\images_NeuroRVQ_ Multi-Scale EEG Tokenization for Generative Large Brainwave Models\figure_6_page15.png
2025-11-09 21:45:46,787 - INFO - root - 成功添加图片 7：./export\images_NeuroRVQ_ Multi-Scale EEG Tokenization for Generative Large Brainwave Models\figure_7_page17.png
2025-11-09 21:45:46,793 - INFO - root - 论文《NeuroRVQ: Multi-Scale EEG Tokenization for Generative Large Brainwave Models》的分析已保存到 ./export\NeuroRVQ_ Multi-Scale EEG Tokenization for Generative Large Brainwave Models.md
2025-11-09 21:45:46,805 - INFO - root - 正在总结论文 23/40: Detect Anything via Next Point Prediction
2025-11-09 21:45:46,806 - INFO - root - LLMClient: rate limit reached, sleeping 5.6s
2025-11-09 21:46:02,156 - INFO - root - LLMClient: rate limit reached, sleeping 18.9s
2025-11-09 21:46:47,221 - INFO - root - LLMClient: rate limit reached, sleeping 5.2s
2025-11-09 21:47:12,026 - INFO - root - 正在提取论文图片...
2025-11-09 21:47:14,731 - INFO - root - 已保存图片 1/10：./export\images_Detect Anything via Next Point Prediction\figure_1_page27.png
2025-11-09 21:47:14,963 - INFO - root - 已保存图片 2/10：./export\images_Detect Anything via Next Point Prediction\figure_2_page30.png
2025-11-09 21:47:15,124 - INFO - root - 已保存图片 3/10：./export\images_Detect Anything via Next Point Prediction\figure_3_page1.jpeg
2025-11-09 21:47:15,316 - INFO - root - 已保存图片 4/10：./export\images_Detect Anything via Next Point Prediction\figure_4_page47.jpeg
2025-11-09 21:47:15,426 - INFO - root - 已保存图片 5/10：./export\images_Detect Anything via Next Point Prediction\figure_5_page1.jpeg
2025-11-09 21:47:15,521 - INFO - root - 已保存图片 6/10：./export\images_Detect Anything via Next Point Prediction\figure_6_page7.jpeg
2025-11-09 21:47:15,602 - INFO - root - 已保存图片 7/10：./export\images_Detect Anything via Next Point Prediction\figure_7_page25.jpeg
2025-11-09 21:47:15,711 - INFO - root - 已保存图片 8/10：./export\images_Detect Anything via Next Point Prediction\figure_8_page47.jpeg
2025-11-09 21:47:15,847 - INFO - root - 已保存图片 9/10：./export\images_Detect Anything via Next Point Prediction\figure_9_page47.jpeg
2025-11-09 21:47:15,962 - INFO - root - 已保存图片 10/10：./export\images_Detect Anything via Next Point Prediction\figure_10_page47.jpeg
2025-11-09 21:47:15,999 - INFO - root - 成功添加图片 1：./export\images_Detect Anything via Next Point Prediction\figure_1_page27.png
2025-11-09 21:47:16,000 - INFO - root - 成功添加图片 2：./export\images_Detect Anything via Next Point Prediction\figure_2_page30.png
2025-11-09 21:47:16,000 - INFO - root - 成功添加图片 3：./export\images_Detect Anything via Next Point Prediction\figure_3_page1.jpeg
2025-11-09 21:47:16,000 - INFO - root - 成功添加图片 4：./export\images_Detect Anything via Next Point Prediction\figure_4_page47.jpeg
2025-11-09 21:47:16,002 - INFO - root - 成功添加图片 5：./export\images_Detect Anything via Next Point Prediction\figure_5_page1.jpeg
2025-11-09 21:47:16,002 - INFO - root - 成功添加图片 6：./export\images_Detect Anything via Next Point Prediction\figure_6_page7.jpeg
2025-11-09 21:47:16,002 - INFO - root - 成功添加图片 7：./export\images_Detect Anything via Next Point Prediction\figure_7_page25.jpeg
2025-11-09 21:47:16,003 - INFO - root - 成功添加图片 8：./export\images_Detect Anything via Next Point Prediction\figure_8_page47.jpeg
2025-11-09 21:47:16,003 - INFO - root - 成功添加图片 9：./export\images_Detect Anything via Next Point Prediction\figure_9_page47.jpeg
2025-11-09 21:47:16,004 - INFO - root - 成功添加图片 10：./export\images_Detect Anything via Next Point Prediction\figure_10_page47.jpeg
2025-11-09 21:47:16,014 - INFO - root - 论文《Detect Anything via Next Point Prediction》的分析已保存到 ./export\Detect Anything via Next Point Prediction.md
2025-11-09 21:47:16,017 - INFO - root - 正在总结论文 24/40: AndesVL Technical Report: An Efficient Mobile-side Multimodal Large Language Model
2025-11-09 21:47:16,021 - INFO - root - LLMClient: rate limit reached, sleeping 5.0s
2025-11-09 21:47:33,434 - INFO - root - LLMClient: rate limit reached, sleeping 18.9s
2025-11-09 21:48:20,242 - INFO - root - LLMClient: rate limit reached, sleeping 0.8s
2025-11-09 21:48:41,393 - INFO - root - 正在提取论文图片...
2025-11-09 21:48:44,224 - INFO - root - 已保存图片 1/10：./export\images_AndesVL Technical Report_ An Efficient Mobile-side Multimodal Large Language Mod\figure_1_page2.png
2025-11-09 21:48:44,451 - INFO - root - 已保存图片 2/10：./export\images_AndesVL Technical Report_ An Efficient Mobile-side Multimodal Large Language Mod\figure_2_page52.png
2025-11-09 21:48:44,702 - INFO - root - 已保存图片 3/10：./export\images_AndesVL Technical Report_ An Efficient Mobile-side Multimodal Large Language Mod\figure_3_page49.png
2025-11-09 21:48:44,823 - INFO - root - 已保存图片 4/10：./export\images_AndesVL Technical Report_ An Efficient Mobile-side Multimodal Large Language Mod\figure_4_page48.jpeg
2025-11-09 21:48:44,981 - INFO - root - 已保存图片 5/10：./export\images_AndesVL Technical Report_ An Efficient Mobile-side Multimodal Large Language Mod\figure_5_page51.png
2025-11-09 21:48:45,076 - INFO - root - 已保存图片 6/10：./export\images_AndesVL Technical Report_ An Efficient Mobile-side Multimodal Large Language Mod\figure_6_page46.png
2025-11-09 21:48:45,167 - INFO - root - 已保存图片 7/10：./export\images_AndesVL Technical Report_ An Efficient Mobile-side Multimodal Large Language Mod\figure_7_page51.png
2025-11-09 21:48:45,296 - INFO - root - 已保存图片 8/10：./export\images_AndesVL Technical Report_ An Efficient Mobile-side Multimodal Large Language Mod\figure_8_page5.png
2025-11-09 21:48:45,363 - INFO - root - 已保存图片 9/10：./export\images_AndesVL Technical Report_ An Efficient Mobile-side Multimodal Large Language Mod\figure_9_page11.png
2025-11-09 21:48:45,395 - INFO - root - 已保存图片 10/10：./export\images_AndesVL Technical Report_ An Efficient Mobile-side Multimodal Large Language Mod\figure_10_page13.png
2025-11-09 21:48:45,406 - INFO - root - 成功添加图片 1：./export\images_AndesVL Technical Report_ An Efficient Mobile-side Multimodal Large Language Mod\figure_1_page2.png
2025-11-09 21:48:45,406 - INFO - root - 成功添加图片 2：./export\images_AndesVL Technical Report_ An Efficient Mobile-side Multimodal Large Language Mod\figure_2_page52.png
2025-11-09 21:48:45,407 - INFO - root - 成功添加图片 3：./export\images_AndesVL Technical Report_ An Efficient Mobile-side Multimodal Large Language Mod\figure_3_page49.png
2025-11-09 21:48:45,407 - INFO - root - 成功添加图片 4：./export\images_AndesVL Technical Report_ An Efficient Mobile-side Multimodal Large Language Mod\figure_4_page48.jpeg
2025-11-09 21:48:45,407 - INFO - root - 成功添加图片 5：./export\images_AndesVL Technical Report_ An Efficient Mobile-side Multimodal Large Language Mod\figure_5_page51.png
2025-11-09 21:48:45,409 - INFO - root - 成功添加图片 6：./export\images_AndesVL Technical Report_ An Efficient Mobile-side Multimodal Large Language Mod\figure_6_page46.png
2025-11-09 21:48:45,409 - INFO - root - 成功添加图片 7：./export\images_AndesVL Technical Report_ An Efficient Mobile-side Multimodal Large Language Mod\figure_7_page51.png
2025-11-09 21:48:45,409 - INFO - root - 成功添加图片 8：./export\images_AndesVL Technical Report_ An Efficient Mobile-side Multimodal Large Language Mod\figure_8_page5.png
2025-11-09 21:48:45,409 - INFO - root - 成功添加图片 9：./export\images_AndesVL Technical Report_ An Efficient Mobile-side Multimodal Large Language Mod\figure_9_page11.png
2025-11-09 21:48:45,410 - INFO - root - 成功添加图片 10：./export\images_AndesVL Technical Report_ An Efficient Mobile-side Multimodal Large Language Mod\figure_10_page13.png
2025-11-09 21:48:45,418 - INFO - root - 论文《AndesVL Technical Report: An Efficient Mobile-side Multimodal Large Language Model》的分析已保存到 ./export\AndesVL Technical Report_ An Efficient Mobile-side Multimodal Large Language Mod.md
2025-11-09 21:48:45,424 - INFO - root - 正在总结论文 25/40: Rescaling-Aware Training for Efficient Deployment of Deep Learning Models on Full-Integer Hardware
2025-11-09 21:48:45,424 - INFO - root - LLMClient: rate limit reached, sleeping 7.0s
2025-11-09 21:49:02,758 - INFO - root - LLMClient: rate limit reached, sleeping 18.3s
2025-11-09 21:50:12,311 - INFO - root - 正在提取论文图片...
2025-11-09 21:50:12,410 - INFO - root - 已保存图片 1/10：./export\images_Rescaling-Aware Training for Efficient Deployment of Deep Learning Models on Ful\figure_1_page1.png
2025-11-09 21:50:12,460 - INFO - root - 已保存图片 2/10：./export\images_Rescaling-Aware Training for Efficient Deployment of Deep Learning Models on Ful\figure_2_page3.png
2025-11-09 21:50:12,479 - INFO - root - 已保存图片 3/10：./export\images_Rescaling-Aware Training for Efficient Deployment of Deep Learning Models on Ful\figure_3_page3.png
2025-11-09 21:50:12,498 - INFO - root - 已保存图片 4/10：./export\images_Rescaling-Aware Training for Efficient Deployment of Deep Learning Models on Ful\figure_4_page3.png
2025-11-09 21:50:12,513 - INFO - root - 已保存图片 5/10：./export\images_Rescaling-Aware Training for Efficient Deployment of Deep Learning Models on Ful\figure_5_page3.png
2025-11-09 21:50:12,525 - INFO - root - 已保存图片 6/10：./export\images_Rescaling-Aware Training for Efficient Deployment of Deep Learning Models on Ful\figure_6_page1.png
2025-11-09 21:50:12,545 - INFO - root - 已保存图片 7/10：./export\images_Rescaling-Aware Training for Efficient Deployment of Deep Learning Models on Ful\figure_7_page3.png
2025-11-09 21:50:12,565 - INFO - root - 已保存图片 8/10：./export\images_Rescaling-Aware Training for Efficient Deployment of Deep Learning Models on Ful\figure_8_page3.png
2025-11-09 21:50:12,583 - INFO - root - 已保存图片 9/10：./export\images_Rescaling-Aware Training for Efficient Deployment of Deep Learning Models on Ful\figure_9_page1.png
2025-11-09 21:50:12,609 - INFO - root - 已保存图片 10/10：./export\images_Rescaling-Aware Training for Efficient Deployment of Deep Learning Models on Ful\figure_10_page1.png
2025-11-09 21:50:12,610 - INFO - root - 成功添加图片 1：./export\images_Rescaling-Aware Training for Efficient Deployment of Deep Learning Models on Ful\figure_1_page1.png
2025-11-09 21:50:12,611 - INFO - root - 成功添加图片 2：./export\images_Rescaling-Aware Training for Efficient Deployment of Deep Learning Models on Ful\figure_2_page3.png
2025-11-09 21:50:12,611 - INFO - root - 成功添加图片 3：./export\images_Rescaling-Aware Training for Efficient Deployment of Deep Learning Models on Ful\figure_3_page3.png
2025-11-09 21:50:12,611 - INFO - root - 成功添加图片 4：./export\images_Rescaling-Aware Training for Efficient Deployment of Deep Learning Models on Ful\figure_4_page3.png
2025-11-09 21:50:12,613 - INFO - root - 成功添加图片 5：./export\images_Rescaling-Aware Training for Efficient Deployment of Deep Learning Models on Ful\figure_5_page3.png
2025-11-09 21:50:12,614 - INFO - root - 成功添加图片 6：./export\images_Rescaling-Aware Training for Efficient Deployment of Deep Learning Models on Ful\figure_6_page1.png
2025-11-09 21:50:12,615 - INFO - root - 成功添加图片 7：./export\images_Rescaling-Aware Training for Efficient Deployment of Deep Learning Models on Ful\figure_7_page3.png
2025-11-09 21:50:12,617 - INFO - root - 成功添加图片 8：./export\images_Rescaling-Aware Training for Efficient Deployment of Deep Learning Models on Ful\figure_8_page3.png
2025-11-09 21:50:12,622 - INFO - root - 成功添加图片 9：./export\images_Rescaling-Aware Training for Efficient Deployment of Deep Learning Models on Ful\figure_9_page1.png
2025-11-09 21:50:12,624 - INFO - root - 成功添加图片 10：./export\images_Rescaling-Aware Training for Efficient Deployment of Deep Learning Models on Ful\figure_10_page1.png
2025-11-09 21:50:12,628 - INFO - root - 论文《Rescaling-Aware Training for Efficient Deployment of Deep Learning Models on Full-Integer Hardware》的分析已保存到 ./export\Rescaling-Aware Training for Efficient Deployment of Deep Learning Models on Ful.md
2025-11-09 21:50:12,657 - INFO - root - 正在总结论文 26/40: SASER: Stego attacks on open-source LLMs
2025-11-09 21:50:12,658 - INFO - root - LLMClient: rate limit reached, sleeping 8.4s
2025-11-09 21:50:32,098 - INFO - root - LLMClient: rate limit reached, sleeping 20.6s
2025-11-09 21:51:51,023 - INFO - root - 正在提取论文图片...
2025-11-09 21:51:52,545 - INFO - root - 已保存图片 1/10：./export\images_SASER_ Stego attacks on open-source LLMs\figure_1_page5.png
2025-11-09 21:51:52,557 - INFO - root - 已保存图片 2/10：./export\images_SASER_ Stego attacks on open-source LLMs\figure_2_page8.png
2025-11-09 21:51:52,574 - INFO - root - 已保存图片 3/10：./export\images_SASER_ Stego attacks on open-source LLMs\figure_3_page8.png
2025-11-09 21:51:52,591 - INFO - root - 已保存图片 4/10：./export\images_SASER_ Stego attacks on open-source LLMs\figure_4_page8.png
2025-11-09 21:51:52,604 - INFO - root - 已保存图片 5/10：./export\images_SASER_ Stego attacks on open-source LLMs\figure_5_page8.png
2025-11-09 21:51:52,617 - INFO - root - 已保存图片 6/10：./export\images_SASER_ Stego attacks on open-source LLMs\figure_6_page9.png
2025-11-09 21:51:52,632 - INFO - root - 已保存图片 7/10：./export\images_SASER_ Stego attacks on open-source LLMs\figure_7_page9.png
2025-11-09 21:51:52,644 - INFO - root - 已保存图片 8/10：./export\images_SASER_ Stego attacks on open-source LLMs\figure_8_page9.png
2025-11-09 21:51:52,656 - INFO - root - 已保存图片 9/10：./export\images_SASER_ Stego attacks on open-source LLMs\figure_9_page9.png
2025-11-09 21:51:52,670 - INFO - root - 已保存图片 10/10：./export\images_SASER_ Stego attacks on open-source LLMs\figure_10_page11.png
2025-11-09 21:51:52,677 - INFO - root - 成功添加图片 1：./export\images_SASER_ Stego attacks on open-source LLMs\figure_1_page5.png
2025-11-09 21:51:52,678 - INFO - root - 成功添加图片 2：./export\images_SASER_ Stego attacks on open-source LLMs\figure_2_page8.png
2025-11-09 21:51:52,679 - INFO - root - 成功添加图片 3：./export\images_SASER_ Stego attacks on open-source LLMs\figure_3_page8.png
2025-11-09 21:51:52,680 - INFO - root - 成功添加图片 4：./export\images_SASER_ Stego attacks on open-source LLMs\figure_4_page8.png
2025-11-09 21:51:52,680 - INFO - root - 成功添加图片 5：./export\images_SASER_ Stego attacks on open-source LLMs\figure_5_page8.png
2025-11-09 21:51:52,680 - INFO - root - 成功添加图片 6：./export\images_SASER_ Stego attacks on open-source LLMs\figure_6_page9.png
2025-11-09 21:51:52,681 - INFO - root - 成功添加图片 7：./export\images_SASER_ Stego attacks on open-source LLMs\figure_7_page9.png
2025-11-09 21:51:52,681 - INFO - root - 成功添加图片 8：./export\images_SASER_ Stego attacks on open-source LLMs\figure_8_page9.png
2025-11-09 21:51:52,681 - INFO - root - 成功添加图片 9：./export\images_SASER_ Stego attacks on open-source LLMs\figure_9_page9.png
2025-11-09 21:51:52,683 - INFO - root - 成功添加图片 10：./export\images_SASER_ Stego attacks on open-source LLMs\figure_10_page11.png
2025-11-09 21:51:52,688 - INFO - root - 论文《SASER: Stego attacks on open-source LLMs》的分析已保存到 ./export\SASER_ Stego attacks on open-source LLMs.md
2025-11-09 21:51:52,696 - INFO - root - 正在总结论文 27/40: Ultralytics YOLO Evolution: An Overview of YOLO26, YOLO11, YOLOv8 and YOLOv5 Object Detectors for Computer Vision and Pattern Recognition
2025-11-09 21:51:52,697 - INFO - root - LLMClient: rate limit reached, sleeping 0.0s
2025-11-09 21:52:01,821 - INFO - root - LLMClient: rate limit reached, sleeping 22.6s
2025-11-09 21:53:20,194 - INFO - root - 正在提取论文图片...
2025-11-09 21:53:20,666 - INFO - root - 已保存图片 1/10：./export\images_Ultralytics YOLO Evolution_ An Overview of YOLO26, YOLO11, YOLOv8 and YOLOv5 Obj\figure_1_page6.png
2025-11-09 21:53:20,727 - INFO - root - 已保存图片 2/10：./export\images_Ultralytics YOLO Evolution_ An Overview of YOLO26, YOLO11, YOLOv8 and YOLOv5 Obj\figure_2_page8.png
2025-11-09 21:53:20,738 - INFO - root - 已保存图片 3/10：./export\images_Ultralytics YOLO Evolution_ An Overview of YOLO26, YOLO11, YOLOv8 and YOLOv5 Obj\figure_3_page7.jpeg
2025-11-09 21:53:20,779 - INFO - root - 已保存图片 4/10：./export\images_Ultralytics YOLO Evolution_ An Overview of YOLO26, YOLO11, YOLOv8 and YOLOv5 Obj\figure_4_page5.jpeg
2025-11-09 21:53:20,818 - INFO - root - 已保存图片 5/10：./export\images_Ultralytics YOLO Evolution_ An Overview of YOLO26, YOLO11, YOLOv8 and YOLOv5 Obj\figure_5_page5.jpeg
2025-11-09 21:53:20,850 - INFO - root - 已保存图片 6/10：./export\images_Ultralytics YOLO Evolution_ An Overview of YOLO26, YOLO11, YOLOv8 and YOLOv5 Obj\figure_6_page5.jpeg
2025-11-09 21:53:20,866 - INFO - root - 已保存图片 7/10：./export\images_Ultralytics YOLO Evolution_ An Overview of YOLO26, YOLO11, YOLOv8 and YOLOv5 Obj\figure_7_page5.jpeg
2025-11-09 21:53:20,909 - INFO - root - 已保存图片 8/10：./export\images_Ultralytics YOLO Evolution_ An Overview of YOLO26, YOLO11, YOLOv8 and YOLOv5 Obj\figure_8_page5.jpeg
2025-11-09 21:53:20,923 - INFO - root - 已保存图片 9/10：./export\images_Ultralytics YOLO Evolution_ An Overview of YOLO26, YOLO11, YOLOv8 and YOLOv5 Obj\figure_9_page5.jpeg
2025-11-09 21:53:20,972 - INFO - root - 已保存图片 10/10：./export\images_Ultralytics YOLO Evolution_ An Overview of YOLO26, YOLO11, YOLOv8 and YOLOv5 Obj\figure_10_page5.png
2025-11-09 21:53:20,977 - INFO - root - 成功添加图片 1：./export\images_Ultralytics YOLO Evolution_ An Overview of YOLO26, YOLO11, YOLOv8 and YOLOv5 Obj\figure_1_page6.png
2025-11-09 21:53:20,977 - INFO - root - 成功添加图片 2：./export\images_Ultralytics YOLO Evolution_ An Overview of YOLO26, YOLO11, YOLOv8 and YOLOv5 Obj\figure_2_page8.png
2025-11-09 21:53:20,978 - INFO - root - 成功添加图片 3：./export\images_Ultralytics YOLO Evolution_ An Overview of YOLO26, YOLO11, YOLOv8 and YOLOv5 Obj\figure_3_page7.jpeg
2025-11-09 21:53:20,978 - INFO - root - 成功添加图片 4：./export\images_Ultralytics YOLO Evolution_ An Overview of YOLO26, YOLO11, YOLOv8 and YOLOv5 Obj\figure_4_page5.jpeg
2025-11-09 21:53:20,979 - INFO - root - 成功添加图片 5：./export\images_Ultralytics YOLO Evolution_ An Overview of YOLO26, YOLO11, YOLOv8 and YOLOv5 Obj\figure_5_page5.jpeg
2025-11-09 21:53:20,979 - INFO - root - 成功添加图片 6：./export\images_Ultralytics YOLO Evolution_ An Overview of YOLO26, YOLO11, YOLOv8 and YOLOv5 Obj\figure_6_page5.jpeg
2025-11-09 21:53:20,979 - INFO - root - 成功添加图片 7：./export\images_Ultralytics YOLO Evolution_ An Overview of YOLO26, YOLO11, YOLOv8 and YOLOv5 Obj\figure_7_page5.jpeg
2025-11-09 21:53:20,980 - INFO - root - 成功添加图片 8：./export\images_Ultralytics YOLO Evolution_ An Overview of YOLO26, YOLO11, YOLOv8 and YOLOv5 Obj\figure_8_page5.jpeg
2025-11-09 21:53:20,980 - INFO - root - 成功添加图片 9：./export\images_Ultralytics YOLO Evolution_ An Overview of YOLO26, YOLO11, YOLOv8 and YOLOv5 Obj\figure_9_page5.jpeg
2025-11-09 21:53:20,980 - INFO - root - 成功添加图片 10：./export\images_Ultralytics YOLO Evolution_ An Overview of YOLO26, YOLO11, YOLOv8 and YOLOv5 Obj\figure_10_page5.png
2025-11-09 21:53:20,984 - INFO - root - 论文《Ultralytics YOLO Evolution: An Overview of YOLO26, YOLO11, YOLOv8 and YOLOv5 Object Detectors for Computer Vision and Pattern Recognition》的分析已保存到 ./export\Ultralytics YOLO Evolution_ An Overview of YOLO26, YOLO11, YOLOv8 and YOLOv5 Obj.md
2025-11-09 21:53:20,998 - INFO - root - 正在总结论文 28/40: A Theoretically-Grounded Codebook for Digital Semantic Communications
2025-11-09 21:53:21,000 - INFO - root - LLMClient: rate limit reached, sleeping 3.4s
2025-11-09 21:53:36,120 - INFO - root - LLMClient: rate limit reached, sleeping 19.6s
2025-11-09 21:54:43,975 - INFO - root - 正在提取论文图片...
2025-11-09 21:54:48,650 - INFO - root - 已保存图片 1/10：./export\images_A Theoretically-Grounded Codebook for Digital Semantic Communications\figure_1_page2.png
2025-11-09 21:54:49,210 - INFO - root - 已保存图片 2/10：./export\images_A Theoretically-Grounded Codebook for Digital Semantic Communications\figure_2_page3.png
2025-11-09 21:54:49,322 - INFO - root - 已保存图片 3/10：./export\images_A Theoretically-Grounded Codebook for Digital Semantic Communications\figure_3_page6.png
2025-11-09 21:54:49,453 - INFO - root - 已保存图片 4/10：./export\images_A Theoretically-Grounded Codebook for Digital Semantic Communications\figure_4_page6.png
2025-11-09 21:54:49,497 - INFO - root - 成功添加图片 1：./export\images_A Theoretically-Grounded Codebook for Digital Semantic Communications\figure_1_page2.png
2025-11-09 21:54:49,498 - INFO - root - 成功添加图片 2：./export\images_A Theoretically-Grounded Codebook for Digital Semantic Communications\figure_2_page3.png
2025-11-09 21:54:49,498 - INFO - root - 成功添加图片 3：./export\images_A Theoretically-Grounded Codebook for Digital Semantic Communications\figure_3_page6.png
2025-11-09 21:54:49,498 - INFO - root - 成功添加图片 4：./export\images_A Theoretically-Grounded Codebook for Digital Semantic Communications\figure_4_page6.png
2025-11-09 21:54:49,503 - INFO - root - 论文《A Theoretically-Grounded Codebook for Digital Semantic Communications》的分析已保存到 ./export\A Theoretically-Grounded Codebook for Digital Semantic Communications.md
2025-11-09 21:54:49,509 - INFO - root - 正在总结论文 29/40: QuantDemoire: Quantization with Outlier Aware for Image Demoiréing
2025-11-09 21:54:49,509 - INFO - root - LLMClient: rate limit reached, sleeping 6.2s
2025-11-09 21:55:04,882 - INFO - root - LLMClient: rate limit reached, sleeping 20.6s
2025-11-09 21:56:22,465 - INFO - root - 正在提取论文图片...
2025-11-09 21:56:30,614 - INFO - root - 已保存图片 1/10：./export\images_QuantDemoire_ Quantization with Outlier Aware for Image Demoiréing\figure_1_page8.png
2025-11-09 21:56:31,050 - INFO - root - 已保存图片 2/10：./export\images_QuantDemoire_ Quantization with Outlier Aware for Image Demoiréing\figure_2_page8.png
2025-11-09 21:56:31,489 - INFO - root - 已保存图片 3/10：./export\images_QuantDemoire_ Quantization with Outlier Aware for Image Demoiréing\figure_3_page8.png
2025-11-09 21:56:31,911 - INFO - root - 已保存图片 4/10：./export\images_QuantDemoire_ Quantization with Outlier Aware for Image Demoiréing\figure_4_page8.png
2025-11-09 21:56:31,984 - INFO - root - 已保存图片 5/10：./export\images_QuantDemoire_ Quantization with Outlier Aware for Image Demoiréing\figure_5_page4.jpeg
2025-11-09 21:56:32,041 - INFO - root - 已保存图片 6/10：./export\images_QuantDemoire_ Quantization with Outlier Aware for Image Demoiréing\figure_6_page4.jpeg
2025-11-09 21:56:32,105 - INFO - root - 已保存图片 7/10：./export\images_QuantDemoire_ Quantization with Outlier Aware for Image Demoiréing\figure_7_page4.jpeg
2025-11-09 21:56:32,123 - INFO - root - 已保存图片 8/10：./export\images_QuantDemoire_ Quantization with Outlier Aware for Image Demoiréing\figure_8_page3.jpeg
2025-11-09 21:56:32,146 - INFO - root - 已保存图片 9/10：./export\images_QuantDemoire_ Quantization with Outlier Aware for Image Demoiréing\figure_9_page3.jpeg
2025-11-09 21:56:32,196 - INFO - root - 已保存图片 10/10：./export\images_QuantDemoire_ Quantization with Outlier Aware for Image Demoiréing\figure_10_page2.jpeg
2025-11-09 21:56:32,219 - INFO - root - 成功添加图片 1：./export\images_QuantDemoire_ Quantization with Outlier Aware for Image Demoiréing\figure_1_page8.png
2025-11-09 21:56:32,219 - INFO - root - 成功添加图片 2：./export\images_QuantDemoire_ Quantization with Outlier Aware for Image Demoiréing\figure_2_page8.png
2025-11-09 21:56:32,220 - INFO - root - 成功添加图片 3：./export\images_QuantDemoire_ Quantization with Outlier Aware for Image Demoiréing\figure_3_page8.png
2025-11-09 21:56:32,220 - INFO - root - 成功添加图片 4：./export\images_QuantDemoire_ Quantization with Outlier Aware for Image Demoiréing\figure_4_page8.png
2025-11-09 21:56:32,220 - INFO - root - 成功添加图片 5：./export\images_QuantDemoire_ Quantization with Outlier Aware for Image Demoiréing\figure_5_page4.jpeg
2025-11-09 21:56:32,221 - INFO - root - 成功添加图片 6：./export\images_QuantDemoire_ Quantization with Outlier Aware for Image Demoiréing\figure_6_page4.jpeg
2025-11-09 21:56:32,221 - INFO - root - 成功添加图片 7：./export\images_QuantDemoire_ Quantization with Outlier Aware for Image Demoiréing\figure_7_page4.jpeg
2025-11-09 21:56:32,223 - INFO - root - 成功添加图片 8：./export\images_QuantDemoire_ Quantization with Outlier Aware for Image Demoiréing\figure_8_page3.jpeg
2025-11-09 21:56:32,223 - INFO - root - 成功添加图片 9：./export\images_QuantDemoire_ Quantization with Outlier Aware for Image Demoiréing\figure_9_page3.jpeg
2025-11-09 21:56:32,223 - INFO - root - 成功添加图片 10：./export\images_QuantDemoire_ Quantization with Outlier Aware for Image Demoiréing\figure_10_page2.jpeg
2025-11-09 21:56:32,229 - INFO - root - 论文《QuantDemoire: Quantization with Outlier Aware for Image Demoiréing》的分析已保存到 ./export\QuantDemoire_ Quantization with Outlier Aware for Image Demoiréing.md
2025-11-09 21:56:32,237 - INFO - root - 正在总结论文 30/40: Adaptively Sampling-Reusing-Mixing Decomposed Gradients to Speed Up Sharpness Aware Minimization
2025-11-09 21:56:42,609 - INFO - root - LLMClient: rate limit reached, sleeping 15.9s
2025-11-09 21:58:02,642 - INFO - root - 正在提取论文图片...
2025-11-09 21:58:02,655 - INFO - root - 论文《Adaptively Sampling-Reusing-Mixing Decomposed Gradients to Speed Up Sharpness Aware Minimization》的分析已保存到 ./export\Adaptively Sampling-Reusing-Mixing Decomposed Gradients to Speed Up Sharpness Aw.md
2025-11-09 21:58:02,661 - INFO - root - 正在总结论文 31/40: Quant-dLLM: Post-Training Extreme Low-Bit Quantization for Diffusion Large Language Models
2025-11-09 21:58:16,405 - INFO - root - LLMClient: rate limit reached, sleeping 24.1s
2025-11-09 21:59:33,510 - INFO - root - 正在提取论文图片...
2025-11-09 21:59:33,594 - INFO - root - 已保存图片 1/10：./export\images_Quant-dLLM_ Post-Training Extreme Low-Bit Quantization for Diffusion Large Langu\figure_1_page3.jpeg
2025-11-09 21:59:33,680 - INFO - root - 已保存图片 2/10：./export\images_Quant-dLLM_ Post-Training Extreme Low-Bit Quantization for Diffusion Large Langu\figure_2_page3.png
2025-11-09 21:59:33,727 - INFO - root - 已保存图片 3/10：./export\images_Quant-dLLM_ Post-Training Extreme Low-Bit Quantization for Diffusion Large Langu\figure_3_page3.jpeg
2025-11-09 21:59:33,806 - INFO - root - 已保存图片 4/10：./export\images_Quant-dLLM_ Post-Training Extreme Low-Bit Quantization for Diffusion Large Langu\figure_4_page3.png
2025-11-09 21:59:33,871 - INFO - root - 已保存图片 5/10：./export\images_Quant-dLLM_ Post-Training Extreme Low-Bit Quantization for Diffusion Large Langu\figure_5_page3.png
2025-11-09 21:59:33,952 - INFO - root - 已保存图片 6/10：./export\images_Quant-dLLM_ Post-Training Extreme Low-Bit Quantization for Diffusion Large Langu\figure_6_page3.png
2025-11-09 21:59:34,016 - INFO - root - 已保存图片 7/10：./export\images_Quant-dLLM_ Post-Training Extreme Low-Bit Quantization for Diffusion Large Langu\figure_7_page3.png
2025-11-09 21:59:34,058 - INFO - root - 已保存图片 8/10：./export\images_Quant-dLLM_ Post-Training Extreme Low-Bit Quantization for Diffusion Large Langu\figure_8_page3.jpeg
2025-11-09 21:59:34,143 - INFO - root - 已保存图片 9/10：./export\images_Quant-dLLM_ Post-Training Extreme Low-Bit Quantization for Diffusion Large Langu\figure_9_page3.png
2025-11-09 21:59:34,160 - INFO - root - 已保存图片 10/10：./export\images_Quant-dLLM_ Post-Training Extreme Low-Bit Quantization for Diffusion Large Langu\figure_10_page3.png
2025-11-09 21:59:34,165 - INFO - root - 成功添加图片 1：./export\images_Quant-dLLM_ Post-Training Extreme Low-Bit Quantization for Diffusion Large Langu\figure_1_page3.jpeg
2025-11-09 21:59:34,166 - INFO - root - 成功添加图片 2：./export\images_Quant-dLLM_ Post-Training Extreme Low-Bit Quantization for Diffusion Large Langu\figure_2_page3.png
2025-11-09 21:59:34,166 - INFO - root - 成功添加图片 3：./export\images_Quant-dLLM_ Post-Training Extreme Low-Bit Quantization for Diffusion Large Langu\figure_3_page3.jpeg
2025-11-09 21:59:34,167 - INFO - root - 成功添加图片 4：./export\images_Quant-dLLM_ Post-Training Extreme Low-Bit Quantization for Diffusion Large Langu\figure_4_page3.png
2025-11-09 21:59:34,167 - INFO - root - 成功添加图片 5：./export\images_Quant-dLLM_ Post-Training Extreme Low-Bit Quantization for Diffusion Large Langu\figure_5_page3.png
2025-11-09 21:59:34,167 - INFO - root - 成功添加图片 6：./export\images_Quant-dLLM_ Post-Training Extreme Low-Bit Quantization for Diffusion Large Langu\figure_6_page3.png
2025-11-09 21:59:34,169 - INFO - root - 成功添加图片 7：./export\images_Quant-dLLM_ Post-Training Extreme Low-Bit Quantization for Diffusion Large Langu\figure_7_page3.png
2025-11-09 21:59:34,169 - INFO - root - 成功添加图片 8：./export\images_Quant-dLLM_ Post-Training Extreme Low-Bit Quantization for Diffusion Large Langu\figure_8_page3.jpeg
2025-11-09 21:59:34,169 - INFO - root - 成功添加图片 9：./export\images_Quant-dLLM_ Post-Training Extreme Low-Bit Quantization for Diffusion Large Langu\figure_9_page3.png
2025-11-09 21:59:34,170 - INFO - root - 成功添加图片 10：./export\images_Quant-dLLM_ Post-Training Extreme Low-Bit Quantization for Diffusion Large Langu\figure_10_page3.png
2025-11-09 21:59:34,177 - INFO - root - 论文《Quant-dLLM: Post-Training Extreme Low-Bit Quantization for Diffusion Large Language Models》的分析已保存到 ./export\Quant-dLLM_ Post-Training Extreme Low-Bit Quantization for Diffusion Large Langu.md
2025-11-09 21:59:34,188 - INFO - root - 正在总结论文 32/40: PT$^2$-LLM: Post-Training Ternarization for Large Language Models
2025-11-09 21:59:34,189 - INFO - root - LLMClient: rate limit reached, sleeping 6.3s
2025-11-09 21:59:51,794 - INFO - root - LLMClient: rate limit reached, sleeping 19.7s
2025-11-09 22:01:38,787 - INFO - root - 正在提取论文图片...
2025-11-09 22:01:39,482 - INFO - root - 已保存图片 1/10：./export\images_PT$^2$-LLM_ Post-Training Ternarization for Large Language Models\figure_1_page6.png
2025-11-09 22:01:39,686 - INFO - root - 已保存图片 2/10：./export\images_PT$^2$-LLM_ Post-Training Ternarization for Large Language Models\figure_2_page6.png
2025-11-09 22:01:39,766 - INFO - root - 已保存图片 3/10：./export\images_PT$^2$-LLM_ Post-Training Ternarization for Large Language Models\figure_3_page6.png
2025-11-09 22:01:39,844 - INFO - root - 已保存图片 4/10：./export\images_PT$^2$-LLM_ Post-Training Ternarization for Large Language Models\figure_4_page3.png
2025-11-09 22:01:39,918 - INFO - root - 已保存图片 5/10：./export\images_PT$^2$-LLM_ Post-Training Ternarization for Large Language Models\figure_5_page3.png
2025-11-09 22:01:39,966 - INFO - root - 已保存图片 6/10：./export\images_PT$^2$-LLM_ Post-Training Ternarization for Large Language Models\figure_6_page3.jpeg
2025-11-09 22:01:40,001 - INFO - root - 已保存图片 7/10：./export\images_PT$^2$-LLM_ Post-Training Ternarization for Large Language Models\figure_7_page6.jpeg
2025-11-09 22:01:40,048 - INFO - root - 已保存图片 8/10：./export\images_PT$^2$-LLM_ Post-Training Ternarization for Large Language Models\figure_8_page3.jpeg
2025-11-09 22:01:40,092 - INFO - root - 已保存图片 9/10：./export\images_PT$^2$-LLM_ Post-Training Ternarization for Large Language Models\figure_9_page6.jpeg
2025-11-09 22:01:40,171 - INFO - root - 已保存图片 10/10：./export\images_PT$^2$-LLM_ Post-Training Ternarization for Large Language Models\figure_10_page3.png
2025-11-09 22:01:40,177 - INFO - root - 成功添加图片 1：./export\images_PT$^2$-LLM_ Post-Training Ternarization for Large Language Models\figure_1_page6.png
2025-11-09 22:01:40,177 - INFO - root - 成功添加图片 2：./export\images_PT$^2$-LLM_ Post-Training Ternarization for Large Language Models\figure_2_page6.png
2025-11-09 22:01:40,179 - INFO - root - 成功添加图片 3：./export\images_PT$^2$-LLM_ Post-Training Ternarization for Large Language Models\figure_3_page6.png
2025-11-09 22:01:40,180 - INFO - root - 成功添加图片 4：./export\images_PT$^2$-LLM_ Post-Training Ternarization for Large Language Models\figure_4_page3.png
2025-11-09 22:01:40,181 - INFO - root - 成功添加图片 5：./export\images_PT$^2$-LLM_ Post-Training Ternarization for Large Language Models\figure_5_page3.png
2025-11-09 22:01:40,181 - INFO - root - 成功添加图片 6：./export\images_PT$^2$-LLM_ Post-Training Ternarization for Large Language Models\figure_6_page3.jpeg
2025-11-09 22:01:40,182 - INFO - root - 成功添加图片 7：./export\images_PT$^2$-LLM_ Post-Training Ternarization for Large Language Models\figure_7_page6.jpeg
2025-11-09 22:01:40,182 - INFO - root - 成功添加图片 8：./export\images_PT$^2$-LLM_ Post-Training Ternarization for Large Language Models\figure_8_page3.jpeg
2025-11-09 22:01:40,182 - INFO - root - 成功添加图片 9：./export\images_PT$^2$-LLM_ Post-Training Ternarization for Large Language Models\figure_9_page6.jpeg
2025-11-09 22:01:40,183 - INFO - root - 成功添加图片 10：./export\images_PT$^2$-LLM_ Post-Training Ternarization for Large Language Models\figure_10_page3.png
2025-11-09 22:01:40,198 - INFO - root - 论文《PT$^2$-LLM: Post-Training Ternarization for Large Language Models》的分析已保存到 ./export\PT$^2$-LLM_ Post-Training Ternarization for Large Language Models.md
2025-11-09 22:01:40,201 - INFO - root - 正在总结论文 33/40: Purrception: Variational Flow Matching for Vector-Quantized Image Generation
2025-11-09 22:01:50,870 - INFO - root - LLMClient: rate limit reached, sleeping 25.4s
2025-11-09 22:03:22,927 - INFO - root - 正在提取论文图片...
2025-11-09 22:03:23,208 - INFO - root - 已保存图片 1/10：./export\images_Purrception_ Variational Flow Matching for Vector-Quantized Image Generation\figure_1_page7.jpeg
2025-11-09 22:03:23,688 - INFO - root - 已保存图片 2/10：./export\images_Purrception_ Variational Flow Matching for Vector-Quantized Image Generation\figure_2_page5.jpeg
2025-11-09 22:03:23,809 - INFO - root - 已保存图片 3/10：./export\images_Purrception_ Variational Flow Matching for Vector-Quantized Image Generation\figure_3_page1.jpeg
2025-11-09 22:03:23,837 - INFO - root - 成功添加图片 1：./export\images_Purrception_ Variational Flow Matching for Vector-Quantized Image Generation\figure_1_page7.jpeg
2025-11-09 22:03:23,852 - INFO - root - 成功添加图片 2：./export\images_Purrception_ Variational Flow Matching for Vector-Quantized Image Generation\figure_2_page5.jpeg
2025-11-09 22:03:23,871 - INFO - root - 成功添加图片 3：./export\images_Purrception_ Variational Flow Matching for Vector-Quantized Image Generation\figure_3_page1.jpeg
2025-11-09 22:03:23,886 - INFO - root - 论文《Purrception: Variational Flow Matching for Vector-Quantized Image Generation》的分析已保存到 ./export\Purrception_ Variational Flow Matching for Vector-Quantized Image Generation.md
2025-11-09 22:03:23,897 - INFO - root - 正在总结论文 34/40: Post-Training Quantization for Audio Diffusion Transformers
2025-11-09 22:03:32,806 - INFO - root - LLMClient: rate limit reached, sleeping 24.2s
2025-11-09 22:04:49,380 - INFO - root - 正在提取论文图片...
2025-11-09 22:04:50,141 - INFO - root - 已保存图片 1/10：./export\images_Post-Training Quantization for Audio Diffusion Transformers\figure_1_page4.png
2025-11-09 22:04:50,271 - INFO - root - 已保存图片 2/10：./export\images_Post-Training Quantization for Audio Diffusion Transformers\figure_2_page3.png
2025-11-09 22:04:50,366 - INFO - root - 已保存图片 3/10：./export\images_Post-Training Quantization for Audio Diffusion Transformers\figure_3_page2.png
2025-11-09 22:04:50,411 - INFO - root - 已保存图片 4/10：./export\images_Post-Training Quantization for Audio Diffusion Transformers\figure_4_page2.png
2025-11-09 22:04:50,417 - INFO - root - 成功添加图片 1：./export\images_Post-Training Quantization for Audio Diffusion Transformers\figure_1_page4.png
2025-11-09 22:04:50,418 - INFO - root - 成功添加图片 2：./export\images_Post-Training Quantization for Audio Diffusion Transformers\figure_2_page3.png
2025-11-09 22:04:50,418 - INFO - root - 成功添加图片 3：./export\images_Post-Training Quantization for Audio Diffusion Transformers\figure_3_page2.png
2025-11-09 22:04:50,418 - INFO - root - 成功添加图片 4：./export\images_Post-Training Quantization for Audio Diffusion Transformers\figure_4_page2.png
2025-11-09 22:04:50,421 - INFO - root - 论文《Post-Training Quantization for Audio Diffusion Transformers》的分析已保存到 ./export\Post-Training Quantization for Audio Diffusion Transformers.md
2025-11-09 22:04:50,425 - INFO - root - 正在总结论文 35/40: Rethinking RoPE Scaling in Quantized LLM: Theory, Outlier, and Channel-Band Analysis with Weight Rescaling
2025-11-09 22:04:50,426 - INFO - root - LLMClient: rate limit reached, sleeping 6.5s
2025-11-09 22:05:09,479 - INFO - root - LLMClient: rate limit reached, sleeping 17.3s
2025-11-09 22:06:19,331 - INFO - root - 正在提取论文图片...
2025-11-09 22:06:19,862 - INFO - root - 已保存图片 1/10：./export\images_Rethinking RoPE Scaling in Quantized LLM_ Theory, Outlier, and Channel-Band Anal\figure_1_page20.png
2025-11-09 22:06:20,053 - INFO - root - 已保存图片 2/10：./export\images_Rethinking RoPE Scaling in Quantized LLM_ Theory, Outlier, and Channel-Band Anal\figure_2_page25.png
2025-11-09 22:06:20,066 - INFO - root - 已保存图片 3/10：./export\images_Rethinking RoPE Scaling in Quantized LLM_ Theory, Outlier, and Channel-Band Anal\figure_3_page25.png
2025-11-09 22:06:20,076 - INFO - root - 成功添加图片 1：./export\images_Rethinking RoPE Scaling in Quantized LLM_ Theory, Outlier, and Channel-Band Anal\figure_1_page20.png
2025-11-09 22:06:20,090 - INFO - root - 成功添加图片 2：./export\images_Rethinking RoPE Scaling in Quantized LLM_ Theory, Outlier, and Channel-Band Anal\figure_2_page25.png
2025-11-09 22:06:20,090 - INFO - root - 成功添加图片 3：./export\images_Rethinking RoPE Scaling in Quantized LLM_ Theory, Outlier, and Channel-Band Anal\figure_3_page25.png
2025-11-09 22:06:20,095 - INFO - root - 论文《Rethinking RoPE Scaling in Quantized LLM: Theory, Outlier, and Channel-Band Analysis with Weight Rescaling》的分析已保存到 ./export\Rethinking RoPE Scaling in Quantized LLM_ Theory, Outlier, and Channel-Band Anal.md
2025-11-09 22:06:20,106 - INFO - root - 正在总结论文 36/40: Post-Training Quantization via Residual Truncation and Zero Suppression for Diffusion Models
2025-11-09 22:06:20,106 - INFO - root - LLMClient: rate limit reached, sleeping 6.6s
2025-11-09 22:06:35,581 - INFO - root - LLMClient: rate limit reached, sleeping 22.4s
2025-11-09 22:07:48,240 - INFO - root - 正在提取论文图片...
2025-11-09 22:07:51,782 - INFO - root - 已保存图片 1/10：./export\images_Post-Training Quantization via Residual Truncation and Zero Suppression for Diff\figure_1_page3.png
2025-11-09 22:07:51,936 - INFO - root - 已保存图片 2/10：./export\images_Post-Training Quantization via Residual Truncation and Zero Suppression for Diff\figure_2_page9.png
2025-11-09 22:07:52,086 - INFO - root - 已保存图片 3/10：./export\images_Post-Training Quantization via Residual Truncation and Zero Suppression for Diff\figure_3_page19.png
2025-11-09 22:07:52,148 - INFO - root - 已保存图片 4/10：./export\images_Post-Training Quantization via Residual Truncation and Zero Suppression for Diff\figure_4_page9.png
2025-11-09 22:07:52,241 - INFO - root - 已保存图片 5/10：./export\images_Post-Training Quantization via Residual Truncation and Zero Suppression for Diff\figure_5_page1.png
2025-11-09 22:07:52,345 - INFO - root - 已保存图片 6/10：./export\images_Post-Training Quantization via Residual Truncation and Zero Suppression for Diff\figure_6_page7.png
2025-11-09 22:07:52,436 - INFO - root - 已保存图片 7/10：./export\images_Post-Training Quantization via Residual Truncation and Zero Suppression for Diff\figure_7_page7.png
2025-11-09 22:07:52,505 - INFO - root - 已保存图片 8/10：./export\images_Post-Training Quantization via Residual Truncation and Zero Suppression for Diff\figure_8_page5.png
2025-11-09 22:07:52,575 - INFO - root - 已保存图片 9/10：./export\images_Post-Training Quantization via Residual Truncation and Zero Suppression for Diff\figure_9_page14.png
2025-11-09 22:07:52,655 - INFO - root - 已保存图片 10/10：./export\images_Post-Training Quantization via Residual Truncation and Zero Suppression for Diff\figure_10_page14.png
2025-11-09 22:07:52,669 - INFO - root - 成功添加图片 1：./export\images_Post-Training Quantization via Residual Truncation and Zero Suppression for Diff\figure_1_page3.png
2025-11-09 22:07:52,669 - INFO - root - 成功添加图片 2：./export\images_Post-Training Quantization via Residual Truncation and Zero Suppression for Diff\figure_2_page9.png
2025-11-09 22:07:52,671 - INFO - root - 成功添加图片 3：./export\images_Post-Training Quantization via Residual Truncation and Zero Suppression for Diff\figure_3_page19.png
2025-11-09 22:07:52,672 - INFO - root - 成功添加图片 4：./export\images_Post-Training Quantization via Residual Truncation and Zero Suppression for Diff\figure_4_page9.png
2025-11-09 22:07:52,672 - INFO - root - 成功添加图片 5：./export\images_Post-Training Quantization via Residual Truncation and Zero Suppression for Diff\figure_5_page1.png
2025-11-09 22:07:52,673 - INFO - root - 成功添加图片 6：./export\images_Post-Training Quantization via Residual Truncation and Zero Suppression for Diff\figure_6_page7.png
2025-11-09 22:07:52,675 - INFO - root - 成功添加图片 7：./export\images_Post-Training Quantization via Residual Truncation and Zero Suppression for Diff\figure_7_page7.png
2025-11-09 22:07:52,677 - INFO - root - 成功添加图片 8：./export\images_Post-Training Quantization via Residual Truncation and Zero Suppression for Diff\figure_8_page5.png
2025-11-09 22:07:52,680 - INFO - root - 成功添加图片 9：./export\images_Post-Training Quantization via Residual Truncation and Zero Suppression for Diff\figure_9_page14.png
2025-11-09 22:07:52,681 - INFO - root - 成功添加图片 10：./export\images_Post-Training Quantization via Residual Truncation and Zero Suppression for Diff\figure_10_page14.png
2025-11-09 22:07:52,710 - INFO - root - 论文《Post-Training Quantization via Residual Truncation and Zero Suppression for Diffusion Models》的分析已保存到 ./export\Post-Training Quantization via Residual Truncation and Zero Suppression for Diff.md
2025-11-09 22:07:52,760 - INFO - root - 正在总结论文 37/40: Cat: Post-Training Quantization Error Reduction via Cluster-based Affine Transformation
2025-11-09 22:07:52,760 - INFO - root - LLMClient: rate limit reached, sleeping 5.2s
2025-11-09 22:08:09,192 - INFO - root - LLMClient: rate limit reached, sleeping 20.0s
2025-11-09 22:09:29,376 - INFO - root - 正在提取论文图片...
2025-11-09 22:09:29,405 - INFO - root - 论文《Cat: Post-Training Quantization Error Reduction via Cluster-based Affine Transformation》的分析已保存到 ./export\Cat_ Post-Training Quantization Error Reduction via Cluster-based Affine Transfo.md
2025-11-09 22:09:29,413 - INFO - root - 正在总结论文 38/40: CAST: Continuous and Differentiable Semi-Structured Sparsity-Aware Training for Large Language Models
2025-11-09 22:09:41,558 - INFO - root - LLMClient: rate limit reached, sleeping 22.0s
2025-11-09 22:10:54,556 - INFO - root - 正在提取论文图片...
2025-11-09 22:10:54,782 - INFO - root - 已保存图片 1/10：./export\images_CAST_ Continuous and Differentiable Semi-Structured Sparsity-Aware Training for\figure_1_page12.jpeg
2025-11-09 22:10:54,873 - INFO - root - 已保存图片 2/10：./export\images_CAST_ Continuous and Differentiable Semi-Structured Sparsity-Aware Training for\figure_2_page12.jpeg
2025-11-09 22:10:54,974 - INFO - root - 已保存图片 3/10：./export\images_CAST_ Continuous and Differentiable Semi-Structured Sparsity-Aware Training for\figure_3_page12.jpeg
2025-11-09 22:10:55,028 - INFO - root - 已保存图片 4/10：./export\images_CAST_ Continuous and Differentiable Semi-Structured Sparsity-Aware Training for\figure_4_page15.jpeg
2025-11-09 22:10:55,101 - INFO - root - 已保存图片 5/10：./export\images_CAST_ Continuous and Differentiable Semi-Structured Sparsity-Aware Training for\figure_5_page5.png
2025-11-09 22:10:55,148 - INFO - root - 已保存图片 6/10：./export\images_CAST_ Continuous and Differentiable Semi-Structured Sparsity-Aware Training for\figure_6_page15.jpeg
2025-11-09 22:10:55,252 - INFO - root - 已保存图片 7/10：./export\images_CAST_ Continuous and Differentiable Semi-Structured Sparsity-Aware Training for\figure_7_page15.jpeg
2025-11-09 22:10:55,279 - INFO - root - 已保存图片 8/10：./export\images_CAST_ Continuous and Differentiable Semi-Structured Sparsity-Aware Training for\figure_8_page8.jpeg
2025-11-09 22:10:55,342 - INFO - root - 已保存图片 9/10：./export\images_CAST_ Continuous and Differentiable Semi-Structured Sparsity-Aware Training for\figure_9_page15.jpeg
2025-11-09 22:10:55,360 - INFO - root - 已保存图片 10/10：./export\images_CAST_ Continuous and Differentiable Semi-Structured Sparsity-Aware Training for\figure_10_page4.jpeg
2025-11-09 22:10:55,367 - INFO - root - 成功添加图片 1：./export\images_CAST_ Continuous and Differentiable Semi-Structured Sparsity-Aware Training for\figure_1_page12.jpeg
2025-11-09 22:10:55,367 - INFO - root - 成功添加图片 2：./export\images_CAST_ Continuous and Differentiable Semi-Structured Sparsity-Aware Training for\figure_2_page12.jpeg
2025-11-09 22:10:55,367 - INFO - root - 成功添加图片 3：./export\images_CAST_ Continuous and Differentiable Semi-Structured Sparsity-Aware Training for\figure_3_page12.jpeg
2025-11-09 22:10:55,368 - INFO - root - 成功添加图片 4：./export\images_CAST_ Continuous and Differentiable Semi-Structured Sparsity-Aware Training for\figure_4_page15.jpeg
2025-11-09 22:10:55,368 - INFO - root - 成功添加图片 5：./export\images_CAST_ Continuous and Differentiable Semi-Structured Sparsity-Aware Training for\figure_5_page5.png
2025-11-09 22:10:55,369 - INFO - root - 成功添加图片 6：./export\images_CAST_ Continuous and Differentiable Semi-Structured Sparsity-Aware Training for\figure_6_page15.jpeg
2025-11-09 22:10:55,369 - INFO - root - 成功添加图片 7：./export\images_CAST_ Continuous and Differentiable Semi-Structured Sparsity-Aware Training for\figure_7_page15.jpeg
2025-11-09 22:10:55,369 - INFO - root - 成功添加图片 8：./export\images_CAST_ Continuous and Differentiable Semi-Structured Sparsity-Aware Training for\figure_8_page8.jpeg
2025-11-09 22:10:55,370 - INFO - root - 成功添加图片 9：./export\images_CAST_ Continuous and Differentiable Semi-Structured Sparsity-Aware Training for\figure_9_page15.jpeg
2025-11-09 22:10:55,370 - INFO - root - 成功添加图片 10：./export\images_CAST_ Continuous and Differentiable Semi-Structured Sparsity-Aware Training for\figure_10_page4.jpeg
2025-11-09 22:10:55,374 - INFO - root - 论文《CAST: Continuous and Differentiable Semi-Structured Sparsity-Aware Training for Large Language Models》的分析已保存到 ./export\CAST_ Continuous and Differentiable Semi-Structured Sparsity-Aware Training for.md
2025-11-09 22:10:55,382 - INFO - root - 正在总结论文 39/40: Norm-Q: Effective Compression Method for Hidden Markov Models in Neuro-Symbolic Applications
2025-11-09 22:10:55,383 - INFO - root - LLMClient: rate limit reached, sleeping 8.2s
2025-11-09 22:11:18,062 - INFO - root - LLMClient: rate limit reached, sleeping 15.2s
2025-11-09 22:12:03,132 - INFO - root - LLMClient: rate limit reached, sleeping 0.5s
2025-11-09 22:12:21,552 - INFO - root - 正在提取论文图片...
2025-11-09 22:12:21,575 - INFO - root - 已保存图片 1/10：./export\images_Norm-Q_ Effective Compression Method for Hidden Markov Models in Neuro-Symbolic\figure_1_page3.png
2025-11-09 22:12:21,582 - INFO - root - 成功添加图片 1：./export\images_Norm-Q_ Effective Compression Method for Hidden Markov Models in Neuro-Symbolic\figure_1_page3.png
2025-11-09 22:12:21,586 - INFO - root - 论文《Norm-Q: Effective Compression Method for Hidden Markov Models in Neuro-Symbolic Applications》的分析已保存到 ./export\Norm-Q_ Effective Compression Method for Hidden Markov Models in Neuro-Symbolic.md
2025-11-09 22:12:21,592 - INFO - root - 正在总结论文 40/40: On-the-Fly Adaptation to Quantization: Configuration-Aware LoRA for Efficient Fine-Tuning of Quantized LLMs
2025-11-09 22:12:21,595 - INFO - root - LLMClient: rate limit reached, sleeping 11.7s
2025-11-09 22:12:44,615 - INFO - root - LLMClient: rate limit reached, sleeping 19.0s
2025-11-09 22:14:00,619 - INFO - root - 正在提取论文图片...
2025-11-09 22:14:00,905 - INFO - root - 已保存图片 1/10：./export\images_On-the-Fly Adaptation to Quantization_ Configuration-Aware LoRA for Efficient Fi\figure_1_page4.jpeg
2025-11-09 22:14:00,944 - INFO - root - 已保存图片 2/10：./export\images_On-the-Fly Adaptation to Quantization_ Configuration-Aware LoRA for Efficient Fi\figure_2_page5.png
2025-11-09 22:14:01,007 - INFO - root - 已保存图片 3/10：./export\images_On-the-Fly Adaptation to Quantization_ Configuration-Aware LoRA for Efficient Fi\figure_3_page5.png
2025-11-09 22:14:01,015 - INFO - root - 已保存图片 4/10：./export\images_On-the-Fly Adaptation to Quantization_ Configuration-Aware LoRA for Efficient Fi\figure_4_page16.png
2025-11-09 22:14:01,025 - INFO - root - 已保存图片 5/10：./export\images_On-the-Fly Adaptation to Quantization_ Configuration-Aware LoRA for Efficient Fi\figure_5_page16.png
2025-11-09 22:14:01,038 - INFO - root - 已保存图片 6/10：./export\images_On-the-Fly Adaptation to Quantization_ Configuration-Aware LoRA for Efficient Fi\figure_6_page16.png
2025-11-09 22:14:01,048 - INFO - root - 已保存图片 7/10：./export\images_On-the-Fly Adaptation to Quantization_ Configuration-Aware LoRA for Efficient Fi\figure_7_page16.png
2025-11-09 22:14:01,061 - INFO - root - 已保存图片 8/10：./export\images_On-the-Fly Adaptation to Quantization_ Configuration-Aware LoRA for Efficient Fi\figure_8_page16.png
2025-11-09 22:14:01,072 - INFO - root - 已保存图片 9/10：./export\images_On-the-Fly Adaptation to Quantization_ Configuration-Aware LoRA for Efficient Fi\figure_9_page16.png
2025-11-09 22:14:01,084 - INFO - root - 已保存图片 10/10：./export\images_On-the-Fly Adaptation to Quantization_ Configuration-Aware LoRA for Efficient Fi\figure_10_page16.png
2025-11-09 22:14:01,085 - INFO - root - 成功添加图片 1：./export\images_On-the-Fly Adaptation to Quantization_ Configuration-Aware LoRA for Efficient Fi\figure_1_page4.jpeg
2025-11-09 22:14:01,085 - INFO - root - 成功添加图片 2：./export\images_On-the-Fly Adaptation to Quantization_ Configuration-Aware LoRA for Efficient Fi\figure_2_page5.png
2025-11-09 22:14:01,086 - INFO - root - 成功添加图片 3：./export\images_On-the-Fly Adaptation to Quantization_ Configuration-Aware LoRA for Efficient Fi\figure_3_page5.png
2025-11-09 22:14:01,087 - INFO - root - 成功添加图片 4：./export\images_On-the-Fly Adaptation to Quantization_ Configuration-Aware LoRA for Efficient Fi\figure_4_page16.png
2025-11-09 22:14:01,087 - INFO - root - 成功添加图片 5：./export\images_On-the-Fly Adaptation to Quantization_ Configuration-Aware LoRA for Efficient Fi\figure_5_page16.png
2025-11-09 22:14:01,089 - INFO - root - 成功添加图片 6：./export\images_On-the-Fly Adaptation to Quantization_ Configuration-Aware LoRA for Efficient Fi\figure_6_page16.png
2025-11-09 22:14:01,089 - INFO - root - 成功添加图片 7：./export\images_On-the-Fly Adaptation to Quantization_ Configuration-Aware LoRA for Efficient Fi\figure_7_page16.png
2025-11-09 22:14:01,090 - INFO - root - 成功添加图片 8：./export\images_On-the-Fly Adaptation to Quantization_ Configuration-Aware LoRA for Efficient Fi\figure_8_page16.png
2025-11-09 22:14:01,090 - INFO - root - 成功添加图片 9：./export\images_On-the-Fly Adaptation to Quantization_ Configuration-Aware LoRA for Efficient Fi\figure_9_page16.png
2025-11-09 22:14:01,090 - INFO - root - 成功添加图片 10：./export\images_On-the-Fly Adaptation to Quantization_ Configuration-Aware LoRA for Efficient Fi\figure_10_page16.png
2025-11-09 22:14:01,093 - INFO - root - 论文《On-the-Fly Adaptation to Quantization: Configuration-Aware LoRA for Efficient Fine-Tuning of Quantized LLMs》的分析已保存到 ./export\On-the-Fly Adaptation to Quantization_ Configuration-Aware LoRA for Efficient Fi.md
2025-11-09 22:14:01,099 - INFO - root - summary time: 2520.59 seconds
2025-11-09 22:23:34,726 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-09 22:23:34,728 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-09 22:23:34,729 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-09 22:23:35,988 - INFO - root - LLMClientManager: 指定使用客户端: DeepSeek
2025-11-09 22:23:35,990 - INFO - root - DeepSeekClient: API key found: 9f9e270e-b...
2025-11-09 22:23:35,990 - INFO - root - DeepSeekClient: 使用模式: 火山引擎
2025-11-09 22:23:35,991 - INFO - root - DeepSeekClient: 模型名称: deepseek-v3-1-terminus
2025-11-09 22:23:40,254 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 22:23:40,276 - INFO - root - DeepSeekClient: initialized successfully with model deepseek-v3-1-terminus
2025-11-09 22:23:40,278 - INFO - root - LLMClientManager: DeepSeek 客户端初始化成功
2025-11-09 22:23:40,278 - INFO - root - LLMClientManager: switched to DeepSeek client
2025-11-09 22:23:40,279 - INFO - root - 已手动切换到 LLM 客户端: DeepSeek
2025-11-09 22:23:40,279 - INFO - root - 使用 LLM 模型: deepseek-v3-1-terminus
2025-11-09 22:23:40,281 - INFO - root - 可用客户端: ['DeepSeek']
2025-11-09 22:23:40,281 - INFO - root - === 运行配置 ===
2025-11-09 22:23:40,281 - INFO - root - 处理模式: arxiv在线搜索
2025-11-09 22:23:40,282 - INFO - root - 关键词: QAT
2025-11-09 22:23:40,282 - INFO - root - 查询: Quantization-Aware-Training
2025-11-09 22:23:40,282 - INFO - root - 排序: None
2025-11-09 22:23:40,283 - INFO - root - 最近天数: 180
2025-11-09 22:23:40,283 - INFO - root - 最大处理数量: 80
2025-11-09 22:23:40,284 - INFO - root - 保存图片: 是
2025-11-09 22:23:40,284 - INFO - root - 输出语言: 中文
2025-11-09 22:23:40,284 - INFO - root - 强制重新处理: 否
2025-11-09 22:23:40,285 - INFO - root - ====================
2025-11-09 22:23:40,285 - INFO - root - 使用 arXiv 搜索模式（通过 chat_arxiv 模块获取）
2025-11-09 22:23:40,285 - INFO - root - Fetching page 1 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50
2025-11-09 22:23:47,708 - INFO - root - get_all_titles_from_web 
2025-11-09 22:23:47,708 - INFO - root - Page:0, Index:0, A Quantized VAE-MLP Botnet Detection Model: A Systematic Evaluation of Quantization-Aware Training and Post-Training Quantization Strategies, https://arxiv.org/pdf/2511.03201, 2025-11-05
2025-11-09 22:23:47,709 - INFO - root - Page:0, Index:1, FP8-Flow-MoE: A Casting-Free FP8 Recipe without Double Quantization Error, https://arxiv.org/pdf/2511.02302, 2025-11-04
2025-11-09 22:23:47,709 - INFO - root - Page:0, Index:2, Outlier-Aware Post-Training Quantization for Image Super-Resolution, https://arxiv.org/pdf/2511.00682, 2025-11-01
2025-11-09 22:23:47,709 - INFO - root - Page:0, Index:3, Evaluation of Wafer-Scale SOT-MRAM for Analog Crossbar Array Applications, https://arxiv.org/pdf/2510.25853, 2025-11-03
2025-11-09 22:23:47,710 - INFO - root - Page:0, Index:4, Improving the Straight-Through Estimator with Zeroth-Order Information, https://arxiv.org/pdf/2510.23926, 2025-10-27
2025-11-09 22:23:47,710 - INFO - root - Page:0, Index:5, Real-Time Semantic Segmentation on FPGA for Autonomous Vehicles Using LMIINet with the CGRA4ML Framework, https://arxiv.org/pdf/2510.22243, 2025-10-25
2025-11-09 22:23:47,710 - INFO - root - Page:0, Index:6, TernaryCLIP: Efficiently Compressing Vision-Language Models with Ternary Weights and Distilled Knowledge, https://arxiv.org/pdf/2510.21879, 2025-10-23
2025-11-09 22:23:47,710 - INFO - root - Page:0, Index:7, KARIPAP: Quantum-Inspired Tensor Network Compression of Large Language Models Using Infinite Projected Entangled Pair States and Tensor Renormalization Group, https://arxiv.org/pdf/2510.21844, 2025-10-22
2025-11-09 22:23:47,710 - INFO - root - Page:0, Index:8, A Convergence Analysis of Adaptive Optimizers under Floating-point Quantization, https://arxiv.org/pdf/2510.21314, 2025-10-24
2025-11-09 22:23:47,711 - INFO - root - Page:0, Index:9, Adaptive Distribution-aware Quantization for Mixed-Precision Neural Networks, https://arxiv.org/pdf/2510.19760, 2025-10-22
2025-11-09 22:23:47,711 - INFO - root - Page:0, Index:10, CAGE: Curvature-Aware Gradient Estimation For Accurate Quantization-Aware Training, https://arxiv.org/pdf/2510.18784, 2025-10-21
2025-11-09 22:23:47,711 - INFO - root - Page:0, Index:11, Mixed-Precision Quantization for Language Models: Techniques and Prospects, https://arxiv.org/pdf/2510.16805, 2025-10-19
2025-11-09 22:23:47,711 - INFO - root - Page:0, Index:12, SPLite Hand: Sparsity-Aware Lightweight 3D Hand Pose Estimation, https://arxiv.org/pdf/2510.16396, 2025-10-30
2025-11-09 22:23:47,712 - INFO - root - Page:0, Index:13, CTR-LoRA: Curvature-Aware and Trust-Region Guided Low-Rank Adaptation for Large Language Models, https://arxiv.org/pdf/2510.15962, 2025-10-11
2025-11-09 22:23:47,712 - INFO - root - Page:0, Index:14, SANR: Scene-Aware Neural Representation for Light Field Image Compression with Rate-Distortion Optimization, https://arxiv.org/pdf/2510.15775, 2025-10-17
2025-11-09 22:23:47,712 - INFO - root - Page:0, Index:15, SpikeFit: Towards Optimal Deployment of Spiking Networks on Neuromorphic Hardware, https://arxiv.org/pdf/2510.15542, 2025-10-31
2025-11-09 22:23:47,712 - INFO - root - Page:0, Index:16, GRank: Towards Target-Aware and Streamlined Industrial Retrieval with a Generate-Rank Framework, https://arxiv.org/pdf/2510.15299, 2025-10-17
2025-11-09 22:23:47,713 - INFO - root - Page:0, Index:17, SaLon3R: Structure-aware Long-term Generalizable 3D Reconstruction from Unposed Images, https://arxiv.org/pdf/2510.15072, 2025-10-16
2025-11-09 22:23:47,713 - INFO - root - Page:0, Index:18, FraQAT: Quantization Aware Training with Fractional bits, https://arxiv.org/pdf/2510.14823, 2025-10-16
2025-11-09 22:23:47,713 - INFO - root - Page:0, Index:19, Computing-In-Memory Aware Model Adaption For Edge Devices, https://arxiv.org/pdf/2510.14379, 2025-10-16
2025-11-09 22:23:47,714 - INFO - root - Page:0, Index:20, Invited Paper: BitMedViT: Ternary-Quantized Vision Transformer for Medical AI Assistants on the Edge, https://arxiv.org/pdf/2510.13760, 2025-11-04
2025-11-09 22:23:47,714 - INFO - root - Page:0, Index:21, NeuroRVQ: Multi-Scale EEG Tokenization for Generative Large Brainwave Models, https://arxiv.org/pdf/2510.13068, 2025-10-14
2025-11-09 22:23:47,714 - INFO - root - Page:0, Index:22, Detect Anything via Next Point Prediction, https://arxiv.org/pdf/2510.12798, 2025-10-14
2025-11-09 22:23:47,716 - INFO - root - Page:0, Index:23, AndesVL Technical Report: An Efficient Mobile-side Multimodal Large Language Model, https://arxiv.org/pdf/2510.11496, 2025-10-14
2025-11-09 22:23:47,716 - INFO - root - Page:0, Index:24, Rescaling-Aware Training for Efficient Deployment of Deep Learning Models on Full-Integer Hardware, https://arxiv.org/pdf/2510.11484, 2025-10-13
2025-11-09 22:23:47,716 - INFO - root - Page:0, Index:25, SASER: Stego attacks on open-source LLMs, https://arxiv.org/pdf/2510.10486, 2025-10-12
2025-11-09 22:23:47,716 - INFO - root - Page:0, Index:26, Ultralytics YOLO Evolution: An Overview of YOLO26, YOLO11, YOLOv8 and YOLOv5 Object Detectors for Computer Vision and Pattern Recognition, https://arxiv.org/pdf/2510.09653, 2025-10-15
2025-11-09 22:23:47,717 - INFO - root - Page:0, Index:27, A Theoretically-Grounded Codebook for Digital Semantic Communications, https://arxiv.org/pdf/2510.07108, 2025-10-14
2025-11-09 22:23:47,718 - INFO - root - Page:0, Index:28, QuantDemoire: Quantization with Outlier Aware for Image Demoiréing, https://arxiv.org/pdf/2510.04066, 2025-10-05
2025-11-09 22:23:47,718 - INFO - root - Page:0, Index:29, Adaptively Sampling-Reusing-Mixing Decomposed Gradients to Speed Up Sharpness Aware Minimization, https://arxiv.org/pdf/2510.03763, 2025-10-04
2025-11-09 22:23:47,719 - INFO - root - Page:0, Index:30, Quant-dLLM: Post-Training Extreme Low-Bit Quantization for Diffusion Large Language Models, https://arxiv.org/pdf/2510.03274, 2025-09-27
2025-11-09 22:23:47,719 - INFO - root - Page:0, Index:31, PT$^2$-LLM: Post-Training Ternarization for Large Language Models, https://arxiv.org/pdf/2510.03267, 2025-09-26
2025-11-09 22:23:47,720 - INFO - root - Page:0, Index:32, Purrception: Variational Flow Matching for Vector-Quantized Image Generation, https://arxiv.org/pdf/2510.01478, 2025-10-01
2025-11-09 22:23:47,720 - INFO - root - Page:0, Index:33, Post-Training Quantization for Audio Diffusion Transformers, https://arxiv.org/pdf/2510.00313, 2025-09-30
2025-11-09 22:23:47,720 - INFO - root - Page:0, Index:34, Rethinking RoPE Scaling in Quantized LLM: Theory, Outlier, and Channel-Band Analysis with Weight Rescaling, https://arxiv.org/pdf/2510.00028, 2025-09-25
2025-11-09 22:23:47,720 - INFO - root - Page:0, Index:35, Post-Training Quantization via Residual Truncation and Zero Suppression for Diffusion Models, https://arxiv.org/pdf/2509.26436, 2025-09-30
2025-11-09 22:23:47,721 - INFO - root - Page:0, Index:36, Cat: Post-Training Quantization Error Reduction via Cluster-based Affine Transformation, https://arxiv.org/pdf/2509.26277, 2025-10-07
2025-11-09 22:23:47,721 - INFO - root - Page:0, Index:37, CAST: Continuous and Differentiable Semi-Structured Sparsity-Aware Training for Large Language Models, https://arxiv.org/pdf/2509.25996, 2025-09-30
2025-11-09 22:23:47,722 - INFO - root - Page:0, Index:38, Norm-Q: Effective Compression Method for Hidden Markov Models in Neuro-Symbolic Applications, https://arxiv.org/pdf/2509.25439, 2025-09-29
2025-11-09 22:23:47,725 - INFO - root - Page:0, Index:39, On-the-Fly Adaptation to Quantization: Configuration-Aware LoRA for Efficient Fine-Tuning of Quantized LLMs, https://arxiv.org/pdf/2509.25214, 2025-09-22
2025-11-09 22:23:47,725 - INFO - root - Page:0, Index:40, VoxCPM: Tokenizer-Free TTS for Context-Aware Speech Generation and True-to-Life Voice Cloning, https://arxiv.org/pdf/2509.24650, 2025-09-29
2025-11-09 22:23:47,726 - INFO - root - Page:0, Index:41, S$^2$NN: Sub-bit Spiking Neural Networks, https://arxiv.org/pdf/2509.24266, 2025-10-24
2025-11-09 22:23:47,726 - INFO - root - Page:0, Index:42, Tequila: Trapping-free Ternary Quantization for Large Language Models, https://arxiv.org/pdf/2509.23809, 2025-10-17
2025-11-09 22:23:47,726 - INFO - root - Page:0, Index:43, Texture Vector-Quantization and Reconstruction Aware Prediction for Generative Super-Resolution, https://arxiv.org/pdf/2509.23774, 2025-09-30
2025-11-09 22:23:47,728 - INFO - root - Page:0, Index:44, RobuQ: Pushing DiTs to W1.58A2 via Robust Activation Quantization, https://arxiv.org/pdf/2509.23582, 2025-09-27
2025-11-09 22:23:47,728 - INFO - root - Page:0, Index:45, Beyond Outliers: A Study of Optimizers Under Quantization, https://arxiv.org/pdf/2509.23500, 2025-10-02
2025-11-09 22:23:47,728 - INFO - root - Page:0, Index:46, Compute-Optimal Quantization-Aware Training, https://arxiv.org/pdf/2509.22935, 2025-09-26
2025-11-09 22:23:47,728 - INFO - root - Page:0, Index:47, COSPADI: Compressing LLMs via Calibration-Guided Sparse Dictionary Learning, https://arxiv.org/pdf/2509.22075, 2025-10-06
2025-11-09 22:23:47,729 - INFO - root - Page:0, Index:48, SlimDiff: Training-Free, Activation-Guided Hands-free Slimming of Diffusion Models, https://arxiv.org/pdf/2509.21498, 2025-09-25
2025-11-09 22:23:47,729 - INFO - root - Page:0, Index:49, Quantized Visual Geometry Grounded Transformer, https://arxiv.org/pdf/2509.21302, 2025-09-29
2025-11-09 22:23:47,729 - INFO - root - Fetching page 2 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=50
2025-11-09 22:23:55,497 - INFO - root - get_all_titles_from_web 
2025-11-09 22:23:55,497 - INFO - root - Page:1, Index:0, Can Less Precise Be More Reliable? A Systematic Evaluation of Quantization's Impact on CLIP Beyond Accuracy, https://arxiv.org/pdf/2509.21173, 2025-10-27
2025-11-09 22:23:55,499 - INFO - root - Page:1, Index:1, Punching Above Precision: Small Quantized Model Distillation with Learnable Regularizer, https://arxiv.org/pdf/2509.20854, 2025-09-25
2025-11-09 22:23:55,499 - INFO - root - Page:1, Index:2, TinyEcoWeedNet: Edge Efficient Real-Time Aerial Agricultural Weed Detection, https://arxiv.org/pdf/2509.18193, 2025-09-19
2025-11-09 22:23:55,499 - INFO - root - Page:1, Index:3, SBVR: Summation of BitVector Representation for Efficient LLM Quantization, https://arxiv.org/pdf/2509.18172, 2025-09-17
2025-11-09 22:23:55,500 - INFO - root - Page:1, Index:4, QWHA: Quantization-Aware Walsh-Hadamard Adaptation for Parameter-Efficient Fine-Tuning on Large Language Models, https://arxiv.org/pdf/2509.17428, 2025-09-26
2025-11-09 22:23:55,500 - INFO - root - Page:1, Index:5, PTQTP: Post-Training Quantization to Trit-Planes for Large Language Models, https://arxiv.org/pdf/2509.16989, 2025-10-28
2025-11-09 22:23:55,500 - INFO - root - Page:1, Index:6, MEC-Quant: Maximum Entropy Coding for Extremely Low Bit Quantization-Aware Training, https://arxiv.org/pdf/2509.15514, 2025-09-18
2025-11-09 22:23:55,500 - INFO - root - Page:1, Index:7, Q-ROAR: Outlier-Aware Rescaling for RoPE Position Interpolation in Quantized Long-Context LLMs, https://arxiv.org/pdf/2509.14391, 2025-09-17
2025-11-09 22:23:55,501 - INFO - root - Page:1, Index:8, Efficient Quantization-Aware Neural Receivers: Beyond Post-Training Quantization, https://arxiv.org/pdf/2509.13786, 2025-09-19
2025-11-09 22:23:55,501 - INFO - root - Page:1, Index:9, Rate-Distortion Limits for Multimodal Retrieval: Theory, Optimal Codes, and Finite-Sample Guarantees, https://arxiv.org/pdf/2509.11054, 2025-09-13
2025-11-09 22:23:55,501 - INFO - root - Page:1, Index:10, SQAP-VLA: A Synergistic Quantization-Aware Pruning Framework for High-Performance Vision-Language-Action Models, https://arxiv.org/pdf/2509.09090, 2025-09-10
2025-11-09 22:23:55,501 - INFO - root - Page:1, Index:11, CSI Compression Beyond Latents: End-to-End Hybrid Attention-CNN Networks with Entropy Regularization, https://arxiv.org/pdf/2509.08776, 2025-09-10
2025-11-09 22:23:55,502 - INFO - root - Page:1, Index:12, Explaining How Quantization Disparately Skews a Model, https://arxiv.org/pdf/2509.07222, 2025-09-08
2025-11-09 22:23:55,502 - INFO - root - Page:1, Index:13, LoaQ: Layer-wise Output Approximation Quantization, https://arxiv.org/pdf/2509.06297, 2025-09-07
2025-11-09 22:23:55,502 - INFO - root - Page:1, Index:14, FineServe: Precision-Aware KV Slab and Two-Level Scheduling for Heterogeneous Precision LLM Serving, https://arxiv.org/pdf/2509.06261, 2025-09-14
2025-11-09 22:23:55,503 - INFO - root - Page:1, Index:15, Sensitivity-Aware Post-Training Quantization for Deep Neural Networks, https://arxiv.org/pdf/2509.05576, 2025-09-05
2025-11-09 22:23:55,503 - INFO - root - Page:1, Index:16, SuperSNN: A Hardware-Aware Framework for Physically Realizable, High-Performance Superconducting Spiking Neural Network Chips, https://arxiv.org/pdf/2509.05532, 2025-09-05
2025-11-09 22:23:55,504 - INFO - root - Page:1, Index:17, Data-Augmented Quantization-Aware Knowledge Distillation, https://arxiv.org/pdf/2509.03850, 2025-09-03
2025-11-09 22:23:55,504 - INFO - root - Page:1, Index:18, DPQuant: Efficient and Differentially-Private Model Training via Dynamic Quantization Scheduling, https://arxiv.org/pdf/2509.03472, 2025-09-03
2025-11-09 22:23:55,505 - INFO - root - Page:1, Index:19, Empowering Large Language Model for Sequential Recommendation via Multimodal Embeddings and Semantic IDs, https://arxiv.org/pdf/2509.02017, 2025-09-02
2025-11-09 22:23:55,505 - INFO - root - Page:1, Index:20, Q-Sched: Pushing the Boundaries of Few-Step Diffusion Models with Quantization-Aware Scheduling, https://arxiv.org/pdf/2509.01624, 2025-09-01
2025-11-09 22:23:55,506 - INFO - root - Page:1, Index:21, Quantization Meets OOD: Generalizable Quantization-aware Training from a Flatness Perspective, https://arxiv.org/pdf/2509.00859, 2025-08-31
2025-11-09 22:23:55,506 - INFO - root - Page:1, Index:22, Progressive Element-wise Gradient Estimation for Neural Network Quantization, https://arxiv.org/pdf/2509.00097, 2025-08-27
2025-11-09 22:23:55,507 - INFO - root - Page:1, Index:23, End-to-End On-Device Quantization-Aware Training for LLMs at Inference Cost, https://arxiv.org/pdf/2509.00031, 2025-09-29
2025-11-09 22:23:55,507 - INFO - root - Page:1, Index:24, Quantization Robustness to Input Degradations for Object Detection, https://arxiv.org/pdf/2508.19600, 2025-08-27
2025-11-09 22:23:55,515 - INFO - root - Page:1, Index:25, Scaling Laws for Task-Stratified Knowledge in Post-Training Quantized Large Language Models, https://arxiv.org/pdf/2508.18609, 2025-08-27
2025-11-09 22:23:55,519 - INFO - root - Page:1, Index:26, AQ-PCDSys: An Adaptive Quantized Planetary Crater Detection System for Autonomous Space Exploration, https://arxiv.org/pdf/2508.18025, 2025-08-25
2025-11-09 22:23:55,521 - INFO - root - Page:1, Index:27, TaDiCodec: Text-aware Diffusion Speech Tokenizer for Speech Language Modeling, https://arxiv.org/pdf/2508.16790, 2025-08-22
2025-11-09 22:23:55,521 - INFO - root - Page:1, Index:28, A Node-Aware Dynamic Quantization Approach for Graph Collaborative Filtering, https://arxiv.org/pdf/2508.16516, 2025-08-22
2025-11-09 22:23:55,522 - INFO - root - Page:1, Index:29, JEDI-linear: Fast and Efficient Graph Neural Networks for Jet Tagging on FPGAs, https://arxiv.org/pdf/2508.15468, 2025-08-21
2025-11-09 22:23:55,522 - INFO - root - Page:1, Index:30, MMQ: Multimodal Mixture-of-Quantization Tokenization for Semantic ID Generation and User Behavioral Adaptation, https://arxiv.org/pdf/2508.15281, 2025-08-21
2025-11-09 22:23:55,522 - INFO - root - Page:1, Index:31, DLLMQuant: Quantizing Diffusion-based Large Language Models, https://arxiv.org/pdf/2508.14090, 2025-08-25
2025-11-09 22:23:55,522 - INFO - root - Page:1, Index:32, Automated Energy-Aware Time-Series Model Deployment on Embedded FPGAs for Resilient Combined Sewer Overflow Management, https://arxiv.org/pdf/2508.13905, 2025-08-19
2025-11-09 22:23:55,524 - INFO - root - Page:1, Index:33, XR-NPE: High-Throughput Mixed-precision SIMD Neural Processing Engine for Extended Reality Perception Workloads, https://arxiv.org/pdf/2508.13049, 2025-08-18
2025-11-09 22:23:55,524 - INFO - root - Page:1, Index:34, Exploring Self-Supervised Audio Models for Generalized Anomalous Sound Detection, https://arxiv.org/pdf/2508.12230, 2025-08-17
2025-11-09 22:23:55,529 - INFO - root - Page:1, Index:35, TriQDef: Disrupting Semantic and Gradient Alignment to Prevent Adversarial Patch Transferability in Quantized Neural Networks, https://arxiv.org/pdf/2508.12132, 2025-08-16
2025-11-09 22:23:55,529 - INFO - root - Page:1, Index:36, Error Propagation Mechanisms and Compensation Strategies for Quantized Diffusion, https://arxiv.org/pdf/2508.12094, 2025-10-13
2025-11-09 22:23:55,529 - INFO - root - Page:1, Index:37, Extending Straight-Through Estimation for Robust Neural Networks on Analog CIM Hardware, https://arxiv.org/pdf/2508.11940, 2025-08-16
2025-11-09 22:23:55,530 - INFO - root - Page:1, Index:38, PTQAT: A Hybrid Parameter-Efficient Quantization Algorithm for 3D Perception Tasks, https://arxiv.org/pdf/2508.10557, 2025-08-15
2025-11-09 22:23:55,530 - INFO - root - Page:1, Index:39, MiCo: End-to-End Mixed Precision Neural Network Co-Exploration Framework for Edge AI, https://arxiv.org/pdf/2508.09500, 2025-08-13
2025-11-09 22:23:55,530 - INFO - root - Page:1, Index:40, SPARC: Soft Probabilistic Adaptive multi-interest Retrieval Model via Codebooks for recommender system, https://arxiv.org/pdf/2508.09090, 2025-08-12
2025-11-09 22:23:55,531 - INFO - root - Page:1, Index:41, Rethinking 1-bit Optimization Leveraging Pre-trained Large Language Models, https://arxiv.org/pdf/2508.06974, 2025-08-09
2025-11-09 22:23:55,532 - INFO - root - Page:1, Index:42, Efficient Deep Neural Receiver with Post-Training Quantization, https://arxiv.org/pdf/2508.06275, 2025-08-08
2025-11-09 22:23:55,533 - INFO - root - Page:1, Index:43, iFairy: the First 2-bit Complex LLM with All Parameters in $\{\pm1, \pm i\}$, https://arxiv.org/pdf/2508.05571, 2025-08-16
2025-11-09 22:23:55,533 - INFO - root - Page:1, Index:44, S$^2$Q-VDiT: Accurate Quantized Video Diffusion Transformer with Salient Data and Sparse Token Distillation, https://arxiv.org/pdf/2508.04016, 2025-10-27
2025-11-09 22:23:55,533 - INFO - root - Page:1, Index:45, LRQ-DiT: Log-Rotation Post-Training Quantization of Diffusion Transformers for Image and Video Generation, https://arxiv.org/pdf/2508.03485, 2025-09-23
2025-11-09 22:23:55,535 - INFO - root - Page:1, Index:46, VLMQ: Efficient Post-Training Quantization for Large Vision-Language Models via Hessian Augmentation, https://arxiv.org/pdf/2508.03351, 2025-08-05
2025-11-09 22:23:55,535 - INFO - root - Page:1, Index:47, TF-MLPNet: Tiny Real-Time Neural Speech Separation, https://arxiv.org/pdf/2508.03047, 2025-08-04
2025-11-09 22:23:55,535 - INFO - root - Page:1, Index:48, SaviorRec: Semantic-Behavior Alignment for Cold-Start Recommendation, https://arxiv.org/pdf/2508.01375, 2025-08-02
2025-11-09 22:23:55,536 - INFO - root - Page:1, Index:49, MixA-Q: Revisiting Activation Sparsity for Vision Transformers from a Mixed-Precision Quantization Perspective, https://arxiv.org/pdf/2507.19131, 2025-07-25
2025-11-09 22:23:55,536 - INFO - root - Fetching page 3 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=100
2025-11-09 22:24:04,061 - INFO - root - get_all_titles_from_web 
2025-11-09 22:24:04,061 - INFO - root - Page:2, Index:0, Enhancing Quantization-Aware Training on Edge Devices via Relative Entropy Coreset Selection and Cascaded Layer Correction, https://arxiv.org/pdf/2507.17768, 2025-07-16
2025-11-09 22:24:04,062 - INFO - root - Page:2, Index:1, SiLQ: Simple Large Language Model Quantization-Aware Training, https://arxiv.org/pdf/2507.16933, 2025-07-22
2025-11-09 22:24:04,062 - INFO - root - Page:2, Index:2, Task-Specific Zero-shot Quantization-Aware Training for Object Detection, https://arxiv.org/pdf/2507.16782, 2025-07-22
2025-11-09 22:24:04,062 - INFO - root - Page:2, Index:3, TorchAO: PyTorch-Native Training-to-Serving Model Optimization, https://arxiv.org/pdf/2507.16099, 2025-07-21
2025-11-09 22:24:04,063 - INFO - root - Page:2, Index:4, SegQuant: A Semantics-Aware and Generalizable Quantization Framework for Diffusion Models, https://arxiv.org/pdf/2507.14811, 2025-08-27
2025-11-09 22:24:04,063 - INFO - root - Page:2, Index:5, Apple Intelligence Foundation Language Models: Tech Report 2025, https://arxiv.org/pdf/2507.13575, 2025-08-27
2025-11-09 22:24:04,063 - INFO - root - Page:2, Index:6, Generative Multi-Target Cross-Domain Recommendation, https://arxiv.org/pdf/2507.12871, 2025-08-07
2025-11-09 22:24:04,063 - INFO - root - Page:2, Index:7, DAF: An Efficient End-to-End Dynamic Activation Framework for on-Device DNN Training, https://arxiv.org/pdf/2507.07149, 2025-07-09
2025-11-09 22:24:04,064 - INFO - root - Page:2, Index:8, Opto-ViT: Architecting a Near-Sensor Region of Interest-Aware Vision Transformer Accelerator with Silicon Photonics, https://arxiv.org/pdf/2507.07044, 2025-07-15
2025-11-09 22:24:04,064 - INFO - root - Page:2, Index:9, QS4D: Quantization-aware training for efficient hardware deployment of structured state-space sequential models, https://arxiv.org/pdf/2507.06079, 2025-07-08
2025-11-09 22:24:04,064 - INFO - root - Page:2, Index:10, GSVR: 2D Gaussian-based Video Representation for 800+ FPS with Hybrid Deformation Field, https://arxiv.org/pdf/2507.05594, 2025-07-07
2025-11-09 22:24:04,064 - INFO - root - Page:2, Index:11, Hita: Holistic Tokenizer for Autoregressive Image Generation, https://arxiv.org/pdf/2507.02358, 2025-07-11
2025-11-09 22:24:04,065 - INFO - root - Page:2, Index:12, QPART: Adaptive Model Quantization and Dynamic Workload Balancing for Accuracy-aware Edge Inference, https://arxiv.org/pdf/2506.23934, 2025-06-30
2025-11-09 22:24:04,065 - INFO - root - Page:2, Index:13, FedWSQ: Efficient Federated Learning with Weight Standardization and Distribution-Aware Non-Uniform Quantization, https://arxiv.org/pdf/2506.23516, 2025-07-21
2025-11-09 22:24:04,065 - INFO - root - Page:2, Index:14, Spectra 1.1: Scaling Laws and Efficient Inference for Ternary Language Models, https://arxiv.org/pdf/2506.23025, 2025-06-28
2025-11-09 22:24:04,066 - INFO - root - Page:2, Index:15, Joint Quantization and Pruning Neural Networks Approach: A Case Study on FSO Receivers, https://arxiv.org/pdf/2506.20084, 2025-06-24
2025-11-09 22:24:04,066 - INFO - root - Page:2, Index:16, Single-step Diffusion for Image Compression at Ultra-Low Bitrates, https://arxiv.org/pdf/2506.16572, 2025-09-22
2025-11-09 22:24:04,066 - INFO - root - Page:2, Index:17, LittleBit: Ultra Low-Bit Quantization via Latent Factorization, https://arxiv.org/pdf/2506.13771, 2025-10-28
2025-11-09 22:24:04,067 - INFO - root - Page:2, Index:18, MARCO: Hardware-Aware Neural Architecture Search for Edge Devices with Multi-Agent Reinforcement Learning and Conformal Prediction Filtering, https://arxiv.org/pdf/2506.13755, 2025-06-16
2025-11-09 22:24:04,068 - INFO - root - Page:2, Index:19, EAQuant: Enhancing Post-Training Quantization for MoE Models via Expert-Aware Optimization, https://arxiv.org/pdf/2506.13329, 2025-07-04
2025-11-09 22:24:04,068 - INFO - root - Page:2, Index:20, Towards Neural Audio Codec Source Parsing, https://arxiv.org/pdf/2506.12627, 2025-06-14
2025-11-09 22:24:04,069 - INFO - root - Page:2, Index:21, Quantizing Small-Scale State-Space Models for Edge AI, https://arxiv.org/pdf/2506.12480, 2025-06-14
2025-11-09 22:24:04,069 - INFO - root - Page:2, Index:22, EMLoC: Emulator-based Memory-efficient Fine-tuning with LoRA Correction, https://arxiv.org/pdf/2506.12015, 2025-06-13
2025-11-09 22:24:04,069 - INFO - root - Page:2, Index:23, Compression Aware Certified Training, https://arxiv.org/pdf/2506.11992, 2025-06-13
2025-11-09 22:24:04,070 - INFO - root - Page:2, Index:24, GPLQ: A General, Practical, and Lightning QAT Method for Vision Transformers, https://arxiv.org/pdf/2506.11784, 2025-06-13
2025-11-09 22:24:04,070 - INFO - root - Page:2, Index:25, TruncQuant: Truncation-Ready Quantization for DNNs with Flexible Weight Bit Precision, https://arxiv.org/pdf/2506.11431, 2025-06-12
2025-11-09 22:24:04,072 - INFO - root - Page:2, Index:26, EfficientQuant: An Efficient Post-Training Quantization for CNN-Transformer Hybrid Models on Edge Devices, https://arxiv.org/pdf/2506.11093, 2025-06-05
2025-11-09 22:24:04,073 - INFO - root - Page:2, Index:27, Starting Positions Matter: A Study on Better Weight Initialization for Neural Network Quantization, https://arxiv.org/pdf/2506.10463, 2025-06-12
2025-11-09 22:24:04,075 - INFO - root - Page:2, Index:28, AWP: Activation-Aware Weight Pruning and Quantization with Projected Gradient Descent, https://arxiv.org/pdf/2506.10205, 2025-06-11
2025-11-09 22:24:04,075 - INFO - root - Page:2, Index:29, Q-SAM2: Accurate Quantization for Segment Anything Model 2, https://arxiv.org/pdf/2506.09782, 2025-06-11
2025-11-09 22:24:04,076 - INFO - root - Page:2, Index:30, Unifying Block-wise PTQ and Distillation-based QAT for Progressive Quantization toward 2-bit Instruction-Tuned LLMs, https://arxiv.org/pdf/2506.09104, 2025-06-10
2025-11-09 22:24:04,076 - INFO - root - Page:2, Index:31, Implementing Keyword Spotting on the MCUX947 Microcontroller with Integrated NPU, https://arxiv.org/pdf/2506.08911, 2025-06-10
2025-11-09 22:24:04,077 - INFO - root - Page:2, Index:32, POLARON: Precision-aware On-device Learning and Adaptive Runtime-cONfigurable AI acceleration, https://arxiv.org/pdf/2506.08785, 2025-06-10
2025-11-09 22:24:04,077 - INFO - root - Page:2, Index:33, MoQAE: Mixed-Precision Quantization for Long-Context LLM Inference via Mixture of Quantization-Aware Experts, https://arxiv.org/pdf/2506.07533, 2025-06-09
2025-11-09 22:24:04,079 - INFO - root - Page:2, Index:34, BitVLA: 1-bit Vision-Language-Action Models for Robotics Manipulation, https://arxiv.org/pdf/2506.07530, 2025-06-09
2025-11-09 22:24:04,079 - INFO - root - Page:2, Index:35, RecGPT: A Foundation Model for Sequential Recommendation, https://arxiv.org/pdf/2506.06270, 2025-06-12
2025-11-09 22:24:04,079 - INFO - root - Page:2, Index:36, FPSAttention: Training-Aware FP8 and Sparsity Co-Design for Fast Video Diffusion, https://arxiv.org/pdf/2506.04648, 2025-06-05
2025-11-09 22:24:04,079 - INFO - root - Page:2, Index:37, BitTTS: Highly Compact Text-to-Speech Using 1.58-bit Quantization and Weight Indexing, https://arxiv.org/pdf/2506.03515, 2025-06-03
2025-11-09 22:24:04,080 - INFO - root - Page:2, Index:38, ShapeLLM-Omni: A Native Multimodal LLM for 3D Generation and Understanding, https://arxiv.org/pdf/2506.01853, 2025-06-02
2025-11-09 22:24:04,080 - INFO - root - Page:2, Index:39, Movable Antenna Enhanced Federated Fine-Tuning of Large Language Models via Hybrid Client Selection Optimization, https://arxiv.org/pdf/2506.00011, 2025-10-26
2025-11-09 22:24:04,080 - INFO - root - Page:2, Index:40, Running Conventional Automatic Speech Recognition on Memristor Hardware: A Simulated Approach, https://arxiv.org/pdf/2505.24721, 2025-05-30
2025-11-09 22:24:04,081 - INFO - root - Page:2, Index:41, GARLIC: GAussian Representation LearnIng for spaCe partitioning, https://arxiv.org/pdf/2505.24608, 2025-10-02
2025-11-09 22:24:04,081 - INFO - root - Page:2, Index:42, AutoChemSchematic AI: Agentic Physics-Aware Automation for Chemical Manufacturing Scale-Up, https://arxiv.org/pdf/2505.24584, 2025-08-18
2025-11-09 22:24:04,081 - INFO - root - Page:2, Index:43, Model-Preserving Adaptive Rounding, https://arxiv.org/pdf/2505.22988, 2025-09-25
2025-11-09 22:24:04,081 - INFO - root - Page:2, Index:44, Highly Efficient and Effective LLMs with Multi-Boolean Architectures, https://arxiv.org/pdf/2505.22811, 2025-10-03
2025-11-09 22:24:04,082 - INFO - root - Page:2, Index:45, Pioneering 4-Bit FP Quantization for Diffusion Models: Mixup-Sign Quantization and Timestep-Aware Fine-Tuning, https://arxiv.org/pdf/2505.21591, 2025-05-27
2025-11-09 22:24:04,082 - INFO - root - Page:2, Index:46, Frequency Composition for Compressed and Domain-Adaptive Neural Networks, https://arxiv.org/pdf/2505.20890, 2025-05-27
2025-11-09 22:24:04,082 - INFO - root - Page:2, Index:47, MoPFormer: Motion-Primitive Transformer for Wearable-Sensor Activity Recognition, https://arxiv.org/pdf/2505.20744, 2025-10-27
2025-11-09 22:24:04,083 - INFO - root - Page:2, Index:48, Optimizing edge AI models on HPC systems with the edge in the loop, https://arxiv.org/pdf/2505.19995, 2025-05-26
2025-11-09 22:24:04,085 - INFO - root - Fetching page 4 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=150
2025-11-09 22:24:11,565 - INFO - root - get_all_titles_from_web 
2025-11-09 22:24:11,565 - INFO - root - Page:3, Index:0, DPASyn: Mechanism-Aware Drug Synergy Prediction via Dual Attention and Precision-Aware Quantization, https://arxiv.org/pdf/2505.19144, 2025-09-20
2025-11-09 22:24:11,565 - INFO - root - Page:3, Index:1, Reducing Storage of Pretrained Neural Networks by Rate-Constrained Quantization and Entropy Coding, https://arxiv.org/pdf/2505.18758, 2025-05-24
2025-11-09 22:24:11,566 - INFO - root - Page:3, Index:2, Beyond Discreteness: Finite-Sample Analysis of Straight-Through Estimator for Quantization, https://arxiv.org/pdf/2505.18113, 2025-05-23
2025-11-09 22:24:11,566 - INFO - root - Page:3, Index:3, Automating Versatile Time-Series Analysis with Tiny Transformers on Embedded FPGAs, https://arxiv.org/pdf/2505.17662, 2025-09-19
2025-11-09 22:24:11,566 - INFO - root - Page:3, Index:4, FPQVAR: Floating Point Quantization for Visual Autoregressive Model with FPGA Hardware Co-design, https://arxiv.org/pdf/2505.16335, 2025-05-22
2025-11-09 22:24:11,567 - INFO - root - Page:3, Index:5, Saliency-Aware Quantized Imitation Learning for Efficient Robotic Control, https://arxiv.org/pdf/2505.15304, 2025-05-30
2025-11-09 22:24:11,567 - INFO - root - Page:3, Index:6, Scaling Law for Quantization-Aware Training, https://arxiv.org/pdf/2505.14302, 2025-05-20
2025-11-09 22:24:11,567 - INFO - root - Page:3, Index:7, Automatic mixed precision for optimizing gained time with constrained loss mean-squared-error based on model partition to sequential sub-graphs, https://arxiv.org/pdf/2505.13060, 2025-05-19
2025-11-09 22:24:11,568 - INFO - root - Page:3, Index:8, Deep Unfolding with Kernel-based Quantization in MIMO Detection, https://arxiv.org/pdf/2505.12736, 2025-05-19
2025-11-09 22:24:11,568 - INFO - root - Page:3, Index:9, FedHQ: Hybrid Runtime Quantization for Federated Learning, https://arxiv.org/pdf/2505.11982, 2025-05-17
2025-11-09 22:24:11,568 - INFO - root - Page:3, Index:10, QVGen: Pushing the Limit of Quantized Video Generative Models, https://arxiv.org/pdf/2505.11497, 2025-09-27
2025-11-09 22:24:11,568 - INFO - root - Page:3, Index:11, EA-3DGS: Efficient and Adaptive 3D Gaussians with Highly Enhanced Quality for outdoor scenes, https://arxiv.org/pdf/2505.10787, 2025-05-15
2025-11-09 22:24:11,569 - INFO - root - Page:3, Index:12, ITERA-LLM: Boosting Sub-8-Bit Large Language Model Inference via Iterative Tensor Decomposition, https://arxiv.org/pdf/2505.08981, 2025-05-13
2025-11-09 22:24:11,569 - INFO - root - Page:3, Index:13, PROM: Prioritize Reduction of Multiplications Over Lower Bit-Widths for Efficient CNNs, https://arxiv.org/pdf/2505.03254, 2025-08-06
2025-11-09 22:24:11,569 - INFO - root - Page:3, Index:14, ICQuant: Index Coding enables Low-bit LLM Quantization, https://arxiv.org/pdf/2505.00850, 2025-08-24
2025-11-09 22:24:11,570 - INFO - root - Page:3, Index:15, Enhancing Ultra-Low-Bit Quantization of Large Language Models Through Saliency-Aware Partial Retraining, https://arxiv.org/pdf/2504.13932, 2025-07-30
2025-11-09 22:24:11,570 - INFO - root - Page:3, Index:16, Achieving binary weight and activation for LLMs using Post-Training Quantization, https://arxiv.org/pdf/2504.05352, 2025-06-30
2025-11-09 22:24:11,572 - INFO - root - Page:3, Index:17, Wireless Hearables With Programmable Speech AI Accelerators, https://arxiv.org/pdf/2503.18698, 2025-10-21
2025-11-09 22:24:11,575 - INFO - root - Page:3, Index:18, GranQ: Efficient Channel-wise Quantization via Vectorized Pre-Scaling for Zero-Shot QAT, https://arxiv.org/pdf/2503.18339, 2025-10-15
2025-11-09 22:24:11,576 - INFO - root - Page:3, Index:19, CompMarkGS: Robust Watermarking for Compressed 3D Gaussian Splatting, https://arxiv.org/pdf/2503.12836, 2025-09-29
2025-11-09 22:24:11,577 - INFO - root - Page:3, Index:20, AHCPTQ: Accurate and Hardware-Compatible Post-Training Quantization for Segment Anything Model, https://arxiv.org/pdf/2503.03088, 2025-07-11
2025-11-09 22:24:11,578 - INFO - root - Page:3, Index:21, Teaching Metric Distance to Discrete Autoregressive Language Models, https://arxiv.org/pdf/2503.02379, 2025-10-07
2025-11-09 22:24:11,580 - INFO - root - Page:3, Index:22, Regularization-based Framework for Quantization-, Fault- and Variability-Aware Training, https://arxiv.org/pdf/2503.01297, 2025-07-12
2025-11-09 22:24:11,580 - INFO - root - Fetching page 5 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=200
2025-11-09 22:24:16,560 - INFO - root - get_all_titles_from_web 
2025-11-09 22:24:16,560 - INFO - root - Page:4, Index:0, Investigating the Impact of Quantization Methods on the Safety and Reliability of Large Language Models, https://arxiv.org/pdf/2502.15799, 2025-06-29
2025-11-09 22:24:16,561 - INFO - root - Page:4, Index:1, Rotate, Clip, and Partition: Towards W2A4KV4 Quantization by Integrating Rotation and Learnable Non-uniform Quantizer, https://arxiv.org/pdf/2502.15779, 2025-09-01
2025-11-09 22:24:16,561 - INFO - root - Page:4, Index:2, RoSTE: An Efficient Quantization-Aware Supervised Fine-Tuning Approach for Large Language Models, https://arxiv.org/pdf/2502.09003, 2025-06-05
2025-11-09 22:24:16,561 - INFO - root - Page:4, Index:3, Spatial Degradation-Aware and Temporal Consistent Diffusion Model for Compressed Video Super-Resolution, https://arxiv.org/pdf/2502.07381, 2025-06-27
2025-11-09 22:24:16,562 - INFO - root - Page:4, Index:4, QuEST: Stable Training of LLMs with 1-Bit Weights and Activations, https://arxiv.org/pdf/2502.05003, 2025-06-10
2025-11-09 22:24:16,562 - INFO - root - Page:4, Index:5, HALO: Hadamard-Assisted Lower-Precision Optimization for LLMs, https://arxiv.org/pdf/2501.02625, 2025-11-05
2025-11-09 22:24:16,563 - INFO - root - Page:4, Index:6, TAR3D: Creating High-Quality 3D Assets via Next-Part Prediction, https://arxiv.org/pdf/2412.16919, 2025-08-08
2025-11-09 22:24:16,563 - INFO - root - Page:4, Index:7, Training Multi-Layer Binary Neural Networks With Local Binary Error Signals, https://arxiv.org/pdf/2412.00119, 2025-08-05
2025-11-09 22:24:16,563 - INFO - root - Page:4, Index:8, Scaling Large-scale GNN Training to Thousands of Processors on CPU-based Supercomputers, https://arxiv.org/pdf/2411.16025, 2025-05-26
2025-11-09 22:24:16,563 - INFO - root - Page:4, Index:9, HAFLQ: Heterogeneous Adaptive Federated LoRA Fine-tuned LLM with Quantization, https://arxiv.org/pdf/2411.06581, 2025-05-16
2025-11-09 22:24:16,564 - INFO - root - Fetching page 6 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=250
2025-11-09 22:24:25,122 - INFO - root - get_all_titles_from_web 
2025-11-09 22:24:25,123 - INFO - root - Page:5, Index:0, Gradient-Free Training of Quantized Neural Networks, https://arxiv.org/pdf/2410.09734, 2025-09-29
2025-11-09 22:24:25,123 - INFO - root - Page:5, Index:1, QT-DoG: Quantization-aware Training for Domain Generalization, https://arxiv.org/pdf/2410.06020, 2025-06-26
2025-11-09 22:24:25,123 - INFO - root - Page:5, Index:2, Constraint Guided Model Quantization of Neural Networks, https://arxiv.org/pdf/2409.20138, 2025-09-12
2025-11-09 22:24:25,124 - INFO - root - Page:5, Index:3, Accumulator-Aware Post-Training Quantization for Large Language Models, https://arxiv.org/pdf/2409.17092, 2025-07-30
2025-11-09 22:24:25,124 - INFO - root - Page:5, Index:4, DilateQuant: Accurate and Efficient Diffusion Quantization via Weight Dilation, https://arxiv.org/pdf/2409.14307, 2025-07-09
2025-11-09 22:24:25,124 - INFO - root - Page:5, Index:5, Robust Training of Neural Networks at Arbitrary Precision and Sparsity, https://arxiv.org/pdf/2409.09245, 2025-09-23
2025-11-09 22:24:25,126 - INFO - root - Page:5, Index:6, VQ-CTAP: Cross-Modal Fine-Grained Sequence Representation Learning for Speech Processing, https://arxiv.org/pdf/2408.05758, 2025-05-27
2025-11-09 22:24:25,127 - INFO - root - Page:5, Index:7, DopQ-ViT: Towards Distribution-Friendly and Outlier-Aware Post-Training Quantization for Vision Transformers, https://arxiv.org/pdf/2408.03291, 2025-06-19
2025-11-09 22:24:25,128 - INFO - root - Page:5, Index:8, Temporal Feature Matters: A Framework for Diffusion Model Quantization, https://arxiv.org/pdf/2407.19547, 2025-07-11
2025-11-09 22:24:25,129 - INFO - root - Page:5, Index:9, EfficientQAT: Efficient Quantization-Aware Training for Large Language Models, https://arxiv.org/pdf/2407.11062, 2025-05-19
2025-11-09 22:24:25,130 - INFO - root - Page:5, Index:10, Integer-only Quantized Transformers for Embedded FPGA-based Time-series Forecasting in AIoT, https://arxiv.org/pdf/2407.11041, 2025-10-31
2025-11-09 22:24:25,132 - INFO - root - Fetching page 7 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=300
2025-11-09 22:24:31,567 - INFO - root - get_all_titles_from_web 
2025-11-09 22:24:31,567 - INFO - root - Page:6, Index:0, BoA: Attention-aware Post-training Quantization without Backpropagation, https://arxiv.org/pdf/2406.13474, 2025-06-06
2025-11-09 22:24:31,568 - INFO - root - Page:6, Index:1, A Rescaling-Invariant Lipschitz Bound Based on Path-Metrics for Modern ReLU Network Parameterizations, https://arxiv.org/pdf/2405.15006, 2025-06-13
2025-11-09 22:24:31,568 - INFO - root - Page:6, Index:2, Scheduling Weight Transitions for Quantization-Aware Training, https://arxiv.org/pdf/2404.19248, 2025-10-01
2025-11-09 22:24:31,569 - INFO - root - Page:6, Index:3, GPTVQ: The Blessing of Dimensionality for LLM Quantization, https://arxiv.org/pdf/2402.15319, 2025-06-03
2025-11-09 22:24:31,570 - INFO - root - Fetching page 8 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=350
2025-11-09 22:24:38,850 - INFO - root - get_all_titles_from_web 
2025-11-09 22:24:38,851 - INFO - root - Page:7, Index:0, Squat: Quant Small Language Models on the Edge, https://arxiv.org/pdf/2402.10787, 2025-07-01
2025-11-09 22:24:38,852 - INFO - root - Page:7, Index:1, L4Q: Parameter Efficient Quantization-Aware Fine-Tuning on Large Language Models, https://arxiv.org/pdf/2402.04902, 2025-07-21
2025-11-09 22:24:38,853 - INFO - root - Fetching page 9 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=400
2025-11-09 22:24:45,687 - INFO - root - ------------------------------------------------------------------------------------------------------------------------
2025-11-09 22:24:45,688 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\A Quantized VAE-MLP Botnet Detection Model_ A Systematic Evaluation of Quantizat.pdf
2025-11-09 22:24:45,691 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\FP8-Flow-MoE_ A Casting-Free FP8 Recipe without Double Quantization Error.pdf
2025-11-09 22:24:45,695 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\Outlier-Aware Post-Training Quantization for Image Super-Resolution.pdf
2025-11-09 22:24:45,696 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\Evaluation of Wafer-Scale SOT-MRAM for Analog Crossbar Array Applications.pdf
2025-11-09 22:24:45,698 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\Improving the Straight-Through Estimator with Zeroth-Order Information.pdf
2025-11-09 22:24:45,699 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\Real-Time Semantic Segmentation on FPGA for Autonomous Vehicles Using LMIINet wi.pdf
2025-11-09 22:24:45,702 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\TernaryCLIP_ Efficiently Compressing Vision-Language Models with Ternary Weights.pdf
2025-11-09 22:24:45,702 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\KARIPAP_ Quantum-Inspired Tensor Network Compression of Large Language Models Us.pdf
2025-11-09 22:24:45,704 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\A Convergence Analysis of Adaptive Optimizers under Floating-point Quantization.pdf
2025-11-09 22:24:45,705 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\Adaptive Distribution-aware Quantization for Mixed-Precision Neural Networks.pdf
2025-11-09 22:24:45,708 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\CAGE_ Curvature-Aware Gradient Estimation For Accurate Quantization-Aware Traini.pdf
2025-11-09 22:24:45,710 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\Mixed-Precision Quantization for Language Models_ Techniques and Prospects.pdf
2025-11-09 22:24:45,712 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\SPLite Hand_ Sparsity-Aware Lightweight 3D Hand Pose Estimation.pdf
2025-11-09 22:24:45,713 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\CTR-LoRA_ Curvature-Aware and Trust-Region Guided Low-Rank Adaptation for Large.pdf
2025-11-09 22:24:45,716 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\SANR_ Scene-Aware Neural Representation for Light Field Image Compression with R.pdf
2025-11-09 22:24:45,717 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\SpikeFit_ Towards Optimal Deployment of Spiking Networks on Neuromorphic Hardwar.pdf
2025-11-09 22:24:45,719 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\GRank_ Towards Target-Aware and Streamlined Industrial Retrieval with a Generate.pdf
2025-11-09 22:24:45,719 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\SaLon3R_ Structure-aware Long-term Generalizable 3D Reconstruction from Unposed.pdf
2025-11-09 22:24:45,723 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\FraQAT_ Quantization Aware Training with Fractional bits.pdf
2025-11-09 22:24:45,725 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\Computing-In-Memory Aware Model Adaption For Edge Devices.pdf
2025-11-09 22:24:45,732 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\Invited Paper_ BitMedViT_ Ternary-Quantized Vision Transformer for Medical AI As.pdf
2025-11-09 22:24:45,733 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\NeuroRVQ_ Multi-Scale EEG Tokenization for Generative Large Brainwave Models.pdf
2025-11-09 22:24:45,735 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\Detect Anything via Next Point Prediction.pdf
2025-11-09 22:24:45,735 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\AndesVL Technical Report_ An Efficient Mobile-side Multimodal Large Language Mod.pdf
2025-11-09 22:24:45,737 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\Rescaling-Aware Training for Efficient Deployment of Deep Learning Models on Ful.pdf
2025-11-09 22:24:45,738 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\SASER_ Stego attacks on open-source LLMs.pdf
2025-11-09 22:24:45,739 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\Ultralytics YOLO Evolution_ An Overview of YOLO26, YOLO11, YOLOv8 and YOLOv5 Obj.pdf
2025-11-09 22:24:45,740 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\A Theoretically-Grounded Codebook for Digital Semantic Communications.pdf
2025-11-09 22:24:45,744 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\QuantDemoire_ Quantization with Outlier Aware for Image Demoiréing.pdf
2025-11-09 22:24:45,748 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\Adaptively Sampling-Reusing-Mixing Decomposed Gradients to Speed Up Sharpness Aw.pdf
2025-11-09 22:24:45,749 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\Quant-dLLM_ Post-Training Extreme Low-Bit Quantization for Diffusion Large Langu.pdf
2025-11-09 22:24:45,752 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\PT$^2$-LLM_ Post-Training Ternarization for Large Language Models.pdf
2025-11-09 22:24:45,761 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\Purrception_ Variational Flow Matching for Vector-Quantized Image Generation.pdf
2025-11-09 22:24:45,766 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\Post-Training Quantization for Audio Diffusion Transformers.pdf
2025-11-09 22:24:45,767 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\Rethinking RoPE Scaling in Quantized LLM_ Theory, Outlier, and Channel-Band Anal.pdf
2025-11-09 22:24:45,781 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\Post-Training Quantization via Residual Truncation and Zero Suppression for Diff.pdf
2025-11-09 22:24:45,782 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\Cat_ Post-Training Quantization Error Reduction via Cluster-based Affine Transfo.pdf
2025-11-09 22:24:45,785 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\CAST_ Continuous and Differentiable Semi-Structured Sparsity-Aware Training for.pdf
2025-11-09 22:24:45,786 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\Norm-Q_ Effective Compression Method for Hidden Markov Models in Neuro-Symbolic.pdf
2025-11-09 22:24:45,787 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\On-the-Fly Adaptation to Quantization_ Configuration-Aware LoRA for Efficient Fi.pdf
2025-11-09 22:36:00,924 - INFO - root - 跳过已处理论文 A Quantized VAE-MLP Botnet Detection Model: A Systematic Evaluation of Quantization-Aware Training and Post-Training Quantization Strategies：d:\ChatPaper\academic Papers\Quantization-Aware-Training\A Quantized VAE-MLP Botnet Detection Model_ A Systematic Evaluation of Quantizat.pdf
2025-11-09 22:36:00,924 - INFO - root - 跳过已处理论文 FP8-Flow-MoE: A Casting-Free FP8 Recipe without Double Quantization Error：d:\ChatPaper\academic Papers\Quantization-Aware-Training\FP8-Flow-MoE_ A Casting-Free FP8 Recipe without Double Quantization Error.pdf
2025-11-09 22:36:00,924 - INFO - root - 跳过已处理论文 Outlier-Aware Post-Training Quantization for Image Super-Resolution：d:\ChatPaper\academic Papers\Quantization-Aware-Training\Outlier-Aware Post-Training Quantization for Image Super-Resolution.pdf
2025-11-09 22:36:00,925 - INFO - root - 跳过已处理论文 Evaluation of Wafer-Scale SOT-MRAM for Analog Crossbar Array Applications：d:\ChatPaper\academic Papers\Quantization-Aware-Training\Evaluation of Wafer-Scale SOT-MRAM for Analog Crossbar Array Applications.pdf
2025-11-09 22:36:00,926 - INFO - root - 跳过已处理论文 Improving the Straight-Through Estimator with Zeroth-Order Information：d:\ChatPaper\academic Papers\Quantization-Aware-Training\Improving the Straight-Through Estimator with Zeroth-Order Information.pdf
2025-11-09 22:36:00,926 - INFO - root - 跳过已处理论文 Real-Time Semantic Segmentation on FPGA for Autonomous Vehicles Using LMIINet with the CGRA4ML Framework：d:\ChatPaper\academic Papers\Quantization-Aware-Training\Real-Time Semantic Segmentation on FPGA for Autonomous Vehicles Using LMIINet wi.pdf
2025-11-09 22:36:00,927 - INFO - root - 跳过已处理论文 TernaryCLIP: Efficiently Compressing Vision-Language Models with Ternary Weights and Distilled Knowledge：d:\ChatPaper\academic Papers\Quantization-Aware-Training\TernaryCLIP_ Efficiently Compressing Vision-Language Models with Ternary Weights.pdf
2025-11-09 22:36:00,927 - INFO - root - 跳过已处理论文 KARIPAP: Quantum-Inspired Tensor Network Compression of Large Language Models Using Infinite Projected Entangled Pair States and Tensor Renormalization Group：d:\ChatPaper\academic Papers\Quantization-Aware-Training\KARIPAP_ Quantum-Inspired Tensor Network Compression of Large Language Models Us.pdf
2025-11-09 22:36:00,928 - INFO - root - 跳过已处理论文 A Convergence Analysis of Adaptive Optimizers under Floating-point Quantization：d:\ChatPaper\academic Papers\Quantization-Aware-Training\A Convergence Analysis of Adaptive Optimizers under Floating-point Quantization.pdf
2025-11-09 22:36:00,928 - INFO - root - 跳过已处理论文 Adaptive Distribution-aware Quantization for Mixed-Precision Neural Networks：d:\ChatPaper\academic Papers\Quantization-Aware-Training\Adaptive Distribution-aware Quantization for Mixed-Precision Neural Networks.pdf
2025-11-09 22:36:00,928 - INFO - root - 跳过已处理论文 CAGE: Curvature-Aware Gradient Estimation For Accurate Quantization-Aware Training：d:\ChatPaper\academic Papers\Quantization-Aware-Training\CAGE_ Curvature-Aware Gradient Estimation For Accurate Quantization-Aware Traini.pdf
2025-11-09 22:36:00,929 - INFO - root - 跳过已处理论文 Mixed-Precision Quantization for Language Models: Techniques and Prospects：d:\ChatPaper\academic Papers\Quantization-Aware-Training\Mixed-Precision Quantization for Language Models_ Techniques and Prospects.pdf
2025-11-09 22:36:00,929 - INFO - root - 跳过已处理论文 SPLite Hand: Sparsity-Aware Lightweight 3D Hand Pose Estimation：d:\ChatPaper\academic Papers\Quantization-Aware-Training\SPLite Hand_ Sparsity-Aware Lightweight 3D Hand Pose Estimation.pdf
2025-11-09 22:36:00,930 - INFO - root - 跳过已处理论文 CTR-LoRA: Curvature-Aware and Trust-Region Guided Low-Rank Adaptation for Large Language Models：d:\ChatPaper\academic Papers\Quantization-Aware-Training\CTR-LoRA_ Curvature-Aware and Trust-Region Guided Low-Rank Adaptation for Large.pdf
2025-11-09 22:36:00,930 - INFO - root - 跳过已处理论文 SANR: Scene-Aware Neural Representation for Light Field Image Compression with Rate-Distortion Optimization：d:\ChatPaper\academic Papers\Quantization-Aware-Training\SANR_ Scene-Aware Neural Representation for Light Field Image Compression with R.pdf
2025-11-09 22:36:00,931 - INFO - root - 跳过已处理论文 SpikeFit: Towards Optimal Deployment of Spiking Networks on Neuromorphic Hardware：d:\ChatPaper\academic Papers\Quantization-Aware-Training\SpikeFit_ Towards Optimal Deployment of Spiking Networks on Neuromorphic Hardwar.pdf
2025-11-09 22:36:00,932 - INFO - root - 跳过已处理论文 GRank: Towards Target-Aware and Streamlined Industrial Retrieval with a Generate-Rank Framework：d:\ChatPaper\academic Papers\Quantization-Aware-Training\GRank_ Towards Target-Aware and Streamlined Industrial Retrieval with a Generate.pdf
2025-11-09 22:36:00,933 - INFO - root - 跳过已处理论文 SaLon3R: Structure-aware Long-term Generalizable 3D Reconstruction from Unposed Images：d:\ChatPaper\academic Papers\Quantization-Aware-Training\SaLon3R_ Structure-aware Long-term Generalizable 3D Reconstruction from Unposed.pdf
2025-11-09 22:36:00,935 - INFO - root - 跳过已处理论文 FraQAT: Quantization Aware Training with Fractional bits：d:\ChatPaper\academic Papers\Quantization-Aware-Training\FraQAT_ Quantization Aware Training with Fractional bits.pdf
2025-11-09 22:36:00,937 - INFO - root - 跳过已处理论文 Computing-In-Memory Aware Model Adaption For Edge Devices：d:\ChatPaper\academic Papers\Quantization-Aware-Training\Computing-In-Memory Aware Model Adaption For Edge Devices.pdf
2025-11-09 22:36:00,940 - INFO - root - 跳过已处理论文 Invited Paper: BitMedViT: Ternary-Quantized Vision Transformer for Medical AI Assistants on the Edge：d:\ChatPaper\academic Papers\Quantization-Aware-Training\Invited Paper_ BitMedViT_ Ternary-Quantized Vision Transformer for Medical AI As.pdf
2025-11-09 22:36:00,942 - INFO - root - 跳过已处理论文 NeuroRVQ: Multi-Scale EEG Tokenization for Generative Large Brainwave Models：d:\ChatPaper\academic Papers\Quantization-Aware-Training\NeuroRVQ_ Multi-Scale EEG Tokenization for Generative Large Brainwave Models.pdf
2025-11-09 22:36:00,943 - INFO - root - 跳过已处理论文 Detect Anything via Next Point Prediction：d:\ChatPaper\academic Papers\Quantization-Aware-Training\Detect Anything via Next Point Prediction.pdf
2025-11-09 22:36:00,944 - INFO - root - 跳过已处理论文 AndesVL Technical Report: An Efficient Mobile-side Multimodal Large Language Model：d:\ChatPaper\academic Papers\Quantization-Aware-Training\AndesVL Technical Report_ An Efficient Mobile-side Multimodal Large Language Mod.pdf
2025-11-09 22:36:00,945 - INFO - root - 跳过已处理论文 Rescaling-Aware Training for Efficient Deployment of Deep Learning Models on Full-Integer Hardware：d:\ChatPaper\academic Papers\Quantization-Aware-Training\Rescaling-Aware Training for Efficient Deployment of Deep Learning Models on Ful.pdf
2025-11-09 22:36:00,958 - INFO - root - 跳过已处理论文 SASER: Stego attacks on open-source LLMs：d:\ChatPaper\academic Papers\Quantization-Aware-Training\SASER_ Stego attacks on open-source LLMs.pdf
2025-11-09 22:36:00,960 - INFO - root - 跳过已处理论文 Ultralytics YOLO Evolution: An Overview of YOLO26, YOLO11, YOLOv8 and YOLOv5 Object Detectors for Computer Vision and Pattern Recognition：d:\ChatPaper\academic Papers\Quantization-Aware-Training\Ultralytics YOLO Evolution_ An Overview of YOLO26, YOLO11, YOLOv8 and YOLOv5 Obj.pdf
2025-11-09 22:36:00,960 - INFO - root - 跳过已处理论文 A Theoretically-Grounded Codebook for Digital Semantic Communications：d:\ChatPaper\academic Papers\Quantization-Aware-Training\A Theoretically-Grounded Codebook for Digital Semantic Communications.pdf
2025-11-09 22:36:00,961 - INFO - root - 跳过已处理论文 QuantDemoire: Quantization with Outlier Aware for Image Demoiréing：d:\ChatPaper\academic Papers\Quantization-Aware-Training\QuantDemoire_ Quantization with Outlier Aware for Image Demoiréing.pdf
2025-11-09 22:36:00,962 - INFO - root - 跳过已处理论文 Adaptively Sampling-Reusing-Mixing Decomposed Gradients to Speed Up Sharpness Aware Minimization：d:\ChatPaper\academic Papers\Quantization-Aware-Training\Adaptively Sampling-Reusing-Mixing Decomposed Gradients to Speed Up Sharpness Aw.pdf
2025-11-09 22:36:00,962 - INFO - root - 跳过已处理论文 Quant-dLLM: Post-Training Extreme Low-Bit Quantization for Diffusion Large Language Models：d:\ChatPaper\academic Papers\Quantization-Aware-Training\Quant-dLLM_ Post-Training Extreme Low-Bit Quantization for Diffusion Large Langu.pdf
2025-11-09 22:36:00,963 - INFO - root - 跳过已处理论文 PT$^2$-LLM: Post-Training Ternarization for Large Language Models：d:\ChatPaper\academic Papers\Quantization-Aware-Training\PT$^2$-LLM_ Post-Training Ternarization for Large Language Models.pdf
2025-11-09 22:36:00,963 - INFO - root - 跳过已处理论文 Purrception: Variational Flow Matching for Vector-Quantized Image Generation：d:\ChatPaper\academic Papers\Quantization-Aware-Training\Purrception_ Variational Flow Matching for Vector-Quantized Image Generation.pdf
2025-11-09 22:36:00,964 - INFO - root - 跳过已处理论文 Post-Training Quantization for Audio Diffusion Transformers：d:\ChatPaper\academic Papers\Quantization-Aware-Training\Post-Training Quantization for Audio Diffusion Transformers.pdf
2025-11-09 22:36:00,964 - INFO - root - 跳过已处理论文 Rethinking RoPE Scaling in Quantized LLM: Theory, Outlier, and Channel-Band Analysis with Weight Rescaling：d:\ChatPaper\academic Papers\Quantization-Aware-Training\Rethinking RoPE Scaling in Quantized LLM_ Theory, Outlier, and Channel-Band Anal.pdf
2025-11-09 22:36:00,965 - INFO - root - 跳过已处理论文 Post-Training Quantization via Residual Truncation and Zero Suppression for Diffusion Models：d:\ChatPaper\academic Papers\Quantization-Aware-Training\Post-Training Quantization via Residual Truncation and Zero Suppression for Diff.pdf
2025-11-09 22:36:00,966 - INFO - root - 跳过已处理论文 Cat: Post-Training Quantization Error Reduction via Cluster-based Affine Transformation：d:\ChatPaper\academic Papers\Quantization-Aware-Training\Cat_ Post-Training Quantization Error Reduction via Cluster-based Affine Transfo.pdf
2025-11-09 22:36:00,969 - INFO - root - 跳过已处理论文 CAST: Continuous and Differentiable Semi-Structured Sparsity-Aware Training for Large Language Models：d:\ChatPaper\academic Papers\Quantization-Aware-Training\CAST_ Continuous and Differentiable Semi-Structured Sparsity-Aware Training for.pdf
2025-11-09 22:36:00,970 - INFO - root - 跳过已处理论文 Norm-Q: Effective Compression Method for Hidden Markov Models in Neuro-Symbolic Applications：d:\ChatPaper\academic Papers\Quantization-Aware-Training\Norm-Q_ Effective Compression Method for Hidden Markov Models in Neuro-Symbolic.pdf
2025-11-09 22:36:00,971 - INFO - root - 跳过已处理论文 On-the-Fly Adaptation to Quantization: Configuration-Aware LoRA for Efficient Fine-Tuning of Quantized LLMs：d:\ChatPaper\academic Papers\Quantization-Aware-Training\On-the-Fly Adaptation to Quantization_ Configuration-Aware LoRA for Efficient Fi.pdf
2025-11-09 22:36:00,972 - INFO - root - 正在总结论文 41/80: VoxCPM: Tokenizer-Free TTS for Context-Aware Speech Generation and True-to-Life Voice Cloning
2025-11-09 22:36:17,942 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 22:37:12,758 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 22:37:51,764 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 22:37:51,766 - INFO - root - 正在提取论文图片...
2025-11-09 22:37:54,337 - INFO - root - 已保存图片 1/10：./export\images_VoxCPM_ Tokenizer-Free TTS for Context-Aware Speech Generation and True-to-Life\figure_1_page14.png
2025-11-09 22:37:54,596 - INFO - root - 已保存图片 2/10：./export\images_VoxCPM_ Tokenizer-Free TTS for Context-Aware Speech Generation and True-to-Life\figure_2_page13.png
2025-11-09 22:37:54,710 - INFO - root - 已保存图片 3/10：./export\images_VoxCPM_ Tokenizer-Free TTS for Context-Aware Speech Generation and True-to-Life\figure_3_page5.png
2025-11-09 22:37:54,763 - INFO - root - 已保存图片 4/10：./export\images_VoxCPM_ Tokenizer-Free TTS for Context-Aware Speech Generation and True-to-Life\figure_4_page1.png
2025-11-09 22:37:54,811 - INFO - root - 已保存图片 5/10：./export\images_VoxCPM_ Tokenizer-Free TTS for Context-Aware Speech Generation and True-to-Life\figure_5_page2.png
2025-11-09 22:37:54,853 - INFO - root - 已保存图片 6/10：./export\images_VoxCPM_ Tokenizer-Free TTS for Context-Aware Speech Generation and True-to-Life\figure_6_page3.png
2025-11-09 22:37:54,907 - INFO - root - 已保存图片 7/10：./export\images_VoxCPM_ Tokenizer-Free TTS for Context-Aware Speech Generation and True-to-Life\figure_7_page4.png
2025-11-09 22:37:54,960 - INFO - root - 已保存图片 8/10：./export\images_VoxCPM_ Tokenizer-Free TTS for Context-Aware Speech Generation and True-to-Life\figure_8_page5.png
2025-11-09 22:37:55,000 - INFO - root - 已保存图片 9/10：./export\images_VoxCPM_ Tokenizer-Free TTS for Context-Aware Speech Generation and True-to-Life\figure_9_page6.png
2025-11-09 22:37:55,051 - INFO - root - 已保存图片 10/10：./export\images_VoxCPM_ Tokenizer-Free TTS for Context-Aware Speech Generation and True-to-Life\figure_10_page7.png
2025-11-09 22:37:55,063 - INFO - root - 成功添加图片 1：./export\images_VoxCPM_ Tokenizer-Free TTS for Context-Aware Speech Generation and True-to-Life\figure_1_page14.png
2025-11-09 22:37:55,068 - INFO - root - 成功添加图片 2：./export\images_VoxCPM_ Tokenizer-Free TTS for Context-Aware Speech Generation and True-to-Life\figure_2_page13.png
2025-11-09 22:37:55,069 - INFO - root - 成功添加图片 3：./export\images_VoxCPM_ Tokenizer-Free TTS for Context-Aware Speech Generation and True-to-Life\figure_3_page5.png
2025-11-09 22:37:55,071 - INFO - root - 成功添加图片 4：./export\images_VoxCPM_ Tokenizer-Free TTS for Context-Aware Speech Generation and True-to-Life\figure_4_page1.png
2025-11-09 22:37:55,071 - INFO - root - 成功添加图片 5：./export\images_VoxCPM_ Tokenizer-Free TTS for Context-Aware Speech Generation and True-to-Life\figure_5_page2.png
2025-11-09 22:37:55,073 - INFO - root - 成功添加图片 6：./export\images_VoxCPM_ Tokenizer-Free TTS for Context-Aware Speech Generation and True-to-Life\figure_6_page3.png
2025-11-09 22:37:55,073 - INFO - root - 成功添加图片 7：./export\images_VoxCPM_ Tokenizer-Free TTS for Context-Aware Speech Generation and True-to-Life\figure_7_page4.png
2025-11-09 22:37:55,074 - INFO - root - 成功添加图片 8：./export\images_VoxCPM_ Tokenizer-Free TTS for Context-Aware Speech Generation and True-to-Life\figure_8_page5.png
2025-11-09 22:37:55,074 - INFO - root - 成功添加图片 9：./export\images_VoxCPM_ Tokenizer-Free TTS for Context-Aware Speech Generation and True-to-Life\figure_9_page6.png
2025-11-09 22:37:55,076 - INFO - root - 成功添加图片 10：./export\images_VoxCPM_ Tokenizer-Free TTS for Context-Aware Speech Generation and True-to-Life\figure_10_page7.png
2025-11-09 22:37:55,078 - INFO - root - 论文《VoxCPM: Tokenizer-Free TTS for Context-Aware Speech Generation and True-to-Life Voice Cloning》的分析已保存到 ./export\VoxCPM_ Tokenizer-Free TTS for Context-Aware Speech Generation and True-to-Life.md
2025-11-09 22:37:55,087 - INFO - root - 正在总结论文 42/80: S$^2$NN: Sub-bit Spiking Neural Networks
2025-11-09 22:38:11,374 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 22:38:11,376 - INFO - root - LLMClient: rate limit reached, sleeping 1.4s
2025-11-09 22:39:02,879 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 22:39:41,228 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 22:39:41,231 - INFO - root - 正在提取论文图片...
2025-11-09 22:39:41,918 - INFO - root - 已保存图片 1/10：./export\images_S$^2$NN_ Sub-bit Spiking Neural Networks\figure_1_page5.jpeg
2025-11-09 22:39:42,131 - INFO - root - 已保存图片 2/10：./export\images_S$^2$NN_ Sub-bit Spiking Neural Networks\figure_2_page4.jpeg
2025-11-09 22:39:42,262 - INFO - root - 已保存图片 3/10：./export\images_S$^2$NN_ Sub-bit Spiking Neural Networks\figure_3_page4.jpeg
2025-11-09 22:39:42,370 - INFO - root - 已保存图片 4/10：./export\images_S$^2$NN_ Sub-bit Spiking Neural Networks\figure_4_page27.png
2025-11-09 22:39:42,409 - INFO - root - 已保存图片 5/10：./export\images_S$^2$NN_ Sub-bit Spiking Neural Networks\figure_5_page9.jpeg
2025-11-09 22:39:42,495 - INFO - root - 已保存图片 6/10：./export\images_S$^2$NN_ Sub-bit Spiking Neural Networks\figure_6_page9.jpeg
2025-11-09 22:39:42,554 - INFO - root - 已保存图片 7/10：./export\images_S$^2$NN_ Sub-bit Spiking Neural Networks\figure_7_page9.jpeg
2025-11-09 22:39:42,609 - INFO - root - 已保存图片 8/10：./export\images_S$^2$NN_ Sub-bit Spiking Neural Networks\figure_8_page9.jpeg
2025-11-09 22:39:42,651 - INFO - root - 已保存图片 9/10：./export\images_S$^2$NN_ Sub-bit Spiking Neural Networks\figure_9_page9.jpeg
2025-11-09 22:39:42,694 - INFO - root - 已保存图片 10/10：./export\images_S$^2$NN_ Sub-bit Spiking Neural Networks\figure_10_page9.jpeg
2025-11-09 22:39:42,714 - INFO - root - 成功添加图片 1：./export\images_S$^2$NN_ Sub-bit Spiking Neural Networks\figure_1_page5.jpeg
2025-11-09 22:39:42,715 - INFO - root - 成功添加图片 2：./export\images_S$^2$NN_ Sub-bit Spiking Neural Networks\figure_2_page4.jpeg
2025-11-09 22:39:42,715 - INFO - root - 成功添加图片 3：./export\images_S$^2$NN_ Sub-bit Spiking Neural Networks\figure_3_page4.jpeg
2025-11-09 22:39:42,715 - INFO - root - 成功添加图片 4：./export\images_S$^2$NN_ Sub-bit Spiking Neural Networks\figure_4_page27.png
2025-11-09 22:39:42,716 - INFO - root - 成功添加图片 5：./export\images_S$^2$NN_ Sub-bit Spiking Neural Networks\figure_5_page9.jpeg
2025-11-09 22:39:42,716 - INFO - root - 成功添加图片 6：./export\images_S$^2$NN_ Sub-bit Spiking Neural Networks\figure_6_page9.jpeg
2025-11-09 22:39:42,716 - INFO - root - 成功添加图片 7：./export\images_S$^2$NN_ Sub-bit Spiking Neural Networks\figure_7_page9.jpeg
2025-11-09 22:39:42,717 - INFO - root - 成功添加图片 8：./export\images_S$^2$NN_ Sub-bit Spiking Neural Networks\figure_8_page9.jpeg
2025-11-09 22:39:42,717 - INFO - root - 成功添加图片 9：./export\images_S$^2$NN_ Sub-bit Spiking Neural Networks\figure_9_page9.jpeg
2025-11-09 22:39:42,717 - INFO - root - 成功添加图片 10：./export\images_S$^2$NN_ Sub-bit Spiking Neural Networks\figure_10_page9.jpeg
2025-11-09 22:39:42,720 - INFO - root - 论文《S$^2$NN: Sub-bit Spiking Neural Networks》的分析已保存到 ./export\S$^2$NN_ Sub-bit Spiking Neural Networks.md
2025-11-09 22:39:42,728 - INFO - root - 正在总结论文 43/80: Tequila: Trapping-free Ternary Quantization for Large Language Models
2025-11-09 22:39:57,705 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 22:39:57,706 - INFO - root - LLMClient: rate limit reached, sleeping 5.2s
2025-11-09 22:41:00,219 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 22:41:50,493 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 22:41:50,495 - INFO - root - 正在提取论文图片...
2025-11-09 22:41:51,197 - INFO - root - 已保存图片 1/10：./export\images_Tequila_ Trapping-free Ternary Quantization for Large Language Models\figure_1_page16.png
2025-11-09 22:41:51,337 - INFO - root - 已保存图片 2/10：./export\images_Tequila_ Trapping-free Ternary Quantization for Large Language Models\figure_2_page16.png
2025-11-09 22:41:51,407 - INFO - root - 已保存图片 3/10：./export\images_Tequila_ Trapping-free Ternary Quantization for Large Language Models\figure_3_page2.png
2025-11-09 22:41:51,455 - INFO - root - 已保存图片 4/10：./export\images_Tequila_ Trapping-free Ternary Quantization for Large Language Models\figure_4_page2.png
2025-11-09 22:41:51,508 - INFO - root - 已保存图片 5/10：./export\images_Tequila_ Trapping-free Ternary Quantization for Large Language Models\figure_5_page2.png
2025-11-09 22:41:51,555 - INFO - root - 已保存图片 6/10：./export\images_Tequila_ Trapping-free Ternary Quantization for Large Language Models\figure_6_page2.png
2025-11-09 22:41:51,597 - INFO - root - 已保存图片 7/10：./export\images_Tequila_ Trapping-free Ternary Quantization for Large Language Models\figure_7_page16.png
2025-11-09 22:41:51,644 - INFO - root - 已保存图片 8/10：./export\images_Tequila_ Trapping-free Ternary Quantization for Large Language Models\figure_8_page16.png
2025-11-09 22:41:51,689 - INFO - root - 已保存图片 9/10：./export\images_Tequila_ Trapping-free Ternary Quantization for Large Language Models\figure_9_page16.png
2025-11-09 22:41:51,759 - INFO - root - 已保存图片 10/10：./export\images_Tequila_ Trapping-free Ternary Quantization for Large Language Models\figure_10_page16.png
2025-11-09 22:41:51,765 - INFO - root - 成功添加图片 1：./export\images_Tequila_ Trapping-free Ternary Quantization for Large Language Models\figure_1_page16.png
2025-11-09 22:41:51,769 - INFO - root - 成功添加图片 2：./export\images_Tequila_ Trapping-free Ternary Quantization for Large Language Models\figure_2_page16.png
2025-11-09 22:41:51,770 - INFO - root - 成功添加图片 3：./export\images_Tequila_ Trapping-free Ternary Quantization for Large Language Models\figure_3_page2.png
2025-11-09 22:41:51,772 - INFO - root - 成功添加图片 4：./export\images_Tequila_ Trapping-free Ternary Quantization for Large Language Models\figure_4_page2.png
2025-11-09 22:41:51,784 - INFO - root - 成功添加图片 5：./export\images_Tequila_ Trapping-free Ternary Quantization for Large Language Models\figure_5_page2.png
2025-11-09 22:41:51,791 - INFO - root - 成功添加图片 6：./export\images_Tequila_ Trapping-free Ternary Quantization for Large Language Models\figure_6_page2.png
2025-11-09 22:41:51,791 - INFO - root - 成功添加图片 7：./export\images_Tequila_ Trapping-free Ternary Quantization for Large Language Models\figure_7_page16.png
2025-11-09 22:41:51,792 - INFO - root - 成功添加图片 8：./export\images_Tequila_ Trapping-free Ternary Quantization for Large Language Models\figure_8_page16.png
2025-11-09 22:41:51,792 - INFO - root - 成功添加图片 9：./export\images_Tequila_ Trapping-free Ternary Quantization for Large Language Models\figure_9_page16.png
2025-11-09 22:41:51,793 - INFO - root - 成功添加图片 10：./export\images_Tequila_ Trapping-free Ternary Quantization for Large Language Models\figure_10_page16.png
2025-11-09 22:41:51,798 - INFO - root - 论文《Tequila: Trapping-free Ternary Quantization for Large Language Models》的分析已保存到 ./export\Tequila_ Trapping-free Ternary Quantization for Large Language Models.md
2025-11-09 22:41:51,807 - INFO - root - 正在总结论文 44/80: Texture Vector-Quantization and Reconstruction Aware Prediction for Generative Super-Resolution
2025-11-09 22:42:10,665 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 22:43:21,183 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 22:43:59,545 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 22:43:59,548 - INFO - root - 正在提取论文图片...
2025-11-09 22:44:00,334 - INFO - root - 已保存图片 1/10：./export\images_Texture Vector-Quantization and Reconstruction Aware Prediction for Generative S\figure_1_page8.png
2025-11-09 22:44:00,411 - INFO - root - 已保存图片 2/10：./export\images_Texture Vector-Quantization and Reconstruction Aware Prediction for Generative S\figure_2_page19.jpeg
2025-11-09 22:44:00,536 - INFO - root - 已保存图片 3/10：./export\images_Texture Vector-Quantization and Reconstruction Aware Prediction for Generative S\figure_3_page19.jpeg
2025-11-09 22:44:00,629 - INFO - root - 已保存图片 4/10：./export\images_Texture Vector-Quantization and Reconstruction Aware Prediction for Generative S\figure_4_page19.jpeg
2025-11-09 22:44:00,699 - INFO - root - 已保存图片 5/10：./export\images_Texture Vector-Quantization and Reconstruction Aware Prediction for Generative S\figure_5_page19.jpeg
2025-11-09 22:44:00,779 - INFO - root - 已保存图片 6/10：./export\images_Texture Vector-Quantization and Reconstruction Aware Prediction for Generative S\figure_6_page19.jpeg
2025-11-09 22:44:00,836 - INFO - root - 已保存图片 7/10：./export\images_Texture Vector-Quantization and Reconstruction Aware Prediction for Generative S\figure_7_page19.jpeg
2025-11-09 22:44:00,887 - INFO - root - 已保存图片 8/10：./export\images_Texture Vector-Quantization and Reconstruction Aware Prediction for Generative S\figure_8_page19.jpeg
2025-11-09 22:44:00,942 - INFO - root - 已保存图片 9/10：./export\images_Texture Vector-Quantization and Reconstruction Aware Prediction for Generative S\figure_9_page19.jpeg
2025-11-09 22:44:00,988 - INFO - root - 已保存图片 10/10：./export\images_Texture Vector-Quantization and Reconstruction Aware Prediction for Generative S\figure_10_page19.jpeg
2025-11-09 22:44:00,996 - INFO - root - 成功添加图片 1：./export\images_Texture Vector-Quantization and Reconstruction Aware Prediction for Generative S\figure_1_page8.png
2025-11-09 22:44:00,996 - INFO - root - 成功添加图片 2：./export\images_Texture Vector-Quantization and Reconstruction Aware Prediction for Generative S\figure_2_page19.jpeg
2025-11-09 22:44:00,997 - INFO - root - 成功添加图片 3：./export\images_Texture Vector-Quantization and Reconstruction Aware Prediction for Generative S\figure_3_page19.jpeg
2025-11-09 22:44:00,998 - INFO - root - 成功添加图片 4：./export\images_Texture Vector-Quantization and Reconstruction Aware Prediction for Generative S\figure_4_page19.jpeg
2025-11-09 22:44:00,999 - INFO - root - 成功添加图片 5：./export\images_Texture Vector-Quantization and Reconstruction Aware Prediction for Generative S\figure_5_page19.jpeg
2025-11-09 22:44:00,999 - INFO - root - 成功添加图片 6：./export\images_Texture Vector-Quantization and Reconstruction Aware Prediction for Generative S\figure_6_page19.jpeg
2025-11-09 22:44:01,000 - INFO - root - 成功添加图片 7：./export\images_Texture Vector-Quantization and Reconstruction Aware Prediction for Generative S\figure_7_page19.jpeg
2025-11-09 22:44:01,000 - INFO - root - 成功添加图片 8：./export\images_Texture Vector-Quantization and Reconstruction Aware Prediction for Generative S\figure_8_page19.jpeg
2025-11-09 22:44:01,000 - INFO - root - 成功添加图片 9：./export\images_Texture Vector-Quantization and Reconstruction Aware Prediction for Generative S\figure_9_page19.jpeg
2025-11-09 22:44:01,003 - INFO - root - 成功添加图片 10：./export\images_Texture Vector-Quantization and Reconstruction Aware Prediction for Generative S\figure_10_page19.jpeg
2025-11-09 22:44:01,011 - INFO - root - 论文《Texture Vector-Quantization and Reconstruction Aware Prediction for Generative Super-Resolution》的分析已保存到 ./export\Texture Vector-Quantization and Reconstruction Aware Prediction for Generative S.md
2025-11-09 22:44:01,020 - INFO - root - 正在总结论文 45/80: RobuQ: Pushing DiTs to W1.58A2 via Robust Activation Quantization
2025-11-09 22:44:16,421 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 22:44:16,422 - INFO - root - LLMClient: rate limit reached, sleeping 4.8s
2025-11-09 22:45:25,755 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 22:45:59,146 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 22:45:59,150 - INFO - root - 正在提取论文图片...
2025-11-09 22:46:00,130 - INFO - root - 已保存图片 1/10：./export\images_RobuQ_ Pushing DiTs to W1.58A2 via Robust Activation Quantization\figure_1_page6.jpeg
2025-11-09 22:46:00,477 - INFO - root - 已保存图片 2/10：./export\images_RobuQ_ Pushing DiTs to W1.58A2 via Robust Activation Quantization\figure_2_page1.png
2025-11-09 22:46:00,573 - INFO - root - 已保存图片 3/10：./export\images_RobuQ_ Pushing DiTs to W1.58A2 via Robust Activation Quantization\figure_3_page21.png
2025-11-09 22:46:00,635 - INFO - root - 已保存图片 4/10：./export\images_RobuQ_ Pushing DiTs to W1.58A2 via Robust Activation Quantization\figure_4_page6.jpeg
2025-11-09 22:46:00,664 - INFO - root - 已保存图片 5/10：./export\images_RobuQ_ Pushing DiTs to W1.58A2 via Robust Activation Quantization\figure_5_page22.jpeg
2025-11-09 22:46:00,695 - INFO - root - 已保存图片 6/10：./export\images_RobuQ_ Pushing DiTs to W1.58A2 via Robust Activation Quantization\figure_6_page22.jpeg
2025-11-09 22:46:00,728 - INFO - root - 已保存图片 7/10：./export\images_RobuQ_ Pushing DiTs to W1.58A2 via Robust Activation Quantization\figure_7_page22.jpeg
2025-11-09 22:46:00,774 - INFO - root - 已保存图片 8/10：./export\images_RobuQ_ Pushing DiTs to W1.58A2 via Robust Activation Quantization\figure_8_page22.jpeg
2025-11-09 22:46:00,813 - INFO - root - 已保存图片 9/10：./export\images_RobuQ_ Pushing DiTs to W1.58A2 via Robust Activation Quantization\figure_9_page22.jpeg
2025-11-09 22:46:00,844 - INFO - root - 已保存图片 10/10：./export\images_RobuQ_ Pushing DiTs to W1.58A2 via Robust Activation Quantization\figure_10_page22.jpeg
2025-11-09 22:46:00,853 - INFO - root - 成功添加图片 1：./export\images_RobuQ_ Pushing DiTs to W1.58A2 via Robust Activation Quantization\figure_1_page6.jpeg
2025-11-09 22:46:00,855 - INFO - root - 成功添加图片 2：./export\images_RobuQ_ Pushing DiTs to W1.58A2 via Robust Activation Quantization\figure_2_page1.png
2025-11-09 22:46:00,855 - INFO - root - 成功添加图片 3：./export\images_RobuQ_ Pushing DiTs to W1.58A2 via Robust Activation Quantization\figure_3_page21.png
2025-11-09 22:46:00,856 - INFO - root - 成功添加图片 4：./export\images_RobuQ_ Pushing DiTs to W1.58A2 via Robust Activation Quantization\figure_4_page6.jpeg
2025-11-09 22:46:00,857 - INFO - root - 成功添加图片 5：./export\images_RobuQ_ Pushing DiTs to W1.58A2 via Robust Activation Quantization\figure_5_page22.jpeg
2025-11-09 22:46:00,858 - INFO - root - 成功添加图片 6：./export\images_RobuQ_ Pushing DiTs to W1.58A2 via Robust Activation Quantization\figure_6_page22.jpeg
2025-11-09 22:46:00,860 - INFO - root - 成功添加图片 7：./export\images_RobuQ_ Pushing DiTs to W1.58A2 via Robust Activation Quantization\figure_7_page22.jpeg
2025-11-09 22:46:00,861 - INFO - root - 成功添加图片 8：./export\images_RobuQ_ Pushing DiTs to W1.58A2 via Robust Activation Quantization\figure_8_page22.jpeg
2025-11-09 22:46:00,861 - INFO - root - 成功添加图片 9：./export\images_RobuQ_ Pushing DiTs to W1.58A2 via Robust Activation Quantization\figure_9_page22.jpeg
2025-11-09 22:46:00,862 - INFO - root - 成功添加图片 10：./export\images_RobuQ_ Pushing DiTs to W1.58A2 via Robust Activation Quantization\figure_10_page22.jpeg
2025-11-09 22:46:00,871 - INFO - root - 论文《RobuQ: Pushing DiTs to W1.58A2 via Robust Activation Quantization》的分析已保存到 ./export\RobuQ_ Pushing DiTs to W1.58A2 via Robust Activation Quantization.md
2025-11-09 22:46:00,878 - INFO - root - 正在总结论文 46/80: Beyond Outliers: A Study of Optimizers Under Quantization
2025-11-09 22:46:21,143 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 22:46:21,145 - INFO - root - LLMClient: rate limit reached, sleeping 4.6s
2025-11-09 22:47:20,920 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 22:48:11,469 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 22:48:11,472 - INFO - root - 正在提取论文图片...
2025-11-09 22:48:11,486 - INFO - root - 论文《Beyond Outliers: A Study of Optimizers Under Quantization》的分析已保存到 ./export\Beyond Outliers_ A Study of Optimizers Under Quantization.md
2025-11-09 22:48:11,522 - INFO - root - 正在总结论文 47/80: Compute-Optimal Quantization-Aware Training
2025-11-09 22:48:25,774 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 22:49:30,487 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 22:50:19,078 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 22:50:19,080 - INFO - root - 正在提取论文图片...
2025-11-09 22:50:19,530 - INFO - root - 已保存图片 1/10：./export\images_Compute-Optimal Quantization-Aware Training\figure_1_page2.png
2025-11-09 22:50:19,603 - INFO - root - 已保存图片 2/10：./export\images_Compute-Optimal Quantization-Aware Training\figure_2_page8.png
2025-11-09 22:50:19,658 - INFO - root - 已保存图片 3/10：./export\images_Compute-Optimal Quantization-Aware Training\figure_3_page22.png
2025-11-09 22:50:19,769 - INFO - root - 已保存图片 4/10：./export\images_Compute-Optimal Quantization-Aware Training\figure_4_page18.png
2025-11-09 22:50:19,865 - INFO - root - 已保存图片 5/10：./export\images_Compute-Optimal Quantization-Aware Training\figure_5_page19.png
2025-11-09 22:50:20,001 - INFO - root - 已保存图片 6/10：./export\images_Compute-Optimal Quantization-Aware Training\figure_6_page20.png
2025-11-09 22:50:20,108 - INFO - root - 已保存图片 7/10：./export\images_Compute-Optimal Quantization-Aware Training\figure_7_page18.png
2025-11-09 22:50:20,207 - INFO - root - 已保存图片 8/10：./export\images_Compute-Optimal Quantization-Aware Training\figure_8_page19.png
2025-11-09 22:50:20,288 - INFO - root - 已保存图片 9/10：./export\images_Compute-Optimal Quantization-Aware Training\figure_9_page19.png
2025-11-09 22:50:20,388 - INFO - root - 已保存图片 10/10：./export\images_Compute-Optimal Quantization-Aware Training\figure_10_page19.png
2025-11-09 22:50:20,390 - INFO - root - 成功添加图片 1：./export\images_Compute-Optimal Quantization-Aware Training\figure_1_page2.png
2025-11-09 22:50:20,390 - INFO - root - 成功添加图片 2：./export\images_Compute-Optimal Quantization-Aware Training\figure_2_page8.png
2025-11-09 22:50:20,391 - INFO - root - 成功添加图片 3：./export\images_Compute-Optimal Quantization-Aware Training\figure_3_page22.png
2025-11-09 22:50:20,391 - INFO - root - 成功添加图片 4：./export\images_Compute-Optimal Quantization-Aware Training\figure_4_page18.png
2025-11-09 22:50:20,391 - INFO - root - 成功添加图片 5：./export\images_Compute-Optimal Quantization-Aware Training\figure_5_page19.png
2025-11-09 22:50:20,391 - INFO - root - 成功添加图片 6：./export\images_Compute-Optimal Quantization-Aware Training\figure_6_page20.png
2025-11-09 22:50:20,393 - INFO - root - 成功添加图片 7：./export\images_Compute-Optimal Quantization-Aware Training\figure_7_page18.png
2025-11-09 22:50:20,393 - INFO - root - 成功添加图片 8：./export\images_Compute-Optimal Quantization-Aware Training\figure_8_page19.png
2025-11-09 22:50:20,395 - INFO - root - 成功添加图片 9：./export\images_Compute-Optimal Quantization-Aware Training\figure_9_page19.png
2025-11-09 22:50:20,397 - INFO - root - 成功添加图片 10：./export\images_Compute-Optimal Quantization-Aware Training\figure_10_page19.png
2025-11-09 22:50:20,403 - INFO - root - 论文《Compute-Optimal Quantization-Aware Training》的分析已保存到 ./export\Compute-Optimal Quantization-Aware Training.md
2025-11-09 22:50:20,411 - INFO - root - 正在总结论文 48/80: COSPADI: Compressing LLMs via Calibration-Guided Sparse Dictionary Learning
2025-11-09 22:50:34,369 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 22:51:26,359 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 22:51:55,270 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 22:51:55,277 - INFO - root - 正在提取论文图片...
2025-11-09 22:51:57,819 - INFO - root - 已保存图片 1/10：./export\images_COSPADI_ Compressing LLMs via Calibration-Guided Sparse Dictionary Learning\figure_1_page21.png
2025-11-09 22:51:58,075 - INFO - root - 已保存图片 2/10：./export\images_COSPADI_ Compressing LLMs via Calibration-Guided Sparse Dictionary Learning\figure_2_page20.png
2025-11-09 22:51:58,636 - INFO - root - 已保存图片 3/10：./export\images_COSPADI_ Compressing LLMs via Calibration-Guided Sparse Dictionary Learning\figure_3_page20.png
2025-11-09 22:51:58,782 - INFO - root - 已保存图片 4/10：./export\images_COSPADI_ Compressing LLMs via Calibration-Guided Sparse Dictionary Learning\figure_4_page7.png
2025-11-09 22:51:58,835 - INFO - root - 成功添加图片 1：./export\images_COSPADI_ Compressing LLMs via Calibration-Guided Sparse Dictionary Learning\figure_1_page21.png
2025-11-09 22:51:58,836 - INFO - root - 成功添加图片 2：./export\images_COSPADI_ Compressing LLMs via Calibration-Guided Sparse Dictionary Learning\figure_2_page20.png
2025-11-09 22:51:58,836 - INFO - root - 成功添加图片 3：./export\images_COSPADI_ Compressing LLMs via Calibration-Guided Sparse Dictionary Learning\figure_3_page20.png
2025-11-09 22:51:58,837 - INFO - root - 成功添加图片 4：./export\images_COSPADI_ Compressing LLMs via Calibration-Guided Sparse Dictionary Learning\figure_4_page7.png
2025-11-09 22:51:58,844 - INFO - root - 论文《COSPADI: Compressing LLMs via Calibration-Guided Sparse Dictionary Learning》的分析已保存到 ./export\COSPADI_ Compressing LLMs via Calibration-Guided Sparse Dictionary Learning.md
2025-11-09 22:51:58,855 - INFO - root - 正在总结论文 49/80: SlimDiff: Training-Free, Activation-Guided Hands-free Slimming of Diffusion Models
2025-11-09 22:52:10,026 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 22:52:10,044 - INFO - root - LLMClient: rate limit reached, sleeping 16.3s
2025-11-09 22:53:19,618 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 22:53:52,770 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 22:53:52,773 - INFO - root - 正在提取论文图片...
2025-11-09 22:53:56,941 - INFO - root - 已保存图片 1/10：./export\images_SlimDiff_ Training-Free, Activation-Guided Hands-free Slimming of Diffusion Mode\figure_1_page18.png
2025-11-09 22:53:57,083 - INFO - root - 已保存图片 2/10：./export\images_SlimDiff_ Training-Free, Activation-Guided Hands-free Slimming of Diffusion Mode\figure_2_page3.png
2025-11-09 22:53:57,319 - INFO - root - 已保存图片 3/10：./export\images_SlimDiff_ Training-Free, Activation-Guided Hands-free Slimming of Diffusion Mode\figure_3_page19.png
2025-11-09 22:53:57,602 - INFO - root - 已保存图片 4/10：./export\images_SlimDiff_ Training-Free, Activation-Guided Hands-free Slimming of Diffusion Mode\figure_4_page19.png
2025-11-09 22:53:57,863 - INFO - root - 已保存图片 5/10：./export\images_SlimDiff_ Training-Free, Activation-Guided Hands-free Slimming of Diffusion Mode\figure_5_page7.png
2025-11-09 22:53:57,979 - INFO - root - 已保存图片 6/10：./export\images_SlimDiff_ Training-Free, Activation-Guided Hands-free Slimming of Diffusion Mode\figure_6_page18.png
2025-11-09 22:53:58,083 - INFO - root - 已保存图片 7/10：./export\images_SlimDiff_ Training-Free, Activation-Guided Hands-free Slimming of Diffusion Mode\figure_7_page9.png
2025-11-09 22:53:58,100 - INFO - root - 已保存图片 8/10：./export\images_SlimDiff_ Training-Free, Activation-Guided Hands-free Slimming of Diffusion Mode\figure_8_page18.png
2025-11-09 22:53:58,119 - INFO - root - 成功添加图片 1：./export\images_SlimDiff_ Training-Free, Activation-Guided Hands-free Slimming of Diffusion Mode\figure_1_page18.png
2025-11-09 22:53:58,120 - INFO - root - 成功添加图片 2：./export\images_SlimDiff_ Training-Free, Activation-Guided Hands-free Slimming of Diffusion Mode\figure_2_page3.png
2025-11-09 22:53:58,120 - INFO - root - 成功添加图片 3：./export\images_SlimDiff_ Training-Free, Activation-Guided Hands-free Slimming of Diffusion Mode\figure_3_page19.png
2025-11-09 22:53:58,121 - INFO - root - 成功添加图片 4：./export\images_SlimDiff_ Training-Free, Activation-Guided Hands-free Slimming of Diffusion Mode\figure_4_page19.png
2025-11-09 22:53:58,121 - INFO - root - 成功添加图片 5：./export\images_SlimDiff_ Training-Free, Activation-Guided Hands-free Slimming of Diffusion Mode\figure_5_page7.png
2025-11-09 22:53:58,122 - INFO - root - 成功添加图片 6：./export\images_SlimDiff_ Training-Free, Activation-Guided Hands-free Slimming of Diffusion Mode\figure_6_page18.png
2025-11-09 22:53:58,126 - INFO - root - 成功添加图片 7：./export\images_SlimDiff_ Training-Free, Activation-Guided Hands-free Slimming of Diffusion Mode\figure_7_page9.png
2025-11-09 22:53:58,126 - INFO - root - 成功添加图片 8：./export\images_SlimDiff_ Training-Free, Activation-Guided Hands-free Slimming of Diffusion Mode\figure_8_page18.png
2025-11-09 22:53:58,136 - INFO - root - 论文《SlimDiff: Training-Free, Activation-Guided Hands-free Slimming of Diffusion Models》的分析已保存到 ./export\SlimDiff_ Training-Free, Activation-Guided Hands-free Slimming of Diffusion Mode.md
2025-11-09 22:53:58,149 - INFO - root - 正在总结论文 50/80: Quantized Visual Geometry Grounded Transformer
2025-11-09 22:54:13,686 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 22:54:13,687 - INFO - root - LLMClient: rate limit reached, sleeping 5.9s
2025-11-09 22:55:07,951 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 22:55:35,665 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 22:55:35,667 - INFO - root - 正在提取论文图片...
2025-11-09 22:55:36,015 - INFO - root - 已保存图片 1/10：./export\images_Quantized Visual Geometry Grounded Transformer\figure_1_page6.jpeg
2025-11-09 22:55:36,256 - INFO - root - 已保存图片 2/10：./export\images_Quantized Visual Geometry Grounded Transformer\figure_2_page5.jpeg
2025-11-09 22:55:36,512 - INFO - root - 已保存图片 3/10：./export\images_Quantized Visual Geometry Grounded Transformer\figure_3_page15.jpeg
2025-11-09 22:55:36,721 - INFO - root - 已保存图片 4/10：./export\images_Quantized Visual Geometry Grounded Transformer\figure_4_page15.jpeg
2025-11-09 22:55:37,000 - INFO - root - 已保存图片 5/10：./export\images_Quantized Visual Geometry Grounded Transformer\figure_5_page15.jpeg
2025-11-09 22:55:37,230 - INFO - root - 已保存图片 6/10：./export\images_Quantized Visual Geometry Grounded Transformer\figure_6_page15.jpeg
2025-11-09 22:55:37,433 - INFO - root - 已保存图片 7/10：./export\images_Quantized Visual Geometry Grounded Transformer\figure_7_page5.jpeg
2025-11-09 22:55:37,612 - INFO - root - 已保存图片 8/10：./export\images_Quantized Visual Geometry Grounded Transformer\figure_8_page5.jpeg
2025-11-09 22:55:37,812 - INFO - root - 已保存图片 9/10：./export\images_Quantized Visual Geometry Grounded Transformer\figure_9_page5.jpeg
2025-11-09 22:55:38,046 - INFO - root - 已保存图片 10/10：./export\images_Quantized Visual Geometry Grounded Transformer\figure_10_page15.jpeg
2025-11-09 22:55:38,082 - INFO - root - 成功添加图片 1：./export\images_Quantized Visual Geometry Grounded Transformer\figure_1_page6.jpeg
2025-11-09 22:55:38,083 - INFO - root - 成功添加图片 2：./export\images_Quantized Visual Geometry Grounded Transformer\figure_2_page5.jpeg
2025-11-09 22:55:38,083 - INFO - root - 成功添加图片 3：./export\images_Quantized Visual Geometry Grounded Transformer\figure_3_page15.jpeg
2025-11-09 22:55:38,084 - INFO - root - 成功添加图片 4：./export\images_Quantized Visual Geometry Grounded Transformer\figure_4_page15.jpeg
2025-11-09 22:55:38,084 - INFO - root - 成功添加图片 5：./export\images_Quantized Visual Geometry Grounded Transformer\figure_5_page15.jpeg
2025-11-09 22:55:38,085 - INFO - root - 成功添加图片 6：./export\images_Quantized Visual Geometry Grounded Transformer\figure_6_page15.jpeg
2025-11-09 22:55:38,085 - INFO - root - 成功添加图片 7：./export\images_Quantized Visual Geometry Grounded Transformer\figure_7_page5.jpeg
2025-11-09 22:55:38,086 - INFO - root - 成功添加图片 8：./export\images_Quantized Visual Geometry Grounded Transformer\figure_8_page5.jpeg
2025-11-09 22:55:38,086 - INFO - root - 成功添加图片 9：./export\images_Quantized Visual Geometry Grounded Transformer\figure_9_page5.jpeg
2025-11-09 22:55:38,086 - INFO - root - 成功添加图片 10：./export\images_Quantized Visual Geometry Grounded Transformer\figure_10_page15.jpeg
2025-11-09 22:55:38,096 - INFO - root - 论文《Quantized Visual Geometry Grounded Transformer》的分析已保存到 ./export\Quantized Visual Geometry Grounded Transformer.md
2025-11-09 22:55:38,101 - INFO - root - 正在总结论文 51/80: Can Less Precise Be More Reliable? A Systematic Evaluation of Quantization's Impact on CLIP Beyond Accuracy
2025-11-09 22:55:51,391 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 22:55:51,393 - INFO - root - LLMClient: rate limit reached, sleeping 16.6s
2025-11-09 22:56:53,942 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 22:57:24,647 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 22:57:24,649 - INFO - root - 正在提取论文图片...
2025-11-09 22:57:25,473 - INFO - root - 已保存图片 1/10：./export\images_Can Less Precise Be More Reliable_ A Systematic Evaluation of Quantization's Imp\figure_1_page1.png
2025-11-09 22:57:25,607 - INFO - root - 已保存图片 2/10：./export\images_Can Less Precise Be More Reliable_ A Systematic Evaluation of Quantization's Imp\figure_2_page18.png
2025-11-09 22:57:25,651 - INFO - root - 已保存图片 3/10：./export\images_Can Less Precise Be More Reliable_ A Systematic Evaluation of Quantization's Imp\figure_3_page7.png
2025-11-09 22:57:25,704 - INFO - root - 已保存图片 4/10：./export\images_Can Less Precise Be More Reliable_ A Systematic Evaluation of Quantization's Imp\figure_4_page7.png
2025-11-09 22:57:25,750 - INFO - root - 已保存图片 5/10：./export\images_Can Less Precise Be More Reliable_ A Systematic Evaluation of Quantization's Imp\figure_5_page7.png
2025-11-09 22:57:25,826 - INFO - root - 已保存图片 6/10：./export\images_Can Less Precise Be More Reliable_ A Systematic Evaluation of Quantization's Imp\figure_6_page7.png
2025-11-09 22:57:25,897 - INFO - root - 已保存图片 7/10：./export\images_Can Less Precise Be More Reliable_ A Systematic Evaluation of Quantization's Imp\figure_7_page7.png
2025-11-09 22:57:25,964 - INFO - root - 已保存图片 8/10：./export\images_Can Less Precise Be More Reliable_ A Systematic Evaluation of Quantization's Imp\figure_8_page12.png
2025-11-09 22:57:26,023 - INFO - root - 已保存图片 9/10：./export\images_Can Less Precise Be More Reliable_ A Systematic Evaluation of Quantization's Imp\figure_9_page12.png
2025-11-09 22:57:26,100 - INFO - root - 已保存图片 10/10：./export\images_Can Less Precise Be More Reliable_ A Systematic Evaluation of Quantization's Imp\figure_10_page12.png
2025-11-09 22:57:26,104 - INFO - root - 成功添加图片 1：./export\images_Can Less Precise Be More Reliable_ A Systematic Evaluation of Quantization's Imp\figure_1_page1.png
2025-11-09 22:57:26,105 - INFO - root - 成功添加图片 2：./export\images_Can Less Precise Be More Reliable_ A Systematic Evaluation of Quantization's Imp\figure_2_page18.png
2025-11-09 22:57:26,105 - INFO - root - 成功添加图片 3：./export\images_Can Less Precise Be More Reliable_ A Systematic Evaluation of Quantization's Imp\figure_3_page7.png
2025-11-09 22:57:26,106 - INFO - root - 成功添加图片 4：./export\images_Can Less Precise Be More Reliable_ A Systematic Evaluation of Quantization's Imp\figure_4_page7.png
2025-11-09 22:57:26,107 - INFO - root - 成功添加图片 5：./export\images_Can Less Precise Be More Reliable_ A Systematic Evaluation of Quantization's Imp\figure_5_page7.png
2025-11-09 22:57:26,107 - INFO - root - 成功添加图片 6：./export\images_Can Less Precise Be More Reliable_ A Systematic Evaluation of Quantization's Imp\figure_6_page7.png
2025-11-09 22:57:26,107 - INFO - root - 成功添加图片 7：./export\images_Can Less Precise Be More Reliable_ A Systematic Evaluation of Quantization's Imp\figure_7_page7.png
2025-11-09 22:57:26,110 - INFO - root - 成功添加图片 8：./export\images_Can Less Precise Be More Reliable_ A Systematic Evaluation of Quantization's Imp\figure_8_page12.png
2025-11-09 22:57:26,110 - INFO - root - 成功添加图片 9：./export\images_Can Less Precise Be More Reliable_ A Systematic Evaluation of Quantization's Imp\figure_9_page12.png
2025-11-09 22:57:26,110 - INFO - root - 成功添加图片 10：./export\images_Can Less Precise Be More Reliable_ A Systematic Evaluation of Quantization's Imp\figure_10_page12.png
2025-11-09 22:57:26,117 - INFO - root - 论文《Can Less Precise Be More Reliable? A Systematic Evaluation of Quantization's Impact on CLIP Beyond Accuracy》的分析已保存到 ./export\Can Less Precise Be More Reliable_ A Systematic Evaluation of Quantization's Imp.md
2025-11-09 22:57:26,126 - INFO - root - 正在总结论文 52/80: Punching Above Precision: Small Quantized Model Distillation with Learnable Regularizer
2025-11-09 22:57:38,672 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 22:57:38,674 - INFO - root - LLMClient: rate limit reached, sleeping 15.3s
2025-11-09 22:58:45,481 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 22:59:25,122 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 22:59:25,126 - INFO - root - 正在提取论文图片...
2025-11-09 22:59:25,684 - INFO - root - 已保存图片 1/10：./export\images_Punching Above Precision_ Small Quantized Model Distillation with Learnable Regu\figure_1_page11.png
2025-11-09 22:59:25,765 - INFO - root - 已保存图片 2/10：./export\images_Punching Above Precision_ Small Quantized Model Distillation with Learnable Regu\figure_2_page5.png
2025-11-09 22:59:25,834 - INFO - root - 已保存图片 3/10：./export\images_Punching Above Precision_ Small Quantized Model Distillation with Learnable Regu\figure_3_page5.png
2025-11-09 22:59:25,859 - INFO - root - 已保存图片 4/10：./export\images_Punching Above Precision_ Small Quantized Model Distillation with Learnable Regu\figure_4_page5.jpeg
2025-11-09 22:59:25,882 - INFO - root - 已保存图片 5/10：./export\images_Punching Above Precision_ Small Quantized Model Distillation with Learnable Regu\figure_5_page5.jpeg
2025-11-09 22:59:25,906 - INFO - root - 已保存图片 6/10：./export\images_Punching Above Precision_ Small Quantized Model Distillation with Learnable Regu\figure_6_page5.jpeg
2025-11-09 22:59:25,926 - INFO - root - 已保存图片 7/10：./export\images_Punching Above Precision_ Small Quantized Model Distillation with Learnable Regu\figure_7_page5.jpeg
2025-11-09 22:59:25,950 - INFO - root - 已保存图片 8/10：./export\images_Punching Above Precision_ Small Quantized Model Distillation with Learnable Regu\figure_8_page5.jpeg
2025-11-09 22:59:25,975 - INFO - root - 已保存图片 9/10：./export\images_Punching Above Precision_ Small Quantized Model Distillation with Learnable Regu\figure_9_page5.jpeg
2025-11-09 22:59:26,046 - INFO - root - 已保存图片 10/10：./export\images_Punching Above Precision_ Small Quantized Model Distillation with Learnable Regu\figure_10_page5.jpeg
2025-11-09 22:59:26,058 - INFO - root - 成功添加图片 1：./export\images_Punching Above Precision_ Small Quantized Model Distillation with Learnable Regu\figure_1_page11.png
2025-11-09 22:59:26,060 - INFO - root - 成功添加图片 2：./export\images_Punching Above Precision_ Small Quantized Model Distillation with Learnable Regu\figure_2_page5.png
2025-11-09 22:59:26,061 - INFO - root - 成功添加图片 3：./export\images_Punching Above Precision_ Small Quantized Model Distillation with Learnable Regu\figure_3_page5.png
2025-11-09 22:59:26,062 - INFO - root - 成功添加图片 4：./export\images_Punching Above Precision_ Small Quantized Model Distillation with Learnable Regu\figure_4_page5.jpeg
2025-11-09 22:59:26,072 - INFO - root - 成功添加图片 5：./export\images_Punching Above Precision_ Small Quantized Model Distillation with Learnable Regu\figure_5_page5.jpeg
2025-11-09 22:59:26,079 - INFO - root - 成功添加图片 6：./export\images_Punching Above Precision_ Small Quantized Model Distillation with Learnable Regu\figure_6_page5.jpeg
2025-11-09 22:59:26,080 - INFO - root - 成功添加图片 7：./export\images_Punching Above Precision_ Small Quantized Model Distillation with Learnable Regu\figure_7_page5.jpeg
2025-11-09 22:59:26,081 - INFO - root - 成功添加图片 8：./export\images_Punching Above Precision_ Small Quantized Model Distillation with Learnable Regu\figure_8_page5.jpeg
2025-11-09 22:59:26,083 - INFO - root - 成功添加图片 9：./export\images_Punching Above Precision_ Small Quantized Model Distillation with Learnable Regu\figure_9_page5.jpeg
2025-11-09 22:59:26,084 - INFO - root - 成功添加图片 10：./export\images_Punching Above Precision_ Small Quantized Model Distillation with Learnable Regu\figure_10_page5.jpeg
2025-11-09 22:59:26,098 - INFO - root - 论文《Punching Above Precision: Small Quantized Model Distillation with Learnable Regularizer》的分析已保存到 ./export\Punching Above Precision_ Small Quantized Model Distillation with Learnable Regu.md
2025-11-09 22:59:26,102 - INFO - root - 正在总结论文 53/80: TinyEcoWeedNet: Edge Efficient Real-Time Aerial Agricultural Weed Detection
2025-11-09 22:59:35,611 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 22:59:35,613 - INFO - root - LLMClient: rate limit reached, sleeping 9.9s
2025-11-09 23:00:43,338 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 23:01:20,990 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 23:01:20,993 - INFO - root - 正在提取论文图片...
2025-11-09 23:01:21,119 - INFO - root - 已保存图片 1/10：./export\images_TinyEcoWeedNet_ Edge Efficient Real-Time Aerial Agricultural Weed Detection\figure_1_page5.jpeg
2025-11-09 23:01:21,199 - INFO - root - 已保存图片 2/10：./export\images_TinyEcoWeedNet_ Edge Efficient Real-Time Aerial Agricultural Weed Detection\figure_2_page5.jpeg
2025-11-09 23:01:21,261 - INFO - root - 已保存图片 3/10：./export\images_TinyEcoWeedNet_ Edge Efficient Real-Time Aerial Agricultural Weed Detection\figure_3_page5.jpeg
2025-11-09 23:01:21,296 - INFO - root - 已保存图片 4/10：./export\images_TinyEcoWeedNet_ Edge Efficient Real-Time Aerial Agricultural Weed Detection\figure_4_page5.jpeg
2025-11-09 23:01:21,344 - INFO - root - 已保存图片 5/10：./export\images_TinyEcoWeedNet_ Edge Efficient Real-Time Aerial Agricultural Weed Detection\figure_5_page5.jpeg
2025-11-09 23:01:21,378 - INFO - root - 已保存图片 6/10：./export\images_TinyEcoWeedNet_ Edge Efficient Real-Time Aerial Agricultural Weed Detection\figure_6_page5.jpeg
2025-11-09 23:01:21,412 - INFO - root - 已保存图片 7/10：./export\images_TinyEcoWeedNet_ Edge Efficient Real-Time Aerial Agricultural Weed Detection\figure_7_page5.jpeg
2025-11-09 23:01:21,448 - INFO - root - 已保存图片 8/10：./export\images_TinyEcoWeedNet_ Edge Efficient Real-Time Aerial Agricultural Weed Detection\figure_8_page5.jpeg
2025-11-09 23:01:21,479 - INFO - root - 已保存图片 9/10：./export\images_TinyEcoWeedNet_ Edge Efficient Real-Time Aerial Agricultural Weed Detection\figure_9_page5.jpeg
2025-11-09 23:01:21,509 - INFO - root - 已保存图片 10/10：./export\images_TinyEcoWeedNet_ Edge Efficient Real-Time Aerial Agricultural Weed Detection\figure_10_page5.jpeg
2025-11-09 23:01:21,511 - INFO - root - 成功添加图片 1：./export\images_TinyEcoWeedNet_ Edge Efficient Real-Time Aerial Agricultural Weed Detection\figure_1_page5.jpeg
2025-11-09 23:01:21,512 - INFO - root - 成功添加图片 2：./export\images_TinyEcoWeedNet_ Edge Efficient Real-Time Aerial Agricultural Weed Detection\figure_2_page5.jpeg
2025-11-09 23:01:21,512 - INFO - root - 成功添加图片 3：./export\images_TinyEcoWeedNet_ Edge Efficient Real-Time Aerial Agricultural Weed Detection\figure_3_page5.jpeg
2025-11-09 23:01:21,512 - INFO - root - 成功添加图片 4：./export\images_TinyEcoWeedNet_ Edge Efficient Real-Time Aerial Agricultural Weed Detection\figure_4_page5.jpeg
2025-11-09 23:01:21,513 - INFO - root - 成功添加图片 5：./export\images_TinyEcoWeedNet_ Edge Efficient Real-Time Aerial Agricultural Weed Detection\figure_5_page5.jpeg
2025-11-09 23:01:21,513 - INFO - root - 成功添加图片 6：./export\images_TinyEcoWeedNet_ Edge Efficient Real-Time Aerial Agricultural Weed Detection\figure_6_page5.jpeg
2025-11-09 23:01:21,513 - INFO - root - 成功添加图片 7：./export\images_TinyEcoWeedNet_ Edge Efficient Real-Time Aerial Agricultural Weed Detection\figure_7_page5.jpeg
2025-11-09 23:01:21,515 - INFO - root - 成功添加图片 8：./export\images_TinyEcoWeedNet_ Edge Efficient Real-Time Aerial Agricultural Weed Detection\figure_8_page5.jpeg
2025-11-09 23:01:21,515 - INFO - root - 成功添加图片 9：./export\images_TinyEcoWeedNet_ Edge Efficient Real-Time Aerial Agricultural Weed Detection\figure_9_page5.jpeg
2025-11-09 23:01:21,516 - INFO - root - 成功添加图片 10：./export\images_TinyEcoWeedNet_ Edge Efficient Real-Time Aerial Agricultural Weed Detection\figure_10_page5.jpeg
2025-11-09 23:01:21,517 - INFO - root - 论文《TinyEcoWeedNet: Edge Efficient Real-Time Aerial Agricultural Weed Detection》的分析已保存到 ./export\TinyEcoWeedNet_ Edge Efficient Real-Time Aerial Agricultural Weed Detection.md
2025-11-09 23:01:21,526 - INFO - root - 正在总结论文 54/80: SBVR: Summation of BitVector Representation for Efficient LLM Quantization
2025-11-09 23:01:35,939 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 23:01:35,941 - INFO - root - LLMClient: rate limit reached, sleeping 7.5s
2025-11-09 23:02:50,730 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 23:03:27,069 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 23:03:27,070 - INFO - root - 正在提取论文图片...
2025-11-09 23:03:27,611 - INFO - root - 已保存图片 1/10：./export\images_SBVR_ Summation of BitVector Representation for Efficient LLM Quantization\figure_1_page2.png
2025-11-09 23:03:27,708 - INFO - root - 已保存图片 2/10：./export\images_SBVR_ Summation of BitVector Representation for Efficient LLM Quantization\figure_2_page2.png
2025-11-09 23:03:27,838 - INFO - root - 已保存图片 3/10：./export\images_SBVR_ Summation of BitVector Representation for Efficient LLM Quantization\figure_3_page2.png
2025-11-09 23:03:27,908 - INFO - root - 已保存图片 4/10：./export\images_SBVR_ Summation of BitVector Representation for Efficient LLM Quantization\figure_4_page2.png
2025-11-09 23:03:27,980 - INFO - root - 已保存图片 5/10：./export\images_SBVR_ Summation of BitVector Representation for Efficient LLM Quantization\figure_5_page4.png
2025-11-09 23:03:27,987 - INFO - root - 成功添加图片 1：./export\images_SBVR_ Summation of BitVector Representation for Efficient LLM Quantization\figure_1_page2.png
2025-11-09 23:03:27,989 - INFO - root - 成功添加图片 2：./export\images_SBVR_ Summation of BitVector Representation for Efficient LLM Quantization\figure_2_page2.png
2025-11-09 23:03:27,990 - INFO - root - 成功添加图片 3：./export\images_SBVR_ Summation of BitVector Representation for Efficient LLM Quantization\figure_3_page2.png
2025-11-09 23:03:27,990 - INFO - root - 成功添加图片 4：./export\images_SBVR_ Summation of BitVector Representation for Efficient LLM Quantization\figure_4_page2.png
2025-11-09 23:03:27,991 - INFO - root - 成功添加图片 5：./export\images_SBVR_ Summation of BitVector Representation for Efficient LLM Quantization\figure_5_page4.png
2025-11-09 23:03:27,994 - INFO - root - 论文《SBVR: Summation of BitVector Representation for Efficient LLM Quantization》的分析已保存到 ./export\SBVR_ Summation of BitVector Representation for Efficient LLM Quantization.md
2025-11-09 23:03:28,001 - INFO - root - 正在总结论文 55/80: QWHA: Quantization-Aware Walsh-Hadamard Adaptation for Parameter-Efficient Fine-Tuning on Large Language Models
2025-11-09 23:03:39,191 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 23:03:39,192 - INFO - root - LLMClient: rate limit reached, sleeping 11.5s
2025-11-09 23:04:49,317 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 23:05:27,595 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 23:05:27,598 - INFO - root - 正在提取论文图片...
2025-11-09 23:05:30,054 - INFO - root - 已保存图片 1/10：./export\images_QWHA_ Quantization-Aware Walsh-Hadamard Adaptation for Parameter-Efficient Fine-\figure_1_page20.png
2025-11-09 23:05:30,247 - INFO - root - 已保存图片 2/10：./export\images_QWHA_ Quantization-Aware Walsh-Hadamard Adaptation for Parameter-Efficient Fine-\figure_2_page5.png
2025-11-09 23:05:30,427 - INFO - root - 已保存图片 3/10：./export\images_QWHA_ Quantization-Aware Walsh-Hadamard Adaptation for Parameter-Efficient Fine-\figure_3_page18.png
2025-11-09 23:05:30,590 - INFO - root - 已保存图片 4/10：./export\images_QWHA_ Quantization-Aware Walsh-Hadamard Adaptation for Parameter-Efficient Fine-\figure_4_page20.png
2025-11-09 23:05:30,699 - INFO - root - 已保存图片 5/10：./export\images_QWHA_ Quantization-Aware Walsh-Hadamard Adaptation for Parameter-Efficient Fine-\figure_5_page20.png
2025-11-09 23:05:30,833 - INFO - root - 已保存图片 6/10：./export\images_QWHA_ Quantization-Aware Walsh-Hadamard Adaptation for Parameter-Efficient Fine-\figure_6_page5.png
2025-11-09 23:05:30,964 - INFO - root - 已保存图片 7/10：./export\images_QWHA_ Quantization-Aware Walsh-Hadamard Adaptation for Parameter-Efficient Fine-\figure_7_page15.png
2025-11-09 23:05:31,061 - INFO - root - 已保存图片 8/10：./export\images_QWHA_ Quantization-Aware Walsh-Hadamard Adaptation for Parameter-Efficient Fine-\figure_8_page5.jpeg
2025-11-09 23:05:31,240 - INFO - root - 已保存图片 9/10：./export\images_QWHA_ Quantization-Aware Walsh-Hadamard Adaptation for Parameter-Efficient Fine-\figure_9_page9.png
2025-11-09 23:05:31,361 - INFO - root - 已保存图片 10/10：./export\images_QWHA_ Quantization-Aware Walsh-Hadamard Adaptation for Parameter-Efficient Fine-\figure_10_page7.png
2025-11-09 23:05:31,379 - INFO - root - 成功添加图片 1：./export\images_QWHA_ Quantization-Aware Walsh-Hadamard Adaptation for Parameter-Efficient Fine-\figure_1_page20.png
2025-11-09 23:05:31,380 - INFO - root - 成功添加图片 2：./export\images_QWHA_ Quantization-Aware Walsh-Hadamard Adaptation for Parameter-Efficient Fine-\figure_2_page5.png
2025-11-09 23:05:31,380 - INFO - root - 成功添加图片 3：./export\images_QWHA_ Quantization-Aware Walsh-Hadamard Adaptation for Parameter-Efficient Fine-\figure_3_page18.png
2025-11-09 23:05:31,381 - INFO - root - 成功添加图片 4：./export\images_QWHA_ Quantization-Aware Walsh-Hadamard Adaptation for Parameter-Efficient Fine-\figure_4_page20.png
2025-11-09 23:05:31,382 - INFO - root - 成功添加图片 5：./export\images_QWHA_ Quantization-Aware Walsh-Hadamard Adaptation for Parameter-Efficient Fine-\figure_5_page20.png
2025-11-09 23:05:31,383 - INFO - root - 成功添加图片 6：./export\images_QWHA_ Quantization-Aware Walsh-Hadamard Adaptation for Parameter-Efficient Fine-\figure_6_page5.png
2025-11-09 23:05:31,384 - INFO - root - 成功添加图片 7：./export\images_QWHA_ Quantization-Aware Walsh-Hadamard Adaptation for Parameter-Efficient Fine-\figure_7_page15.png
2025-11-09 23:05:31,384 - INFO - root - 成功添加图片 8：./export\images_QWHA_ Quantization-Aware Walsh-Hadamard Adaptation for Parameter-Efficient Fine-\figure_8_page5.jpeg
2025-11-09 23:05:31,386 - INFO - root - 成功添加图片 9：./export\images_QWHA_ Quantization-Aware Walsh-Hadamard Adaptation for Parameter-Efficient Fine-\figure_9_page9.png
2025-11-09 23:05:31,386 - INFO - root - 成功添加图片 10：./export\images_QWHA_ Quantization-Aware Walsh-Hadamard Adaptation for Parameter-Efficient Fine-\figure_10_page7.png
2025-11-09 23:05:31,394 - INFO - root - 论文《QWHA: Quantization-Aware Walsh-Hadamard Adaptation for Parameter-Efficient Fine-Tuning on Large Language Models》的分析已保存到 ./export\QWHA_ Quantization-Aware Walsh-Hadamard Adaptation for Parameter-Efficient Fine-.md
2025-11-09 23:05:31,399 - INFO - root - 正在总结论文 56/80: PTQTP: Post-Training Quantization to Trit-Planes for Large Language Models
2025-11-09 23:05:42,847 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 23:05:42,849 - INFO - root - LLMClient: rate limit reached, sleeping 6.5s
2025-11-09 23:07:01,264 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 23:07:37,734 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 23:07:37,736 - INFO - root - 正在提取论文图片...
2025-11-09 23:07:39,741 - INFO - root - 已保存图片 1/10：./export\images_PTQTP_ Post-Training Quantization to Trit-Planes for Large Language Models\figure_1_page14.png
2025-11-09 23:07:40,056 - INFO - root - 已保存图片 2/10：./export\images_PTQTP_ Post-Training Quantization to Trit-Planes for Large Language Models\figure_2_page14.jpeg
2025-11-09 23:07:40,233 - INFO - root - 已保存图片 3/10：./export\images_PTQTP_ Post-Training Quantization to Trit-Planes for Large Language Models\figure_3_page2.png
2025-11-09 23:07:40,286 - INFO - root - 已保存图片 4/10：./export\images_PTQTP_ Post-Training Quantization to Trit-Planes for Large Language Models\figure_4_page2.png
2025-11-09 23:07:40,416 - INFO - root - 已保存图片 5/10：./export\images_PTQTP_ Post-Training Quantization to Trit-Planes for Large Language Models\figure_5_page2.png
2025-11-09 23:07:40,491 - INFO - root - 已保存图片 6/10：./export\images_PTQTP_ Post-Training Quantization to Trit-Planes for Large Language Models\figure_6_page2.png
2025-11-09 23:07:40,538 - INFO - root - 已保存图片 7/10：./export\images_PTQTP_ Post-Training Quantization to Trit-Planes for Large Language Models\figure_7_page2.png
2025-11-09 23:07:40,592 - INFO - root - 已保存图片 8/10：./export\images_PTQTP_ Post-Training Quantization to Trit-Planes for Large Language Models\figure_8_page2.png
2025-11-09 23:07:40,626 - INFO - root - 已保存图片 9/10：./export\images_PTQTP_ Post-Training Quantization to Trit-Planes for Large Language Models\figure_9_page4.png
2025-11-09 23:07:40,714 - INFO - root - 已保存图片 10/10：./export\images_PTQTP_ Post-Training Quantization to Trit-Planes for Large Language Models\figure_10_page4.png
2025-11-09 23:07:40,720 - INFO - root - 成功添加图片 1：./export\images_PTQTP_ Post-Training Quantization to Trit-Planes for Large Language Models\figure_1_page14.png
2025-11-09 23:07:40,721 - INFO - root - 成功添加图片 2：./export\images_PTQTP_ Post-Training Quantization to Trit-Planes for Large Language Models\figure_2_page14.jpeg
2025-11-09 23:07:40,722 - INFO - root - 成功添加图片 3：./export\images_PTQTP_ Post-Training Quantization to Trit-Planes for Large Language Models\figure_3_page2.png
2025-11-09 23:07:40,724 - INFO - root - 成功添加图片 4：./export\images_PTQTP_ Post-Training Quantization to Trit-Planes for Large Language Models\figure_4_page2.png
2025-11-09 23:07:40,726 - INFO - root - 成功添加图片 5：./export\images_PTQTP_ Post-Training Quantization to Trit-Planes for Large Language Models\figure_5_page2.png
2025-11-09 23:07:40,727 - INFO - root - 成功添加图片 6：./export\images_PTQTP_ Post-Training Quantization to Trit-Planes for Large Language Models\figure_6_page2.png
2025-11-09 23:07:40,729 - INFO - root - 成功添加图片 7：./export\images_PTQTP_ Post-Training Quantization to Trit-Planes for Large Language Models\figure_7_page2.png
2025-11-09 23:07:40,730 - INFO - root - 成功添加图片 8：./export\images_PTQTP_ Post-Training Quantization to Trit-Planes for Large Language Models\figure_8_page2.png
2025-11-09 23:07:40,731 - INFO - root - 成功添加图片 9：./export\images_PTQTP_ Post-Training Quantization to Trit-Planes for Large Language Models\figure_9_page4.png
2025-11-09 23:07:40,731 - INFO - root - 成功添加图片 10：./export\images_PTQTP_ Post-Training Quantization to Trit-Planes for Large Language Models\figure_10_page4.png
2025-11-09 23:07:40,742 - INFO - root - 论文《PTQTP: Post-Training Quantization to Trit-Planes for Large Language Models》的分析已保存到 ./export\PTQTP_ Post-Training Quantization to Trit-Planes for Large Language Models.md
2025-11-09 23:07:40,773 - INFO - root - 正在总结论文 57/80: MEC-Quant: Maximum Entropy Coding for Extremely Low Bit Quantization-Aware Training
2025-11-09 23:07:55,319 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 23:07:55,322 - INFO - root - LLMClient: rate limit reached, sleeping 5.9s
2025-11-09 23:08:53,861 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 23:09:31,774 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 23:09:31,780 - INFO - root - 正在提取论文图片...
2025-11-09 23:09:31,792 - INFO - root - 论文《MEC-Quant: Maximum Entropy Coding for Extremely Low Bit Quantization-Aware Training》的分析已保存到 ./export\MEC-Quant_ Maximum Entropy Coding for Extremely Low Bit Quantization-Aware Train.md
2025-11-09 23:09:31,802 - INFO - root - 正在总结论文 58/80: Q-ROAR: Outlier-Aware Rescaling for RoPE Position Interpolation in Quantized Long-Context LLMs
2025-11-09 23:09:44,360 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 23:09:44,362 - INFO - root - LLMClient: rate limit reached, sleeping 9.5s
2025-11-09 23:10:49,561 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 23:11:26,233 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 23:11:26,238 - INFO - root - 正在提取论文图片...
2025-11-09 23:11:26,248 - INFO - root - 论文《Q-ROAR: Outlier-Aware Rescaling for RoPE Position Interpolation in Quantized Long-Context LLMs》的分析已保存到 ./export\Q-ROAR_ Outlier-Aware Rescaling for RoPE Position Interpolation in Quantized Lon.md
2025-11-09 23:11:26,254 - INFO - root - 正在总结论文 59/80: Efficient Quantization-Aware Neural Receivers: Beyond Post-Training Quantization
2025-11-09 23:11:39,633 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 23:11:39,635 - INFO - root - LLMClient: rate limit reached, sleeping 9.9s
2025-11-09 23:12:41,935 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 23:13:16,957 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 23:13:16,960 - INFO - root - 正在提取论文图片...
2025-11-09 23:13:19,451 - INFO - root - 已保存图片 1/10：./export\images_Efficient Quantization-Aware Neural Receivers_ Beyond Post-Training Quantization\figure_1_page4.png
2025-11-09 23:13:19,462 - INFO - root - 成功添加图片 1：./export\images_Efficient Quantization-Aware Neural Receivers_ Beyond Post-Training Quantization\figure_1_page4.png
2025-11-09 23:13:19,464 - INFO - root - 论文《Efficient Quantization-Aware Neural Receivers: Beyond Post-Training Quantization》的分析已保存到 ./export\Efficient Quantization-Aware Neural Receivers_ Beyond Post-Training Quantization.md
2025-11-09 23:13:19,469 - INFO - root - 正在总结论文 60/80: Rate-Distortion Limits for Multimodal Retrieval: Theory, Optimal Codes, and Finite-Sample Guarantees
2025-11-09 23:13:34,621 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 23:13:34,623 - INFO - root - LLMClient: rate limit reached, sleeping 7.3s
2025-11-09 23:14:37,171 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 23:15:12,084 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 23:15:12,085 - INFO - root - 正在提取论文图片...
2025-11-09 23:15:12,113 - INFO - root - 论文《Rate-Distortion Limits for Multimodal Retrieval: Theory, Optimal Codes, and Finite-Sample Guarantees》的分析已保存到 ./export\Rate-Distortion Limits for Multimodal Retrieval_ Theory, Optimal Codes, and Fini.md
2025-11-09 23:15:12,118 - INFO - root - 正在总结论文 61/80: SQAP-VLA: A Synergistic Quantization-Aware Pruning Framework for High-Performance Vision-Language-Action Models
2025-11-09 23:15:20,725 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 23:15:20,748 - INFO - root - LLMClient: rate limit reached, sleeping 16.4s
2025-11-09 23:16:35,525 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 23:17:06,298 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 23:17:06,300 - INFO - root - 正在提取论文图片...
2025-11-09 23:17:09,336 - INFO - root - 已保存图片 1/10：./export\images_SQAP-VLA_ A Synergistic Quantization-Aware Pruning Framework for High-Performanc\figure_1_page6.png
2025-11-09 23:17:09,722 - INFO - root - 已保存图片 2/10：./export\images_SQAP-VLA_ A Synergistic Quantization-Aware Pruning Framework for High-Performanc\figure_2_page6.png
2025-11-09 23:17:09,841 - INFO - root - 已保存图片 3/10：./export\images_SQAP-VLA_ A Synergistic Quantization-Aware Pruning Framework for High-Performanc\figure_3_page2.png
2025-11-09 23:17:09,873 - INFO - root - 已保存图片 4/10：./export\images_SQAP-VLA_ A Synergistic Quantization-Aware Pruning Framework for High-Performanc\figure_4_page8.png
2025-11-09 23:17:09,912 - INFO - root - 已保存图片 5/10：./export\images_SQAP-VLA_ A Synergistic Quantization-Aware Pruning Framework for High-Performanc\figure_5_page8.png
2025-11-09 23:17:10,046 - INFO - root - 已保存图片 6/10：./export\images_SQAP-VLA_ A Synergistic Quantization-Aware Pruning Framework for High-Performanc\figure_6_page4.png
2025-11-09 23:17:10,201 - INFO - root - 已保存图片 7/10：./export\images_SQAP-VLA_ A Synergistic Quantization-Aware Pruning Framework for High-Performanc\figure_7_page4.png
2025-11-09 23:17:10,446 - INFO - root - 已保存图片 8/10：./export\images_SQAP-VLA_ A Synergistic Quantization-Aware Pruning Framework for High-Performanc\figure_8_page4.png
2025-11-09 23:17:10,667 - INFO - root - 已保存图片 9/10：./export\images_SQAP-VLA_ A Synergistic Quantization-Aware Pruning Framework for High-Performanc\figure_9_page4.png
2025-11-09 23:17:10,685 - INFO - root - 成功添加图片 1：./export\images_SQAP-VLA_ A Synergistic Quantization-Aware Pruning Framework for High-Performanc\figure_1_page6.png
2025-11-09 23:17:10,686 - INFO - root - 成功添加图片 2：./export\images_SQAP-VLA_ A Synergistic Quantization-Aware Pruning Framework for High-Performanc\figure_2_page6.png
2025-11-09 23:17:10,686 - INFO - root - 成功添加图片 3：./export\images_SQAP-VLA_ A Synergistic Quantization-Aware Pruning Framework for High-Performanc\figure_3_page2.png
2025-11-09 23:17:10,687 - INFO - root - 成功添加图片 4：./export\images_SQAP-VLA_ A Synergistic Quantization-Aware Pruning Framework for High-Performanc\figure_4_page8.png
2025-11-09 23:17:10,688 - INFO - root - 成功添加图片 5：./export\images_SQAP-VLA_ A Synergistic Quantization-Aware Pruning Framework for High-Performanc\figure_5_page8.png
2025-11-09 23:17:10,693 - INFO - root - 成功添加图片 6：./export\images_SQAP-VLA_ A Synergistic Quantization-Aware Pruning Framework for High-Performanc\figure_6_page4.png
2025-11-09 23:17:10,694 - INFO - root - 成功添加图片 7：./export\images_SQAP-VLA_ A Synergistic Quantization-Aware Pruning Framework for High-Performanc\figure_7_page4.png
2025-11-09 23:17:10,694 - INFO - root - 成功添加图片 8：./export\images_SQAP-VLA_ A Synergistic Quantization-Aware Pruning Framework for High-Performanc\figure_8_page4.png
2025-11-09 23:17:10,695 - INFO - root - 成功添加图片 9：./export\images_SQAP-VLA_ A Synergistic Quantization-Aware Pruning Framework for High-Performanc\figure_9_page4.png
2025-11-09 23:17:10,700 - INFO - root - 论文《SQAP-VLA: A Synergistic Quantization-Aware Pruning Framework for High-Performance Vision-Language-Action Models》的分析已保存到 ./export\SQAP-VLA_ A Synergistic Quantization-Aware Pruning Framework for High-Performanc.md
2025-11-09 23:17:10,713 - INFO - root - 正在总结论文 62/80: CSI Compression Beyond Latents: End-to-End Hybrid Attention-CNN Networks with Entropy Regularization
2025-11-09 23:17:19,079 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 23:17:19,080 - INFO - root - LLMClient: rate limit reached, sleeping 16.4s
2025-11-09 23:18:27,934 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 23:18:56,233 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 23:18:56,234 - INFO - root - 正在提取论文图片...
2025-11-09 23:18:56,397 - INFO - root - 已保存图片 1/10：./export\images_CSI Compression Beyond Latents_ End-to-End Hybrid Attention-CNN Networks with En\figure_1_page2.png
2025-11-09 23:18:56,456 - INFO - root - 已保存图片 2/10：./export\images_CSI Compression Beyond Latents_ End-to-End Hybrid Attention-CNN Networks with En\figure_2_page2.png
2025-11-09 23:18:56,464 - INFO - root - 成功添加图片 1：./export\images_CSI Compression Beyond Latents_ End-to-End Hybrid Attention-CNN Networks with En\figure_1_page2.png
2025-11-09 23:18:56,467 - INFO - root - 成功添加图片 2：./export\images_CSI Compression Beyond Latents_ End-to-End Hybrid Attention-CNN Networks with En\figure_2_page2.png
2025-11-09 23:18:56,471 - INFO - root - 论文《CSI Compression Beyond Latents: End-to-End Hybrid Attention-CNN Networks with Entropy Regularization》的分析已保存到 ./export\CSI Compression Beyond Latents_ End-to-End Hybrid Attention-CNN Networks with En.md
2025-11-09 23:18:56,480 - INFO - root - 正在总结论文 63/80: Explaining How Quantization Disparately Skews a Model
2025-11-09 23:19:07,125 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 23:19:07,125 - INFO - root - LLMClient: rate limit reached, sleeping 20.8s
2025-11-09 23:20:13,663 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 23:20:52,312 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 23:20:52,315 - INFO - root - 正在提取论文图片...
2025-11-09 23:20:52,909 - INFO - root - 已保存图片 1/10：./export\images_Explaining How Quantization Disparately Skews a Model\figure_1_page11.jpeg
2025-11-09 23:20:53,225 - INFO - root - 已保存图片 2/10：./export\images_Explaining How Quantization Disparately Skews a Model\figure_2_page7.jpeg
2025-11-09 23:20:53,460 - INFO - root - 已保存图片 3/10：./export\images_Explaining How Quantization Disparately Skews a Model\figure_3_page7.jpeg
2025-11-09 23:20:53,723 - INFO - root - 已保存图片 4/10：./export\images_Explaining How Quantization Disparately Skews a Model\figure_4_page7.jpeg
2025-11-09 23:20:53,957 - INFO - root - 已保存图片 5/10：./export\images_Explaining How Quantization Disparately Skews a Model\figure_5_page2.jpeg
2025-11-09 23:20:54,187 - INFO - root - 已保存图片 6/10：./export\images_Explaining How Quantization Disparately Skews a Model\figure_6_page10.jpeg
2025-11-09 23:20:54,392 - INFO - root - 已保存图片 7/10：./export\images_Explaining How Quantization Disparately Skews a Model\figure_7_page10.jpeg
2025-11-09 23:20:54,525 - INFO - root - 已保存图片 8/10：./export\images_Explaining How Quantization Disparately Skews a Model\figure_8_page8.jpeg
2025-11-09 23:20:54,728 - INFO - root - 已保存图片 9/10：./export\images_Explaining How Quantization Disparately Skews a Model\figure_9_page10.jpeg
2025-11-09 23:20:54,834 - INFO - root - 已保存图片 10/10：./export\images_Explaining How Quantization Disparately Skews a Model\figure_10_page5.jpeg
2025-11-09 23:20:54,895 - INFO - root - 成功添加图片 1：./export\images_Explaining How Quantization Disparately Skews a Model\figure_1_page11.jpeg
2025-11-09 23:20:54,895 - INFO - root - 成功添加图片 2：./export\images_Explaining How Quantization Disparately Skews a Model\figure_2_page7.jpeg
2025-11-09 23:20:54,896 - INFO - root - 成功添加图片 3：./export\images_Explaining How Quantization Disparately Skews a Model\figure_3_page7.jpeg
2025-11-09 23:20:54,897 - INFO - root - 成功添加图片 4：./export\images_Explaining How Quantization Disparately Skews a Model\figure_4_page7.jpeg
2025-11-09 23:20:54,898 - INFO - root - 成功添加图片 5：./export\images_Explaining How Quantization Disparately Skews a Model\figure_5_page2.jpeg
2025-11-09 23:20:54,899 - INFO - root - 成功添加图片 6：./export\images_Explaining How Quantization Disparately Skews a Model\figure_6_page10.jpeg
2025-11-09 23:20:54,899 - INFO - root - 成功添加图片 7：./export\images_Explaining How Quantization Disparately Skews a Model\figure_7_page10.jpeg
2025-11-09 23:20:54,899 - INFO - root - 成功添加图片 8：./export\images_Explaining How Quantization Disparately Skews a Model\figure_8_page8.jpeg
2025-11-09 23:20:54,900 - INFO - root - 成功添加图片 9：./export\images_Explaining How Quantization Disparately Skews a Model\figure_9_page10.jpeg
2025-11-09 23:20:54,901 - INFO - root - 成功添加图片 10：./export\images_Explaining How Quantization Disparately Skews a Model\figure_10_page5.jpeg
2025-11-09 23:20:54,904 - INFO - root - 论文《Explaining How Quantization Disparately Skews a Model》的分析已保存到 ./export\Explaining How Quantization Disparately Skews a Model.md
2025-11-09 23:20:54,909 - INFO - root - 正在总结论文 64/80: LoaQ: Layer-wise Output Approximation Quantization
2025-11-09 23:21:08,393 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 23:21:08,394 - INFO - root - LLMClient: rate limit reached, sleeping 5.3s
2025-11-09 23:22:02,106 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 23:22:39,104 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 23:22:39,106 - INFO - root - 正在提取论文图片...
2025-11-09 23:22:39,122 - INFO - root - 论文《LoaQ: Layer-wise Output Approximation Quantization》的分析已保存到 ./export\LoaQ_ Layer-wise Output Approximation Quantization.md
2025-11-09 23:22:39,135 - INFO - root - 正在总结论文 65/80: FineServe: Precision-Aware KV Slab and Two-Level Scheduling for Heterogeneous Precision LLM Serving
2025-11-09 23:22:56,247 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 23:22:56,248 - INFO - root - LLMClient: rate limit reached, sleeping 5.9s
2025-11-09 23:23:50,246 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 23:24:24,448 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 23:24:24,472 - INFO - root - 正在提取论文图片...
2025-11-09 23:24:25,495 - INFO - root - 已保存图片 1/10：./export\images_FineServe_ Precision-Aware KV Slab and Two-Level Scheduling for Heterogeneous Pr\figure_1_page4.png
2025-11-09 23:24:25,594 - INFO - root - 已保存图片 2/10：./export\images_FineServe_ Precision-Aware KV Slab and Two-Level Scheduling for Heterogeneous Pr\figure_2_page10.png
2025-11-09 23:24:25,656 - INFO - root - 已保存图片 3/10：./export\images_FineServe_ Precision-Aware KV Slab and Two-Level Scheduling for Heterogeneous Pr\figure_3_page4.png
2025-11-09 23:24:25,716 - INFO - root - 已保存图片 4/10：./export\images_FineServe_ Precision-Aware KV Slab and Two-Level Scheduling for Heterogeneous Pr\figure_4_page6.png
2025-11-09 23:24:25,781 - INFO - root - 已保存图片 5/10：./export\images_FineServe_ Precision-Aware KV Slab and Two-Level Scheduling for Heterogeneous Pr\figure_5_page3.png
2025-11-09 23:24:25,839 - INFO - root - 已保存图片 6/10：./export\images_FineServe_ Precision-Aware KV Slab and Two-Level Scheduling for Heterogeneous Pr\figure_6_page3.png
2025-11-09 23:24:25,917 - INFO - root - 已保存图片 7/10：./export\images_FineServe_ Precision-Aware KV Slab and Two-Level Scheduling for Heterogeneous Pr\figure_7_page6.png
2025-11-09 23:24:25,972 - INFO - root - 已保存图片 8/10：./export\images_FineServe_ Precision-Aware KV Slab and Two-Level Scheduling for Heterogeneous Pr\figure_8_page10.png
2025-11-09 23:24:26,029 - INFO - root - 已保存图片 9/10：./export\images_FineServe_ Precision-Aware KV Slab and Two-Level Scheduling for Heterogeneous Pr\figure_9_page10.png
2025-11-09 23:24:26,081 - INFO - root - 已保存图片 10/10：./export\images_FineServe_ Precision-Aware KV Slab and Two-Level Scheduling for Heterogeneous Pr\figure_10_page5.png
2025-11-09 23:24:26,089 - INFO - root - 成功添加图片 1：./export\images_FineServe_ Precision-Aware KV Slab and Two-Level Scheduling for Heterogeneous Pr\figure_1_page4.png
2025-11-09 23:24:26,092 - INFO - root - 成功添加图片 2：./export\images_FineServe_ Precision-Aware KV Slab and Two-Level Scheduling for Heterogeneous Pr\figure_2_page10.png
2025-11-09 23:24:26,092 - INFO - root - 成功添加图片 3：./export\images_FineServe_ Precision-Aware KV Slab and Two-Level Scheduling for Heterogeneous Pr\figure_3_page4.png
2025-11-09 23:24:26,093 - INFO - root - 成功添加图片 4：./export\images_FineServe_ Precision-Aware KV Slab and Two-Level Scheduling for Heterogeneous Pr\figure_4_page6.png
2025-11-09 23:24:26,093 - INFO - root - 成功添加图片 5：./export\images_FineServe_ Precision-Aware KV Slab and Two-Level Scheduling for Heterogeneous Pr\figure_5_page3.png
2025-11-09 23:24:26,094 - INFO - root - 成功添加图片 6：./export\images_FineServe_ Precision-Aware KV Slab and Two-Level Scheduling for Heterogeneous Pr\figure_6_page3.png
2025-11-09 23:24:26,095 - INFO - root - 成功添加图片 7：./export\images_FineServe_ Precision-Aware KV Slab and Two-Level Scheduling for Heterogeneous Pr\figure_7_page6.png
2025-11-09 23:24:26,095 - INFO - root - 成功添加图片 8：./export\images_FineServe_ Precision-Aware KV Slab and Two-Level Scheduling for Heterogeneous Pr\figure_8_page10.png
2025-11-09 23:24:26,097 - INFO - root - 成功添加图片 9：./export\images_FineServe_ Precision-Aware KV Slab and Two-Level Scheduling for Heterogeneous Pr\figure_9_page10.png
2025-11-09 23:24:26,097 - INFO - root - 成功添加图片 10：./export\images_FineServe_ Precision-Aware KV Slab and Two-Level Scheduling for Heterogeneous Pr\figure_10_page5.png
2025-11-09 23:24:26,100 - INFO - root - 论文《FineServe: Precision-Aware KV Slab and Two-Level Scheduling for Heterogeneous Precision LLM Serving》的分析已保存到 ./export\FineServe_ Precision-Aware KV Slab and Two-Level Scheduling for Heterogeneous Pr.md
2025-11-09 23:24:26,114 - INFO - root - 正在总结论文 66/80: Sensitivity-Aware Post-Training Quantization for Deep Neural Networks
2025-11-09 23:24:41,668 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 23:24:41,669 - INFO - root - LLMClient: rate limit reached, sleeping 8.6s
2025-11-09 23:25:42,565 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 23:26:17,991 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 23:26:17,997 - INFO - root - 正在提取论文图片...
2025-11-09 23:26:21,330 - INFO - root - 已保存图片 1/10：./export\images_Sensitivity-Aware Post-Training Quantization for Deep Neural Networks\figure_1_page7.png
2025-11-09 23:26:21,638 - INFO - root - 已保存图片 2/10：./export\images_Sensitivity-Aware Post-Training Quantization for Deep Neural Networks\figure_2_page7.png
2025-11-09 23:26:21,962 - INFO - root - 已保存图片 3/10：./export\images_Sensitivity-Aware Post-Training Quantization for Deep Neural Networks\figure_3_page7.png
2025-11-09 23:26:22,254 - INFO - root - 已保存图片 4/10：./export\images_Sensitivity-Aware Post-Training Quantization for Deep Neural Networks\figure_4_page7.png
2025-11-09 23:26:22,519 - INFO - root - 已保存图片 5/10：./export\images_Sensitivity-Aware Post-Training Quantization for Deep Neural Networks\figure_5_page7.png
2025-11-09 23:26:22,543 - INFO - root - 成功添加图片 1：./export\images_Sensitivity-Aware Post-Training Quantization for Deep Neural Networks\figure_1_page7.png
2025-11-09 23:26:22,544 - INFO - root - 成功添加图片 2：./export\images_Sensitivity-Aware Post-Training Quantization for Deep Neural Networks\figure_2_page7.png
2025-11-09 23:26:22,545 - INFO - root - 成功添加图片 3：./export\images_Sensitivity-Aware Post-Training Quantization for Deep Neural Networks\figure_3_page7.png
2025-11-09 23:26:22,546 - INFO - root - 成功添加图片 4：./export\images_Sensitivity-Aware Post-Training Quantization for Deep Neural Networks\figure_4_page7.png
2025-11-09 23:26:22,547 - INFO - root - 成功添加图片 5：./export\images_Sensitivity-Aware Post-Training Quantization for Deep Neural Networks\figure_5_page7.png
2025-11-09 23:26:22,550 - INFO - root - 论文《Sensitivity-Aware Post-Training Quantization for Deep Neural Networks》的分析已保存到 ./export\Sensitivity-Aware Post-Training Quantization for Deep Neural Networks.md
2025-11-09 23:26:22,554 - INFO - root - 正在总结论文 67/80: SuperSNN: A Hardware-Aware Framework for Physically Realizable, High-Performance Superconducting Spiking Neural Network Chips
2025-11-09 23:26:38,312 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 23:26:38,396 - INFO - root - LLMClient: rate limit reached, sleeping 4.2s
2025-11-09 23:27:32,391 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 23:28:11,018 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 23:28:11,020 - INFO - root - 正在提取论文图片...
2025-11-09 23:28:14,882 - INFO - root - 已保存图片 1/10：./export\images_SuperSNN_ A Hardware-Aware Framework for Physically Realizable, High-Performance\figure_1_page6.png
2025-11-09 23:28:15,180 - INFO - root - 已保存图片 2/10：./export\images_SuperSNN_ A Hardware-Aware Framework for Physically Realizable, High-Performance\figure_2_page9.png
2025-11-09 23:28:15,534 - INFO - root - 已保存图片 3/10：./export\images_SuperSNN_ A Hardware-Aware Framework for Physically Realizable, High-Performance\figure_3_page9.png
2025-11-09 23:28:15,848 - INFO - root - 已保存图片 4/10：./export\images_SuperSNN_ A Hardware-Aware Framework for Physically Realizable, High-Performance\figure_4_page6.png
2025-11-09 23:28:15,963 - INFO - root - 已保存图片 5/10：./export\images_SuperSNN_ A Hardware-Aware Framework for Physically Realizable, High-Performance\figure_5_page7.png
2025-11-09 23:28:16,264 - INFO - root - 已保存图片 6/10：./export\images_SuperSNN_ A Hardware-Aware Framework for Physically Realizable, High-Performance\figure_6_page8.png
2025-11-09 23:28:16,376 - INFO - root - 已保存图片 7/10：./export\images_SuperSNN_ A Hardware-Aware Framework for Physically Realizable, High-Performance\figure_7_page6.png
2025-11-09 23:28:16,583 - INFO - root - 已保存图片 8/10：./export\images_SuperSNN_ A Hardware-Aware Framework for Physically Realizable, High-Performance\figure_8_page6.png
2025-11-09 23:28:16,790 - INFO - root - 已保存图片 9/10：./export\images_SuperSNN_ A Hardware-Aware Framework for Physically Realizable, High-Performance\figure_9_page3.png
2025-11-09 23:28:16,869 - INFO - root - 已保存图片 10/10：./export\images_SuperSNN_ A Hardware-Aware Framework for Physically Realizable, High-Performance\figure_10_page4.png
2025-11-09 23:28:16,888 - INFO - root - 成功添加图片 1：./export\images_SuperSNN_ A Hardware-Aware Framework for Physically Realizable, High-Performance\figure_1_page6.png
2025-11-09 23:28:16,890 - INFO - root - 成功添加图片 2：./export\images_SuperSNN_ A Hardware-Aware Framework for Physically Realizable, High-Performance\figure_2_page9.png
2025-11-09 23:28:16,891 - INFO - root - 成功添加图片 3：./export\images_SuperSNN_ A Hardware-Aware Framework for Physically Realizable, High-Performance\figure_3_page9.png
2025-11-09 23:28:16,891 - INFO - root - 成功添加图片 4：./export\images_SuperSNN_ A Hardware-Aware Framework for Physically Realizable, High-Performance\figure_4_page6.png
2025-11-09 23:28:16,893 - INFO - root - 成功添加图片 5：./export\images_SuperSNN_ A Hardware-Aware Framework for Physically Realizable, High-Performance\figure_5_page7.png
2025-11-09 23:28:16,894 - INFO - root - 成功添加图片 6：./export\images_SuperSNN_ A Hardware-Aware Framework for Physically Realizable, High-Performance\figure_6_page8.png
2025-11-09 23:28:16,894 - INFO - root - 成功添加图片 7：./export\images_SuperSNN_ A Hardware-Aware Framework for Physically Realizable, High-Performance\figure_7_page6.png
2025-11-09 23:28:16,895 - INFO - root - 成功添加图片 8：./export\images_SuperSNN_ A Hardware-Aware Framework for Physically Realizable, High-Performance\figure_8_page6.png
2025-11-09 23:28:16,897 - INFO - root - 成功添加图片 9：./export\images_SuperSNN_ A Hardware-Aware Framework for Physically Realizable, High-Performance\figure_9_page3.png
2025-11-09 23:28:16,898 - INFO - root - 成功添加图片 10：./export\images_SuperSNN_ A Hardware-Aware Framework for Physically Realizable, High-Performance\figure_10_page4.png
2025-11-09 23:28:16,910 - INFO - root - 论文《SuperSNN: A Hardware-Aware Framework for Physically Realizable, High-Performance Superconducting Spiking Neural Network Chips》的分析已保存到 ./export\SuperSNN_ A Hardware-Aware Framework for Physically Realizable, High-Performance.md
2025-11-09 23:28:16,914 - INFO - root - 正在总结论文 68/80: Data-Augmented Quantization-Aware Knowledge Distillation
2025-11-09 23:28:28,395 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 23:28:28,396 - INFO - root - LLMClient: rate limit reached, sleeping 4.0s
2025-11-09 23:29:19,668 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 23:29:52,137 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 23:29:52,139 - INFO - root - 正在提取论文图片...
2025-11-09 23:29:52,416 - INFO - root - 已保存图片 1/10：./export\images_Data-Augmented Quantization-Aware Knowledge Distillation\figure_1_page8.png
2025-11-09 23:29:52,573 - INFO - root - 已保存图片 2/10：./export\images_Data-Augmented Quantization-Aware Knowledge Distillation\figure_2_page8.png
2025-11-09 23:29:52,799 - INFO - root - 已保存图片 3/10：./export\images_Data-Augmented Quantization-Aware Knowledge Distillation\figure_3_page8.png
2025-11-09 23:29:52,800 - INFO - root - 成功添加图片 1：./export\images_Data-Augmented Quantization-Aware Knowledge Distillation\figure_1_page8.png
2025-11-09 23:29:52,800 - INFO - root - 成功添加图片 2：./export\images_Data-Augmented Quantization-Aware Knowledge Distillation\figure_2_page8.png
2025-11-09 23:29:52,800 - INFO - root - 成功添加图片 3：./export\images_Data-Augmented Quantization-Aware Knowledge Distillation\figure_3_page8.png
2025-11-09 23:29:52,808 - INFO - root - 论文《Data-Augmented Quantization-Aware Knowledge Distillation》的分析已保存到 ./export\Data-Augmented Quantization-Aware Knowledge Distillation.md
2025-11-09 23:29:52,816 - INFO - root - 正在总结论文 69/80: DPQuant: Efficient and Differentially-Private Model Training via Dynamic Quantization Scheduling
2025-11-09 23:30:12,010 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 23:30:12,042 - INFO - root - LLMClient: rate limit reached, sleeping 7.6s
2025-11-09 23:31:18,665 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 23:31:53,424 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 23:31:53,430 - INFO - root - 正在提取论文图片...
2025-11-09 23:31:53,474 - INFO - root - 论文《DPQuant: Efficient and Differentially-Private Model Training via Dynamic Quantization Scheduling》的分析已保存到 ./export\DPQuant_ Efficient and Differentially-Private Model Training via Dynamic Quantiz.md
2025-11-09 23:31:53,507 - INFO - root - 正在总结论文 70/80: Empowering Large Language Model for Sequential Recommendation via Multimodal Embeddings and Semantic IDs
2025-11-09 23:32:10,140 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 23:32:10,143 - INFO - root - LLMClient: rate limit reached, sleeping 8.5s
2025-11-09 23:33:17,625 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 23:33:55,497 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 23:33:55,500 - INFO - root - 正在提取论文图片...
2025-11-09 23:33:55,610 - INFO - root - 已保存图片 1/10：./export\images_Empowering Large Language Model for Sequential Recommendation via Multimodal Emb\figure_1_page4.jpeg
2025-11-09 23:33:55,614 - INFO - root - 成功添加图片 1：./export\images_Empowering Large Language Model for Sequential Recommendation via Multimodal Emb\figure_1_page4.jpeg
2025-11-09 23:33:55,623 - INFO - root - 论文《Empowering Large Language Model for Sequential Recommendation via Multimodal Embeddings and Semantic IDs》的分析已保存到 ./export\Empowering Large Language Model for Sequential Recommendation via Multimodal Emb.md
2025-11-09 23:33:55,632 - INFO - root - 正在总结论文 71/80: Q-Sched: Pushing the Boundaries of Few-Step Diffusion Models with Quantization-Aware Scheduling
2025-11-09 23:34:07,099 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 23:34:07,100 - INFO - root - LLMClient: rate limit reached, sleeping 10.5s
2025-11-09 23:35:15,795 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 23:35:44,888 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 23:35:44,891 - INFO - root - 正在提取论文图片...
2025-11-09 23:35:47,552 - INFO - root - 已保存图片 1/10：./export\images_Q-Sched_ Pushing the Boundaries of Few-Step Diffusion Models with Quantization-A\figure_1_page2.png
2025-11-09 23:35:47,751 - INFO - root - 已保存图片 2/10：./export\images_Q-Sched_ Pushing the Boundaries of Few-Step Diffusion Models with Quantization-A\figure_2_page22.jpeg
2025-11-09 23:35:47,920 - INFO - root - 已保存图片 3/10：./export\images_Q-Sched_ Pushing the Boundaries of Few-Step Diffusion Models with Quantization-A\figure_3_page23.jpeg
2025-11-09 23:35:48,431 - INFO - root - 已保存图片 4/10：./export\images_Q-Sched_ Pushing the Boundaries of Few-Step Diffusion Models with Quantization-A\figure_4_page22.jpeg
2025-11-09 23:35:48,967 - INFO - root - 已保存图片 5/10：./export\images_Q-Sched_ Pushing the Boundaries of Few-Step Diffusion Models with Quantization-A\figure_5_page8.png
2025-11-09 23:35:49,277 - INFO - root - 已保存图片 6/10：./export\images_Q-Sched_ Pushing the Boundaries of Few-Step Diffusion Models with Quantization-A\figure_6_page1.png
2025-11-09 23:35:49,459 - INFO - root - 已保存图片 7/10：./export\images_Q-Sched_ Pushing the Boundaries of Few-Step Diffusion Models with Quantization-A\figure_7_page3.png
2025-11-09 23:35:49,587 - INFO - root - 已保存图片 8/10：./export\images_Q-Sched_ Pushing the Boundaries of Few-Step Diffusion Models with Quantization-A\figure_8_page16.png
2025-11-09 23:35:49,756 - INFO - root - 已保存图片 9/10：./export\images_Q-Sched_ Pushing the Boundaries of Few-Step Diffusion Models with Quantization-A\figure_9_page16.png
2025-11-09 23:35:49,897 - INFO - root - 已保存图片 10/10：./export\images_Q-Sched_ Pushing the Boundaries of Few-Step Diffusion Models with Quantization-A\figure_10_page9.png
2025-11-09 23:35:49,923 - INFO - root - 成功添加图片 1：./export\images_Q-Sched_ Pushing the Boundaries of Few-Step Diffusion Models with Quantization-A\figure_1_page2.png
2025-11-09 23:35:49,923 - INFO - root - 成功添加图片 2：./export\images_Q-Sched_ Pushing the Boundaries of Few-Step Diffusion Models with Quantization-A\figure_2_page22.jpeg
2025-11-09 23:35:49,924 - INFO - root - 成功添加图片 3：./export\images_Q-Sched_ Pushing the Boundaries of Few-Step Diffusion Models with Quantization-A\figure_3_page23.jpeg
2025-11-09 23:35:49,926 - INFO - root - 成功添加图片 4：./export\images_Q-Sched_ Pushing the Boundaries of Few-Step Diffusion Models with Quantization-A\figure_4_page22.jpeg
2025-11-09 23:35:49,927 - INFO - root - 成功添加图片 5：./export\images_Q-Sched_ Pushing the Boundaries of Few-Step Diffusion Models with Quantization-A\figure_5_page8.png
2025-11-09 23:35:49,928 - INFO - root - 成功添加图片 6：./export\images_Q-Sched_ Pushing the Boundaries of Few-Step Diffusion Models with Quantization-A\figure_6_page1.png
2025-11-09 23:35:49,929 - INFO - root - 成功添加图片 7：./export\images_Q-Sched_ Pushing the Boundaries of Few-Step Diffusion Models with Quantization-A\figure_7_page3.png
2025-11-09 23:35:49,930 - INFO - root - 成功添加图片 8：./export\images_Q-Sched_ Pushing the Boundaries of Few-Step Diffusion Models with Quantization-A\figure_8_page16.png
2025-11-09 23:35:49,930 - INFO - root - 成功添加图片 9：./export\images_Q-Sched_ Pushing the Boundaries of Few-Step Diffusion Models with Quantization-A\figure_9_page16.png
2025-11-09 23:35:49,930 - INFO - root - 成功添加图片 10：./export\images_Q-Sched_ Pushing the Boundaries of Few-Step Diffusion Models with Quantization-A\figure_10_page9.png
2025-11-09 23:35:49,933 - INFO - root - 论文《Q-Sched: Pushing the Boundaries of Few-Step Diffusion Models with Quantization-Aware Scheduling》的分析已保存到 ./export\Q-Sched_ Pushing the Boundaries of Few-Step Diffusion Models with Quantization-A.md
2025-11-09 23:35:49,944 - INFO - root - 正在总结论文 72/80: Quantization Meets OOD: Generalizable Quantization-aware Training from a Flatness Perspective
2025-11-09 23:36:01,122 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 23:36:01,123 - INFO - root - LLMClient: rate limit reached, sleeping 14.7s
2025-11-09 23:37:09,842 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 23:37:44,192 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 23:37:44,194 - INFO - root - 正在提取论文图片...
2025-11-09 23:37:46,699 - INFO - root - 已保存图片 1/10：./export\images_Quantization Meets OOD_ Generalizable Quantization-aware Training from a Flatnes\figure_1_page8.png
2025-11-09 23:37:46,850 - INFO - root - 已保存图片 2/10：./export\images_Quantization Meets OOD_ Generalizable Quantization-aware Training from a Flatnes\figure_2_page8.png
2025-11-09 23:37:47,029 - INFO - root - 已保存图片 3/10：./export\images_Quantization Meets OOD_ Generalizable Quantization-aware Training from a Flatnes\figure_3_page8.png
2025-11-09 23:37:47,220 - INFO - root - 已保存图片 4/10：./export\images_Quantization Meets OOD_ Generalizable Quantization-aware Training from a Flatnes\figure_4_page8.png
2025-11-09 23:37:47,438 - INFO - root - 已保存图片 5/10：./export\images_Quantization Meets OOD_ Generalizable Quantization-aware Training from a Flatnes\figure_5_page8.png
2025-11-09 23:37:47,621 - INFO - root - 已保存图片 6/10：./export\images_Quantization Meets OOD_ Generalizable Quantization-aware Training from a Flatnes\figure_6_page8.png
2025-11-09 23:37:47,801 - INFO - root - 已保存图片 7/10：./export\images_Quantization Meets OOD_ Generalizable Quantization-aware Training from a Flatnes\figure_7_page8.png
2025-11-09 23:37:47,974 - INFO - root - 已保存图片 8/10：./export\images_Quantization Meets OOD_ Generalizable Quantization-aware Training from a Flatnes\figure_8_page8.png
2025-11-09 23:37:48,067 - INFO - root - 已保存图片 9/10：./export\images_Quantization Meets OOD_ Generalizable Quantization-aware Training from a Flatnes\figure_9_page12.jpeg
2025-11-09 23:37:48,153 - INFO - root - 已保存图片 10/10：./export\images_Quantization Meets OOD_ Generalizable Quantization-aware Training from a Flatnes\figure_10_page12.jpeg
2025-11-09 23:37:48,163 - INFO - root - 成功添加图片 1：./export\images_Quantization Meets OOD_ Generalizable Quantization-aware Training from a Flatnes\figure_1_page8.png
2025-11-09 23:37:48,163 - INFO - root - 成功添加图片 2：./export\images_Quantization Meets OOD_ Generalizable Quantization-aware Training from a Flatnes\figure_2_page8.png
2025-11-09 23:37:48,164 - INFO - root - 成功添加图片 3：./export\images_Quantization Meets OOD_ Generalizable Quantization-aware Training from a Flatnes\figure_3_page8.png
2025-11-09 23:37:48,165 - INFO - root - 成功添加图片 4：./export\images_Quantization Meets OOD_ Generalizable Quantization-aware Training from a Flatnes\figure_4_page8.png
2025-11-09 23:37:48,166 - INFO - root - 成功添加图片 5：./export\images_Quantization Meets OOD_ Generalizable Quantization-aware Training from a Flatnes\figure_5_page8.png
2025-11-09 23:37:48,166 - INFO - root - 成功添加图片 6：./export\images_Quantization Meets OOD_ Generalizable Quantization-aware Training from a Flatnes\figure_6_page8.png
2025-11-09 23:37:48,167 - INFO - root - 成功添加图片 7：./export\images_Quantization Meets OOD_ Generalizable Quantization-aware Training from a Flatnes\figure_7_page8.png
2025-11-09 23:37:48,167 - INFO - root - 成功添加图片 8：./export\images_Quantization Meets OOD_ Generalizable Quantization-aware Training from a Flatnes\figure_8_page8.png
2025-11-09 23:37:48,171 - INFO - root - 成功添加图片 9：./export\images_Quantization Meets OOD_ Generalizable Quantization-aware Training from a Flatnes\figure_9_page12.jpeg
2025-11-09 23:37:48,172 - INFO - root - 成功添加图片 10：./export\images_Quantization Meets OOD_ Generalizable Quantization-aware Training from a Flatnes\figure_10_page12.jpeg
2025-11-09 23:37:48,179 - INFO - root - 论文《Quantization Meets OOD: Generalizable Quantization-aware Training from a Flatness Perspective》的分析已保存到 ./export\Quantization Meets OOD_ Generalizable Quantization-aware Training from a Flatnes.md
2025-11-09 23:37:48,188 - INFO - root - 正在总结论文 73/80: Progressive Element-wise Gradient Estimation for Neural Network Quantization
2025-11-09 23:38:02,142 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 23:38:02,143 - INFO - root - LLMClient: rate limit reached, sleeping 7.7s
2025-11-09 23:39:10,469 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 23:39:44,856 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 23:39:44,857 - INFO - root - 正在提取论文图片...
2025-11-09 23:39:44,875 - INFO - root - 论文《Progressive Element-wise Gradient Estimation for Neural Network Quantization》的分析已保存到 ./export\Progressive Element-wise Gradient Estimation for Neural Network Quantization.md
2025-11-09 23:39:44,883 - INFO - root - 正在总结论文 74/80: End-to-End On-Device Quantization-Aware Training for LLMs at Inference Cost
2025-11-09 23:39:56,861 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 23:39:56,891 - INFO - root - LLMClient: rate limit reached, sleeping 13.6s
2025-11-09 23:41:14,382 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 23:41:50,601 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 23:41:50,605 - INFO - root - 正在提取论文图片...
2025-11-09 23:41:51,306 - INFO - root - 已保存图片 1/10：./export\images_End-to-End On-Device Quantization-Aware Training for LLMs at Inference Cost\figure_1_page6.png
2025-11-09 23:41:51,386 - INFO - root - 已保存图片 2/10：./export\images_End-to-End On-Device Quantization-Aware Training for LLMs at Inference Cost\figure_2_page6.png
2025-11-09 23:41:51,460 - INFO - root - 已保存图片 3/10：./export\images_End-to-End On-Device Quantization-Aware Training for LLMs at Inference Cost\figure_3_page6.png
2025-11-09 23:41:51,542 - INFO - root - 已保存图片 4/10：./export\images_End-to-End On-Device Quantization-Aware Training for LLMs at Inference Cost\figure_4_page6.png
2025-11-09 23:41:51,612 - INFO - root - 已保存图片 5/10：./export\images_End-to-End On-Device Quantization-Aware Training for LLMs at Inference Cost\figure_5_page6.png
2025-11-09 23:41:51,706 - INFO - root - 已保存图片 6/10：./export\images_End-to-End On-Device Quantization-Aware Training for LLMs at Inference Cost\figure_6_page6.png
2025-11-09 23:41:51,808 - INFO - root - 已保存图片 7/10：./export\images_End-to-End On-Device Quantization-Aware Training for LLMs at Inference Cost\figure_7_page6.png
2025-11-09 23:41:51,926 - INFO - root - 已保存图片 8/10：./export\images_End-to-End On-Device Quantization-Aware Training for LLMs at Inference Cost\figure_8_page6.png
2025-11-09 23:41:52,045 - INFO - root - 已保存图片 9/10：./export\images_End-to-End On-Device Quantization-Aware Training for LLMs at Inference Cost\figure_9_page6.png
2025-11-09 23:41:52,209 - INFO - root - 已保存图片 10/10：./export\images_End-to-End On-Device Quantization-Aware Training for LLMs at Inference Cost\figure_10_page6.png
2025-11-09 23:41:52,211 - INFO - root - 成功添加图片 1：./export\images_End-to-End On-Device Quantization-Aware Training for LLMs at Inference Cost\figure_1_page6.png
2025-11-09 23:41:52,212 - INFO - root - 成功添加图片 2：./export\images_End-to-End On-Device Quantization-Aware Training for LLMs at Inference Cost\figure_2_page6.png
2025-11-09 23:41:52,212 - INFO - root - 成功添加图片 3：./export\images_End-to-End On-Device Quantization-Aware Training for LLMs at Inference Cost\figure_3_page6.png
2025-11-09 23:41:52,213 - INFO - root - 成功添加图片 4：./export\images_End-to-End On-Device Quantization-Aware Training for LLMs at Inference Cost\figure_4_page6.png
2025-11-09 23:41:52,214 - INFO - root - 成功添加图片 5：./export\images_End-to-End On-Device Quantization-Aware Training for LLMs at Inference Cost\figure_5_page6.png
2025-11-09 23:41:52,214 - INFO - root - 成功添加图片 6：./export\images_End-to-End On-Device Quantization-Aware Training for LLMs at Inference Cost\figure_6_page6.png
2025-11-09 23:41:52,215 - INFO - root - 成功添加图片 7：./export\images_End-to-End On-Device Quantization-Aware Training for LLMs at Inference Cost\figure_7_page6.png
2025-11-09 23:41:52,215 - INFO - root - 成功添加图片 8：./export\images_End-to-End On-Device Quantization-Aware Training for LLMs at Inference Cost\figure_8_page6.png
2025-11-09 23:41:52,217 - INFO - root - 成功添加图片 9：./export\images_End-to-End On-Device Quantization-Aware Training for LLMs at Inference Cost\figure_9_page6.png
2025-11-09 23:41:52,218 - INFO - root - 成功添加图片 10：./export\images_End-to-End On-Device Quantization-Aware Training for LLMs at Inference Cost\figure_10_page6.png
2025-11-09 23:41:52,224 - INFO - root - 论文《End-to-End On-Device Quantization-Aware Training for LLMs at Inference Cost》的分析已保存到 ./export\End-to-End On-Device Quantization-Aware Training for LLMs at Inference Cost.md
2025-11-09 23:41:52,230 - INFO - root - 正在总结论文 75/80: Quantization Robustness to Input Degradations for Object Detection
2025-11-09 23:42:08,037 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 23:42:08,042 - INFO - root - LLMClient: rate limit reached, sleeping 6.3s
2025-11-09 23:43:10,780 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 23:43:48,038 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 23:43:48,042 - INFO - root - 正在提取论文图片...
2025-11-09 23:43:48,062 - INFO - root - 论文《Quantization Robustness to Input Degradations for Object Detection》的分析已保存到 ./export\Quantization Robustness to Input Degradations for Object Detection.md
2025-11-09 23:43:48,067 - INFO - root - 正在总结论文 76/80: Scaling Laws for Task-Stratified Knowledge in Post-Training Quantized Large Language Models
2025-11-09 23:44:00,197 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 23:44:00,198 - INFO - root - LLMClient: rate limit reached, sleeping 10.6s
2025-11-09 23:45:04,388 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 23:45:37,193 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 23:45:37,195 - INFO - root - 正在提取论文图片...
2025-11-09 23:45:37,610 - INFO - root - 已保存图片 1/10：./export\images_Scaling Laws for Task-Stratified Knowledge in Post-Training Quantized Large Lang\figure_1_page8.png
2025-11-09 23:45:37,611 - INFO - root - 成功添加图片 1：./export\images_Scaling Laws for Task-Stratified Knowledge in Post-Training Quantized Large Lang\figure_1_page8.png
2025-11-09 23:45:37,622 - INFO - root - 论文《Scaling Laws for Task-Stratified Knowledge in Post-Training Quantized Large Language Models》的分析已保存到 ./export\Scaling Laws for Task-Stratified Knowledge in Post-Training Quantized Large Lang.md
2025-11-09 23:45:37,633 - INFO - root - 正在总结论文 77/80: AQ-PCDSys: An Adaptive Quantized Planetary Crater Detection System for Autonomous Space Exploration
2025-11-09 23:45:48,573 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 23:45:48,575 - INFO - root - LLMClient: rate limit reached, sleeping 15.8s
2025-11-09 23:46:55,033 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 23:47:30,402 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 23:47:30,408 - INFO - root - 正在提取论文图片...
2025-11-09 23:47:30,428 - INFO - root - 论文《AQ-PCDSys: An Adaptive Quantized Planetary Crater Detection System for Autonomous Space Exploration》的分析已保存到 ./export\AQ-PCDSys_ An Adaptive Quantized Planetary Crater Detection System for Autonomou.md
2025-11-09 23:47:30,437 - INFO - root - 正在总结论文 78/80: TaDiCodec: Text-aware Diffusion Speech Tokenizer for Speech Language Modeling
2025-11-09 23:47:41,871 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 23:47:41,874 - INFO - root - LLMClient: rate limit reached, sleeping 13.2s
2025-11-09 23:48:48,500 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 23:49:22,358 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 23:49:22,364 - INFO - root - 正在提取论文图片...
2025-11-09 23:49:22,744 - INFO - root - 已保存图片 1/10：./export\images_TaDiCodec_ Text-aware Diffusion Speech Tokenizer for Speech Language Modeling\figure_1_page22.png
2025-11-09 23:49:22,751 - INFO - root - 成功添加图片 1：./export\images_TaDiCodec_ Text-aware Diffusion Speech Tokenizer for Speech Language Modeling\figure_1_page22.png
2025-11-09 23:49:22,754 - INFO - root - 论文《TaDiCodec: Text-aware Diffusion Speech Tokenizer for Speech Language Modeling》的分析已保存到 ./export\TaDiCodec_ Text-aware Diffusion Speech Tokenizer for Speech Language Modeling.md
2025-11-09 23:49:22,764 - INFO - root - 正在总结论文 79/80: A Node-Aware Dynamic Quantization Approach for Graph Collaborative Filtering
2025-11-09 23:49:42,402 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 23:49:42,404 - INFO - root - LLMClient: rate limit reached, sleeping 6.1s
2025-11-09 23:50:45,375 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 23:51:29,547 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 23:51:29,554 - INFO - root - 正在提取论文图片...
2025-11-09 23:51:31,371 - INFO - root - 已保存图片 1/10：./export\images_A Node-Aware Dynamic Quantization Approach for Graph Collaborative Filtering\figure_1_page4.png
2025-11-09 23:51:31,623 - INFO - root - 已保存图片 2/10：./export\images_A Node-Aware Dynamic Quantization Approach for Graph Collaborative Filtering\figure_2_page7.png
2025-11-09 23:51:31,824 - INFO - root - 已保存图片 3/10：./export\images_A Node-Aware Dynamic Quantization Approach for Graph Collaborative Filtering\figure_3_page2.png
2025-11-09 23:51:31,915 - INFO - root - 已保存图片 4/10：./export\images_A Node-Aware Dynamic Quantization Approach for Graph Collaborative Filtering\figure_4_page6.png
2025-11-09 23:51:31,936 - INFO - root - 成功添加图片 1：./export\images_A Node-Aware Dynamic Quantization Approach for Graph Collaborative Filtering\figure_1_page4.png
2025-11-09 23:51:31,940 - INFO - root - 成功添加图片 2：./export\images_A Node-Aware Dynamic Quantization Approach for Graph Collaborative Filtering\figure_2_page7.png
2025-11-09 23:51:31,941 - INFO - root - 成功添加图片 3：./export\images_A Node-Aware Dynamic Quantization Approach for Graph Collaborative Filtering\figure_3_page2.png
2025-11-09 23:51:31,942 - INFO - root - 成功添加图片 4：./export\images_A Node-Aware Dynamic Quantization Approach for Graph Collaborative Filtering\figure_4_page6.png
2025-11-09 23:51:31,955 - INFO - root - 论文《A Node-Aware Dynamic Quantization Approach for Graph Collaborative Filtering》的分析已保存到 ./export\A Node-Aware Dynamic Quantization Approach for Graph Collaborative Filtering.md
2025-11-09 23:51:31,959 - INFO - root - 正在总结论文 80/80: JEDI-linear: Fast and Efficient Graph Neural Networks for Jet Tagging on FPGAs
2025-11-09 23:51:45,016 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 23:51:45,017 - INFO - root - LLMClient: rate limit reached, sleeping 0.4s
2025-11-09 23:52:35,452 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 23:53:04,401 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 23:53:04,403 - INFO - root - 正在提取论文图片...
2025-11-09 23:53:04,689 - INFO - root - 已保存图片 1/10：./export\images_JEDI-linear_ Fast and Efficient Graph Neural Networks for Jet Tagging on FPGAs\figure_1_page6.jpeg
2025-11-09 23:53:04,753 - INFO - root - 已保存图片 2/10：./export\images_JEDI-linear_ Fast and Efficient Graph Neural Networks for Jet Tagging on FPGAs\figure_2_page6.jpeg
2025-11-09 23:53:04,809 - INFO - root - 已保存图片 3/10：./export\images_JEDI-linear_ Fast and Efficient Graph Neural Networks for Jet Tagging on FPGAs\figure_3_page7.jpeg
2025-11-09 23:53:04,854 - INFO - root - 已保存图片 4/10：./export\images_JEDI-linear_ Fast and Efficient Graph Neural Networks for Jet Tagging on FPGAs\figure_4_page7.jpeg
2025-11-09 23:53:04,909 - INFO - root - 已保存图片 5/10：./export\images_JEDI-linear_ Fast and Efficient Graph Neural Networks for Jet Tagging on FPGAs\figure_5_page6.jpeg
2025-11-09 23:53:04,952 - INFO - root - 已保存图片 6/10：./export\images_JEDI-linear_ Fast and Efficient Graph Neural Networks for Jet Tagging on FPGAs\figure_6_page2.jpeg
2025-11-09 23:53:05,055 - INFO - root - 已保存图片 7/10：./export\images_JEDI-linear_ Fast and Efficient Graph Neural Networks for Jet Tagging on FPGAs\figure_7_page5.png
2025-11-09 23:53:05,057 - INFO - root - 成功添加图片 1：./export\images_JEDI-linear_ Fast and Efficient Graph Neural Networks for Jet Tagging on FPGAs\figure_1_page6.jpeg
2025-11-09 23:53:05,058 - INFO - root - 成功添加图片 2：./export\images_JEDI-linear_ Fast and Efficient Graph Neural Networks for Jet Tagging on FPGAs\figure_2_page6.jpeg
2025-11-09 23:53:05,058 - INFO - root - 成功添加图片 3：./export\images_JEDI-linear_ Fast and Efficient Graph Neural Networks for Jet Tagging on FPGAs\figure_3_page7.jpeg
2025-11-09 23:53:05,059 - INFO - root - 成功添加图片 4：./export\images_JEDI-linear_ Fast and Efficient Graph Neural Networks for Jet Tagging on FPGAs\figure_4_page7.jpeg
2025-11-09 23:53:05,059 - INFO - root - 成功添加图片 5：./export\images_JEDI-linear_ Fast and Efficient Graph Neural Networks for Jet Tagging on FPGAs\figure_5_page6.jpeg
2025-11-09 23:53:05,059 - INFO - root - 成功添加图片 6：./export\images_JEDI-linear_ Fast and Efficient Graph Neural Networks for Jet Tagging on FPGAs\figure_6_page2.jpeg
2025-11-09 23:53:05,060 - INFO - root - 成功添加图片 7：./export\images_JEDI-linear_ Fast and Efficient Graph Neural Networks for Jet Tagging on FPGAs\figure_7_page5.png
2025-11-09 23:53:05,066 - INFO - root - 论文《JEDI-linear: Fast and Efficient Graph Neural Networks for Jet Tagging on FPGAs》的分析已保存到 ./export\JEDI-linear_ Fast and Efficient Graph Neural Networks for Jet Tagging on FPGAs.md
2025-11-09 23:53:05,077 - INFO - root - summary time: 5370.35 seconds
2025-11-10 22:57:34,877 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-10 22:57:34,885 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-10 22:57:34,906 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-10 22:58:38,105 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-10 22:58:38,107 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-10 22:58:38,109 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-10 22:58:39,202 - INFO - root - LLMClientManager: 指定使用客户端: DeepSeek
2025-11-10 22:58:39,202 - INFO - root - DeepSeekClient: API key found: 9f9e270e-b...
2025-11-10 22:58:39,204 - INFO - root - DeepSeekClient: 使用模式: 火山引擎
2025-11-10 22:58:39,204 - INFO - root - DeepSeekClient: 模型名称: deepseek-v3-1-terminus
2025-11-10 22:58:43,423 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-10 22:58:43,441 - INFO - root - DeepSeekClient: initialized successfully with model deepseek-v3-1-terminus
2025-11-10 22:58:43,442 - INFO - root - LLMClientManager: DeepSeek 客户端初始化成功
2025-11-10 22:58:43,442 - INFO - root - LLMClientManager: switched to DeepSeek client
2025-11-10 22:58:43,443 - INFO - root - 已手动切换到 LLM 客户端: DeepSeek
2025-11-10 22:58:43,443 - INFO - root - 使用 LLM 模型: deepseek-v3-1-terminus
2025-11-10 22:58:43,444 - INFO - root - 可用客户端: ['DeepSeek']
2025-11-10 22:58:43,445 - INFO - root - === 运行配置 ===
2025-11-10 22:58:43,445 - INFO - root - 处理模式: arxiv在线搜索
2025-11-10 22:58:43,446 - INFO - root - 关键词: QAT
2025-11-10 22:58:43,447 - INFO - root - 查询: CVPR 2025
2025-11-10 22:58:43,452 - INFO - root - 排序: None
2025-11-10 22:58:43,457 - INFO - root - 最近天数: 180
2025-11-10 22:58:43,457 - INFO - root - 最大处理数量: 2
2025-11-10 22:58:43,459 - INFO - root - 保存图片: 是
2025-11-10 22:58:43,459 - INFO - root - 输出语言: 中文
2025-11-10 22:58:43,460 - INFO - root - 强制重新处理: 否
2025-11-10 22:58:43,460 - INFO - root - ====================
2025-11-10 22:58:43,460 - INFO - root - 使用 arXiv 搜索模式（通过 chat_arxiv 模块获取）
2025-11-10 22:58:43,461 - INFO - root - Fetching page 1 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50
2025-11-10 22:59:07,882 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-10 22:59:07,883 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-10 22:59:07,885 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-10 22:59:08,759 - INFO - root - LLMClientManager: 指定使用客户端: Gemini
2025-11-10 22:59:09,607 - INFO - root - GeminiClient: trying model models/gemini-2.5-flash
2025-11-10 22:59:13,513 - INFO - root - GeminiClient: initialized model gemini-2.5-flash
2025-11-10 22:59:13,514 - INFO - root - LLMClientManager: Gemini 客户端初始化成功
2025-11-10 22:59:13,514 - INFO - root - LLMClientManager: switched to Gemini client
2025-11-10 22:59:13,514 - INFO - root - 已手动切换到 LLM 客户端: Gemini
2025-11-10 22:59:13,515 - INFO - root - 使用 LLM 模型: gemini-2.5-flash
2025-11-10 22:59:13,515 - INFO - root - 可用客户端: ['Gemini']
2025-11-10 22:59:13,515 - INFO - root - === 运行配置 ===
2025-11-10 22:59:13,516 - INFO - root - 处理模式: arxiv在线搜索
2025-11-10 22:59:13,516 - INFO - root - 关键词: QAT
2025-11-10 22:59:13,516 - INFO - root - 查询: CVPR 2025
2025-11-10 22:59:13,517 - INFO - root - 排序: None
2025-11-10 22:59:13,517 - INFO - root - 最近天数: 180
2025-11-10 22:59:13,517 - INFO - root - 最大处理数量: 2
2025-11-10 22:59:13,518 - INFO - root - 保存图片: 是
2025-11-10 22:59:13,518 - INFO - root - 输出语言: 中文
2025-11-10 22:59:13,518 - INFO - root - 强制重新处理: 否
2025-11-10 22:59:13,518 - INFO - root - ====================
2025-11-10 22:59:13,519 - INFO - root - 使用 arXiv 搜索模式（通过 chat_arxiv 模块获取）
2025-11-10 22:59:13,519 - INFO - root - Fetching page 1 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50
2025-11-10 22:59:21,010 - INFO - root - get_all_titles_from_web 
2025-11-10 22:59:21,011 - INFO - root - Page:0, Index:0, Learning to Seek Evidence: A Verifiable Reasoning Agent with Causal Faithfulness Analysis, https://arxiv.org/pdf/2511.01425, 2025-11-03
2025-11-10 22:59:21,011 - INFO - root - Page:0, Index:1, OmniTrack++: Omnidirectional Multi-Object Tracking by Learning Large-FoV Trajectory Feedback, https://arxiv.org/pdf/2511.00510, 2025-11-01
2025-11-10 22:59:21,011 - INFO - root - Page:0, Index:2, NeuCo-Bench: A Novel Benchmark Framework for Neural Embeddings in Earth Observation, https://arxiv.org/pdf/2510.17914, 2025-10-19
2025-11-10 22:59:21,011 - INFO - root - Page:0, Index:3, NTIRE 2025 Challenge on Low Light Image Enhancement: Methods and Results, https://arxiv.org/pdf/2510.13670, 2025-10-15
2025-11-10 22:59:21,012 - INFO - root - Page:0, Index:4, Class Prototypes based Contrastive Learning for Classifying Multi-Label and Fine-Grained Educational Videos, https://arxiv.org/pdf/2510.11204, 2025-10-13
2025-11-10 22:59:21,012 - INFO - root - Page:0, Index:5, MIMO: A medical vision language model with visual referring multimodal input and pixel grounding multimodal output, https://arxiv.org/pdf/2510.10011, 2025-10-11
2025-11-10 22:59:21,012 - INFO - root - Page:0, Index:6, Vision Language Models: A Survey of 26K Papers, https://arxiv.org/pdf/2510.09586, 2025-10-10
2025-11-10 22:59:21,012 - INFO - root - Page:0, Index:7, DiT-VTON: Diffusion Transformer Framework for Unified Multi-Category Virtual Try-On and Virtual Try-All with Integrated Image Editing, https://arxiv.org/pdf/2510.04797, 2025-10-03
2025-11-10 22:59:21,012 - INFO - root - Page:0, Index:8, PatchVSR: Breaking Video Diffusion Resolution Limits with Patch-wise Video Super-Resolution, https://arxiv.org/pdf/2509.26025, 2025-09-30
2025-11-10 22:59:21,013 - INFO - root - Page:0, Index:9, FreqDebias: Towards Generalizable Deepfake Detection via Consistency-Driven Frequency Debiasing, https://arxiv.org/pdf/2509.22412, 2025-09-26
2025-11-10 22:59:21,013 - INFO - root - Page:0, Index:10, A Mutual Learning Method for Salient Object Detection with intertwined Multi-Supervision--Revised, https://arxiv.org/pdf/2509.21363, 2025-09-21
2025-11-10 22:59:21,013 - INFO - root - Page:0, Index:11, InstructVTON: Optimal Auto-Masking and Natural-Language-Guided Interactive Style Control for Inpainting-Based Virtual Try-On, https://arxiv.org/pdf/2509.20524, 2025-09-24
2025-11-10 22:59:21,013 - INFO - root - Page:0, Index:12, Efficient Encoder-Free Pose Conditioning and Pose Control for Virtual Try-On, https://arxiv.org/pdf/2509.20343, 2025-09-24
2025-11-10 22:59:21,014 - INFO - root - Page:0, Index:13, The Photographer Eye: Teaching Multimodal Large Language Models to Understand Image Aesthetics like Photographers, https://arxiv.org/pdf/2509.18582, 2025-10-22
2025-11-10 22:59:21,014 - INFO - root - Page:0, Index:14, ENSAM: an efficient foundation model for interactive segmentation of 3D medical images, https://arxiv.org/pdf/2509.15874, 2025-09-19
2025-11-10 22:59:21,014 - INFO - root - Page:0, Index:15, DEFT-VTON: Efficient Virtual Try-On with Consistent Generalised H-Transform, https://arxiv.org/pdf/2509.13506, 2025-09-16
2025-11-10 22:59:21,014 - INFO - root - Page:0, Index:16, Weakly and Self-Supervised Class-Agnostic Motion Prediction for Autonomous Driving, https://arxiv.org/pdf/2509.13116, 2025-09-16
2025-11-10 22:59:21,016 - INFO - root - Page:0, Index:17, Domain-Adaptive Pretraining Improves Primate Behavior Recognition, https://arxiv.org/pdf/2509.12193, 2025-09-15
2025-11-10 22:59:21,016 - INFO - root - Page:0, Index:18, The System Description of CPS Team for Track on Driving with Language of CVPR 2024 Autonomous Grand Challenge, https://arxiv.org/pdf/2509.11071, 2025-09-13
2025-11-10 22:59:21,016 - INFO - root - Page:0, Index:19, An HMM-based framework for identity-aware long-term multi-object tracking from sparse and uncertain identification: use case on long-term tracking in livestock, https://arxiv.org/pdf/2509.09962, 2025-09-12
2025-11-10 22:59:21,017 - INFO - root - Page:0, Index:20, InterAct: Advancing Large-Scale Versatile 3D Human-Object Interaction Generation, https://arxiv.org/pdf/2509.09555, 2025-09-11
2025-11-10 22:59:21,022 - INFO - root - Page:0, Index:21, Geospatial Foundational Embedder: Top-1 Winning Solution on EarthVision Embed2Scale Challenge (CVPR 2025), https://arxiv.org/pdf/2509.06993, 2025-09-03
2025-11-10 22:59:21,022 - INFO - root - Page:0, Index:22, 2nd Place Solution for CVPR2024 E2E Challenge: End-to-End Autonomous Driving Using Vision Language Model, https://arxiv.org/pdf/2509.02659, 2025-09-02
2025-11-10 22:59:21,022 - INFO - root - Page:0, Index:23, Unsupervised Training of Vision Transformers with Synthetic Negatives, https://arxiv.org/pdf/2509.02024, 2025-09-02
2025-11-10 22:59:21,023 - INFO - root - Page:0, Index:24, MV-SSM: Multi-View State Space Modeling for 3D Human Pose Estimation, https://arxiv.org/pdf/2509.00649, 2025-08-30
2025-11-10 22:59:21,023 - INFO - root - Page:0, Index:25, CryptoFace: End-to-End Encrypted Face Recognition, https://arxiv.org/pdf/2509.00332, 2025-08-29
2025-11-10 22:59:21,023 - INFO - root - Page:0, Index:26, ControlEchoSynth: Boosting Ejection Fraction Estimation Models via Controlled Video Diffusion, https://arxiv.org/pdf/2508.17631, 2025-08-26
2025-11-10 22:59:21,024 - INFO - root - Page:0, Index:27, Explain Before You Answer: A Survey on Compositional Visual Reasoning, https://arxiv.org/pdf/2508.17298, 2025-08-27
2025-11-10 22:59:21,024 - INFO - root - Page:0, Index:28, Investigating Different Geo Priors for Image Classification, https://arxiv.org/pdf/2508.15946, 2025-08-21
2025-11-10 22:59:21,024 - INFO - root - Page:0, Index:29, Towards Source-Free Machine Unlearning, https://arxiv.org/pdf/2508.15127, 2025-08-20
2025-11-10 22:59:21,024 - INFO - root - Page:0, Index:30, MR6D: Benchmarking 6D Pose Estimation for Mobile Robots, https://arxiv.org/pdf/2508.13775, 2025-08-19
2025-11-10 22:59:21,026 - INFO - root - Page:0, Index:31, Calibrating Biased Distribution in VFM-derived Latent Space via Cross-Domain Geometric Consistency, https://arxiv.org/pdf/2508.13518, 2025-08-19
2025-11-10 22:59:21,026 - INFO - root - Page:0, Index:32, SIS-Challenge: Event-based Spatio-temporal Instance Segmentation Challenge at the CVPR 2025 Event-based Vision Workshop, https://arxiv.org/pdf/2508.12813, 2025-08-18
2025-11-10 22:59:21,026 - INFO - root - Page:0, Index:33, Multi-Level Knowledge Distillation and Dynamic Self-Supervised Learning for Continual Learning, https://arxiv.org/pdf/2508.12692, 2025-08-22
2025-11-10 22:59:21,026 - INFO - root - Page:0, Index:34, Stochastic-based Patch Filtering for Few-Shot Learning, https://arxiv.org/pdf/2508.10066, 2025-08-13
2025-11-10 22:59:21,027 - INFO - root - Page:0, Index:35, Slot Attention-based Feature Filtering for Few-Shot Learning, https://arxiv.org/pdf/2508.09699, 2025-08-13
2025-11-10 22:59:21,027 - INFO - root - Page:0, Index:36, Comparison Reveals Commonality: Customized Image Generation through Contrastive Inversion, https://arxiv.org/pdf/2508.07755, 2025-08-11
2025-11-10 22:59:21,028 - INFO - root - Page:0, Index:37, SLRTP2025 Sign Language Production Challenge: Methodology, Results, and Future Work, https://arxiv.org/pdf/2508.06951, 2025-08-09
2025-11-10 22:59:21,029 - INFO - root - Page:0, Index:38, Exploring Fairness across Fine-Grained Attributes in Large Vision-Language Models, https://arxiv.org/pdf/2508.03079, 2025-08-05
2025-11-10 22:59:21,029 - INFO - root - Page:0, Index:39, Devil is in the Detail: Towards Injecting Fine Details of Image Prompt in Image Generation via Conflict-free Guidance and Stratified Attention, https://arxiv.org/pdf/2508.02004, 2025-08-03
2025-11-10 22:59:21,029 - INFO - root - Page:0, Index:40, IAUNet: Instance-Aware U-Net, https://arxiv.org/pdf/2508.01928, 2025-08-03
2025-11-10 22:59:21,030 - INFO - root - Page:0, Index:41, Gaussian Splatting Feature Fields for Privacy-Preserving Visual Localization, https://arxiv.org/pdf/2507.23569, 2025-08-26
2025-11-10 22:59:21,030 - INFO - root - Page:0, Index:42, From Scan to Action: Leveraging Realistic Scans for Embodied Scene Understanding, https://arxiv.org/pdf/2507.17585, 2025-07-23
2025-11-10 22:59:21,031 - INFO - root - Page:0, Index:43, LEAD: Exploring Logit Space Evolution for Model Selection, https://arxiv.org/pdf/2507.14559, 2025-07-19
2025-11-10 22:59:21,031 - INFO - root - Page:0, Index:44, HeCoFuse: Cross-Modal Complementary V2X Cooperative Perception with Heterogeneous Sensors, https://arxiv.org/pdf/2507.13677, 2025-07-18
2025-11-10 22:59:21,033 - INFO - root - Page:0, Index:45, OmniVec2 -- A Novel Transformer based Network for Large Scale Multimodal and Multitask Learning, https://arxiv.org/pdf/2507.13364, 2025-07-06
2025-11-10 22:59:21,033 - INFO - root - Page:0, Index:46, A Training-Free, Task-Agnostic Framework for Enhancing MLLM Performance on High-Resolution Images, https://arxiv.org/pdf/2507.10202, 2025-07-14
2025-11-10 22:59:21,034 - INFO - root - Page:0, Index:47, Quantum Federated Learning for Multimodal Data: A Modality-Agnostic Approach, https://arxiv.org/pdf/2507.08217, 2025-07-10
2025-11-10 22:59:21,034 - INFO - root - Page:0, Index:48, CuriosAI Submission to the EgoExo4D Proficiency Estimation Challenge 2025, https://arxiv.org/pdf/2507.08022, 2025-07-08
2025-11-10 22:59:21,034 - INFO - root - Page:0, Index:49, Rethinking Query-based Transformer for Continual Image Segmentation, https://arxiv.org/pdf/2507.07831, 2025-07-10
2025-11-10 22:59:21,035 - INFO - root - Fetching page 2 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=50
2025-11-10 22:59:27,771 - INFO - root - get_all_titles_from_web 
2025-11-10 22:59:27,771 - INFO - root - Page:1, Index:0, Scalable and Realistic Virtual Try-on Application for Foundation Makeup with Kubelka-Munk Theory, https://arxiv.org/pdf/2507.07333, 2025-07-09
2025-11-10 22:59:27,771 - INFO - root - Page:1, Index:1, Free on the Fly: Enhancing Flexibility in Test-Time Adaptation with Online EM, https://arxiv.org/pdf/2507.06973, 2025-07-09
2025-11-10 22:59:27,772 - INFO - root - Page:1, Index:2, Adaptive Part Learning for Fine-Grained Generalized Category Discovery: A Plug-and-Play Enhancement, https://arxiv.org/pdf/2507.06928, 2025-07-09
2025-11-10 22:59:27,772 - INFO - root - Page:1, Index:3, Grounded Gesture Generation: Language, Motion, and Space, https://arxiv.org/pdf/2507.04522, 2025-07-06
2025-11-10 22:59:27,772 - INFO - root - Page:1, Index:4, Comprehensive Information Bottleneck for Unveiling Universal Attribution to Interpret Vision Transformers, https://arxiv.org/pdf/2507.04388, 2025-07-06
2025-11-10 22:59:27,772 - INFO - root - Page:1, Index:5, ZERO: Industry-ready Vision Foundation Model with Multi-modal Prompts, https://arxiv.org/pdf/2507.04270, 2025-11-07
2025-11-10 22:59:27,772 - INFO - root - Page:1, Index:6, Beyond Accuracy: Metrics that Uncover What Makes a 'Good' Visual Descriptor, https://arxiv.org/pdf/2507.03542, 2025-07-08
2025-11-10 22:59:27,773 - INFO - root - Page:1, Index:7, ConceptMix++: Leveling the Playing Field in Text-to-Image Benchmarking via Iterative Prompt Optimization, https://arxiv.org/pdf/2507.03275, 2025-07-03
2025-11-10 22:59:27,773 - INFO - root - Page:1, Index:8, APT: Adaptive Personalized Training for Diffusion Models with Limited Data, https://arxiv.org/pdf/2507.02687, 2025-07-03
2025-11-10 22:59:27,773 - INFO - root - Page:1, Index:9, DreamComposer++: Empowering Diffusion Models with Multi-View Conditions for 3D Content Generation, https://arxiv.org/pdf/2507.02299, 2025-07-03
2025-11-10 22:59:27,773 - INFO - root - Page:1, Index:10, Soft Self-labeling and Potts Relaxations for Weakly-Supervised Segmentation, https://arxiv.org/pdf/2507.01721, 2025-07-02
2025-11-10 22:59:27,773 - INFO - root - Page:1, Index:11, Interpolation-Based Event Visual Data Filtering Algorithms, https://arxiv.org/pdf/2507.01557, 2025-07-02
2025-11-10 22:59:27,780 - INFO - root - Page:1, Index:12, AVC-DPO: Aligned Video Captioning via Direct Preference Optimization, https://arxiv.org/pdf/2507.01492, 2025-07-02
2025-11-10 22:59:27,781 - INFO - root - Page:1, Index:13, NN-Former: Rethinking Graph Structure in Neural Architecture Representation, https://arxiv.org/pdf/2507.00880, 2025-07-01
2025-11-10 22:59:27,782 - INFO - root - Page:1, Index:14, Instant Particle Size Distribution Measurement Using CNNs Trained on Synthetic Data, https://arxiv.org/pdf/2507.00822, 2025-07-01
2025-11-10 22:59:27,782 - INFO - root - Page:1, Index:15, Moment Sampling in Video LLMs for Long-Form Video QA, https://arxiv.org/pdf/2507.00033, 2025-06-17
2025-11-10 22:59:27,782 - INFO - root - Page:1, Index:16, Revisiting Audio-Visual Segmentation with Vision-Centric Transformer, https://arxiv.org/pdf/2506.23623, 2025-06-30
2025-11-10 22:59:27,782 - INFO - root - Page:1, Index:17, MTADiffusion: Mask Text Alignment Diffusion Model for Object Inpainting, https://arxiv.org/pdf/2506.23482, 2025-06-29
2025-11-10 22:59:27,783 - INFO - root - Page:1, Index:18, Benchmarking Generalizable Bimanual Manipulation: RoboTwin Dual-Arm Collaboration Challenge at CVPR 2025 MEIS Workshop, https://arxiv.org/pdf/2506.23351, 2025-07-02
2025-11-10 22:59:27,783 - INFO - root - Page:1, Index:19, Prompting without Panic: Attribute-aware, Zero-shot, Test-Time Calibration, https://arxiv.org/pdf/2506.22819, 2025-06-28
2025-11-10 22:59:27,785 - INFO - root - Page:1, Index:20, Analyzing and Fine-Tuning Whisper Models for Multilingual Pilot Speech Transcription in the Cockpit, https://arxiv.org/pdf/2506.21990, 2025-06-27
2025-11-10 22:59:27,786 - INFO - root - Page:1, Index:21, SceneDiffuser++: City-Scale Traffic Simulation via a Generative World Model, https://arxiv.org/pdf/2506.21976, 2025-06-27
2025-11-10 22:59:27,787 - INFO - root - Page:1, Index:22, DIVE: Deep-search Iterative Video Exploration A Technical Report for the CVRR Challenge at CVPR 2025, https://arxiv.org/pdf/2506.21891, 2025-06-27
2025-11-10 22:59:27,787 - INFO - root - Page:1, Index:23, End-to-End RGB-IR Joint Image Compression With Channel-wise Cross-modality Entropy Model, https://arxiv.org/pdf/2506.21851, 2025-06-26
2025-11-10 22:59:27,788 - INFO - root - Page:1, Index:24, Distilling Normalizing Flows, https://arxiv.org/pdf/2506.21003, 2025-06-26
2025-11-10 22:59:27,788 - INFO - root - Page:1, Index:25, Joint attitude estimation and 3D neural reconstruction of non-cooperative space objects, https://arxiv.org/pdf/2506.20638, 2025-06-25
2025-11-10 22:59:27,788 - INFO - root - Page:1, Index:26, Accept More, Reject Less: Reducing up to 19% Unnecessary Desk-Rejections over 11 Years of ICLR Data, https://arxiv.org/pdf/2506.20141, 2025-06-25
2025-11-10 22:59:27,789 - INFO - root - Page:1, Index:27, SceneCrafter: Controllable Multi-View Driving Scene Editing, https://arxiv.org/pdf/2506.19488, 2025-06-24
2025-11-10 22:59:27,789 - INFO - root - Page:1, Index:28, Emergence of Text Readability in Vision Language Models, https://arxiv.org/pdf/2506.19389, 2025-06-24
2025-11-10 22:59:27,789 - INFO - root - Page:1, Index:29, MedErr-CT: A Visual Question Answering Benchmark for Identifying and Correcting Errors in CT Reports, https://arxiv.org/pdf/2506.19217, 2025-06-23
2025-11-10 22:59:27,790 - INFO - root - Page:1, Index:30, RareSpot: Spotting Small and Rare Wildlife in Aerial Imagery with Multi-Scale Consistency and Context-Aware Augmentation, https://arxiv.org/pdf/2506.19087, 2025-06-23
2025-11-10 22:59:27,793 - INFO - root - Page:1, Index:31, Object-aware Sound Source Localization via Audio-Visual Scene Understanding, https://arxiv.org/pdf/2506.18557, 2025-06-23
2025-11-10 22:59:27,794 - INFO - root - Page:1, Index:32, Rethinking Decoder Design: Improving Biomarker Segmentation Using Depth-to-Space Restoration and Residual Linear Attention, https://arxiv.org/pdf/2506.18335, 2025-06-23
2025-11-10 22:59:27,794 - INFO - root - Page:1, Index:33, Relation3D: Enhancing Relation Modeling for Point Cloud Instance Segmentation, https://arxiv.org/pdf/2506.17891, 2025-06-21
2025-11-10 22:59:27,795 - INFO - root - Page:1, Index:34, HIRE: Lightweight High-Resolution Image Feature Enrichment for Multimodal LLMs, https://arxiv.org/pdf/2506.17608, 2025-06-21
2025-11-10 22:59:27,795 - INFO - root - Page:1, Index:35, Spatially-Aware Evaluation of Segmentation Uncertainty, https://arxiv.org/pdf/2506.16589, 2025-06-19
2025-11-10 22:59:27,797 - INFO - root - Page:1, Index:36, Tripartite Weight-Space Ensemble for Few-Shot Class-Incremental Learning, https://arxiv.org/pdf/2506.15720, 2025-06-03
2025-11-10 22:59:27,797 - INFO - root - Page:1, Index:37, PARC: A Quantitative Framework Uncovering the Symmetries within Vision Language Models, https://arxiv.org/pdf/2506.14808, 2025-06-03
2025-11-10 22:59:27,798 - INFO - root - Page:1, Index:38, Self-supervised Representation Learning with Local Aggregation for Image-based Profiling, https://arxiv.org/pdf/2506.14265, 2025-10-27
2025-11-10 22:59:27,798 - INFO - root - Page:1, Index:39, Towards Robust Learning to Optimize with Theoretical Guarantees, https://arxiv.org/pdf/2506.14263, 2025-06-17
2025-11-10 22:59:27,798 - INFO - root - Page:1, Index:40, Hidden Bias in the Machine: Stereotypes in Text-to-Image Models, https://arxiv.org/pdf/2506.13780, 2025-06-09
2025-11-10 22:59:27,798 - INFO - root - Page:1, Index:41, SmartHome-Bench: A Comprehensive Benchmark for Video Anomaly Detection in Smart Homes Using Multi-Modal Large Language Models, https://arxiv.org/pdf/2506.12992, 2025-06-15
2025-11-10 22:59:27,799 - INFO - root - Page:1, Index:42, Generative 4D Scene Gaussian Splatting with Object View-Synthesis Priors, https://arxiv.org/pdf/2506.12716, 2025-06-15
2025-11-10 22:59:27,801 - INFO - root - Page:1, Index:43, DejaVid: Encoder-Agnostic Learned Temporal Matching for Video Classification, https://arxiv.org/pdf/2506.12585, 2025-06-14
2025-11-10 22:59:27,801 - INFO - root - Page:1, Index:44, Pushing the Limits of Safety: A Technical Report on the ATLAS Challenge 2025, https://arxiv.org/pdf/2506.12430, 2025-07-10
2025-11-10 22:59:27,802 - INFO - root - Page:1, Index:45, FIMA-Q: Post-Training Quantization for Vision Transformers by Fisher Information Matrix Approximation, https://arxiv.org/pdf/2506.11543, 2025-06-13
2025-11-10 22:59:27,802 - INFO - root - Page:1, Index:46, Stop learning it all to mitigate visual hallucination, Focus on the hallucination target, https://arxiv.org/pdf/2506.11417, 2025-06-12
2025-11-10 22:59:27,802 - INFO - root - Page:1, Index:47, EfficientQuant: An Efficient Post-Training Quantization for CNN-Transformer Hybrid Models on Edge Devices, https://arxiv.org/pdf/2506.11093, 2025-06-05
2025-11-10 22:59:27,802 - INFO - root - Page:1, Index:48, HalLoc: Token-level Localization of Hallucinations for Vision Language Models, https://arxiv.org/pdf/2506.10286, 2025-06-11
2025-11-10 22:59:27,803 - INFO - root - Page:1, Index:49, DySS: Dynamic Queries and State-Space Learning for Efficient 3D Object Detection from Multi-Camera Videos, https://arxiv.org/pdf/2506.10242, 2025-06-11
2025-11-10 22:59:27,803 - INFO - root - Fetching page 3 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=100
2025-11-10 22:59:35,475 - INFO - root - get_all_titles_from_web 
2025-11-10 22:59:35,475 - INFO - root - Page:2, Index:0, Improving Personalized Search with Regularized Low-Rank Parameter Updates, https://arxiv.org/pdf/2506.10182, 2025-06-11
2025-11-10 22:59:35,475 - INFO - root - Page:2, Index:1, Hearing Hands: Generating Sounds from Physical Interactions in 3D Scenes, https://arxiv.org/pdf/2506.09989, 2025-06-11
2025-11-10 22:59:35,476 - INFO - root - Page:2, Index:2, UniPre3D: Unified Pre-training of 3D Point Cloud Models with Cross-Modal Gaussian Splatting, https://arxiv.org/pdf/2506.09952, 2025-06-11
2025-11-10 22:59:35,476 - INFO - root - Page:2, Index:3, Provoking Multi-modal Few-Shot LVLM via Exploration-Exploitation In-Context Learning, https://arxiv.org/pdf/2506.09473, 2025-06-11
2025-11-10 22:59:35,476 - INFO - root - Page:2, Index:4, Synthetic Human Action Video Data Generation with Pose Transfer, https://arxiv.org/pdf/2506.09411, 2025-06-11
2025-11-10 22:59:35,476 - INFO - root - Page:2, Index:5, ScaleLSD: Scalable Deep Line Segment Detection Streamlined, https://arxiv.org/pdf/2506.09369, 2025-06-10
2025-11-10 22:59:35,476 - INFO - root - Page:2, Index:6, CheckManual: A New Challenge and Benchmark for Manual-based Appliance Manipulation, https://arxiv.org/pdf/2506.09343, 2025-06-10
2025-11-10 22:59:35,476 - INFO - root - Page:2, Index:7, PatchGuard: Adversarially Robust Anomaly Detection and Localization through Vision Transformers and Pseudo Anomalies, https://arxiv.org/pdf/2506.09237, 2025-10-24
2025-11-10 22:59:35,476 - INFO - root - Page:2, Index:8, SILK: Smooth InterpoLation frameworK for motion in-betweening A Simplified Computational Approach, https://arxiv.org/pdf/2506.09075, 2025-06-09
2025-11-10 22:59:35,476 - INFO - root - Page:2, Index:9, BG-HOP: A Bimanual Generative Hand-Object Prior, https://arxiv.org/pdf/2506.09068, 2025-06-08
2025-11-10 22:59:35,476 - INFO - root - Page:2, Index:10, ORIDa: Object-centric Real-world Image Composition Dataset, https://arxiv.org/pdf/2506.08964, 2025-06-10
2025-11-10 22:59:35,478 - INFO - root - Page:2, Index:11, DiscoVLA: Discrepancy Reduction in Vision, Language, and Alignment for Parameter-Efficient Video-Text Retrieval, https://arxiv.org/pdf/2506.08887, 2025-06-10
2025-11-10 22:59:35,478 - INFO - root - Page:2, Index:12, A Comprehensive Study of Decoder-Only LLMs for Text-to-Image Generation, https://arxiv.org/pdf/2506.08210, 2025-06-09
2025-11-10 22:59:35,478 - INFO - root - Page:2, Index:13, Open World Scene Graph Generation using Vision Language Models, https://arxiv.org/pdf/2506.08189, 2025-06-09
2025-11-10 22:59:35,478 - INFO - root - Page:2, Index:14, Aligning Proteins and Language: A Foundation Model for Protein Retrieval, https://arxiv.org/pdf/2506.08023, 2025-05-27
2025-11-10 22:59:35,478 - INFO - root - Page:2, Index:15, UA-Pose: Uncertainty-Aware 6D Object Pose Estimation and Online Object Completion with Partial References, https://arxiv.org/pdf/2506.07996, 2025-06-09
2025-11-10 22:59:35,480 - INFO - root - Page:2, Index:16, Speedy Deformable 3D Gaussian Splatting: Fast Rendering and Compression of Dynamic Scenes, https://arxiv.org/pdf/2506.07917, 2025-06-09
2025-11-10 22:59:35,480 - INFO - root - Page:2, Index:17, GaussianVAE: Adaptive Learning Dynamics of 3D Gaussians for High-Fidelity Super-Resolution, https://arxiv.org/pdf/2506.07897, 2025-06-09
2025-11-10 22:59:35,480 - INFO - root - Page:2, Index:18, Spatio-Temporal State Space Model For Efficient Event-Based Optical Flow, https://arxiv.org/pdf/2506.07878, 2025-06-09
2025-11-10 22:59:35,481 - INFO - root - Page:2, Index:19, FreeGave: 3D Physics Learning from Dynamic Videos by Gaussian Velocity, https://arxiv.org/pdf/2506.07865, 2025-06-09
2025-11-10 22:59:35,483 - INFO - root - Page:2, Index:20, LogoSP: Local-global Grouping of Superpoints for Unsupervised Semantic Segmentation of 3D Point Clouds, https://arxiv.org/pdf/2506.07857, 2025-06-09
2025-11-10 22:59:35,483 - INFO - root - Page:2, Index:21, Difference Inversion: Interpolate and Isolate the Difference with Token Consistency for Image Analogy Generation, https://arxiv.org/pdf/2506.07750, 2025-06-09
2025-11-10 22:59:35,484 - INFO - root - Page:2, Index:22, Synthetic Visual Genome, https://arxiv.org/pdf/2506.07643, 2025-06-09
2025-11-10 22:59:35,485 - INFO - root - Page:2, Index:23, Fractional Collisions: A Framework for Risk Estimation of Counterfactual Conflicts using Autonomous Driving Behavior Simulations, https://arxiv.org/pdf/2506.07540, 2025-06-09
2025-11-10 22:59:35,486 - INFO - root - Page:2, Index:24, Multi-Step Guided Diffusion for Image Restoration on Edge Devices: Toward Lightweight Perception in Embodied AI, https://arxiv.org/pdf/2506.07286, 2025-06-08
2025-11-10 22:59:35,486 - INFO - root - Page:2, Index:25, LLM-Enhanced Rapid-Reflex Async-Reflect Embodied Agent for Real-Time Decision-Making in Dynamically Changing Environments, https://arxiv.org/pdf/2506.07223, 2025-06-08
2025-11-10 22:59:35,487 - INFO - root - Page:2, Index:26, UCOD-DPL: Unsupervised Camouflaged Object Detection via Dynamic Pseudo-label Learning, https://arxiv.org/pdf/2506.07087, 2025-06-08
2025-11-10 22:59:35,490 - INFO - root - Page:2, Index:27, BePo: Leveraging Birds Eye View and Sparse Points for Efficient and Accurate 3D Occupancy Prediction, https://arxiv.org/pdf/2506.07002, 2025-06-08
2025-11-10 22:59:35,490 - INFO - root - Page:2, Index:28, Reading in the Dark with Foveated Event Vision, https://arxiv.org/pdf/2506.06918, 2025-06-07
2025-11-10 22:59:35,492 - INFO - root - Page:2, Index:29, NSD-Imagery: A benchmark dataset for extending fMRI vision decoding methods to mental imagery, https://arxiv.org/pdf/2506.06898, 2025-06-07
2025-11-10 22:59:35,492 - INFO - root - Page:2, Index:30, Continuous-Time SO(3) Forecasting with Savitzky--Golay Neural Controlled Differential Equations, https://arxiv.org/pdf/2506.06780, 2025-06-07
2025-11-10 22:59:35,493 - INFO - root - Page:2, Index:31, Generalized Trajectory Scoring for End-to-end Multimodal Planning, https://arxiv.org/pdf/2506.06664, 2025-06-07
2025-11-10 22:59:35,493 - INFO - root - Page:2, Index:32, EV-LayerSegNet: Self-supervised Motion Segmentation using Event Cameras, https://arxiv.org/pdf/2506.06596, 2025-06-06
2025-11-10 22:59:35,493 - INFO - root - Page:2, Index:33, Vid2Sim: Generalizable, Video-based Reconstruction of Appearance, Geometry and Physics for Mesh-free Simulation, https://arxiv.org/pdf/2506.06440, 2025-06-06
2025-11-10 22:59:35,494 - INFO - root - Page:2, Index:34, FADE: Frequency-Aware Diffusion Model Factorization for Video Editing, https://arxiv.org/pdf/2506.05934, 2025-06-06
2025-11-10 22:59:35,494 - INFO - root - Page:2, Index:35, Unleashing the Potential of Consistency Learning for Detecting and Grounding Multi-Modal Media Manipulation, https://arxiv.org/pdf/2506.05890, 2025-06-06
2025-11-10 22:59:35,494 - INFO - root - Page:2, Index:36, DeformCL: Learning Deformable Centerline Representation for Vessel Extraction in 3D Medical Image, https://arxiv.org/pdf/2506.05820, 2025-06-06
2025-11-10 22:59:35,496 - INFO - root - Page:2, Index:37, NTIRE 2025 Challenge on HR Depth from Images of Specular and Transparent Surfaces, https://arxiv.org/pdf/2506.05815, 2025-06-06
2025-11-10 22:59:35,496 - INFO - root - Page:2, Index:38, GazeNLQ @ Ego4D Natural Language Queries Challenge 2025, https://arxiv.org/pdf/2506.05782, 2025-06-06
2025-11-10 22:59:35,497 - INFO - root - Page:2, Index:39, Robust sensor fusion against on-vehicle sensor staleness, https://arxiv.org/pdf/2506.05780, 2025-06-06
2025-11-10 22:59:35,497 - INFO - root - Page:2, Index:40, Where Is The Ball: 3D Ball Trajectory Estimation From 2D Monocular Tracking, https://arxiv.org/pdf/2506.05763, 2025-06-06
2025-11-10 22:59:35,498 - INFO - root - Page:2, Index:41, VoxelSplat: Dynamic Gaussian Splatting as an Effective Loss for Occupancy and Flow Prediction, https://arxiv.org/pdf/2506.05563, 2025-06-05
2025-11-10 22:59:35,498 - INFO - root - Page:2, Index:42, Gen4D: Synthesizing Humans and Scenes in the Wild, https://arxiv.org/pdf/2506.05397, 2025-06-03
2025-11-10 22:59:35,499 - INFO - root - Page:2, Index:43, Attacking Attention of Foundation Models Disrupts Downstream Tasks, https://arxiv.org/pdf/2506.05394, 2025-09-12
2025-11-10 22:59:35,501 - INFO - root - Page:2, Index:44, FreeTimeGS: Free Gaussian Primitives at Anytime and Anywhere for Dynamic Scene Reconstruction, https://arxiv.org/pdf/2506.05348, 2025-06-06
2025-11-10 22:59:35,506 - INFO - root - Page:2, Index:45, LotusFilter: Fast Diverse Nearest Neighbor Search via a Learned Cutoff Table, https://arxiv.org/pdf/2506.04790, 2025-06-05
2025-11-10 22:59:35,506 - INFO - root - Page:2, Index:46, Towards Holistic Visual Quality Assessment of AI-Generated Videos: A LLM-Based Multi-Dimensional Evaluation Model, https://arxiv.org/pdf/2506.04715, 2025-06-11
2025-11-10 22:59:35,507 - INFO - root - Page:2, Index:47, Gradient Inversion Attacks on Parameter-Efficient Fine-Tuning, https://arxiv.org/pdf/2506.04453, 2025-06-04
2025-11-10 22:59:35,507 - INFO - root - Page:2, Index:48, HMAR: Efficient Hierarchical Masked Auto-Regressive Image Generation, https://arxiv.org/pdf/2506.04421, 2025-06-04
2025-11-10 22:59:35,509 - INFO - root - Page:2, Index:49, Visualizing and Controlling Cortical Responses Using Voxel-Weighted Activation Maximization, https://arxiv.org/pdf/2506.04379, 2025-06-04
2025-11-10 22:59:35,510 - INFO - root - Fetching page 4 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=150
2025-11-10 22:59:41,782 - INFO - root - get_all_titles_from_web 
2025-11-10 22:59:41,782 - INFO - root - Page:3, Index:0, FlexGS: Train Once, Deploy Everywhere with Many-in-One Flexible 3D Gaussian Splatting, https://arxiv.org/pdf/2506.04174, 2025-06-04
2025-11-10 22:59:41,783 - INFO - root - Page:3, Index:1, Multi-view Surface Reconstruction Using Normal and Reflectance Cues, https://arxiv.org/pdf/2506.04115, 2025-06-04
2025-11-10 22:59:41,783 - INFO - root - Page:3, Index:2, Vocabulary-free few-shot learning for Vision-Language Models, https://arxiv.org/pdf/2506.04005, 2025-06-04
2025-11-10 22:59:41,783 - INFO - root - Page:3, Index:3, Learning from Noise: Enhancing DNNs for Event-Based Vision through Controlled Noise Injection, https://arxiv.org/pdf/2506.03918, 2025-06-04
2025-11-10 22:59:41,784 - INFO - root - Page:3, Index:4, Video, How Do Your Tokens Merge?, https://arxiv.org/pdf/2506.03885, 2025-06-04
2025-11-10 22:59:41,784 - INFO - root - Page:3, Index:5, OSGNet @ Ego4D Episodic Memory Challenge 2025, https://arxiv.org/pdf/2506.03710, 2025-06-04
2025-11-10 22:59:41,784 - INFO - root - Page:3, Index:6, AetherVision-Bench: An Open-Vocabulary RGB-Infrared Benchmark for Multi-Angle Segmentation across Aerial and Ground Perspectives, https://arxiv.org/pdf/2506.03709, 2025-06-04
2025-11-10 22:59:41,785 - INFO - root - Page:3, Index:7, OV-COAST: Cost Aggregation with Optimal Transport for Open-Vocabulary Semantic Segmentation, https://arxiv.org/pdf/2506.03706, 2025-06-04
2025-11-10 22:59:41,785 - INFO - root - Page:3, Index:8, Generating 6DoF Object Manipulation Trajectories from Action Description in Egocentric Vision, https://arxiv.org/pdf/2506.03605, 2025-06-04
2025-11-10 22:59:41,785 - INFO - root - Page:3, Index:9, SemNav: A Model-Based Planner for Zero-Shot Object Goal Navigation Using Vision-Foundation Models, https://arxiv.org/pdf/2506.03516, 2025-06-03
2025-11-10 22:59:41,785 - INFO - root - Page:3, Index:10, Heterogeneous Skeleton-Based Action Representation Learning, https://arxiv.org/pdf/2506.03481, 2025-06-03
2025-11-10 22:59:41,787 - INFO - root - Page:3, Index:11, Hybrid Ensemble of Segmentation-Assisted Classification and GBDT for Skin Cancer Detection with Engineered Metadata and Synthetic Lesions from ISIC 2024 Non-Dermoscopic 3D-TBP Images, https://arxiv.org/pdf/2506.03420, 2025-06-03
2025-11-10 22:59:41,787 - INFO - root - Page:3, Index:12, Self-Supervised Spatial Correspondence Across Modalities, https://arxiv.org/pdf/2506.03148, 2025-06-03
2025-11-10 22:59:41,788 - INFO - root - Page:3, Index:13, Dense Match Summarization for Faster Two-view Estimation, https://arxiv.org/pdf/2506.02893, 2025-06-03
2025-11-10 22:59:41,789 - INFO - root - Page:3, Index:14, NTIRE 2025 XGC Quality Assessment Challenge: Methods and Results, https://arxiv.org/pdf/2506.02875, 2025-06-03
2025-11-10 22:59:41,789 - INFO - root - Page:3, Index:15, FreeScene: Mixed Graph Diffusion for 3D Scene Synthesis from Free Prompts, https://arxiv.org/pdf/2506.02781, 2025-06-03
2025-11-10 22:59:41,790 - INFO - root - Page:3, Index:16, Technical Report for Ego4D Long-Term Action Anticipation Challenge 2025, https://arxiv.org/pdf/2506.02550, 2025-06-11
2025-11-10 22:59:41,790 - INFO - root - Page:3, Index:17, Probabilistic Online Event Downsampling, https://arxiv.org/pdf/2506.02547, 2025-09-23
2025-11-10 22:59:41,790 - INFO - root - Page:3, Index:18, Towards In-the-wild 3D Plane Reconstruction from a Single Image, https://arxiv.org/pdf/2506.02493, 2025-06-03
2025-11-10 22:59:41,791 - INFO - root - Page:3, Index:19, Efficient Test-time Adaptive Object Detection via Sensitivity-Guided Pruning, https://arxiv.org/pdf/2506.02462, 2025-06-03
2025-11-10 22:59:41,791 - INFO - root - Page:3, Index:20, EgoVIS@CVPR: PAIR-Net: Enhancing Egocentric Speaker Detection via Pretrained Audio-Visual Fusion and Alignment Loss, https://arxiv.org/pdf/2506.02247, 2025-09-26
2025-11-10 22:59:41,793 - INFO - root - Page:3, Index:21, Diff2Flow: Training Flow Matching Models via Diffusion Model Alignment, https://arxiv.org/pdf/2506.02221, 2025-06-02
2025-11-10 22:59:41,793 - INFO - root - Page:3, Index:22, NTIRE 2025 Challenge on RAW Image Restoration and Super-Resolution, https://arxiv.org/pdf/2506.02197, 2025-06-04
2025-11-10 22:59:41,793 - INFO - root - Page:3, Index:23, RAW Image Reconstruction from RGB on Smartphones. NTIRE 2025 Challenge Report, https://arxiv.org/pdf/2506.01947, 2025-06-02
2025-11-10 22:59:41,795 - INFO - root - Page:3, Index:24, Silence is Golden: Leveraging Adversarial Examples to Nullify Audio Control in LDM-based Talking-Head Generation, https://arxiv.org/pdf/2506.01591, 2025-06-02
2025-11-10 22:59:41,796 - INFO - root - Page:3, Index:25, SAM2-LOVE: Segment Anything Model 2 in Language-aided Audio-Visual Scenes, https://arxiv.org/pdf/2506.01558, 2025-06-02
2025-11-10 22:59:41,796 - INFO - root - Page:3, Index:26, Neural shape reconstruction from multiple views with static pattern projection, https://arxiv.org/pdf/2506.01389, 2025-06-02
2025-11-10 22:59:41,797 - INFO - root - Page:3, Index:27, SAM-I2V: Upgrading SAM to Support Promptable Video Segmentation with Less than 0.2% Training Cost, https://arxiv.org/pdf/2506.01304, 2025-06-02
2025-11-10 22:59:41,797 - INFO - root - Page:3, Index:28, Perceptual Inductive Bias Is What You Need Before Contrastive Learning, https://arxiv.org/pdf/2506.01201, 2025-06-01
2025-11-10 22:59:41,798 - INFO - root - Page:3, Index:29, Test Automation for Interactive Scenarios via Promptable Traffic Simulation, https://arxiv.org/pdf/2506.01199, 2025-06-04
2025-11-10 22:59:41,798 - INFO - root - Page:3, Index:30, GraphPad: Inference-Time 3D Scene Graph Updates for Embodied Question Answering, https://arxiv.org/pdf/2506.01174, 2025-06-01
2025-11-10 22:59:41,799 - INFO - root - Page:3, Index:31, Aligned Contrastive Loss for Long-Tailed Recognition, https://arxiv.org/pdf/2506.01071, 2025-06-01
2025-11-10 22:59:41,799 - INFO - root - Page:3, Index:32, Self-supervised ControlNet with Spatio-Temporal Mamba for Real-world Video Super-resolution, https://arxiv.org/pdf/2506.01037, 2025-06-01
2025-11-10 22:59:41,799 - INFO - root - Page:3, Index:33, ArtiScene: Language-Driven Artistic 3D Scene Generation Through Image Intermediary, https://arxiv.org/pdf/2506.00742, 2025-05-31
2025-11-10 22:59:41,799 - INFO - root - Page:3, Index:34, 3D Gaussian Splat Vulnerabilities, https://arxiv.org/pdf/2506.00280, 2025-05-30
2025-11-10 22:59:41,799 - INFO - root - Page:3, Index:35, EgoVIS@CVPR: What Changed and What Could Have Changed? State-Change Counterfactuals for Procedure-Aware Video Representation Learning, https://arxiv.org/pdf/2506.00101, 2025-09-26
2025-11-10 22:59:41,800 - INFO - root - Page:3, Index:36, CL-LoRA: Continual Low-Rank Adaptation for Rehearsal-Free Class-Incremental Learning, https://arxiv.org/pdf/2505.24816, 2025-05-30
2025-11-10 22:59:41,800 - INFO - root - Page:3, Index:37, PatchDEMUX: A Certifiably Robust Framework for Multi-label Classifiers Against Adversarial Patches, https://arxiv.org/pdf/2505.24703, 2025-05-30
2025-11-10 22:59:41,800 - INFO - root - Page:3, Index:38, Conformal Prediction for Zero-Shot Models, https://arxiv.org/pdf/2505.24693, 2025-05-30
2025-11-10 22:59:41,800 - INFO - root - Page:3, Index:39, Learning reusable concepts across different egocentric video understanding tasks, https://arxiv.org/pdf/2505.24690, 2025-05-30
2025-11-10 22:59:41,801 - INFO - root - Page:3, Index:40, Period-LLM: Extending the Periodic Capability of Multimodal Large Language Model, https://arxiv.org/pdf/2505.24476, 2025-05-30
2025-11-10 22:59:41,801 - INFO - root - Page:3, Index:41, PCIE_Interaction Solution for Ego4D Social Interaction Challenge, https://arxiv.org/pdf/2505.24404, 2025-05-30
2025-11-10 22:59:41,801 - INFO - root - Page:3, Index:42, Leadership Assessment in Pediatric Intensive Care Unit Team Training, https://arxiv.org/pdf/2505.24389, 2025-08-28
2025-11-10 22:59:41,801 - INFO - root - Page:3, Index:43, Interpreting Large Text-to-Image Diffusion Models with Dictionary Learning, https://arxiv.org/pdf/2505.24360, 2025-07-10
2025-11-10 22:59:41,801 - INFO - root - Page:3, Index:44, InteractAnything: Zero-shot Human Object Interaction Synthesis via LLM Feedback and Object Affordance Parsing, https://arxiv.org/pdf/2505.24315, 2025-05-30
2025-11-10 22:59:41,803 - INFO - root - Page:3, Index:45, MaskAdapt: Unsupervised Geometry-Aware Domain Adaptation Using Multimodal Contextual Learning and RGB-Depth Masking, https://arxiv.org/pdf/2505.24026, 2025-05-29
2025-11-10 22:59:41,803 - INFO - root - Page:3, Index:46, Argus: Vision-Centric Reasoning with Grounded Chain-of-Thought, https://arxiv.org/pdf/2505.23766, 2025-05-29
2025-11-10 22:59:41,803 - INFO - root - Page:3, Index:47, Sketch Down the FLOPs: Towards Efficient Networks for Human Sketch, https://arxiv.org/pdf/2505.23763, 2025-05-29
2025-11-10 22:59:41,804 - INFO - root - Page:3, Index:48, Boosting Domain Incremental Learning: Selecting the Optimal Parameters is All You Need, https://arxiv.org/pdf/2505.23744, 2025-05-29
2025-11-10 22:59:41,805 - INFO - root - Page:3, Index:49, DA-VPT: Semantic-Guided Visual Prompt Tuning for Vision Transformers, https://arxiv.org/pdf/2505.23694, 2025-06-01
2025-11-10 22:59:41,806 - INFO - root - Fetching page 5 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=200
2025-11-10 22:59:48,236 - INFO - root - get_all_titles_from_web 
2025-11-10 22:59:48,236 - INFO - root - Page:4, Index:0, Bridging Classical and Modern Computer Vision: PerceptiveNet for Tree Crown Semantic Segmentation, https://arxiv.org/pdf/2505.23597, 2025-05-29
2025-11-10 22:59:48,237 - INFO - root - Page:4, Index:1, Synthetic Generation and Latent Projection Denoising of Rim Lesions in Multiple Sclerosis, https://arxiv.org/pdf/2505.23353, 2025-05-29
2025-11-10 22:59:48,237 - INFO - root - Page:4, Index:2, Wav2Sem: Plug-and-Play Audio Semantic Decoupling for 3D Speech-Driven Facial Animation, https://arxiv.org/pdf/2505.23290, 2025-05-29
2025-11-10 22:59:48,237 - INFO - root - Page:4, Index:3, Proximal Algorithm Unrolling: Flexible and Efficient Reconstruction Networks for Single-Pixel Imaging, https://arxiv.org/pdf/2505.23180, 2025-05-29
2025-11-10 22:59:48,237 - INFO - root - Page:4, Index:4, HMAD: Advancing E2E Driving with Anchored Offset Proposals and Simulation-Supervised Multi-target Scoring, https://arxiv.org/pdf/2505.23129, 2025-05-29
2025-11-10 22:59:48,238 - INFO - root - Page:4, Index:5, URWKV: Unified RWKV Model with Multi-state Perspective for Low-light Image Restoration, https://arxiv.org/pdf/2505.23068, 2025-05-29
2025-11-10 22:59:48,238 - INFO - root - Page:4, Index:6, 4DTAM: Non-Rigid Tracking and Mapping via Dynamic Surface Gaussians, https://arxiv.org/pdf/2505.22859, 2025-05-28
2025-11-10 22:59:48,239 - INFO - root - Page:4, Index:7, A Probabilistic Jump-Diffusion Framework for Open-World Egocentric Activity Recognition, https://arxiv.org/pdf/2505.22858, 2025-05-28
2025-11-10 22:59:48,239 - INFO - root - Page:4, Index:8, PS4PRO: Pixel-to-pixel Supervision for Photorealistic Rendering and Optimization, https://arxiv.org/pdf/2505.22616, 2025-05-28
2025-11-10 22:59:48,239 - INFO - root - Page:4, Index:9, Universal Domain Adaptation for Semantic Segmentation, https://arxiv.org/pdf/2505.22458, 2025-06-05
2025-11-10 22:59:48,239 - INFO - root - Page:4, Index:10, Zero-Shot 3D Visual Grounding from Vision-Language Models, https://arxiv.org/pdf/2505.22429, 2025-05-28
2025-11-10 22:59:48,239 - INFO - root - Page:4, Index:11, RC-AutoCalib: An End-to-End Radar-Camera Automatic Calibration Network, https://arxiv.org/pdf/2505.22427, 2025-05-28
2025-11-10 22:59:48,240 - INFO - root - Page:4, Index:12, Bringing CLIP to the Clinic: Dynamic Soft Labels and Negation-Aware Learning for Medical Analysis, https://arxiv.org/pdf/2505.22079, 2025-05-28
2025-11-10 22:59:48,240 - INFO - root - Page:4, Index:13, Point-to-Region Loss for Semi-Supervised Point-Based Crowd Counting, https://arxiv.org/pdf/2505.21943, 2025-05-27
2025-11-10 22:59:48,240 - INFO - root - Page:4, Index:14, FRAMES-VQA: Benchmarking Fine-Tuning Robustness across Multi-Modal Shifts in Visual Question Answering, https://arxiv.org/pdf/2505.21755, 2025-06-20
2025-11-10 22:59:48,242 - INFO - root - Page:4, Index:15, Knowledge Distillation Approach for SOS Fusion Staging: Towards Fully Automated Skeletal Maturity Assessment, https://arxiv.org/pdf/2505.21561, 2025-05-26
2025-11-10 22:59:48,242 - INFO - root - Page:4, Index:16, Enhancing Vision Transformer Explainability Using Artificial Astrocytes, https://arxiv.org/pdf/2505.21513, 2025-05-20
2025-11-10 22:59:48,242 - INFO - root - Page:4, Index:17, Empowering Vector Graphics with Consistently Arbitrary Viewing and View-dependent Visibility, https://arxiv.org/pdf/2505.21377, 2025-05-27
2025-11-10 22:59:48,242 - INFO - root - Page:4, Index:18, Structure from Collision, https://arxiv.org/pdf/2505.21335, 2025-05-27
2025-11-10 22:59:48,242 - INFO - root - Page:4, Index:19, Boosting Adversarial Transferability via High-Frequency Augmentation and Hierarchical-Gradient Fusion, https://arxiv.org/pdf/2505.21181, 2025-05-27
2025-11-10 22:59:48,243 - INFO - root - Page:4, Index:20, RefAV: Towards Planning-Centric Scenario Mining, https://arxiv.org/pdf/2505.20981, 2025-06-18
2025-11-10 22:59:48,243 - INFO - root - Page:4, Index:21, PMA: Towards Parameter-Efficient Point Cloud Understanding via Point Mamba Adapter, https://arxiv.org/pdf/2505.20941, 2025-05-27
2025-11-10 22:59:48,243 - INFO - root - Page:4, Index:22, HuMoCon: Concept Discovery for Human Motion Understanding, https://arxiv.org/pdf/2505.20920, 2025-05-27
2025-11-10 22:59:48,245 - INFO - root - Page:4, Index:23, Exploring Timeline Control for Facial Motion Generation, https://arxiv.org/pdf/2505.20861, 2025-05-27
2025-11-10 22:59:48,246 - INFO - root - Page:4, Index:24, ConText-CIR: Learning from Concepts in Text for Composed Image Retrieval, https://arxiv.org/pdf/2505.20764, 2025-05-27
2025-11-10 22:59:48,246 - INFO - root - Page:4, Index:25, HCQA-1.5 @ Ego4D EgoSchema Challenge 2025, https://arxiv.org/pdf/2505.20644, 2025-05-26
2025-11-10 22:59:48,249 - INFO - root - Page:4, Index:26, Roboflow100-VL: A Multi-Domain Object Detection Benchmark for Vision-Language Models, https://arxiv.org/pdf/2505.20612, 2025-10-22
2025-11-10 22:59:48,249 - INFO - root - Page:4, Index:27, MotionPro: A Precise Motion Controller for Image-to-Video Generation, https://arxiv.org/pdf/2505.20287, 2025-05-26
2025-11-10 22:59:48,250 - INFO - root - Page:4, Index:28, Category-Agnostic Neural Object Rigging, https://arxiv.org/pdf/2505.20283, 2025-05-26
2025-11-10 22:59:48,251 - INFO - root - Page:4, Index:29, Towards Video to Piano Music Generation with Chain-of-Perform Support Benchmarks, https://arxiv.org/pdf/2505.20038, 2025-05-26
2025-11-10 22:59:48,252 - INFO - root - Page:4, Index:30, Can Visual Encoder Learn to See Arrows?, https://arxiv.org/pdf/2505.19944, 2025-05-26
2025-11-10 22:59:48,252 - INFO - root - Page:4, Index:31, GoLF-NRT: Integrating Global Context and Local Geometry for Few-Shot View Synthesis, https://arxiv.org/pdf/2505.19813, 2025-05-26
2025-11-10 22:59:48,261 - INFO - root - Page:4, Index:32, Depth-Guided Bundle Sampling for Efficient Generalizable Neural Radiance Field Reconstruction, https://arxiv.org/pdf/2505.19793, 2025-05-26
2025-11-10 22:59:48,265 - INFO - root - Page:4, Index:33, SuperAD: A Training-free Anomaly Classification and Segmentation Method for CVPR 2025 VAND 3.0 Workshop Challenge Track 1: Adapt & Detect, https://arxiv.org/pdf/2505.19750, 2025-05-27
2025-11-10 22:59:48,268 - INFO - root - Page:4, Index:34, Knowledge-Aligned Counterfactual-Enhancement Diffusion Perception for Unsupervised Cross-Domain Visual Emotion Recognition, https://arxiv.org/pdf/2505.19694, 2025-05-26
2025-11-10 22:59:48,269 - INFO - root - Page:4, Index:35, Rotation-Equivariant Self-Supervised Method in Image Denoising, https://arxiv.org/pdf/2505.19618, 2025-05-26
2025-11-10 22:59:48,271 - INFO - root - Page:4, Index:36, NTIRE 2025 Challenge on Video Quality Enhancement for Video Conferencing: Datasets, Methods and Results, https://arxiv.org/pdf/2505.18988, 2025-05-25
2025-11-10 22:59:48,272 - INFO - root - Page:4, Index:37, Geometry-guided Online 3D Video Synthesis with Multi-View Temporal Consistency, https://arxiv.org/pdf/2505.18932, 2025-05-24
2025-11-10 22:59:48,276 - INFO - root - Page:4, Index:38, Digital Overconsumption and Waste: A Closer Look at the Impacts of Generative AI, https://arxiv.org/pdf/2505.18894, 2025-05-24
2025-11-10 22:59:48,276 - INFO - root - Page:4, Index:39, VISTA: Vision-Language Inference for Training-Free Stock Time-Series Analysis, https://arxiv.org/pdf/2505.18570, 2025-06-11
2025-11-10 22:59:48,277 - INFO - root - Page:4, Index:40, Syn3DTxt: Embedding 3D Cues for Scene Text Generation, https://arxiv.org/pdf/2505.18479, 2025-05-23
2025-11-10 22:59:48,286 - INFO - root - Page:4, Index:41, CTRL-GS: Cascaded Temporal Residue Learning for 4D Gaussian Splatting, https://arxiv.org/pdf/2505.18306, 2025-05-31
2025-11-10 22:59:48,287 - INFO - root - Page:4, Index:42, DualTalk: Dual-Speaker Interaction for 3D Talking Head Conversations, https://arxiv.org/pdf/2505.18096, 2025-05-26
2025-11-10 22:59:48,287 - INFO - root - Page:4, Index:43, SeaLion: Semantic Part-Aware Latent Point Diffusion Models for 3D Generation, https://arxiv.org/pdf/2505.17721, 2025-07-07
2025-11-10 22:59:48,288 - INFO - root - Page:4, Index:44, PoseBH: Prototypical Multi-Dataset Training Beyond Human Pose Estimation, https://arxiv.org/pdf/2505.17475, 2025-05-23
2025-11-10 22:59:48,288 - INFO - root - Page:4, Index:45, Pursuing Temporal-Consistent Video Virtual Try-On via Dynamic Pose Interaction, https://arxiv.org/pdf/2505.16980, 2025-05-22
2025-11-10 22:59:48,288 - INFO - root - Page:4, Index:46, UniPhy: Learning a Unified Constitutive Model for Inverse Physics Simulation, https://arxiv.org/pdf/2505.16971, 2025-05-22
2025-11-10 22:59:48,289 - INFO - root - Page:4, Index:47, Tracking the Flight: Exploring a Computational Framework for Analyzing Escape Responses in Plains Zebra (Equus quagga), https://arxiv.org/pdf/2505.16882, 2025-05-23
2025-11-10 22:59:48,291 - INFO - root - Page:4, Index:48, Semi-Supervised State-Space Model with Dynamic Stacking Filter for Real-World Video Deraining, https://arxiv.org/pdf/2505.16811, 2025-05-22
2025-11-10 22:59:48,292 - INFO - root - Page:4, Index:49, SOLVE: Synergy of Language-Vision and End-to-End Networks for Autonomous Driving, https://arxiv.org/pdf/2505.16805, 2025-05-22
2025-11-10 22:59:48,293 - INFO - root - Fetching page 6 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=250
2025-11-10 22:59:55,061 - INFO - root - get_all_titles_from_web 
2025-11-10 22:59:55,061 - INFO - root - Page:5, Index:0, Four Eyes Are Better Than Two: Harnessing the Collaborative Potential of Large Models via Differentiated Thinking and Complementary Ensembles, https://arxiv.org/pdf/2505.16784, 2025-06-07
2025-11-10 22:59:55,061 - INFO - root - Page:5, Index:1, Single Domain Generalization for Few-Shot Counting via Universal Representation Matching, https://arxiv.org/pdf/2505.16778, 2025-05-22
2025-11-10 22:59:55,061 - INFO - root - Page:5, Index:2, Seeing Far and Clearly: Mitigating Hallucinations in MLLMs with Attention Causal Decoding, https://arxiv.org/pdf/2505.16652, 2025-06-07
2025-11-10 22:59:55,063 - INFO - root - Page:5, Index:3, Sketchy Bounding-box Supervision for 3D Instance Segmentation, https://arxiv.org/pdf/2505.16399, 2025-05-22
2025-11-10 22:59:55,063 - INFO - root - Page:5, Index:4, DeCafNet: Delegate and Conquer for Efficient Temporal Grounding in Long Videos, https://arxiv.org/pdf/2505.16376, 2025-05-22
2025-11-10 22:59:55,063 - INFO - root - Page:5, Index:5, NTIRE 2025 challenge on Text to Image Generation Model Quality Assessment, https://arxiv.org/pdf/2505.16314, 2025-05-22
2025-11-10 22:59:55,064 - INFO - root - Page:5, Index:6, Analyzing Hierarchical Structure in Vision Models with Sparse Autoencoders, https://arxiv.org/pdf/2505.15970, 2025-05-21
2025-11-10 22:59:55,064 - INFO - root - Page:5, Index:7, Efficient Data Driven Mixture-of-Expert Extraction from Trained Networks, https://arxiv.org/pdf/2505.15414, 2025-05-21
2025-11-10 22:59:55,065 - INFO - root - Page:5, Index:8, Mouse Lockbox Dataset: Behavior Recognition for Mice Solving Lockboxes, https://arxiv.org/pdf/2505.15408, 2025-06-17
2025-11-10 22:59:55,065 - INFO - root - Page:5, Index:9, Zero-Shot Gaze-based Volumetric Medical Image Segmentation, https://arxiv.org/pdf/2505.15256, 2025-06-10
2025-11-10 22:59:55,065 - INFO - root - Page:5, Index:10, Dual Precision Quantization for Efficient and Accurate Deep Neural Networks Inference, https://arxiv.org/pdf/2505.14638, 2025-05-20
2025-11-10 22:59:55,066 - INFO - root - Page:5, Index:11, Neural Video Compression with Context Modulation, https://arxiv.org/pdf/2505.14541, 2025-05-20
2025-11-10 22:59:55,066 - INFO - root - Page:5, Index:12, Selective Structured State Space for Multispectral-fused Small Target Detection, https://arxiv.org/pdf/2505.14043, 2025-05-23
2025-11-10 22:59:55,066 - INFO - root - Page:5, Index:13, OmniStyle: Filtering High Quality Style Transfer Data at Scale, https://arxiv.org/pdf/2505.14028, 2025-05-20
2025-11-10 22:59:55,066 - INFO - root - Page:5, Index:14, Domain Adaptation of VLM for Soccer Video Understanding, https://arxiv.org/pdf/2505.13860, 2025-07-07
2025-11-10 22:59:55,067 - INFO - root - Page:5, Index:15, Ground-V: Teaching VLMs to Ground Complex Instructions in Pixels, https://arxiv.org/pdf/2505.13788, 2025-05-19
2025-11-10 22:59:55,068 - INFO - root - Page:5, Index:16, FinePhys: Fine-grained Human Action Generation by Explicitly Incorporating Physical Laws for Effective Skeletal Guidance, https://arxiv.org/pdf/2505.13437, 2025-05-19
2025-11-10 22:59:55,069 - INFO - root - Page:5, Index:17, The Way Up: A Dataset for Hold Usage Detection in Sport Climbing, https://arxiv.org/pdf/2505.12854, 2025-05-19
2025-11-10 22:59:55,070 - INFO - root - Page:5, Index:18, PEER pressure: Model-to-Model Regularization for Single Source Domain Generalization, https://arxiv.org/pdf/2505.12745, 2025-05-19
2025-11-10 22:59:55,070 - INFO - root - Page:5, Index:19, Mamba-Adaptor: State Space Model Adaptor for Visual Recognition, https://arxiv.org/pdf/2505.12685, 2025-05-19
2025-11-10 22:59:55,070 - INFO - root - Page:5, Index:20, Scalable Video-to-Dataset Generation for Cross-Platform Mobile Agents, https://arxiv.org/pdf/2505.12632, 2025-05-18
2025-11-10 22:59:55,070 - INFO - root - Page:5, Index:21, Degradation-Aware Feature Perturbation for All-in-One Image Restoration, https://arxiv.org/pdf/2505.12630, 2025-05-18
2025-11-10 22:59:55,072 - INFO - root - Page:5, Index:22, Guiding Diffusion with Deep Geometric Moments: Balancing Fidelity and Variation, https://arxiv.org/pdf/2505.12486, 2025-05-18
2025-11-10 22:59:55,072 - INFO - root - Page:5, Index:23, Learning to Highlight Audio by Watching Movies, https://arxiv.org/pdf/2505.12154, 2025-05-17
2025-11-10 22:59:55,073 - INFO - root - Page:5, Index:24, Understanding the Capabilities of Molecular Graph Neural Networks in Materials Science Through Multimodal Learning and Physical Context Encoding, https://arxiv.org/pdf/2505.12137, 2025-05-17
2025-11-10 22:59:55,073 - INFO - root - Page:5, Index:25, iSegMan: Interactive Segment-and-Manipulate 3D Gaussians, https://arxiv.org/pdf/2505.11934, 2025-05-17
2025-11-10 22:59:55,073 - INFO - root - Page:5, Index:26, Self-Learning Hyperspectral and Multispectral Image Fusion via Adaptive Residual Guided Subspace Diffusion Model, https://arxiv.org/pdf/2505.11800, 2025-05-16
2025-11-10 22:59:55,075 - INFO - root - Page:5, Index:27, X-Edit: Detecting and Localizing Edits in Images Altered by Text-Guided Diffusion Models, https://arxiv.org/pdf/2505.11753, 2025-05-16
2025-11-10 22:59:55,075 - INFO - root - Page:5, Index:28, MTevent: A Multi-Task Event Camera Dataset for 6D Pose Estimation and Moving Object Detection, https://arxiv.org/pdf/2505.11282, 2025-06-02
2025-11-10 22:59:55,076 - INFO - root - Page:5, Index:29, Imputation-free and Alignment-free: Incomplete Multi-view Clustering Driven by Consensus Semantic Learning, https://arxiv.org/pdf/2505.11182, 2025-05-16
2025-11-10 22:59:55,076 - INFO - root - Page:5, Index:30, MultiLink: Multi-class Structure Recovery via Agglomerative Clustering and Model Selection, https://arxiv.org/pdf/2505.10874, 2025-05-16
2025-11-10 22:59:55,076 - INFO - root - Page:5, Index:31, RefPose: Leveraging Reference Geometric Correspondences for Accurate 6D Pose Estimation of Unseen Objects, https://arxiv.org/pdf/2505.10841, 2025-05-16
2025-11-10 22:59:55,076 - INFO - root - Page:5, Index:32, MoCLIP: Motion-Aware Fine-Tuning and Distillation of CLIP for Human Motion Generation, https://arxiv.org/pdf/2505.10810, 2025-05-15
2025-11-10 22:59:55,077 - INFO - root - Page:5, Index:33, Automated Detection of Salvin's Albatrosses: Improving Deep Learning Tools for Aerial Wildlife Surveys, https://arxiv.org/pdf/2505.10737, 2025-05-15
2025-11-10 22:59:55,077 - INFO - root - Page:5, Index:34, Advancing Multiple Instance Learning with Continual Learning for Whole Slide Imaging, https://arxiv.org/pdf/2505.10649, 2025-05-15
2025-11-10 22:59:55,078 - INFO - root - Page:5, Index:35, Inferring Driving Maps by Deep Learning-based Trail Map Extraction, https://arxiv.org/pdf/2505.10258, 2025-05-15
2025-11-10 22:59:55,078 - INFO - root - Page:5, Index:36, Dyadic Mamba: Long-term Dyadic Human Motion Synthesis, https://arxiv.org/pdf/2505.09827, 2025-05-14
2025-11-10 22:59:55,079 - INFO - root - Page:5, Index:37, UWAV: Uncertainty-weighted Weakly-supervised Audio-Visual Video Parsing, https://arxiv.org/pdf/2505.09615, 2025-05-14
2025-11-10 22:59:55,081 - INFO - root - Page:5, Index:38, Camera-Only 3D Panoptic Scene Completion for Autonomous Driving through Differentiable Object Shapes, https://arxiv.org/pdf/2505.09562, 2025-05-14
2025-11-10 22:59:55,081 - INFO - root - Page:5, Index:39, Sparse Point Cloud Patches Rendering via Splitting 2D Gaussians, https://arxiv.org/pdf/2505.09413, 2025-05-14
2025-11-10 22:59:55,083 - INFO - root - Page:5, Index:40, UMotion: Uncertainty-driven Human Motion Estimation from Inertial and Ultra-wideband Units, https://arxiv.org/pdf/2505.09393, 2025-05-14
2025-11-10 22:59:55,084 - INFO - root - Page:5, Index:41, Marigold: Affordable Adaptation of Diffusion-Based Image Generators for Image Analysis, https://arxiv.org/pdf/2505.09358, 2025-05-14
2025-11-10 22:59:55,085 - INFO - root - Page:5, Index:42, Predicting butterfly species presence from satellite imagery using soft contrastive regularisation, https://arxiv.org/pdf/2505.09306, 2025-05-14
2025-11-10 22:59:55,086 - INFO - root - Page:5, Index:43, Behind Maya: Building a Multilingual Vision Language Model, https://arxiv.org/pdf/2505.08910, 2025-05-15
2025-11-10 22:59:55,086 - INFO - root - Page:5, Index:44, PosterO: Structuring Layout Trees to Enable Language Models in Generalized Content-Aware Layout Generation, https://arxiv.org/pdf/2505.07843, 2025-05-26
2025-11-10 22:59:55,087 - INFO - root - Page:5, Index:45, Prototype Augmented Hypernetworks for Continual Learning, https://arxiv.org/pdf/2505.07450, 2025-05-16
2025-11-10 22:59:55,087 - INFO - root - Fetching page 7 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=300
2025-11-10 23:00:01,653 - INFO - root - get_all_titles_from_web 
2025-11-10 23:00:01,653 - INFO - root - Page:6, Index:0, Convex Relaxation for Robust Vanishing Point Estimation in Manhattan World, https://arxiv.org/pdf/2505.04788, 2025-06-05
2025-11-10 23:00:01,654 - INFO - root - Page:6, Index:1, S3D: Sketch-Driven 3D Model Generation, https://arxiv.org/pdf/2505.04185, 2025-06-03
2025-11-10 23:00:01,654 - INFO - root - Page:6, Index:2, Generating Synthetic Data via Augmentations for Improved Facial Resemblance in DreamBooth and InstantID, https://arxiv.org/pdf/2505.03557, 2025-07-17
2025-11-10 23:00:01,654 - INFO - root - Page:6, Index:3, CAV-MAE Sync: Improving Contrastive Audio-Visual Mask Autoencoders via Fine-Grained Alignment, https://arxiv.org/pdf/2505.01237, 2025-05-21
2025-11-10 23:00:01,654 - INFO - root - Fetching page 8 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=350
2025-11-10 23:00:10,253 - INFO - root - get_all_titles_from_web 
2025-11-10 23:00:10,253 - INFO - root - Page:7, Index:0, Where's the liability in the Generative Era? Recovery-based Black-Box Detection of AI-Generated Content, https://arxiv.org/pdf/2505.01008, 2025-08-25
2025-11-10 23:00:10,253 - INFO - root - Page:7, Index:1, SpatialLLM: A Compound 3D-Informed Design towards Spatially-Intelligent Large Multimodal Models, https://arxiv.org/pdf/2505.00788, 2025-06-10
2025-11-10 23:00:10,254 - INFO - root - Page:7, Index:2, Prisma: An Open Source Toolkit for Mechanistic Interpretability in Vision and Video, https://arxiv.org/pdf/2504.19475, 2025-06-03
2025-11-10 23:00:10,254 - INFO - root - Page:7, Index:3, SSL4Eco: A Global Seasonal Dataset for Geospatial Foundation Models in Ecology, https://arxiv.org/pdf/2504.18256, 2025-10-20
2025-11-10 23:00:10,254 - INFO - root - Page:7, Index:4, Vision-Language Models Are Not Pragmatically Competent in Referring Expression Generation, https://arxiv.org/pdf/2504.16060, 2025-07-30
2025-11-10 23:00:10,254 - INFO - root - Fetching page 9 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=400
2025-11-10 23:00:18,561 - INFO - root - get_all_titles_from_web 
2025-11-10 23:00:18,561 - INFO - root - Page:8, Index:0, Leveraging Automatic CAD Annotations for Supervised Learning in 3D Scene Understanding, https://arxiv.org/pdf/2504.13580, 2025-05-16
2025-11-10 23:00:18,562 - INFO - root - Page:8, Index:1, CAP-Net: A Unified Network for 6D Pose and Size Estimation of Categorical Articulated Parts from a Single RGB-D Image, https://arxiv.org/pdf/2504.11230, 2025-06-02
2025-11-10 23:00:18,563 - INFO - root - Page:8, Index:2, Video Summarization with Large Language Models, https://arxiv.org/pdf/2504.11199, 2025-06-05
2025-11-10 23:00:18,563 - INFO - root - Page:8, Index:3, R-TPT: Improving Adversarial Robustness of Vision-Language Models through Test-Time Prompt Tuning, https://arxiv.org/pdf/2504.11195, 2025-08-27
2025-11-10 23:00:18,563 - INFO - root - Page:8, Index:4, TerraMesh: A Planetary Mosaic of Multimodal Earth Observation Data, https://arxiv.org/pdf/2504.11172, 2025-08-01
2025-11-10 23:00:18,563 - INFO - root - Page:8, Index:5, Seeing like a Cephalopod: Colour Vision with a Monochrome Event Camera, https://arxiv.org/pdf/2504.10984, 2025-06-06
2025-11-10 23:00:18,563 - INFO - root - Page:8, Index:6, Hearing Anywhere in Any Environment, https://arxiv.org/pdf/2504.10746, 2025-06-04
2025-11-10 23:00:18,563 - INFO - root - Fetching page 10 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=450
2025-11-10 23:00:26,240 - INFO - root - get_all_titles_from_web 
2025-11-10 23:00:26,240 - INFO - root - Page:9, Index:0, Correlative and Discriminative Label Grouping for Multi-Label Visual Prompt Tuning, https://arxiv.org/pdf/2504.09990, 2025-07-09
2025-11-10 23:00:26,240 - INFO - root - Page:9, Index:1, SPICE: A Synergistic, Precise, Iterative, and Customizable Image Editing Workflow, https://arxiv.org/pdf/2504.09697, 2025-10-16
2025-11-10 23:00:26,241 - INFO - root - Page:9, Index:2, Mimic In-Context Learning for Multimodal Tasks, https://arxiv.org/pdf/2504.08851, 2025-05-17
2025-11-10 23:00:26,241 - INFO - root - Page:9, Index:3, Digital Twin Catalog: A Large-Scale Photorealistic 3D Object Digital Twin Dataset, https://arxiv.org/pdf/2504.08541, 2025-05-18
2025-11-10 23:00:26,241 - INFO - root - Page:9, Index:4, MMLA: Multi-Environment, Multi-Species, Low-Altitude Drone Dataset, https://arxiv.org/pdf/2504.07744, 2025-10-22
2025-11-10 23:00:26,241 - INFO - root - Fetching page 11 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=500
2025-11-10 23:00:33,409 - INFO - root - get_all_titles_from_web 
2025-11-10 23:00:33,410 - INFO - root - Page:10, Index:0, PromptHMR: Promptable Human Mesh Recovery, https://arxiv.org/pdf/2504.06397, 2025-05-23
2025-11-10 23:00:33,410 - INFO - root - Page:10, Index:1, SCAM: A Real-World Typographic Robustness Evaluation for Multimodal Foundation Models, https://arxiv.org/pdf/2504.04893, 2025-09-26
2025-11-10 23:00:33,411 - INFO - root - Fetching page 12 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=550
2025-11-10 23:00:41,583 - INFO - root - get_all_titles_from_web 
2025-11-10 23:00:41,583 - INFO - root - Page:11, Index:0, Charm: The Missing Piece in ViT fine-tuning for Image Aesthetic Assessment, https://arxiv.org/pdf/2504.02522, 2025-05-15
2025-11-10 23:00:41,584 - INFO - root - Page:11, Index:1, T*: Re-thinking Temporal Search for Long-Form Video Understanding, https://arxiv.org/pdf/2504.02259, 2025-08-24
2025-11-10 23:00:41,584 - INFO - root - Page:11, Index:2, CoMatcher: Multi-View Collaborative Feature Matching, https://arxiv.org/pdf/2504.01872, 2025-08-20
2025-11-10 23:00:41,584 - INFO - root - Page:11, Index:3, Learned Image Compression with Dictionary-based Entropy Model, https://arxiv.org/pdf/2504.00496, 2025-05-14
2025-11-10 23:00:41,584 - INFO - root - Page:11, Index:4, Think Small, Act Big: Primitive Prompt Learning for Lifelong Robot Manipulation, https://arxiv.org/pdf/2504.00420, 2025-06-01
2025-11-10 23:00:41,585 - INFO - root - Fetching page 13 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=600
2025-11-10 23:00:50,520 - INFO - root - get_all_titles_from_web 
2025-11-10 23:00:50,520 - INFO - root - Page:12, Index:0, It's a (Blind) Match! Towards Vision-Language Correspondence without Parallel Data, https://arxiv.org/pdf/2503.24129, 2025-05-29
2025-11-10 23:00:50,521 - INFO - root - Page:12, Index:1, ReferDINO-Plus: 2nd Solution for 4th PVUW MeViS Challenge at CVPR 2025, https://arxiv.org/pdf/2503.23509, 2025-05-29
2025-11-10 23:00:50,521 - INFO - root - Page:12, Index:2, A Unified Image-Dense Annotation Generation Model for Underwater Scenes, https://arxiv.org/pdf/2503.21771, 2025-07-27
2025-11-10 23:00:50,521 - INFO - root - Fetching page 14 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=650
2025-11-10 23:00:57,727 - INFO - root - get_all_titles_from_web 
2025-11-10 23:00:57,727 - INFO - root - Page:13, Index:0, Learning Class Prototypes for Unified Sparse Supervised 3D Object Detection, https://arxiv.org/pdf/2503.21099, 2025-06-13
2025-11-10 23:00:57,727 - INFO - root - Page:13, Index:1, LATTE-MV: Learning to Anticipate Table Tennis Hits from Monocular Videos, https://arxiv.org/pdf/2503.20936, 2025-09-01
2025-11-10 23:00:57,728 - INFO - root - Page:13, Index:2, BizGen: Advancing Article-level Visual Text Rendering for Infographics Generation, https://arxiv.org/pdf/2503.20672, 2025-07-02
2025-11-10 23:00:57,728 - INFO - root - Page:13, Index:3, ITA-MDT: Image-Timestep-Adaptive Masked Diffusion Transformer Framework for Image-Based Virtual Try-On, https://arxiv.org/pdf/2503.20418, 2025-06-01
2025-11-10 23:00:57,728 - INFO - root - Page:13, Index:4, Faster Parameter-Efficient Tuning with Token Redundancy Reduction, https://arxiv.org/pdf/2503.20282, 2025-08-26
2025-11-10 23:00:57,729 - INFO - root - Page:13, Index:5, DINeMo: Learning Neural Mesh Models with no 3D Annotations, https://arxiv.org/pdf/2503.20220, 2025-06-09
2025-11-10 23:00:57,730 - INFO - root - Page:13, Index:6, Scaling Vision Pre-Training to 4K Resolution, https://arxiv.org/pdf/2503.19903, 2025-08-03
2025-11-10 23:00:57,731 - INFO - root - Page:13, Index:7, GENIUS: A Generative Framework for Universal Multimodal Search, https://arxiv.org/pdf/2503.19868, 2025-06-05
2025-11-10 23:00:57,731 - INFO - root - Fetching page 15 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=700
2025-11-10 23:01:04,501 - INFO - root - get_all_titles_from_web 
2025-11-10 23:01:04,501 - INFO - root - Page:14, Index:0, Galaxy Walker: Geometry-aware VLMs For Galaxy-scale Understanding, https://arxiv.org/pdf/2503.18578, 2025-05-25
2025-11-10 23:01:04,503 - INFO - root - Page:14, Index:1, LookCloser: Frequency-aware Radiance Field for Tiny-Detail Scene, https://arxiv.org/pdf/2503.18513, 2025-07-29
2025-11-10 23:01:04,503 - INFO - root - Fetching page 16 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=750
2025-11-10 23:01:12,887 - INFO - root - get_all_titles_from_web 
2025-11-10 23:01:12,888 - INFO - root - Page:15, Index:0, LoTUS: Large-Scale Machine Unlearning with a Taste of Uncertainty, https://arxiv.org/pdf/2503.18314, 2025-05-29
2025-11-10 23:01:12,888 - INFO - root - Page:15, Index:1, MammAlps: A multi-view video behavior monitoring dataset of wild mammals in the Swiss Alps, https://arxiv.org/pdf/2503.18223, 2025-06-04
2025-11-10 23:01:12,888 - INFO - root - Page:15, Index:2, Progressive Prompt Detailing for Improved Alignment in Text-to-Image Generative Models, https://arxiv.org/pdf/2503.17794, 2025-05-30
2025-11-10 23:01:12,888 - INFO - root - Page:15, Index:3, CountLLM: Towards Generalizable Repetitive Action Counting via Large Language Model, https://arxiv.org/pdf/2503.17690, 2025-06-29
2025-11-10 23:01:12,889 - INFO - root - Page:15, Index:4, TaoAvatar: Real-Time Lifelike Full-Body Talking Avatars for Augmented Reality via 3D Gaussian Splatting, https://arxiv.org/pdf/2503.17032, 2025-07-23
2025-11-10 23:01:12,889 - INFO - root - Page:15, Index:5, Generalized Few-shot 3D Point Cloud Segmentation with Vision-Language Model, https://arxiv.org/pdf/2503.16282, 2025-05-20
2025-11-10 23:01:12,889 - INFO - root - Fetching page 17 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=800
2025-11-10 23:01:23,372 - INFO - root - get_all_titles_from_web 
2025-11-10 23:01:23,373 - INFO - root - Page:16, Index:0, High Temporal Consistency through Semantic Similarity Propagation in Semi-Supervised Video Semantic Segmentation for Autonomous Flight, https://arxiv.org/pdf/2503.15676, 2025-06-26
2025-11-10 23:01:23,374 - INFO - root - Page:16, Index:1, DPFlow: Adaptive Optical Flow Estimation with a Dual-Pyramid Framework, https://arxiv.org/pdf/2503.14880, 2025-09-29
2025-11-10 23:01:23,374 - INFO - root - Fetching page 18 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=850
2025-11-10 23:01:33,228 - INFO - root - get_all_titles_from_web 
2025-11-10 23:01:33,228 - INFO - root - Page:17, Index:0, From Head to Tail: Towards Balanced Representation in Large Vision-Language Models through Adaptive Data Calibration, https://arxiv.org/pdf/2503.12821, 2025-05-29
2025-11-10 23:01:33,229 - INFO - root - Page:17, Index:1, MambaIC: State Space Models for High-Performance Learned Image Compression, https://arxiv.org/pdf/2503.12461, 2025-08-22
2025-11-10 23:01:33,229 - INFO - root - Page:17, Index:2, Localized Concept Erasure for Text-to-Image Diffusion Models Using Training-Free Gated Low-Rank Adaptation, https://arxiv.org/pdf/2503.12356, 2025-07-09
2025-11-10 23:01:33,229 - INFO - root - Page:17, Index:3, TASTE-Rob: Advancing Video Generation of Task-Oriented Hand-Object Interaction for Generalizable Robotic Manipulation, https://arxiv.org/pdf/2503.11423, 2025-06-05
2025-11-10 23:01:33,230 - INFO - root - Page:17, Index:4, Panopticon: Advancing Any-Sensor Foundation Models for Earth Observation, https://arxiv.org/pdf/2503.10845, 2025-08-01
2025-11-10 23:01:33,230 - INFO - root - Page:17, Index:5, Transformers without Normalization, https://arxiv.org/pdf/2503.10622, 2025-06-14
2025-11-10 23:01:33,231 - INFO - root - Page:17, Index:6, dFLMoE: Decentralized Federated Learning via Mixture of Experts for Medical Data Analysis, https://arxiv.org/pdf/2503.10412, 2025-05-19
2025-11-10 23:01:33,231 - INFO - root - Fetching page 19 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=900
2025-11-10 23:01:39,953 - INFO - root - get_all_titles_from_web 
2025-11-10 23:01:39,953 - INFO - root - Page:18, Index:0, Project-Probe-Aggregate: Efficient Fine-Tuning for Group Robustness, https://arxiv.org/pdf/2503.09487, 2025-08-26
2025-11-10 23:01:39,954 - INFO - root - Page:18, Index:1, VLog: Video-Language Models by Generative Retrieval of Narration Vocabulary, https://arxiv.org/pdf/2503.09402, 2025-06-09
2025-11-10 23:01:39,954 - INFO - root - Fetching page 20 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=950
2025-11-10 23:01:47,482 - INFO - root - get_all_titles_from_web 
2025-11-10 23:01:47,483 - INFO - root - Page:19, Index:0, Escaping Plato's Cave: Towards the Alignment of 3D and Text Latent Spaces, https://arxiv.org/pdf/2503.05283, 2025-06-04
2025-11-10 23:01:47,483 - INFO - root - Page:19, Index:1, FluidNexus: 3D Fluid Reconstruction and Prediction from a Single Video, https://arxiv.org/pdf/2503.04720, 2025-07-09
2025-11-10 23:01:47,484 - INFO - root - Page:19, Index:2, Question-Aware Gaussian Experts for Audio-Visual Question Answering, https://arxiv.org/pdf/2503.04459, 2025-06-11
2025-11-10 23:01:47,484 - INFO - root - Page:19, Index:3, Q-Eval-100K: Evaluating Visual Quality and Alignment Level for Text-to-Vision Content, https://arxiv.org/pdf/2503.02357, 2025-06-15
2025-11-10 23:01:47,484 - INFO - root - Fetching page 21 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=1000
2025-11-10 23:01:54,184 - INFO - root - get_all_titles_from_web 
2025-11-10 23:01:54,184 - INFO - root - Page:20, Index:0, Data Distributional Properties As Inductive Bias for Systematic Generalization, https://arxiv.org/pdf/2502.20499, 2025-06-17
2025-11-10 23:01:54,186 - INFO - root - Page:20, Index:1, Knowledge Bridger: Towards Training-free Missing Modality Completion, https://arxiv.org/pdf/2502.19834, 2025-06-17
2025-11-10 23:01:54,188 - INFO - root - Fetching page 22 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=1050
2025-11-10 23:02:00,650 - INFO - root - get_all_titles_from_web 
2025-11-10 23:02:00,650 - INFO - root - Page:21, Index:0, MALT Diffusion: Memory-Augmented Latent Transformers for Any-Length Video Generation, https://arxiv.org/pdf/2502.12632, 2025-07-08
2025-11-10 23:02:00,650 - INFO - root - Page:21, Index:1, ILIAS: Instance-Level Image retrieval At Scale, https://arxiv.org/pdf/2502.11748, 2025-06-23
2025-11-10 23:02:00,652 - INFO - root - Page:21, Index:2, Distraction is All You Need for Multimodal Large Language Model Jailbreaking, https://arxiv.org/pdf/2502.10794, 2025-06-16
2025-11-10 23:02:00,652 - INFO - root - Page:21, Index:3, Spatial457: A Diagnostic Benchmark for 6D Spatial Reasoning of Large Multimodal Models, https://arxiv.org/pdf/2502.08636, 2025-06-08
2025-11-10 23:02:00,652 - INFO - root - Page:21, Index:4, TRAVEL: Training-Free Retrieval and Alignment for Vision-and-Language Navigation, https://arxiv.org/pdf/2502.07306, 2025-06-09
2025-11-10 23:02:00,652 - INFO - root - Page:21, Index:5, DiTASK: Multi-Task Fine-Tuning with Diffeomorphic Transformations, https://arxiv.org/pdf/2502.06029, 2025-06-01
2025-11-10 23:02:00,653 - INFO - root - Page:21, Index:6, ConceptAttention: Diffusion Transformers Learn Highly Interpretable Features, https://arxiv.org/pdf/2502.04320, 2025-07-01
2025-11-10 23:02:00,653 - INFO - root - Page:21, Index:7, GCE-Pose: Global Context Enhancement for Category-level Object Pose Estimation, https://arxiv.org/pdf/2502.04293, 2025-06-24
2025-11-10 23:02:00,653 - INFO - root - Page:21, Index:8, Calibrated Multi-Preference Optimization for Aligning Diffusion Models, https://arxiv.org/pdf/2502.02588, 2025-09-26
2025-11-10 23:02:00,654 - INFO - root - Page:21, Index:9, Instruct-4DGS: Efficient Dynamic Scene Editing via 4D Gaussian-based Static-Dynamic Separation, https://arxiv.org/pdf/2502.02091, 2025-07-01
2025-11-10 23:02:00,654 - INFO - root - Page:21, Index:10, Low-Resource Video Super-Resolution using Memory, Wavelets, and Deformable Convolutions, https://arxiv.org/pdf/2502.01816, 2025-06-19
2025-11-10 23:02:00,654 - INFO - root - Page:21, Index:11, Bridging Text and Crystal Structures: Literature-driven Contrastive Learning for Materials Science, https://arxiv.org/pdf/2501.12919, 2025-06-18
2025-11-10 23:02:00,654 - INFO - root - Page:21, Index:12, T2ISafety: Benchmark for Assessing Fairness, Toxicity, and Privacy in Image Generation, https://arxiv.org/pdf/2501.12612, 2025-07-25
2025-11-10 23:02:00,655 - INFO - root - Page:21, Index:13, Fine-Grained Image-Text Correspondence with Cost Aggregation for Open-Vocabulary Part Segmentation, https://arxiv.org/pdf/2501.09688, 2025-08-08
2025-11-10 23:02:00,655 - INFO - root - Fetching page 23 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=1100
2025-11-10 23:02:07,239 - INFO - root - get_all_titles_from_web 
2025-11-10 23:02:07,239 - INFO - root - Page:22, Index:0, Bias for Action: Video Implicit Neural Representations with Bias Modulation, https://arxiv.org/pdf/2501.09277, 2025-06-06
2025-11-10 23:02:07,240 - INFO - root - Page:22, Index:1, MonSter++: Unified Stereo Matching, Multi-view Stereo, and Real-time Stereo with Monodepth Priors, https://arxiv.org/pdf/2501.08643, 2025-09-25
2025-11-10 23:02:07,240 - INFO - root - Page:22, Index:2, Go-with-the-Flow: Motion-Controllable Video Diffusion Models Using Real-Time Warped Noise, https://arxiv.org/pdf/2501.08331, 2025-08-06
2025-11-10 23:02:07,240 - INFO - root - Page:22, Index:3, Nonisotropic Gaussian Diffusion for Realistic 3D Human Motion Prediction, https://arxiv.org/pdf/2501.06035, 2025-07-08
2025-11-10 23:02:07,240 - INFO - root - Page:22, Index:4, Discovering Hidden Visual Concepts Beyond Linguistic Input in Infant Learning, https://arxiv.org/pdf/2501.05205, 2025-06-13
2025-11-10 23:02:07,241 - INFO - root - Page:22, Index:5, PERSE: Personalized 3D Generative Avatars from A Single Portrait, https://arxiv.org/pdf/2412.21206, 2025-09-28
2025-11-10 23:02:07,241 - INFO - root - Page:22, Index:6, MaskGaussian: Adaptive 3D Gaussian Representation from Probabilistic Masks, https://arxiv.org/pdf/2412.20522, 2025-06-14
2025-11-10 23:02:07,241 - INFO - root - Page:22, Index:7, SimLTD: Simple Supervised and Semi-Supervised Long-Tailed Object Detection, https://arxiv.org/pdf/2412.20047, 2025-06-09
2025-11-10 23:02:07,242 - INFO - root - Page:22, Index:8, Conditional Balance: Improving Multi-Conditioning Trade-Offs in Image Generation, https://arxiv.org/pdf/2412.19853, 2025-08-03
2025-11-10 23:02:07,242 - INFO - root - Fetching page 24 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=1150
2025-11-10 23:02:14,321 - INFO - root - get_all_titles_from_web 
2025-11-10 23:02:14,321 - INFO - root - Page:23, Index:0, CoCoGaussian: Leveraging Circle of Confusion for Gaussian Splatting from Defocused Images, https://arxiv.org/pdf/2412.16028, 2025-05-15
2025-11-10 23:02:14,321 - INFO - root - Page:23, Index:1, EnergyMoGen: Compositional Human Motion Generation with Energy-Based Diffusion Model in Latent Space, https://arxiv.org/pdf/2412.14706, 2025-06-04
2025-11-10 23:02:14,322 - INFO - root - Page:23, Index:2, DarkIR: Robust Low-Light Image Restoration, https://arxiv.org/pdf/2412.13443, 2025-10-14
2025-11-10 23:02:14,322 - INFO - root - Page:23, Index:3, FastVLM: Efficient Vision Encoding for Vision Language Models, https://arxiv.org/pdf/2412.13303, 2025-05-15
2025-11-10 23:02:14,323 - INFO - root - Page:23, Index:4, Real-time Free-view Human Rendering from Sparse-view RGB Videos using Double Unprojected Textures, https://arxiv.org/pdf/2412.13183, 2025-06-20
2025-11-10 23:02:14,324 - INFO - root - Page:23, Index:5, CondiMen: Conditional Multi-Person Mesh Recovery, https://arxiv.org/pdf/2412.13058, 2025-06-04
2025-11-10 23:02:14,324 - INFO - root - Page:23, Index:6, MASt3R-SLAM: Real-Time Dense SLAM with 3D Reconstruction Priors, https://arxiv.org/pdf/2412.12392, 2025-06-02
2025-11-10 23:02:14,325 - INFO - root - Page:23, Index:7, DynamicScaler: Seamless and Scalable Video Generation for Panoramic Scenes, https://arxiv.org/pdf/2412.11100, 2025-10-04
2025-11-10 23:02:14,325 - INFO - root - Page:23, Index:8, SnapGen-V: Generating a Five-Second Video within Five Seconds on a Mobile Device, https://arxiv.org/pdf/2412.10494, 2025-06-09
2025-11-10 23:02:14,325 - INFO - root - Page:23, Index:9, Mr. DETR++: Instructive Multi-Route Training for Detection Transformers with Mixture-of-Experts, https://arxiv.org/pdf/2412.10028, 2025-06-26
2025-11-10 23:02:14,326 - INFO - root - Page:23, Index:10, LinGen: Towards High-Resolution Minute-Length Text-to-Video Generation with Linear Computational Complexity, https://arxiv.org/pdf/2412.09856, 2025-05-24
2025-11-10 23:02:14,327 - INFO - root - Page:23, Index:11, Gaze-LLE: Gaze Target Estimation via Large-Scale Learned Encoders, https://arxiv.org/pdf/2412.09586, 2025-06-03
2025-11-10 23:02:14,328 - INFO - root - Fetching page 25 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=1200
2025-11-10 23:02:21,759 - INFO - root - get_all_titles_from_web 
2025-11-10 23:02:21,760 - INFO - root - Page:24, Index:0, From Slow Bidirectional to Fast Autoregressive Video Diffusion Models, https://arxiv.org/pdf/2412.07772, 2025-09-23
2025-11-10 23:02:21,760 - INFO - root - Page:24, Index:1, Rate-In: Information-Driven Adaptive Dropout Rates for Improved Inference-Time Uncertainty Estimation, https://arxiv.org/pdf/2412.07169, 2025-06-03
2025-11-10 23:02:21,760 - INFO - root - Page:24, Index:2, FIRE: Robust Detection of Diffusion-Generated Images via Frequency-Guided Reconstruction Error, https://arxiv.org/pdf/2412.07140, 2025-11-03
2025-11-10 23:02:21,761 - INFO - root - Page:24, Index:3, Birth and Death of a Rose, https://arxiv.org/pdf/2412.05278, 2025-06-05
2025-11-10 23:02:21,761 - INFO - root - Page:24, Index:4, DualPM: Dual Posed-Canonical Point Maps for 3D Shape and Pose Reconstruction, https://arxiv.org/pdf/2412.04464, 2025-08-14
2025-11-10 23:02:21,761 - INFO - root - Page:24, Index:5, SeeGround: See and Ground for Zero-Shot Open-Vocabulary 3D Visual Grounding, https://arxiv.org/pdf/2412.04383, 2025-05-29
2025-11-10 23:02:21,761 - INFO - root - ------------------------------------------------------------------------------------------------------------------------
2025-11-10 23:02:37,818 - INFO - root - 正在总结论文 1/2: Learning to Seek Evidence: A Verifiable Reasoning Agent with Causal Faithfulness Analysis
2025-11-10 23:03:28,449 - INFO - root - LLMClient: rate limit reached, sleeping 9.4s
2025-11-10 23:03:57,616 - INFO - root - 正在提取论文图片...
2025-11-10 23:03:57,795 - INFO - root - 已保存图片 1/10：./export\images_Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness\figure_1_page2.jpeg
2025-11-10 23:03:57,801 - INFO - root - 已保存图片 2/10：./export\images_Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness\figure_2_page2.jpeg
2025-11-10 23:03:57,816 - INFO - root - 已保存图片 3/10：./export\images_Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness\figure_3_page2.jpeg
2025-11-10 23:03:57,822 - INFO - root - 已保存图片 4/10：./export\images_Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness\figure_4_page2.jpeg
2025-11-10 23:03:57,837 - INFO - root - 已保存图片 5/10：./export\images_Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness\figure_5_page2.jpeg
2025-11-10 23:03:57,848 - INFO - root - 已保存图片 6/10：./export\images_Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness\figure_6_page2.jpeg
2025-11-10 23:03:57,864 - INFO - root - 已保存图片 7/10：./export\images_Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness\figure_7_page2.jpeg
2025-11-10 23:03:57,883 - INFO - root - 已保存图片 8/10：./export\images_Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness\figure_8_page2.jpeg
2025-11-10 23:03:57,921 - INFO - root - 已保存图片 9/10：./export\images_Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness\figure_9_page2.jpeg
2025-11-10 23:03:57,940 - INFO - root - 已保存图片 10/10：./export\images_Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness\figure_10_page2.jpeg
2025-11-10 23:03:57,944 - INFO - root - 成功添加图片 1：./export\images_Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness\figure_1_page2.jpeg
2025-11-10 23:03:57,945 - INFO - root - 成功添加图片 2：./export\images_Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness\figure_2_page2.jpeg
2025-11-10 23:03:57,946 - INFO - root - 成功添加图片 3：./export\images_Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness\figure_3_page2.jpeg
2025-11-10 23:03:57,947 - INFO - root - 成功添加图片 4：./export\images_Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness\figure_4_page2.jpeg
2025-11-10 23:03:57,947 - INFO - root - 成功添加图片 5：./export\images_Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness\figure_5_page2.jpeg
2025-11-10 23:03:57,947 - INFO - root - 成功添加图片 6：./export\images_Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness\figure_6_page2.jpeg
2025-11-10 23:03:57,949 - INFO - root - 成功添加图片 7：./export\images_Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness\figure_7_page2.jpeg
2025-11-10 23:03:57,949 - INFO - root - 成功添加图片 8：./export\images_Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness\figure_8_page2.jpeg
2025-11-10 23:03:57,950 - INFO - root - 成功添加图片 9：./export\images_Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness\figure_9_page2.jpeg
2025-11-10 23:03:57,950 - INFO - root - 成功添加图片 10：./export\images_Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness\figure_10_page2.jpeg
2025-11-10 23:03:57,977 - INFO - root - 论文《Learning to Seek Evidence: A Verifiable Reasoning Agent with Causal Faithfulness Analysis》的分析已保存到 ./export\QAT\Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness.md
2025-11-10 23:03:57,991 - INFO - root - 正在总结论文 2/2: OmniTrack++: Omnidirectional Multi-Object Tracking by Learning Large-FoV Trajectory Feedback
2025-11-10 23:04:12,676 - INFO - root - LLMClient: rate limit reached, sleeping 25.1s
2025-11-10 23:07:48,949 - INFO - root - 正在提取论文图片...
2025-11-10 23:07:49,383 - INFO - root - 已保存图片 1/10：./export\images_OmniTrack++_ Omnidirectional Multi-Object Tracking by Learning Large-FoV Traject\figure_1_page13.jpeg
2025-11-10 23:07:49,436 - INFO - root - 已保存图片 2/10：./export\images_OmniTrack++_ Omnidirectional Multi-Object Tracking by Learning Large-FoV Traject\figure_2_page13.jpeg
2025-11-10 23:07:49,482 - INFO - root - 已保存图片 3/10：./export\images_OmniTrack++_ Omnidirectional Multi-Object Tracking by Learning Large-FoV Traject\figure_3_page13.jpeg
2025-11-10 23:07:49,535 - INFO - root - 已保存图片 4/10：./export\images_OmniTrack++_ Omnidirectional Multi-Object Tracking by Learning Large-FoV Traject\figure_4_page2.jpeg
2025-11-10 23:07:49,594 - INFO - root - 已保存图片 5/10：./export\images_OmniTrack++_ Omnidirectional Multi-Object Tracking by Learning Large-FoV Traject\figure_5_page5.png
2025-11-10 23:07:49,627 - INFO - root - 已保存图片 6/10：./export\images_OmniTrack++_ Omnidirectional Multi-Object Tracking by Learning Large-FoV Traject\figure_6_page13.jpeg
2025-11-10 23:07:49,667 - INFO - root - 已保存图片 7/10：./export\images_OmniTrack++_ Omnidirectional Multi-Object Tracking by Learning Large-FoV Traject\figure_7_page2.jpeg
2025-11-10 23:07:49,701 - INFO - root - 已保存图片 8/10：./export\images_OmniTrack++_ Omnidirectional Multi-Object Tracking by Learning Large-FoV Traject\figure_8_page8.jpeg
2025-11-10 23:07:49,726 - INFO - root - 已保存图片 9/10：./export\images_OmniTrack++_ Omnidirectional Multi-Object Tracking by Learning Large-FoV Traject\figure_9_page1.jpeg
2025-11-10 23:07:49,748 - INFO - root - 已保存图片 10/10：./export\images_OmniTrack++_ Omnidirectional Multi-Object Tracking by Learning Large-FoV Traject\figure_10_page1.png
2025-11-10 23:07:49,756 - INFO - root - 成功添加图片 1：./export\images_OmniTrack++_ Omnidirectional Multi-Object Tracking by Learning Large-FoV Traject\figure_1_page13.jpeg
2025-11-10 23:07:49,756 - INFO - root - 成功添加图片 2：./export\images_OmniTrack++_ Omnidirectional Multi-Object Tracking by Learning Large-FoV Traject\figure_2_page13.jpeg
2025-11-10 23:07:49,757 - INFO - root - 成功添加图片 3：./export\images_OmniTrack++_ Omnidirectional Multi-Object Tracking by Learning Large-FoV Traject\figure_3_page13.jpeg
2025-11-10 23:07:49,757 - INFO - root - 成功添加图片 4：./export\images_OmniTrack++_ Omnidirectional Multi-Object Tracking by Learning Large-FoV Traject\figure_4_page2.jpeg
2025-11-10 23:07:49,757 - INFO - root - 成功添加图片 5：./export\images_OmniTrack++_ Omnidirectional Multi-Object Tracking by Learning Large-FoV Traject\figure_5_page5.png
2025-11-10 23:07:49,758 - INFO - root - 成功添加图片 6：./export\images_OmniTrack++_ Omnidirectional Multi-Object Tracking by Learning Large-FoV Traject\figure_6_page13.jpeg
2025-11-10 23:07:49,758 - INFO - root - 成功添加图片 7：./export\images_OmniTrack++_ Omnidirectional Multi-Object Tracking by Learning Large-FoV Traject\figure_7_page2.jpeg
2025-11-10 23:07:49,758 - INFO - root - 成功添加图片 8：./export\images_OmniTrack++_ Omnidirectional Multi-Object Tracking by Learning Large-FoV Traject\figure_8_page8.jpeg
2025-11-10 23:07:49,759 - INFO - root - 成功添加图片 9：./export\images_OmniTrack++_ Omnidirectional Multi-Object Tracking by Learning Large-FoV Traject\figure_9_page1.jpeg
2025-11-10 23:07:49,759 - INFO - root - 成功添加图片 10：./export\images_OmniTrack++_ Omnidirectional Multi-Object Tracking by Learning Large-FoV Traject\figure_10_page1.png
2025-11-10 23:07:49,770 - INFO - root - 论文《OmniTrack++: Omnidirectional Multi-Object Tracking by Learning Large-FoV Trajectory Feedback》的分析已保存到 ./export\QAT\OmniTrack++_ Omnidirectional Multi-Object Tracking by Learning Large-FoV Traject.md
2025-11-10 23:07:49,837 - WARNING - root - 生成汇总Excel表格失败: No module named 'openpyxl'
2025-11-10 23:07:49,842 - INFO - root - summary time: 521.96 seconds
2025-11-10 23:16:46,805 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-10 23:16:46,807 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-10 23:16:46,808 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-10 23:16:48,273 - INFO - root - LLMClientManager: 指定使用客户端: Gemini
2025-11-10 23:16:50,460 - INFO - root - GeminiClient: trying model models/gemini-2.5-flash
2025-11-10 23:16:53,768 - INFO - root - GeminiClient: initialized model gemini-2.5-flash
2025-11-10 23:16:53,769 - INFO - root - LLMClientManager: Gemini 客户端初始化成功
2025-11-10 23:16:53,770 - INFO - root - LLMClientManager: switched to Gemini client
2025-11-10 23:16:53,771 - INFO - root - 已手动切换到 LLM 客户端: Gemini
2025-11-10 23:16:53,771 - INFO - root - 使用 LLM 模型: gemini-2.5-flash
2025-11-10 23:16:53,773 - INFO - root - 可用客户端: ['Gemini']
2025-11-10 23:16:53,774 - INFO - root - === 运行配置 ===
2025-11-10 23:16:53,775 - INFO - root - 处理模式: arxiv在线搜索
2025-11-10 23:16:53,775 - INFO - root - 关键词: QAT
2025-11-10 23:16:53,776 - INFO - root - 查询: CVPR 2026
2025-11-10 23:16:53,777 - INFO - root - 排序: None
2025-11-10 23:16:53,778 - INFO - root - 最近天数: 180
2025-11-10 23:16:53,786 - INFO - root - 最大处理数量: 2
2025-11-10 23:16:53,788 - INFO - root - 保存图片: 是
2025-11-10 23:16:53,789 - INFO - root - 输出语言: 中文
2025-11-10 23:16:53,789 - INFO - root - 强制重新处理: 否
2025-11-10 23:16:53,789 - INFO - root - ====================
2025-11-10 23:16:53,790 - INFO - root - 使用 arXiv 搜索模式（通过 chat_arxiv 模块获取）
2025-11-10 23:16:53,790 - INFO - root - Fetching page 1 with URL: https://arxiv.org/search/?query=CVPR+2026&searchtype=all&abstracts=show&order=-announced_date_first&size=50
2025-11-10 23:17:00,013 - INFO - root - get_all_titles_from_web 
2025-11-10 23:17:00,154 - INFO - root - Page:0, Index:0, Learning to Seek Evidence: A Verifiable Reasoning Agent with Causal Faithfulness Analysis, https://arxiv.org/pdf/2511.01425, 2025-11-03
2025-11-10 23:17:00,264 - INFO - root - Fetching page 2 with URL: https://arxiv.org/search/?query=CVPR+2026&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=50
2025-11-10 23:17:06,660 - INFO - root - ------------------------------------------------------------------------------------------------------------------------
2025-11-10 23:17:18,416 - INFO - root - 跳过已处理论文 Learning to Seek Evidence: A Verifiable Reasoning Agent with Causal Faithfulness Analysis：d:\ChatPaper\academic Papers\CVPR 2026\Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness.pdf
2025-11-10 23:17:25,317 - WARNING - root - 未找到论文信息: 2511.01425
2025-11-10 23:17:25,333 - WARNING - root - 生成汇总Excel表格失败: No module named 'openpyxl'
2025-11-10 23:17:25,334 - INFO - root - summary time: 38.53 seconds
2025-11-10 23:25:03,333 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-10 23:25:03,333 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-10 23:25:03,336 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-10 23:25:04,198 - INFO - root - LLMClientManager: 指定使用客户端: Gemini
2025-11-10 23:25:05,057 - INFO - root - GeminiClient: trying model models/gemini-2.5-flash
2025-11-10 23:25:06,742 - INFO - root - GeminiClient: initialized model gemini-2.5-flash
2025-11-10 23:25:06,743 - INFO - root - LLMClientManager: Gemini 客户端初始化成功
2025-11-10 23:25:06,743 - INFO - root - LLMClientManager: switched to Gemini client
2025-11-10 23:25:06,743 - INFO - root - 已手动切换到 LLM 客户端: Gemini
2025-11-10 23:25:06,743 - INFO - root - 使用 LLM 模型: gemini-2.5-flash
2025-11-10 23:25:06,744 - INFO - root - 可用客户端: ['Gemini']
2025-11-10 23:25:06,745 - INFO - root - === 运行配置 ===
2025-11-10 23:25:06,745 - INFO - root - 处理模式: arxiv在线搜索
2025-11-10 23:25:06,745 - INFO - root - 关键词: QAT
2025-11-10 23:25:06,745 - INFO - root - 查询: CVPR 2026
2025-11-10 23:25:06,746 - INFO - root - 排序: None
2025-11-10 23:25:06,746 - INFO - root - 最近天数: 180
2025-11-10 23:25:06,747 - INFO - root - 最大处理数量: 2
2025-11-10 23:25:06,747 - INFO - root - 保存图片: 是
2025-11-10 23:25:06,747 - INFO - root - 输出语言: 中文
2025-11-10 23:25:06,747 - INFO - root - 强制重新处理: 否
2025-11-10 23:25:06,748 - INFO - root - ====================
2025-11-10 23:25:06,748 - INFO - root - 使用 arXiv 搜索模式（通过 chat_arxiv 模块获取）
2025-11-10 23:25:06,749 - INFO - root - Fetching page 1 with URL: https://arxiv.org/search/?query=CVPR+2026&searchtype=all&abstracts=show&order=-announced_date_first&size=50
2025-11-10 23:25:12,993 - INFO - root - get_all_titles_from_web 
2025-11-10 23:25:12,994 - INFO - root - Page:0, Index:0, Learning to Seek Evidence: A Verifiable Reasoning Agent with Causal Faithfulness Analysis, https://arxiv.org/pdf/2511.01425, 2025-11-03
2025-11-10 23:25:12,994 - INFO - root - Fetching page 2 with URL: https://arxiv.org/search/?query=CVPR+2026&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=50
2025-11-10 23:25:19,507 - INFO - root - ------------------------------------------------------------------------------------------------------------------------
2025-11-10 23:25:19,509 - INFO - root - File already exists, skipping download: D:\ChatPaper\academic Papers\CVPR 2026\Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness.pdf
2025-11-10 23:25:19,511 - INFO - root - 正在总结论文 1/1: Learning to Seek Evidence: A Verifiable Reasoning Agent with Causal Faithfulness Analysis
2025-11-10 23:28:36,131 - INFO - root - 正在提取论文图片...
2025-11-10 23:28:36,304 - INFO - root - 已保存图片 1/10：./export\images_Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness\figure_1_page2.jpeg
2025-11-10 23:28:36,314 - INFO - root - 已保存图片 2/10：./export\images_Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness\figure_2_page2.jpeg
2025-11-10 23:28:36,325 - INFO - root - 已保存图片 3/10：./export\images_Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness\figure_3_page2.jpeg
2025-11-10 23:28:36,402 - INFO - root - 已保存图片 4/10：./export\images_Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness\figure_4_page2.jpeg
2025-11-10 23:28:36,431 - INFO - root - 已保存图片 5/10：./export\images_Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness\figure_5_page2.jpeg
2025-11-10 23:28:36,450 - INFO - root - 已保存图片 6/10：./export\images_Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness\figure_6_page2.jpeg
2025-11-10 23:28:36,467 - INFO - root - 已保存图片 7/10：./export\images_Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness\figure_7_page2.jpeg
2025-11-10 23:28:36,480 - INFO - root - 已保存图片 8/10：./export\images_Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness\figure_8_page2.jpeg
2025-11-10 23:28:36,522 - INFO - root - 已保存图片 9/10：./export\images_Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness\figure_9_page2.jpeg
2025-11-10 23:28:36,539 - INFO - root - 已保存图片 10/10：./export\images_Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness\figure_10_page2.jpeg
2025-11-10 23:28:36,541 - INFO - root - 成功添加图片 1：./export\images_Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness\figure_1_page2.jpeg
2025-11-10 23:28:36,546 - INFO - root - 成功添加图片 2：./export\images_Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness\figure_2_page2.jpeg
2025-11-10 23:28:36,550 - INFO - root - 成功添加图片 3：./export\images_Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness\figure_3_page2.jpeg
2025-11-10 23:28:36,551 - INFO - root - 成功添加图片 4：./export\images_Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness\figure_4_page2.jpeg
2025-11-10 23:28:36,553 - INFO - root - 成功添加图片 5：./export\images_Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness\figure_5_page2.jpeg
2025-11-10 23:28:36,553 - INFO - root - 成功添加图片 6：./export\images_Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness\figure_6_page2.jpeg
2025-11-10 23:28:36,554 - INFO - root - 成功添加图片 7：./export\images_Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness\figure_7_page2.jpeg
2025-11-10 23:28:36,554 - INFO - root - 成功添加图片 8：./export\images_Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness\figure_8_page2.jpeg
2025-11-10 23:28:36,557 - INFO - root - 成功添加图片 9：./export\images_Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness\figure_9_page2.jpeg
2025-11-10 23:28:36,557 - INFO - root - 成功添加图片 10：./export\images_Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness\figure_10_page2.jpeg
2025-11-10 23:28:42,122 - WARNING - root - 未找到论文信息: 2511.01425
2025-11-10 23:28:42,132 - INFO - root - 论文《Learning to Seek Evidence: A Verifiable Reasoning Agent with Causal Faithfulness Analysis》的分析已保存到 ./export\QAT\Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness.md
2025-11-10 23:28:47,557 - WARNING - root - 未找到论文信息: 2511.01425
2025-11-10 23:28:47,848 - INFO - root - 已生成汇总Excel表格: ./export\QAT\论文汇总_QAT_20251110_232847.xlsx
2025-11-10 23:28:47,849 - INFO - root - 已生成汇总Excel表格: ./export\QAT\论文汇总_QAT_20251110_232847.xlsx
2025-11-10 23:28:47,849 - INFO - root - summary time: 224.52 seconds
2025-11-10 23:36:24,184 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-10 23:36:24,185 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-10 23:36:24,186 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-10 23:36:26,188 - INFO - root - LLMClientManager: 指定使用客户端: Gemini
2025-11-10 23:36:27,300 - INFO - root - GeminiClient: trying model models/gemini-2.5-flash
2025-11-10 23:36:31,172 - INFO - root - GeminiClient: initialized model gemini-2.5-flash
2025-11-10 23:36:31,172 - INFO - root - LLMClientManager: Gemini 客户端初始化成功
2025-11-10 23:36:31,173 - INFO - root - LLMClientManager: switched to Gemini client
2025-11-10 23:36:31,174 - INFO - root - 已手动切换到 LLM 客户端: Gemini
2025-11-10 23:36:31,174 - INFO - root - 使用 LLM 模型: gemini-2.5-flash
2025-11-10 23:36:31,175 - INFO - root - 可用客户端: ['Gemini']
2025-11-10 23:36:31,176 - INFO - root - === 运行配置 ===
2025-11-10 23:36:31,177 - INFO - root - 处理模式: arxiv在线搜索
2025-11-10 23:36:31,177 - INFO - root - 关键词: QAT
2025-11-10 23:36:31,178 - INFO - root - 查询: Quantization-Aware-Training
2025-11-10 23:36:31,179 - INFO - root - 排序: None
2025-11-10 23:36:31,180 - INFO - root - 最近天数: 180
2025-11-10 23:36:31,181 - INFO - root - 最大处理数量: 2
2025-11-10 23:36:31,187 - INFO - root - 保存图片: 是
2025-11-10 23:36:31,188 - INFO - root - 输出语言: 中文
2025-11-10 23:36:31,189 - INFO - root - 强制重新处理: 否
2025-11-10 23:36:31,189 - INFO - root - ====================
2025-11-10 23:36:31,190 - INFO - root - 使用 arXiv 搜索模式（通过 chat_arxiv 模块获取）
2025-11-10 23:36:31,191 - INFO - root - Fetching page 1 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50
2025-11-10 23:36:38,764 - INFO - root - get_all_titles_from_web 
2025-11-10 23:36:38,764 - INFO - root - Page:0, Index:0, Data Efficiency and Transfer Robustness in Biomedical Image Segmentation: A Study of Redundancy and Forgetting with Cellpose, https://arxiv.org/pdf/2511.04803, 2025-11-06
2025-11-10 23:36:38,764 - INFO - root - Page:0, Index:1, A Quantized VAE-MLP Botnet Detection Model: A Systematic Evaluation of Quantization-Aware Training and Post-Training Quantization Strategies, https://arxiv.org/pdf/2511.03201, 2025-11-05
2025-11-10 23:36:38,766 - INFO - root - Page:0, Index:2, FP8-Flow-MoE: A Casting-Free FP8 Recipe without Double Quantization Error, https://arxiv.org/pdf/2511.02302, 2025-11-04
2025-11-10 23:36:38,766 - INFO - root - Page:0, Index:3, Outlier-Aware Post-Training Quantization for Image Super-Resolution, https://arxiv.org/pdf/2511.00682, 2025-11-01
2025-11-10 23:36:38,766 - INFO - root - Page:0, Index:4, Evaluation of Wafer-Scale SOT-MRAM for Analog Crossbar Array Applications, https://arxiv.org/pdf/2510.25853, 2025-11-03
2025-11-10 23:36:38,766 - INFO - root - Page:0, Index:5, Improving the Straight-Through Estimator with Zeroth-Order Information, https://arxiv.org/pdf/2510.23926, 2025-10-27
2025-11-10 23:36:38,767 - INFO - root - Page:0, Index:6, Real-Time Semantic Segmentation on FPGA for Autonomous Vehicles Using LMIINet with the CGRA4ML Framework, https://arxiv.org/pdf/2510.22243, 2025-10-25
2025-11-10 23:36:38,767 - INFO - root - Page:0, Index:7, TernaryCLIP: Efficiently Compressing Vision-Language Models with Ternary Weights and Distilled Knowledge, https://arxiv.org/pdf/2510.21879, 2025-10-23
2025-11-10 23:36:38,767 - INFO - root - Page:0, Index:8, KARIPAP: Quantum-Inspired Tensor Network Compression of Large Language Models Using Infinite Projected Entangled Pair States and Tensor Renormalization Group, https://arxiv.org/pdf/2510.21844, 2025-10-22
2025-11-10 23:36:38,767 - INFO - root - Page:0, Index:9, A Convergence Analysis of Adaptive Optimizers under Floating-point Quantization, https://arxiv.org/pdf/2510.21314, 2025-10-24
2025-11-10 23:36:38,768 - INFO - root - Page:0, Index:10, Adaptive Distribution-aware Quantization for Mixed-Precision Neural Networks, https://arxiv.org/pdf/2510.19760, 2025-10-22
2025-11-10 23:36:38,768 - INFO - root - Page:0, Index:11, CAGE: Curvature-Aware Gradient Estimation For Accurate Quantization-Aware Training, https://arxiv.org/pdf/2510.18784, 2025-10-21
2025-11-10 23:36:38,768 - INFO - root - Page:0, Index:12, Mixed-Precision Quantization for Language Models: Techniques and Prospects, https://arxiv.org/pdf/2510.16805, 2025-10-19
2025-11-10 23:36:38,768 - INFO - root - Page:0, Index:13, SPLite Hand: Sparsity-Aware Lightweight 3D Hand Pose Estimation, https://arxiv.org/pdf/2510.16396, 2025-10-30
2025-11-10 23:36:38,769 - INFO - root - Page:0, Index:14, CTR-LoRA: Curvature-Aware and Trust-Region Guided Low-Rank Adaptation for Large Language Models, https://arxiv.org/pdf/2510.15962, 2025-10-11
2025-11-10 23:36:38,769 - INFO - root - Page:0, Index:15, SANR: Scene-Aware Neural Representation for Light Field Image Compression with Rate-Distortion Optimization, https://arxiv.org/pdf/2510.15775, 2025-10-17
2025-11-10 23:36:38,769 - INFO - root - Page:0, Index:16, SpikeFit: Towards Optimal Deployment of Spiking Networks on Neuromorphic Hardware, https://arxiv.org/pdf/2510.15542, 2025-10-31
2025-11-10 23:36:38,770 - INFO - root - Page:0, Index:17, GRank: Towards Target-Aware and Streamlined Industrial Retrieval with a Generate-Rank Framework, https://arxiv.org/pdf/2510.15299, 2025-10-17
2025-11-10 23:36:38,770 - INFO - root - Page:0, Index:18, SaLon3R: Structure-aware Long-term Generalizable 3D Reconstruction from Unposed Images, https://arxiv.org/pdf/2510.15072, 2025-10-16
2025-11-10 23:36:38,771 - INFO - root - Page:0, Index:19, FraQAT: Quantization Aware Training with Fractional bits, https://arxiv.org/pdf/2510.14823, 2025-10-16
2025-11-10 23:36:38,771 - INFO - root - Page:0, Index:20, Computing-In-Memory Aware Model Adaption For Edge Devices, https://arxiv.org/pdf/2510.14379, 2025-10-16
2025-11-10 23:36:38,772 - INFO - root - Page:0, Index:21, Invited Paper: BitMedViT: Ternary-Quantized Vision Transformer for Medical AI Assistants on the Edge, https://arxiv.org/pdf/2510.13760, 2025-11-04
2025-11-10 23:36:38,774 - INFO - root - Page:0, Index:22, NeuroRVQ: Multi-Scale EEG Tokenization for Generative Large Brainwave Models, https://arxiv.org/pdf/2510.13068, 2025-10-14
2025-11-10 23:36:38,775 - INFO - root - Page:0, Index:23, Detect Anything via Next Point Prediction, https://arxiv.org/pdf/2510.12798, 2025-10-14
2025-11-10 23:36:38,776 - INFO - root - Page:0, Index:24, AndesVL Technical Report: An Efficient Mobile-side Multimodal Large Language Model, https://arxiv.org/pdf/2510.11496, 2025-10-14
2025-11-10 23:36:38,776 - INFO - root - Page:0, Index:25, Rescaling-Aware Training for Efficient Deployment of Deep Learning Models on Full-Integer Hardware, https://arxiv.org/pdf/2510.11484, 2025-10-13
2025-11-10 23:36:38,776 - INFO - root - Page:0, Index:26, SASER: Stego attacks on open-source LLMs, https://arxiv.org/pdf/2510.10486, 2025-10-12
2025-11-10 23:36:38,778 - INFO - root - Page:0, Index:27, Ultralytics YOLO Evolution: An Overview of YOLO26, YOLO11, YOLOv8 and YOLOv5 Object Detectors for Computer Vision and Pattern Recognition, https://arxiv.org/pdf/2510.09653, 2025-10-15
2025-11-10 23:36:38,778 - INFO - root - Page:0, Index:28, A Theoretically-Grounded Codebook for Digital Semantic Communications, https://arxiv.org/pdf/2510.07108, 2025-10-14
2025-11-10 23:36:38,778 - INFO - root - Page:0, Index:29, QuantDemoire: Quantization with Outlier Aware for Image Demoiréing, https://arxiv.org/pdf/2510.04066, 2025-10-05
2025-11-10 23:36:38,779 - INFO - root - Page:0, Index:30, Adaptively Sampling-Reusing-Mixing Decomposed Gradients to Speed Up Sharpness Aware Minimization, https://arxiv.org/pdf/2510.03763, 2025-10-04
2025-11-10 23:36:38,780 - INFO - root - Page:0, Index:31, Quant-dLLM: Post-Training Extreme Low-Bit Quantization for Diffusion Large Language Models, https://arxiv.org/pdf/2510.03274, 2025-09-27
2025-11-10 23:36:38,780 - INFO - root - Page:0, Index:32, PT$^2$-LLM: Post-Training Ternarization for Large Language Models, https://arxiv.org/pdf/2510.03267, 2025-09-26
2025-11-10 23:36:38,780 - INFO - root - Page:0, Index:33, Purrception: Variational Flow Matching for Vector-Quantized Image Generation, https://arxiv.org/pdf/2510.01478, 2025-10-01
2025-11-10 23:36:38,782 - INFO - root - Page:0, Index:34, Post-Training Quantization for Audio Diffusion Transformers, https://arxiv.org/pdf/2510.00313, 2025-09-30
2025-11-10 23:36:38,783 - INFO - root - Page:0, Index:35, Rethinking RoPE Scaling in Quantized LLM: Theory, Outlier, and Channel-Band Analysis with Weight Rescaling, https://arxiv.org/pdf/2510.00028, 2025-09-25
2025-11-10 23:36:38,784 - INFO - root - Page:0, Index:36, Post-Training Quantization via Residual Truncation and Zero Suppression for Diffusion Models, https://arxiv.org/pdf/2509.26436, 2025-09-30
2025-11-10 23:36:38,785 - INFO - root - Page:0, Index:37, Cat: Post-Training Quantization Error Reduction via Cluster-based Affine Transformation, https://arxiv.org/pdf/2509.26277, 2025-10-07
2025-11-10 23:36:38,785 - INFO - root - Page:0, Index:38, CAST: Continuous and Differentiable Semi-Structured Sparsity-Aware Training for Large Language Models, https://arxiv.org/pdf/2509.25996, 2025-09-30
2025-11-10 23:36:38,786 - INFO - root - Page:0, Index:39, Norm-Q: Effective Compression Method for Hidden Markov Models in Neuro-Symbolic Applications, https://arxiv.org/pdf/2509.25439, 2025-09-29
2025-11-10 23:36:38,786 - INFO - root - Page:0, Index:40, On-the-Fly Adaptation to Quantization: Configuration-Aware LoRA for Efficient Fine-Tuning of Quantized LLMs, https://arxiv.org/pdf/2509.25214, 2025-09-22
2025-11-10 23:36:38,786 - INFO - root - Page:0, Index:41, VoxCPM: Tokenizer-Free TTS for Context-Aware Speech Generation and True-to-Life Voice Cloning, https://arxiv.org/pdf/2509.24650, 2025-09-29
2025-11-10 23:36:38,787 - INFO - root - Page:0, Index:42, S$^2$NN: Sub-bit Spiking Neural Networks, https://arxiv.org/pdf/2509.24266, 2025-10-24
2025-11-10 23:36:38,787 - INFO - root - Page:0, Index:43, Tequila: Trapping-free Ternary Quantization for Large Language Models, https://arxiv.org/pdf/2509.23809, 2025-10-17
2025-11-10 23:36:38,787 - INFO - root - Page:0, Index:44, Texture Vector-Quantization and Reconstruction Aware Prediction for Generative Super-Resolution, https://arxiv.org/pdf/2509.23774, 2025-09-30
2025-11-10 23:36:38,788 - INFO - root - Page:0, Index:45, RobuQ: Pushing DiTs to W1.58A2 via Robust Activation Quantization, https://arxiv.org/pdf/2509.23582, 2025-09-27
2025-11-10 23:36:38,788 - INFO - root - Page:0, Index:46, Beyond Outliers: A Study of Optimizers Under Quantization, https://arxiv.org/pdf/2509.23500, 2025-10-02
2025-11-10 23:36:38,793 - INFO - root - Page:0, Index:47, Compute-Optimal Quantization-Aware Training, https://arxiv.org/pdf/2509.22935, 2025-09-26
2025-11-10 23:36:38,794 - INFO - root - Page:0, Index:48, COSPADI: Compressing LLMs via Calibration-Guided Sparse Dictionary Learning, https://arxiv.org/pdf/2509.22075, 2025-10-06
2025-11-10 23:36:38,796 - INFO - root - Page:0, Index:49, SlimDiff: Training-Free, Activation-Guided Hands-free Slimming of Diffusion Models, https://arxiv.org/pdf/2509.21498, 2025-09-25
2025-11-10 23:36:38,797 - INFO - root - Fetching page 2 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=50
2025-11-10 23:36:46,495 - INFO - root - get_all_titles_from_web 
2025-11-10 23:36:46,499 - INFO - root - Page:1, Index:0, Quantized Visual Geometry Grounded Transformer, https://arxiv.org/pdf/2509.21302, 2025-09-29
2025-11-10 23:36:46,550 - INFO - root - Page:1, Index:1, Can Less Precise Be More Reliable? A Systematic Evaluation of Quantization's Impact on CLIP Beyond Accuracy, https://arxiv.org/pdf/2509.21173, 2025-10-27
2025-11-10 23:36:46,575 - INFO - root - Page:1, Index:2, Punching Above Precision: Small Quantized Model Distillation with Learnable Regularizer, https://arxiv.org/pdf/2509.20854, 2025-09-25
2025-11-10 23:36:46,623 - INFO - root - Page:1, Index:3, TinyEcoWeedNet: Edge Efficient Real-Time Aerial Agricultural Weed Detection, https://arxiv.org/pdf/2509.18193, 2025-09-19
2025-11-10 23:36:46,626 - INFO - root - Page:1, Index:4, SBVR: Summation of BitVector Representation for Efficient LLM Quantization, https://arxiv.org/pdf/2509.18172, 2025-09-17
2025-11-10 23:36:46,642 - INFO - root - Page:1, Index:5, QWHA: Quantization-Aware Walsh-Hadamard Adaptation for Parameter-Efficient Fine-Tuning on Large Language Models, https://arxiv.org/pdf/2509.17428, 2025-09-26
2025-11-10 23:36:46,644 - INFO - root - Page:1, Index:6, PTQTP: Post-Training Quantization to Trit-Planes for Large Language Models, https://arxiv.org/pdf/2509.16989, 2025-10-28
2025-11-10 23:36:46,645 - INFO - root - Page:1, Index:7, MEC-Quant: Maximum Entropy Coding for Extremely Low Bit Quantization-Aware Training, https://arxiv.org/pdf/2509.15514, 2025-09-18
2025-11-10 23:36:46,646 - INFO - root - Page:1, Index:8, Q-ROAR: Outlier-Aware Rescaling for RoPE Position Interpolation in Quantized Long-Context LLMs, https://arxiv.org/pdf/2509.14391, 2025-09-17
2025-11-10 23:36:46,649 - INFO - root - Page:1, Index:9, Efficient Quantization-Aware Neural Receivers: Beyond Post-Training Quantization, https://arxiv.org/pdf/2509.13786, 2025-09-19
2025-11-10 23:36:46,651 - INFO - root - Page:1, Index:10, Rate-Distortion Limits for Multimodal Retrieval: Theory, Optimal Codes, and Finite-Sample Guarantees, https://arxiv.org/pdf/2509.11054, 2025-09-13
2025-11-10 23:36:46,654 - INFO - root - Page:1, Index:11, SQAP-VLA: A Synergistic Quantization-Aware Pruning Framework for High-Performance Vision-Language-Action Models, https://arxiv.org/pdf/2509.09090, 2025-09-10
2025-11-10 23:36:46,655 - INFO - root - Page:1, Index:12, CSI Compression Beyond Latents: End-to-End Hybrid Attention-CNN Networks with Entropy Regularization, https://arxiv.org/pdf/2509.08776, 2025-09-10
2025-11-10 23:36:46,655 - INFO - root - Page:1, Index:13, Explaining How Quantization Disparately Skews a Model, https://arxiv.org/pdf/2509.07222, 2025-09-08
2025-11-10 23:36:46,656 - INFO - root - Page:1, Index:14, LoaQ: Layer-wise Output Approximation Quantization, https://arxiv.org/pdf/2509.06297, 2025-09-07
2025-11-10 23:36:46,657 - INFO - root - Page:1, Index:15, FineServe: Precision-Aware KV Slab and Two-Level Scheduling for Heterogeneous Precision LLM Serving, https://arxiv.org/pdf/2509.06261, 2025-09-14
2025-11-10 23:36:46,657 - INFO - root - Page:1, Index:16, Sensitivity-Aware Post-Training Quantization for Deep Neural Networks, https://arxiv.org/pdf/2509.05576, 2025-09-05
2025-11-10 23:36:46,658 - INFO - root - Page:1, Index:17, SuperSNN: A Hardware-Aware Framework for Physically Realizable, High-Performance Superconducting Spiking Neural Network Chips, https://arxiv.org/pdf/2509.05532, 2025-09-05
2025-11-10 23:36:46,667 - INFO - root - Page:1, Index:18, Data-Augmented Quantization-Aware Knowledge Distillation, https://arxiv.org/pdf/2509.03850, 2025-09-03
2025-11-10 23:36:46,676 - INFO - root - Page:1, Index:19, DPQuant: Efficient and Differentially-Private Model Training via Dynamic Quantization Scheduling, https://arxiv.org/pdf/2509.03472, 2025-09-03
2025-11-10 23:36:46,687 - INFO - root - Page:1, Index:20, Empowering Large Language Model for Sequential Recommendation via Multimodal Embeddings and Semantic IDs, https://arxiv.org/pdf/2509.02017, 2025-09-02
2025-11-10 23:36:46,688 - INFO - root - Page:1, Index:21, Q-Sched: Pushing the Boundaries of Few-Step Diffusion Models with Quantization-Aware Scheduling, https://arxiv.org/pdf/2509.01624, 2025-09-01
2025-11-10 23:36:46,690 - INFO - root - Page:1, Index:22, Quantization Meets OOD: Generalizable Quantization-aware Training from a Flatness Perspective, https://arxiv.org/pdf/2509.00859, 2025-08-31
2025-11-10 23:36:46,696 - INFO - root - Page:1, Index:23, Progressive Element-wise Gradient Estimation for Neural Network Quantization, https://arxiv.org/pdf/2509.00097, 2025-08-27
2025-11-10 23:36:46,706 - INFO - root - Page:1, Index:24, End-to-End On-Device Quantization-Aware Training for LLMs at Inference Cost, https://arxiv.org/pdf/2509.00031, 2025-09-29
2025-11-10 23:36:46,708 - INFO - root - Page:1, Index:25, Quantization Robustness to Input Degradations for Object Detection, https://arxiv.org/pdf/2508.19600, 2025-08-27
2025-11-10 23:36:46,708 - INFO - root - Page:1, Index:26, Scaling Laws for Task-Stratified Knowledge in Post-Training Quantized Large Language Models, https://arxiv.org/pdf/2508.18609, 2025-08-27
2025-11-10 23:36:46,712 - INFO - root - Page:1, Index:27, AQ-PCDSys: An Adaptive Quantized Planetary Crater Detection System for Autonomous Space Exploration, https://arxiv.org/pdf/2508.18025, 2025-08-25
2025-11-10 23:36:46,713 - INFO - root - Page:1, Index:28, TaDiCodec: Text-aware Diffusion Speech Tokenizer for Speech Language Modeling, https://arxiv.org/pdf/2508.16790, 2025-08-22
2025-11-10 23:36:46,714 - INFO - root - Page:1, Index:29, A Node-Aware Dynamic Quantization Approach for Graph Collaborative Filtering, https://arxiv.org/pdf/2508.16516, 2025-08-22
2025-11-10 23:36:46,717 - INFO - root - Page:1, Index:30, JEDI-linear: Fast and Efficient Graph Neural Networks for Jet Tagging on FPGAs, https://arxiv.org/pdf/2508.15468, 2025-08-21
2025-11-10 23:36:46,718 - INFO - root - Page:1, Index:31, MMQ: Multimodal Mixture-of-Quantization Tokenization for Semantic ID Generation and User Behavioral Adaptation, https://arxiv.org/pdf/2508.15281, 2025-08-21
2025-11-10 23:36:46,720 - INFO - root - Page:1, Index:32, DLLMQuant: Quantizing Diffusion-based Large Language Models, https://arxiv.org/pdf/2508.14090, 2025-08-25
2025-11-10 23:36:46,721 - INFO - root - Page:1, Index:33, Automated Energy-Aware Time-Series Model Deployment on Embedded FPGAs for Resilient Combined Sewer Overflow Management, https://arxiv.org/pdf/2508.13905, 2025-08-19
2025-11-10 23:36:46,722 - INFO - root - Page:1, Index:34, XR-NPE: High-Throughput Mixed-precision SIMD Neural Processing Engine for Extended Reality Perception Workloads, https://arxiv.org/pdf/2508.13049, 2025-08-18
2025-11-10 23:36:46,722 - INFO - root - Page:1, Index:35, Exploring Self-Supervised Audio Models for Generalized Anomalous Sound Detection, https://arxiv.org/pdf/2508.12230, 2025-08-17
2025-11-10 23:36:46,723 - INFO - root - Page:1, Index:36, TriQDef: Disrupting Semantic and Gradient Alignment to Prevent Adversarial Patch Transferability in Quantized Neural Networks, https://arxiv.org/pdf/2508.12132, 2025-08-16
2025-11-10 23:36:46,724 - INFO - root - Page:1, Index:37, Error Propagation Mechanisms and Compensation Strategies for Quantized Diffusion, https://arxiv.org/pdf/2508.12094, 2025-10-13
2025-11-10 23:36:46,727 - INFO - root - Page:1, Index:38, Extending Straight-Through Estimation for Robust Neural Networks on Analog CIM Hardware, https://arxiv.org/pdf/2508.11940, 2025-08-16
2025-11-10 23:36:46,730 - INFO - root - Page:1, Index:39, PTQAT: A Hybrid Parameter-Efficient Quantization Algorithm for 3D Perception Tasks, https://arxiv.org/pdf/2508.10557, 2025-08-15
2025-11-10 23:36:46,734 - INFO - root - Page:1, Index:40, MiCo: End-to-End Mixed Precision Neural Network Co-Exploration Framework for Edge AI, https://arxiv.org/pdf/2508.09500, 2025-08-13
2025-11-10 23:36:46,735 - INFO - root - Page:1, Index:41, SPARC: Soft Probabilistic Adaptive multi-interest Retrieval Model via Codebooks for recommender system, https://arxiv.org/pdf/2508.09090, 2025-08-12
2025-11-10 23:36:46,738 - INFO - root - Page:1, Index:42, Rethinking 1-bit Optimization Leveraging Pre-trained Large Language Models, https://arxiv.org/pdf/2508.06974, 2025-08-09
2025-11-10 23:36:46,738 - INFO - root - Page:1, Index:43, Efficient Deep Neural Receiver with Post-Training Quantization, https://arxiv.org/pdf/2508.06275, 2025-08-08
2025-11-10 23:36:46,742 - INFO - root - Page:1, Index:44, iFairy: the First 2-bit Complex LLM with All Parameters in $\{\pm1, \pm i\}$, https://arxiv.org/pdf/2508.05571, 2025-08-16
2025-11-10 23:36:46,742 - INFO - root - Page:1, Index:45, S$^2$Q-VDiT: Accurate Quantized Video Diffusion Transformer with Salient Data and Sparse Token Distillation, https://arxiv.org/pdf/2508.04016, 2025-10-27
2025-11-10 23:36:46,744 - INFO - root - Page:1, Index:46, LRQ-DiT: Log-Rotation Post-Training Quantization of Diffusion Transformers for Image and Video Generation, https://arxiv.org/pdf/2508.03485, 2025-09-23
2025-11-10 23:36:46,745 - INFO - root - Page:1, Index:47, VLMQ: Efficient Post-Training Quantization for Large Vision-Language Models via Hessian Augmentation, https://arxiv.org/pdf/2508.03351, 2025-08-05
2025-11-10 23:36:46,747 - INFO - root - Page:1, Index:48, TF-MLPNet: Tiny Real-Time Neural Speech Separation, https://arxiv.org/pdf/2508.03047, 2025-08-04
2025-11-10 23:36:46,758 - INFO - root - Page:1, Index:49, SaviorRec: Semantic-Behavior Alignment for Cold-Start Recommendation, https://arxiv.org/pdf/2508.01375, 2025-08-02
2025-11-10 23:36:46,763 - INFO - root - Fetching page 3 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=100
2025-11-10 23:36:53,502 - INFO - root - get_all_titles_from_web 
2025-11-10 23:36:53,504 - INFO - root - Page:2, Index:0, MixA-Q: Revisiting Activation Sparsity for Vision Transformers from a Mixed-Precision Quantization Perspective, https://arxiv.org/pdf/2507.19131, 2025-07-25
2025-11-10 23:36:53,508 - INFO - root - Page:2, Index:1, Enhancing Quantization-Aware Training on Edge Devices via Relative Entropy Coreset Selection and Cascaded Layer Correction, https://arxiv.org/pdf/2507.17768, 2025-07-16
2025-11-10 23:36:53,509 - INFO - root - Page:2, Index:2, SiLQ: Simple Large Language Model Quantization-Aware Training, https://arxiv.org/pdf/2507.16933, 2025-07-22
2025-11-10 23:36:53,511 - INFO - root - Page:2, Index:3, Task-Specific Zero-shot Quantization-Aware Training for Object Detection, https://arxiv.org/pdf/2507.16782, 2025-07-22
2025-11-10 23:36:53,512 - INFO - root - Page:2, Index:4, TorchAO: PyTorch-Native Training-to-Serving Model Optimization, https://arxiv.org/pdf/2507.16099, 2025-07-21
2025-11-10 23:36:53,516 - INFO - root - Page:2, Index:5, SegQuant: A Semantics-Aware and Generalizable Quantization Framework for Diffusion Models, https://arxiv.org/pdf/2507.14811, 2025-08-27
2025-11-10 23:36:53,547 - INFO - root - Page:2, Index:6, Apple Intelligence Foundation Language Models: Tech Report 2025, https://arxiv.org/pdf/2507.13575, 2025-08-27
2025-11-10 23:36:53,547 - INFO - root - Page:2, Index:7, Generative Multi-Target Cross-Domain Recommendation, https://arxiv.org/pdf/2507.12871, 2025-08-07
2025-11-10 23:36:53,547 - INFO - root - Page:2, Index:8, DAF: An Efficient End-to-End Dynamic Activation Framework for on-Device DNN Training, https://arxiv.org/pdf/2507.07149, 2025-07-09
2025-11-10 23:36:53,548 - INFO - root - Page:2, Index:9, Opto-ViT: Architecting a Near-Sensor Region of Interest-Aware Vision Transformer Accelerator with Silicon Photonics, https://arxiv.org/pdf/2507.07044, 2025-07-15
2025-11-10 23:36:53,548 - INFO - root - Page:2, Index:10, QS4D: Quantization-aware training for efficient hardware deployment of structured state-space sequential models, https://arxiv.org/pdf/2507.06079, 2025-07-08
2025-11-10 23:36:53,548 - INFO - root - Page:2, Index:11, GSVR: 2D Gaussian-based Video Representation for 800+ FPS with Hybrid Deformation Field, https://arxiv.org/pdf/2507.05594, 2025-07-07
2025-11-10 23:36:53,553 - INFO - root - Page:2, Index:12, Hita: Holistic Tokenizer for Autoregressive Image Generation, https://arxiv.org/pdf/2507.02358, 2025-07-11
2025-11-10 23:36:53,563 - INFO - root - Page:2, Index:13, QPART: Adaptive Model Quantization and Dynamic Workload Balancing for Accuracy-aware Edge Inference, https://arxiv.org/pdf/2506.23934, 2025-06-30
2025-11-10 23:36:53,575 - INFO - root - Page:2, Index:14, FedWSQ: Efficient Federated Learning with Weight Standardization and Distribution-Aware Non-Uniform Quantization, https://arxiv.org/pdf/2506.23516, 2025-07-21
2025-11-10 23:36:53,578 - INFO - root - Page:2, Index:15, Spectra 1.1: Scaling Laws and Efficient Inference for Ternary Language Models, https://arxiv.org/pdf/2506.23025, 2025-06-28
2025-11-10 23:36:53,580 - INFO - root - Page:2, Index:16, Joint Quantization and Pruning Neural Networks Approach: A Case Study on FSO Receivers, https://arxiv.org/pdf/2506.20084, 2025-06-24
2025-11-10 23:36:53,581 - INFO - root - Page:2, Index:17, Single-step Diffusion for Image Compression at Ultra-Low Bitrates, https://arxiv.org/pdf/2506.16572, 2025-09-22
2025-11-10 23:36:53,582 - INFO - root - Page:2, Index:18, LittleBit: Ultra Low-Bit Quantization via Latent Factorization, https://arxiv.org/pdf/2506.13771, 2025-10-28
2025-11-10 23:36:53,615 - INFO - root - Page:2, Index:19, MARCO: Hardware-Aware Neural Architecture Search for Edge Devices with Multi-Agent Reinforcement Learning and Conformal Prediction Filtering, https://arxiv.org/pdf/2506.13755, 2025-06-16
2025-11-10 23:36:53,620 - INFO - root - Page:2, Index:20, EAQuant: Enhancing Post-Training Quantization for MoE Models via Expert-Aware Optimization, https://arxiv.org/pdf/2506.13329, 2025-07-04
2025-11-10 23:36:53,624 - INFO - root - Page:2, Index:21, Towards Neural Audio Codec Source Parsing, https://arxiv.org/pdf/2506.12627, 2025-06-14
2025-11-10 23:36:53,625 - INFO - root - Page:2, Index:22, Quantizing Small-Scale State-Space Models for Edge AI, https://arxiv.org/pdf/2506.12480, 2025-06-14
2025-11-10 23:36:53,625 - INFO - root - Page:2, Index:23, EMLoC: Emulator-based Memory-efficient Fine-tuning with LoRA Correction, https://arxiv.org/pdf/2506.12015, 2025-06-13
2025-11-10 23:36:53,626 - INFO - root - Page:2, Index:24, Compression Aware Certified Training, https://arxiv.org/pdf/2506.11992, 2025-06-13
2025-11-10 23:36:53,628 - INFO - root - Page:2, Index:25, GPLQ: A General, Practical, and Lightning QAT Method for Vision Transformers, https://arxiv.org/pdf/2506.11784, 2025-06-13
2025-11-10 23:36:53,631 - INFO - root - Page:2, Index:26, TruncQuant: Truncation-Ready Quantization for DNNs with Flexible Weight Bit Precision, https://arxiv.org/pdf/2506.11431, 2025-06-12
2025-11-10 23:36:53,635 - INFO - root - Page:2, Index:27, EfficientQuant: An Efficient Post-Training Quantization for CNN-Transformer Hybrid Models on Edge Devices, https://arxiv.org/pdf/2506.11093, 2025-06-05
2025-11-10 23:36:53,637 - INFO - root - Page:2, Index:28, Starting Positions Matter: A Study on Better Weight Initialization for Neural Network Quantization, https://arxiv.org/pdf/2506.10463, 2025-06-12
2025-11-10 23:36:53,638 - INFO - root - Page:2, Index:29, AWP: Activation-Aware Weight Pruning and Quantization with Projected Gradient Descent, https://arxiv.org/pdf/2506.10205, 2025-06-11
2025-11-10 23:36:53,646 - INFO - root - Page:2, Index:30, Q-SAM2: Accurate Quantization for Segment Anything Model 2, https://arxiv.org/pdf/2506.09782, 2025-06-11
2025-11-10 23:36:53,648 - INFO - root - Page:2, Index:31, Unifying Block-wise PTQ and Distillation-based QAT for Progressive Quantization toward 2-bit Instruction-Tuned LLMs, https://arxiv.org/pdf/2506.09104, 2025-06-10
2025-11-10 23:36:53,648 - INFO - root - Page:2, Index:32, Implementing Keyword Spotting on the MCUX947 Microcontroller with Integrated NPU, https://arxiv.org/pdf/2506.08911, 2025-06-10
2025-11-10 23:36:53,650 - INFO - root - Page:2, Index:33, POLARON: Precision-aware On-device Learning and Adaptive Runtime-cONfigurable AI acceleration, https://arxiv.org/pdf/2506.08785, 2025-06-10
2025-11-10 23:36:53,652 - INFO - root - Page:2, Index:34, MoQAE: Mixed-Precision Quantization for Long-Context LLM Inference via Mixture of Quantization-Aware Experts, https://arxiv.org/pdf/2506.07533, 2025-06-09
2025-11-10 23:36:53,653 - INFO - root - Page:2, Index:35, BitVLA: 1-bit Vision-Language-Action Models for Robotics Manipulation, https://arxiv.org/pdf/2506.07530, 2025-06-09
2025-11-10 23:36:53,654 - INFO - root - Page:2, Index:36, RecGPT: A Foundation Model for Sequential Recommendation, https://arxiv.org/pdf/2506.06270, 2025-06-12
2025-11-10 23:36:53,654 - INFO - root - Page:2, Index:37, FPSAttention: Training-Aware FP8 and Sparsity Co-Design for Fast Video Diffusion, https://arxiv.org/pdf/2506.04648, 2025-06-05
2025-11-10 23:36:53,657 - INFO - root - Page:2, Index:38, BitTTS: Highly Compact Text-to-Speech Using 1.58-bit Quantization and Weight Indexing, https://arxiv.org/pdf/2506.03515, 2025-06-03
2025-11-10 23:36:53,658 - INFO - root - Page:2, Index:39, ShapeLLM-Omni: A Native Multimodal LLM for 3D Generation and Understanding, https://arxiv.org/pdf/2506.01853, 2025-06-02
2025-11-10 23:36:53,668 - INFO - root - Page:2, Index:40, Movable Antenna Enhanced Federated Fine-Tuning of Large Language Models via Hybrid Client Selection Optimization, https://arxiv.org/pdf/2506.00011, 2025-10-26
2025-11-10 23:36:53,670 - INFO - root - Page:2, Index:41, Running Conventional Automatic Speech Recognition on Memristor Hardware: A Simulated Approach, https://arxiv.org/pdf/2505.24721, 2025-05-30
2025-11-10 23:36:53,670 - INFO - root - Page:2, Index:42, GARLIC: GAussian Representation LearnIng for spaCe partitioning, https://arxiv.org/pdf/2505.24608, 2025-10-02
2025-11-10 23:36:53,671 - INFO - root - Page:2, Index:43, AutoChemSchematic AI: Agentic Physics-Aware Automation for Chemical Manufacturing Scale-Up, https://arxiv.org/pdf/2505.24584, 2025-08-18
2025-11-10 23:36:53,676 - INFO - root - Page:2, Index:44, Model-Preserving Adaptive Rounding, https://arxiv.org/pdf/2505.22988, 2025-09-25
2025-11-10 23:36:53,679 - INFO - root - Page:2, Index:45, Highly Efficient and Effective LLMs with Multi-Boolean Architectures, https://arxiv.org/pdf/2505.22811, 2025-10-03
2025-11-10 23:36:53,679 - INFO - root - Page:2, Index:46, Pioneering 4-Bit FP Quantization for Diffusion Models: Mixup-Sign Quantization and Timestep-Aware Fine-Tuning, https://arxiv.org/pdf/2505.21591, 2025-05-27
2025-11-10 23:36:53,683 - INFO - root - Page:2, Index:47, Frequency Composition for Compressed and Domain-Adaptive Neural Networks, https://arxiv.org/pdf/2505.20890, 2025-05-27
2025-11-10 23:36:53,692 - INFO - root - Page:2, Index:48, MoPFormer: Motion-Primitive Transformer for Wearable-Sensor Activity Recognition, https://arxiv.org/pdf/2505.20744, 2025-10-27
2025-11-10 23:36:53,702 - INFO - root - Fetching page 4 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=150
2025-11-10 23:37:01,052 - INFO - root - get_all_titles_from_web 
2025-11-10 23:37:01,053 - INFO - root - Page:3, Index:0, Optimizing edge AI models on HPC systems with the edge in the loop, https://arxiv.org/pdf/2505.19995, 2025-05-26
2025-11-10 23:37:01,053 - INFO - root - Page:3, Index:1, DPASyn: Mechanism-Aware Drug Synergy Prediction via Dual Attention and Precision-Aware Quantization, https://arxiv.org/pdf/2505.19144, 2025-09-20
2025-11-10 23:37:01,053 - INFO - root - Page:3, Index:2, Reducing Storage of Pretrained Neural Networks by Rate-Constrained Quantization and Entropy Coding, https://arxiv.org/pdf/2505.18758, 2025-05-24
2025-11-10 23:37:01,056 - INFO - root - Page:3, Index:3, Beyond Discreteness: Finite-Sample Analysis of Straight-Through Estimator for Quantization, https://arxiv.org/pdf/2505.18113, 2025-05-23
2025-11-10 23:37:01,056 - INFO - root - Page:3, Index:4, Automating Versatile Time-Series Analysis with Tiny Transformers on Embedded FPGAs, https://arxiv.org/pdf/2505.17662, 2025-09-19
2025-11-10 23:37:01,056 - INFO - root - Page:3, Index:5, FPQVAR: Floating Point Quantization for Visual Autoregressive Model with FPGA Hardware Co-design, https://arxiv.org/pdf/2505.16335, 2025-05-22
2025-11-10 23:37:01,056 - INFO - root - Page:3, Index:6, Saliency-Aware Quantized Imitation Learning for Efficient Robotic Control, https://arxiv.org/pdf/2505.15304, 2025-05-30
2025-11-10 23:37:01,058 - INFO - root - Page:3, Index:7, Scaling Law for Quantization-Aware Training, https://arxiv.org/pdf/2505.14302, 2025-05-20
2025-11-10 23:37:01,059 - INFO - root - Page:3, Index:8, Automatic mixed precision for optimizing gained time with constrained loss mean-squared-error based on model partition to sequential sub-graphs, https://arxiv.org/pdf/2505.13060, 2025-05-19
2025-11-10 23:37:01,060 - INFO - root - Page:3, Index:9, Deep Unfolding with Kernel-based Quantization in MIMO Detection, https://arxiv.org/pdf/2505.12736, 2025-05-19
2025-11-10 23:37:01,060 - INFO - root - Page:3, Index:10, FedHQ: Hybrid Runtime Quantization for Federated Learning, https://arxiv.org/pdf/2505.11982, 2025-05-17
2025-11-10 23:37:01,060 - INFO - root - Page:3, Index:11, QVGen: Pushing the Limit of Quantized Video Generative Models, https://arxiv.org/pdf/2505.11497, 2025-09-27
2025-11-10 23:37:01,066 - INFO - root - Page:3, Index:12, EA-3DGS: Efficient and Adaptive 3D Gaussians with Highly Enhanced Quality for outdoor scenes, https://arxiv.org/pdf/2505.10787, 2025-05-15
2025-11-10 23:37:01,066 - INFO - root - Page:3, Index:13, PROM: Prioritize Reduction of Multiplications Over Lower Bit-Widths for Efficient CNNs, https://arxiv.org/pdf/2505.03254, 2025-08-06
2025-11-10 23:37:01,066 - INFO - root - Page:3, Index:14, ICQuant: Index Coding enables Low-bit LLM Quantization, https://arxiv.org/pdf/2505.00850, 2025-08-24
2025-11-10 23:37:01,067 - INFO - root - Page:3, Index:15, Enhancing Ultra-Low-Bit Quantization of Large Language Models Through Saliency-Aware Partial Retraining, https://arxiv.org/pdf/2504.13932, 2025-07-30
2025-11-10 23:37:01,067 - INFO - root - Page:3, Index:16, Achieving binary weight and activation for LLMs using Post-Training Quantization, https://arxiv.org/pdf/2504.05352, 2025-06-30
2025-11-10 23:37:01,067 - INFO - root - Page:3, Index:17, Wireless Hearables With Programmable Speech AI Accelerators, https://arxiv.org/pdf/2503.18698, 2025-10-21
2025-11-10 23:37:01,067 - INFO - root - Page:3, Index:18, GranQ: Efficient Channel-wise Quantization via Vectorized Pre-Scaling for Zero-Shot QAT, https://arxiv.org/pdf/2503.18339, 2025-10-15
2025-11-10 23:37:01,069 - INFO - root - Page:3, Index:19, CompMarkGS: Robust Watermarking for Compressed 3D Gaussian Splatting, https://arxiv.org/pdf/2503.12836, 2025-09-29
2025-11-10 23:37:01,070 - INFO - root - Page:3, Index:20, AHCPTQ: Accurate and Hardware-Compatible Post-Training Quantization for Segment Anything Model, https://arxiv.org/pdf/2503.03088, 2025-07-11
2025-11-10 23:37:01,073 - INFO - root - Page:3, Index:21, Teaching Metric Distance to Discrete Autoregressive Language Models, https://arxiv.org/pdf/2503.02379, 2025-10-07
2025-11-10 23:37:01,076 - INFO - root - Fetching page 5 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=200
2025-11-10 23:37:07,738 - INFO - root - get_all_titles_from_web 
2025-11-10 23:37:07,738 - INFO - root - Page:4, Index:0, Regularization-based Framework for Quantization-, Fault- and Variability-Aware Training, https://arxiv.org/pdf/2503.01297, 2025-07-12
2025-11-10 23:37:07,738 - INFO - root - Page:4, Index:1, Investigating the Impact of Quantization Methods on the Safety and Reliability of Large Language Models, https://arxiv.org/pdf/2502.15799, 2025-06-29
2025-11-10 23:37:07,740 - INFO - root - Page:4, Index:2, Rotate, Clip, and Partition: Towards W2A4KV4 Quantization by Integrating Rotation and Learnable Non-uniform Quantizer, https://arxiv.org/pdf/2502.15779, 2025-09-01
2025-11-10 23:37:07,740 - INFO - root - Page:4, Index:3, RoSTE: An Efficient Quantization-Aware Supervised Fine-Tuning Approach for Large Language Models, https://arxiv.org/pdf/2502.09003, 2025-06-05
2025-11-10 23:37:07,740 - INFO - root - Page:4, Index:4, Spatial Degradation-Aware and Temporal Consistent Diffusion Model for Compressed Video Super-Resolution, https://arxiv.org/pdf/2502.07381, 2025-06-27
2025-11-10 23:37:07,740 - INFO - root - Page:4, Index:5, QuEST: Stable Training of LLMs with 1-Bit Weights and Activations, https://arxiv.org/pdf/2502.05003, 2025-06-10
2025-11-10 23:37:07,741 - INFO - root - Page:4, Index:6, HALO: Hadamard-Assisted Lower-Precision Optimization for LLMs, https://arxiv.org/pdf/2501.02625, 2025-11-05
2025-11-10 23:37:07,741 - INFO - root - Page:4, Index:7, TAR3D: Creating High-Quality 3D Assets via Next-Part Prediction, https://arxiv.org/pdf/2412.16919, 2025-08-08
2025-11-10 23:37:07,741 - INFO - root - Page:4, Index:8, Training Multi-Layer Binary Neural Networks With Local Binary Error Signals, https://arxiv.org/pdf/2412.00119, 2025-08-05
2025-11-10 23:37:07,742 - INFO - root - Page:4, Index:9, Scaling Large-scale GNN Training to Thousands of Processors on CPU-based Supercomputers, https://arxiv.org/pdf/2411.16025, 2025-05-26
2025-11-10 23:37:07,742 - INFO - root - Page:4, Index:10, HAFLQ: Heterogeneous Adaptive Federated LoRA Fine-tuned LLM with Quantization, https://arxiv.org/pdf/2411.06581, 2025-05-16
2025-11-10 23:37:07,742 - INFO - root - Fetching page 6 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=250
2025-11-10 23:37:15,385 - INFO - root - get_all_titles_from_web 
2025-11-10 23:37:15,386 - INFO - root - Page:5, Index:0, Gradient-Free Training of Quantized Neural Networks, https://arxiv.org/pdf/2410.09734, 2025-09-29
2025-11-10 23:37:15,386 - INFO - root - Page:5, Index:1, QT-DoG: Quantization-aware Training for Domain Generalization, https://arxiv.org/pdf/2410.06020, 2025-06-26
2025-11-10 23:37:15,386 - INFO - root - Page:5, Index:2, Constraint Guided Model Quantization of Neural Networks, https://arxiv.org/pdf/2409.20138, 2025-09-12
2025-11-10 23:37:15,387 - INFO - root - Page:5, Index:3, Accumulator-Aware Post-Training Quantization for Large Language Models, https://arxiv.org/pdf/2409.17092, 2025-07-30
2025-11-10 23:37:15,387 - INFO - root - Page:5, Index:4, DilateQuant: Accurate and Efficient Diffusion Quantization via Weight Dilation, https://arxiv.org/pdf/2409.14307, 2025-07-09
2025-11-10 23:37:15,388 - INFO - root - Page:5, Index:5, Robust Training of Neural Networks at Arbitrary Precision and Sparsity, https://arxiv.org/pdf/2409.09245, 2025-09-23
2025-11-10 23:37:15,388 - INFO - root - Page:5, Index:6, VQ-CTAP: Cross-Modal Fine-Grained Sequence Representation Learning for Speech Processing, https://arxiv.org/pdf/2408.05758, 2025-05-27
2025-11-10 23:37:15,389 - INFO - root - Page:5, Index:7, DopQ-ViT: Towards Distribution-Friendly and Outlier-Aware Post-Training Quantization for Vision Transformers, https://arxiv.org/pdf/2408.03291, 2025-06-19
2025-11-10 23:37:15,389 - INFO - root - Page:5, Index:8, Temporal Feature Matters: A Framework for Diffusion Model Quantization, https://arxiv.org/pdf/2407.19547, 2025-07-11
2025-11-10 23:37:15,390 - INFO - root - Page:5, Index:9, EfficientQAT: Efficient Quantization-Aware Training for Large Language Models, https://arxiv.org/pdf/2407.11062, 2025-05-19
2025-11-10 23:37:15,390 - INFO - root - Page:5, Index:10, Integer-only Quantized Transformers for Embedded FPGA-based Time-series Forecasting in AIoT, https://arxiv.org/pdf/2407.11041, 2025-10-31
2025-11-10 23:37:15,390 - INFO - root - Fetching page 7 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=300
2025-11-10 23:37:22,802 - INFO - root - get_all_titles_from_web 
2025-11-10 23:37:22,802 - INFO - root - Page:6, Index:0, BoA: Attention-aware Post-training Quantization without Backpropagation, https://arxiv.org/pdf/2406.13474, 2025-06-06
2025-11-10 23:37:22,803 - INFO - root - Page:6, Index:1, A Rescaling-Invariant Lipschitz Bound Based on Path-Metrics for Modern ReLU Network Parameterizations, https://arxiv.org/pdf/2405.15006, 2025-06-13
2025-11-10 23:37:22,803 - INFO - root - Page:6, Index:2, Scheduling Weight Transitions for Quantization-Aware Training, https://arxiv.org/pdf/2404.19248, 2025-10-01
2025-11-10 23:37:22,803 - INFO - root - Page:6, Index:3, GPTVQ: The Blessing of Dimensionality for LLM Quantization, https://arxiv.org/pdf/2402.15319, 2025-06-03
2025-11-10 23:37:22,806 - INFO - root - Fetching page 8 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=350
2025-11-10 23:37:30,847 - INFO - root - get_all_titles_from_web 
2025-11-10 23:37:30,847 - INFO - root - Page:7, Index:0, Squat: Quant Small Language Models on the Edge, https://arxiv.org/pdf/2402.10787, 2025-07-01
2025-11-10 23:37:30,848 - INFO - root - Page:7, Index:1, L4Q: Parameter Efficient Quantization-Aware Fine-Tuning on Large Language Models, https://arxiv.org/pdf/2402.04902, 2025-07-21
2025-11-10 23:37:30,848 - INFO - root - Fetching page 9 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=400
2025-11-10 23:37:39,094 - INFO - root - ------------------------------------------------------------------------------------------------------------------------
2025-11-10 23:37:48,292 - INFO - root - File already exists, skipping download: D:\ChatPaper\academic Papers\Quantization-Aware-Training\A Quantized VAE-MLP Botnet Detection Model_ A Systematic Evaluation of Quantizat.pdf
2025-11-10 23:37:48,294 - INFO - root - 正在总结论文 1/2: Data Efficiency and Transfer Robustness in Biomedical Image Segmentation: A Study of Redundancy and Forgetting with Cellpose
2025-11-10 23:40:22,460 - INFO - root - 正在提取论文图片...
2025-11-10 23:40:24,695 - INFO - root - 已保存图片 1/10：./export\images_Data Efficiency and Transfer Robustness in Biomedical Image Segmentation_ A Stud\figure_1_page4.png
2025-11-10 23:40:24,873 - INFO - root - 已保存图片 2/10：./export\images_Data Efficiency and Transfer Robustness in Biomedical Image Segmentation_ A Stud\figure_2_page6.png
2025-11-10 23:40:25,127 - INFO - root - 已保存图片 3/10：./export\images_Data Efficiency and Transfer Robustness in Biomedical Image Segmentation_ A Stud\figure_3_page3.png
2025-11-10 23:40:25,462 - INFO - root - 已保存图片 4/10：./export\images_Data Efficiency and Transfer Robustness in Biomedical Image Segmentation_ A Stud\figure_4_page4.png
2025-11-10 23:40:25,481 - INFO - root - 成功添加图片 1：./export\images_Data Efficiency and Transfer Robustness in Biomedical Image Segmentation_ A Stud\figure_1_page4.png
2025-11-10 23:40:25,509 - INFO - root - 成功添加图片 2：./export\images_Data Efficiency and Transfer Robustness in Biomedical Image Segmentation_ A Stud\figure_2_page6.png
2025-11-10 23:40:25,521 - INFO - root - 成功添加图片 3：./export\images_Data Efficiency and Transfer Robustness in Biomedical Image Segmentation_ A Stud\figure_3_page3.png
2025-11-10 23:40:25,529 - INFO - root - 成功添加图片 4：./export\images_Data Efficiency and Transfer Robustness in Biomedical Image Segmentation_ A Stud\figure_4_page4.png
2025-11-10 23:40:25,538 - INFO - root - 提取到arXiv ID: 2511.04803
2025-11-10 23:40:25,541 - INFO - root - 调用arXiv API: https://export.arxiv.org/api/query?id=2511.04803
2025-11-10 23:40:31,564 - WARNING - root - 未找到论文信息: 2511.04803
2025-11-10 23:40:31,567 - INFO - root - 估算引用量: 10
2025-11-10 23:40:31,574 - INFO - root - 论文《Data Efficiency and Transfer Robustness in Biomedical Image Segmentation: A Study of Redundancy and Forgetting with Cellpose》的分析已保存到 ./export\QAT\Data Efficiency and Transfer Robustness in Biomedical Image Segmentation_ A Stud.md
2025-11-10 23:40:31,597 - INFO - root - 正在总结论文 2/2: A Quantized VAE-MLP Botnet Detection Model: A Systematic Evaluation of Quantization-Aware Training and Post-Training Quantization Strategies
2025-11-10 23:41:27,488 - INFO - root - LLMClient: rate limit reached, sleeping 4.1s
2025-11-10 23:41:57,342 - INFO - root - 正在提取论文图片...
2025-11-10 23:41:57,472 - INFO - root - 已保存图片 1/10：./export\images_A Quantized VAE-MLP Botnet Detection Model_ A Systematic Evaluation of Quantizat\figure_1_page4.png
2025-11-10 23:41:57,569 - INFO - root - 已保存图片 2/10：./export\images_A Quantized VAE-MLP Botnet Detection Model_ A Systematic Evaluation of Quantizat\figure_2_page4.png
2025-11-10 23:41:57,677 - INFO - root - 已保存图片 3/10：./export\images_A Quantized VAE-MLP Botnet Detection Model_ A Systematic Evaluation of Quantizat\figure_3_page4.png
2025-11-10 23:41:57,769 - INFO - root - 已保存图片 4/10：./export\images_A Quantized VAE-MLP Botnet Detection Model_ A Systematic Evaluation of Quantizat\figure_4_page5.png
2025-11-10 23:41:57,850 - INFO - root - 已保存图片 5/10：./export\images_A Quantized VAE-MLP Botnet Detection Model_ A Systematic Evaluation of Quantizat\figure_5_page3.png
2025-11-10 23:41:58,032 - INFO - root - 已保存图片 6/10：./export\images_A Quantized VAE-MLP Botnet Detection Model_ A Systematic Evaluation of Quantizat\figure_6_page4.png
2025-11-10 23:41:58,034 - INFO - root - 成功添加图片 1：./export\images_A Quantized VAE-MLP Botnet Detection Model_ A Systematic Evaluation of Quantizat\figure_1_page4.png
2025-11-10 23:41:58,035 - INFO - root - 成功添加图片 2：./export\images_A Quantized VAE-MLP Botnet Detection Model_ A Systematic Evaluation of Quantizat\figure_2_page4.png
2025-11-10 23:41:58,035 - INFO - root - 成功添加图片 3：./export\images_A Quantized VAE-MLP Botnet Detection Model_ A Systematic Evaluation of Quantizat\figure_3_page4.png
2025-11-10 23:41:58,036 - INFO - root - 成功添加图片 4：./export\images_A Quantized VAE-MLP Botnet Detection Model_ A Systematic Evaluation of Quantizat\figure_4_page5.png
2025-11-10 23:41:58,036 - INFO - root - 成功添加图片 5：./export\images_A Quantized VAE-MLP Botnet Detection Model_ A Systematic Evaluation of Quantizat\figure_5_page3.png
2025-11-10 23:41:58,037 - INFO - root - 成功添加图片 6：./export\images_A Quantized VAE-MLP Botnet Detection Model_ A Systematic Evaluation of Quantizat\figure_6_page4.png
2025-11-10 23:41:58,037 - INFO - root - 提取到arXiv ID: 2511.03201
2025-11-10 23:41:58,037 - INFO - root - 调用arXiv API: https://export.arxiv.org/api/query?id=2511.03201
2025-11-10 23:42:03,803 - WARNING - root - 未找到论文信息: 2511.03201
2025-11-10 23:42:03,805 - INFO - root - 估算引用量: 10
2025-11-10 23:42:03,809 - INFO - root - 论文《A Quantized VAE-MLP Botnet Detection Model: A Systematic Evaluation of Quantization-Aware Training and Post-Training Quantization Strategies》的分析已保存到 ./export\QAT\A Quantized VAE-MLP Botnet Detection Model_ A Systematic Evaluation of Quantizat.md
2025-11-10 23:42:03,826 - INFO - root - 提取到arXiv ID: 2511.04803
2025-11-10 23:42:03,837 - INFO - root - 调用arXiv API: https://export.arxiv.org/api/query?id=2511.04803
2025-11-10 23:42:09,223 - WARNING - root - 未找到论文信息: 2511.04803
2025-11-10 23:42:09,226 - INFO - root - 估算引用量: 10
2025-11-10 23:42:09,226 - INFO - root - 提取到arXiv ID: 2511.03201
2025-11-10 23:42:09,226 - INFO - root - 调用arXiv API: https://export.arxiv.org/api/query?id=2511.03201
2025-11-10 23:42:14,645 - WARNING - root - 未找到论文信息: 2511.03201
2025-11-10 23:42:14,647 - INFO - root - 估算引用量: 7
2025-11-10 23:42:15,227 - INFO - root - 已生成汇总Excel表格: ./export\QAT\论文汇总_QAT_20251110_234214.xlsx
2025-11-10 23:42:15,231 - INFO - root - 已生成汇总Excel表格: ./export\QAT\论文汇总_QAT_20251110_234214.xlsx
2025-11-10 23:42:15,232 - INFO - root - summary time: 351.05 seconds
2025-11-10 23:47:17,286 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-10 23:47:17,288 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-10 23:47:17,290 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-10 23:47:18,855 - INFO - root - LLMClientManager: 指定使用客户端: Gemini
2025-11-10 23:47:19,845 - INFO - root - GeminiClient: trying model models/gemini-2.5-flash
2025-11-10 23:47:27,021 - INFO - root - GeminiClient: initialized model gemini-2.5-flash
2025-11-10 23:47:27,022 - INFO - root - LLMClientManager: Gemini 客户端初始化成功
2025-11-10 23:47:27,022 - INFO - root - LLMClientManager: switched to Gemini client
2025-11-10 23:47:27,023 - INFO - root - 已手动切换到 LLM 客户端: Gemini
2025-11-10 23:47:27,023 - INFO - root - 使用 LLM 模型: gemini-2.5-flash
2025-11-10 23:47:27,023 - INFO - root - 可用客户端: ['Gemini']
2025-11-10 23:47:27,024 - INFO - root - === 运行配置 ===
2025-11-10 23:47:27,024 - INFO - root - 处理模式: arxiv在线搜索
2025-11-10 23:47:27,025 - INFO - root - 关键词: QAT
2025-11-10 23:47:27,025 - INFO - root - 查询: CVPR 2026
2025-11-10 23:47:27,025 - INFO - root - 排序: None
2025-11-10 23:47:27,026 - INFO - root - 最近天数: 180
2025-11-10 23:47:27,027 - INFO - root - 最大处理数量: 2
2025-11-10 23:47:27,028 - INFO - root - 保存图片: 是
2025-11-10 23:47:27,029 - INFO - root - 输出语言: 中文
2025-11-10 23:47:27,029 - INFO - root - 强制重新处理: 否
2025-11-10 23:47:27,030 - INFO - root - ====================
2025-11-10 23:47:27,030 - INFO - root - 使用 arXiv 搜索模式（通过 chat_arxiv 模块获取）
2025-11-10 23:47:27,031 - INFO - root - Fetching page 1 with URL: https://arxiv.org/search/?query=CVPR+2026&searchtype=all&abstracts=show&order=-announced_date_first&size=50
2025-11-10 23:47:32,894 - INFO - root - get_all_titles_from_web 
2025-11-10 23:47:32,895 - INFO - root - Page:0, Index:0, Learning to Seek Evidence: A Verifiable Reasoning Agent with Causal Faithfulness Analysis, https://arxiv.org/pdf/2511.01425, 2025-11-03
2025-11-10 23:47:32,895 - INFO - root - Fetching page 2 with URL: https://arxiv.org/search/?query=CVPR+2026&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=50
2025-11-10 23:47:39,628 - INFO - root - ------------------------------------------------------------------------------------------------------------------------
2025-11-10 23:47:39,633 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\CVPR 2026\Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness.pdf
2025-11-10 23:47:39,639 - INFO - root - 跳过已处理论文 Learning to Seek Evidence: A Verifiable Reasoning Agent with Causal Faithfulness Analysis：d:\ChatPaper\academic Papers\CVPR 2026\Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness.pdf
2025-11-10 23:47:39,641 - INFO - root - 提取到arXiv ID: 2511.01425
2025-11-10 23:47:39,641 - INFO - root - 估算引用量: 12
2025-11-10 23:47:40,285 - INFO - root - 已生成汇总Excel表格: ./export\QAT\论文汇总_QAT_20251110_234739.xlsx
2025-11-10 23:47:40,291 - INFO - root - 已生成汇总Excel表格: ./export\QAT\论文汇总_QAT_20251110_234739.xlsx
2025-11-10 23:47:40,293 - INFO - root - summary time: 23.01 seconds
2025-11-10 23:52:29,381 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-10 23:52:29,386 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-10 23:52:29,391 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-10 23:52:34,846 - INFO - root - LLMClientManager: 指定使用客户端: Gemini
2025-11-10 23:52:36,052 - INFO - root - GeminiClient: trying model models/gemini-2.5-flash
2025-11-10 23:52:45,998 - INFO - root - GeminiClient: initialized model gemini-2.5-flash
2025-11-10 23:52:45,998 - INFO - root - LLMClientManager: Gemini 客户端初始化成功
2025-11-10 23:52:45,999 - INFO - root - LLMClientManager: switched to Gemini client
2025-11-10 23:52:45,999 - INFO - root - 已手动切换到 LLM 客户端: Gemini
2025-11-10 23:52:45,999 - INFO - root - 使用 LLM 模型: gemini-2.5-flash
2025-11-10 23:52:45,999 - INFO - root - 可用客户端: ['Gemini']
2025-11-10 23:52:46,000 - INFO - root - === 运行配置 ===
2025-11-10 23:52:46,000 - INFO - root - 处理模式: arxiv在线搜索
2025-11-10 23:52:46,000 - INFO - root - 关键词: QAT
2025-11-10 23:52:46,000 - INFO - root - 查询: CVPR 2026
2025-11-10 23:52:46,000 - INFO - root - 排序: None
2025-11-10 23:52:46,001 - INFO - root - 最近天数: 180
2025-11-10 23:52:46,001 - INFO - root - 最大处理数量: 2
2025-11-10 23:52:46,001 - INFO - root - 保存图片: 是
2025-11-10 23:52:46,001 - INFO - root - 输出语言: 中文
2025-11-10 23:52:46,002 - INFO - root - 强制重新处理: 否
2025-11-10 23:52:46,002 - INFO - root - ====================
2025-11-10 23:52:46,002 - INFO - root - 使用 arXiv 搜索模式（通过 chat_arxiv 模块获取）
2025-11-10 23:52:46,002 - INFO - root - Fetching page 1 with URL: https://arxiv.org/search/?query=CVPR+2026&searchtype=all&abstracts=show&order=-announced_date_first&size=50
2025-11-10 23:52:52,158 - INFO - root - get_all_titles_from_web 
2025-11-10 23:52:52,159 - INFO - root - Page:0, Index:0, Learning to Seek Evidence: A Verifiable Reasoning Agent with Causal Faithfulness Analysis, https://arxiv.org/pdf/2511.01425, 2025-11-03
2025-11-10 23:52:52,160 - INFO - root - Fetching page 2 with URL: https://arxiv.org/search/?query=CVPR+2026&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=50
2025-11-10 23:52:58,367 - INFO - root - ------------------------------------------------------------------------------------------------------------------------
2025-11-10 23:52:58,374 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\CVPR 2026\Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness.pdf
2025-11-10 23:52:58,406 - INFO - root - 正在总结论文 1/1: Learning to Seek Evidence: A Verifiable Reasoning Agent with Causal Faithfulness Analysis
2025-11-10 23:53:52,234 - INFO - root - LLMClient: rate limit reached, sleeping 6.2s
2025-11-10 23:54:51,191 - INFO - root - 正在提取论文图片...
2025-11-10 23:54:51,535 - INFO - root - 已保存图片 1/10：./export\QAT\images\figure_1_page2.jpeg
2025-11-10 23:54:51,570 - INFO - root - 已保存图片 2/10：./export\QAT\images\figure_2_page2.jpeg
2025-11-10 23:54:51,599 - INFO - root - 已保存图片 3/10：./export\QAT\images\figure_3_page2.jpeg
2025-11-10 23:54:51,617 - INFO - root - 已保存图片 4/10：./export\QAT\images\figure_4_page2.jpeg
2025-11-10 23:54:51,631 - INFO - root - 已保存图片 5/10：./export\QAT\images\figure_5_page2.jpeg
2025-11-10 23:54:51,647 - INFO - root - 已保存图片 6/10：./export\QAT\images\figure_6_page2.jpeg
2025-11-10 23:54:51,676 - INFO - root - 已保存图片 7/10：./export\QAT\images\figure_7_page2.jpeg
2025-11-10 23:54:51,702 - INFO - root - 已保存图片 8/10：./export\QAT\images\figure_8_page2.jpeg
2025-11-10 23:54:51,768 - INFO - root - 已保存图片 9/10：./export\QAT\images\figure_9_page2.jpeg
2025-11-10 23:54:51,790 - INFO - root - 已保存图片 10/10：./export\QAT\images\figure_10_page2.jpeg
2025-11-10 23:54:51,791 - INFO - root - 成功添加图片 1：./export\QAT\images\figure_1_page2.jpeg
2025-11-10 23:54:51,793 - INFO - root - 成功添加图片 2：./export\QAT\images\figure_2_page2.jpeg
2025-11-10 23:54:51,793 - INFO - root - 成功添加图片 3：./export\QAT\images\figure_3_page2.jpeg
2025-11-10 23:54:51,793 - INFO - root - 成功添加图片 4：./export\QAT\images\figure_4_page2.jpeg
2025-11-10 23:54:51,794 - INFO - root - 成功添加图片 5：./export\QAT\images\figure_5_page2.jpeg
2025-11-10 23:54:51,794 - INFO - root - 成功添加图片 6：./export\QAT\images\figure_6_page2.jpeg
2025-11-10 23:54:51,795 - INFO - root - 成功添加图片 7：./export\QAT\images\figure_7_page2.jpeg
2025-11-10 23:54:51,796 - INFO - root - 成功添加图片 8：./export\QAT\images\figure_8_page2.jpeg
2025-11-10 23:54:51,796 - INFO - root - 成功添加图片 9：./export\QAT\images\figure_9_page2.jpeg
2025-11-10 23:54:51,797 - INFO - root - 成功添加图片 10：./export\QAT\images\figure_10_page2.jpeg
2025-11-10 23:54:51,797 - INFO - root - 提取到arXiv ID: 2511.01425
2025-11-10 23:54:51,798 - INFO - root - 估算引用量: 5
2025-11-10 23:54:51,802 - WARNING - root - 图片文件不存在: images/figure_10_page2.jpeg
2025-11-10 23:54:51,803 - INFO - root - 图片存在于images目录: ./export\QAT\images\figure_10_page2.jpeg
2025-11-10 23:54:51,804 - WARNING - root - 图片文件不存在: images/figure_9_page2.jpeg
2025-11-10 23:54:51,804 - INFO - root - 图片存在于images目录: ./export\QAT\images\figure_9_page2.jpeg
2025-11-10 23:54:51,804 - WARNING - root - 图片文件不存在: images/figure_8_page2.jpeg
2025-11-10 23:54:51,805 - INFO - root - 图片存在于images目录: ./export\QAT\images\figure_8_page2.jpeg
2025-11-10 23:54:51,805 - WARNING - root - 图片文件不存在: images/figure_7_page2.jpeg
2025-11-10 23:54:51,805 - INFO - root - 图片存在于images目录: ./export\QAT\images\figure_7_page2.jpeg
2025-11-10 23:54:51,806 - WARNING - root - 图片文件不存在: images/figure_6_page2.jpeg
2025-11-10 23:54:51,806 - INFO - root - 图片存在于images目录: ./export\QAT\images\figure_6_page2.jpeg
2025-11-10 23:54:51,806 - WARNING - root - 图片文件不存在: images/figure_5_page2.jpeg
2025-11-10 23:54:51,807 - INFO - root - 图片存在于images目录: ./export\QAT\images\figure_5_page2.jpeg
2025-11-10 23:54:51,808 - WARNING - root - 图片文件不存在: images/figure_4_page2.jpeg
2025-11-10 23:54:51,809 - INFO - root - 图片存在于images目录: ./export\QAT\images\figure_4_page2.jpeg
2025-11-10 23:54:51,809 - WARNING - root - 图片文件不存在: images/figure_3_page2.jpeg
2025-11-10 23:54:51,809 - INFO - root - 图片存在于images目录: ./export\QAT\images\figure_3_page2.jpeg
2025-11-10 23:54:51,809 - WARNING - root - 图片文件不存在: images/figure_2_page2.jpeg
2025-11-10 23:54:51,811 - INFO - root - 图片存在于images目录: ./export\QAT\images\figure_2_page2.jpeg
2025-11-10 23:54:51,811 - WARNING - root - 图片文件不存在: images/figure_1_page2.jpeg
2025-11-10 23:54:51,811 - INFO - root - 图片存在于images目录: ./export\QAT\images\figure_1_page2.jpeg
2025-11-10 23:54:51,818 - INFO - root - 论文《Learning to Seek Evidence: A Verifiable Reasoning Agent with Causal Faithfulness Analysis》的分析已保存到 ./export\QAT\Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness.md
2025-11-10 23:54:51,824 - INFO - root - 提取到arXiv ID: 2511.01425
2025-11-10 23:54:51,824 - INFO - root - 估算引用量: 6
2025-11-10 23:54:52,184 - INFO - root - 已生成汇总Excel表格: ./export\QAT\论文汇总_QAT_20251110_235451.xlsx
2025-11-10 23:54:52,187 - INFO - root - 已生成汇总Excel表格: ./export\QAT\论文汇总_QAT_20251110_235451.xlsx
2025-11-10 23:54:52,187 - INFO - root - summary time: 142.81 seconds
2025-11-11 00:07:17,876 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-11 00:07:17,878 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-11 00:07:17,880 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-11 00:07:19,749 - INFO - root - LLMClientManager: 指定使用客户端: Gemini
2025-11-11 00:07:21,345 - INFO - root - GeminiClient: trying model models/gemini-2.5-flash
2025-11-11 00:07:26,101 - INFO - root - GeminiClient: initialized model gemini-2.5-flash
2025-11-11 00:07:26,102 - INFO - root - LLMClientManager: Gemini 客户端初始化成功
2025-11-11 00:07:26,102 - INFO - root - LLMClientManager: switched to Gemini client
2025-11-11 00:07:26,103 - INFO - root - 已手动切换到 LLM 客户端: Gemini
2025-11-11 00:07:26,103 - INFO - root - 使用 LLM 模型: gemini-2.5-flash
2025-11-11 00:07:26,103 - INFO - root - 可用客户端: ['Gemini']
2025-11-11 00:07:26,104 - INFO - root - === 运行配置 ===
2025-11-11 00:07:26,105 - INFO - root - 处理模式: arxiv在线搜索
2025-11-11 00:07:26,106 - INFO - root - 关键词: QAT
2025-11-11 00:07:26,106 - INFO - root - 查询: CVPR 2026
2025-11-11 00:07:26,106 - INFO - root - 排序: None
2025-11-11 00:07:26,107 - INFO - root - 最近天数: 180
2025-11-11 00:07:26,107 - INFO - root - 最大处理数量: 2
2025-11-11 00:07:26,107 - INFO - root - 保存图片: 是
2025-11-11 00:07:26,108 - INFO - root - 输出语言: 中文
2025-11-11 00:07:26,108 - INFO - root - 强制重新处理: 否
2025-11-11 00:07:26,109 - INFO - root - ====================
2025-11-11 00:07:26,110 - INFO - root - 使用 arXiv 搜索模式（通过 chat_arxiv 模块获取）
2025-11-11 00:07:26,110 - INFO - root - Fetching page 1 with URL: https://arxiv.org/search/?query=CVPR+2026&searchtype=all&abstracts=show&order=-announced_date_first&size=50
2025-11-11 00:07:32,188 - INFO - root - get_all_titles_from_web 
2025-11-11 00:07:32,189 - INFO - root - Page:0, Index:0, Learning to Seek Evidence: A Verifiable Reasoning Agent with Causal Faithfulness Analysis, https://arxiv.org/pdf/2511.01425, 2025-11-03
2025-11-11 00:07:32,190 - INFO - root - Fetching page 2 with URL: https://arxiv.org/search/?query=CVPR+2026&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=50
2025-11-11 00:07:38,463 - INFO - root - ------------------------------------------------------------------------------------------------------------------------
2025-11-11 00:07:38,469 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\CVPR 2026\Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness.pdf
2025-11-11 00:07:38,473 - INFO - root - 跳过已处理论文 Learning to Seek Evidence: A Verifiable Reasoning Agent with Causal Faithfulness Analysis：d:\ChatPaper\academic Papers\CVPR 2026\Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness.pdf
2025-11-11 00:07:38,475 - INFO - root - 提取到arXiv ID: 2511.01425
2025-11-11 00:07:38,480 - INFO - root - 调用arXiv API: https://export.arxiv.org/api/query?id=2511.01425
2025-11-11 00:07:44,397 - WARNING - root - 未找到entry元素: 2511.01425
2025-11-11 00:07:44,400 - WARNING - root - arXiv API请求失败: 200
2025-11-11 00:07:44,403 - INFO - root - 估算引用量: 12
2025-11-11 00:07:44,771 - INFO - root - 已生成汇总Excel表格: ./export\QAT\论文汇总_QAT_20251111_000744.xlsx
2025-11-11 00:07:44,773 - INFO - root - 已生成汇总Excel表格: ./export\QAT\论文汇总_QAT_20251111_000744.xlsx
2025-11-11 00:07:44,773 - INFO - root - summary time: 26.90 seconds
2025-11-11 00:15:27,194 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-11 00:15:27,199 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-11 00:15:27,201 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-11 00:15:29,228 - INFO - root - LLMClientManager: 指定使用客户端: Gemini
2025-11-11 00:15:30,523 - INFO - root - GeminiClient: trying model models/gemini-2.5-flash
2025-11-11 00:15:34,827 - INFO - root - GeminiClient: initialized model gemini-2.5-flash
2025-11-11 00:15:34,827 - INFO - root - LLMClientManager: Gemini 客户端初始化成功
2025-11-11 00:15:34,828 - INFO - root - LLMClientManager: switched to Gemini client
2025-11-11 00:15:34,828 - INFO - root - 已手动切换到 LLM 客户端: Gemini
2025-11-11 00:15:34,829 - INFO - root - 使用 LLM 模型: gemini-2.5-flash
2025-11-11 00:15:34,829 - INFO - root - 可用客户端: ['Gemini']
2025-11-11 00:15:34,829 - INFO - root - === 运行配置 ===
2025-11-11 00:15:34,830 - INFO - root - 处理模式: arxiv在线搜索
2025-11-11 00:15:34,830 - INFO - root - 关键词: QAT
2025-11-11 00:15:34,830 - INFO - root - 查询: CVPR 2026
2025-11-11 00:15:34,830 - INFO - root - 排序: None
2025-11-11 00:15:34,831 - INFO - root - 最近天数: 180
2025-11-11 00:15:34,832 - INFO - root - 最大处理数量: 2
2025-11-11 00:15:34,832 - INFO - root - 保存图片: 是
2025-11-11 00:15:34,833 - INFO - root - 输出语言: 中文
2025-11-11 00:15:34,833 - INFO - root - 强制重新处理: 否
2025-11-11 00:15:34,834 - INFO - root - ====================
2025-11-11 00:15:34,834 - INFO - root - 使用 arXiv 搜索模式（通过 chat_arxiv 模块获取）
2025-11-11 00:15:34,834 - INFO - root - Fetching page 1 with URL: https://arxiv.org/search/?query=CVPR+2026&searchtype=all&abstracts=show&order=-announced_date_first&size=50
2025-11-11 00:15:40,901 - INFO - root - get_all_titles_from_web 
2025-11-11 00:15:40,902 - INFO - root - Page:0, Index:0, Learning to Seek Evidence: A Verifiable Reasoning Agent with Causal Faithfulness Analysis, https://arxiv.org/pdf/2511.01425, 2025-11-03
2025-11-11 00:15:40,903 - INFO - root - Fetching page 2 with URL: https://arxiv.org/search/?query=CVPR+2026&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=50
2025-11-11 00:15:46,773 - INFO - root - ------------------------------------------------------------------------------------------------------------------------
2025-11-11 00:15:46,778 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\CVPR 2026\Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness.pdf
2025-11-11 00:15:46,782 - INFO - root - 正在总结论文 1/1: Learning to Seek Evidence: A Verifiable Reasoning Agent with Causal Faithfulness Analysis
2025-11-11 00:16:41,609 - INFO - root - LLMClient: rate limit reached, sleeping 5.2s
2025-11-11 00:17:46,190 - INFO - root - 正在提取论文图片...
2025-11-11 00:17:46,421 - INFO - root - 已保存图片 1/10：./export\QAT\images\figure_1_page2.jpeg
2025-11-11 00:17:46,430 - INFO - root - 已保存图片 2/10：./export\QAT\images\figure_2_page2.jpeg
2025-11-11 00:17:46,438 - INFO - root - 已保存图片 3/10：./export\QAT\images\figure_3_page2.jpeg
2025-11-11 00:17:46,453 - INFO - root - 已保存图片 4/10：./export\QAT\images\figure_4_page2.jpeg
2025-11-11 00:17:46,477 - INFO - root - 已保存图片 5/10：./export\QAT\images\figure_5_page2.jpeg
2025-11-11 00:17:46,491 - INFO - root - 已保存图片 6/10：./export\QAT\images\figure_6_page2.jpeg
2025-11-11 00:17:46,520 - INFO - root - 已保存图片 7/10：./export\QAT\images\figure_7_page2.jpeg
2025-11-11 00:17:46,543 - INFO - root - 已保存图片 8/10：./export\QAT\images\figure_8_page2.jpeg
2025-11-11 00:17:46,615 - INFO - root - 已保存图片 9/10：./export\QAT\images\figure_9_page2.jpeg
2025-11-11 00:17:46,631 - INFO - root - 已保存图片 10/10：./export\QAT\images\figure_10_page2.jpeg
2025-11-11 00:17:46,645 - INFO - root - 成功添加图片 1：./export\QAT\images\figure_1_page2.jpeg
2025-11-11 00:17:46,646 - INFO - root - 成功添加图片 2：./export\QAT\images\figure_2_page2.jpeg
2025-11-11 00:17:46,647 - INFO - root - 成功添加图片 3：./export\QAT\images\figure_3_page2.jpeg
2025-11-11 00:17:46,647 - INFO - root - 成功添加图片 4：./export\QAT\images\figure_4_page2.jpeg
2025-11-11 00:17:46,647 - INFO - root - 成功添加图片 5：./export\QAT\images\figure_5_page2.jpeg
2025-11-11 00:17:46,647 - INFO - root - 成功添加图片 6：./export\QAT\images\figure_6_page2.jpeg
2025-11-11 00:17:46,653 - INFO - root - 成功添加图片 7：./export\QAT\images\figure_7_page2.jpeg
2025-11-11 00:17:46,654 - INFO - root - 成功添加图片 8：./export\QAT\images\figure_8_page2.jpeg
2025-11-11 00:17:46,654 - INFO - root - 成功添加图片 9：./export\QAT\images\figure_9_page2.jpeg
2025-11-11 00:17:46,654 - INFO - root - 成功添加图片 10：./export\QAT\images\figure_10_page2.jpeg
2025-11-11 00:17:46,656 - INFO - root - 提取到arXiv ID: 2511.01425
2025-11-11 00:17:46,658 - INFO - root - 调用arXiv API: https://export.arxiv.org/api/query?id=2511.01425
2025-11-11 00:17:52,559 - WARNING - root - 未找到entry元素: 2511.01425
2025-11-11 00:17:52,559 - INFO - root - XML根元素标签: {http://www.w3.org/2005/Atom}feed
2025-11-11 00:17:52,559 - INFO - root - XML根元素属性: {}
2025-11-11 00:17:52,559 - INFO - root - 根元素的直接子元素:
2025-11-11 00:17:52,560 - INFO - root -   0. {http://www.w3.org/2005/Atom}link: None
2025-11-11 00:17:52,560 - INFO - root -   1. {http://www.w3.org/2005/Atom}title: ArXiv Query: search_query=&id_list=&start=0&max_results=10
2025-11-11 00:17:52,560 - INFO - root -   2. {http://www.w3.org/2005/Atom}id: http://arxiv.org/api/iQlyOhQ3W8t8kI903+StmrBZNWM
2025-11-11 00:17:52,560 - INFO - root -   3. {http://www.w3.org/2005/Atom}updated: 2025-11-10T00:00:00-05:00
2025-11-11 00:17:52,561 - INFO - root -   4. {http://a9.com/-/spec/opensearch/1.1/}totalResults: 0
2025-11-11 00:17:52,561 - INFO - root -   5. {http://a9.com/-/spec/opensearch/1.1/}startIndex: 0
2025-11-11 00:17:52,561 - INFO - root -   6. {http://a9.com/-/spec/opensearch/1.1/}itemsPerPage: 10
2025-11-11 00:17:52,561 - INFO - root - XML内容前500字符: <?xml version="1.0" encoding="UTF-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <link href="http://arxiv.org/api/query?search_query%3D%26id_list%3D%26start%3D0%26max_results%3D10" rel="self" type="application/atom+xml"/>
  <title type="html">ArXiv Query: search_query=&amp;id_list=&amp;start=0&amp;max_results=10</title>
  <id>http://arxiv.org/api/iQlyOhQ3W8t8kI903+StmrBZNWM</id>
  <updated>2025-11-10T00:00:00-05:00</updated>
  <opensearch:totalResults xmlns:opensearch="http://a9.com/-/spec/op
2025-11-11 00:17:52,564 - INFO - root - 估算引用量: 3
2025-11-11 00:17:52,566 - WARNING - root - 图片文件不存在: images/figure_10_page2.jpeg
2025-11-11 00:17:52,568 - INFO - root - 图片存在于images目录: ./export\QAT\images\figure_10_page2.jpeg
2025-11-11 00:17:52,568 - WARNING - root - 图片文件不存在: images/figure_9_page2.jpeg
2025-11-11 00:17:52,568 - INFO - root - 图片存在于images目录: ./export\QAT\images\figure_9_page2.jpeg
2025-11-11 00:17:52,569 - WARNING - root - 图片文件不存在: images/figure_8_page2.jpeg
2025-11-11 00:17:52,569 - INFO - root - 图片存在于images目录: ./export\QAT\images\figure_8_page2.jpeg
2025-11-11 00:17:52,570 - WARNING - root - 图片文件不存在: images/figure_7_page2.jpeg
2025-11-11 00:17:52,572 - INFO - root - 图片存在于images目录: ./export\QAT\images\figure_7_page2.jpeg
2025-11-11 00:17:52,574 - WARNING - root - 图片文件不存在: images/figure_6_page2.jpeg
2025-11-11 00:17:52,577 - INFO - root - 图片存在于images目录: ./export\QAT\images\figure_6_page2.jpeg
2025-11-11 00:17:52,579 - WARNING - root - 图片文件不存在: images/figure_5_page2.jpeg
2025-11-11 00:17:52,579 - INFO - root - 图片存在于images目录: ./export\QAT\images\figure_5_page2.jpeg
2025-11-11 00:17:52,579 - WARNING - root - 图片文件不存在: images/figure_4_page2.jpeg
2025-11-11 00:17:52,580 - INFO - root - 图片存在于images目录: ./export\QAT\images\figure_4_page2.jpeg
2025-11-11 00:17:52,580 - WARNING - root - 图片文件不存在: images/figure_3_page2.jpeg
2025-11-11 00:17:52,580 - INFO - root - 图片存在于images目录: ./export\QAT\images\figure_3_page2.jpeg
2025-11-11 00:17:52,581 - WARNING - root - 图片文件不存在: images/figure_2_page2.jpeg
2025-11-11 00:17:52,581 - INFO - root - 图片存在于images目录: ./export\QAT\images\figure_2_page2.jpeg
2025-11-11 00:17:52,581 - WARNING - root - 图片文件不存在: images/figure_1_page2.jpeg
2025-11-11 00:17:52,581 - INFO - root - 图片存在于images目录: ./export\QAT\images\figure_1_page2.jpeg
2025-11-11 00:17:52,584 - INFO - root - 论文《Learning to Seek Evidence: A Verifiable Reasoning Agent with Causal Faithfulness Analysis》的分析已保存到 ./export\QAT\Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness.md
2025-11-11 00:17:52,589 - INFO - root - 提取到arXiv ID: 2511.01425
2025-11-11 00:17:52,592 - INFO - root - 调用arXiv API: https://export.arxiv.org/api/query?id=2511.01425
2025-11-11 00:17:58,009 - WARNING - root - 未找到entry元素: 2511.01425
2025-11-11 00:17:58,010 - INFO - root - XML根元素标签: {http://www.w3.org/2005/Atom}feed
2025-11-11 00:17:58,011 - INFO - root - XML根元素属性: {}
2025-11-11 00:17:58,012 - INFO - root - 根元素的直接子元素:
2025-11-11 00:17:58,013 - INFO - root -   0. {http://www.w3.org/2005/Atom}link: None
2025-11-11 00:17:58,013 - INFO - root -   1. {http://www.w3.org/2005/Atom}title: ArXiv Query: search_query=&id_list=&start=0&max_results=10
2025-11-11 00:17:58,013 - INFO - root -   2. {http://www.w3.org/2005/Atom}id: http://arxiv.org/api/iQlyOhQ3W8t8kI903+StmrBZNWM
2025-11-11 00:17:58,013 - INFO - root -   3. {http://www.w3.org/2005/Atom}updated: 2025-11-10T00:00:00-05:00
2025-11-11 00:17:58,013 - INFO - root -   4. {http://a9.com/-/spec/opensearch/1.1/}totalResults: 0
2025-11-11 00:17:58,013 - INFO - root -   5. {http://a9.com/-/spec/opensearch/1.1/}startIndex: 0
2025-11-11 00:17:58,014 - INFO - root -   6. {http://a9.com/-/spec/opensearch/1.1/}itemsPerPage: 10
2025-11-11 00:17:58,014 - INFO - root - XML内容前500字符: <?xml version="1.0" encoding="UTF-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <link href="http://arxiv.org/api/query?search_query%3D%26id_list%3D%26start%3D0%26max_results%3D10" rel="self" type="application/atom+xml"/>
  <title type="html">ArXiv Query: search_query=&amp;id_list=&amp;start=0&amp;max_results=10</title>
  <id>http://arxiv.org/api/iQlyOhQ3W8t8kI903+StmrBZNWM</id>
  <updated>2025-11-10T00:00:00-05:00</updated>
  <opensearch:totalResults xmlns:opensearch="http://a9.com/-/spec/op
2025-11-11 00:17:58,018 - INFO - root - 估算引用量: 13
2025-11-11 00:17:58,370 - INFO - root - 已生成汇总Excel表格: ./export\QAT\论文汇总_QAT_20251111_001758.xlsx
2025-11-11 00:17:58,372 - INFO - root - 已生成汇总Excel表格: ./export\QAT\论文汇总_QAT_20251111_001758.xlsx
2025-11-11 00:17:58,373 - INFO - root - summary time: 151.18 seconds
2025-11-11 00:19:34,204 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-11 00:19:34,206 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-11 00:19:34,209 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-11 00:19:36,364 - INFO - root - LLMClientManager: 指定使用客户端: Gemini
2025-11-11 00:19:37,230 - INFO - root - GeminiClient: trying model models/gemini-2.5-flash
2025-11-11 00:19:44,898 - INFO - root - GeminiClient: initialized model gemini-2.5-flash
2025-11-11 00:19:44,900 - INFO - root - LLMClientManager: Gemini 客户端初始化成功
2025-11-11 00:19:44,902 - INFO - root - LLMClientManager: switched to Gemini client
2025-11-11 00:19:44,904 - INFO - root - 已手动切换到 LLM 客户端: Gemini
2025-11-11 00:19:44,905 - INFO - root - 使用 LLM 模型: gemini-2.5-flash
2025-11-11 00:19:44,906 - INFO - root - 可用客户端: ['Gemini']
2025-11-11 00:19:44,908 - INFO - root - === 运行配置 ===
2025-11-11 00:19:44,908 - INFO - root - 处理模式: arxiv在线搜索
2025-11-11 00:19:44,909 - INFO - root - 关键词: CVPR
2025-11-11 00:19:44,910 - INFO - root - 查询: CVPR 2025
2025-11-11 00:19:44,911 - INFO - root - 排序: None
2025-11-11 00:19:44,913 - INFO - root - 最近天数: 180
2025-11-11 00:19:44,915 - INFO - root - 最大处理数量: 5
2025-11-11 00:19:44,917 - INFO - root - 保存图片: 是
2025-11-11 00:19:44,920 - INFO - root - 输出语言: 中文
2025-11-11 00:19:44,921 - INFO - root - 强制重新处理: 否
2025-11-11 00:19:44,922 - INFO - root - ====================
2025-11-11 00:19:44,923 - INFO - root - 使用 arXiv 搜索模式（通过 chat_arxiv 模块获取）
2025-11-11 00:19:44,925 - INFO - root - Fetching page 1 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50
2025-11-11 00:19:52,377 - INFO - root - get_all_titles_from_web 
2025-11-11 00:19:52,378 - INFO - root - Page:0, Index:0, Learning to Seek Evidence: A Verifiable Reasoning Agent with Causal Faithfulness Analysis, https://arxiv.org/pdf/2511.01425, 2025-11-03
2025-11-11 00:19:52,378 - INFO - root - Page:0, Index:1, OmniTrack++: Omnidirectional Multi-Object Tracking by Learning Large-FoV Trajectory Feedback, https://arxiv.org/pdf/2511.00510, 2025-11-01
2025-11-11 00:19:52,379 - INFO - root - Page:0, Index:2, NeuCo-Bench: A Novel Benchmark Framework for Neural Embeddings in Earth Observation, https://arxiv.org/pdf/2510.17914, 2025-10-19
2025-11-11 00:19:52,379 - INFO - root - Page:0, Index:3, NTIRE 2025 Challenge on Low Light Image Enhancement: Methods and Results, https://arxiv.org/pdf/2510.13670, 2025-10-15
2025-11-11 00:19:52,379 - INFO - root - Page:0, Index:4, Class Prototypes based Contrastive Learning for Classifying Multi-Label and Fine-Grained Educational Videos, https://arxiv.org/pdf/2510.11204, 2025-10-13
2025-11-11 00:19:52,379 - INFO - root - Page:0, Index:5, MIMO: A medical vision language model with visual referring multimodal input and pixel grounding multimodal output, https://arxiv.org/pdf/2510.10011, 2025-10-11
2025-11-11 00:19:52,379 - INFO - root - Page:0, Index:6, Vision Language Models: A Survey of 26K Papers, https://arxiv.org/pdf/2510.09586, 2025-10-10
2025-11-11 00:19:52,380 - INFO - root - Page:0, Index:7, DiT-VTON: Diffusion Transformer Framework for Unified Multi-Category Virtual Try-On and Virtual Try-All with Integrated Image Editing, https://arxiv.org/pdf/2510.04797, 2025-10-03
2025-11-11 00:19:52,380 - INFO - root - Page:0, Index:8, PatchVSR: Breaking Video Diffusion Resolution Limits with Patch-wise Video Super-Resolution, https://arxiv.org/pdf/2509.26025, 2025-09-30
2025-11-11 00:19:52,380 - INFO - root - Page:0, Index:9, FreqDebias: Towards Generalizable Deepfake Detection via Consistency-Driven Frequency Debiasing, https://arxiv.org/pdf/2509.22412, 2025-09-26
2025-11-11 00:19:52,380 - INFO - root - Page:0, Index:10, A Mutual Learning Method for Salient Object Detection with intertwined Multi-Supervision--Revised, https://arxiv.org/pdf/2509.21363, 2025-09-21
2025-11-11 00:19:52,380 - INFO - root - Page:0, Index:11, InstructVTON: Optimal Auto-Masking and Natural-Language-Guided Interactive Style Control for Inpainting-Based Virtual Try-On, https://arxiv.org/pdf/2509.20524, 2025-09-24
2025-11-11 00:19:52,381 - INFO - root - Page:0, Index:12, Efficient Encoder-Free Pose Conditioning and Pose Control for Virtual Try-On, https://arxiv.org/pdf/2509.20343, 2025-09-24
2025-11-11 00:19:52,381 - INFO - root - Page:0, Index:13, The Photographer Eye: Teaching Multimodal Large Language Models to Understand Image Aesthetics like Photographers, https://arxiv.org/pdf/2509.18582, 2025-10-22
2025-11-11 00:19:52,381 - INFO - root - Page:0, Index:14, ENSAM: an efficient foundation model for interactive segmentation of 3D medical images, https://arxiv.org/pdf/2509.15874, 2025-09-19
2025-11-11 00:19:52,381 - INFO - root - Page:0, Index:15, DEFT-VTON: Efficient Virtual Try-On with Consistent Generalised H-Transform, https://arxiv.org/pdf/2509.13506, 2025-09-16
2025-11-11 00:19:52,381 - INFO - root - Page:0, Index:16, Weakly and Self-Supervised Class-Agnostic Motion Prediction for Autonomous Driving, https://arxiv.org/pdf/2509.13116, 2025-09-16
2025-11-11 00:19:52,381 - INFO - root - Page:0, Index:17, Domain-Adaptive Pretraining Improves Primate Behavior Recognition, https://arxiv.org/pdf/2509.12193, 2025-09-15
2025-11-11 00:19:52,381 - INFO - root - Page:0, Index:18, The System Description of CPS Team for Track on Driving with Language of CVPR 2024 Autonomous Grand Challenge, https://arxiv.org/pdf/2509.11071, 2025-09-13
2025-11-11 00:19:52,381 - INFO - root - Page:0, Index:19, An HMM-based framework for identity-aware long-term multi-object tracking from sparse and uncertain identification: use case on long-term tracking in livestock, https://arxiv.org/pdf/2509.09962, 2025-09-12
2025-11-11 00:19:52,383 - INFO - root - Page:0, Index:20, InterAct: Advancing Large-Scale Versatile 3D Human-Object Interaction Generation, https://arxiv.org/pdf/2509.09555, 2025-09-11
2025-11-11 00:19:52,384 - INFO - root - Page:0, Index:21, Geospatial Foundational Embedder: Top-1 Winning Solution on EarthVision Embed2Scale Challenge (CVPR 2025), https://arxiv.org/pdf/2509.06993, 2025-09-03
2025-11-11 00:19:52,385 - INFO - root - Page:0, Index:22, 2nd Place Solution for CVPR2024 E2E Challenge: End-to-End Autonomous Driving Using Vision Language Model, https://arxiv.org/pdf/2509.02659, 2025-09-02
2025-11-11 00:19:52,386 - INFO - root - Page:0, Index:23, Unsupervised Training of Vision Transformers with Synthetic Negatives, https://arxiv.org/pdf/2509.02024, 2025-09-02
2025-11-11 00:19:52,386 - INFO - root - Page:0, Index:24, MV-SSM: Multi-View State Space Modeling for 3D Human Pose Estimation, https://arxiv.org/pdf/2509.00649, 2025-08-30
2025-11-11 00:19:52,387 - INFO - root - Page:0, Index:25, CryptoFace: End-to-End Encrypted Face Recognition, https://arxiv.org/pdf/2509.00332, 2025-08-29
2025-11-11 00:19:52,389 - INFO - root - Page:0, Index:26, ControlEchoSynth: Boosting Ejection Fraction Estimation Models via Controlled Video Diffusion, https://arxiv.org/pdf/2508.17631, 2025-08-26
2025-11-11 00:19:52,390 - INFO - root - Page:0, Index:27, Explain Before You Answer: A Survey on Compositional Visual Reasoning, https://arxiv.org/pdf/2508.17298, 2025-08-27
2025-11-11 00:19:52,391 - INFO - root - Page:0, Index:28, Investigating Different Geo Priors for Image Classification, https://arxiv.org/pdf/2508.15946, 2025-08-21
2025-11-11 00:19:52,400 - INFO - root - Page:0, Index:29, Towards Source-Free Machine Unlearning, https://arxiv.org/pdf/2508.15127, 2025-08-20
2025-11-11 00:19:52,416 - INFO - root - Page:0, Index:30, MR6D: Benchmarking 6D Pose Estimation for Mobile Robots, https://arxiv.org/pdf/2508.13775, 2025-08-19
2025-11-11 00:19:52,419 - INFO - root - Page:0, Index:31, Calibrating Biased Distribution in VFM-derived Latent Space via Cross-Domain Geometric Consistency, https://arxiv.org/pdf/2508.13518, 2025-08-19
2025-11-11 00:19:52,420 - INFO - root - Page:0, Index:32, SIS-Challenge: Event-based Spatio-temporal Instance Segmentation Challenge at the CVPR 2025 Event-based Vision Workshop, https://arxiv.org/pdf/2508.12813, 2025-08-18
2025-11-11 00:19:52,421 - INFO - root - Page:0, Index:33, Multi-Level Knowledge Distillation and Dynamic Self-Supervised Learning for Continual Learning, https://arxiv.org/pdf/2508.12692, 2025-08-22
2025-11-11 00:19:52,424 - INFO - root - Page:0, Index:34, Stochastic-based Patch Filtering for Few-Shot Learning, https://arxiv.org/pdf/2508.10066, 2025-08-13
2025-11-11 00:19:52,433 - INFO - root - Page:0, Index:35, Slot Attention-based Feature Filtering for Few-Shot Learning, https://arxiv.org/pdf/2508.09699, 2025-08-13
2025-11-11 00:19:52,437 - INFO - root - Page:0, Index:36, Comparison Reveals Commonality: Customized Image Generation through Contrastive Inversion, https://arxiv.org/pdf/2508.07755, 2025-08-11
2025-11-11 00:19:52,439 - INFO - root - Page:0, Index:37, SLRTP2025 Sign Language Production Challenge: Methodology, Results, and Future Work, https://arxiv.org/pdf/2508.06951, 2025-08-09
2025-11-11 00:19:52,439 - INFO - root - Page:0, Index:38, Exploring Fairness across Fine-Grained Attributes in Large Vision-Language Models, https://arxiv.org/pdf/2508.03079, 2025-08-05
2025-11-11 00:19:52,441 - INFO - root - Page:0, Index:39, Devil is in the Detail: Towards Injecting Fine Details of Image Prompt in Image Generation via Conflict-free Guidance and Stratified Attention, https://arxiv.org/pdf/2508.02004, 2025-08-03
2025-11-11 00:19:52,444 - INFO - root - Page:0, Index:40, IAUNet: Instance-Aware U-Net, https://arxiv.org/pdf/2508.01928, 2025-08-03
2025-11-11 00:19:52,448 - INFO - root - Page:0, Index:41, Gaussian Splatting Feature Fields for Privacy-Preserving Visual Localization, https://arxiv.org/pdf/2507.23569, 2025-08-26
2025-11-11 00:19:52,452 - INFO - root - Page:0, Index:42, From Scan to Action: Leveraging Realistic Scans for Embodied Scene Understanding, https://arxiv.org/pdf/2507.17585, 2025-07-23
2025-11-11 00:19:52,457 - INFO - root - Page:0, Index:43, LEAD: Exploring Logit Space Evolution for Model Selection, https://arxiv.org/pdf/2507.14559, 2025-07-19
2025-11-11 00:19:52,464 - INFO - root - Page:0, Index:44, HeCoFuse: Cross-Modal Complementary V2X Cooperative Perception with Heterogeneous Sensors, https://arxiv.org/pdf/2507.13677, 2025-07-18
2025-11-11 00:19:52,467 - INFO - root - Page:0, Index:45, OmniVec2 -- A Novel Transformer based Network for Large Scale Multimodal and Multitask Learning, https://arxiv.org/pdf/2507.13364, 2025-07-06
2025-11-11 00:19:52,468 - INFO - root - Page:0, Index:46, A Training-Free, Task-Agnostic Framework for Enhancing MLLM Performance on High-Resolution Images, https://arxiv.org/pdf/2507.10202, 2025-07-14
2025-11-11 00:19:52,469 - INFO - root - Page:0, Index:47, Quantum Federated Learning for Multimodal Data: A Modality-Agnostic Approach, https://arxiv.org/pdf/2507.08217, 2025-07-10
2025-11-11 00:19:52,479 - INFO - root - Page:0, Index:48, CuriosAI Submission to the EgoExo4D Proficiency Estimation Challenge 2025, https://arxiv.org/pdf/2507.08022, 2025-07-08
2025-11-11 00:19:52,484 - INFO - root - Page:0, Index:49, Rethinking Query-based Transformer for Continual Image Segmentation, https://arxiv.org/pdf/2507.07831, 2025-07-10
2025-11-11 00:19:52,486 - INFO - root - Fetching page 2 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=50
2025-11-11 00:20:00,191 - INFO - root - get_all_titles_from_web 
2025-11-11 00:20:00,192 - INFO - root - Page:1, Index:0, Scalable and Realistic Virtual Try-on Application for Foundation Makeup with Kubelka-Munk Theory, https://arxiv.org/pdf/2507.07333, 2025-07-09
2025-11-11 00:20:00,192 - INFO - root - Page:1, Index:1, Free on the Fly: Enhancing Flexibility in Test-Time Adaptation with Online EM, https://arxiv.org/pdf/2507.06973, 2025-07-09
2025-11-11 00:20:00,192 - INFO - root - Page:1, Index:2, Adaptive Part Learning for Fine-Grained Generalized Category Discovery: A Plug-and-Play Enhancement, https://arxiv.org/pdf/2507.06928, 2025-07-09
2025-11-11 00:20:00,192 - INFO - root - Page:1, Index:3, Grounded Gesture Generation: Language, Motion, and Space, https://arxiv.org/pdf/2507.04522, 2025-07-06
2025-11-11 00:20:00,194 - INFO - root - Page:1, Index:4, Comprehensive Information Bottleneck for Unveiling Universal Attribution to Interpret Vision Transformers, https://arxiv.org/pdf/2507.04388, 2025-07-06
2025-11-11 00:20:00,194 - INFO - root - Page:1, Index:5, ZERO: Industry-ready Vision Foundation Model with Multi-modal Prompts, https://arxiv.org/pdf/2507.04270, 2025-11-07
2025-11-11 00:20:00,194 - INFO - root - Page:1, Index:6, Beyond Accuracy: Metrics that Uncover What Makes a 'Good' Visual Descriptor, https://arxiv.org/pdf/2507.03542, 2025-07-08
2025-11-11 00:20:00,195 - INFO - root - Page:1, Index:7, ConceptMix++: Leveling the Playing Field in Text-to-Image Benchmarking via Iterative Prompt Optimization, https://arxiv.org/pdf/2507.03275, 2025-07-03
2025-11-11 00:20:00,195 - INFO - root - Page:1, Index:8, APT: Adaptive Personalized Training for Diffusion Models with Limited Data, https://arxiv.org/pdf/2507.02687, 2025-07-03
2025-11-11 00:20:00,196 - INFO - root - Page:1, Index:9, DreamComposer++: Empowering Diffusion Models with Multi-View Conditions for 3D Content Generation, https://arxiv.org/pdf/2507.02299, 2025-07-03
2025-11-11 00:20:00,196 - INFO - root - Page:1, Index:10, Soft Self-labeling and Potts Relaxations for Weakly-Supervised Segmentation, https://arxiv.org/pdf/2507.01721, 2025-07-02
2025-11-11 00:20:00,196 - INFO - root - Page:1, Index:11, Interpolation-Based Event Visual Data Filtering Algorithms, https://arxiv.org/pdf/2507.01557, 2025-07-02
2025-11-11 00:20:00,196 - INFO - root - Page:1, Index:12, AVC-DPO: Aligned Video Captioning via Direct Preference Optimization, https://arxiv.org/pdf/2507.01492, 2025-07-02
2025-11-11 00:20:00,198 - INFO - root - Page:1, Index:13, NN-Former: Rethinking Graph Structure in Neural Architecture Representation, https://arxiv.org/pdf/2507.00880, 2025-07-01
2025-11-11 00:20:00,198 - INFO - root - Page:1, Index:14, Instant Particle Size Distribution Measurement Using CNNs Trained on Synthetic Data, https://arxiv.org/pdf/2507.00822, 2025-07-01
2025-11-11 00:20:00,200 - INFO - root - Page:1, Index:15, Moment Sampling in Video LLMs for Long-Form Video QA, https://arxiv.org/pdf/2507.00033, 2025-06-17
2025-11-11 00:20:00,200 - INFO - root - Page:1, Index:16, Revisiting Audio-Visual Segmentation with Vision-Centric Transformer, https://arxiv.org/pdf/2506.23623, 2025-06-30
2025-11-11 00:20:00,200 - INFO - root - Page:1, Index:17, MTADiffusion: Mask Text Alignment Diffusion Model for Object Inpainting, https://arxiv.org/pdf/2506.23482, 2025-06-29
2025-11-11 00:20:00,200 - INFO - root - Page:1, Index:18, Benchmarking Generalizable Bimanual Manipulation: RoboTwin Dual-Arm Collaboration Challenge at CVPR 2025 MEIS Workshop, https://arxiv.org/pdf/2506.23351, 2025-07-02
2025-11-11 00:20:00,200 - INFO - root - Page:1, Index:19, Prompting without Panic: Attribute-aware, Zero-shot, Test-Time Calibration, https://arxiv.org/pdf/2506.22819, 2025-06-28
2025-11-11 00:20:00,201 - INFO - root - Page:1, Index:20, Analyzing and Fine-Tuning Whisper Models for Multilingual Pilot Speech Transcription in the Cockpit, https://arxiv.org/pdf/2506.21990, 2025-06-27
2025-11-11 00:20:00,201 - INFO - root - Page:1, Index:21, SceneDiffuser++: City-Scale Traffic Simulation via a Generative World Model, https://arxiv.org/pdf/2506.21976, 2025-06-27
2025-11-11 00:20:00,201 - INFO - root - Page:1, Index:22, DIVE: Deep-search Iterative Video Exploration A Technical Report for the CVRR Challenge at CVPR 2025, https://arxiv.org/pdf/2506.21891, 2025-06-27
2025-11-11 00:20:00,201 - INFO - root - Page:1, Index:23, End-to-End RGB-IR Joint Image Compression With Channel-wise Cross-modality Entropy Model, https://arxiv.org/pdf/2506.21851, 2025-06-26
2025-11-11 00:20:00,201 - INFO - root - Page:1, Index:24, Distilling Normalizing Flows, https://arxiv.org/pdf/2506.21003, 2025-06-26
2025-11-11 00:20:00,201 - INFO - root - Page:1, Index:25, Joint attitude estimation and 3D neural reconstruction of non-cooperative space objects, https://arxiv.org/pdf/2506.20638, 2025-06-25
2025-11-11 00:20:00,202 - INFO - root - Page:1, Index:26, Accept More, Reject Less: Reducing up to 19% Unnecessary Desk-Rejections over 11 Years of ICLR Data, https://arxiv.org/pdf/2506.20141, 2025-06-25
2025-11-11 00:20:00,202 - INFO - root - Page:1, Index:27, SceneCrafter: Controllable Multi-View Driving Scene Editing, https://arxiv.org/pdf/2506.19488, 2025-06-24
2025-11-11 00:20:00,202 - INFO - root - Page:1, Index:28, Emergence of Text Readability in Vision Language Models, https://arxiv.org/pdf/2506.19389, 2025-06-24
2025-11-11 00:20:00,202 - INFO - root - Page:1, Index:29, MedErr-CT: A Visual Question Answering Benchmark for Identifying and Correcting Errors in CT Reports, https://arxiv.org/pdf/2506.19217, 2025-06-23
2025-11-11 00:20:00,204 - INFO - root - Page:1, Index:30, RareSpot: Spotting Small and Rare Wildlife in Aerial Imagery with Multi-Scale Consistency and Context-Aware Augmentation, https://arxiv.org/pdf/2506.19087, 2025-06-23
2025-11-11 00:20:00,204 - INFO - root - Page:1, Index:31, Object-aware Sound Source Localization via Audio-Visual Scene Understanding, https://arxiv.org/pdf/2506.18557, 2025-06-23
2025-11-11 00:20:00,205 - INFO - root - Page:1, Index:32, Rethinking Decoder Design: Improving Biomarker Segmentation Using Depth-to-Space Restoration and Residual Linear Attention, https://arxiv.org/pdf/2506.18335, 2025-06-23
2025-11-11 00:20:00,207 - INFO - root - Page:1, Index:33, Relation3D: Enhancing Relation Modeling for Point Cloud Instance Segmentation, https://arxiv.org/pdf/2506.17891, 2025-06-21
2025-11-11 00:20:00,207 - INFO - root - Page:1, Index:34, HIRE: Lightweight High-Resolution Image Feature Enrichment for Multimodal LLMs, https://arxiv.org/pdf/2506.17608, 2025-06-21
2025-11-11 00:20:00,207 - INFO - root - Page:1, Index:35, Spatially-Aware Evaluation of Segmentation Uncertainty, https://arxiv.org/pdf/2506.16589, 2025-06-19
2025-11-11 00:20:00,209 - INFO - root - Page:1, Index:36, Tripartite Weight-Space Ensemble for Few-Shot Class-Incremental Learning, https://arxiv.org/pdf/2506.15720, 2025-06-03
2025-11-11 00:20:00,210 - INFO - root - Page:1, Index:37, PARC: A Quantitative Framework Uncovering the Symmetries within Vision Language Models, https://arxiv.org/pdf/2506.14808, 2025-06-03
2025-11-11 00:20:00,211 - INFO - root - Page:1, Index:38, Self-supervised Representation Learning with Local Aggregation for Image-based Profiling, https://arxiv.org/pdf/2506.14265, 2025-10-27
2025-11-11 00:20:00,212 - INFO - root - Page:1, Index:39, Towards Robust Learning to Optimize with Theoretical Guarantees, https://arxiv.org/pdf/2506.14263, 2025-06-17
2025-11-11 00:20:00,213 - INFO - root - Page:1, Index:40, Hidden Bias in the Machine: Stereotypes in Text-to-Image Models, https://arxiv.org/pdf/2506.13780, 2025-06-09
2025-11-11 00:20:00,213 - INFO - root - Page:1, Index:41, SmartHome-Bench: A Comprehensive Benchmark for Video Anomaly Detection in Smart Homes Using Multi-Modal Large Language Models, https://arxiv.org/pdf/2506.12992, 2025-06-15
2025-11-11 00:20:00,214 - INFO - root - Page:1, Index:42, Generative 4D Scene Gaussian Splatting with Object View-Synthesis Priors, https://arxiv.org/pdf/2506.12716, 2025-06-15
2025-11-11 00:20:00,215 - INFO - root - Page:1, Index:43, DejaVid: Encoder-Agnostic Learned Temporal Matching for Video Classification, https://arxiv.org/pdf/2506.12585, 2025-06-14
2025-11-11 00:20:00,219 - INFO - root - Page:1, Index:44, Pushing the Limits of Safety: A Technical Report on the ATLAS Challenge 2025, https://arxiv.org/pdf/2506.12430, 2025-07-10
2025-11-11 00:20:00,220 - INFO - root - Page:1, Index:45, FIMA-Q: Post-Training Quantization for Vision Transformers by Fisher Information Matrix Approximation, https://arxiv.org/pdf/2506.11543, 2025-06-13
2025-11-11 00:20:00,222 - INFO - root - Page:1, Index:46, Stop learning it all to mitigate visual hallucination, Focus on the hallucination target, https://arxiv.org/pdf/2506.11417, 2025-06-12
2025-11-11 00:20:00,222 - INFO - root - Page:1, Index:47, EfficientQuant: An Efficient Post-Training Quantization for CNN-Transformer Hybrid Models on Edge Devices, https://arxiv.org/pdf/2506.11093, 2025-06-05
2025-11-11 00:20:00,222 - INFO - root - Page:1, Index:48, HalLoc: Token-level Localization of Hallucinations for Vision Language Models, https://arxiv.org/pdf/2506.10286, 2025-06-11
2025-11-11 00:20:00,223 - INFO - root - Page:1, Index:49, DySS: Dynamic Queries and State-Space Learning for Efficient 3D Object Detection from Multi-Camera Videos, https://arxiv.org/pdf/2506.10242, 2025-06-11
2025-11-11 00:20:00,224 - INFO - root - Fetching page 3 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=100
2025-11-11 00:20:08,109 - INFO - root - get_all_titles_from_web 
2025-11-11 00:20:08,110 - INFO - root - Page:2, Index:0, Improving Personalized Search with Regularized Low-Rank Parameter Updates, https://arxiv.org/pdf/2506.10182, 2025-06-11
2025-11-11 00:20:08,110 - INFO - root - Page:2, Index:1, Hearing Hands: Generating Sounds from Physical Interactions in 3D Scenes, https://arxiv.org/pdf/2506.09989, 2025-06-11
2025-11-11 00:20:08,111 - INFO - root - Page:2, Index:2, UniPre3D: Unified Pre-training of 3D Point Cloud Models with Cross-Modal Gaussian Splatting, https://arxiv.org/pdf/2506.09952, 2025-06-11
2025-11-11 00:20:08,111 - INFO - root - Page:2, Index:3, Provoking Multi-modal Few-Shot LVLM via Exploration-Exploitation In-Context Learning, https://arxiv.org/pdf/2506.09473, 2025-06-11
2025-11-11 00:20:08,111 - INFO - root - Page:2, Index:4, Synthetic Human Action Video Data Generation with Pose Transfer, https://arxiv.org/pdf/2506.09411, 2025-06-11
2025-11-11 00:20:08,112 - INFO - root - Page:2, Index:5, ScaleLSD: Scalable Deep Line Segment Detection Streamlined, https://arxiv.org/pdf/2506.09369, 2025-06-10
2025-11-11 00:20:08,112 - INFO - root - Page:2, Index:6, CheckManual: A New Challenge and Benchmark for Manual-based Appliance Manipulation, https://arxiv.org/pdf/2506.09343, 2025-06-10
2025-11-11 00:20:08,112 - INFO - root - Page:2, Index:7, PatchGuard: Adversarially Robust Anomaly Detection and Localization through Vision Transformers and Pseudo Anomalies, https://arxiv.org/pdf/2506.09237, 2025-10-24
2025-11-11 00:20:08,112 - INFO - root - Page:2, Index:8, SILK: Smooth InterpoLation frameworK for motion in-betweening A Simplified Computational Approach, https://arxiv.org/pdf/2506.09075, 2025-06-09
2025-11-11 00:20:08,112 - INFO - root - Page:2, Index:9, BG-HOP: A Bimanual Generative Hand-Object Prior, https://arxiv.org/pdf/2506.09068, 2025-06-08
2025-11-11 00:20:08,112 - INFO - root - Page:2, Index:10, ORIDa: Object-centric Real-world Image Composition Dataset, https://arxiv.org/pdf/2506.08964, 2025-06-10
2025-11-11 00:20:08,114 - INFO - root - Page:2, Index:11, DiscoVLA: Discrepancy Reduction in Vision, Language, and Alignment for Parameter-Efficient Video-Text Retrieval, https://arxiv.org/pdf/2506.08887, 2025-06-10
2025-11-11 00:20:08,114 - INFO - root - Page:2, Index:12, A Comprehensive Study of Decoder-Only LLMs for Text-to-Image Generation, https://arxiv.org/pdf/2506.08210, 2025-06-09
2025-11-11 00:20:08,114 - INFO - root - Page:2, Index:13, Open World Scene Graph Generation using Vision Language Models, https://arxiv.org/pdf/2506.08189, 2025-06-09
2025-11-11 00:20:08,115 - INFO - root - Page:2, Index:14, Aligning Proteins and Language: A Foundation Model for Protein Retrieval, https://arxiv.org/pdf/2506.08023, 2025-05-27
2025-11-11 00:20:08,115 - INFO - root - Page:2, Index:15, UA-Pose: Uncertainty-Aware 6D Object Pose Estimation and Online Object Completion with Partial References, https://arxiv.org/pdf/2506.07996, 2025-06-09
2025-11-11 00:20:08,115 - INFO - root - Page:2, Index:16, Speedy Deformable 3D Gaussian Splatting: Fast Rendering and Compression of Dynamic Scenes, https://arxiv.org/pdf/2506.07917, 2025-06-09
2025-11-11 00:20:08,116 - INFO - root - Page:2, Index:17, GaussianVAE: Adaptive Learning Dynamics of 3D Gaussians for High-Fidelity Super-Resolution, https://arxiv.org/pdf/2506.07897, 2025-06-09
2025-11-11 00:20:08,117 - INFO - root - Page:2, Index:18, Spatio-Temporal State Space Model For Efficient Event-Based Optical Flow, https://arxiv.org/pdf/2506.07878, 2025-06-09
2025-11-11 00:20:08,119 - INFO - root - Page:2, Index:19, FreeGave: 3D Physics Learning from Dynamic Videos by Gaussian Velocity, https://arxiv.org/pdf/2506.07865, 2025-06-09
2025-11-11 00:20:08,119 - INFO - root - Page:2, Index:20, LogoSP: Local-global Grouping of Superpoints for Unsupervised Semantic Segmentation of 3D Point Clouds, https://arxiv.org/pdf/2506.07857, 2025-06-09
2025-11-11 00:20:08,122 - INFO - root - Page:2, Index:21, Difference Inversion: Interpolate and Isolate the Difference with Token Consistency for Image Analogy Generation, https://arxiv.org/pdf/2506.07750, 2025-06-09
2025-11-11 00:20:08,122 - INFO - root - Page:2, Index:22, Synthetic Visual Genome, https://arxiv.org/pdf/2506.07643, 2025-06-09
2025-11-11 00:20:08,129 - INFO - root - Page:2, Index:23, Fractional Collisions: A Framework for Risk Estimation of Counterfactual Conflicts using Autonomous Driving Behavior Simulations, https://arxiv.org/pdf/2506.07540, 2025-06-09
2025-11-11 00:20:08,129 - INFO - root - Page:2, Index:24, Multi-Step Guided Diffusion for Image Restoration on Edge Devices: Toward Lightweight Perception in Embodied AI, https://arxiv.org/pdf/2506.07286, 2025-06-08
2025-11-11 00:20:08,130 - INFO - root - Page:2, Index:25, LLM-Enhanced Rapid-Reflex Async-Reflect Embodied Agent for Real-Time Decision-Making in Dynamically Changing Environments, https://arxiv.org/pdf/2506.07223, 2025-06-08
2025-11-11 00:20:08,130 - INFO - root - Page:2, Index:26, UCOD-DPL: Unsupervised Camouflaged Object Detection via Dynamic Pseudo-label Learning, https://arxiv.org/pdf/2506.07087, 2025-06-08
2025-11-11 00:20:08,130 - INFO - root - Page:2, Index:27, BePo: Leveraging Birds Eye View and Sparse Points for Efficient and Accurate 3D Occupancy Prediction, https://arxiv.org/pdf/2506.07002, 2025-06-08
2025-11-11 00:20:08,130 - INFO - root - Page:2, Index:28, Reading in the Dark with Foveated Event Vision, https://arxiv.org/pdf/2506.06918, 2025-06-07
2025-11-11 00:20:08,131 - INFO - root - Page:2, Index:29, NSD-Imagery: A benchmark dataset for extending fMRI vision decoding methods to mental imagery, https://arxiv.org/pdf/2506.06898, 2025-06-07
2025-11-11 00:20:08,131 - INFO - root - Page:2, Index:30, Continuous-Time SO(3) Forecasting with Savitzky--Golay Neural Controlled Differential Equations, https://arxiv.org/pdf/2506.06780, 2025-06-07
2025-11-11 00:20:08,131 - INFO - root - Page:2, Index:31, Generalized Trajectory Scoring for End-to-end Multimodal Planning, https://arxiv.org/pdf/2506.06664, 2025-06-07
2025-11-11 00:20:08,132 - INFO - root - Page:2, Index:32, EV-LayerSegNet: Self-supervised Motion Segmentation using Event Cameras, https://arxiv.org/pdf/2506.06596, 2025-06-06
2025-11-11 00:20:08,132 - INFO - root - Page:2, Index:33, Vid2Sim: Generalizable, Video-based Reconstruction of Appearance, Geometry and Physics for Mesh-free Simulation, https://arxiv.org/pdf/2506.06440, 2025-06-06
2025-11-11 00:20:08,133 - INFO - root - Page:2, Index:34, FADE: Frequency-Aware Diffusion Model Factorization for Video Editing, https://arxiv.org/pdf/2506.05934, 2025-06-06
2025-11-11 00:20:08,133 - INFO - root - Page:2, Index:35, Unleashing the Potential of Consistency Learning for Detecting and Grounding Multi-Modal Media Manipulation, https://arxiv.org/pdf/2506.05890, 2025-06-06
2025-11-11 00:20:08,134 - INFO - root - Page:2, Index:36, DeformCL: Learning Deformable Centerline Representation for Vessel Extraction in 3D Medical Image, https://arxiv.org/pdf/2506.05820, 2025-06-06
2025-11-11 00:20:08,138 - INFO - root - Page:2, Index:37, NTIRE 2025 Challenge on HR Depth from Images of Specular and Transparent Surfaces, https://arxiv.org/pdf/2506.05815, 2025-06-06
2025-11-11 00:20:08,143 - INFO - root - Page:2, Index:38, GazeNLQ @ Ego4D Natural Language Queries Challenge 2025, https://arxiv.org/pdf/2506.05782, 2025-06-06
2025-11-11 00:20:08,146 - INFO - root - Page:2, Index:39, Robust sensor fusion against on-vehicle sensor staleness, https://arxiv.org/pdf/2506.05780, 2025-06-06
2025-11-11 00:20:08,146 - INFO - root - Page:2, Index:40, Where Is The Ball: 3D Ball Trajectory Estimation From 2D Monocular Tracking, https://arxiv.org/pdf/2506.05763, 2025-06-06
2025-11-11 00:20:08,147 - INFO - root - Page:2, Index:41, VoxelSplat: Dynamic Gaussian Splatting as an Effective Loss for Occupancy and Flow Prediction, https://arxiv.org/pdf/2506.05563, 2025-06-05
2025-11-11 00:20:08,147 - INFO - root - Page:2, Index:42, Gen4D: Synthesizing Humans and Scenes in the Wild, https://arxiv.org/pdf/2506.05397, 2025-06-03
2025-11-11 00:20:08,149 - INFO - root - Page:2, Index:43, Attacking Attention of Foundation Models Disrupts Downstream Tasks, https://arxiv.org/pdf/2506.05394, 2025-09-12
2025-11-11 00:20:08,149 - INFO - root - Page:2, Index:44, FreeTimeGS: Free Gaussian Primitives at Anytime and Anywhere for Dynamic Scene Reconstruction, https://arxiv.org/pdf/2506.05348, 2025-06-06
2025-11-11 00:20:08,149 - INFO - root - Page:2, Index:45, LotusFilter: Fast Diverse Nearest Neighbor Search via a Learned Cutoff Table, https://arxiv.org/pdf/2506.04790, 2025-06-05
2025-11-11 00:20:08,151 - INFO - root - Page:2, Index:46, Towards Holistic Visual Quality Assessment of AI-Generated Videos: A LLM-Based Multi-Dimensional Evaluation Model, https://arxiv.org/pdf/2506.04715, 2025-06-11
2025-11-11 00:20:08,151 - INFO - root - Page:2, Index:47, Gradient Inversion Attacks on Parameter-Efficient Fine-Tuning, https://arxiv.org/pdf/2506.04453, 2025-06-04
2025-11-11 00:20:08,152 - INFO - root - Page:2, Index:48, HMAR: Efficient Hierarchical Masked Auto-Regressive Image Generation, https://arxiv.org/pdf/2506.04421, 2025-06-04
2025-11-11 00:20:08,152 - INFO - root - Page:2, Index:49, Visualizing and Controlling Cortical Responses Using Voxel-Weighted Activation Maximization, https://arxiv.org/pdf/2506.04379, 2025-06-04
2025-11-11 00:20:08,152 - INFO - root - Fetching page 4 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=150
2025-11-11 00:20:14,479 - INFO - root - get_all_titles_from_web 
2025-11-11 00:20:14,479 - INFO - root - Page:3, Index:0, FlexGS: Train Once, Deploy Everywhere with Many-in-One Flexible 3D Gaussian Splatting, https://arxiv.org/pdf/2506.04174, 2025-06-04
2025-11-11 00:20:14,479 - INFO - root - Page:3, Index:1, Multi-view Surface Reconstruction Using Normal and Reflectance Cues, https://arxiv.org/pdf/2506.04115, 2025-06-04
2025-11-11 00:20:14,481 - INFO - root - Page:3, Index:2, Vocabulary-free few-shot learning for Vision-Language Models, https://arxiv.org/pdf/2506.04005, 2025-06-04
2025-11-11 00:20:14,482 - INFO - root - Page:3, Index:3, Learning from Noise: Enhancing DNNs for Event-Based Vision through Controlled Noise Injection, https://arxiv.org/pdf/2506.03918, 2025-06-04
2025-11-11 00:20:14,482 - INFO - root - Page:3, Index:4, Video, How Do Your Tokens Merge?, https://arxiv.org/pdf/2506.03885, 2025-06-04
2025-11-11 00:20:14,483 - INFO - root - Page:3, Index:5, OSGNet @ Ego4D Episodic Memory Challenge 2025, https://arxiv.org/pdf/2506.03710, 2025-06-04
2025-11-11 00:20:14,483 - INFO - root - Page:3, Index:6, AetherVision-Bench: An Open-Vocabulary RGB-Infrared Benchmark for Multi-Angle Segmentation across Aerial and Ground Perspectives, https://arxiv.org/pdf/2506.03709, 2025-06-04
2025-11-11 00:20:14,483 - INFO - root - Page:3, Index:7, OV-COAST: Cost Aggregation with Optimal Transport for Open-Vocabulary Semantic Segmentation, https://arxiv.org/pdf/2506.03706, 2025-06-04
2025-11-11 00:20:14,484 - INFO - root - Page:3, Index:8, Generating 6DoF Object Manipulation Trajectories from Action Description in Egocentric Vision, https://arxiv.org/pdf/2506.03605, 2025-06-04
2025-11-11 00:20:14,484 - INFO - root - Page:3, Index:9, SemNav: A Model-Based Planner for Zero-Shot Object Goal Navigation Using Vision-Foundation Models, https://arxiv.org/pdf/2506.03516, 2025-06-03
2025-11-11 00:20:14,484 - INFO - root - Page:3, Index:10, Heterogeneous Skeleton-Based Action Representation Learning, https://arxiv.org/pdf/2506.03481, 2025-06-03
2025-11-11 00:20:14,484 - INFO - root - Page:3, Index:11, Hybrid Ensemble of Segmentation-Assisted Classification and GBDT for Skin Cancer Detection with Engineered Metadata and Synthetic Lesions from ISIC 2024 Non-Dermoscopic 3D-TBP Images, https://arxiv.org/pdf/2506.03420, 2025-06-03
2025-11-11 00:20:14,484 - INFO - root - Page:3, Index:12, Self-Supervised Spatial Correspondence Across Modalities, https://arxiv.org/pdf/2506.03148, 2025-06-03
2025-11-11 00:20:14,485 - INFO - root - Page:3, Index:13, Dense Match Summarization for Faster Two-view Estimation, https://arxiv.org/pdf/2506.02893, 2025-06-03
2025-11-11 00:20:14,485 - INFO - root - Page:3, Index:14, NTIRE 2025 XGC Quality Assessment Challenge: Methods and Results, https://arxiv.org/pdf/2506.02875, 2025-06-03
2025-11-11 00:20:14,485 - INFO - root - Page:3, Index:15, FreeScene: Mixed Graph Diffusion for 3D Scene Synthesis from Free Prompts, https://arxiv.org/pdf/2506.02781, 2025-06-03
2025-11-11 00:20:14,486 - INFO - root - Page:3, Index:16, Technical Report for Ego4D Long-Term Action Anticipation Challenge 2025, https://arxiv.org/pdf/2506.02550, 2025-06-11
2025-11-11 00:20:14,486 - INFO - root - Page:3, Index:17, Probabilistic Online Event Downsampling, https://arxiv.org/pdf/2506.02547, 2025-09-23
2025-11-11 00:20:14,486 - INFO - root - Page:3, Index:18, Towards In-the-wild 3D Plane Reconstruction from a Single Image, https://arxiv.org/pdf/2506.02493, 2025-06-03
2025-11-11 00:20:14,487 - INFO - root - Page:3, Index:19, Efficient Test-time Adaptive Object Detection via Sensitivity-Guided Pruning, https://arxiv.org/pdf/2506.02462, 2025-06-03
2025-11-11 00:20:14,487 - INFO - root - Page:3, Index:20, EgoVIS@CVPR: PAIR-Net: Enhancing Egocentric Speaker Detection via Pretrained Audio-Visual Fusion and Alignment Loss, https://arxiv.org/pdf/2506.02247, 2025-09-26
2025-11-11 00:20:14,488 - INFO - root - Page:3, Index:21, Diff2Flow: Training Flow Matching Models via Diffusion Model Alignment, https://arxiv.org/pdf/2506.02221, 2025-06-02
2025-11-11 00:20:14,488 - INFO - root - Page:3, Index:22, NTIRE 2025 Challenge on RAW Image Restoration and Super-Resolution, https://arxiv.org/pdf/2506.02197, 2025-06-04
2025-11-11 00:20:14,494 - INFO - root - Page:3, Index:23, RAW Image Reconstruction from RGB on Smartphones. NTIRE 2025 Challenge Report, https://arxiv.org/pdf/2506.01947, 2025-06-02
2025-11-11 00:20:14,499 - INFO - root - Page:3, Index:24, Silence is Golden: Leveraging Adversarial Examples to Nullify Audio Control in LDM-based Talking-Head Generation, https://arxiv.org/pdf/2506.01591, 2025-06-02
2025-11-11 00:20:14,502 - INFO - root - Page:3, Index:25, SAM2-LOVE: Segment Anything Model 2 in Language-aided Audio-Visual Scenes, https://arxiv.org/pdf/2506.01558, 2025-06-02
2025-11-11 00:20:14,502 - INFO - root - Page:3, Index:26, Neural shape reconstruction from multiple views with static pattern projection, https://arxiv.org/pdf/2506.01389, 2025-06-02
2025-11-11 00:20:14,504 - INFO - root - Page:3, Index:27, SAM-I2V: Upgrading SAM to Support Promptable Video Segmentation with Less than 0.2% Training Cost, https://arxiv.org/pdf/2506.01304, 2025-06-02
2025-11-11 00:20:14,504 - INFO - root - Page:3, Index:28, Perceptual Inductive Bias Is What You Need Before Contrastive Learning, https://arxiv.org/pdf/2506.01201, 2025-06-01
2025-11-11 00:20:14,505 - INFO - root - Page:3, Index:29, Test Automation for Interactive Scenarios via Promptable Traffic Simulation, https://arxiv.org/pdf/2506.01199, 2025-06-04
2025-11-11 00:20:14,505 - INFO - root - Page:3, Index:30, GraphPad: Inference-Time 3D Scene Graph Updates for Embodied Question Answering, https://arxiv.org/pdf/2506.01174, 2025-06-01
2025-11-11 00:20:14,505 - INFO - root - Page:3, Index:31, Aligned Contrastive Loss for Long-Tailed Recognition, https://arxiv.org/pdf/2506.01071, 2025-06-01
2025-11-11 00:20:14,506 - INFO - root - Page:3, Index:32, Self-supervised ControlNet with Spatio-Temporal Mamba for Real-world Video Super-resolution, https://arxiv.org/pdf/2506.01037, 2025-06-01
2025-11-11 00:20:14,507 - INFO - root - Page:3, Index:33, ArtiScene: Language-Driven Artistic 3D Scene Generation Through Image Intermediary, https://arxiv.org/pdf/2506.00742, 2025-05-31
2025-11-11 00:20:14,507 - INFO - root - Page:3, Index:34, 3D Gaussian Splat Vulnerabilities, https://arxiv.org/pdf/2506.00280, 2025-05-30
2025-11-11 00:20:14,507 - INFO - root - Page:3, Index:35, EgoVIS@CVPR: What Changed and What Could Have Changed? State-Change Counterfactuals for Procedure-Aware Video Representation Learning, https://arxiv.org/pdf/2506.00101, 2025-09-26
2025-11-11 00:20:14,511 - INFO - root - Page:3, Index:36, CL-LoRA: Continual Low-Rank Adaptation for Rehearsal-Free Class-Incremental Learning, https://arxiv.org/pdf/2505.24816, 2025-05-30
2025-11-11 00:20:14,512 - INFO - root - Page:3, Index:37, PatchDEMUX: A Certifiably Robust Framework for Multi-label Classifiers Against Adversarial Patches, https://arxiv.org/pdf/2505.24703, 2025-05-30
2025-11-11 00:20:14,512 - INFO - root - Page:3, Index:38, Conformal Prediction for Zero-Shot Models, https://arxiv.org/pdf/2505.24693, 2025-05-30
2025-11-11 00:20:14,519 - INFO - root - Page:3, Index:39, Learning reusable concepts across different egocentric video understanding tasks, https://arxiv.org/pdf/2505.24690, 2025-05-30
2025-11-11 00:20:14,520 - INFO - root - Page:3, Index:40, Period-LLM: Extending the Periodic Capability of Multimodal Large Language Model, https://arxiv.org/pdf/2505.24476, 2025-05-30
2025-11-11 00:20:14,522 - INFO - root - Page:3, Index:41, PCIE_Interaction Solution for Ego4D Social Interaction Challenge, https://arxiv.org/pdf/2505.24404, 2025-05-30
2025-11-11 00:20:14,522 - INFO - root - Page:3, Index:42, Leadership Assessment in Pediatric Intensive Care Unit Team Training, https://arxiv.org/pdf/2505.24389, 2025-08-28
2025-11-11 00:20:14,523 - INFO - root - Page:3, Index:43, Interpreting Large Text-to-Image Diffusion Models with Dictionary Learning, https://arxiv.org/pdf/2505.24360, 2025-07-10
2025-11-11 00:20:14,523 - INFO - root - Page:3, Index:44, InteractAnything: Zero-shot Human Object Interaction Synthesis via LLM Feedback and Object Affordance Parsing, https://arxiv.org/pdf/2505.24315, 2025-05-30
2025-11-11 00:20:14,524 - INFO - root - Page:3, Index:45, MaskAdapt: Unsupervised Geometry-Aware Domain Adaptation Using Multimodal Contextual Learning and RGB-Depth Masking, https://arxiv.org/pdf/2505.24026, 2025-05-29
2025-11-11 00:20:14,524 - INFO - root - Page:3, Index:46, Argus: Vision-Centric Reasoning with Grounded Chain-of-Thought, https://arxiv.org/pdf/2505.23766, 2025-05-29
2025-11-11 00:20:14,527 - INFO - root - Page:3, Index:47, Sketch Down the FLOPs: Towards Efficient Networks for Human Sketch, https://arxiv.org/pdf/2505.23763, 2025-05-29
2025-11-11 00:20:14,527 - INFO - root - Page:3, Index:48, Boosting Domain Incremental Learning: Selecting the Optimal Parameters is All You Need, https://arxiv.org/pdf/2505.23744, 2025-05-29
2025-11-11 00:20:14,527 - INFO - root - Page:3, Index:49, DA-VPT: Semantic-Guided Visual Prompt Tuning for Vision Transformers, https://arxiv.org/pdf/2505.23694, 2025-06-01
2025-11-11 00:20:14,527 - INFO - root - Fetching page 5 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=200
2025-11-11 00:20:21,165 - INFO - root - get_all_titles_from_web 
2025-11-11 00:20:21,166 - INFO - root - Page:4, Index:0, Bridging Classical and Modern Computer Vision: PerceptiveNet for Tree Crown Semantic Segmentation, https://arxiv.org/pdf/2505.23597, 2025-05-29
2025-11-11 00:20:21,166 - INFO - root - Page:4, Index:1, Synthetic Generation and Latent Projection Denoising of Rim Lesions in Multiple Sclerosis, https://arxiv.org/pdf/2505.23353, 2025-05-29
2025-11-11 00:20:21,166 - INFO - root - Page:4, Index:2, Wav2Sem: Plug-and-Play Audio Semantic Decoupling for 3D Speech-Driven Facial Animation, https://arxiv.org/pdf/2505.23290, 2025-05-29
2025-11-11 00:20:21,167 - INFO - root - Page:4, Index:3, Proximal Algorithm Unrolling: Flexible and Efficient Reconstruction Networks for Single-Pixel Imaging, https://arxiv.org/pdf/2505.23180, 2025-05-29
2025-11-11 00:20:21,167 - INFO - root - Page:4, Index:4, HMAD: Advancing E2E Driving with Anchored Offset Proposals and Simulation-Supervised Multi-target Scoring, https://arxiv.org/pdf/2505.23129, 2025-05-29
2025-11-11 00:20:21,167 - INFO - root - Page:4, Index:5, URWKV: Unified RWKV Model with Multi-state Perspective for Low-light Image Restoration, https://arxiv.org/pdf/2505.23068, 2025-05-29
2025-11-11 00:20:21,168 - INFO - root - Page:4, Index:6, 4DTAM: Non-Rigid Tracking and Mapping via Dynamic Surface Gaussians, https://arxiv.org/pdf/2505.22859, 2025-05-28
2025-11-11 00:20:21,168 - INFO - root - Page:4, Index:7, A Probabilistic Jump-Diffusion Framework for Open-World Egocentric Activity Recognition, https://arxiv.org/pdf/2505.22858, 2025-05-28
2025-11-11 00:20:21,168 - INFO - root - Page:4, Index:8, PS4PRO: Pixel-to-pixel Supervision for Photorealistic Rendering and Optimization, https://arxiv.org/pdf/2505.22616, 2025-05-28
2025-11-11 00:20:21,169 - INFO - root - Page:4, Index:9, Universal Domain Adaptation for Semantic Segmentation, https://arxiv.org/pdf/2505.22458, 2025-06-05
2025-11-11 00:20:21,169 - INFO - root - Page:4, Index:10, Zero-Shot 3D Visual Grounding from Vision-Language Models, https://arxiv.org/pdf/2505.22429, 2025-05-28
2025-11-11 00:20:21,170 - INFO - root - Page:4, Index:11, RC-AutoCalib: An End-to-End Radar-Camera Automatic Calibration Network, https://arxiv.org/pdf/2505.22427, 2025-05-28
2025-11-11 00:20:21,170 - INFO - root - Page:4, Index:12, Bringing CLIP to the Clinic: Dynamic Soft Labels and Negation-Aware Learning for Medical Analysis, https://arxiv.org/pdf/2505.22079, 2025-05-28
2025-11-11 00:20:21,170 - INFO - root - Page:4, Index:13, Point-to-Region Loss for Semi-Supervised Point-Based Crowd Counting, https://arxiv.org/pdf/2505.21943, 2025-05-27
2025-11-11 00:20:21,172 - INFO - root - Page:4, Index:14, FRAMES-VQA: Benchmarking Fine-Tuning Robustness across Multi-Modal Shifts in Visual Question Answering, https://arxiv.org/pdf/2505.21755, 2025-06-20
2025-11-11 00:20:21,173 - INFO - root - Page:4, Index:15, Knowledge Distillation Approach for SOS Fusion Staging: Towards Fully Automated Skeletal Maturity Assessment, https://arxiv.org/pdf/2505.21561, 2025-05-26
2025-11-11 00:20:21,173 - INFO - root - Page:4, Index:16, Enhancing Vision Transformer Explainability Using Artificial Astrocytes, https://arxiv.org/pdf/2505.21513, 2025-05-20
2025-11-11 00:20:21,173 - INFO - root - Page:4, Index:17, Empowering Vector Graphics with Consistently Arbitrary Viewing and View-dependent Visibility, https://arxiv.org/pdf/2505.21377, 2025-05-27
2025-11-11 00:20:21,174 - INFO - root - Page:4, Index:18, Structure from Collision, https://arxiv.org/pdf/2505.21335, 2025-05-27
2025-11-11 00:20:21,176 - INFO - root - Page:4, Index:19, Boosting Adversarial Transferability via High-Frequency Augmentation and Hierarchical-Gradient Fusion, https://arxiv.org/pdf/2505.21181, 2025-05-27
2025-11-11 00:20:21,178 - INFO - root - Page:4, Index:20, RefAV: Towards Planning-Centric Scenario Mining, https://arxiv.org/pdf/2505.20981, 2025-06-18
2025-11-11 00:20:21,178 - INFO - root - Page:4, Index:21, PMA: Towards Parameter-Efficient Point Cloud Understanding via Point Mamba Adapter, https://arxiv.org/pdf/2505.20941, 2025-05-27
2025-11-11 00:20:21,180 - INFO - root - Page:4, Index:22, HuMoCon: Concept Discovery for Human Motion Understanding, https://arxiv.org/pdf/2505.20920, 2025-05-27
2025-11-11 00:20:21,181 - INFO - root - Page:4, Index:23, Exploring Timeline Control for Facial Motion Generation, https://arxiv.org/pdf/2505.20861, 2025-05-27
2025-11-11 00:20:21,181 - INFO - root - Page:4, Index:24, ConText-CIR: Learning from Concepts in Text for Composed Image Retrieval, https://arxiv.org/pdf/2505.20764, 2025-05-27
2025-11-11 00:20:21,181 - INFO - root - Page:4, Index:25, HCQA-1.5 @ Ego4D EgoSchema Challenge 2025, https://arxiv.org/pdf/2505.20644, 2025-05-26
2025-11-11 00:20:21,183 - INFO - root - Page:4, Index:26, Roboflow100-VL: A Multi-Domain Object Detection Benchmark for Vision-Language Models, https://arxiv.org/pdf/2505.20612, 2025-10-22
2025-11-11 00:20:21,184 - INFO - root - Page:4, Index:27, MotionPro: A Precise Motion Controller for Image-to-Video Generation, https://arxiv.org/pdf/2505.20287, 2025-05-26
2025-11-11 00:20:21,185 - INFO - root - Page:4, Index:28, Category-Agnostic Neural Object Rigging, https://arxiv.org/pdf/2505.20283, 2025-05-26
2025-11-11 00:20:21,187 - INFO - root - Page:4, Index:29, Towards Video to Piano Music Generation with Chain-of-Perform Support Benchmarks, https://arxiv.org/pdf/2505.20038, 2025-05-26
2025-11-11 00:20:21,191 - INFO - root - Page:4, Index:30, Can Visual Encoder Learn to See Arrows?, https://arxiv.org/pdf/2505.19944, 2025-05-26
2025-11-11 00:20:21,191 - INFO - root - Page:4, Index:31, GoLF-NRT: Integrating Global Context and Local Geometry for Few-Shot View Synthesis, https://arxiv.org/pdf/2505.19813, 2025-05-26
2025-11-11 00:20:21,192 - INFO - root - Page:4, Index:32, Depth-Guided Bundle Sampling for Efficient Generalizable Neural Radiance Field Reconstruction, https://arxiv.org/pdf/2505.19793, 2025-05-26
2025-11-11 00:20:21,192 - INFO - root - Page:4, Index:33, SuperAD: A Training-free Anomaly Classification and Segmentation Method for CVPR 2025 VAND 3.0 Workshop Challenge Track 1: Adapt & Detect, https://arxiv.org/pdf/2505.19750, 2025-05-27
2025-11-11 00:20:21,194 - INFO - root - Page:4, Index:34, Knowledge-Aligned Counterfactual-Enhancement Diffusion Perception for Unsupervised Cross-Domain Visual Emotion Recognition, https://arxiv.org/pdf/2505.19694, 2025-05-26
2025-11-11 00:20:21,195 - INFO - root - Page:4, Index:35, Rotation-Equivariant Self-Supervised Method in Image Denoising, https://arxiv.org/pdf/2505.19618, 2025-05-26
2025-11-11 00:20:21,195 - INFO - root - Page:4, Index:36, NTIRE 2025 Challenge on Video Quality Enhancement for Video Conferencing: Datasets, Methods and Results, https://arxiv.org/pdf/2505.18988, 2025-05-25
2025-11-11 00:20:21,195 - INFO - root - Page:4, Index:37, Geometry-guided Online 3D Video Synthesis with Multi-View Temporal Consistency, https://arxiv.org/pdf/2505.18932, 2025-05-24
2025-11-11 00:20:21,196 - INFO - root - Page:4, Index:38, Digital Overconsumption and Waste: A Closer Look at the Impacts of Generative AI, https://arxiv.org/pdf/2505.18894, 2025-05-24
2025-11-11 00:20:21,196 - INFO - root - Page:4, Index:39, VISTA: Vision-Language Inference for Training-Free Stock Time-Series Analysis, https://arxiv.org/pdf/2505.18570, 2025-06-11
2025-11-11 00:20:21,197 - INFO - root - Page:4, Index:40, Syn3DTxt: Embedding 3D Cues for Scene Text Generation, https://arxiv.org/pdf/2505.18479, 2025-05-23
2025-11-11 00:20:21,198 - INFO - root - Page:4, Index:41, CTRL-GS: Cascaded Temporal Residue Learning for 4D Gaussian Splatting, https://arxiv.org/pdf/2505.18306, 2025-05-31
2025-11-11 00:20:21,198 - INFO - root - Page:4, Index:42, DualTalk: Dual-Speaker Interaction for 3D Talking Head Conversations, https://arxiv.org/pdf/2505.18096, 2025-05-26
2025-11-11 00:20:21,201 - INFO - root - Page:4, Index:43, SeaLion: Semantic Part-Aware Latent Point Diffusion Models for 3D Generation, https://arxiv.org/pdf/2505.17721, 2025-07-07
2025-11-11 00:20:21,201 - INFO - root - Page:4, Index:44, PoseBH: Prototypical Multi-Dataset Training Beyond Human Pose Estimation, https://arxiv.org/pdf/2505.17475, 2025-05-23
2025-11-11 00:20:21,202 - INFO - root - Page:4, Index:45, Pursuing Temporal-Consistent Video Virtual Try-On via Dynamic Pose Interaction, https://arxiv.org/pdf/2505.16980, 2025-05-22
2025-11-11 00:20:21,207 - INFO - root - Page:4, Index:46, UniPhy: Learning a Unified Constitutive Model for Inverse Physics Simulation, https://arxiv.org/pdf/2505.16971, 2025-05-22
2025-11-11 00:20:21,207 - INFO - root - Page:4, Index:47, Tracking the Flight: Exploring a Computational Framework for Analyzing Escape Responses in Plains Zebra (Equus quagga), https://arxiv.org/pdf/2505.16882, 2025-05-23
2025-11-11 00:20:21,210 - INFO - root - Page:4, Index:48, Semi-Supervised State-Space Model with Dynamic Stacking Filter for Real-World Video Deraining, https://arxiv.org/pdf/2505.16811, 2025-05-22
2025-11-11 00:20:21,210 - INFO - root - Page:4, Index:49, SOLVE: Synergy of Language-Vision and End-to-End Networks for Autonomous Driving, https://arxiv.org/pdf/2505.16805, 2025-05-22
2025-11-11 00:20:21,210 - INFO - root - Fetching page 6 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=250
2025-11-11 00:20:27,839 - INFO - root - get_all_titles_from_web 
2025-11-11 00:20:27,839 - INFO - root - Page:5, Index:0, Four Eyes Are Better Than Two: Harnessing the Collaborative Potential of Large Models via Differentiated Thinking and Complementary Ensembles, https://arxiv.org/pdf/2505.16784, 2025-06-07
2025-11-11 00:20:27,840 - INFO - root - Page:5, Index:1, Single Domain Generalization for Few-Shot Counting via Universal Representation Matching, https://arxiv.org/pdf/2505.16778, 2025-05-22
2025-11-11 00:20:27,840 - INFO - root - Page:5, Index:2, Seeing Far and Clearly: Mitigating Hallucinations in MLLMs with Attention Causal Decoding, https://arxiv.org/pdf/2505.16652, 2025-06-07
2025-11-11 00:20:27,840 - INFO - root - Page:5, Index:3, Sketchy Bounding-box Supervision for 3D Instance Segmentation, https://arxiv.org/pdf/2505.16399, 2025-05-22
2025-11-11 00:20:27,841 - INFO - root - Page:5, Index:4, DeCafNet: Delegate and Conquer for Efficient Temporal Grounding in Long Videos, https://arxiv.org/pdf/2505.16376, 2025-05-22
2025-11-11 00:20:27,841 - INFO - root - Page:5, Index:5, NTIRE 2025 challenge on Text to Image Generation Model Quality Assessment, https://arxiv.org/pdf/2505.16314, 2025-05-22
2025-11-11 00:20:27,841 - INFO - root - Page:5, Index:6, Analyzing Hierarchical Structure in Vision Models with Sparse Autoencoders, https://arxiv.org/pdf/2505.15970, 2025-05-21
2025-11-11 00:20:27,841 - INFO - root - Page:5, Index:7, Efficient Data Driven Mixture-of-Expert Extraction from Trained Networks, https://arxiv.org/pdf/2505.15414, 2025-05-21
2025-11-11 00:20:27,842 - INFO - root - Page:5, Index:8, Mouse Lockbox Dataset: Behavior Recognition for Mice Solving Lockboxes, https://arxiv.org/pdf/2505.15408, 2025-06-17
2025-11-11 00:20:27,842 - INFO - root - Page:5, Index:9, Zero-Shot Gaze-based Volumetric Medical Image Segmentation, https://arxiv.org/pdf/2505.15256, 2025-06-10
2025-11-11 00:20:27,842 - INFO - root - Page:5, Index:10, Dual Precision Quantization for Efficient and Accurate Deep Neural Networks Inference, https://arxiv.org/pdf/2505.14638, 2025-05-20
2025-11-11 00:20:27,842 - INFO - root - Page:5, Index:11, Neural Video Compression with Context Modulation, https://arxiv.org/pdf/2505.14541, 2025-05-20
2025-11-11 00:20:27,843 - INFO - root - Page:5, Index:12, Selective Structured State Space for Multispectral-fused Small Target Detection, https://arxiv.org/pdf/2505.14043, 2025-05-23
2025-11-11 00:20:27,844 - INFO - root - Page:5, Index:13, OmniStyle: Filtering High Quality Style Transfer Data at Scale, https://arxiv.org/pdf/2505.14028, 2025-05-20
2025-11-11 00:20:27,845 - INFO - root - Page:5, Index:14, Domain Adaptation of VLM for Soccer Video Understanding, https://arxiv.org/pdf/2505.13860, 2025-07-07
2025-11-11 00:20:27,846 - INFO - root - Page:5, Index:15, Ground-V: Teaching VLMs to Ground Complex Instructions in Pixels, https://arxiv.org/pdf/2505.13788, 2025-05-19
2025-11-11 00:20:27,847 - INFO - root - Page:5, Index:16, FinePhys: Fine-grained Human Action Generation by Explicitly Incorporating Physical Laws for Effective Skeletal Guidance, https://arxiv.org/pdf/2505.13437, 2025-05-19
2025-11-11 00:20:27,847 - INFO - root - Page:5, Index:17, The Way Up: A Dataset for Hold Usage Detection in Sport Climbing, https://arxiv.org/pdf/2505.12854, 2025-05-19
2025-11-11 00:20:27,849 - INFO - root - Page:5, Index:18, PEER pressure: Model-to-Model Regularization for Single Source Domain Generalization, https://arxiv.org/pdf/2505.12745, 2025-05-19
2025-11-11 00:20:27,849 - INFO - root - Page:5, Index:19, Mamba-Adaptor: State Space Model Adaptor for Visual Recognition, https://arxiv.org/pdf/2505.12685, 2025-05-19
2025-11-11 00:20:27,969 - INFO - root - Page:5, Index:20, Scalable Video-to-Dataset Generation for Cross-Platform Mobile Agents, https://arxiv.org/pdf/2505.12632, 2025-05-18
2025-11-11 00:20:28,033 - INFO - root - Page:5, Index:21, Degradation-Aware Feature Perturbation for All-in-One Image Restoration, https://arxiv.org/pdf/2505.12630, 2025-05-18
2025-11-11 00:20:28,040 - INFO - root - Page:5, Index:22, Guiding Diffusion with Deep Geometric Moments: Balancing Fidelity and Variation, https://arxiv.org/pdf/2505.12486, 2025-05-18
2025-11-11 00:20:28,046 - INFO - root - Page:5, Index:23, Learning to Highlight Audio by Watching Movies, https://arxiv.org/pdf/2505.12154, 2025-05-17
2025-11-11 00:20:28,051 - INFO - root - Page:5, Index:24, Understanding the Capabilities of Molecular Graph Neural Networks in Materials Science Through Multimodal Learning and Physical Context Encoding, https://arxiv.org/pdf/2505.12137, 2025-05-17
2025-11-11 00:20:28,099 - INFO - root - Page:5, Index:25, iSegMan: Interactive Segment-and-Manipulate 3D Gaussians, https://arxiv.org/pdf/2505.11934, 2025-05-17
2025-11-11 00:20:28,102 - INFO - root - Page:5, Index:26, Self-Learning Hyperspectral and Multispectral Image Fusion via Adaptive Residual Guided Subspace Diffusion Model, https://arxiv.org/pdf/2505.11800, 2025-05-16
2025-11-11 00:20:28,102 - INFO - root - Page:5, Index:27, X-Edit: Detecting and Localizing Edits in Images Altered by Text-Guided Diffusion Models, https://arxiv.org/pdf/2505.11753, 2025-05-16
2025-11-11 00:20:28,102 - INFO - root - Page:5, Index:28, MTevent: A Multi-Task Event Camera Dataset for 6D Pose Estimation and Moving Object Detection, https://arxiv.org/pdf/2505.11282, 2025-06-02
2025-11-11 00:20:28,103 - INFO - root - Page:5, Index:29, Imputation-free and Alignment-free: Incomplete Multi-view Clustering Driven by Consensus Semantic Learning, https://arxiv.org/pdf/2505.11182, 2025-05-16
2025-11-11 00:20:28,104 - INFO - root - Page:5, Index:30, MultiLink: Multi-class Structure Recovery via Agglomerative Clustering and Model Selection, https://arxiv.org/pdf/2505.10874, 2025-05-16
2025-11-11 00:20:28,104 - INFO - root - Page:5, Index:31, RefPose: Leveraging Reference Geometric Correspondences for Accurate 6D Pose Estimation of Unseen Objects, https://arxiv.org/pdf/2505.10841, 2025-05-16
2025-11-11 00:20:28,105 - INFO - root - Page:5, Index:32, MoCLIP: Motion-Aware Fine-Tuning and Distillation of CLIP for Human Motion Generation, https://arxiv.org/pdf/2505.10810, 2025-05-15
2025-11-11 00:20:28,107 - INFO - root - Page:5, Index:33, Automated Detection of Salvin's Albatrosses: Improving Deep Learning Tools for Aerial Wildlife Surveys, https://arxiv.org/pdf/2505.10737, 2025-05-15
2025-11-11 00:20:28,107 - INFO - root - Page:5, Index:34, Advancing Multiple Instance Learning with Continual Learning for Whole Slide Imaging, https://arxiv.org/pdf/2505.10649, 2025-05-15
2025-11-11 00:20:28,107 - INFO - root - Page:5, Index:35, Inferring Driving Maps by Deep Learning-based Trail Map Extraction, https://arxiv.org/pdf/2505.10258, 2025-05-15
2025-11-11 00:20:28,108 - INFO - root - Page:5, Index:36, Behind Maya: Building a Multilingual Vision Language Model, https://arxiv.org/pdf/2505.08910, 2025-05-15
2025-11-11 00:20:28,108 - INFO - root - Page:5, Index:37, PosterO: Structuring Layout Trees to Enable Language Models in Generalized Content-Aware Layout Generation, https://arxiv.org/pdf/2505.07843, 2025-05-26
2025-11-11 00:20:28,108 - INFO - root - Page:5, Index:38, Prototype Augmented Hypernetworks for Continual Learning, https://arxiv.org/pdf/2505.07450, 2025-05-16
2025-11-11 00:20:28,112 - INFO - root - Fetching page 7 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=300
2025-11-11 00:20:35,825 - INFO - root - get_all_titles_from_web 
2025-11-11 00:20:35,825 - INFO - root - Page:6, Index:0, Convex Relaxation for Robust Vanishing Point Estimation in Manhattan World, https://arxiv.org/pdf/2505.04788, 2025-06-05
2025-11-11 00:20:35,826 - INFO - root - Page:6, Index:1, S3D: Sketch-Driven 3D Model Generation, https://arxiv.org/pdf/2505.04185, 2025-06-03
2025-11-11 00:20:35,826 - INFO - root - Page:6, Index:2, Generating Synthetic Data via Augmentations for Improved Facial Resemblance in DreamBooth and InstantID, https://arxiv.org/pdf/2505.03557, 2025-07-17
2025-11-11 00:20:35,826 - INFO - root - Page:6, Index:3, CAV-MAE Sync: Improving Contrastive Audio-Visual Mask Autoencoders via Fine-Grained Alignment, https://arxiv.org/pdf/2505.01237, 2025-05-21
2025-11-11 00:20:35,826 - INFO - root - Fetching page 8 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=350
2025-11-11 00:20:43,715 - INFO - root - get_all_titles_from_web 
2025-11-11 00:20:43,716 - INFO - root - Page:7, Index:0, Where's the liability in the Generative Era? Recovery-based Black-Box Detection of AI-Generated Content, https://arxiv.org/pdf/2505.01008, 2025-08-25
2025-11-11 00:20:43,716 - INFO - root - Page:7, Index:1, SpatialLLM: A Compound 3D-Informed Design towards Spatially-Intelligent Large Multimodal Models, https://arxiv.org/pdf/2505.00788, 2025-06-10
2025-11-11 00:20:43,716 - INFO - root - Page:7, Index:2, Prisma: An Open Source Toolkit for Mechanistic Interpretability in Vision and Video, https://arxiv.org/pdf/2504.19475, 2025-06-03
2025-11-11 00:20:43,717 - INFO - root - Page:7, Index:3, SSL4Eco: A Global Seasonal Dataset for Geospatial Foundation Models in Ecology, https://arxiv.org/pdf/2504.18256, 2025-10-20
2025-11-11 00:20:43,717 - INFO - root - Page:7, Index:4, Vision-Language Models Are Not Pragmatically Competent in Referring Expression Generation, https://arxiv.org/pdf/2504.16060, 2025-07-30
2025-11-11 00:20:43,718 - INFO - root - Fetching page 9 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=400
2025-11-11 00:20:51,605 - INFO - root - get_all_titles_from_web 
2025-11-11 00:20:51,605 - INFO - root - Page:8, Index:0, Leveraging Automatic CAD Annotations for Supervised Learning in 3D Scene Understanding, https://arxiv.org/pdf/2504.13580, 2025-05-16
2025-11-11 00:20:51,606 - INFO - root - Page:8, Index:1, CAP-Net: A Unified Network for 6D Pose and Size Estimation of Categorical Articulated Parts from a Single RGB-D Image, https://arxiv.org/pdf/2504.11230, 2025-06-02
2025-11-11 00:20:51,606 - INFO - root - Page:8, Index:2, Video Summarization with Large Language Models, https://arxiv.org/pdf/2504.11199, 2025-06-05
2025-11-11 00:20:51,606 - INFO - root - Page:8, Index:3, R-TPT: Improving Adversarial Robustness of Vision-Language Models through Test-Time Prompt Tuning, https://arxiv.org/pdf/2504.11195, 2025-08-27
2025-11-11 00:20:51,606 - INFO - root - Page:8, Index:4, TerraMesh: A Planetary Mosaic of Multimodal Earth Observation Data, https://arxiv.org/pdf/2504.11172, 2025-08-01
2025-11-11 00:20:51,607 - INFO - root - Page:8, Index:5, Seeing like a Cephalopod: Colour Vision with a Monochrome Event Camera, https://arxiv.org/pdf/2504.10984, 2025-06-06
2025-11-11 00:20:51,607 - INFO - root - Page:8, Index:6, Hearing Anywhere in Any Environment, https://arxiv.org/pdf/2504.10746, 2025-06-04
2025-11-11 00:20:51,607 - INFO - root - Fetching page 10 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=450
2025-11-11 00:20:58,171 - INFO - root - get_all_titles_from_web 
2025-11-11 00:20:58,171 - INFO - root - Page:9, Index:0, Correlative and Discriminative Label Grouping for Multi-Label Visual Prompt Tuning, https://arxiv.org/pdf/2504.09990, 2025-07-09
2025-11-11 00:20:58,172 - INFO - root - Page:9, Index:1, SPICE: A Synergistic, Precise, Iterative, and Customizable Image Editing Workflow, https://arxiv.org/pdf/2504.09697, 2025-10-16
2025-11-11 00:20:58,172 - INFO - root - Page:9, Index:2, Mimic In-Context Learning for Multimodal Tasks, https://arxiv.org/pdf/2504.08851, 2025-05-17
2025-11-11 00:20:58,172 - INFO - root - Page:9, Index:3, Digital Twin Catalog: A Large-Scale Photorealistic 3D Object Digital Twin Dataset, https://arxiv.org/pdf/2504.08541, 2025-05-18
2025-11-11 00:20:58,172 - INFO - root - Page:9, Index:4, MMLA: Multi-Environment, Multi-Species, Low-Altitude Drone Dataset, https://arxiv.org/pdf/2504.07744, 2025-10-22
2025-11-11 00:20:58,172 - INFO - root - Fetching page 11 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=500
2025-11-11 00:21:06,578 - INFO - root - get_all_titles_from_web 
2025-11-11 00:21:06,579 - INFO - root - Page:10, Index:0, PromptHMR: Promptable Human Mesh Recovery, https://arxiv.org/pdf/2504.06397, 2025-05-23
2025-11-11 00:21:06,579 - INFO - root - Page:10, Index:1, SCAM: A Real-World Typographic Robustness Evaluation for Multimodal Foundation Models, https://arxiv.org/pdf/2504.04893, 2025-09-26
2025-11-11 00:21:06,580 - INFO - root - Fetching page 12 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=550
2025-11-11 00:21:13,544 - INFO - root - get_all_titles_from_web 
2025-11-11 00:21:13,545 - INFO - root - Page:11, Index:0, Charm: The Missing Piece in ViT fine-tuning for Image Aesthetic Assessment, https://arxiv.org/pdf/2504.02522, 2025-05-15
2025-11-11 00:21:13,545 - INFO - root - Page:11, Index:1, T*: Re-thinking Temporal Search for Long-Form Video Understanding, https://arxiv.org/pdf/2504.02259, 2025-08-24
2025-11-11 00:21:13,546 - INFO - root - Page:11, Index:2, CoMatcher: Multi-View Collaborative Feature Matching, https://arxiv.org/pdf/2504.01872, 2025-08-20
2025-11-11 00:21:13,546 - INFO - root - Page:11, Index:3, Think Small, Act Big: Primitive Prompt Learning for Lifelong Robot Manipulation, https://arxiv.org/pdf/2504.00420, 2025-06-01
2025-11-11 00:21:13,547 - INFO - root - Fetching page 13 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=600
2025-11-11 00:21:20,290 - INFO - root - get_all_titles_from_web 
2025-11-11 00:21:20,291 - INFO - root - Page:12, Index:0, It's a (Blind) Match! Towards Vision-Language Correspondence without Parallel Data, https://arxiv.org/pdf/2503.24129, 2025-05-29
2025-11-11 00:21:20,292 - INFO - root - Page:12, Index:1, ReferDINO-Plus: 2nd Solution for 4th PVUW MeViS Challenge at CVPR 2025, https://arxiv.org/pdf/2503.23509, 2025-05-29
2025-11-11 00:21:20,292 - INFO - root - Page:12, Index:2, A Unified Image-Dense Annotation Generation Model for Underwater Scenes, https://arxiv.org/pdf/2503.21771, 2025-07-27
2025-11-11 00:21:20,292 - INFO - root - Fetching page 14 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=650
2025-11-11 00:21:28,461 - INFO - root - get_all_titles_from_web 
2025-11-11 00:21:28,462 - INFO - root - Page:13, Index:0, Learning Class Prototypes for Unified Sparse Supervised 3D Object Detection, https://arxiv.org/pdf/2503.21099, 2025-06-13
2025-11-11 00:21:28,462 - INFO - root - Page:13, Index:1, LATTE-MV: Learning to Anticipate Table Tennis Hits from Monocular Videos, https://arxiv.org/pdf/2503.20936, 2025-09-01
2025-11-11 00:21:28,462 - INFO - root - Page:13, Index:2, BizGen: Advancing Article-level Visual Text Rendering for Infographics Generation, https://arxiv.org/pdf/2503.20672, 2025-07-02
2025-11-11 00:21:28,463 - INFO - root - Page:13, Index:3, ITA-MDT: Image-Timestep-Adaptive Masked Diffusion Transformer Framework for Image-Based Virtual Try-On, https://arxiv.org/pdf/2503.20418, 2025-06-01
2025-11-11 00:21:28,464 - INFO - root - Page:13, Index:4, Faster Parameter-Efficient Tuning with Token Redundancy Reduction, https://arxiv.org/pdf/2503.20282, 2025-08-26
2025-11-11 00:21:28,464 - INFO - root - Page:13, Index:5, DINeMo: Learning Neural Mesh Models with no 3D Annotations, https://arxiv.org/pdf/2503.20220, 2025-06-09
2025-11-11 00:21:28,465 - INFO - root - Page:13, Index:6, Scaling Vision Pre-Training to 4K Resolution, https://arxiv.org/pdf/2503.19903, 2025-08-03
2025-11-11 00:21:28,465 - INFO - root - Page:13, Index:7, GENIUS: A Generative Framework for Universal Multimodal Search, https://arxiv.org/pdf/2503.19868, 2025-06-05
2025-11-11 00:21:28,466 - INFO - root - Fetching page 15 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=700
2025-11-11 00:21:35,978 - INFO - root - get_all_titles_from_web 
2025-11-11 00:21:35,979 - INFO - root - Page:14, Index:0, Galaxy Walker: Geometry-aware VLMs For Galaxy-scale Understanding, https://arxiv.org/pdf/2503.18578, 2025-05-25
2025-11-11 00:21:35,980 - INFO - root - Page:14, Index:1, LookCloser: Frequency-aware Radiance Field for Tiny-Detail Scene, https://arxiv.org/pdf/2503.18513, 2025-07-29
2025-11-11 00:21:35,980 - INFO - root - Fetching page 16 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=750
2025-11-11 00:21:43,144 - INFO - root - get_all_titles_from_web 
2025-11-11 00:21:43,144 - INFO - root - Page:15, Index:0, LoTUS: Large-Scale Machine Unlearning with a Taste of Uncertainty, https://arxiv.org/pdf/2503.18314, 2025-05-29
2025-11-11 00:21:43,144 - INFO - root - Page:15, Index:1, MammAlps: A multi-view video behavior monitoring dataset of wild mammals in the Swiss Alps, https://arxiv.org/pdf/2503.18223, 2025-06-04
2025-11-11 00:21:43,145 - INFO - root - Page:15, Index:2, Progressive Prompt Detailing for Improved Alignment in Text-to-Image Generative Models, https://arxiv.org/pdf/2503.17794, 2025-05-30
2025-11-11 00:21:43,145 - INFO - root - Page:15, Index:3, CountLLM: Towards Generalizable Repetitive Action Counting via Large Language Model, https://arxiv.org/pdf/2503.17690, 2025-06-29
2025-11-11 00:21:43,145 - INFO - root - Page:15, Index:4, TaoAvatar: Real-Time Lifelike Full-Body Talking Avatars for Augmented Reality via 3D Gaussian Splatting, https://arxiv.org/pdf/2503.17032, 2025-07-23
2025-11-11 00:21:43,146 - INFO - root - Page:15, Index:5, Generalized Few-shot 3D Point Cloud Segmentation with Vision-Language Model, https://arxiv.org/pdf/2503.16282, 2025-05-20
2025-11-11 00:21:43,146 - INFO - root - Fetching page 17 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=800
2025-11-11 00:21:49,448 - INFO - root - get_all_titles_from_web 
2025-11-11 00:21:49,449 - INFO - root - Page:16, Index:0, High Temporal Consistency through Semantic Similarity Propagation in Semi-Supervised Video Semantic Segmentation for Autonomous Flight, https://arxiv.org/pdf/2503.15676, 2025-06-26
2025-11-11 00:21:49,449 - INFO - root - Page:16, Index:1, DPFlow: Adaptive Optical Flow Estimation with a Dual-Pyramid Framework, https://arxiv.org/pdf/2503.14880, 2025-09-29
2025-11-11 00:21:49,449 - INFO - root - Fetching page 18 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=850
2025-11-11 00:21:56,341 - INFO - root - get_all_titles_from_web 
2025-11-11 00:21:56,342 - INFO - root - Page:17, Index:0, From Head to Tail: Towards Balanced Representation in Large Vision-Language Models through Adaptive Data Calibration, https://arxiv.org/pdf/2503.12821, 2025-05-29
2025-11-11 00:21:56,342 - INFO - root - Page:17, Index:1, MambaIC: State Space Models for High-Performance Learned Image Compression, https://arxiv.org/pdf/2503.12461, 2025-08-22
2025-11-11 00:21:56,342 - INFO - root - Page:17, Index:2, Localized Concept Erasure for Text-to-Image Diffusion Models Using Training-Free Gated Low-Rank Adaptation, https://arxiv.org/pdf/2503.12356, 2025-07-09
2025-11-11 00:21:56,344 - INFO - root - Page:17, Index:3, TASTE-Rob: Advancing Video Generation of Task-Oriented Hand-Object Interaction for Generalizable Robotic Manipulation, https://arxiv.org/pdf/2503.11423, 2025-06-05
2025-11-11 00:21:56,344 - INFO - root - Page:17, Index:4, Panopticon: Advancing Any-Sensor Foundation Models for Earth Observation, https://arxiv.org/pdf/2503.10845, 2025-08-01
2025-11-11 00:21:56,344 - INFO - root - Page:17, Index:5, Transformers without Normalization, https://arxiv.org/pdf/2503.10622, 2025-06-14
2025-11-11 00:21:56,345 - INFO - root - Page:17, Index:6, dFLMoE: Decentralized Federated Learning via Mixture of Experts for Medical Data Analysis, https://arxiv.org/pdf/2503.10412, 2025-05-19
2025-11-11 00:21:56,345 - INFO - root - Fetching page 19 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=900
2025-11-11 00:22:03,280 - INFO - root - get_all_titles_from_web 
2025-11-11 00:22:03,280 - INFO - root - Page:18, Index:0, Project-Probe-Aggregate: Efficient Fine-Tuning for Group Robustness, https://arxiv.org/pdf/2503.09487, 2025-08-26
2025-11-11 00:22:03,280 - INFO - root - Page:18, Index:1, VLog: Video-Language Models by Generative Retrieval of Narration Vocabulary, https://arxiv.org/pdf/2503.09402, 2025-06-09
2025-11-11 00:22:03,282 - INFO - root - Fetching page 20 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=950
2025-11-11 00:22:11,506 - INFO - root - get_all_titles_from_web 
2025-11-11 00:22:11,506 - INFO - root - Page:19, Index:0, Escaping Plato's Cave: Towards the Alignment of 3D and Text Latent Spaces, https://arxiv.org/pdf/2503.05283, 2025-06-04
2025-11-11 00:22:11,508 - INFO - root - Page:19, Index:1, FluidNexus: 3D Fluid Reconstruction and Prediction from a Single Video, https://arxiv.org/pdf/2503.04720, 2025-07-09
2025-11-11 00:22:11,508 - INFO - root - Page:19, Index:2, Question-Aware Gaussian Experts for Audio-Visual Question Answering, https://arxiv.org/pdf/2503.04459, 2025-06-11
2025-11-11 00:22:11,508 - INFO - root - Page:19, Index:3, Q-Eval-100K: Evaluating Visual Quality and Alignment Level for Text-to-Vision Content, https://arxiv.org/pdf/2503.02357, 2025-06-15
2025-11-11 00:22:11,509 - INFO - root - Fetching page 21 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=1000
2025-11-11 00:22:18,399 - INFO - root - get_all_titles_from_web 
2025-11-11 00:22:18,399 - INFO - root - Page:20, Index:0, Data Distributional Properties As Inductive Bias for Systematic Generalization, https://arxiv.org/pdf/2502.20499, 2025-06-17
2025-11-11 00:22:18,400 - INFO - root - Page:20, Index:1, Knowledge Bridger: Towards Training-free Missing Modality Completion, https://arxiv.org/pdf/2502.19834, 2025-06-17
2025-11-11 00:22:18,400 - INFO - root - Fetching page 22 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=1050
2025-11-11 00:22:25,340 - INFO - root - get_all_titles_from_web 
2025-11-11 00:22:25,341 - INFO - root - Page:21, Index:0, MALT Diffusion: Memory-Augmented Latent Transformers for Any-Length Video Generation, https://arxiv.org/pdf/2502.12632, 2025-07-08
2025-11-11 00:22:25,341 - INFO - root - Page:21, Index:1, ILIAS: Instance-Level Image retrieval At Scale, https://arxiv.org/pdf/2502.11748, 2025-06-23
2025-11-11 00:22:25,341 - INFO - root - Page:21, Index:2, Distraction is All You Need for Multimodal Large Language Model Jailbreaking, https://arxiv.org/pdf/2502.10794, 2025-06-16
2025-11-11 00:22:25,342 - INFO - root - Page:21, Index:3, Spatial457: A Diagnostic Benchmark for 6D Spatial Reasoning of Large Multimodal Models, https://arxiv.org/pdf/2502.08636, 2025-06-08
2025-11-11 00:22:25,342 - INFO - root - Page:21, Index:4, TRAVEL: Training-Free Retrieval and Alignment for Vision-and-Language Navigation, https://arxiv.org/pdf/2502.07306, 2025-06-09
2025-11-11 00:22:25,342 - INFO - root - Page:21, Index:5, DiTASK: Multi-Task Fine-Tuning with Diffeomorphic Transformations, https://arxiv.org/pdf/2502.06029, 2025-06-01
2025-11-11 00:22:25,342 - INFO - root - Page:21, Index:6, ConceptAttention: Diffusion Transformers Learn Highly Interpretable Features, https://arxiv.org/pdf/2502.04320, 2025-07-01
2025-11-11 00:22:25,343 - INFO - root - Page:21, Index:7, GCE-Pose: Global Context Enhancement for Category-level Object Pose Estimation, https://arxiv.org/pdf/2502.04293, 2025-06-24
2025-11-11 00:22:25,343 - INFO - root - Page:21, Index:8, Calibrated Multi-Preference Optimization for Aligning Diffusion Models, https://arxiv.org/pdf/2502.02588, 2025-09-26
2025-11-11 00:22:25,343 - INFO - root - Page:21, Index:9, Instruct-4DGS: Efficient Dynamic Scene Editing via 4D Gaussian-based Static-Dynamic Separation, https://arxiv.org/pdf/2502.02091, 2025-07-01
2025-11-11 00:22:25,344 - INFO - root - Page:21, Index:10, Low-Resource Video Super-Resolution using Memory, Wavelets, and Deformable Convolutions, https://arxiv.org/pdf/2502.01816, 2025-06-19
2025-11-11 00:22:25,344 - INFO - root - Page:21, Index:11, Bridging Text and Crystal Structures: Literature-driven Contrastive Learning for Materials Science, https://arxiv.org/pdf/2501.12919, 2025-06-18
2025-11-11 00:22:25,346 - INFO - root - Page:21, Index:12, T2ISafety: Benchmark for Assessing Fairness, Toxicity, and Privacy in Image Generation, https://arxiv.org/pdf/2501.12612, 2025-07-25
2025-11-11 00:22:25,347 - INFO - root - Page:21, Index:13, Fine-Grained Image-Text Correspondence with Cost Aggregation for Open-Vocabulary Part Segmentation, https://arxiv.org/pdf/2501.09688, 2025-08-08
2025-11-11 00:22:25,348 - INFO - root - Fetching page 23 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=1100
2025-11-11 00:22:32,049 - INFO - root - get_all_titles_from_web 
2025-11-11 00:22:32,050 - INFO - root - Page:22, Index:0, Bias for Action: Video Implicit Neural Representations with Bias Modulation, https://arxiv.org/pdf/2501.09277, 2025-06-06
2025-11-11 00:22:32,050 - INFO - root - Page:22, Index:1, MonSter++: Unified Stereo Matching, Multi-view Stereo, and Real-time Stereo with Monodepth Priors, https://arxiv.org/pdf/2501.08643, 2025-09-25
2025-11-11 00:22:32,050 - INFO - root - Page:22, Index:2, Go-with-the-Flow: Motion-Controllable Video Diffusion Models Using Real-Time Warped Noise, https://arxiv.org/pdf/2501.08331, 2025-08-06
2025-11-11 00:22:32,052 - INFO - root - Page:22, Index:3, Nonisotropic Gaussian Diffusion for Realistic 3D Human Motion Prediction, https://arxiv.org/pdf/2501.06035, 2025-07-08
2025-11-11 00:22:32,052 - INFO - root - Page:22, Index:4, Discovering Hidden Visual Concepts Beyond Linguistic Input in Infant Learning, https://arxiv.org/pdf/2501.05205, 2025-06-13
2025-11-11 00:22:32,054 - INFO - root - Page:22, Index:5, PERSE: Personalized 3D Generative Avatars from A Single Portrait, https://arxiv.org/pdf/2412.21206, 2025-09-28
2025-11-11 00:22:32,054 - INFO - root - Page:22, Index:6, MaskGaussian: Adaptive 3D Gaussian Representation from Probabilistic Masks, https://arxiv.org/pdf/2412.20522, 2025-06-14
2025-11-11 00:22:32,055 - INFO - root - Page:22, Index:7, SimLTD: Simple Supervised and Semi-Supervised Long-Tailed Object Detection, https://arxiv.org/pdf/2412.20047, 2025-06-09
2025-11-11 00:22:32,055 - INFO - root - Page:22, Index:8, Conditional Balance: Improving Multi-Conditioning Trade-Offs in Image Generation, https://arxiv.org/pdf/2412.19853, 2025-08-03
2025-11-11 00:22:32,056 - INFO - root - Fetching page 24 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=1150
2025-11-11 00:22:38,677 - INFO - root - get_all_titles_from_web 
2025-11-11 00:22:38,678 - INFO - root - Page:23, Index:0, CoCoGaussian: Leveraging Circle of Confusion for Gaussian Splatting from Defocused Images, https://arxiv.org/pdf/2412.16028, 2025-05-15
2025-11-11 00:22:38,678 - INFO - root - Page:23, Index:1, EnergyMoGen: Compositional Human Motion Generation with Energy-Based Diffusion Model in Latent Space, https://arxiv.org/pdf/2412.14706, 2025-06-04
2025-11-11 00:22:38,679 - INFO - root - Page:23, Index:2, DarkIR: Robust Low-Light Image Restoration, https://arxiv.org/pdf/2412.13443, 2025-10-14
2025-11-11 00:22:38,679 - INFO - root - Page:23, Index:3, FastVLM: Efficient Vision Encoding for Vision Language Models, https://arxiv.org/pdf/2412.13303, 2025-05-15
2025-11-11 00:22:38,679 - INFO - root - Page:23, Index:4, Real-time Free-view Human Rendering from Sparse-view RGB Videos using Double Unprojected Textures, https://arxiv.org/pdf/2412.13183, 2025-06-20
2025-11-11 00:22:38,680 - INFO - root - Page:23, Index:5, CondiMen: Conditional Multi-Person Mesh Recovery, https://arxiv.org/pdf/2412.13058, 2025-06-04
2025-11-11 00:22:38,680 - INFO - root - Page:23, Index:6, MASt3R-SLAM: Real-Time Dense SLAM with 3D Reconstruction Priors, https://arxiv.org/pdf/2412.12392, 2025-06-02
2025-11-11 00:22:38,680 - INFO - root - Page:23, Index:7, DynamicScaler: Seamless and Scalable Video Generation for Panoramic Scenes, https://arxiv.org/pdf/2412.11100, 2025-10-04
2025-11-11 00:22:38,680 - INFO - root - Page:23, Index:8, SnapGen-V: Generating a Five-Second Video within Five Seconds on a Mobile Device, https://arxiv.org/pdf/2412.10494, 2025-06-09
2025-11-11 00:22:38,681 - INFO - root - Page:23, Index:9, Mr. DETR++: Instructive Multi-Route Training for Detection Transformers with Mixture-of-Experts, https://arxiv.org/pdf/2412.10028, 2025-06-26
2025-11-11 00:22:38,681 - INFO - root - Page:23, Index:10, LinGen: Towards High-Resolution Minute-Length Text-to-Video Generation with Linear Computational Complexity, https://arxiv.org/pdf/2412.09856, 2025-05-24
2025-11-11 00:22:38,681 - INFO - root - Page:23, Index:11, Gaze-LLE: Gaze Target Estimation via Large-Scale Learned Encoders, https://arxiv.org/pdf/2412.09586, 2025-06-03
2025-11-11 00:22:38,682 - INFO - root - Fetching page 25 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=1200
2025-11-11 00:22:46,139 - INFO - root - get_all_titles_from_web 
2025-11-11 00:22:46,140 - INFO - root - Page:24, Index:0, From Slow Bidirectional to Fast Autoregressive Video Diffusion Models, https://arxiv.org/pdf/2412.07772, 2025-09-23
2025-11-11 00:22:46,140 - INFO - root - Page:24, Index:1, Rate-In: Information-Driven Adaptive Dropout Rates for Improved Inference-Time Uncertainty Estimation, https://arxiv.org/pdf/2412.07169, 2025-06-03
2025-11-11 00:22:46,140 - INFO - root - Page:24, Index:2, FIRE: Robust Detection of Diffusion-Generated Images via Frequency-Guided Reconstruction Error, https://arxiv.org/pdf/2412.07140, 2025-11-03
2025-11-11 00:22:46,141 - INFO - root - Page:24, Index:3, Birth and Death of a Rose, https://arxiv.org/pdf/2412.05278, 2025-06-05
2025-11-11 00:22:46,141 - INFO - root - Page:24, Index:4, DualPM: Dual Posed-Canonical Point Maps for 3D Shape and Pose Reconstruction, https://arxiv.org/pdf/2412.04464, 2025-08-14
2025-11-11 00:22:46,143 - INFO - root - Page:24, Index:5, SeeGround: See and Ground for Zero-Shot Open-Vocabulary 3D Visual Grounding, https://arxiv.org/pdf/2412.04383, 2025-05-29
2025-11-11 00:22:46,143 - INFO - root - ------------------------------------------------------------------------------------------------------------------------
2025-11-11 00:22:46,148 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\CVPR 2025\Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness.pdf
2025-11-11 00:22:46,152 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\CVPR 2025\OmniTrack++_ Omnidirectional Multi-Object Tracking by Learning Large-FoV Traject.pdf
2025-11-11 00:23:24,076 - INFO - root - 正在总结论文 1/5: Learning to Seek Evidence: A Verifiable Reasoning Agent with Causal Faithfulness Analysis
2025-11-11 00:28:56,634 - INFO - root - 正在提取论文图片...
2025-11-11 00:28:57,079 - INFO - root - 已保存图片 1/10：./export\CVPR\images\figure_1_page2.jpeg
2025-11-11 00:28:57,090 - INFO - root - 已保存图片 2/10：./export\CVPR\images\figure_2_page2.jpeg
2025-11-11 00:28:57,110 - INFO - root - 已保存图片 3/10：./export\CVPR\images\figure_3_page2.jpeg
2025-11-11 00:28:57,133 - INFO - root - 已保存图片 4/10：./export\CVPR\images\figure_4_page2.jpeg
2025-11-11 00:28:57,151 - INFO - root - 已保存图片 5/10：./export\CVPR\images\figure_5_page2.jpeg
2025-11-11 00:28:57,163 - INFO - root - 已保存图片 6/10：./export\CVPR\images\figure_6_page2.jpeg
2025-11-11 00:28:57,174 - INFO - root - 已保存图片 7/10：./export\CVPR\images\figure_7_page2.jpeg
2025-11-11 00:28:57,181 - INFO - root - 已保存图片 8/10：./export\CVPR\images\figure_8_page2.jpeg
2025-11-11 00:28:57,224 - INFO - root - 已保存图片 9/10：./export\CVPR\images\figure_9_page2.jpeg
2025-11-11 00:28:57,233 - INFO - root - 已保存图片 10/10：./export\CVPR\images\figure_10_page2.jpeg
2025-11-11 00:28:57,234 - INFO - root - 成功添加图片 1：./export\CVPR\images\figure_1_page2.jpeg
2025-11-11 00:28:57,238 - INFO - root - 成功添加图片 2：./export\CVPR\images\figure_2_page2.jpeg
2025-11-11 00:28:57,239 - INFO - root - 成功添加图片 3：./export\CVPR\images\figure_3_page2.jpeg
2025-11-11 00:28:57,240 - INFO - root - 成功添加图片 4：./export\CVPR\images\figure_4_page2.jpeg
2025-11-11 00:28:57,241 - INFO - root - 成功添加图片 5：./export\CVPR\images\figure_5_page2.jpeg
2025-11-11 00:28:57,241 - INFO - root - 成功添加图片 6：./export\CVPR\images\figure_6_page2.jpeg
2025-11-11 00:28:57,242 - INFO - root - 成功添加图片 7：./export\CVPR\images\figure_7_page2.jpeg
2025-11-11 00:28:57,242 - INFO - root - 成功添加图片 8：./export\CVPR\images\figure_8_page2.jpeg
2025-11-11 00:28:57,243 - INFO - root - 成功添加图片 9：./export\CVPR\images\figure_9_page2.jpeg
2025-11-11 00:28:57,243 - INFO - root - 成功添加图片 10：./export\CVPR\images\figure_10_page2.jpeg
2025-11-11 00:28:57,244 - INFO - root - 提取到arXiv ID: 2511.01425
2025-11-11 00:28:57,245 - INFO - root - 调用arXiv API: https://export.arxiv.org/api/query?id=2511.01425
2025-11-11 00:29:02,662 - WARNING - root - 未找到entry元素: 2511.01425
2025-11-11 00:29:02,662 - INFO - root - XML根元素标签: {http://www.w3.org/2005/Atom}feed
2025-11-11 00:29:02,662 - INFO - root - XML根元素属性: {}
2025-11-11 00:29:02,662 - INFO - root - 根元素的直接子元素:
2025-11-11 00:29:02,663 - INFO - root -   0. {http://www.w3.org/2005/Atom}link: None
2025-11-11 00:29:02,663 - INFO - root -   1. {http://www.w3.org/2005/Atom}title: ArXiv Query: search_query=&id_list=&start=0&max_results=10
2025-11-11 00:29:02,663 - INFO - root -   2. {http://www.w3.org/2005/Atom}id: http://arxiv.org/api/iQlyOhQ3W8t8kI903+StmrBZNWM
2025-11-11 00:29:02,664 - INFO - root -   3. {http://www.w3.org/2005/Atom}updated: 2025-11-10T00:00:00-05:00
2025-11-11 00:29:02,664 - INFO - root -   4. {http://a9.com/-/spec/opensearch/1.1/}totalResults: 0
2025-11-11 00:29:02,665 - INFO - root -   5. {http://a9.com/-/spec/opensearch/1.1/}startIndex: 0
2025-11-11 00:29:02,665 - INFO - root -   6. {http://a9.com/-/spec/opensearch/1.1/}itemsPerPage: 10
2025-11-11 00:29:02,665 - INFO - root - XML内容前500字符: <?xml version="1.0" encoding="UTF-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <link href="http://arxiv.org/api/query?search_query%3D%26id_list%3D%26start%3D0%26max_results%3D10" rel="self" type="application/atom+xml"/>
  <title type="html">ArXiv Query: search_query=&amp;id_list=&amp;start=0&amp;max_results=10</title>
  <id>http://arxiv.org/api/iQlyOhQ3W8t8kI903+StmrBZNWM</id>
  <updated>2025-11-10T00:00:00-05:00</updated>
  <opensearch:totalResults xmlns:opensearch="http://a9.com/-/spec/op
2025-11-11 00:29:02,668 - INFO - root - 估算引用量: 8
2025-11-11 00:29:02,671 - WARNING - root - 图片文件不存在: images/figure_10_page2.jpeg
2025-11-11 00:29:02,672 - INFO - root - 图片存在于images目录: ./export\CVPR\images\figure_10_page2.jpeg
2025-11-11 00:29:02,679 - WARNING - root - 图片文件不存在: images/figure_9_page2.jpeg
2025-11-11 00:29:02,679 - INFO - root - 图片存在于images目录: ./export\CVPR\images\figure_9_page2.jpeg
2025-11-11 00:29:02,680 - WARNING - root - 图片文件不存在: images/figure_8_page2.jpeg
2025-11-11 00:29:02,681 - INFO - root - 图片存在于images目录: ./export\CVPR\images\figure_8_page2.jpeg
2025-11-11 00:29:02,686 - WARNING - root - 图片文件不存在: images/figure_7_page2.jpeg
2025-11-11 00:29:02,689 - INFO - root - 图片存在于images目录: ./export\CVPR\images\figure_7_page2.jpeg
2025-11-11 00:29:02,693 - WARNING - root - 图片文件不存在: images/figure_6_page2.jpeg
2025-11-11 00:29:02,695 - INFO - root - 图片存在于images目录: ./export\CVPR\images\figure_6_page2.jpeg
2025-11-11 00:29:02,697 - WARNING - root - 图片文件不存在: images/figure_5_page2.jpeg
2025-11-11 00:29:02,698 - INFO - root - 图片存在于images目录: ./export\CVPR\images\figure_5_page2.jpeg
2025-11-11 00:29:02,698 - WARNING - root - 图片文件不存在: images/figure_4_page2.jpeg
2025-11-11 00:29:02,699 - INFO - root - 图片存在于images目录: ./export\CVPR\images\figure_4_page2.jpeg
2025-11-11 00:29:02,699 - WARNING - root - 图片文件不存在: images/figure_3_page2.jpeg
2025-11-11 00:29:02,699 - INFO - root - 图片存在于images目录: ./export\CVPR\images\figure_3_page2.jpeg
2025-11-11 00:29:02,701 - WARNING - root - 图片文件不存在: images/figure_2_page2.jpeg
2025-11-11 00:29:02,701 - INFO - root - 图片存在于images目录: ./export\CVPR\images\figure_2_page2.jpeg
2025-11-11 00:29:02,705 - WARNING - root - 图片文件不存在: images/figure_1_page2.jpeg
2025-11-11 00:29:02,705 - INFO - root - 图片存在于images目录: ./export\CVPR\images\figure_1_page2.jpeg
2025-11-11 00:29:02,714 - INFO - root - 论文《Learning to Seek Evidence: A Verifiable Reasoning Agent with Causal Faithfulness Analysis》的分析已保存到 ./export\CVPR\Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness.md
2025-11-11 00:29:02,717 - INFO - root - 正在总结论文 2/5: OmniTrack++: Omnidirectional Multi-Object Tracking by Learning Large-FoV Trajectory Feedback
2025-11-11 00:30:54,714 - INFO - root - 正在提取论文图片...
2025-11-11 00:30:56,228 - INFO - root - 已保存图片 1/10：./export\CVPR\images\figure_1_page13.jpeg
2025-11-11 00:30:56,393 - INFO - root - 已保存图片 2/10：./export\CVPR\images\figure_2_page13.jpeg
2025-11-11 00:30:56,501 - INFO - root - 已保存图片 3/10：./export\CVPR\images\figure_3_page13.jpeg
2025-11-11 00:30:56,628 - INFO - root - 已保存图片 4/10：./export\CVPR\images\figure_4_page2.jpeg
2025-11-11 00:30:56,776 - INFO - root - 已保存图片 5/10：./export\CVPR\images\figure_5_page5.png
2025-11-11 00:30:56,843 - INFO - root - 已保存图片 6/10：./export\CVPR\images\figure_6_page13.jpeg
2025-11-11 00:30:56,897 - INFO - root - 已保存图片 7/10：./export\CVPR\images\figure_7_page2.jpeg
2025-11-11 00:30:56,969 - INFO - root - 已保存图片 8/10：./export\CVPR\images\figure_8_page8.jpeg
2025-11-11 00:30:57,019 - INFO - root - 已保存图片 9/10：./export\CVPR\images\figure_9_page1.jpeg
2025-11-11 00:30:57,060 - INFO - root - 已保存图片 10/10：./export\CVPR\images\figure_10_page1.png
2025-11-11 00:30:57,082 - INFO - root - 成功添加图片 1：./export\CVPR\images\figure_1_page13.jpeg
2025-11-11 00:30:57,083 - INFO - root - 成功添加图片 2：./export\CVPR\images\figure_2_page13.jpeg
2025-11-11 00:30:57,084 - INFO - root - 成功添加图片 3：./export\CVPR\images\figure_3_page13.jpeg
2025-11-11 00:30:57,085 - INFO - root - 成功添加图片 4：./export\CVPR\images\figure_4_page2.jpeg
2025-11-11 00:30:57,086 - INFO - root - 成功添加图片 5：./export\CVPR\images\figure_5_page5.png
2025-11-11 00:30:57,087 - INFO - root - 成功添加图片 6：./export\CVPR\images\figure_6_page13.jpeg
2025-11-11 00:30:57,088 - INFO - root - 成功添加图片 7：./export\CVPR\images\figure_7_page2.jpeg
2025-11-11 00:30:57,090 - INFO - root - 成功添加图片 8：./export\CVPR\images\figure_8_page8.jpeg
2025-11-11 00:30:57,092 - INFO - root - 成功添加图片 9：./export\CVPR\images\figure_9_page1.jpeg
2025-11-11 00:30:57,093 - INFO - root - 成功添加图片 10：./export\CVPR\images\figure_10_page1.png
2025-11-11 00:30:57,096 - INFO - root - 提取到arXiv ID: 2511.00510
2025-11-11 00:30:57,097 - INFO - root - 调用arXiv API: https://export.arxiv.org/api/query?id=2511.00510
2025-11-11 00:31:02,923 - WARNING - root - 未找到entry元素: 2511.00510
2025-11-11 00:31:02,923 - INFO - root - XML根元素标签: {http://www.w3.org/2005/Atom}feed
2025-11-11 00:31:02,924 - INFO - root - XML根元素属性: {}
2025-11-11 00:31:02,924 - INFO - root - 根元素的直接子元素:
2025-11-11 00:31:02,924 - INFO - root -   0. {http://www.w3.org/2005/Atom}link: None
2025-11-11 00:31:02,924 - INFO - root -   1. {http://www.w3.org/2005/Atom}title: ArXiv Query: search_query=&id_list=&start=0&max_results=10
2025-11-11 00:31:02,924 - INFO - root -   2. {http://www.w3.org/2005/Atom}id: http://arxiv.org/api/iQlyOhQ3W8t8kI903+StmrBZNWM
2025-11-11 00:31:02,924 - INFO - root -   3. {http://www.w3.org/2005/Atom}updated: 2025-11-10T00:00:00-05:00
2025-11-11 00:31:02,926 - INFO - root -   4. {http://a9.com/-/spec/opensearch/1.1/}totalResults: 0
2025-11-11 00:31:02,926 - INFO - root -   5. {http://a9.com/-/spec/opensearch/1.1/}startIndex: 0
2025-11-11 00:31:02,926 - INFO - root -   6. {http://a9.com/-/spec/opensearch/1.1/}itemsPerPage: 10
2025-11-11 00:31:02,926 - INFO - root - XML内容前500字符: <?xml version="1.0" encoding="UTF-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <link href="http://arxiv.org/api/query?search_query%3D%26id_list%3D%26start%3D0%26max_results%3D10" rel="self" type="application/atom+xml"/>
  <title type="html">ArXiv Query: search_query=&amp;id_list=&amp;start=0&amp;max_results=10</title>
  <id>http://arxiv.org/api/iQlyOhQ3W8t8kI903+StmrBZNWM</id>
  <updated>2025-11-10T00:00:00-05:00</updated>
  <opensearch:totalResults xmlns:opensearch="http://a9.com/-/spec/op
2025-11-11 00:31:02,931 - INFO - root - 估算引用量: 13
2025-11-11 00:31:02,933 - WARNING - root - 图片文件不存在: images/figure_10_page1.png
2025-11-11 00:31:02,933 - INFO - root - 图片存在于images目录: ./export\CVPR\images\figure_10_page1.png
2025-11-11 00:31:02,934 - WARNING - root - 图片文件不存在: images/figure_9_page1.jpeg
2025-11-11 00:31:02,934 - INFO - root - 图片存在于images目录: ./export\CVPR\images\figure_9_page1.jpeg
2025-11-11 00:31:02,935 - WARNING - root - 图片文件不存在: images/figure_8_page8.jpeg
2025-11-11 00:31:02,935 - INFO - root - 图片存在于images目录: ./export\CVPR\images\figure_8_page8.jpeg
2025-11-11 00:31:02,936 - WARNING - root - 图片文件不存在: images/figure_7_page2.jpeg
2025-11-11 00:31:02,936 - INFO - root - 图片存在于images目录: ./export\CVPR\images\figure_7_page2.jpeg
2025-11-11 00:31:02,936 - WARNING - root - 图片文件不存在: images/figure_6_page13.jpeg
2025-11-11 00:31:02,937 - INFO - root - 图片存在于images目录: ./export\CVPR\images\figure_6_page13.jpeg
2025-11-11 00:31:02,937 - WARNING - root - 图片文件不存在: images/figure_5_page5.png
2025-11-11 00:31:02,937 - INFO - root - 图片存在于images目录: ./export\CVPR\images\figure_5_page5.png
2025-11-11 00:31:02,937 - WARNING - root - 图片文件不存在: images/figure_4_page2.jpeg
2025-11-11 00:31:02,940 - INFO - root - 图片存在于images目录: ./export\CVPR\images\figure_4_page2.jpeg
2025-11-11 00:31:02,941 - WARNING - root - 图片文件不存在: images/figure_3_page13.jpeg
2025-11-11 00:31:02,941 - INFO - root - 图片存在于images目录: ./export\CVPR\images\figure_3_page13.jpeg
2025-11-11 00:31:02,942 - WARNING - root - 图片文件不存在: images/figure_2_page13.jpeg
2025-11-11 00:31:02,943 - INFO - root - 图片存在于images目录: ./export\CVPR\images\figure_2_page13.jpeg
2025-11-11 00:31:02,949 - WARNING - root - 图片文件不存在: images/figure_1_page13.jpeg
2025-11-11 00:31:02,950 - INFO - root - 图片存在于images目录: ./export\CVPR\images\figure_1_page13.jpeg
2025-11-11 00:31:02,953 - INFO - root - 论文《OmniTrack++: Omnidirectional Multi-Object Tracking by Learning Large-FoV Trajectory Feedback》的分析已保存到 ./export\CVPR\OmniTrack++_ Omnidirectional Multi-Object Tracking by Learning Large-FoV Traject.md
2025-11-11 00:31:02,966 - INFO - root - 正在总结论文 3/5: NeuCo-Bench: A Novel Benchmark Framework for Neural Embeddings in Earth Observation
2025-11-11 00:40:43,629 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-11 00:40:43,633 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-11 00:40:43,635 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-11 00:40:44,754 - INFO - root - LLMClientManager: 指定使用客户端: Gemini
2025-11-11 00:40:46,706 - INFO - root - GeminiClient: trying model models/gemini-2.5-flash
2025-11-11 00:40:48,552 - INFO - root - GeminiClient: initialized model gemini-2.5-flash
2025-11-11 00:40:48,552 - INFO - root - LLMClientManager: Gemini 客户端初始化成功
2025-11-11 00:40:48,552 - INFO - root - LLMClientManager: switched to Gemini client
2025-11-11 00:40:48,553 - INFO - root - 已手动切换到 LLM 客户端: Gemini
2025-11-11 00:40:48,553 - INFO - root - 使用 LLM 模型: gemini-2.5-flash
2025-11-11 00:40:48,554 - INFO - root - 可用客户端: ['Gemini']
2025-11-11 00:40:48,554 - INFO - root - === 运行配置 ===
2025-11-11 00:40:48,554 - INFO - root - 处理模式: arxiv在线搜索
2025-11-11 00:40:48,555 - INFO - root - 关键词: CVPR
2025-11-11 00:40:48,555 - INFO - root - 查询: CVPR 2025
2025-11-11 00:40:48,555 - INFO - root - 排序: None
2025-11-11 00:40:48,556 - INFO - root - 最近天数: 180
2025-11-11 00:40:48,556 - INFO - root - 最大处理数量: 5
2025-11-11 00:40:48,556 - INFO - root - 保存图片: 是
2025-11-11 00:40:48,556 - INFO - root - 输出语言: 中文
2025-11-11 00:40:48,557 - INFO - root - 强制重新处理: 否
2025-11-11 00:40:48,558 - INFO - root - ====================
2025-11-11 00:40:48,558 - INFO - root - 使用 arXiv 搜索模式（通过 chat_arxiv 模块获取）
2025-11-11 00:40:48,558 - INFO - root - Fetching page 1 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50
2025-11-11 00:40:55,229 - INFO - root - get_all_titles_from_web 
2025-11-11 00:40:55,229 - INFO - root - Page:0, Index:0, Learning to Seek Evidence: A Verifiable Reasoning Agent with Causal Faithfulness Analysis, https://arxiv.org/pdf/2511.01425, 2025-11-03
2025-11-11 00:40:55,230 - INFO - root - Page:0, Index:1, OmniTrack++: Omnidirectional Multi-Object Tracking by Learning Large-FoV Trajectory Feedback, https://arxiv.org/pdf/2511.00510, 2025-11-01
2025-11-11 00:40:55,230 - INFO - root - Page:0, Index:2, NeuCo-Bench: A Novel Benchmark Framework for Neural Embeddings in Earth Observation, https://arxiv.org/pdf/2510.17914, 2025-10-19
2025-11-11 00:40:55,230 - INFO - root - Page:0, Index:3, NTIRE 2025 Challenge on Low Light Image Enhancement: Methods and Results, https://arxiv.org/pdf/2510.13670, 2025-10-15
2025-11-11 00:40:55,232 - INFO - root - Page:0, Index:4, Class Prototypes based Contrastive Learning for Classifying Multi-Label and Fine-Grained Educational Videos, https://arxiv.org/pdf/2510.11204, 2025-10-13
2025-11-11 00:40:55,232 - INFO - root - Page:0, Index:5, MIMO: A medical vision language model with visual referring multimodal input and pixel grounding multimodal output, https://arxiv.org/pdf/2510.10011, 2025-10-11
2025-11-11 00:40:55,232 - INFO - root - Page:0, Index:6, Vision Language Models: A Survey of 26K Papers, https://arxiv.org/pdf/2510.09586, 2025-10-10
2025-11-11 00:40:55,233 - INFO - root - Page:0, Index:7, DiT-VTON: Diffusion Transformer Framework for Unified Multi-Category Virtual Try-On and Virtual Try-All with Integrated Image Editing, https://arxiv.org/pdf/2510.04797, 2025-10-03
2025-11-11 00:40:55,233 - INFO - root - Page:0, Index:8, PatchVSR: Breaking Video Diffusion Resolution Limits with Patch-wise Video Super-Resolution, https://arxiv.org/pdf/2509.26025, 2025-09-30
2025-11-11 00:40:55,233 - INFO - root - Page:0, Index:9, FreqDebias: Towards Generalizable Deepfake Detection via Consistency-Driven Frequency Debiasing, https://arxiv.org/pdf/2509.22412, 2025-09-26
2025-11-11 00:40:55,233 - INFO - root - Page:0, Index:10, A Mutual Learning Method for Salient Object Detection with intertwined Multi-Supervision--Revised, https://arxiv.org/pdf/2509.21363, 2025-09-21
2025-11-11 00:40:55,234 - INFO - root - Page:0, Index:11, InstructVTON: Optimal Auto-Masking and Natural-Language-Guided Interactive Style Control for Inpainting-Based Virtual Try-On, https://arxiv.org/pdf/2509.20524, 2025-09-24
2025-11-11 00:40:55,234 - INFO - root - Page:0, Index:12, Efficient Encoder-Free Pose Conditioning and Pose Control for Virtual Try-On, https://arxiv.org/pdf/2509.20343, 2025-09-24
2025-11-11 00:40:55,234 - INFO - root - Page:0, Index:13, The Photographer Eye: Teaching Multimodal Large Language Models to Understand Image Aesthetics like Photographers, https://arxiv.org/pdf/2509.18582, 2025-10-22
2025-11-11 00:40:55,234 - INFO - root - Page:0, Index:14, ENSAM: an efficient foundation model for interactive segmentation of 3D medical images, https://arxiv.org/pdf/2509.15874, 2025-09-19
2025-11-11 00:40:55,236 - INFO - root - Page:0, Index:15, DEFT-VTON: Efficient Virtual Try-On with Consistent Generalised H-Transform, https://arxiv.org/pdf/2509.13506, 2025-09-16
2025-11-11 00:40:55,237 - INFO - root - Page:0, Index:16, Weakly and Self-Supervised Class-Agnostic Motion Prediction for Autonomous Driving, https://arxiv.org/pdf/2509.13116, 2025-09-16
2025-11-11 00:40:55,238 - INFO - root - Page:0, Index:17, Domain-Adaptive Pretraining Improves Primate Behavior Recognition, https://arxiv.org/pdf/2509.12193, 2025-09-15
2025-11-11 00:40:55,238 - INFO - root - Page:0, Index:18, The System Description of CPS Team for Track on Driving with Language of CVPR 2024 Autonomous Grand Challenge, https://arxiv.org/pdf/2509.11071, 2025-09-13
2025-11-11 00:40:55,238 - INFO - root - Page:0, Index:19, An HMM-based framework for identity-aware long-term multi-object tracking from sparse and uncertain identification: use case on long-term tracking in livestock, https://arxiv.org/pdf/2509.09962, 2025-09-12
2025-11-11 00:40:55,239 - INFO - root - Page:0, Index:20, InterAct: Advancing Large-Scale Versatile 3D Human-Object Interaction Generation, https://arxiv.org/pdf/2509.09555, 2025-09-11
2025-11-11 00:40:55,239 - INFO - root - Page:0, Index:21, Geospatial Foundational Embedder: Top-1 Winning Solution on EarthVision Embed2Scale Challenge (CVPR 2025), https://arxiv.org/pdf/2509.06993, 2025-09-03
2025-11-11 00:40:55,240 - INFO - root - Page:0, Index:22, 2nd Place Solution for CVPR2024 E2E Challenge: End-to-End Autonomous Driving Using Vision Language Model, https://arxiv.org/pdf/2509.02659, 2025-09-02
2025-11-11 00:40:55,241 - INFO - root - Page:0, Index:23, Unsupervised Training of Vision Transformers with Synthetic Negatives, https://arxiv.org/pdf/2509.02024, 2025-09-02
2025-11-11 00:40:55,243 - INFO - root - Page:0, Index:24, MV-SSM: Multi-View State Space Modeling for 3D Human Pose Estimation, https://arxiv.org/pdf/2509.00649, 2025-08-30
2025-11-11 00:40:55,244 - INFO - root - Page:0, Index:25, CryptoFace: End-to-End Encrypted Face Recognition, https://arxiv.org/pdf/2509.00332, 2025-08-29
2025-11-11 00:40:55,244 - INFO - root - Page:0, Index:26, ControlEchoSynth: Boosting Ejection Fraction Estimation Models via Controlled Video Diffusion, https://arxiv.org/pdf/2508.17631, 2025-08-26
2025-11-11 00:40:55,244 - INFO - root - Page:0, Index:27, Explain Before You Answer: A Survey on Compositional Visual Reasoning, https://arxiv.org/pdf/2508.17298, 2025-08-27
2025-11-11 00:40:55,244 - INFO - root - Page:0, Index:28, Investigating Different Geo Priors for Image Classification, https://arxiv.org/pdf/2508.15946, 2025-08-21
2025-11-11 00:40:55,246 - INFO - root - Page:0, Index:29, Towards Source-Free Machine Unlearning, https://arxiv.org/pdf/2508.15127, 2025-08-20
2025-11-11 00:40:55,246 - INFO - root - Page:0, Index:30, MR6D: Benchmarking 6D Pose Estimation for Mobile Robots, https://arxiv.org/pdf/2508.13775, 2025-08-19
2025-11-11 00:40:55,246 - INFO - root - Page:0, Index:31, Calibrating Biased Distribution in VFM-derived Latent Space via Cross-Domain Geometric Consistency, https://arxiv.org/pdf/2508.13518, 2025-08-19
2025-11-11 00:40:55,246 - INFO - root - Page:0, Index:32, SIS-Challenge: Event-based Spatio-temporal Instance Segmentation Challenge at the CVPR 2025 Event-based Vision Workshop, https://arxiv.org/pdf/2508.12813, 2025-08-18
2025-11-11 00:40:55,248 - INFO - root - Page:0, Index:33, Multi-Level Knowledge Distillation and Dynamic Self-Supervised Learning for Continual Learning, https://arxiv.org/pdf/2508.12692, 2025-08-22
2025-11-11 00:40:55,248 - INFO - root - Page:0, Index:34, Stochastic-based Patch Filtering for Few-Shot Learning, https://arxiv.org/pdf/2508.10066, 2025-08-13
2025-11-11 00:40:55,248 - INFO - root - Page:0, Index:35, Slot Attention-based Feature Filtering for Few-Shot Learning, https://arxiv.org/pdf/2508.09699, 2025-08-13
2025-11-11 00:40:55,249 - INFO - root - Page:0, Index:36, Comparison Reveals Commonality: Customized Image Generation through Contrastive Inversion, https://arxiv.org/pdf/2508.07755, 2025-08-11
2025-11-11 00:40:55,249 - INFO - root - Page:0, Index:37, SLRTP2025 Sign Language Production Challenge: Methodology, Results, and Future Work, https://arxiv.org/pdf/2508.06951, 2025-08-09
2025-11-11 00:40:55,249 - INFO - root - Page:0, Index:38, Exploring Fairness across Fine-Grained Attributes in Large Vision-Language Models, https://arxiv.org/pdf/2508.03079, 2025-08-05
2025-11-11 00:40:55,250 - INFO - root - Page:0, Index:39, Devil is in the Detail: Towards Injecting Fine Details of Image Prompt in Image Generation via Conflict-free Guidance and Stratified Attention, https://arxiv.org/pdf/2508.02004, 2025-08-03
2025-11-11 00:40:55,250 - INFO - root - Page:0, Index:40, IAUNet: Instance-Aware U-Net, https://arxiv.org/pdf/2508.01928, 2025-08-03
2025-11-11 00:40:55,250 - INFO - root - Page:0, Index:41, Gaussian Splatting Feature Fields for Privacy-Preserving Visual Localization, https://arxiv.org/pdf/2507.23569, 2025-08-26
2025-11-11 00:40:55,253 - INFO - root - Page:0, Index:42, From Scan to Action: Leveraging Realistic Scans for Embodied Scene Understanding, https://arxiv.org/pdf/2507.17585, 2025-07-23
2025-11-11 00:40:55,254 - INFO - root - Page:0, Index:43, LEAD: Exploring Logit Space Evolution for Model Selection, https://arxiv.org/pdf/2507.14559, 2025-07-19
2025-11-11 00:40:55,255 - INFO - root - Page:0, Index:44, HeCoFuse: Cross-Modal Complementary V2X Cooperative Perception with Heterogeneous Sensors, https://arxiv.org/pdf/2507.13677, 2025-07-18
2025-11-11 00:40:55,258 - INFO - root - Page:0, Index:45, OmniVec2 -- A Novel Transformer based Network for Large Scale Multimodal and Multitask Learning, https://arxiv.org/pdf/2507.13364, 2025-07-06
2025-11-11 00:40:55,259 - INFO - root - Page:0, Index:46, A Training-Free, Task-Agnostic Framework for Enhancing MLLM Performance on High-Resolution Images, https://arxiv.org/pdf/2507.10202, 2025-07-14
2025-11-11 00:40:55,259 - INFO - root - Page:0, Index:47, Quantum Federated Learning for Multimodal Data: A Modality-Agnostic Approach, https://arxiv.org/pdf/2507.08217, 2025-07-10
2025-11-11 00:40:55,260 - INFO - root - Page:0, Index:48, CuriosAI Submission to the EgoExo4D Proficiency Estimation Challenge 2025, https://arxiv.org/pdf/2507.08022, 2025-07-08
2025-11-11 00:40:55,260 - INFO - root - Page:0, Index:49, Rethinking Query-based Transformer for Continual Image Segmentation, https://arxiv.org/pdf/2507.07831, 2025-07-10
2025-11-11 00:40:55,261 - INFO - root - Fetching page 2 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=50
2025-11-11 00:41:03,516 - INFO - root - get_all_titles_from_web 
2025-11-11 00:41:03,517 - INFO - root - Page:1, Index:0, Scalable and Realistic Virtual Try-on Application for Foundation Makeup with Kubelka-Munk Theory, https://arxiv.org/pdf/2507.07333, 2025-07-09
2025-11-11 00:41:03,517 - INFO - root - Page:1, Index:1, Free on the Fly: Enhancing Flexibility in Test-Time Adaptation with Online EM, https://arxiv.org/pdf/2507.06973, 2025-07-09
2025-11-11 00:41:03,517 - INFO - root - Page:1, Index:2, Adaptive Part Learning for Fine-Grained Generalized Category Discovery: A Plug-and-Play Enhancement, https://arxiv.org/pdf/2507.06928, 2025-07-09
2025-11-11 00:41:03,517 - INFO - root - Page:1, Index:3, Grounded Gesture Generation: Language, Motion, and Space, https://arxiv.org/pdf/2507.04522, 2025-07-06
2025-11-11 00:41:03,518 - INFO - root - Page:1, Index:4, Comprehensive Information Bottleneck for Unveiling Universal Attribution to Interpret Vision Transformers, https://arxiv.org/pdf/2507.04388, 2025-07-06
2025-11-11 00:41:03,518 - INFO - root - Page:1, Index:5, ZERO: Industry-ready Vision Foundation Model with Multi-modal Prompts, https://arxiv.org/pdf/2507.04270, 2025-11-07
2025-11-11 00:41:03,519 - INFO - root - Page:1, Index:6, Beyond Accuracy: Metrics that Uncover What Makes a 'Good' Visual Descriptor, https://arxiv.org/pdf/2507.03542, 2025-07-08
2025-11-11 00:41:03,520 - INFO - root - Page:1, Index:7, ConceptMix++: Leveling the Playing Field in Text-to-Image Benchmarking via Iterative Prompt Optimization, https://arxiv.org/pdf/2507.03275, 2025-07-03
2025-11-11 00:41:03,520 - INFO - root - Page:1, Index:8, APT: Adaptive Personalized Training for Diffusion Models with Limited Data, https://arxiv.org/pdf/2507.02687, 2025-07-03
2025-11-11 00:41:03,520 - INFO - root - Page:1, Index:9, DreamComposer++: Empowering Diffusion Models with Multi-View Conditions for 3D Content Generation, https://arxiv.org/pdf/2507.02299, 2025-07-03
2025-11-11 00:41:03,520 - INFO - root - Page:1, Index:10, Soft Self-labeling and Potts Relaxations for Weakly-Supervised Segmentation, https://arxiv.org/pdf/2507.01721, 2025-07-02
2025-11-11 00:41:03,520 - INFO - root - Page:1, Index:11, Interpolation-Based Event Visual Data Filtering Algorithms, https://arxiv.org/pdf/2507.01557, 2025-07-02
2025-11-11 00:41:03,520 - INFO - root - Page:1, Index:12, AVC-DPO: Aligned Video Captioning via Direct Preference Optimization, https://arxiv.org/pdf/2507.01492, 2025-07-02
2025-11-11 00:41:03,521 - INFO - root - Page:1, Index:13, NN-Former: Rethinking Graph Structure in Neural Architecture Representation, https://arxiv.org/pdf/2507.00880, 2025-07-01
2025-11-11 00:41:03,521 - INFO - root - Page:1, Index:14, Instant Particle Size Distribution Measurement Using CNNs Trained on Synthetic Data, https://arxiv.org/pdf/2507.00822, 2025-07-01
2025-11-11 00:41:03,521 - INFO - root - Page:1, Index:15, Moment Sampling in Video LLMs for Long-Form Video QA, https://arxiv.org/pdf/2507.00033, 2025-06-17
2025-11-11 00:41:03,522 - INFO - root - Page:1, Index:16, Revisiting Audio-Visual Segmentation with Vision-Centric Transformer, https://arxiv.org/pdf/2506.23623, 2025-06-30
2025-11-11 00:41:03,522 - INFO - root - Page:1, Index:17, MTADiffusion: Mask Text Alignment Diffusion Model for Object Inpainting, https://arxiv.org/pdf/2506.23482, 2025-06-29
2025-11-11 00:41:03,522 - INFO - root - Page:1, Index:18, Benchmarking Generalizable Bimanual Manipulation: RoboTwin Dual-Arm Collaboration Challenge at CVPR 2025 MEIS Workshop, https://arxiv.org/pdf/2506.23351, 2025-07-02
2025-11-11 00:41:03,524 - INFO - root - Page:1, Index:19, Prompting without Panic: Attribute-aware, Zero-shot, Test-Time Calibration, https://arxiv.org/pdf/2506.22819, 2025-06-28
2025-11-11 00:41:03,524 - INFO - root - Page:1, Index:20, Analyzing and Fine-Tuning Whisper Models for Multilingual Pilot Speech Transcription in the Cockpit, https://arxiv.org/pdf/2506.21990, 2025-06-27
2025-11-11 00:41:03,524 - INFO - root - Page:1, Index:21, SceneDiffuser++: City-Scale Traffic Simulation via a Generative World Model, https://arxiv.org/pdf/2506.21976, 2025-06-27
2025-11-11 00:41:03,525 - INFO - root - Page:1, Index:22, DIVE: Deep-search Iterative Video Exploration A Technical Report for the CVRR Challenge at CVPR 2025, https://arxiv.org/pdf/2506.21891, 2025-06-27
2025-11-11 00:41:03,525 - INFO - root - Page:1, Index:23, End-to-End RGB-IR Joint Image Compression With Channel-wise Cross-modality Entropy Model, https://arxiv.org/pdf/2506.21851, 2025-06-26
2025-11-11 00:41:03,525 - INFO - root - Page:1, Index:24, Distilling Normalizing Flows, https://arxiv.org/pdf/2506.21003, 2025-06-26
2025-11-11 00:41:03,526 - INFO - root - Page:1, Index:25, Joint attitude estimation and 3D neural reconstruction of non-cooperative space objects, https://arxiv.org/pdf/2506.20638, 2025-06-25
2025-11-11 00:41:03,530 - INFO - root - Page:1, Index:26, Accept More, Reject Less: Reducing up to 19% Unnecessary Desk-Rejections over 11 Years of ICLR Data, https://arxiv.org/pdf/2506.20141, 2025-06-25
2025-11-11 00:41:03,532 - INFO - root - Page:1, Index:27, SceneCrafter: Controllable Multi-View Driving Scene Editing, https://arxiv.org/pdf/2506.19488, 2025-06-24
2025-11-11 00:41:03,532 - INFO - root - Page:1, Index:28, Emergence of Text Readability in Vision Language Models, https://arxiv.org/pdf/2506.19389, 2025-06-24
2025-11-11 00:41:03,532 - INFO - root - Page:1, Index:29, MedErr-CT: A Visual Question Answering Benchmark for Identifying and Correcting Errors in CT Reports, https://arxiv.org/pdf/2506.19217, 2025-06-23
2025-11-11 00:41:03,532 - INFO - root - Page:1, Index:30, RareSpot: Spotting Small and Rare Wildlife in Aerial Imagery with Multi-Scale Consistency and Context-Aware Augmentation, https://arxiv.org/pdf/2506.19087, 2025-06-23
2025-11-11 00:41:03,532 - INFO - root - Page:1, Index:31, Object-aware Sound Source Localization via Audio-Visual Scene Understanding, https://arxiv.org/pdf/2506.18557, 2025-06-23
2025-11-11 00:41:03,532 - INFO - root - Page:1, Index:32, Rethinking Decoder Design: Improving Biomarker Segmentation Using Depth-to-Space Restoration and Residual Linear Attention, https://arxiv.org/pdf/2506.18335, 2025-06-23
2025-11-11 00:41:03,532 - INFO - root - Page:1, Index:33, Relation3D: Enhancing Relation Modeling for Point Cloud Instance Segmentation, https://arxiv.org/pdf/2506.17891, 2025-06-21
2025-11-11 00:41:03,533 - INFO - root - Page:1, Index:34, HIRE: Lightweight High-Resolution Image Feature Enrichment for Multimodal LLMs, https://arxiv.org/pdf/2506.17608, 2025-06-21
2025-11-11 00:41:03,533 - INFO - root - Page:1, Index:35, Spatially-Aware Evaluation of Segmentation Uncertainty, https://arxiv.org/pdf/2506.16589, 2025-06-19
2025-11-11 00:41:03,533 - INFO - root - Page:1, Index:36, Tripartite Weight-Space Ensemble for Few-Shot Class-Incremental Learning, https://arxiv.org/pdf/2506.15720, 2025-06-03
2025-11-11 00:41:03,535 - INFO - root - Page:1, Index:37, PARC: A Quantitative Framework Uncovering the Symmetries within Vision Language Models, https://arxiv.org/pdf/2506.14808, 2025-06-03
2025-11-11 00:41:03,535 - INFO - root - Page:1, Index:38, Self-supervised Representation Learning with Local Aggregation for Image-based Profiling, https://arxiv.org/pdf/2506.14265, 2025-10-27
2025-11-11 00:41:03,535 - INFO - root - Page:1, Index:39, Towards Robust Learning to Optimize with Theoretical Guarantees, https://arxiv.org/pdf/2506.14263, 2025-06-17
2025-11-11 00:41:03,535 - INFO - root - Page:1, Index:40, Hidden Bias in the Machine: Stereotypes in Text-to-Image Models, https://arxiv.org/pdf/2506.13780, 2025-06-09
2025-11-11 00:41:03,536 - INFO - root - Page:1, Index:41, SmartHome-Bench: A Comprehensive Benchmark for Video Anomaly Detection in Smart Homes Using Multi-Modal Large Language Models, https://arxiv.org/pdf/2506.12992, 2025-06-15
2025-11-11 00:41:03,536 - INFO - root - Page:1, Index:42, Generative 4D Scene Gaussian Splatting with Object View-Synthesis Priors, https://arxiv.org/pdf/2506.12716, 2025-06-15
2025-11-11 00:41:03,536 - INFO - root - Page:1, Index:43, DejaVid: Encoder-Agnostic Learned Temporal Matching for Video Classification, https://arxiv.org/pdf/2506.12585, 2025-06-14
2025-11-11 00:41:03,537 - INFO - root - Page:1, Index:44, Pushing the Limits of Safety: A Technical Report on the ATLAS Challenge 2025, https://arxiv.org/pdf/2506.12430, 2025-07-10
2025-11-11 00:41:03,537 - INFO - root - Page:1, Index:45, FIMA-Q: Post-Training Quantization for Vision Transformers by Fisher Information Matrix Approximation, https://arxiv.org/pdf/2506.11543, 2025-06-13
2025-11-11 00:41:03,537 - INFO - root - Page:1, Index:46, Stop learning it all to mitigate visual hallucination, Focus on the hallucination target, https://arxiv.org/pdf/2506.11417, 2025-06-12
2025-11-11 00:41:03,538 - INFO - root - Page:1, Index:47, EfficientQuant: An Efficient Post-Training Quantization for CNN-Transformer Hybrid Models on Edge Devices, https://arxiv.org/pdf/2506.11093, 2025-06-05
2025-11-11 00:41:03,538 - INFO - root - Page:1, Index:48, HalLoc: Token-level Localization of Hallucinations for Vision Language Models, https://arxiv.org/pdf/2506.10286, 2025-06-11
2025-11-11 00:41:03,538 - INFO - root - Page:1, Index:49, DySS: Dynamic Queries and State-Space Learning for Efficient 3D Object Detection from Multi-Camera Videos, https://arxiv.org/pdf/2506.10242, 2025-06-11
2025-11-11 00:41:03,538 - INFO - root - Fetching page 3 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=100
2025-11-11 00:41:10,712 - INFO - root - get_all_titles_from_web 
2025-11-11 00:41:10,712 - INFO - root - Page:2, Index:0, Improving Personalized Search with Regularized Low-Rank Parameter Updates, https://arxiv.org/pdf/2506.10182, 2025-06-11
2025-11-11 00:41:10,713 - INFO - root - Page:2, Index:1, Hearing Hands: Generating Sounds from Physical Interactions in 3D Scenes, https://arxiv.org/pdf/2506.09989, 2025-06-11
2025-11-11 00:41:10,713 - INFO - root - Page:2, Index:2, UniPre3D: Unified Pre-training of 3D Point Cloud Models with Cross-Modal Gaussian Splatting, https://arxiv.org/pdf/2506.09952, 2025-06-11
2025-11-11 00:41:10,713 - INFO - root - Page:2, Index:3, Provoking Multi-modal Few-Shot LVLM via Exploration-Exploitation In-Context Learning, https://arxiv.org/pdf/2506.09473, 2025-06-11
2025-11-11 00:41:10,714 - INFO - root - Page:2, Index:4, Synthetic Human Action Video Data Generation with Pose Transfer, https://arxiv.org/pdf/2506.09411, 2025-06-11
2025-11-11 00:41:10,714 - INFO - root - Page:2, Index:5, ScaleLSD: Scalable Deep Line Segment Detection Streamlined, https://arxiv.org/pdf/2506.09369, 2025-06-10
2025-11-11 00:41:10,714 - INFO - root - Page:2, Index:6, CheckManual: A New Challenge and Benchmark for Manual-based Appliance Manipulation, https://arxiv.org/pdf/2506.09343, 2025-06-10
2025-11-11 00:41:10,714 - INFO - root - Page:2, Index:7, PatchGuard: Adversarially Robust Anomaly Detection and Localization through Vision Transformers and Pseudo Anomalies, https://arxiv.org/pdf/2506.09237, 2025-10-24
2025-11-11 00:41:10,715 - INFO - root - Page:2, Index:8, SILK: Smooth InterpoLation frameworK for motion in-betweening A Simplified Computational Approach, https://arxiv.org/pdf/2506.09075, 2025-06-09
2025-11-11 00:41:10,715 - INFO - root - Page:2, Index:9, BG-HOP: A Bimanual Generative Hand-Object Prior, https://arxiv.org/pdf/2506.09068, 2025-06-08
2025-11-11 00:41:10,715 - INFO - root - Page:2, Index:10, ORIDa: Object-centric Real-world Image Composition Dataset, https://arxiv.org/pdf/2506.08964, 2025-06-10
2025-11-11 00:41:10,716 - INFO - root - Page:2, Index:11, DiscoVLA: Discrepancy Reduction in Vision, Language, and Alignment for Parameter-Efficient Video-Text Retrieval, https://arxiv.org/pdf/2506.08887, 2025-06-10
2025-11-11 00:41:10,716 - INFO - root - Page:2, Index:12, A Comprehensive Study of Decoder-Only LLMs for Text-to-Image Generation, https://arxiv.org/pdf/2506.08210, 2025-06-09
2025-11-11 00:41:10,716 - INFO - root - Page:2, Index:13, Open World Scene Graph Generation using Vision Language Models, https://arxiv.org/pdf/2506.08189, 2025-06-09
2025-11-11 00:41:10,718 - INFO - root - Page:2, Index:14, Aligning Proteins and Language: A Foundation Model for Protein Retrieval, https://arxiv.org/pdf/2506.08023, 2025-05-27
2025-11-11 00:41:10,718 - INFO - root - Page:2, Index:15, UA-Pose: Uncertainty-Aware 6D Object Pose Estimation and Online Object Completion with Partial References, https://arxiv.org/pdf/2506.07996, 2025-06-09
2025-11-11 00:41:10,718 - INFO - root - Page:2, Index:16, Speedy Deformable 3D Gaussian Splatting: Fast Rendering and Compression of Dynamic Scenes, https://arxiv.org/pdf/2506.07917, 2025-06-09
2025-11-11 00:41:10,719 - INFO - root - Page:2, Index:17, GaussianVAE: Adaptive Learning Dynamics of 3D Gaussians for High-Fidelity Super-Resolution, https://arxiv.org/pdf/2506.07897, 2025-06-09
2025-11-11 00:41:10,719 - INFO - root - Page:2, Index:18, Spatio-Temporal State Space Model For Efficient Event-Based Optical Flow, https://arxiv.org/pdf/2506.07878, 2025-06-09
2025-11-11 00:41:10,720 - INFO - root - Page:2, Index:19, FreeGave: 3D Physics Learning from Dynamic Videos by Gaussian Velocity, https://arxiv.org/pdf/2506.07865, 2025-06-09
2025-11-11 00:41:10,720 - INFO - root - Page:2, Index:20, LogoSP: Local-global Grouping of Superpoints for Unsupervised Semantic Segmentation of 3D Point Clouds, https://arxiv.org/pdf/2506.07857, 2025-06-09
2025-11-11 00:41:10,720 - INFO - root - Page:2, Index:21, Difference Inversion: Interpolate and Isolate the Difference with Token Consistency for Image Analogy Generation, https://arxiv.org/pdf/2506.07750, 2025-06-09
2025-11-11 00:41:10,721 - INFO - root - Page:2, Index:22, Synthetic Visual Genome, https://arxiv.org/pdf/2506.07643, 2025-06-09
2025-11-11 00:41:10,721 - INFO - root - Page:2, Index:23, Fractional Collisions: A Framework for Risk Estimation of Counterfactual Conflicts using Autonomous Driving Behavior Simulations, https://arxiv.org/pdf/2506.07540, 2025-06-09
2025-11-11 00:41:10,721 - INFO - root - Page:2, Index:24, Multi-Step Guided Diffusion for Image Restoration on Edge Devices: Toward Lightweight Perception in Embodied AI, https://arxiv.org/pdf/2506.07286, 2025-06-08
2025-11-11 00:41:10,721 - INFO - root - Page:2, Index:25, LLM-Enhanced Rapid-Reflex Async-Reflect Embodied Agent for Real-Time Decision-Making in Dynamically Changing Environments, https://arxiv.org/pdf/2506.07223, 2025-06-08
2025-11-11 00:41:10,722 - INFO - root - Page:2, Index:26, UCOD-DPL: Unsupervised Camouflaged Object Detection via Dynamic Pseudo-label Learning, https://arxiv.org/pdf/2506.07087, 2025-06-08
2025-11-11 00:41:10,722 - INFO - root - Page:2, Index:27, BePo: Leveraging Birds Eye View and Sparse Points for Efficient and Accurate 3D Occupancy Prediction, https://arxiv.org/pdf/2506.07002, 2025-06-08
2025-11-11 00:41:10,722 - INFO - root - Page:2, Index:28, Reading in the Dark with Foveated Event Vision, https://arxiv.org/pdf/2506.06918, 2025-06-07
2025-11-11 00:41:10,724 - INFO - root - Page:2, Index:29, NSD-Imagery: A benchmark dataset for extending fMRI vision decoding methods to mental imagery, https://arxiv.org/pdf/2506.06898, 2025-06-07
2025-11-11 00:41:10,724 - INFO - root - Page:2, Index:30, Continuous-Time SO(3) Forecasting with Savitzky--Golay Neural Controlled Differential Equations, https://arxiv.org/pdf/2506.06780, 2025-06-07
2025-11-11 00:41:10,725 - INFO - root - Page:2, Index:31, Generalized Trajectory Scoring for End-to-end Multimodal Planning, https://arxiv.org/pdf/2506.06664, 2025-06-07
2025-11-11 00:41:10,725 - INFO - root - Page:2, Index:32, EV-LayerSegNet: Self-supervised Motion Segmentation using Event Cameras, https://arxiv.org/pdf/2506.06596, 2025-06-06
2025-11-11 00:41:10,725 - INFO - root - Page:2, Index:33, Vid2Sim: Generalizable, Video-based Reconstruction of Appearance, Geometry and Physics for Mesh-free Simulation, https://arxiv.org/pdf/2506.06440, 2025-06-06
2025-11-11 00:41:10,725 - INFO - root - Page:2, Index:34, FADE: Frequency-Aware Diffusion Model Factorization for Video Editing, https://arxiv.org/pdf/2506.05934, 2025-06-06
2025-11-11 00:41:10,726 - INFO - root - Page:2, Index:35, Unleashing the Potential of Consistency Learning for Detecting and Grounding Multi-Modal Media Manipulation, https://arxiv.org/pdf/2506.05890, 2025-06-06
2025-11-11 00:41:10,726 - INFO - root - Page:2, Index:36, DeformCL: Learning Deformable Centerline Representation for Vessel Extraction in 3D Medical Image, https://arxiv.org/pdf/2506.05820, 2025-06-06
2025-11-11 00:41:10,726 - INFO - root - Page:2, Index:37, NTIRE 2025 Challenge on HR Depth from Images of Specular and Transparent Surfaces, https://arxiv.org/pdf/2506.05815, 2025-06-06
2025-11-11 00:41:10,726 - INFO - root - Page:2, Index:38, GazeNLQ @ Ego4D Natural Language Queries Challenge 2025, https://arxiv.org/pdf/2506.05782, 2025-06-06
2025-11-11 00:41:10,727 - INFO - root - Page:2, Index:39, Robust sensor fusion against on-vehicle sensor staleness, https://arxiv.org/pdf/2506.05780, 2025-06-06
2025-11-11 00:41:10,727 - INFO - root - Page:2, Index:40, Where Is The Ball: 3D Ball Trajectory Estimation From 2D Monocular Tracking, https://arxiv.org/pdf/2506.05763, 2025-06-06
2025-11-11 00:41:10,727 - INFO - root - Page:2, Index:41, VoxelSplat: Dynamic Gaussian Splatting as an Effective Loss for Occupancy and Flow Prediction, https://arxiv.org/pdf/2506.05563, 2025-06-05
2025-11-11 00:41:10,728 - INFO - root - Page:2, Index:42, Gen4D: Synthesizing Humans and Scenes in the Wild, https://arxiv.org/pdf/2506.05397, 2025-06-03
2025-11-11 00:41:10,728 - INFO - root - Page:2, Index:43, Attacking Attention of Foundation Models Disrupts Downstream Tasks, https://arxiv.org/pdf/2506.05394, 2025-09-12
2025-11-11 00:41:10,728 - INFO - root - Page:2, Index:44, FreeTimeGS: Free Gaussian Primitives at Anytime and Anywhere for Dynamic Scene Reconstruction, https://arxiv.org/pdf/2506.05348, 2025-06-06
2025-11-11 00:41:10,729 - INFO - root - Page:2, Index:45, LotusFilter: Fast Diverse Nearest Neighbor Search via a Learned Cutoff Table, https://arxiv.org/pdf/2506.04790, 2025-06-05
2025-11-11 00:41:10,729 - INFO - root - Page:2, Index:46, Towards Holistic Visual Quality Assessment of AI-Generated Videos: A LLM-Based Multi-Dimensional Evaluation Model, https://arxiv.org/pdf/2506.04715, 2025-06-11
2025-11-11 00:41:10,729 - INFO - root - Page:2, Index:47, Gradient Inversion Attacks on Parameter-Efficient Fine-Tuning, https://arxiv.org/pdf/2506.04453, 2025-06-04
2025-11-11 00:41:10,729 - INFO - root - Page:2, Index:48, HMAR: Efficient Hierarchical Masked Auto-Regressive Image Generation, https://arxiv.org/pdf/2506.04421, 2025-06-04
2025-11-11 00:41:10,730 - INFO - root - Page:2, Index:49, Visualizing and Controlling Cortical Responses Using Voxel-Weighted Activation Maximization, https://arxiv.org/pdf/2506.04379, 2025-06-04
2025-11-11 00:41:10,730 - INFO - root - Fetching page 4 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=150
2025-11-11 00:41:17,134 - INFO - root - get_all_titles_from_web 
2025-11-11 00:41:17,135 - INFO - root - Page:3, Index:0, FlexGS: Train Once, Deploy Everywhere with Many-in-One Flexible 3D Gaussian Splatting, https://arxiv.org/pdf/2506.04174, 2025-06-04
2025-11-11 00:41:17,135 - INFO - root - Page:3, Index:1, Multi-view Surface Reconstruction Using Normal and Reflectance Cues, https://arxiv.org/pdf/2506.04115, 2025-06-04
2025-11-11 00:41:17,136 - INFO - root - Page:3, Index:2, Vocabulary-free few-shot learning for Vision-Language Models, https://arxiv.org/pdf/2506.04005, 2025-06-04
2025-11-11 00:41:17,136 - INFO - root - Page:3, Index:3, Learning from Noise: Enhancing DNNs for Event-Based Vision through Controlled Noise Injection, https://arxiv.org/pdf/2506.03918, 2025-06-04
2025-11-11 00:41:17,137 - INFO - root - Page:3, Index:4, Video, How Do Your Tokens Merge?, https://arxiv.org/pdf/2506.03885, 2025-06-04
2025-11-11 00:41:17,137 - INFO - root - Page:3, Index:5, OSGNet @ Ego4D Episodic Memory Challenge 2025, https://arxiv.org/pdf/2506.03710, 2025-06-04
2025-11-11 00:41:17,137 - INFO - root - Page:3, Index:6, AetherVision-Bench: An Open-Vocabulary RGB-Infrared Benchmark for Multi-Angle Segmentation across Aerial and Ground Perspectives, https://arxiv.org/pdf/2506.03709, 2025-06-04
2025-11-11 00:41:17,138 - INFO - root - Page:3, Index:7, OV-COAST: Cost Aggregation with Optimal Transport for Open-Vocabulary Semantic Segmentation, https://arxiv.org/pdf/2506.03706, 2025-06-04
2025-11-11 00:41:17,138 - INFO - root - Page:3, Index:8, Generating 6DoF Object Manipulation Trajectories from Action Description in Egocentric Vision, https://arxiv.org/pdf/2506.03605, 2025-06-04
2025-11-11 00:41:17,138 - INFO - root - Page:3, Index:9, SemNav: A Model-Based Planner for Zero-Shot Object Goal Navigation Using Vision-Foundation Models, https://arxiv.org/pdf/2506.03516, 2025-06-03
2025-11-11 00:41:17,139 - INFO - root - Page:3, Index:10, Heterogeneous Skeleton-Based Action Representation Learning, https://arxiv.org/pdf/2506.03481, 2025-06-03
2025-11-11 00:41:17,139 - INFO - root - Page:3, Index:11, Hybrid Ensemble of Segmentation-Assisted Classification and GBDT for Skin Cancer Detection with Engineered Metadata and Synthetic Lesions from ISIC 2024 Non-Dermoscopic 3D-TBP Images, https://arxiv.org/pdf/2506.03420, 2025-06-03
2025-11-11 00:41:17,139 - INFO - root - Page:3, Index:12, Self-Supervised Spatial Correspondence Across Modalities, https://arxiv.org/pdf/2506.03148, 2025-06-03
2025-11-11 00:41:17,143 - INFO - root - Page:3, Index:13, Dense Match Summarization for Faster Two-view Estimation, https://arxiv.org/pdf/2506.02893, 2025-06-03
2025-11-11 00:41:17,144 - INFO - root - Page:3, Index:14, NTIRE 2025 XGC Quality Assessment Challenge: Methods and Results, https://arxiv.org/pdf/2506.02875, 2025-06-03
2025-11-11 00:41:17,146 - INFO - root - Page:3, Index:15, FreeScene: Mixed Graph Diffusion for 3D Scene Synthesis from Free Prompts, https://arxiv.org/pdf/2506.02781, 2025-06-03
2025-11-11 00:41:17,147 - INFO - root - Page:3, Index:16, Technical Report for Ego4D Long-Term Action Anticipation Challenge 2025, https://arxiv.org/pdf/2506.02550, 2025-06-11
2025-11-11 00:41:17,147 - INFO - root - Page:3, Index:17, Probabilistic Online Event Downsampling, https://arxiv.org/pdf/2506.02547, 2025-09-23
2025-11-11 00:41:17,148 - INFO - root - Page:3, Index:18, Towards In-the-wild 3D Plane Reconstruction from a Single Image, https://arxiv.org/pdf/2506.02493, 2025-06-03
2025-11-11 00:41:17,149 - INFO - root - Page:3, Index:19, Efficient Test-time Adaptive Object Detection via Sensitivity-Guided Pruning, https://arxiv.org/pdf/2506.02462, 2025-06-03
2025-11-11 00:41:17,149 - INFO - root - Page:3, Index:20, EgoVIS@CVPR: PAIR-Net: Enhancing Egocentric Speaker Detection via Pretrained Audio-Visual Fusion and Alignment Loss, https://arxiv.org/pdf/2506.02247, 2025-09-26
2025-11-11 00:41:17,150 - INFO - root - Page:3, Index:21, Diff2Flow: Training Flow Matching Models via Diffusion Model Alignment, https://arxiv.org/pdf/2506.02221, 2025-06-02
2025-11-11 00:41:17,150 - INFO - root - Page:3, Index:22, NTIRE 2025 Challenge on RAW Image Restoration and Super-Resolution, https://arxiv.org/pdf/2506.02197, 2025-06-04
2025-11-11 00:41:17,150 - INFO - root - Page:3, Index:23, RAW Image Reconstruction from RGB on Smartphones. NTIRE 2025 Challenge Report, https://arxiv.org/pdf/2506.01947, 2025-06-02
2025-11-11 00:41:17,152 - INFO - root - Page:3, Index:24, Silence is Golden: Leveraging Adversarial Examples to Nullify Audio Control in LDM-based Talking-Head Generation, https://arxiv.org/pdf/2506.01591, 2025-06-02
2025-11-11 00:41:17,152 - INFO - root - Page:3, Index:25, SAM2-LOVE: Segment Anything Model 2 in Language-aided Audio-Visual Scenes, https://arxiv.org/pdf/2506.01558, 2025-06-02
2025-11-11 00:41:17,152 - INFO - root - Page:3, Index:26, Neural shape reconstruction from multiple views with static pattern projection, https://arxiv.org/pdf/2506.01389, 2025-06-02
2025-11-11 00:41:17,152 - INFO - root - Page:3, Index:27, SAM-I2V: Upgrading SAM to Support Promptable Video Segmentation with Less than 0.2% Training Cost, https://arxiv.org/pdf/2506.01304, 2025-06-02
2025-11-11 00:41:17,152 - INFO - root - Page:3, Index:28, Perceptual Inductive Bias Is What You Need Before Contrastive Learning, https://arxiv.org/pdf/2506.01201, 2025-06-01
2025-11-11 00:41:17,153 - INFO - root - Page:3, Index:29, Test Automation for Interactive Scenarios via Promptable Traffic Simulation, https://arxiv.org/pdf/2506.01199, 2025-06-04
2025-11-11 00:41:17,153 - INFO - root - Page:3, Index:30, GraphPad: Inference-Time 3D Scene Graph Updates for Embodied Question Answering, https://arxiv.org/pdf/2506.01174, 2025-06-01
2025-11-11 00:41:17,153 - INFO - root - Page:3, Index:31, Aligned Contrastive Loss for Long-Tailed Recognition, https://arxiv.org/pdf/2506.01071, 2025-06-01
2025-11-11 00:41:17,153 - INFO - root - Page:3, Index:32, Self-supervised ControlNet with Spatio-Temporal Mamba for Real-world Video Super-resolution, https://arxiv.org/pdf/2506.01037, 2025-06-01
2025-11-11 00:41:17,154 - INFO - root - Page:3, Index:33, ArtiScene: Language-Driven Artistic 3D Scene Generation Through Image Intermediary, https://arxiv.org/pdf/2506.00742, 2025-05-31
2025-11-11 00:41:17,154 - INFO - root - Page:3, Index:34, 3D Gaussian Splat Vulnerabilities, https://arxiv.org/pdf/2506.00280, 2025-05-30
2025-11-11 00:41:17,154 - INFO - root - Page:3, Index:35, EgoVIS@CVPR: What Changed and What Could Have Changed? State-Change Counterfactuals for Procedure-Aware Video Representation Learning, https://arxiv.org/pdf/2506.00101, 2025-09-26
2025-11-11 00:41:17,154 - INFO - root - Page:3, Index:36, CL-LoRA: Continual Low-Rank Adaptation for Rehearsal-Free Class-Incremental Learning, https://arxiv.org/pdf/2505.24816, 2025-05-30
2025-11-11 00:41:17,155 - INFO - root - Page:3, Index:37, PatchDEMUX: A Certifiably Robust Framework for Multi-label Classifiers Against Adversarial Patches, https://arxiv.org/pdf/2505.24703, 2025-05-30
2025-11-11 00:41:17,155 - INFO - root - Page:3, Index:38, Conformal Prediction for Zero-Shot Models, https://arxiv.org/pdf/2505.24693, 2025-05-30
2025-11-11 00:41:17,155 - INFO - root - Page:3, Index:39, Learning reusable concepts across different egocentric video understanding tasks, https://arxiv.org/pdf/2505.24690, 2025-05-30
2025-11-11 00:41:17,158 - INFO - root - Page:3, Index:40, Period-LLM: Extending the Periodic Capability of Multimodal Large Language Model, https://arxiv.org/pdf/2505.24476, 2025-05-30
2025-11-11 00:41:17,159 - INFO - root - Page:3, Index:41, PCIE_Interaction Solution for Ego4D Social Interaction Challenge, https://arxiv.org/pdf/2505.24404, 2025-05-30
2025-11-11 00:41:17,159 - INFO - root - Page:3, Index:42, Leadership Assessment in Pediatric Intensive Care Unit Team Training, https://arxiv.org/pdf/2505.24389, 2025-08-28
2025-11-11 00:41:17,159 - INFO - root - Page:3, Index:43, Interpreting Large Text-to-Image Diffusion Models with Dictionary Learning, https://arxiv.org/pdf/2505.24360, 2025-07-10
2025-11-11 00:41:17,160 - INFO - root - Page:3, Index:44, InteractAnything: Zero-shot Human Object Interaction Synthesis via LLM Feedback and Object Affordance Parsing, https://arxiv.org/pdf/2505.24315, 2025-05-30
2025-11-11 00:41:17,161 - INFO - root - Page:3, Index:45, MaskAdapt: Unsupervised Geometry-Aware Domain Adaptation Using Multimodal Contextual Learning and RGB-Depth Masking, https://arxiv.org/pdf/2505.24026, 2025-05-29
2025-11-11 00:41:17,162 - INFO - root - Page:3, Index:46, Argus: Vision-Centric Reasoning with Grounded Chain-of-Thought, https://arxiv.org/pdf/2505.23766, 2025-05-29
2025-11-11 00:41:17,162 - INFO - root - Page:3, Index:47, Sketch Down the FLOPs: Towards Efficient Networks for Human Sketch, https://arxiv.org/pdf/2505.23763, 2025-05-29
2025-11-11 00:41:17,162 - INFO - root - Page:3, Index:48, Boosting Domain Incremental Learning: Selecting the Optimal Parameters is All You Need, https://arxiv.org/pdf/2505.23744, 2025-05-29
2025-11-11 00:41:17,163 - INFO - root - Page:3, Index:49, DA-VPT: Semantic-Guided Visual Prompt Tuning for Vision Transformers, https://arxiv.org/pdf/2505.23694, 2025-06-01
2025-11-11 00:41:17,164 - INFO - root - Fetching page 5 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=200
2025-11-11 00:41:23,349 - INFO - root - get_all_titles_from_web 
2025-11-11 00:41:23,350 - INFO - root - Page:4, Index:0, Bridging Classical and Modern Computer Vision: PerceptiveNet for Tree Crown Semantic Segmentation, https://arxiv.org/pdf/2505.23597, 2025-05-29
2025-11-11 00:41:23,350 - INFO - root - Page:4, Index:1, Synthetic Generation and Latent Projection Denoising of Rim Lesions in Multiple Sclerosis, https://arxiv.org/pdf/2505.23353, 2025-05-29
2025-11-11 00:41:23,350 - INFO - root - Page:4, Index:2, Wav2Sem: Plug-and-Play Audio Semantic Decoupling for 3D Speech-Driven Facial Animation, https://arxiv.org/pdf/2505.23290, 2025-05-29
2025-11-11 00:41:23,350 - INFO - root - Page:4, Index:3, Proximal Algorithm Unrolling: Flexible and Efficient Reconstruction Networks for Single-Pixel Imaging, https://arxiv.org/pdf/2505.23180, 2025-05-29
2025-11-11 00:41:23,351 - INFO - root - Page:4, Index:4, HMAD: Advancing E2E Driving with Anchored Offset Proposals and Simulation-Supervised Multi-target Scoring, https://arxiv.org/pdf/2505.23129, 2025-05-29
2025-11-11 00:41:23,351 - INFO - root - Page:4, Index:5, URWKV: Unified RWKV Model with Multi-state Perspective for Low-light Image Restoration, https://arxiv.org/pdf/2505.23068, 2025-05-29
2025-11-11 00:41:23,351 - INFO - root - Page:4, Index:6, 4DTAM: Non-Rigid Tracking and Mapping via Dynamic Surface Gaussians, https://arxiv.org/pdf/2505.22859, 2025-05-28
2025-11-11 00:41:23,352 - INFO - root - Page:4, Index:7, A Probabilistic Jump-Diffusion Framework for Open-World Egocentric Activity Recognition, https://arxiv.org/pdf/2505.22858, 2025-05-28
2025-11-11 00:41:23,352 - INFO - root - Page:4, Index:8, PS4PRO: Pixel-to-pixel Supervision for Photorealistic Rendering and Optimization, https://arxiv.org/pdf/2505.22616, 2025-05-28
2025-11-11 00:41:23,352 - INFO - root - Page:4, Index:9, Universal Domain Adaptation for Semantic Segmentation, https://arxiv.org/pdf/2505.22458, 2025-06-05
2025-11-11 00:41:23,353 - INFO - root - Page:4, Index:10, Zero-Shot 3D Visual Grounding from Vision-Language Models, https://arxiv.org/pdf/2505.22429, 2025-05-28
2025-11-11 00:41:23,353 - INFO - root - Page:4, Index:11, RC-AutoCalib: An End-to-End Radar-Camera Automatic Calibration Network, https://arxiv.org/pdf/2505.22427, 2025-05-28
2025-11-11 00:41:23,353 - INFO - root - Page:4, Index:12, Bringing CLIP to the Clinic: Dynamic Soft Labels and Negation-Aware Learning for Medical Analysis, https://arxiv.org/pdf/2505.22079, 2025-05-28
2025-11-11 00:41:23,353 - INFO - root - Page:4, Index:13, Point-to-Region Loss for Semi-Supervised Point-Based Crowd Counting, https://arxiv.org/pdf/2505.21943, 2025-05-27
2025-11-11 00:41:23,354 - INFO - root - Page:4, Index:14, FRAMES-VQA: Benchmarking Fine-Tuning Robustness across Multi-Modal Shifts in Visual Question Answering, https://arxiv.org/pdf/2505.21755, 2025-06-20
2025-11-11 00:41:23,354 - INFO - root - Page:4, Index:15, Knowledge Distillation Approach for SOS Fusion Staging: Towards Fully Automated Skeletal Maturity Assessment, https://arxiv.org/pdf/2505.21561, 2025-05-26
2025-11-11 00:41:23,355 - INFO - root - Page:4, Index:16, Enhancing Vision Transformer Explainability Using Artificial Astrocytes, https://arxiv.org/pdf/2505.21513, 2025-05-20
2025-11-11 00:41:23,355 - INFO - root - Page:4, Index:17, Empowering Vector Graphics with Consistently Arbitrary Viewing and View-dependent Visibility, https://arxiv.org/pdf/2505.21377, 2025-05-27
2025-11-11 00:41:23,355 - INFO - root - Page:4, Index:18, Structure from Collision, https://arxiv.org/pdf/2505.21335, 2025-05-27
2025-11-11 00:41:23,355 - INFO - root - Page:4, Index:19, Boosting Adversarial Transferability via High-Frequency Augmentation and Hierarchical-Gradient Fusion, https://arxiv.org/pdf/2505.21181, 2025-05-27
2025-11-11 00:41:23,356 - INFO - root - Page:4, Index:20, RefAV: Towards Planning-Centric Scenario Mining, https://arxiv.org/pdf/2505.20981, 2025-06-18
2025-11-11 00:41:23,356 - INFO - root - Page:4, Index:21, PMA: Towards Parameter-Efficient Point Cloud Understanding via Point Mamba Adapter, https://arxiv.org/pdf/2505.20941, 2025-05-27
2025-11-11 00:41:23,356 - INFO - root - Page:4, Index:22, HuMoCon: Concept Discovery for Human Motion Understanding, https://arxiv.org/pdf/2505.20920, 2025-05-27
2025-11-11 00:41:23,356 - INFO - root - Page:4, Index:23, Exploring Timeline Control for Facial Motion Generation, https://arxiv.org/pdf/2505.20861, 2025-05-27
2025-11-11 00:41:23,357 - INFO - root - Page:4, Index:24, ConText-CIR: Learning from Concepts in Text for Composed Image Retrieval, https://arxiv.org/pdf/2505.20764, 2025-05-27
2025-11-11 00:41:23,357 - INFO - root - Page:4, Index:25, HCQA-1.5 @ Ego4D EgoSchema Challenge 2025, https://arxiv.org/pdf/2505.20644, 2025-05-26
2025-11-11 00:41:23,357 - INFO - root - Page:4, Index:26, Roboflow100-VL: A Multi-Domain Object Detection Benchmark for Vision-Language Models, https://arxiv.org/pdf/2505.20612, 2025-10-22
2025-11-11 00:41:23,357 - INFO - root - Page:4, Index:27, MotionPro: A Precise Motion Controller for Image-to-Video Generation, https://arxiv.org/pdf/2505.20287, 2025-05-26
2025-11-11 00:41:23,357 - INFO - root - Page:4, Index:28, Category-Agnostic Neural Object Rigging, https://arxiv.org/pdf/2505.20283, 2025-05-26
2025-11-11 00:41:23,357 - INFO - root - Page:4, Index:29, Towards Video to Piano Music Generation with Chain-of-Perform Support Benchmarks, https://arxiv.org/pdf/2505.20038, 2025-05-26
2025-11-11 00:41:23,357 - INFO - root - Page:4, Index:30, Can Visual Encoder Learn to See Arrows?, https://arxiv.org/pdf/2505.19944, 2025-05-26
2025-11-11 00:41:23,357 - INFO - root - Page:4, Index:31, GoLF-NRT: Integrating Global Context and Local Geometry for Few-Shot View Synthesis, https://arxiv.org/pdf/2505.19813, 2025-05-26
2025-11-11 00:41:23,359 - INFO - root - Page:4, Index:32, Depth-Guided Bundle Sampling for Efficient Generalizable Neural Radiance Field Reconstruction, https://arxiv.org/pdf/2505.19793, 2025-05-26
2025-11-11 00:41:23,359 - INFO - root - Page:4, Index:33, SuperAD: A Training-free Anomaly Classification and Segmentation Method for CVPR 2025 VAND 3.0 Workshop Challenge Track 1: Adapt & Detect, https://arxiv.org/pdf/2505.19750, 2025-05-27
2025-11-11 00:41:23,359 - INFO - root - Page:4, Index:34, Knowledge-Aligned Counterfactual-Enhancement Diffusion Perception for Unsupervised Cross-Domain Visual Emotion Recognition, https://arxiv.org/pdf/2505.19694, 2025-05-26
2025-11-11 00:41:23,360 - INFO - root - Page:4, Index:35, Rotation-Equivariant Self-Supervised Method in Image Denoising, https://arxiv.org/pdf/2505.19618, 2025-05-26
2025-11-11 00:41:23,360 - INFO - root - Page:4, Index:36, NTIRE 2025 Challenge on Video Quality Enhancement for Video Conferencing: Datasets, Methods and Results, https://arxiv.org/pdf/2505.18988, 2025-05-25
2025-11-11 00:41:23,361 - INFO - root - Page:4, Index:37, Geometry-guided Online 3D Video Synthesis with Multi-View Temporal Consistency, https://arxiv.org/pdf/2505.18932, 2025-05-24
2025-11-11 00:41:23,362 - INFO - root - Page:4, Index:38, Digital Overconsumption and Waste: A Closer Look at the Impacts of Generative AI, https://arxiv.org/pdf/2505.18894, 2025-05-24
2025-11-11 00:41:23,363 - INFO - root - Page:4, Index:39, VISTA: Vision-Language Inference for Training-Free Stock Time-Series Analysis, https://arxiv.org/pdf/2505.18570, 2025-06-11
2025-11-11 00:41:23,366 - INFO - root - Page:4, Index:40, Syn3DTxt: Embedding 3D Cues for Scene Text Generation, https://arxiv.org/pdf/2505.18479, 2025-05-23
2025-11-11 00:41:23,367 - INFO - root - Page:4, Index:41, CTRL-GS: Cascaded Temporal Residue Learning for 4D Gaussian Splatting, https://arxiv.org/pdf/2505.18306, 2025-05-31
2025-11-11 00:41:23,368 - INFO - root - Page:4, Index:42, DualTalk: Dual-Speaker Interaction for 3D Talking Head Conversations, https://arxiv.org/pdf/2505.18096, 2025-05-26
2025-11-11 00:41:23,369 - INFO - root - Page:4, Index:43, SeaLion: Semantic Part-Aware Latent Point Diffusion Models for 3D Generation, https://arxiv.org/pdf/2505.17721, 2025-07-07
2025-11-11 00:41:23,369 - INFO - root - Page:4, Index:44, PoseBH: Prototypical Multi-Dataset Training Beyond Human Pose Estimation, https://arxiv.org/pdf/2505.17475, 2025-05-23
2025-11-11 00:41:23,369 - INFO - root - Page:4, Index:45, Pursuing Temporal-Consistent Video Virtual Try-On via Dynamic Pose Interaction, https://arxiv.org/pdf/2505.16980, 2025-05-22
2025-11-11 00:41:23,369 - INFO - root - Page:4, Index:46, UniPhy: Learning a Unified Constitutive Model for Inverse Physics Simulation, https://arxiv.org/pdf/2505.16971, 2025-05-22
2025-11-11 00:41:23,369 - INFO - root - Page:4, Index:47, Tracking the Flight: Exploring a Computational Framework for Analyzing Escape Responses in Plains Zebra (Equus quagga), https://arxiv.org/pdf/2505.16882, 2025-05-23
2025-11-11 00:41:23,370 - INFO - root - Page:4, Index:48, Semi-Supervised State-Space Model with Dynamic Stacking Filter for Real-World Video Deraining, https://arxiv.org/pdf/2505.16811, 2025-05-22
2025-11-11 00:41:23,370 - INFO - root - Page:4, Index:49, SOLVE: Synergy of Language-Vision and End-to-End Networks for Autonomous Driving, https://arxiv.org/pdf/2505.16805, 2025-05-22
2025-11-11 00:41:23,371 - INFO - root - Fetching page 6 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=250
2025-11-11 00:41:30,431 - INFO - root - get_all_titles_from_web 
2025-11-11 00:41:30,431 - INFO - root - Page:5, Index:0, Four Eyes Are Better Than Two: Harnessing the Collaborative Potential of Large Models via Differentiated Thinking and Complementary Ensembles, https://arxiv.org/pdf/2505.16784, 2025-06-07
2025-11-11 00:41:30,432 - INFO - root - Page:5, Index:1, Single Domain Generalization for Few-Shot Counting via Universal Representation Matching, https://arxiv.org/pdf/2505.16778, 2025-05-22
2025-11-11 00:41:30,432 - INFO - root - Page:5, Index:2, Seeing Far and Clearly: Mitigating Hallucinations in MLLMs with Attention Causal Decoding, https://arxiv.org/pdf/2505.16652, 2025-06-07
2025-11-11 00:41:30,432 - INFO - root - Page:5, Index:3, Sketchy Bounding-box Supervision for 3D Instance Segmentation, https://arxiv.org/pdf/2505.16399, 2025-05-22
2025-11-11 00:41:30,432 - INFO - root - Page:5, Index:4, DeCafNet: Delegate and Conquer for Efficient Temporal Grounding in Long Videos, https://arxiv.org/pdf/2505.16376, 2025-05-22
2025-11-11 00:41:30,432 - INFO - root - Page:5, Index:5, NTIRE 2025 challenge on Text to Image Generation Model Quality Assessment, https://arxiv.org/pdf/2505.16314, 2025-05-22
2025-11-11 00:41:30,433 - INFO - root - Page:5, Index:6, Analyzing Hierarchical Structure in Vision Models with Sparse Autoencoders, https://arxiv.org/pdf/2505.15970, 2025-05-21
2025-11-11 00:41:30,433 - INFO - root - Page:5, Index:7, Efficient Data Driven Mixture-of-Expert Extraction from Trained Networks, https://arxiv.org/pdf/2505.15414, 2025-05-21
2025-11-11 00:41:30,433 - INFO - root - Page:5, Index:8, Mouse Lockbox Dataset: Behavior Recognition for Mice Solving Lockboxes, https://arxiv.org/pdf/2505.15408, 2025-06-17
2025-11-11 00:41:30,433 - INFO - root - Page:5, Index:9, Zero-Shot Gaze-based Volumetric Medical Image Segmentation, https://arxiv.org/pdf/2505.15256, 2025-06-10
2025-11-11 00:41:30,434 - INFO - root - Page:5, Index:10, Dual Precision Quantization for Efficient and Accurate Deep Neural Networks Inference, https://arxiv.org/pdf/2505.14638, 2025-05-20
2025-11-11 00:41:30,434 - INFO - root - Page:5, Index:11, Neural Video Compression with Context Modulation, https://arxiv.org/pdf/2505.14541, 2025-05-20
2025-11-11 00:41:30,434 - INFO - root - Page:5, Index:12, Selective Structured State Space for Multispectral-fused Small Target Detection, https://arxiv.org/pdf/2505.14043, 2025-05-23
2025-11-11 00:41:30,434 - INFO - root - Page:5, Index:13, OmniStyle: Filtering High Quality Style Transfer Data at Scale, https://arxiv.org/pdf/2505.14028, 2025-05-20
2025-11-11 00:41:30,435 - INFO - root - Page:5, Index:14, Domain Adaptation of VLM for Soccer Video Understanding, https://arxiv.org/pdf/2505.13860, 2025-07-07
2025-11-11 00:41:30,435 - INFO - root - Page:5, Index:15, Ground-V: Teaching VLMs to Ground Complex Instructions in Pixels, https://arxiv.org/pdf/2505.13788, 2025-05-19
2025-11-11 00:41:30,435 - INFO - root - Page:5, Index:16, FinePhys: Fine-grained Human Action Generation by Explicitly Incorporating Physical Laws for Effective Skeletal Guidance, https://arxiv.org/pdf/2505.13437, 2025-05-19
2025-11-11 00:41:30,435 - INFO - root - Page:5, Index:17, The Way Up: A Dataset for Hold Usage Detection in Sport Climbing, https://arxiv.org/pdf/2505.12854, 2025-05-19
2025-11-11 00:41:30,436 - INFO - root - Page:5, Index:18, PEER pressure: Model-to-Model Regularization for Single Source Domain Generalization, https://arxiv.org/pdf/2505.12745, 2025-05-19
2025-11-11 00:41:30,437 - INFO - root - Page:5, Index:19, Mamba-Adaptor: State Space Model Adaptor for Visual Recognition, https://arxiv.org/pdf/2505.12685, 2025-05-19
2025-11-11 00:41:30,437 - INFO - root - Page:5, Index:20, Scalable Video-to-Dataset Generation for Cross-Platform Mobile Agents, https://arxiv.org/pdf/2505.12632, 2025-05-18
2025-11-11 00:41:30,437 - INFO - root - Page:5, Index:21, Degradation-Aware Feature Perturbation for All-in-One Image Restoration, https://arxiv.org/pdf/2505.12630, 2025-05-18
2025-11-11 00:41:30,439 - INFO - root - Page:5, Index:22, Guiding Diffusion with Deep Geometric Moments: Balancing Fidelity and Variation, https://arxiv.org/pdf/2505.12486, 2025-05-18
2025-11-11 00:41:30,440 - INFO - root - Page:5, Index:23, Learning to Highlight Audio by Watching Movies, https://arxiv.org/pdf/2505.12154, 2025-05-17
2025-11-11 00:41:30,441 - INFO - root - Page:5, Index:24, Understanding the Capabilities of Molecular Graph Neural Networks in Materials Science Through Multimodal Learning and Physical Context Encoding, https://arxiv.org/pdf/2505.12137, 2025-05-17
2025-11-11 00:41:30,441 - INFO - root - Page:5, Index:25, iSegMan: Interactive Segment-and-Manipulate 3D Gaussians, https://arxiv.org/pdf/2505.11934, 2025-05-17
2025-11-11 00:41:30,441 - INFO - root - Page:5, Index:26, Self-Learning Hyperspectral and Multispectral Image Fusion via Adaptive Residual Guided Subspace Diffusion Model, https://arxiv.org/pdf/2505.11800, 2025-05-16
2025-11-11 00:41:30,442 - INFO - root - Page:5, Index:27, X-Edit: Detecting and Localizing Edits in Images Altered by Text-Guided Diffusion Models, https://arxiv.org/pdf/2505.11753, 2025-05-16
2025-11-11 00:41:30,442 - INFO - root - Page:5, Index:28, MTevent: A Multi-Task Event Camera Dataset for 6D Pose Estimation and Moving Object Detection, https://arxiv.org/pdf/2505.11282, 2025-06-02
2025-11-11 00:41:30,442 - INFO - root - Page:5, Index:29, Imputation-free and Alignment-free: Incomplete Multi-view Clustering Driven by Consensus Semantic Learning, https://arxiv.org/pdf/2505.11182, 2025-05-16
2025-11-11 00:41:30,443 - INFO - root - Page:5, Index:30, MultiLink: Multi-class Structure Recovery via Agglomerative Clustering and Model Selection, https://arxiv.org/pdf/2505.10874, 2025-05-16
2025-11-11 00:41:30,445 - INFO - root - Page:5, Index:31, RefPose: Leveraging Reference Geometric Correspondences for Accurate 6D Pose Estimation of Unseen Objects, https://arxiv.org/pdf/2505.10841, 2025-05-16
2025-11-11 00:41:30,446 - INFO - root - Page:5, Index:32, MoCLIP: Motion-Aware Fine-Tuning and Distillation of CLIP for Human Motion Generation, https://arxiv.org/pdf/2505.10810, 2025-05-15
2025-11-11 00:41:30,446 - INFO - root - Page:5, Index:33, Automated Detection of Salvin's Albatrosses: Improving Deep Learning Tools for Aerial Wildlife Surveys, https://arxiv.org/pdf/2505.10737, 2025-05-15
2025-11-11 00:41:30,446 - INFO - root - Page:5, Index:34, Advancing Multiple Instance Learning with Continual Learning for Whole Slide Imaging, https://arxiv.org/pdf/2505.10649, 2025-05-15
2025-11-11 00:41:30,448 - INFO - root - Page:5, Index:35, Inferring Driving Maps by Deep Learning-based Trail Map Extraction, https://arxiv.org/pdf/2505.10258, 2025-05-15
2025-11-11 00:41:30,448 - INFO - root - Page:5, Index:36, Behind Maya: Building a Multilingual Vision Language Model, https://arxiv.org/pdf/2505.08910, 2025-05-15
2025-11-11 00:41:30,449 - INFO - root - Page:5, Index:37, PosterO: Structuring Layout Trees to Enable Language Models in Generalized Content-Aware Layout Generation, https://arxiv.org/pdf/2505.07843, 2025-05-26
2025-11-11 00:41:30,449 - INFO - root - Page:5, Index:38, Prototype Augmented Hypernetworks for Continual Learning, https://arxiv.org/pdf/2505.07450, 2025-05-16
2025-11-11 00:41:30,450 - INFO - root - Fetching page 7 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=300
2025-11-11 00:41:36,838 - INFO - root - get_all_titles_from_web 
2025-11-11 00:41:36,839 - INFO - root - Page:6, Index:0, Convex Relaxation for Robust Vanishing Point Estimation in Manhattan World, https://arxiv.org/pdf/2505.04788, 2025-06-05
2025-11-11 00:41:36,839 - INFO - root - Page:6, Index:1, S3D: Sketch-Driven 3D Model Generation, https://arxiv.org/pdf/2505.04185, 2025-06-03
2025-11-11 00:41:36,839 - INFO - root - Page:6, Index:2, Generating Synthetic Data via Augmentations for Improved Facial Resemblance in DreamBooth and InstantID, https://arxiv.org/pdf/2505.03557, 2025-07-17
2025-11-11 00:41:36,840 - INFO - root - Page:6, Index:3, CAV-MAE Sync: Improving Contrastive Audio-Visual Mask Autoencoders via Fine-Grained Alignment, https://arxiv.org/pdf/2505.01237, 2025-05-21
2025-11-11 00:41:36,840 - INFO - root - Fetching page 8 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=350
2025-11-11 00:41:43,255 - INFO - root - get_all_titles_from_web 
2025-11-11 00:41:43,256 - INFO - root - Page:7, Index:0, Where's the liability in the Generative Era? Recovery-based Black-Box Detection of AI-Generated Content, https://arxiv.org/pdf/2505.01008, 2025-08-25
2025-11-11 00:41:43,256 - INFO - root - Page:7, Index:1, SpatialLLM: A Compound 3D-Informed Design towards Spatially-Intelligent Large Multimodal Models, https://arxiv.org/pdf/2505.00788, 2025-06-10
2025-11-11 00:41:43,256 - INFO - root - Page:7, Index:2, Prisma: An Open Source Toolkit for Mechanistic Interpretability in Vision and Video, https://arxiv.org/pdf/2504.19475, 2025-06-03
2025-11-11 00:41:43,256 - INFO - root - Page:7, Index:3, SSL4Eco: A Global Seasonal Dataset for Geospatial Foundation Models in Ecology, https://arxiv.org/pdf/2504.18256, 2025-10-20
2025-11-11 00:41:43,258 - INFO - root - Page:7, Index:4, Vision-Language Models Are Not Pragmatically Competent in Referring Expression Generation, https://arxiv.org/pdf/2504.16060, 2025-07-30
2025-11-11 00:41:43,258 - INFO - root - Fetching page 9 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=400
2025-11-11 00:41:49,820 - INFO - root - get_all_titles_from_web 
2025-11-11 00:41:49,821 - INFO - root - Page:8, Index:0, Leveraging Automatic CAD Annotations for Supervised Learning in 3D Scene Understanding, https://arxiv.org/pdf/2504.13580, 2025-05-16
2025-11-11 00:41:49,821 - INFO - root - Page:8, Index:1, CAP-Net: A Unified Network for 6D Pose and Size Estimation of Categorical Articulated Parts from a Single RGB-D Image, https://arxiv.org/pdf/2504.11230, 2025-06-02
2025-11-11 00:41:49,821 - INFO - root - Page:8, Index:2, Video Summarization with Large Language Models, https://arxiv.org/pdf/2504.11199, 2025-06-05
2025-11-11 00:41:49,822 - INFO - root - Page:8, Index:3, R-TPT: Improving Adversarial Robustness of Vision-Language Models through Test-Time Prompt Tuning, https://arxiv.org/pdf/2504.11195, 2025-08-27
2025-11-11 00:41:49,823 - INFO - root - Page:8, Index:4, TerraMesh: A Planetary Mosaic of Multimodal Earth Observation Data, https://arxiv.org/pdf/2504.11172, 2025-08-01
2025-11-11 00:41:49,824 - INFO - root - Page:8, Index:5, Seeing like a Cephalopod: Colour Vision with a Monochrome Event Camera, https://arxiv.org/pdf/2504.10984, 2025-06-06
2025-11-11 00:41:49,824 - INFO - root - Page:8, Index:6, Hearing Anywhere in Any Environment, https://arxiv.org/pdf/2504.10746, 2025-06-04
2025-11-11 00:41:49,824 - INFO - root - Fetching page 10 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=450
2025-11-11 00:41:56,428 - INFO - root - get_all_titles_from_web 
2025-11-11 00:41:56,430 - INFO - root - Page:9, Index:0, Correlative and Discriminative Label Grouping for Multi-Label Visual Prompt Tuning, https://arxiv.org/pdf/2504.09990, 2025-07-09
2025-11-11 00:41:56,431 - INFO - root - Page:9, Index:1, SPICE: A Synergistic, Precise, Iterative, and Customizable Image Editing Workflow, https://arxiv.org/pdf/2504.09697, 2025-10-16
2025-11-11 00:41:56,432 - INFO - root - Page:9, Index:2, Mimic In-Context Learning for Multimodal Tasks, https://arxiv.org/pdf/2504.08851, 2025-05-17
2025-11-11 00:41:56,433 - INFO - root - Page:9, Index:3, Digital Twin Catalog: A Large-Scale Photorealistic 3D Object Digital Twin Dataset, https://arxiv.org/pdf/2504.08541, 2025-05-18
2025-11-11 00:41:56,433 - INFO - root - Page:9, Index:4, MMLA: Multi-Environment, Multi-Species, Low-Altitude Drone Dataset, https://arxiv.org/pdf/2504.07744, 2025-10-22
2025-11-11 00:41:56,434 - INFO - root - Fetching page 11 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=500
2025-11-11 00:42:02,681 - INFO - root - get_all_titles_from_web 
2025-11-11 00:42:02,681 - INFO - root - Page:10, Index:0, PromptHMR: Promptable Human Mesh Recovery, https://arxiv.org/pdf/2504.06397, 2025-05-23
2025-11-11 00:42:02,681 - INFO - root - Page:10, Index:1, SCAM: A Real-World Typographic Robustness Evaluation for Multimodal Foundation Models, https://arxiv.org/pdf/2504.04893, 2025-09-26
2025-11-11 00:42:02,682 - INFO - root - Fetching page 12 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=550
2025-11-11 00:42:09,214 - INFO - root - get_all_titles_from_web 
2025-11-11 00:42:09,214 - INFO - root - Page:11, Index:0, Charm: The Missing Piece in ViT fine-tuning for Image Aesthetic Assessment, https://arxiv.org/pdf/2504.02522, 2025-05-15
2025-11-11 00:42:09,215 - INFO - root - Page:11, Index:1, T*: Re-thinking Temporal Search for Long-Form Video Understanding, https://arxiv.org/pdf/2504.02259, 2025-08-24
2025-11-11 00:42:09,216 - INFO - root - Page:11, Index:2, CoMatcher: Multi-View Collaborative Feature Matching, https://arxiv.org/pdf/2504.01872, 2025-08-20
2025-11-11 00:42:09,216 - INFO - root - Page:11, Index:3, Think Small, Act Big: Primitive Prompt Learning for Lifelong Robot Manipulation, https://arxiv.org/pdf/2504.00420, 2025-06-01
2025-11-11 00:42:09,216 - INFO - root - Fetching page 13 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=600
2025-11-11 00:42:15,708 - INFO - root - get_all_titles_from_web 
2025-11-11 00:42:15,708 - INFO - root - Page:12, Index:0, It's a (Blind) Match! Towards Vision-Language Correspondence without Parallel Data, https://arxiv.org/pdf/2503.24129, 2025-05-29
2025-11-11 00:42:15,709 - INFO - root - Page:12, Index:1, ReferDINO-Plus: 2nd Solution for 4th PVUW MeViS Challenge at CVPR 2025, https://arxiv.org/pdf/2503.23509, 2025-05-29
2025-11-11 00:42:15,709 - INFO - root - Page:12, Index:2, A Unified Image-Dense Annotation Generation Model for Underwater Scenes, https://arxiv.org/pdf/2503.21771, 2025-07-27
2025-11-11 00:42:15,709 - INFO - root - Fetching page 14 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=650
2025-11-11 00:42:21,984 - INFO - root - get_all_titles_from_web 
2025-11-11 00:42:21,985 - INFO - root - Page:13, Index:0, Learning Class Prototypes for Unified Sparse Supervised 3D Object Detection, https://arxiv.org/pdf/2503.21099, 2025-06-13
2025-11-11 00:42:21,985 - INFO - root - Page:13, Index:1, LATTE-MV: Learning to Anticipate Table Tennis Hits from Monocular Videos, https://arxiv.org/pdf/2503.20936, 2025-09-01
2025-11-11 00:42:21,985 - INFO - root - Page:13, Index:2, BizGen: Advancing Article-level Visual Text Rendering for Infographics Generation, https://arxiv.org/pdf/2503.20672, 2025-07-02
2025-11-11 00:42:21,985 - INFO - root - Page:13, Index:3, ITA-MDT: Image-Timestep-Adaptive Masked Diffusion Transformer Framework for Image-Based Virtual Try-On, https://arxiv.org/pdf/2503.20418, 2025-06-01
2025-11-11 00:42:21,986 - INFO - root - Page:13, Index:4, Faster Parameter-Efficient Tuning with Token Redundancy Reduction, https://arxiv.org/pdf/2503.20282, 2025-08-26
2025-11-11 00:42:21,987 - INFO - root - Page:13, Index:5, DINeMo: Learning Neural Mesh Models with no 3D Annotations, https://arxiv.org/pdf/2503.20220, 2025-06-09
2025-11-11 00:42:21,987 - INFO - root - Page:13, Index:6, Scaling Vision Pre-Training to 4K Resolution, https://arxiv.org/pdf/2503.19903, 2025-08-03
2025-11-11 00:42:21,987 - INFO - root - Page:13, Index:7, GENIUS: A Generative Framework for Universal Multimodal Search, https://arxiv.org/pdf/2503.19868, 2025-06-05
2025-11-11 00:42:21,987 - INFO - root - Fetching page 15 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=700
2025-11-11 00:42:28,685 - INFO - root - get_all_titles_from_web 
2025-11-11 00:42:28,686 - INFO - root - Page:14, Index:0, Galaxy Walker: Geometry-aware VLMs For Galaxy-scale Understanding, https://arxiv.org/pdf/2503.18578, 2025-05-25
2025-11-11 00:42:28,686 - INFO - root - Page:14, Index:1, LookCloser: Frequency-aware Radiance Field for Tiny-Detail Scene, https://arxiv.org/pdf/2503.18513, 2025-07-29
2025-11-11 00:42:28,686 - INFO - root - Fetching page 16 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=750
2025-11-11 00:42:35,624 - INFO - root - get_all_titles_from_web 
2025-11-11 00:42:35,624 - INFO - root - Page:15, Index:0, LoTUS: Large-Scale Machine Unlearning with a Taste of Uncertainty, https://arxiv.org/pdf/2503.18314, 2025-05-29
2025-11-11 00:42:35,625 - INFO - root - Page:15, Index:1, MammAlps: A multi-view video behavior monitoring dataset of wild mammals in the Swiss Alps, https://arxiv.org/pdf/2503.18223, 2025-06-04
2025-11-11 00:42:35,625 - INFO - root - Page:15, Index:2, Progressive Prompt Detailing for Improved Alignment in Text-to-Image Generative Models, https://arxiv.org/pdf/2503.17794, 2025-05-30
2025-11-11 00:42:35,625 - INFO - root - Page:15, Index:3, CountLLM: Towards Generalizable Repetitive Action Counting via Large Language Model, https://arxiv.org/pdf/2503.17690, 2025-06-29
2025-11-11 00:42:35,625 - INFO - root - Page:15, Index:4, TaoAvatar: Real-Time Lifelike Full-Body Talking Avatars for Augmented Reality via 3D Gaussian Splatting, https://arxiv.org/pdf/2503.17032, 2025-07-23
2025-11-11 00:42:35,626 - INFO - root - Page:15, Index:5, Generalized Few-shot 3D Point Cloud Segmentation with Vision-Language Model, https://arxiv.org/pdf/2503.16282, 2025-05-20
2025-11-11 00:42:35,626 - INFO - root - Fetching page 17 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=800
2025-11-11 00:42:43,013 - INFO - root - get_all_titles_from_web 
2025-11-11 00:42:43,013 - INFO - root - Page:16, Index:0, High Temporal Consistency through Semantic Similarity Propagation in Semi-Supervised Video Semantic Segmentation for Autonomous Flight, https://arxiv.org/pdf/2503.15676, 2025-06-26
2025-11-11 00:42:43,014 - INFO - root - Page:16, Index:1, DPFlow: Adaptive Optical Flow Estimation with a Dual-Pyramid Framework, https://arxiv.org/pdf/2503.14880, 2025-09-29
2025-11-11 00:42:43,014 - INFO - root - Fetching page 18 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=850
2025-11-11 00:42:49,802 - INFO - root - get_all_titles_from_web 
2025-11-11 00:42:49,803 - INFO - root - Page:17, Index:0, From Head to Tail: Towards Balanced Representation in Large Vision-Language Models through Adaptive Data Calibration, https://arxiv.org/pdf/2503.12821, 2025-05-29
2025-11-11 00:42:49,803 - INFO - root - Page:17, Index:1, MambaIC: State Space Models for High-Performance Learned Image Compression, https://arxiv.org/pdf/2503.12461, 2025-08-22
2025-11-11 00:42:49,804 - INFO - root - Page:17, Index:2, Localized Concept Erasure for Text-to-Image Diffusion Models Using Training-Free Gated Low-Rank Adaptation, https://arxiv.org/pdf/2503.12356, 2025-07-09
2025-11-11 00:42:49,804 - INFO - root - Page:17, Index:3, TASTE-Rob: Advancing Video Generation of Task-Oriented Hand-Object Interaction for Generalizable Robotic Manipulation, https://arxiv.org/pdf/2503.11423, 2025-06-05
2025-11-11 00:42:49,804 - INFO - root - Page:17, Index:4, Panopticon: Advancing Any-Sensor Foundation Models for Earth Observation, https://arxiv.org/pdf/2503.10845, 2025-08-01
2025-11-11 00:42:49,804 - INFO - root - Page:17, Index:5, Transformers without Normalization, https://arxiv.org/pdf/2503.10622, 2025-06-14
2025-11-11 00:42:49,805 - INFO - root - Page:17, Index:6, dFLMoE: Decentralized Federated Learning via Mixture of Experts for Medical Data Analysis, https://arxiv.org/pdf/2503.10412, 2025-05-19
2025-11-11 00:42:49,805 - INFO - root - Fetching page 19 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=900
2025-11-11 00:42:57,013 - INFO - root - get_all_titles_from_web 
2025-11-11 00:42:57,014 - INFO - root - Page:18, Index:0, Project-Probe-Aggregate: Efficient Fine-Tuning for Group Robustness, https://arxiv.org/pdf/2503.09487, 2025-08-26
2025-11-11 00:42:57,014 - INFO - root - Page:18, Index:1, VLog: Video-Language Models by Generative Retrieval of Narration Vocabulary, https://arxiv.org/pdf/2503.09402, 2025-06-09
2025-11-11 00:42:57,014 - INFO - root - Fetching page 20 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=950
2025-11-11 00:43:03,218 - INFO - root - get_all_titles_from_web 
2025-11-11 00:43:03,219 - INFO - root - Page:19, Index:0, Escaping Plato's Cave: Towards the Alignment of 3D and Text Latent Spaces, https://arxiv.org/pdf/2503.05283, 2025-06-04
2025-11-11 00:43:03,219 - INFO - root - Page:19, Index:1, FluidNexus: 3D Fluid Reconstruction and Prediction from a Single Video, https://arxiv.org/pdf/2503.04720, 2025-07-09
2025-11-11 00:43:03,219 - INFO - root - Page:19, Index:2, Question-Aware Gaussian Experts for Audio-Visual Question Answering, https://arxiv.org/pdf/2503.04459, 2025-06-11
2025-11-11 00:43:03,219 - INFO - root - Page:19, Index:3, Q-Eval-100K: Evaluating Visual Quality and Alignment Level for Text-to-Vision Content, https://arxiv.org/pdf/2503.02357, 2025-06-15
2025-11-11 00:43:03,220 - INFO - root - Fetching page 21 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=1000
2025-11-11 00:43:09,628 - INFO - root - get_all_titles_from_web 
2025-11-11 00:43:09,628 - INFO - root - Page:20, Index:0, Data Distributional Properties As Inductive Bias for Systematic Generalization, https://arxiv.org/pdf/2502.20499, 2025-06-17
2025-11-11 00:43:09,629 - INFO - root - Page:20, Index:1, Knowledge Bridger: Towards Training-free Missing Modality Completion, https://arxiv.org/pdf/2502.19834, 2025-06-17
2025-11-11 00:43:09,629 - INFO - root - Fetching page 22 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=1050
2025-11-11 00:43:16,773 - INFO - root - get_all_titles_from_web 
2025-11-11 00:43:16,773 - INFO - root - Page:21, Index:0, MALT Diffusion: Memory-Augmented Latent Transformers for Any-Length Video Generation, https://arxiv.org/pdf/2502.12632, 2025-07-08
2025-11-11 00:43:16,774 - INFO - root - Page:21, Index:1, ILIAS: Instance-Level Image retrieval At Scale, https://arxiv.org/pdf/2502.11748, 2025-06-23
2025-11-11 00:43:16,774 - INFO - root - Page:21, Index:2, Distraction is All You Need for Multimodal Large Language Model Jailbreaking, https://arxiv.org/pdf/2502.10794, 2025-06-16
2025-11-11 00:43:16,774 - INFO - root - Page:21, Index:3, Spatial457: A Diagnostic Benchmark for 6D Spatial Reasoning of Large Multimodal Models, https://arxiv.org/pdf/2502.08636, 2025-06-08
2025-11-11 00:43:16,774 - INFO - root - Page:21, Index:4, TRAVEL: Training-Free Retrieval and Alignment for Vision-and-Language Navigation, https://arxiv.org/pdf/2502.07306, 2025-06-09
2025-11-11 00:43:16,775 - INFO - root - Page:21, Index:5, DiTASK: Multi-Task Fine-Tuning with Diffeomorphic Transformations, https://arxiv.org/pdf/2502.06029, 2025-06-01
2025-11-11 00:43:16,775 - INFO - root - Page:21, Index:6, ConceptAttention: Diffusion Transformers Learn Highly Interpretable Features, https://arxiv.org/pdf/2502.04320, 2025-07-01
2025-11-11 00:43:16,776 - INFO - root - Page:21, Index:7, GCE-Pose: Global Context Enhancement for Category-level Object Pose Estimation, https://arxiv.org/pdf/2502.04293, 2025-06-24
2025-11-11 00:43:16,776 - INFO - root - Page:21, Index:8, Calibrated Multi-Preference Optimization for Aligning Diffusion Models, https://arxiv.org/pdf/2502.02588, 2025-09-26
2025-11-11 00:43:16,777 - INFO - root - Page:21, Index:9, Instruct-4DGS: Efficient Dynamic Scene Editing via 4D Gaussian-based Static-Dynamic Separation, https://arxiv.org/pdf/2502.02091, 2025-07-01
2025-11-11 00:43:16,777 - INFO - root - Page:21, Index:10, Low-Resource Video Super-Resolution using Memory, Wavelets, and Deformable Convolutions, https://arxiv.org/pdf/2502.01816, 2025-06-19
2025-11-11 00:43:16,778 - INFO - root - Page:21, Index:11, Bridging Text and Crystal Structures: Literature-driven Contrastive Learning for Materials Science, https://arxiv.org/pdf/2501.12919, 2025-06-18
2025-11-11 00:43:16,778 - INFO - root - Page:21, Index:12, T2ISafety: Benchmark for Assessing Fairness, Toxicity, and Privacy in Image Generation, https://arxiv.org/pdf/2501.12612, 2025-07-25
2025-11-11 00:43:16,780 - INFO - root - Page:21, Index:13, Fine-Grained Image-Text Correspondence with Cost Aggregation for Open-Vocabulary Part Segmentation, https://arxiv.org/pdf/2501.09688, 2025-08-08
2025-11-11 00:43:16,780 - INFO - root - Fetching page 23 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=1100
2025-11-11 00:43:23,053 - INFO - root - get_all_titles_from_web 
2025-11-11 00:43:23,054 - INFO - root - Page:22, Index:0, Bias for Action: Video Implicit Neural Representations with Bias Modulation, https://arxiv.org/pdf/2501.09277, 2025-06-06
2025-11-11 00:43:23,054 - INFO - root - Page:22, Index:1, MonSter++: Unified Stereo Matching, Multi-view Stereo, and Real-time Stereo with Monodepth Priors, https://arxiv.org/pdf/2501.08643, 2025-09-25
2025-11-11 00:43:23,054 - INFO - root - Page:22, Index:2, Go-with-the-Flow: Motion-Controllable Video Diffusion Models Using Real-Time Warped Noise, https://arxiv.org/pdf/2501.08331, 2025-08-06
2025-11-11 00:43:23,054 - INFO - root - Page:22, Index:3, Nonisotropic Gaussian Diffusion for Realistic 3D Human Motion Prediction, https://arxiv.org/pdf/2501.06035, 2025-07-08
2025-11-11 00:43:23,055 - INFO - root - Page:22, Index:4, Discovering Hidden Visual Concepts Beyond Linguistic Input in Infant Learning, https://arxiv.org/pdf/2501.05205, 2025-06-13
2025-11-11 00:43:23,055 - INFO - root - Page:22, Index:5, PERSE: Personalized 3D Generative Avatars from A Single Portrait, https://arxiv.org/pdf/2412.21206, 2025-09-28
2025-11-11 00:43:23,055 - INFO - root - Page:22, Index:6, MaskGaussian: Adaptive 3D Gaussian Representation from Probabilistic Masks, https://arxiv.org/pdf/2412.20522, 2025-06-14
2025-11-11 00:43:23,056 - INFO - root - Page:22, Index:7, SimLTD: Simple Supervised and Semi-Supervised Long-Tailed Object Detection, https://arxiv.org/pdf/2412.20047, 2025-06-09
2025-11-11 00:43:23,056 - INFO - root - Page:22, Index:8, Conditional Balance: Improving Multi-Conditioning Trade-Offs in Image Generation, https://arxiv.org/pdf/2412.19853, 2025-08-03
2025-11-11 00:43:23,056 - INFO - root - Fetching page 24 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=1150
2025-11-11 00:43:29,695 - INFO - root - get_all_titles_from_web 
2025-11-11 00:43:29,696 - INFO - root - Page:23, Index:0, CoCoGaussian: Leveraging Circle of Confusion for Gaussian Splatting from Defocused Images, https://arxiv.org/pdf/2412.16028, 2025-05-15
2025-11-11 00:43:29,696 - INFO - root - Page:23, Index:1, EnergyMoGen: Compositional Human Motion Generation with Energy-Based Diffusion Model in Latent Space, https://arxiv.org/pdf/2412.14706, 2025-06-04
2025-11-11 00:43:29,696 - INFO - root - Page:23, Index:2, DarkIR: Robust Low-Light Image Restoration, https://arxiv.org/pdf/2412.13443, 2025-10-14
2025-11-11 00:43:29,697 - INFO - root - Page:23, Index:3, FastVLM: Efficient Vision Encoding for Vision Language Models, https://arxiv.org/pdf/2412.13303, 2025-05-15
2025-11-11 00:43:29,697 - INFO - root - Page:23, Index:4, Real-time Free-view Human Rendering from Sparse-view RGB Videos using Double Unprojected Textures, https://arxiv.org/pdf/2412.13183, 2025-06-20
2025-11-11 00:43:29,697 - INFO - root - Page:23, Index:5, CondiMen: Conditional Multi-Person Mesh Recovery, https://arxiv.org/pdf/2412.13058, 2025-06-04
2025-11-11 00:43:29,697 - INFO - root - Page:23, Index:6, MASt3R-SLAM: Real-Time Dense SLAM with 3D Reconstruction Priors, https://arxiv.org/pdf/2412.12392, 2025-06-02
2025-11-11 00:43:29,697 - INFO - root - Page:23, Index:7, DynamicScaler: Seamless and Scalable Video Generation for Panoramic Scenes, https://arxiv.org/pdf/2412.11100, 2025-10-04
2025-11-11 00:43:29,697 - INFO - root - Page:23, Index:8, SnapGen-V: Generating a Five-Second Video within Five Seconds on a Mobile Device, https://arxiv.org/pdf/2412.10494, 2025-06-09
2025-11-11 00:43:29,698 - INFO - root - Page:23, Index:9, Mr. DETR++: Instructive Multi-Route Training for Detection Transformers with Mixture-of-Experts, https://arxiv.org/pdf/2412.10028, 2025-06-26
2025-11-11 00:43:29,698 - INFO - root - Page:23, Index:10, LinGen: Towards High-Resolution Minute-Length Text-to-Video Generation with Linear Computational Complexity, https://arxiv.org/pdf/2412.09856, 2025-05-24
2025-11-11 00:43:29,698 - INFO - root - Page:23, Index:11, Gaze-LLE: Gaze Target Estimation via Large-Scale Learned Encoders, https://arxiv.org/pdf/2412.09586, 2025-06-03
2025-11-11 00:43:29,698 - INFO - root - Fetching page 25 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=1200
2025-11-11 00:43:36,519 - INFO - root - get_all_titles_from_web 
2025-11-11 00:43:36,519 - INFO - root - Page:24, Index:0, From Slow Bidirectional to Fast Autoregressive Video Diffusion Models, https://arxiv.org/pdf/2412.07772, 2025-09-23
2025-11-11 00:43:36,520 - INFO - root - Page:24, Index:1, Rate-In: Information-Driven Adaptive Dropout Rates for Improved Inference-Time Uncertainty Estimation, https://arxiv.org/pdf/2412.07169, 2025-06-03
2025-11-11 00:43:36,520 - INFO - root - Page:24, Index:2, FIRE: Robust Detection of Diffusion-Generated Images via Frequency-Guided Reconstruction Error, https://arxiv.org/pdf/2412.07140, 2025-11-03
2025-11-11 00:43:36,520 - INFO - root - Page:24, Index:3, Birth and Death of a Rose, https://arxiv.org/pdf/2412.05278, 2025-06-05
2025-11-11 00:43:36,520 - INFO - root - Page:24, Index:4, DualPM: Dual Posed-Canonical Point Maps for 3D Shape and Pose Reconstruction, https://arxiv.org/pdf/2412.04464, 2025-08-14
2025-11-11 00:43:36,521 - INFO - root - Page:24, Index:5, SeeGround: See and Ground for Zero-Shot Open-Vocabulary 3D Visual Grounding, https://arxiv.org/pdf/2412.04383, 2025-05-29
2025-11-11 00:43:36,521 - INFO - root - ------------------------------------------------------------------------------------------------------------------------
2025-11-11 00:43:36,526 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\CVPR 2025\Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness.pdf
2025-11-11 00:43:36,548 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\CVPR 2025\OmniTrack++_ Omnidirectional Multi-Object Tracking by Learning Large-FoV Traject.pdf
2025-11-11 00:43:36,550 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\CVPR 2025\NeuCo-Bench_ A Novel Benchmark Framework for Neural Embeddings in Earth Observat.pdf
2025-11-11 00:43:36,551 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\CVPR 2025\NTIRE 2025 Challenge on Low Light Image Enhancement_ Methods and Results.pdf
2025-11-11 00:43:36,551 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\CVPR 2025\Class Prototypes based Contrastive Learning for Classifying Multi-Label and Fine.pdf
2025-11-11 00:43:36,553 - INFO - root - 跳过已处理论文 Learning to Seek Evidence: A Verifiable Reasoning Agent with Causal Faithfulness Analysis：d:\ChatPaper\academic Papers\CVPR 2025\Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness.pdf
2025-11-11 00:43:36,553 - INFO - root - 跳过已处理论文 OmniTrack++: Omnidirectional Multi-Object Tracking by Learning Large-FoV Trajectory Feedback：d:\ChatPaper\academic Papers\CVPR 2025\OmniTrack++_ Omnidirectional Multi-Object Tracking by Learning Large-FoV Traject.pdf
2025-11-11 00:43:36,555 - INFO - root - 正在总结论文 3/5: NeuCo-Bench: A Novel Benchmark Framework for Neural Embeddings in Earth Observation
2025-11-11 00:44:19,194 - INFO - root - LLMClient: rate limit reached, sleeping 17.4s
2025-11-11 00:44:59,217 - INFO - root - 正在提取论文图片...
2025-11-11 00:45:01,118 - INFO - root - 已保存图片 1/10：./export\CVPR\images\figure_1_page30.png
2025-11-11 00:45:01,252 - INFO - root - 已保存图片 2/10：./export\CVPR\images\figure_2_page33.png
2025-11-11 00:45:01,373 - INFO - root - 已保存图片 3/10：./export\CVPR\images\figure_3_page33.png
2025-11-11 00:45:01,469 - INFO - root - 已保存图片 4/10：./export\CVPR\images\figure_4_page30.jpeg
2025-11-11 00:45:01,580 - INFO - root - 已保存图片 5/10：./export\CVPR\images\figure_5_page24.png
2025-11-11 00:45:01,654 - INFO - root - 已保存图片 6/10：./export\CVPR\images\figure_6_page34.png
2025-11-11 00:45:01,720 - INFO - root - 已保存图片 7/10：./export\CVPR\images\figure_7_page32.png
2025-11-11 00:45:01,753 - INFO - root - 已保存图片 8/10：./export\CVPR\images\figure_8_page29.jpeg
2025-11-11 00:45:01,788 - INFO - root - 已保存图片 9/10：./export\CVPR\images\figure_9_page29.jpeg
2025-11-11 00:45:01,819 - INFO - root - 已保存图片 10/10：./export\CVPR\images\figure_10_page29.jpeg
2025-11-11 00:45:01,835 - INFO - root - 成功添加图片 1：./export\CVPR\images\figure_1_page30.png
2025-11-11 00:45:01,835 - INFO - root - 成功添加图片 2：./export\CVPR\images\figure_2_page33.png
2025-11-11 00:45:01,836 - INFO - root - 成功添加图片 3：./export\CVPR\images\figure_3_page33.png
2025-11-11 00:45:01,836 - INFO - root - 成功添加图片 4：./export\CVPR\images\figure_4_page30.jpeg
2025-11-11 00:45:01,837 - INFO - root - 成功添加图片 5：./export\CVPR\images\figure_5_page24.png
2025-11-11 00:45:01,837 - INFO - root - 成功添加图片 6：./export\CVPR\images\figure_6_page34.png
2025-11-11 00:45:01,839 - INFO - root - 成功添加图片 7：./export\CVPR\images\figure_7_page32.png
2025-11-11 00:45:01,839 - INFO - root - 成功添加图片 8：./export\CVPR\images\figure_8_page29.jpeg
2025-11-11 00:45:01,839 - INFO - root - 成功添加图片 9：./export\CVPR\images\figure_9_page29.jpeg
2025-11-11 00:45:01,840 - INFO - root - 成功添加图片 10：./export\CVPR\images\figure_10_page29.jpeg
2025-11-11 00:45:01,843 - INFO - root - 论文《NeuCo-Bench: A Novel Benchmark Framework for Neural Embeddings in Earth Observation》的分析已保存到 ./export\CVPR\NeuCo-Bench_ A Novel Benchmark Framework for Neural Embeddings in Earth Observat.md
2025-11-11 00:45:01,847 - INFO - root - 正在总结论文 4/5: NTIRE 2025 Challenge on Low Light Image Enhancement: Methods and Results
2025-11-11 00:51:35,083 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-11 00:51:35,085 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-11 00:51:35,088 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-11 00:51:36,445 - INFO - root - LLMClientManager: 指定使用客户端: Gemini
2025-11-11 00:51:37,869 - INFO - root - GeminiClient: trying model models/gemini-2.5-flash
2025-11-11 00:51:45,253 - INFO - root - GeminiClient: initialized model gemini-2.5-flash
2025-11-11 00:51:45,394 - INFO - root - LLMClientManager: Gemini 客户端初始化成功
2025-11-11 00:51:45,475 - INFO - root - LLMClientManager: switched to Gemini client
2025-11-11 00:51:45,489 - INFO - root - 已手动切换到 LLM 客户端: Gemini
2025-11-11 00:51:45,493 - INFO - root - 使用 LLM 模型: gemini-2.5-flash
2025-11-11 00:51:45,504 - INFO - root - 可用客户端: ['Gemini']
2025-11-11 00:51:45,505 - INFO - root - === 运行配置 ===
2025-11-11 00:51:45,506 - INFO - root - 处理模式: arxiv在线搜索
2025-11-11 00:51:45,507 - INFO - root - 关键词: CVPR
2025-11-11 00:51:45,508 - INFO - root - 查询: CVPR 2025
2025-11-11 00:51:45,508 - INFO - root - 排序: None
2025-11-11 00:51:45,512 - INFO - root - 最近天数: 180
2025-11-11 00:51:45,513 - INFO - root - 最大处理数量: 5
2025-11-11 00:51:45,513 - INFO - root - 保存图片: 是
2025-11-11 00:51:45,514 - INFO - root - 输出语言: 中文
2025-11-11 00:51:45,522 - INFO - root - 强制重新处理: 否
2025-11-11 00:51:45,523 - INFO - root - ====================
2025-11-11 00:51:45,524 - INFO - root - 使用 arXiv 搜索模式（通过 chat_arxiv 模块获取）
2025-11-11 00:51:45,525 - INFO - root - Fetching page 1 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50
2025-11-11 00:51:55,470 - INFO - root - get_all_titles_from_web 
2025-11-11 00:51:55,470 - INFO - root - Page:0, Index:0, Learning to Seek Evidence: A Verifiable Reasoning Agent with Causal Faithfulness Analysis, https://arxiv.org/pdf/2511.01425, 2025-11-03
2025-11-11 00:51:55,472 - INFO - root - Page:0, Index:1, OmniTrack++: Omnidirectional Multi-Object Tracking by Learning Large-FoV Trajectory Feedback, https://arxiv.org/pdf/2511.00510, 2025-11-01
2025-11-11 00:51:55,472 - INFO - root - Page:0, Index:2, NeuCo-Bench: A Novel Benchmark Framework for Neural Embeddings in Earth Observation, https://arxiv.org/pdf/2510.17914, 2025-10-19
2025-11-11 00:51:55,472 - INFO - root - Page:0, Index:3, NTIRE 2025 Challenge on Low Light Image Enhancement: Methods and Results, https://arxiv.org/pdf/2510.13670, 2025-10-15
2025-11-11 00:51:55,472 - INFO - root - Page:0, Index:4, Class Prototypes based Contrastive Learning for Classifying Multi-Label and Fine-Grained Educational Videos, https://arxiv.org/pdf/2510.11204, 2025-10-13
2025-11-11 00:51:55,473 - INFO - root - Page:0, Index:5, MIMO: A medical vision language model with visual referring multimodal input and pixel grounding multimodal output, https://arxiv.org/pdf/2510.10011, 2025-10-11
2025-11-11 00:51:55,473 - INFO - root - Page:0, Index:6, Vision Language Models: A Survey of 26K Papers, https://arxiv.org/pdf/2510.09586, 2025-10-10
2025-11-11 00:51:55,473 - INFO - root - Page:0, Index:7, DiT-VTON: Diffusion Transformer Framework for Unified Multi-Category Virtual Try-On and Virtual Try-All with Integrated Image Editing, https://arxiv.org/pdf/2510.04797, 2025-10-03
2025-11-11 00:51:55,473 - INFO - root - Page:0, Index:8, PatchVSR: Breaking Video Diffusion Resolution Limits with Patch-wise Video Super-Resolution, https://arxiv.org/pdf/2509.26025, 2025-09-30
2025-11-11 00:51:55,474 - INFO - root - Page:0, Index:9, FreqDebias: Towards Generalizable Deepfake Detection via Consistency-Driven Frequency Debiasing, https://arxiv.org/pdf/2509.22412, 2025-09-26
2025-11-11 00:51:55,474 - INFO - root - Page:0, Index:10, A Mutual Learning Method for Salient Object Detection with intertwined Multi-Supervision--Revised, https://arxiv.org/pdf/2509.21363, 2025-09-21
2025-11-11 00:51:55,476 - INFO - root - Page:0, Index:11, InstructVTON: Optimal Auto-Masking and Natural-Language-Guided Interactive Style Control for Inpainting-Based Virtual Try-On, https://arxiv.org/pdf/2509.20524, 2025-09-24
2025-11-11 00:51:55,482 - INFO - root - Page:0, Index:12, Efficient Encoder-Free Pose Conditioning and Pose Control for Virtual Try-On, https://arxiv.org/pdf/2509.20343, 2025-09-24
2025-11-11 00:51:55,484 - INFO - root - Page:0, Index:13, The Photographer Eye: Teaching Multimodal Large Language Models to Understand Image Aesthetics like Photographers, https://arxiv.org/pdf/2509.18582, 2025-10-22
2025-11-11 00:51:55,484 - INFO - root - Page:0, Index:14, ENSAM: an efficient foundation model for interactive segmentation of 3D medical images, https://arxiv.org/pdf/2509.15874, 2025-09-19
2025-11-11 00:51:55,485 - INFO - root - Page:0, Index:15, DEFT-VTON: Efficient Virtual Try-On with Consistent Generalised H-Transform, https://arxiv.org/pdf/2509.13506, 2025-09-16
2025-11-11 00:51:55,486 - INFO - root - Page:0, Index:16, Weakly and Self-Supervised Class-Agnostic Motion Prediction for Autonomous Driving, https://arxiv.org/pdf/2509.13116, 2025-09-16
2025-11-11 00:51:55,486 - INFO - root - Page:0, Index:17, Domain-Adaptive Pretraining Improves Primate Behavior Recognition, https://arxiv.org/pdf/2509.12193, 2025-09-15
2025-11-11 00:51:55,486 - INFO - root - Page:0, Index:18, The System Description of CPS Team for Track on Driving with Language of CVPR 2024 Autonomous Grand Challenge, https://arxiv.org/pdf/2509.11071, 2025-09-13
2025-11-11 00:51:55,487 - INFO - root - Page:0, Index:19, An HMM-based framework for identity-aware long-term multi-object tracking from sparse and uncertain identification: use case on long-term tracking in livestock, https://arxiv.org/pdf/2509.09962, 2025-09-12
2025-11-11 00:51:55,490 - INFO - root - Page:0, Index:20, InterAct: Advancing Large-Scale Versatile 3D Human-Object Interaction Generation, https://arxiv.org/pdf/2509.09555, 2025-09-11
2025-11-11 00:51:55,491 - INFO - root - Page:0, Index:21, Geospatial Foundational Embedder: Top-1 Winning Solution on EarthVision Embed2Scale Challenge (CVPR 2025), https://arxiv.org/pdf/2509.06993, 2025-09-03
2025-11-11 00:51:55,493 - INFO - root - Page:0, Index:22, 2nd Place Solution for CVPR2024 E2E Challenge: End-to-End Autonomous Driving Using Vision Language Model, https://arxiv.org/pdf/2509.02659, 2025-09-02
2025-11-11 00:51:55,496 - INFO - root - Page:0, Index:23, Unsupervised Training of Vision Transformers with Synthetic Negatives, https://arxiv.org/pdf/2509.02024, 2025-09-02
2025-11-11 00:51:55,498 - INFO - root - Page:0, Index:24, MV-SSM: Multi-View State Space Modeling for 3D Human Pose Estimation, https://arxiv.org/pdf/2509.00649, 2025-08-30
2025-11-11 00:51:55,500 - INFO - root - Page:0, Index:25, CryptoFace: End-to-End Encrypted Face Recognition, https://arxiv.org/pdf/2509.00332, 2025-08-29
2025-11-11 00:51:55,501 - INFO - root - Page:0, Index:26, ControlEchoSynth: Boosting Ejection Fraction Estimation Models via Controlled Video Diffusion, https://arxiv.org/pdf/2508.17631, 2025-08-26
2025-11-11 00:51:55,502 - INFO - root - Page:0, Index:27, Explain Before You Answer: A Survey on Compositional Visual Reasoning, https://arxiv.org/pdf/2508.17298, 2025-08-27
2025-11-11 00:51:55,503 - INFO - root - Page:0, Index:28, Investigating Different Geo Priors for Image Classification, https://arxiv.org/pdf/2508.15946, 2025-08-21
2025-11-11 00:51:55,505 - INFO - root - Page:0, Index:29, Towards Source-Free Machine Unlearning, https://arxiv.org/pdf/2508.15127, 2025-08-20
2025-11-11 00:51:55,505 - INFO - root - Page:0, Index:30, MR6D: Benchmarking 6D Pose Estimation for Mobile Robots, https://arxiv.org/pdf/2508.13775, 2025-08-19
2025-11-11 00:51:55,509 - INFO - root - Page:0, Index:31, Calibrating Biased Distribution in VFM-derived Latent Space via Cross-Domain Geometric Consistency, https://arxiv.org/pdf/2508.13518, 2025-08-19
2025-11-11 00:51:55,523 - INFO - root - Page:0, Index:32, SIS-Challenge: Event-based Spatio-temporal Instance Segmentation Challenge at the CVPR 2025 Event-based Vision Workshop, https://arxiv.org/pdf/2508.12813, 2025-08-18
2025-11-11 00:51:55,525 - INFO - root - Page:0, Index:33, Multi-Level Knowledge Distillation and Dynamic Self-Supervised Learning for Continual Learning, https://arxiv.org/pdf/2508.12692, 2025-08-22
2025-11-11 00:51:55,526 - INFO - root - Page:0, Index:34, Stochastic-based Patch Filtering for Few-Shot Learning, https://arxiv.org/pdf/2508.10066, 2025-08-13
2025-11-11 00:51:55,528 - INFO - root - Page:0, Index:35, Slot Attention-based Feature Filtering for Few-Shot Learning, https://arxiv.org/pdf/2508.09699, 2025-08-13
2025-11-11 00:51:55,534 - INFO - root - Page:0, Index:36, Comparison Reveals Commonality: Customized Image Generation through Contrastive Inversion, https://arxiv.org/pdf/2508.07755, 2025-08-11
2025-11-11 00:51:55,535 - INFO - root - Page:0, Index:37, SLRTP2025 Sign Language Production Challenge: Methodology, Results, and Future Work, https://arxiv.org/pdf/2508.06951, 2025-08-09
2025-11-11 00:51:55,535 - INFO - root - Page:0, Index:38, Exploring Fairness across Fine-Grained Attributes in Large Vision-Language Models, https://arxiv.org/pdf/2508.03079, 2025-08-05
2025-11-11 00:51:55,535 - INFO - root - Page:0, Index:39, Devil is in the Detail: Towards Injecting Fine Details of Image Prompt in Image Generation via Conflict-free Guidance and Stratified Attention, https://arxiv.org/pdf/2508.02004, 2025-08-03
2025-11-11 00:51:55,538 - INFO - root - Page:0, Index:40, IAUNet: Instance-Aware U-Net, https://arxiv.org/pdf/2508.01928, 2025-08-03
2025-11-11 00:51:55,540 - INFO - root - Page:0, Index:41, Gaussian Splatting Feature Fields for Privacy-Preserving Visual Localization, https://arxiv.org/pdf/2507.23569, 2025-08-26
2025-11-11 00:51:55,540 - INFO - root - Page:0, Index:42, From Scan to Action: Leveraging Realistic Scans for Embodied Scene Understanding, https://arxiv.org/pdf/2507.17585, 2025-07-23
2025-11-11 00:51:55,543 - INFO - root - Page:0, Index:43, LEAD: Exploring Logit Space Evolution for Model Selection, https://arxiv.org/pdf/2507.14559, 2025-07-19
2025-11-11 00:51:55,545 - INFO - root - Page:0, Index:44, HeCoFuse: Cross-Modal Complementary V2X Cooperative Perception with Heterogeneous Sensors, https://arxiv.org/pdf/2507.13677, 2025-07-18
2025-11-11 00:51:55,554 - INFO - root - Page:0, Index:45, OmniVec2 -- A Novel Transformer based Network for Large Scale Multimodal and Multitask Learning, https://arxiv.org/pdf/2507.13364, 2025-07-06
2025-11-11 00:51:55,563 - INFO - root - Page:0, Index:46, A Training-Free, Task-Agnostic Framework for Enhancing MLLM Performance on High-Resolution Images, https://arxiv.org/pdf/2507.10202, 2025-07-14
2025-11-11 00:51:55,569 - INFO - root - Page:0, Index:47, Quantum Federated Learning for Multimodal Data: A Modality-Agnostic Approach, https://arxiv.org/pdf/2507.08217, 2025-07-10
2025-11-11 00:51:55,572 - INFO - root - Page:0, Index:48, CuriosAI Submission to the EgoExo4D Proficiency Estimation Challenge 2025, https://arxiv.org/pdf/2507.08022, 2025-07-08
2025-11-11 00:51:55,573 - INFO - root - Page:0, Index:49, Rethinking Query-based Transformer for Continual Image Segmentation, https://arxiv.org/pdf/2507.07831, 2025-07-10
2025-11-11 00:51:55,580 - INFO - root - Fetching page 2 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=50
2025-11-11 00:52:02,095 - INFO - root - get_all_titles_from_web 
2025-11-11 00:52:02,095 - INFO - root - Page:1, Index:0, Scalable and Realistic Virtual Try-on Application for Foundation Makeup with Kubelka-Munk Theory, https://arxiv.org/pdf/2507.07333, 2025-07-09
2025-11-11 00:52:02,096 - INFO - root - Page:1, Index:1, Free on the Fly: Enhancing Flexibility in Test-Time Adaptation with Online EM, https://arxiv.org/pdf/2507.06973, 2025-07-09
2025-11-11 00:52:02,096 - INFO - root - Page:1, Index:2, Adaptive Part Learning for Fine-Grained Generalized Category Discovery: A Plug-and-Play Enhancement, https://arxiv.org/pdf/2507.06928, 2025-07-09
2025-11-11 00:52:02,096 - INFO - root - Page:1, Index:3, Grounded Gesture Generation: Language, Motion, and Space, https://arxiv.org/pdf/2507.04522, 2025-07-06
2025-11-11 00:52:02,096 - INFO - root - Page:1, Index:4, Comprehensive Information Bottleneck for Unveiling Universal Attribution to Interpret Vision Transformers, https://arxiv.org/pdf/2507.04388, 2025-07-06
2025-11-11 00:52:02,097 - INFO - root - Page:1, Index:5, ZERO: Industry-ready Vision Foundation Model with Multi-modal Prompts, https://arxiv.org/pdf/2507.04270, 2025-11-07
2025-11-11 00:52:02,097 - INFO - root - Page:1, Index:6, Beyond Accuracy: Metrics that Uncover What Makes a 'Good' Visual Descriptor, https://arxiv.org/pdf/2507.03542, 2025-07-08
2025-11-11 00:52:02,098 - INFO - root - Page:1, Index:7, ConceptMix++: Leveling the Playing Field in Text-to-Image Benchmarking via Iterative Prompt Optimization, https://arxiv.org/pdf/2507.03275, 2025-07-03
2025-11-11 00:52:02,099 - INFO - root - Page:1, Index:8, APT: Adaptive Personalized Training for Diffusion Models with Limited Data, https://arxiv.org/pdf/2507.02687, 2025-07-03
2025-11-11 00:52:02,099 - INFO - root - Page:1, Index:9, DreamComposer++: Empowering Diffusion Models with Multi-View Conditions for 3D Content Generation, https://arxiv.org/pdf/2507.02299, 2025-07-03
2025-11-11 00:52:02,099 - INFO - root - Page:1, Index:10, Soft Self-labeling and Potts Relaxations for Weakly-Supervised Segmentation, https://arxiv.org/pdf/2507.01721, 2025-07-02
2025-11-11 00:52:02,101 - INFO - root - Page:1, Index:11, Interpolation-Based Event Visual Data Filtering Algorithms, https://arxiv.org/pdf/2507.01557, 2025-07-02
2025-11-11 00:52:02,102 - INFO - root - Page:1, Index:12, AVC-DPO: Aligned Video Captioning via Direct Preference Optimization, https://arxiv.org/pdf/2507.01492, 2025-07-02
2025-11-11 00:52:02,102 - INFO - root - Page:1, Index:13, NN-Former: Rethinking Graph Structure in Neural Architecture Representation, https://arxiv.org/pdf/2507.00880, 2025-07-01
2025-11-11 00:52:02,102 - INFO - root - Page:1, Index:14, Instant Particle Size Distribution Measurement Using CNNs Trained on Synthetic Data, https://arxiv.org/pdf/2507.00822, 2025-07-01
2025-11-11 00:52:02,103 - INFO - root - Page:1, Index:15, Moment Sampling in Video LLMs for Long-Form Video QA, https://arxiv.org/pdf/2507.00033, 2025-06-17
2025-11-11 00:52:02,103 - INFO - root - Page:1, Index:16, Revisiting Audio-Visual Segmentation with Vision-Centric Transformer, https://arxiv.org/pdf/2506.23623, 2025-06-30
2025-11-11 00:52:02,103 - INFO - root - Page:1, Index:17, MTADiffusion: Mask Text Alignment Diffusion Model for Object Inpainting, https://arxiv.org/pdf/2506.23482, 2025-06-29
2025-11-11 00:52:02,103 - INFO - root - Page:1, Index:18, Benchmarking Generalizable Bimanual Manipulation: RoboTwin Dual-Arm Collaboration Challenge at CVPR 2025 MEIS Workshop, https://arxiv.org/pdf/2506.23351, 2025-07-02
2025-11-11 00:52:02,104 - INFO - root - Page:1, Index:19, Prompting without Panic: Attribute-aware, Zero-shot, Test-Time Calibration, https://arxiv.org/pdf/2506.22819, 2025-06-28
2025-11-11 00:52:02,104 - INFO - root - Page:1, Index:20, Analyzing and Fine-Tuning Whisper Models for Multilingual Pilot Speech Transcription in the Cockpit, https://arxiv.org/pdf/2506.21990, 2025-06-27
2025-11-11 00:52:02,104 - INFO - root - Page:1, Index:21, SceneDiffuser++: City-Scale Traffic Simulation via a Generative World Model, https://arxiv.org/pdf/2506.21976, 2025-06-27
2025-11-11 00:52:02,104 - INFO - root - Page:1, Index:22, DIVE: Deep-search Iterative Video Exploration A Technical Report for the CVRR Challenge at CVPR 2025, https://arxiv.org/pdf/2506.21891, 2025-06-27
2025-11-11 00:52:02,105 - INFO - root - Page:1, Index:23, End-to-End RGB-IR Joint Image Compression With Channel-wise Cross-modality Entropy Model, https://arxiv.org/pdf/2506.21851, 2025-06-26
2025-11-11 00:52:02,106 - INFO - root - Page:1, Index:24, Distilling Normalizing Flows, https://arxiv.org/pdf/2506.21003, 2025-06-26
2025-11-11 00:52:02,106 - INFO - root - Page:1, Index:25, Joint attitude estimation and 3D neural reconstruction of non-cooperative space objects, https://arxiv.org/pdf/2506.20638, 2025-06-25
2025-11-11 00:52:02,106 - INFO - root - Page:1, Index:26, Accept More, Reject Less: Reducing up to 19% Unnecessary Desk-Rejections over 11 Years of ICLR Data, https://arxiv.org/pdf/2506.20141, 2025-06-25
2025-11-11 00:52:02,106 - INFO - root - Page:1, Index:27, SceneCrafter: Controllable Multi-View Driving Scene Editing, https://arxiv.org/pdf/2506.19488, 2025-06-24
2025-11-11 00:52:02,106 - INFO - root - Page:1, Index:28, Emergence of Text Readability in Vision Language Models, https://arxiv.org/pdf/2506.19389, 2025-06-24
2025-11-11 00:52:02,107 - INFO - root - Page:1, Index:29, MedErr-CT: A Visual Question Answering Benchmark for Identifying and Correcting Errors in CT Reports, https://arxiv.org/pdf/2506.19217, 2025-06-23
2025-11-11 00:52:02,107 - INFO - root - Page:1, Index:30, RareSpot: Spotting Small and Rare Wildlife in Aerial Imagery with Multi-Scale Consistency and Context-Aware Augmentation, https://arxiv.org/pdf/2506.19087, 2025-06-23
2025-11-11 00:52:02,107 - INFO - root - Page:1, Index:31, Object-aware Sound Source Localization via Audio-Visual Scene Understanding, https://arxiv.org/pdf/2506.18557, 2025-06-23
2025-11-11 00:52:02,108 - INFO - root - Page:1, Index:32, Rethinking Decoder Design: Improving Biomarker Segmentation Using Depth-to-Space Restoration and Residual Linear Attention, https://arxiv.org/pdf/2506.18335, 2025-06-23
2025-11-11 00:52:02,108 - INFO - root - Page:1, Index:33, Relation3D: Enhancing Relation Modeling for Point Cloud Instance Segmentation, https://arxiv.org/pdf/2506.17891, 2025-06-21
2025-11-11 00:52:02,108 - INFO - root - Page:1, Index:34, HIRE: Lightweight High-Resolution Image Feature Enrichment for Multimodal LLMs, https://arxiv.org/pdf/2506.17608, 2025-06-21
2025-11-11 00:52:02,109 - INFO - root - Page:1, Index:35, Spatially-Aware Evaluation of Segmentation Uncertainty, https://arxiv.org/pdf/2506.16589, 2025-06-19
2025-11-11 00:52:02,109 - INFO - root - Page:1, Index:36, Tripartite Weight-Space Ensemble for Few-Shot Class-Incremental Learning, https://arxiv.org/pdf/2506.15720, 2025-06-03
2025-11-11 00:52:02,109 - INFO - root - Page:1, Index:37, PARC: A Quantitative Framework Uncovering the Symmetries within Vision Language Models, https://arxiv.org/pdf/2506.14808, 2025-06-03
2025-11-11 00:52:02,109 - INFO - root - Page:1, Index:38, Self-supervised Representation Learning with Local Aggregation for Image-based Profiling, https://arxiv.org/pdf/2506.14265, 2025-10-27
2025-11-11 00:52:02,110 - INFO - root - Page:1, Index:39, Towards Robust Learning to Optimize with Theoretical Guarantees, https://arxiv.org/pdf/2506.14263, 2025-06-17
2025-11-11 00:52:02,110 - INFO - root - Page:1, Index:40, Hidden Bias in the Machine: Stereotypes in Text-to-Image Models, https://arxiv.org/pdf/2506.13780, 2025-06-09
2025-11-11 00:52:02,110 - INFO - root - Page:1, Index:41, SmartHome-Bench: A Comprehensive Benchmark for Video Anomaly Detection in Smart Homes Using Multi-Modal Large Language Models, https://arxiv.org/pdf/2506.12992, 2025-06-15
2025-11-11 00:52:02,110 - INFO - root - Page:1, Index:42, Generative 4D Scene Gaussian Splatting with Object View-Synthesis Priors, https://arxiv.org/pdf/2506.12716, 2025-06-15
2025-11-11 00:52:02,111 - INFO - root - Page:1, Index:43, DejaVid: Encoder-Agnostic Learned Temporal Matching for Video Classification, https://arxiv.org/pdf/2506.12585, 2025-06-14
2025-11-11 00:52:02,111 - INFO - root - Page:1, Index:44, Pushing the Limits of Safety: A Technical Report on the ATLAS Challenge 2025, https://arxiv.org/pdf/2506.12430, 2025-07-10
2025-11-11 00:52:02,111 - INFO - root - Page:1, Index:45, FIMA-Q: Post-Training Quantization for Vision Transformers by Fisher Information Matrix Approximation, https://arxiv.org/pdf/2506.11543, 2025-06-13
2025-11-11 00:52:02,112 - INFO - root - Page:1, Index:46, Stop learning it all to mitigate visual hallucination, Focus on the hallucination target, https://arxiv.org/pdf/2506.11417, 2025-06-12
2025-11-11 00:52:02,112 - INFO - root - Page:1, Index:47, EfficientQuant: An Efficient Post-Training Quantization for CNN-Transformer Hybrid Models on Edge Devices, https://arxiv.org/pdf/2506.11093, 2025-06-05
2025-11-11 00:52:02,112 - INFO - root - Page:1, Index:48, HalLoc: Token-level Localization of Hallucinations for Vision Language Models, https://arxiv.org/pdf/2506.10286, 2025-06-11
2025-11-11 00:52:02,112 - INFO - root - Page:1, Index:49, DySS: Dynamic Queries and State-Space Learning for Efficient 3D Object Detection from Multi-Camera Videos, https://arxiv.org/pdf/2506.10242, 2025-06-11
2025-11-11 00:52:02,113 - INFO - root - Fetching page 3 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=100
2025-11-11 00:52:08,601 - INFO - root - get_all_titles_from_web 
2025-11-11 00:52:08,602 - INFO - root - Page:2, Index:0, Improving Personalized Search with Regularized Low-Rank Parameter Updates, https://arxiv.org/pdf/2506.10182, 2025-06-11
2025-11-11 00:52:08,602 - INFO - root - Page:2, Index:1, Hearing Hands: Generating Sounds from Physical Interactions in 3D Scenes, https://arxiv.org/pdf/2506.09989, 2025-06-11
2025-11-11 00:52:08,602 - INFO - root - Page:2, Index:2, UniPre3D: Unified Pre-training of 3D Point Cloud Models with Cross-Modal Gaussian Splatting, https://arxiv.org/pdf/2506.09952, 2025-06-11
2025-11-11 00:52:08,604 - INFO - root - Page:2, Index:3, Provoking Multi-modal Few-Shot LVLM via Exploration-Exploitation In-Context Learning, https://arxiv.org/pdf/2506.09473, 2025-06-11
2025-11-11 00:52:08,604 - INFO - root - Page:2, Index:4, Synthetic Human Action Video Data Generation with Pose Transfer, https://arxiv.org/pdf/2506.09411, 2025-06-11
2025-11-11 00:52:08,604 - INFO - root - Page:2, Index:5, ScaleLSD: Scalable Deep Line Segment Detection Streamlined, https://arxiv.org/pdf/2506.09369, 2025-06-10
2025-11-11 00:52:08,606 - INFO - root - Page:2, Index:6, CheckManual: A New Challenge and Benchmark for Manual-based Appliance Manipulation, https://arxiv.org/pdf/2506.09343, 2025-06-10
2025-11-11 00:52:08,606 - INFO - root - Page:2, Index:7, PatchGuard: Adversarially Robust Anomaly Detection and Localization through Vision Transformers and Pseudo Anomalies, https://arxiv.org/pdf/2506.09237, 2025-10-24
2025-11-11 00:52:08,606 - INFO - root - Page:2, Index:8, SILK: Smooth InterpoLation frameworK for motion in-betweening A Simplified Computational Approach, https://arxiv.org/pdf/2506.09075, 2025-06-09
2025-11-11 00:52:08,608 - INFO - root - Page:2, Index:9, BG-HOP: A Bimanual Generative Hand-Object Prior, https://arxiv.org/pdf/2506.09068, 2025-06-08
2025-11-11 00:52:08,608 - INFO - root - Page:2, Index:10, ORIDa: Object-centric Real-world Image Composition Dataset, https://arxiv.org/pdf/2506.08964, 2025-06-10
2025-11-11 00:52:08,608 - INFO - root - Page:2, Index:11, DiscoVLA: Discrepancy Reduction in Vision, Language, and Alignment for Parameter-Efficient Video-Text Retrieval, https://arxiv.org/pdf/2506.08887, 2025-06-10
2025-11-11 00:52:08,608 - INFO - root - Page:2, Index:12, A Comprehensive Study of Decoder-Only LLMs for Text-to-Image Generation, https://arxiv.org/pdf/2506.08210, 2025-06-09
2025-11-11 00:52:08,608 - INFO - root - Page:2, Index:13, Open World Scene Graph Generation using Vision Language Models, https://arxiv.org/pdf/2506.08189, 2025-06-09
2025-11-11 00:52:08,608 - INFO - root - Page:2, Index:14, Aligning Proteins and Language: A Foundation Model for Protein Retrieval, https://arxiv.org/pdf/2506.08023, 2025-05-27
2025-11-11 00:52:08,608 - INFO - root - Page:2, Index:15, UA-Pose: Uncertainty-Aware 6D Object Pose Estimation and Online Object Completion with Partial References, https://arxiv.org/pdf/2506.07996, 2025-06-09
2025-11-11 00:52:08,609 - INFO - root - Page:2, Index:16, Speedy Deformable 3D Gaussian Splatting: Fast Rendering and Compression of Dynamic Scenes, https://arxiv.org/pdf/2506.07917, 2025-06-09
2025-11-11 00:52:08,610 - INFO - root - Page:2, Index:17, GaussianVAE: Adaptive Learning Dynamics of 3D Gaussians for High-Fidelity Super-Resolution, https://arxiv.org/pdf/2506.07897, 2025-06-09
2025-11-11 00:52:08,610 - INFO - root - Page:2, Index:18, Spatio-Temporal State Space Model For Efficient Event-Based Optical Flow, https://arxiv.org/pdf/2506.07878, 2025-06-09
2025-11-11 00:52:08,610 - INFO - root - Page:2, Index:19, FreeGave: 3D Physics Learning from Dynamic Videos by Gaussian Velocity, https://arxiv.org/pdf/2506.07865, 2025-06-09
2025-11-11 00:52:08,611 - INFO - root - Page:2, Index:20, LogoSP: Local-global Grouping of Superpoints for Unsupervised Semantic Segmentation of 3D Point Clouds, https://arxiv.org/pdf/2506.07857, 2025-06-09
2025-11-11 00:52:08,611 - INFO - root - Page:2, Index:21, Difference Inversion: Interpolate and Isolate the Difference with Token Consistency for Image Analogy Generation, https://arxiv.org/pdf/2506.07750, 2025-06-09
2025-11-11 00:52:08,611 - INFO - root - Page:2, Index:22, Synthetic Visual Genome, https://arxiv.org/pdf/2506.07643, 2025-06-09
2025-11-11 00:52:08,611 - INFO - root - Page:2, Index:23, Fractional Collisions: A Framework for Risk Estimation of Counterfactual Conflicts using Autonomous Driving Behavior Simulations, https://arxiv.org/pdf/2506.07540, 2025-06-09
2025-11-11 00:52:08,612 - INFO - root - Page:2, Index:24, Multi-Step Guided Diffusion for Image Restoration on Edge Devices: Toward Lightweight Perception in Embodied AI, https://arxiv.org/pdf/2506.07286, 2025-06-08
2025-11-11 00:52:08,612 - INFO - root - Page:2, Index:25, LLM-Enhanced Rapid-Reflex Async-Reflect Embodied Agent for Real-Time Decision-Making in Dynamically Changing Environments, https://arxiv.org/pdf/2506.07223, 2025-06-08
2025-11-11 00:52:08,612 - INFO - root - Page:2, Index:26, UCOD-DPL: Unsupervised Camouflaged Object Detection via Dynamic Pseudo-label Learning, https://arxiv.org/pdf/2506.07087, 2025-06-08
2025-11-11 00:52:08,612 - INFO - root - Page:2, Index:27, BePo: Leveraging Birds Eye View and Sparse Points for Efficient and Accurate 3D Occupancy Prediction, https://arxiv.org/pdf/2506.07002, 2025-06-08
2025-11-11 00:52:08,613 - INFO - root - Page:2, Index:28, Reading in the Dark with Foveated Event Vision, https://arxiv.org/pdf/2506.06918, 2025-06-07
2025-11-11 00:52:08,613 - INFO - root - Page:2, Index:29, NSD-Imagery: A benchmark dataset for extending fMRI vision decoding methods to mental imagery, https://arxiv.org/pdf/2506.06898, 2025-06-07
2025-11-11 00:52:08,613 - INFO - root - Page:2, Index:30, Continuous-Time SO(3) Forecasting with Savitzky--Golay Neural Controlled Differential Equations, https://arxiv.org/pdf/2506.06780, 2025-06-07
2025-11-11 00:52:08,613 - INFO - root - Page:2, Index:31, Generalized Trajectory Scoring for End-to-end Multimodal Planning, https://arxiv.org/pdf/2506.06664, 2025-06-07
2025-11-11 00:52:08,613 - INFO - root - Page:2, Index:32, EV-LayerSegNet: Self-supervised Motion Segmentation using Event Cameras, https://arxiv.org/pdf/2506.06596, 2025-06-06
2025-11-11 00:52:08,613 - INFO - root - Page:2, Index:33, Vid2Sim: Generalizable, Video-based Reconstruction of Appearance, Geometry and Physics for Mesh-free Simulation, https://arxiv.org/pdf/2506.06440, 2025-06-06
2025-11-11 00:52:08,614 - INFO - root - Page:2, Index:34, FADE: Frequency-Aware Diffusion Model Factorization for Video Editing, https://arxiv.org/pdf/2506.05934, 2025-06-06
2025-11-11 00:52:08,614 - INFO - root - Page:2, Index:35, Unleashing the Potential of Consistency Learning for Detecting and Grounding Multi-Modal Media Manipulation, https://arxiv.org/pdf/2506.05890, 2025-06-06
2025-11-11 00:52:08,614 - INFO - root - Page:2, Index:36, DeformCL: Learning Deformable Centerline Representation for Vessel Extraction in 3D Medical Image, https://arxiv.org/pdf/2506.05820, 2025-06-06
2025-11-11 00:52:08,614 - INFO - root - Page:2, Index:37, NTIRE 2025 Challenge on HR Depth from Images of Specular and Transparent Surfaces, https://arxiv.org/pdf/2506.05815, 2025-06-06
2025-11-11 00:52:08,614 - INFO - root - Page:2, Index:38, GazeNLQ @ Ego4D Natural Language Queries Challenge 2025, https://arxiv.org/pdf/2506.05782, 2025-06-06
2025-11-11 00:52:08,616 - INFO - root - Page:2, Index:39, Robust sensor fusion against on-vehicle sensor staleness, https://arxiv.org/pdf/2506.05780, 2025-06-06
2025-11-11 00:52:08,617 - INFO - root - Page:2, Index:40, Where Is The Ball: 3D Ball Trajectory Estimation From 2D Monocular Tracking, https://arxiv.org/pdf/2506.05763, 2025-06-06
2025-11-11 00:52:08,617 - INFO - root - Page:2, Index:41, VoxelSplat: Dynamic Gaussian Splatting as an Effective Loss for Occupancy and Flow Prediction, https://arxiv.org/pdf/2506.05563, 2025-06-05
2025-11-11 00:52:08,617 - INFO - root - Page:2, Index:42, Gen4D: Synthesizing Humans and Scenes in the Wild, https://arxiv.org/pdf/2506.05397, 2025-06-03
2025-11-11 00:52:08,618 - INFO - root - Page:2, Index:43, Attacking Attention of Foundation Models Disrupts Downstream Tasks, https://arxiv.org/pdf/2506.05394, 2025-09-12
2025-11-11 00:52:08,618 - INFO - root - Page:2, Index:44, FreeTimeGS: Free Gaussian Primitives at Anytime and Anywhere for Dynamic Scene Reconstruction, https://arxiv.org/pdf/2506.05348, 2025-06-06
2025-11-11 00:52:08,618 - INFO - root - Page:2, Index:45, LotusFilter: Fast Diverse Nearest Neighbor Search via a Learned Cutoff Table, https://arxiv.org/pdf/2506.04790, 2025-06-05
2025-11-11 00:52:08,618 - INFO - root - Page:2, Index:46, Towards Holistic Visual Quality Assessment of AI-Generated Videos: A LLM-Based Multi-Dimensional Evaluation Model, https://arxiv.org/pdf/2506.04715, 2025-06-11
2025-11-11 00:52:08,618 - INFO - root - Page:2, Index:47, Gradient Inversion Attacks on Parameter-Efficient Fine-Tuning, https://arxiv.org/pdf/2506.04453, 2025-06-04
2025-11-11 00:52:08,618 - INFO - root - Page:2, Index:48, HMAR: Efficient Hierarchical Masked Auto-Regressive Image Generation, https://arxiv.org/pdf/2506.04421, 2025-06-04
2025-11-11 00:52:08,619 - INFO - root - Page:2, Index:49, Visualizing and Controlling Cortical Responses Using Voxel-Weighted Activation Maximization, https://arxiv.org/pdf/2506.04379, 2025-06-04
2025-11-11 00:52:08,619 - INFO - root - Fetching page 4 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=150
2025-11-11 00:52:15,507 - INFO - root - get_all_titles_from_web 
2025-11-11 00:52:15,508 - INFO - root - Page:3, Index:0, FlexGS: Train Once, Deploy Everywhere with Many-in-One Flexible 3D Gaussian Splatting, https://arxiv.org/pdf/2506.04174, 2025-06-04
2025-11-11 00:52:15,508 - INFO - root - Page:3, Index:1, Multi-view Surface Reconstruction Using Normal and Reflectance Cues, https://arxiv.org/pdf/2506.04115, 2025-06-04
2025-11-11 00:52:15,508 - INFO - root - Page:3, Index:2, Vocabulary-free few-shot learning for Vision-Language Models, https://arxiv.org/pdf/2506.04005, 2025-06-04
2025-11-11 00:52:15,508 - INFO - root - Page:3, Index:3, Learning from Noise: Enhancing DNNs for Event-Based Vision through Controlled Noise Injection, https://arxiv.org/pdf/2506.03918, 2025-06-04
2025-11-11 00:52:15,509 - INFO - root - Page:3, Index:4, Video, How Do Your Tokens Merge?, https://arxiv.org/pdf/2506.03885, 2025-06-04
2025-11-11 00:52:15,509 - INFO - root - Page:3, Index:5, OSGNet @ Ego4D Episodic Memory Challenge 2025, https://arxiv.org/pdf/2506.03710, 2025-06-04
2025-11-11 00:52:15,510 - INFO - root - Page:3, Index:6, AetherVision-Bench: An Open-Vocabulary RGB-Infrared Benchmark for Multi-Angle Segmentation across Aerial and Ground Perspectives, https://arxiv.org/pdf/2506.03709, 2025-06-04
2025-11-11 00:52:15,510 - INFO - root - Page:3, Index:7, OV-COAST: Cost Aggregation with Optimal Transport for Open-Vocabulary Semantic Segmentation, https://arxiv.org/pdf/2506.03706, 2025-06-04
2025-11-11 00:52:15,517 - INFO - root - Page:3, Index:8, Generating 6DoF Object Manipulation Trajectories from Action Description in Egocentric Vision, https://arxiv.org/pdf/2506.03605, 2025-06-04
2025-11-11 00:52:15,519 - INFO - root - Page:3, Index:9, SemNav: A Model-Based Planner for Zero-Shot Object Goal Navigation Using Vision-Foundation Models, https://arxiv.org/pdf/2506.03516, 2025-06-03
2025-11-11 00:52:15,519 - INFO - root - Page:3, Index:10, Heterogeneous Skeleton-Based Action Representation Learning, https://arxiv.org/pdf/2506.03481, 2025-06-03
2025-11-11 00:52:15,519 - INFO - root - Page:3, Index:11, Hybrid Ensemble of Segmentation-Assisted Classification and GBDT for Skin Cancer Detection with Engineered Metadata and Synthetic Lesions from ISIC 2024 Non-Dermoscopic 3D-TBP Images, https://arxiv.org/pdf/2506.03420, 2025-06-03
2025-11-11 00:52:15,520 - INFO - root - Page:3, Index:12, Self-Supervised Spatial Correspondence Across Modalities, https://arxiv.org/pdf/2506.03148, 2025-06-03
2025-11-11 00:52:15,520 - INFO - root - Page:3, Index:13, Dense Match Summarization for Faster Two-view Estimation, https://arxiv.org/pdf/2506.02893, 2025-06-03
2025-11-11 00:52:15,521 - INFO - root - Page:3, Index:14, NTIRE 2025 XGC Quality Assessment Challenge: Methods and Results, https://arxiv.org/pdf/2506.02875, 2025-06-03
2025-11-11 00:52:15,521 - INFO - root - Page:3, Index:15, FreeScene: Mixed Graph Diffusion for 3D Scene Synthesis from Free Prompts, https://arxiv.org/pdf/2506.02781, 2025-06-03
2025-11-11 00:52:15,521 - INFO - root - Page:3, Index:16, Technical Report for Ego4D Long-Term Action Anticipation Challenge 2025, https://arxiv.org/pdf/2506.02550, 2025-06-11
2025-11-11 00:52:15,523 - INFO - root - Page:3, Index:17, Probabilistic Online Event Downsampling, https://arxiv.org/pdf/2506.02547, 2025-09-23
2025-11-11 00:52:15,523 - INFO - root - Page:3, Index:18, Towards In-the-wild 3D Plane Reconstruction from a Single Image, https://arxiv.org/pdf/2506.02493, 2025-06-03
2025-11-11 00:52:15,525 - INFO - root - Page:3, Index:19, Efficient Test-time Adaptive Object Detection via Sensitivity-Guided Pruning, https://arxiv.org/pdf/2506.02462, 2025-06-03
2025-11-11 00:52:15,525 - INFO - root - Page:3, Index:20, EgoVIS@CVPR: PAIR-Net: Enhancing Egocentric Speaker Detection via Pretrained Audio-Visual Fusion and Alignment Loss, https://arxiv.org/pdf/2506.02247, 2025-09-26
2025-11-11 00:52:15,525 - INFO - root - Page:3, Index:21, Diff2Flow: Training Flow Matching Models via Diffusion Model Alignment, https://arxiv.org/pdf/2506.02221, 2025-06-02
2025-11-11 00:52:15,526 - INFO - root - Page:3, Index:22, NTIRE 2025 Challenge on RAW Image Restoration and Super-Resolution, https://arxiv.org/pdf/2506.02197, 2025-06-04
2025-11-11 00:52:15,526 - INFO - root - Page:3, Index:23, RAW Image Reconstruction from RGB on Smartphones. NTIRE 2025 Challenge Report, https://arxiv.org/pdf/2506.01947, 2025-06-02
2025-11-11 00:52:15,526 - INFO - root - Page:3, Index:24, Silence is Golden: Leveraging Adversarial Examples to Nullify Audio Control in LDM-based Talking-Head Generation, https://arxiv.org/pdf/2506.01591, 2025-06-02
2025-11-11 00:52:15,527 - INFO - root - Page:3, Index:25, SAM2-LOVE: Segment Anything Model 2 in Language-aided Audio-Visual Scenes, https://arxiv.org/pdf/2506.01558, 2025-06-02
2025-11-11 00:52:15,527 - INFO - root - Page:3, Index:26, Neural shape reconstruction from multiple views with static pattern projection, https://arxiv.org/pdf/2506.01389, 2025-06-02
2025-11-11 00:52:15,537 - INFO - root - Page:3, Index:27, SAM-I2V: Upgrading SAM to Support Promptable Video Segmentation with Less than 0.2% Training Cost, https://arxiv.org/pdf/2506.01304, 2025-06-02
2025-11-11 00:52:15,537 - INFO - root - Page:3, Index:28, Perceptual Inductive Bias Is What You Need Before Contrastive Learning, https://arxiv.org/pdf/2506.01201, 2025-06-01
2025-11-11 00:52:15,537 - INFO - root - Page:3, Index:29, Test Automation for Interactive Scenarios via Promptable Traffic Simulation, https://arxiv.org/pdf/2506.01199, 2025-06-04
2025-11-11 00:52:15,539 - INFO - root - Page:3, Index:30, GraphPad: Inference-Time 3D Scene Graph Updates for Embodied Question Answering, https://arxiv.org/pdf/2506.01174, 2025-06-01
2025-11-11 00:52:15,539 - INFO - root - Page:3, Index:31, Aligned Contrastive Loss for Long-Tailed Recognition, https://arxiv.org/pdf/2506.01071, 2025-06-01
2025-11-11 00:52:15,540 - INFO - root - Page:3, Index:32, Self-supervised ControlNet with Spatio-Temporal Mamba for Real-world Video Super-resolution, https://arxiv.org/pdf/2506.01037, 2025-06-01
2025-11-11 00:52:15,540 - INFO - root - Page:3, Index:33, ArtiScene: Language-Driven Artistic 3D Scene Generation Through Image Intermediary, https://arxiv.org/pdf/2506.00742, 2025-05-31
2025-11-11 00:52:15,541 - INFO - root - Page:3, Index:34, 3D Gaussian Splat Vulnerabilities, https://arxiv.org/pdf/2506.00280, 2025-05-30
2025-11-11 00:52:15,542 - INFO - root - Page:3, Index:35, EgoVIS@CVPR: What Changed and What Could Have Changed? State-Change Counterfactuals for Procedure-Aware Video Representation Learning, https://arxiv.org/pdf/2506.00101, 2025-09-26
2025-11-11 00:52:15,542 - INFO - root - Page:3, Index:36, CL-LoRA: Continual Low-Rank Adaptation for Rehearsal-Free Class-Incremental Learning, https://arxiv.org/pdf/2505.24816, 2025-05-30
2025-11-11 00:52:15,543 - INFO - root - Page:3, Index:37, PatchDEMUX: A Certifiably Robust Framework for Multi-label Classifiers Against Adversarial Patches, https://arxiv.org/pdf/2505.24703, 2025-05-30
2025-11-11 00:52:15,543 - INFO - root - Page:3, Index:38, Conformal Prediction for Zero-Shot Models, https://arxiv.org/pdf/2505.24693, 2025-05-30
2025-11-11 00:52:15,544 - INFO - root - Page:3, Index:39, Learning reusable concepts across different egocentric video understanding tasks, https://arxiv.org/pdf/2505.24690, 2025-05-30
2025-11-11 00:52:15,544 - INFO - root - Page:3, Index:40, Period-LLM: Extending the Periodic Capability of Multimodal Large Language Model, https://arxiv.org/pdf/2505.24476, 2025-05-30
2025-11-11 00:52:15,549 - INFO - root - Page:3, Index:41, PCIE_Interaction Solution for Ego4D Social Interaction Challenge, https://arxiv.org/pdf/2505.24404, 2025-05-30
2025-11-11 00:52:15,550 - INFO - root - Page:3, Index:42, Leadership Assessment in Pediatric Intensive Care Unit Team Training, https://arxiv.org/pdf/2505.24389, 2025-08-28
2025-11-11 00:52:15,551 - INFO - root - Page:3, Index:43, Interpreting Large Text-to-Image Diffusion Models with Dictionary Learning, https://arxiv.org/pdf/2505.24360, 2025-07-10
2025-11-11 00:52:15,555 - INFO - root - Page:3, Index:44, InteractAnything: Zero-shot Human Object Interaction Synthesis via LLM Feedback and Object Affordance Parsing, https://arxiv.org/pdf/2505.24315, 2025-05-30
2025-11-11 00:52:15,557 - INFO - root - Page:3, Index:45, MaskAdapt: Unsupervised Geometry-Aware Domain Adaptation Using Multimodal Contextual Learning and RGB-Depth Masking, https://arxiv.org/pdf/2505.24026, 2025-05-29
2025-11-11 00:52:15,558 - INFO - root - Page:3, Index:46, Argus: Vision-Centric Reasoning with Grounded Chain-of-Thought, https://arxiv.org/pdf/2505.23766, 2025-05-29
2025-11-11 00:52:15,558 - INFO - root - Page:3, Index:47, Sketch Down the FLOPs: Towards Efficient Networks for Human Sketch, https://arxiv.org/pdf/2505.23763, 2025-05-29
2025-11-11 00:52:15,559 - INFO - root - Page:3, Index:48, Boosting Domain Incremental Learning: Selecting the Optimal Parameters is All You Need, https://arxiv.org/pdf/2505.23744, 2025-05-29
2025-11-11 00:52:15,559 - INFO - root - Page:3, Index:49, DA-VPT: Semantic-Guided Visual Prompt Tuning for Vision Transformers, https://arxiv.org/pdf/2505.23694, 2025-06-01
2025-11-11 00:52:15,559 - INFO - root - Fetching page 5 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=200
2025-11-11 00:52:21,895 - INFO - root - get_all_titles_from_web 
2025-11-11 00:52:21,896 - INFO - root - Page:4, Index:0, Bridging Classical and Modern Computer Vision: PerceptiveNet for Tree Crown Semantic Segmentation, https://arxiv.org/pdf/2505.23597, 2025-05-29
2025-11-11 00:52:21,896 - INFO - root - Page:4, Index:1, Synthetic Generation and Latent Projection Denoising of Rim Lesions in Multiple Sclerosis, https://arxiv.org/pdf/2505.23353, 2025-05-29
2025-11-11 00:52:21,896 - INFO - root - Page:4, Index:2, Wav2Sem: Plug-and-Play Audio Semantic Decoupling for 3D Speech-Driven Facial Animation, https://arxiv.org/pdf/2505.23290, 2025-05-29
2025-11-11 00:52:21,896 - INFO - root - Page:4, Index:3, Proximal Algorithm Unrolling: Flexible and Efficient Reconstruction Networks for Single-Pixel Imaging, https://arxiv.org/pdf/2505.23180, 2025-05-29
2025-11-11 00:52:21,897 - INFO - root - Page:4, Index:4, HMAD: Advancing E2E Driving with Anchored Offset Proposals and Simulation-Supervised Multi-target Scoring, https://arxiv.org/pdf/2505.23129, 2025-05-29
2025-11-11 00:52:21,897 - INFO - root - Page:4, Index:5, URWKV: Unified RWKV Model with Multi-state Perspective for Low-light Image Restoration, https://arxiv.org/pdf/2505.23068, 2025-05-29
2025-11-11 00:52:21,897 - INFO - root - Page:4, Index:6, 4DTAM: Non-Rigid Tracking and Mapping via Dynamic Surface Gaussians, https://arxiv.org/pdf/2505.22859, 2025-05-28
2025-11-11 00:52:21,897 - INFO - root - Page:4, Index:7, A Probabilistic Jump-Diffusion Framework for Open-World Egocentric Activity Recognition, https://arxiv.org/pdf/2505.22858, 2025-05-28
2025-11-11 00:52:21,897 - INFO - root - Page:4, Index:8, PS4PRO: Pixel-to-pixel Supervision for Photorealistic Rendering and Optimization, https://arxiv.org/pdf/2505.22616, 2025-05-28
2025-11-11 00:52:21,899 - INFO - root - Page:4, Index:9, Universal Domain Adaptation for Semantic Segmentation, https://arxiv.org/pdf/2505.22458, 2025-06-05
2025-11-11 00:52:21,899 - INFO - root - Page:4, Index:10, Zero-Shot 3D Visual Grounding from Vision-Language Models, https://arxiv.org/pdf/2505.22429, 2025-05-28
2025-11-11 00:52:21,899 - INFO - root - Page:4, Index:11, RC-AutoCalib: An End-to-End Radar-Camera Automatic Calibration Network, https://arxiv.org/pdf/2505.22427, 2025-05-28
2025-11-11 00:52:21,899 - INFO - root - Page:4, Index:12, Bringing CLIP to the Clinic: Dynamic Soft Labels and Negation-Aware Learning for Medical Analysis, https://arxiv.org/pdf/2505.22079, 2025-05-28
2025-11-11 00:52:21,900 - INFO - root - Page:4, Index:13, Point-to-Region Loss for Semi-Supervised Point-Based Crowd Counting, https://arxiv.org/pdf/2505.21943, 2025-05-27
2025-11-11 00:52:21,900 - INFO - root - Page:4, Index:14, FRAMES-VQA: Benchmarking Fine-Tuning Robustness across Multi-Modal Shifts in Visual Question Answering, https://arxiv.org/pdf/2505.21755, 2025-06-20
2025-11-11 00:52:21,902 - INFO - root - Page:4, Index:15, Knowledge Distillation Approach for SOS Fusion Staging: Towards Fully Automated Skeletal Maturity Assessment, https://arxiv.org/pdf/2505.21561, 2025-05-26
2025-11-11 00:52:21,905 - INFO - root - Page:4, Index:16, Enhancing Vision Transformer Explainability Using Artificial Astrocytes, https://arxiv.org/pdf/2505.21513, 2025-05-20
2025-11-11 00:52:21,907 - INFO - root - Page:4, Index:17, Empowering Vector Graphics with Consistently Arbitrary Viewing and View-dependent Visibility, https://arxiv.org/pdf/2505.21377, 2025-05-27
2025-11-11 00:52:21,908 - INFO - root - Page:4, Index:18, Structure from Collision, https://arxiv.org/pdf/2505.21335, 2025-05-27
2025-11-11 00:52:21,909 - INFO - root - Page:4, Index:19, Boosting Adversarial Transferability via High-Frequency Augmentation and Hierarchical-Gradient Fusion, https://arxiv.org/pdf/2505.21181, 2025-05-27
2025-11-11 00:52:21,911 - INFO - root - Page:4, Index:20, RefAV: Towards Planning-Centric Scenario Mining, https://arxiv.org/pdf/2505.20981, 2025-06-18
2025-11-11 00:52:21,911 - INFO - root - Page:4, Index:21, PMA: Towards Parameter-Efficient Point Cloud Understanding via Point Mamba Adapter, https://arxiv.org/pdf/2505.20941, 2025-05-27
2025-11-11 00:52:21,911 - INFO - root - Page:4, Index:22, HuMoCon: Concept Discovery for Human Motion Understanding, https://arxiv.org/pdf/2505.20920, 2025-05-27
2025-11-11 00:52:21,912 - INFO - root - Page:4, Index:23, Exploring Timeline Control for Facial Motion Generation, https://arxiv.org/pdf/2505.20861, 2025-05-27
2025-11-11 00:52:21,912 - INFO - root - Page:4, Index:24, ConText-CIR: Learning from Concepts in Text for Composed Image Retrieval, https://arxiv.org/pdf/2505.20764, 2025-05-27
2025-11-11 00:52:21,914 - INFO - root - Page:4, Index:25, HCQA-1.5 @ Ego4D EgoSchema Challenge 2025, https://arxiv.org/pdf/2505.20644, 2025-05-26
2025-11-11 00:52:21,914 - INFO - root - Page:4, Index:26, Roboflow100-VL: A Multi-Domain Object Detection Benchmark for Vision-Language Models, https://arxiv.org/pdf/2505.20612, 2025-10-22
2025-11-11 00:52:21,915 - INFO - root - Page:4, Index:27, MotionPro: A Precise Motion Controller for Image-to-Video Generation, https://arxiv.org/pdf/2505.20287, 2025-05-26
2025-11-11 00:52:21,916 - INFO - root - Page:4, Index:28, Category-Agnostic Neural Object Rigging, https://arxiv.org/pdf/2505.20283, 2025-05-26
2025-11-11 00:52:21,916 - INFO - root - Page:4, Index:29, Towards Video to Piano Music Generation with Chain-of-Perform Support Benchmarks, https://arxiv.org/pdf/2505.20038, 2025-05-26
2025-11-11 00:52:21,917 - INFO - root - Page:4, Index:30, Can Visual Encoder Learn to See Arrows?, https://arxiv.org/pdf/2505.19944, 2025-05-26
2025-11-11 00:52:21,917 - INFO - root - Page:4, Index:31, GoLF-NRT: Integrating Global Context and Local Geometry for Few-Shot View Synthesis, https://arxiv.org/pdf/2505.19813, 2025-05-26
2025-11-11 00:52:21,919 - INFO - root - Page:4, Index:32, Depth-Guided Bundle Sampling for Efficient Generalizable Neural Radiance Field Reconstruction, https://arxiv.org/pdf/2505.19793, 2025-05-26
2025-11-11 00:52:21,919 - INFO - root - Page:4, Index:33, SuperAD: A Training-free Anomaly Classification and Segmentation Method for CVPR 2025 VAND 3.0 Workshop Challenge Track 1: Adapt & Detect, https://arxiv.org/pdf/2505.19750, 2025-05-27
2025-11-11 00:52:21,923 - INFO - root - Page:4, Index:34, Knowledge-Aligned Counterfactual-Enhancement Diffusion Perception for Unsupervised Cross-Domain Visual Emotion Recognition, https://arxiv.org/pdf/2505.19694, 2025-05-26
2025-11-11 00:52:21,923 - INFO - root - Page:4, Index:35, Rotation-Equivariant Self-Supervised Method in Image Denoising, https://arxiv.org/pdf/2505.19618, 2025-05-26
2025-11-11 00:52:21,924 - INFO - root - Page:4, Index:36, NTIRE 2025 Challenge on Video Quality Enhancement for Video Conferencing: Datasets, Methods and Results, https://arxiv.org/pdf/2505.18988, 2025-05-25
2025-11-11 00:52:21,924 - INFO - root - Page:4, Index:37, Geometry-guided Online 3D Video Synthesis with Multi-View Temporal Consistency, https://arxiv.org/pdf/2505.18932, 2025-05-24
2025-11-11 00:52:21,924 - INFO - root - Page:4, Index:38, Digital Overconsumption and Waste: A Closer Look at the Impacts of Generative AI, https://arxiv.org/pdf/2505.18894, 2025-05-24
2025-11-11 00:52:21,925 - INFO - root - Page:4, Index:39, VISTA: Vision-Language Inference for Training-Free Stock Time-Series Analysis, https://arxiv.org/pdf/2505.18570, 2025-06-11
2025-11-11 00:52:21,925 - INFO - root - Page:4, Index:40, Syn3DTxt: Embedding 3D Cues for Scene Text Generation, https://arxiv.org/pdf/2505.18479, 2025-05-23
2025-11-11 00:52:21,926 - INFO - root - Page:4, Index:41, CTRL-GS: Cascaded Temporal Residue Learning for 4D Gaussian Splatting, https://arxiv.org/pdf/2505.18306, 2025-05-31
2025-11-11 00:52:21,926 - INFO - root - Page:4, Index:42, DualTalk: Dual-Speaker Interaction for 3D Talking Head Conversations, https://arxiv.org/pdf/2505.18096, 2025-05-26
2025-11-11 00:52:21,926 - INFO - root - Page:4, Index:43, SeaLion: Semantic Part-Aware Latent Point Diffusion Models for 3D Generation, https://arxiv.org/pdf/2505.17721, 2025-07-07
2025-11-11 00:52:21,927 - INFO - root - Page:4, Index:44, PoseBH: Prototypical Multi-Dataset Training Beyond Human Pose Estimation, https://arxiv.org/pdf/2505.17475, 2025-05-23
2025-11-11 00:52:21,927 - INFO - root - Page:4, Index:45, Pursuing Temporal-Consistent Video Virtual Try-On via Dynamic Pose Interaction, https://arxiv.org/pdf/2505.16980, 2025-05-22
2025-11-11 00:52:21,927 - INFO - root - Page:4, Index:46, UniPhy: Learning a Unified Constitutive Model for Inverse Physics Simulation, https://arxiv.org/pdf/2505.16971, 2025-05-22
2025-11-11 00:52:21,928 - INFO - root - Page:4, Index:47, Tracking the Flight: Exploring a Computational Framework for Analyzing Escape Responses in Plains Zebra (Equus quagga), https://arxiv.org/pdf/2505.16882, 2025-05-23
2025-11-11 00:52:21,929 - INFO - root - Page:4, Index:48, Semi-Supervised State-Space Model with Dynamic Stacking Filter for Real-World Video Deraining, https://arxiv.org/pdf/2505.16811, 2025-05-22
2025-11-11 00:52:21,929 - INFO - root - Page:4, Index:49, SOLVE: Synergy of Language-Vision and End-to-End Networks for Autonomous Driving, https://arxiv.org/pdf/2505.16805, 2025-05-22
2025-11-11 00:52:21,929 - INFO - root - Fetching page 6 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=250
2025-11-11 00:52:29,618 - INFO - root - get_all_titles_from_web 
2025-11-11 00:52:29,618 - INFO - root - Page:5, Index:0, Four Eyes Are Better Than Two: Harnessing the Collaborative Potential of Large Models via Differentiated Thinking and Complementary Ensembles, https://arxiv.org/pdf/2505.16784, 2025-06-07
2025-11-11 00:52:29,619 - INFO - root - Page:5, Index:1, Single Domain Generalization for Few-Shot Counting via Universal Representation Matching, https://arxiv.org/pdf/2505.16778, 2025-05-22
2025-11-11 00:52:29,619 - INFO - root - Page:5, Index:2, Seeing Far and Clearly: Mitigating Hallucinations in MLLMs with Attention Causal Decoding, https://arxiv.org/pdf/2505.16652, 2025-06-07
2025-11-11 00:52:29,620 - INFO - root - Page:5, Index:3, Sketchy Bounding-box Supervision for 3D Instance Segmentation, https://arxiv.org/pdf/2505.16399, 2025-05-22
2025-11-11 00:52:29,620 - INFO - root - Page:5, Index:4, DeCafNet: Delegate and Conquer for Efficient Temporal Grounding in Long Videos, https://arxiv.org/pdf/2505.16376, 2025-05-22
2025-11-11 00:52:29,620 - INFO - root - Page:5, Index:5, NTIRE 2025 challenge on Text to Image Generation Model Quality Assessment, https://arxiv.org/pdf/2505.16314, 2025-05-22
2025-11-11 00:52:29,622 - INFO - root - Page:5, Index:6, Analyzing Hierarchical Structure in Vision Models with Sparse Autoencoders, https://arxiv.org/pdf/2505.15970, 2025-05-21
2025-11-11 00:52:29,622 - INFO - root - Page:5, Index:7, Efficient Data Driven Mixture-of-Expert Extraction from Trained Networks, https://arxiv.org/pdf/2505.15414, 2025-05-21
2025-11-11 00:52:29,622 - INFO - root - Page:5, Index:8, Mouse Lockbox Dataset: Behavior Recognition for Mice Solving Lockboxes, https://arxiv.org/pdf/2505.15408, 2025-06-17
2025-11-11 00:52:29,624 - INFO - root - Page:5, Index:9, Zero-Shot Gaze-based Volumetric Medical Image Segmentation, https://arxiv.org/pdf/2505.15256, 2025-06-10
2025-11-11 00:52:29,625 - INFO - root - Page:5, Index:10, Dual Precision Quantization for Efficient and Accurate Deep Neural Networks Inference, https://arxiv.org/pdf/2505.14638, 2025-05-20
2025-11-11 00:52:29,626 - INFO - root - Page:5, Index:11, Neural Video Compression with Context Modulation, https://arxiv.org/pdf/2505.14541, 2025-05-20
2025-11-11 00:52:29,626 - INFO - root - Page:5, Index:12, Selective Structured State Space for Multispectral-fused Small Target Detection, https://arxiv.org/pdf/2505.14043, 2025-05-23
2025-11-11 00:52:29,626 - INFO - root - Page:5, Index:13, OmniStyle: Filtering High Quality Style Transfer Data at Scale, https://arxiv.org/pdf/2505.14028, 2025-05-20
2025-11-11 00:52:29,628 - INFO - root - Page:5, Index:14, Domain Adaptation of VLM for Soccer Video Understanding, https://arxiv.org/pdf/2505.13860, 2025-07-07
2025-11-11 00:52:29,628 - INFO - root - Page:5, Index:15, Ground-V: Teaching VLMs to Ground Complex Instructions in Pixels, https://arxiv.org/pdf/2505.13788, 2025-05-19
2025-11-11 00:52:29,628 - INFO - root - Page:5, Index:16, FinePhys: Fine-grained Human Action Generation by Explicitly Incorporating Physical Laws for Effective Skeletal Guidance, https://arxiv.org/pdf/2505.13437, 2025-05-19
2025-11-11 00:52:29,628 - INFO - root - Page:5, Index:17, The Way Up: A Dataset for Hold Usage Detection in Sport Climbing, https://arxiv.org/pdf/2505.12854, 2025-05-19
2025-11-11 00:52:29,629 - INFO - root - Page:5, Index:18, PEER pressure: Model-to-Model Regularization for Single Source Domain Generalization, https://arxiv.org/pdf/2505.12745, 2025-05-19
2025-11-11 00:52:29,630 - INFO - root - Page:5, Index:19, Mamba-Adaptor: State Space Model Adaptor for Visual Recognition, https://arxiv.org/pdf/2505.12685, 2025-05-19
2025-11-11 00:52:29,631 - INFO - root - Page:5, Index:20, Scalable Video-to-Dataset Generation for Cross-Platform Mobile Agents, https://arxiv.org/pdf/2505.12632, 2025-05-18
2025-11-11 00:52:29,631 - INFO - root - Page:5, Index:21, Degradation-Aware Feature Perturbation for All-in-One Image Restoration, https://arxiv.org/pdf/2505.12630, 2025-05-18
2025-11-11 00:52:29,632 - INFO - root - Page:5, Index:22, Guiding Diffusion with Deep Geometric Moments: Balancing Fidelity and Variation, https://arxiv.org/pdf/2505.12486, 2025-05-18
2025-11-11 00:52:29,632 - INFO - root - Page:5, Index:23, Learning to Highlight Audio by Watching Movies, https://arxiv.org/pdf/2505.12154, 2025-05-17
2025-11-11 00:52:29,632 - INFO - root - Page:5, Index:24, Understanding the Capabilities of Molecular Graph Neural Networks in Materials Science Through Multimodal Learning and Physical Context Encoding, https://arxiv.org/pdf/2505.12137, 2025-05-17
2025-11-11 00:52:29,632 - INFO - root - Page:5, Index:25, iSegMan: Interactive Segment-and-Manipulate 3D Gaussians, https://arxiv.org/pdf/2505.11934, 2025-05-17
2025-11-11 00:52:29,634 - INFO - root - Page:5, Index:26, Self-Learning Hyperspectral and Multispectral Image Fusion via Adaptive Residual Guided Subspace Diffusion Model, https://arxiv.org/pdf/2505.11800, 2025-05-16
2025-11-11 00:52:29,634 - INFO - root - Page:5, Index:27, X-Edit: Detecting and Localizing Edits in Images Altered by Text-Guided Diffusion Models, https://arxiv.org/pdf/2505.11753, 2025-05-16
2025-11-11 00:52:29,635 - INFO - root - Page:5, Index:28, MTevent: A Multi-Task Event Camera Dataset for 6D Pose Estimation and Moving Object Detection, https://arxiv.org/pdf/2505.11282, 2025-06-02
2025-11-11 00:52:29,637 - INFO - root - Page:5, Index:29, Imputation-free and Alignment-free: Incomplete Multi-view Clustering Driven by Consensus Semantic Learning, https://arxiv.org/pdf/2505.11182, 2025-05-16
2025-11-11 00:52:29,637 - INFO - root - Page:5, Index:30, MultiLink: Multi-class Structure Recovery via Agglomerative Clustering and Model Selection, https://arxiv.org/pdf/2505.10874, 2025-05-16
2025-11-11 00:52:29,637 - INFO - root - Page:5, Index:31, RefPose: Leveraging Reference Geometric Correspondences for Accurate 6D Pose Estimation of Unseen Objects, https://arxiv.org/pdf/2505.10841, 2025-05-16
2025-11-11 00:52:29,637 - INFO - root - Page:5, Index:32, MoCLIP: Motion-Aware Fine-Tuning and Distillation of CLIP for Human Motion Generation, https://arxiv.org/pdf/2505.10810, 2025-05-15
2025-11-11 00:52:29,639 - INFO - root - Page:5, Index:33, Automated Detection of Salvin's Albatrosses: Improving Deep Learning Tools for Aerial Wildlife Surveys, https://arxiv.org/pdf/2505.10737, 2025-05-15
2025-11-11 00:52:29,641 - INFO - root - Page:5, Index:34, Advancing Multiple Instance Learning with Continual Learning for Whole Slide Imaging, https://arxiv.org/pdf/2505.10649, 2025-05-15
2025-11-11 00:52:29,641 - INFO - root - Page:5, Index:35, Inferring Driving Maps by Deep Learning-based Trail Map Extraction, https://arxiv.org/pdf/2505.10258, 2025-05-15
2025-11-11 00:52:29,643 - INFO - root - Page:5, Index:36, Behind Maya: Building a Multilingual Vision Language Model, https://arxiv.org/pdf/2505.08910, 2025-05-15
2025-11-11 00:52:29,646 - INFO - root - Page:5, Index:37, PosterO: Structuring Layout Trees to Enable Language Models in Generalized Content-Aware Layout Generation, https://arxiv.org/pdf/2505.07843, 2025-05-26
2025-11-11 00:52:29,649 - INFO - root - Page:5, Index:38, Prototype Augmented Hypernetworks for Continual Learning, https://arxiv.org/pdf/2505.07450, 2025-05-16
2025-11-11 00:52:29,652 - INFO - root - Fetching page 7 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=300
2025-11-11 00:52:36,246 - INFO - root - get_all_titles_from_web 
2025-11-11 00:52:36,246 - INFO - root - Page:6, Index:0, Convex Relaxation for Robust Vanishing Point Estimation in Manhattan World, https://arxiv.org/pdf/2505.04788, 2025-06-05
2025-11-11 00:52:36,248 - INFO - root - Page:6, Index:1, S3D: Sketch-Driven 3D Model Generation, https://arxiv.org/pdf/2505.04185, 2025-06-03
2025-11-11 00:52:36,252 - INFO - root - Page:6, Index:2, Generating Synthetic Data via Augmentations for Improved Facial Resemblance in DreamBooth and InstantID, https://arxiv.org/pdf/2505.03557, 2025-07-17
2025-11-11 00:52:36,252 - INFO - root - Page:6, Index:3, CAV-MAE Sync: Improving Contrastive Audio-Visual Mask Autoencoders via Fine-Grained Alignment, https://arxiv.org/pdf/2505.01237, 2025-05-21
2025-11-11 00:52:36,256 - INFO - root - Fetching page 8 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=350
2025-11-11 00:52:42,951 - INFO - root - get_all_titles_from_web 
2025-11-11 00:52:42,951 - INFO - root - Page:7, Index:0, Where's the liability in the Generative Era? Recovery-based Black-Box Detection of AI-Generated Content, https://arxiv.org/pdf/2505.01008, 2025-08-25
2025-11-11 00:52:42,952 - INFO - root - Page:7, Index:1, SpatialLLM: A Compound 3D-Informed Design towards Spatially-Intelligent Large Multimodal Models, https://arxiv.org/pdf/2505.00788, 2025-06-10
2025-11-11 00:52:42,953 - INFO - root - Page:7, Index:2, Prisma: An Open Source Toolkit for Mechanistic Interpretability in Vision and Video, https://arxiv.org/pdf/2504.19475, 2025-06-03
2025-11-11 00:52:42,954 - INFO - root - Page:7, Index:3, SSL4Eco: A Global Seasonal Dataset for Geospatial Foundation Models in Ecology, https://arxiv.org/pdf/2504.18256, 2025-10-20
2025-11-11 00:52:42,954 - INFO - root - Page:7, Index:4, Vision-Language Models Are Not Pragmatically Competent in Referring Expression Generation, https://arxiv.org/pdf/2504.16060, 2025-07-30
2025-11-11 00:52:42,961 - INFO - root - Fetching page 9 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=400
2025-11-11 00:52:49,900 - INFO - root - get_all_titles_from_web 
2025-11-11 00:52:49,909 - INFO - root - Page:8, Index:0, Leveraging Automatic CAD Annotations for Supervised Learning in 3D Scene Understanding, https://arxiv.org/pdf/2504.13580, 2025-05-16
2025-11-11 00:52:49,919 - INFO - root - Page:8, Index:1, CAP-Net: A Unified Network for 6D Pose and Size Estimation of Categorical Articulated Parts from a Single RGB-D Image, https://arxiv.org/pdf/2504.11230, 2025-06-02
2025-11-11 00:52:49,936 - INFO - root - Page:8, Index:2, Video Summarization with Large Language Models, https://arxiv.org/pdf/2504.11199, 2025-06-05
2025-11-11 00:52:49,957 - INFO - root - Page:8, Index:3, R-TPT: Improving Adversarial Robustness of Vision-Language Models through Test-Time Prompt Tuning, https://arxiv.org/pdf/2504.11195, 2025-08-27
2025-11-11 00:52:49,973 - INFO - root - Page:8, Index:4, TerraMesh: A Planetary Mosaic of Multimodal Earth Observation Data, https://arxiv.org/pdf/2504.11172, 2025-08-01
2025-11-11 00:52:49,986 - INFO - root - Page:8, Index:5, Seeing like a Cephalopod: Colour Vision with a Monochrome Event Camera, https://arxiv.org/pdf/2504.10984, 2025-06-06
2025-11-11 00:52:49,994 - INFO - root - Page:8, Index:6, Hearing Anywhere in Any Environment, https://arxiv.org/pdf/2504.10746, 2025-06-04
2025-11-11 00:52:50,007 - INFO - root - Fetching page 10 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=450
2025-11-11 00:52:56,382 - INFO - root - get_all_titles_from_web 
2025-11-11 00:52:56,383 - INFO - root - Page:9, Index:0, Correlative and Discriminative Label Grouping for Multi-Label Visual Prompt Tuning, https://arxiv.org/pdf/2504.09990, 2025-07-09
2025-11-11 00:52:56,383 - INFO - root - Page:9, Index:1, SPICE: A Synergistic, Precise, Iterative, and Customizable Image Editing Workflow, https://arxiv.org/pdf/2504.09697, 2025-10-16
2025-11-11 00:52:56,383 - INFO - root - Page:9, Index:2, Mimic In-Context Learning for Multimodal Tasks, https://arxiv.org/pdf/2504.08851, 2025-05-17
2025-11-11 00:52:56,383 - INFO - root - Page:9, Index:3, Digital Twin Catalog: A Large-Scale Photorealistic 3D Object Digital Twin Dataset, https://arxiv.org/pdf/2504.08541, 2025-05-18
2025-11-11 00:52:56,384 - INFO - root - Page:9, Index:4, MMLA: Multi-Environment, Multi-Species, Low-Altitude Drone Dataset, https://arxiv.org/pdf/2504.07744, 2025-10-22
2025-11-11 00:52:56,384 - INFO - root - Fetching page 11 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=500
2025-11-11 00:53:02,604 - INFO - root - get_all_titles_from_web 
2025-11-11 00:53:02,605 - INFO - root - Page:10, Index:0, PromptHMR: Promptable Human Mesh Recovery, https://arxiv.org/pdf/2504.06397, 2025-05-23
2025-11-11 00:53:02,605 - INFO - root - Page:10, Index:1, SCAM: A Real-World Typographic Robustness Evaluation for Multimodal Foundation Models, https://arxiv.org/pdf/2504.04893, 2025-09-26
2025-11-11 00:53:02,606 - INFO - root - Fetching page 12 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=550
2025-11-11 00:53:09,285 - INFO - root - get_all_titles_from_web 
2025-11-11 00:53:09,286 - INFO - root - Page:11, Index:0, Charm: The Missing Piece in ViT fine-tuning for Image Aesthetic Assessment, https://arxiv.org/pdf/2504.02522, 2025-05-15
2025-11-11 00:53:09,286 - INFO - root - Page:11, Index:1, T*: Re-thinking Temporal Search for Long-Form Video Understanding, https://arxiv.org/pdf/2504.02259, 2025-08-24
2025-11-11 00:53:09,287 - INFO - root - Page:11, Index:2, CoMatcher: Multi-View Collaborative Feature Matching, https://arxiv.org/pdf/2504.01872, 2025-08-20
2025-11-11 00:53:09,287 - INFO - root - Page:11, Index:3, Think Small, Act Big: Primitive Prompt Learning for Lifelong Robot Manipulation, https://arxiv.org/pdf/2504.00420, 2025-06-01
2025-11-11 00:53:09,287 - INFO - root - Fetching page 13 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=600
2025-11-11 00:53:16,159 - INFO - root - get_all_titles_from_web 
2025-11-11 00:53:16,159 - INFO - root - Page:12, Index:0, It's a (Blind) Match! Towards Vision-Language Correspondence without Parallel Data, https://arxiv.org/pdf/2503.24129, 2025-05-29
2025-11-11 00:53:16,159 - INFO - root - Page:12, Index:1, ReferDINO-Plus: 2nd Solution for 4th PVUW MeViS Challenge at CVPR 2025, https://arxiv.org/pdf/2503.23509, 2025-05-29
2025-11-11 00:53:16,161 - INFO - root - Page:12, Index:2, A Unified Image-Dense Annotation Generation Model for Underwater Scenes, https://arxiv.org/pdf/2503.21771, 2025-07-27
2025-11-11 00:53:16,161 - INFO - root - Fetching page 14 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=650
2025-11-11 00:53:22,725 - INFO - root - get_all_titles_from_web 
2025-11-11 00:53:22,726 - INFO - root - Page:13, Index:0, Learning Class Prototypes for Unified Sparse Supervised 3D Object Detection, https://arxiv.org/pdf/2503.21099, 2025-06-13
2025-11-11 00:53:22,727 - INFO - root - Page:13, Index:1, LATTE-MV: Learning to Anticipate Table Tennis Hits from Monocular Videos, https://arxiv.org/pdf/2503.20936, 2025-09-01
2025-11-11 00:53:22,731 - INFO - root - Page:13, Index:2, BizGen: Advancing Article-level Visual Text Rendering for Infographics Generation, https://arxiv.org/pdf/2503.20672, 2025-07-02
2025-11-11 00:53:22,732 - INFO - root - Page:13, Index:3, ITA-MDT: Image-Timestep-Adaptive Masked Diffusion Transformer Framework for Image-Based Virtual Try-On, https://arxiv.org/pdf/2503.20418, 2025-06-01
2025-11-11 00:53:22,734 - INFO - root - Page:13, Index:4, Faster Parameter-Efficient Tuning with Token Redundancy Reduction, https://arxiv.org/pdf/2503.20282, 2025-08-26
2025-11-11 00:53:22,734 - INFO - root - Page:13, Index:5, DINeMo: Learning Neural Mesh Models with no 3D Annotations, https://arxiv.org/pdf/2503.20220, 2025-06-09
2025-11-11 00:53:22,736 - INFO - root - Page:13, Index:6, Scaling Vision Pre-Training to 4K Resolution, https://arxiv.org/pdf/2503.19903, 2025-08-03
2025-11-11 00:53:22,737 - INFO - root - Page:13, Index:7, GENIUS: A Generative Framework for Universal Multimodal Search, https://arxiv.org/pdf/2503.19868, 2025-06-05
2025-11-11 00:53:22,738 - INFO - root - Fetching page 15 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=700
2025-11-11 00:53:29,330 - INFO - root - get_all_titles_from_web 
2025-11-11 00:53:29,330 - INFO - root - Page:14, Index:0, Galaxy Walker: Geometry-aware VLMs For Galaxy-scale Understanding, https://arxiv.org/pdf/2503.18578, 2025-05-25
2025-11-11 00:53:29,331 - INFO - root - Page:14, Index:1, LookCloser: Frequency-aware Radiance Field for Tiny-Detail Scene, https://arxiv.org/pdf/2503.18513, 2025-07-29
2025-11-11 00:53:29,331 - INFO - root - Fetching page 16 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=750
2025-11-11 00:53:35,662 - INFO - root - get_all_titles_from_web 
2025-11-11 00:53:35,662 - INFO - root - Page:15, Index:0, LoTUS: Large-Scale Machine Unlearning with a Taste of Uncertainty, https://arxiv.org/pdf/2503.18314, 2025-05-29
2025-11-11 00:53:35,662 - INFO - root - Page:15, Index:1, MammAlps: A multi-view video behavior monitoring dataset of wild mammals in the Swiss Alps, https://arxiv.org/pdf/2503.18223, 2025-06-04
2025-11-11 00:53:35,663 - INFO - root - Page:15, Index:2, Progressive Prompt Detailing for Improved Alignment in Text-to-Image Generative Models, https://arxiv.org/pdf/2503.17794, 2025-05-30
2025-11-11 00:53:35,663 - INFO - root - Page:15, Index:3, CountLLM: Towards Generalizable Repetitive Action Counting via Large Language Model, https://arxiv.org/pdf/2503.17690, 2025-06-29
2025-11-11 00:53:35,663 - INFO - root - Page:15, Index:4, TaoAvatar: Real-Time Lifelike Full-Body Talking Avatars for Augmented Reality via 3D Gaussian Splatting, https://arxiv.org/pdf/2503.17032, 2025-07-23
2025-11-11 00:53:35,663 - INFO - root - Page:15, Index:5, Generalized Few-shot 3D Point Cloud Segmentation with Vision-Language Model, https://arxiv.org/pdf/2503.16282, 2025-05-20
2025-11-11 00:53:35,664 - INFO - root - Fetching page 17 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=800
2025-11-11 00:53:43,084 - INFO - root - get_all_titles_from_web 
2025-11-11 00:53:43,085 - INFO - root - Page:16, Index:0, High Temporal Consistency through Semantic Similarity Propagation in Semi-Supervised Video Semantic Segmentation for Autonomous Flight, https://arxiv.org/pdf/2503.15676, 2025-06-26
2025-11-11 00:53:43,086 - INFO - root - Page:16, Index:1, DPFlow: Adaptive Optical Flow Estimation with a Dual-Pyramid Framework, https://arxiv.org/pdf/2503.14880, 2025-09-29
2025-11-11 00:53:43,086 - INFO - root - Fetching page 18 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=850
2025-11-11 00:53:50,096 - INFO - root - get_all_titles_from_web 
2025-11-11 00:53:50,115 - INFO - root - Page:17, Index:0, From Head to Tail: Towards Balanced Representation in Large Vision-Language Models through Adaptive Data Calibration, https://arxiv.org/pdf/2503.12821, 2025-05-29
2025-11-11 00:53:50,116 - INFO - root - Page:17, Index:1, MambaIC: State Space Models for High-Performance Learned Image Compression, https://arxiv.org/pdf/2503.12461, 2025-08-22
2025-11-11 00:53:50,117 - INFO - root - Page:17, Index:2, Localized Concept Erasure for Text-to-Image Diffusion Models Using Training-Free Gated Low-Rank Adaptation, https://arxiv.org/pdf/2503.12356, 2025-07-09
2025-11-11 00:53:50,117 - INFO - root - Page:17, Index:3, TASTE-Rob: Advancing Video Generation of Task-Oriented Hand-Object Interaction for Generalizable Robotic Manipulation, https://arxiv.org/pdf/2503.11423, 2025-06-05
2025-11-11 00:53:50,118 - INFO - root - Page:17, Index:4, Panopticon: Advancing Any-Sensor Foundation Models for Earth Observation, https://arxiv.org/pdf/2503.10845, 2025-08-01
2025-11-11 00:53:50,119 - INFO - root - Page:17, Index:5, Transformers without Normalization, https://arxiv.org/pdf/2503.10622, 2025-06-14
2025-11-11 00:53:50,119 - INFO - root - Page:17, Index:6, dFLMoE: Decentralized Federated Learning via Mixture of Experts for Medical Data Analysis, https://arxiv.org/pdf/2503.10412, 2025-05-19
2025-11-11 00:53:50,120 - INFO - root - Fetching page 19 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=900
2025-11-11 00:53:56,899 - INFO - root - get_all_titles_from_web 
2025-11-11 00:53:56,900 - INFO - root - Page:18, Index:0, Project-Probe-Aggregate: Efficient Fine-Tuning for Group Robustness, https://arxiv.org/pdf/2503.09487, 2025-08-26
2025-11-11 00:53:56,900 - INFO - root - Page:18, Index:1, VLog: Video-Language Models by Generative Retrieval of Narration Vocabulary, https://arxiv.org/pdf/2503.09402, 2025-06-09
2025-11-11 00:53:56,900 - INFO - root - Fetching page 20 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=950
2025-11-11 00:54:04,043 - INFO - root - get_all_titles_from_web 
2025-11-11 00:54:04,044 - INFO - root - Page:19, Index:0, Escaping Plato's Cave: Towards the Alignment of 3D and Text Latent Spaces, https://arxiv.org/pdf/2503.05283, 2025-06-04
2025-11-11 00:54:04,044 - INFO - root - Page:19, Index:1, FluidNexus: 3D Fluid Reconstruction and Prediction from a Single Video, https://arxiv.org/pdf/2503.04720, 2025-07-09
2025-11-11 00:54:04,044 - INFO - root - Page:19, Index:2, Question-Aware Gaussian Experts for Audio-Visual Question Answering, https://arxiv.org/pdf/2503.04459, 2025-06-11
2025-11-11 00:54:04,045 - INFO - root - Page:19, Index:3, Q-Eval-100K: Evaluating Visual Quality and Alignment Level for Text-to-Vision Content, https://arxiv.org/pdf/2503.02357, 2025-06-15
2025-11-11 00:54:04,045 - INFO - root - Fetching page 21 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=1000
2025-11-11 00:54:11,758 - INFO - root - get_all_titles_from_web 
2025-11-11 00:54:11,758 - INFO - root - Page:20, Index:0, Data Distributional Properties As Inductive Bias for Systematic Generalization, https://arxiv.org/pdf/2502.20499, 2025-06-17
2025-11-11 00:54:11,758 - INFO - root - Page:20, Index:1, Knowledge Bridger: Towards Training-free Missing Modality Completion, https://arxiv.org/pdf/2502.19834, 2025-06-17
2025-11-11 00:54:11,758 - INFO - root - Fetching page 22 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=1050
2025-11-11 00:54:18,063 - INFO - root - get_all_titles_from_web 
2025-11-11 00:54:18,064 - INFO - root - Page:21, Index:0, MALT Diffusion: Memory-Augmented Latent Transformers for Any-Length Video Generation, https://arxiv.org/pdf/2502.12632, 2025-07-08
2025-11-11 00:54:18,064 - INFO - root - Page:21, Index:1, ILIAS: Instance-Level Image retrieval At Scale, https://arxiv.org/pdf/2502.11748, 2025-06-23
2025-11-11 00:54:18,065 - INFO - root - Page:21, Index:2, Distraction is All You Need for Multimodal Large Language Model Jailbreaking, https://arxiv.org/pdf/2502.10794, 2025-06-16
2025-11-11 00:54:18,065 - INFO - root - Page:21, Index:3, Spatial457: A Diagnostic Benchmark for 6D Spatial Reasoning of Large Multimodal Models, https://arxiv.org/pdf/2502.08636, 2025-06-08
2025-11-11 00:54:18,065 - INFO - root - Page:21, Index:4, TRAVEL: Training-Free Retrieval and Alignment for Vision-and-Language Navigation, https://arxiv.org/pdf/2502.07306, 2025-06-09
2025-11-11 00:54:18,066 - INFO - root - Page:21, Index:5, DiTASK: Multi-Task Fine-Tuning with Diffeomorphic Transformations, https://arxiv.org/pdf/2502.06029, 2025-06-01
2025-11-11 00:54:18,066 - INFO - root - Page:21, Index:6, ConceptAttention: Diffusion Transformers Learn Highly Interpretable Features, https://arxiv.org/pdf/2502.04320, 2025-07-01
2025-11-11 00:54:18,071 - INFO - root - Page:21, Index:7, GCE-Pose: Global Context Enhancement for Category-level Object Pose Estimation, https://arxiv.org/pdf/2502.04293, 2025-06-24
2025-11-11 00:54:18,072 - INFO - root - Page:21, Index:8, Calibrated Multi-Preference Optimization for Aligning Diffusion Models, https://arxiv.org/pdf/2502.02588, 2025-09-26
2025-11-11 00:54:18,074 - INFO - root - Page:21, Index:9, Instruct-4DGS: Efficient Dynamic Scene Editing via 4D Gaussian-based Static-Dynamic Separation, https://arxiv.org/pdf/2502.02091, 2025-07-01
2025-11-11 00:54:18,074 - INFO - root - Page:21, Index:10, Low-Resource Video Super-Resolution using Memory, Wavelets, and Deformable Convolutions, https://arxiv.org/pdf/2502.01816, 2025-06-19
2025-11-11 00:54:18,075 - INFO - root - Page:21, Index:11, Bridging Text and Crystal Structures: Literature-driven Contrastive Learning for Materials Science, https://arxiv.org/pdf/2501.12919, 2025-06-18
2025-11-11 00:54:18,075 - INFO - root - Page:21, Index:12, T2ISafety: Benchmark for Assessing Fairness, Toxicity, and Privacy in Image Generation, https://arxiv.org/pdf/2501.12612, 2025-07-25
2025-11-11 00:54:18,076 - INFO - root - Page:21, Index:13, Fine-Grained Image-Text Correspondence with Cost Aggregation for Open-Vocabulary Part Segmentation, https://arxiv.org/pdf/2501.09688, 2025-08-08
2025-11-11 00:54:18,076 - INFO - root - Fetching page 23 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=1100
2025-11-11 00:54:24,555 - INFO - root - get_all_titles_from_web 
2025-11-11 00:54:24,557 - INFO - root - Page:22, Index:0, Bias for Action: Video Implicit Neural Representations with Bias Modulation, https://arxiv.org/pdf/2501.09277, 2025-06-06
2025-11-11 00:54:24,559 - INFO - root - Page:22, Index:1, MonSter++: Unified Stereo Matching, Multi-view Stereo, and Real-time Stereo with Monodepth Priors, https://arxiv.org/pdf/2501.08643, 2025-09-25
2025-11-11 00:54:24,559 - INFO - root - Page:22, Index:2, Go-with-the-Flow: Motion-Controllable Video Diffusion Models Using Real-Time Warped Noise, https://arxiv.org/pdf/2501.08331, 2025-08-06
2025-11-11 00:54:24,559 - INFO - root - Page:22, Index:3, Nonisotropic Gaussian Diffusion for Realistic 3D Human Motion Prediction, https://arxiv.org/pdf/2501.06035, 2025-07-08
2025-11-11 00:54:24,559 - INFO - root - Page:22, Index:4, Discovering Hidden Visual Concepts Beyond Linguistic Input in Infant Learning, https://arxiv.org/pdf/2501.05205, 2025-06-13
2025-11-11 00:54:24,560 - INFO - root - Page:22, Index:5, PERSE: Personalized 3D Generative Avatars from A Single Portrait, https://arxiv.org/pdf/2412.21206, 2025-09-28
2025-11-11 00:54:24,560 - INFO - root - Page:22, Index:6, MaskGaussian: Adaptive 3D Gaussian Representation from Probabilistic Masks, https://arxiv.org/pdf/2412.20522, 2025-06-14
2025-11-11 00:54:24,560 - INFO - root - Page:22, Index:7, SimLTD: Simple Supervised and Semi-Supervised Long-Tailed Object Detection, https://arxiv.org/pdf/2412.20047, 2025-06-09
2025-11-11 00:54:24,560 - INFO - root - Page:22, Index:8, Conditional Balance: Improving Multi-Conditioning Trade-Offs in Image Generation, https://arxiv.org/pdf/2412.19853, 2025-08-03
2025-11-11 00:54:24,560 - INFO - root - Fetching page 24 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=1150
2025-11-11 00:54:31,036 - INFO - root - get_all_titles_from_web 
2025-11-11 00:54:31,037 - INFO - root - Page:23, Index:0, CoCoGaussian: Leveraging Circle of Confusion for Gaussian Splatting from Defocused Images, https://arxiv.org/pdf/2412.16028, 2025-05-15
2025-11-11 00:54:31,037 - INFO - root - Page:23, Index:1, EnergyMoGen: Compositional Human Motion Generation with Energy-Based Diffusion Model in Latent Space, https://arxiv.org/pdf/2412.14706, 2025-06-04
2025-11-11 00:54:31,038 - INFO - root - Page:23, Index:2, DarkIR: Robust Low-Light Image Restoration, https://arxiv.org/pdf/2412.13443, 2025-10-14
2025-11-11 00:54:31,038 - INFO - root - Page:23, Index:3, FastVLM: Efficient Vision Encoding for Vision Language Models, https://arxiv.org/pdf/2412.13303, 2025-05-15
2025-11-11 00:54:31,038 - INFO - root - Page:23, Index:4, Real-time Free-view Human Rendering from Sparse-view RGB Videos using Double Unprojected Textures, https://arxiv.org/pdf/2412.13183, 2025-06-20
2025-11-11 00:54:31,038 - INFO - root - Page:23, Index:5, CondiMen: Conditional Multi-Person Mesh Recovery, https://arxiv.org/pdf/2412.13058, 2025-06-04
2025-11-11 00:54:31,039 - INFO - root - Page:23, Index:6, MASt3R-SLAM: Real-Time Dense SLAM with 3D Reconstruction Priors, https://arxiv.org/pdf/2412.12392, 2025-06-02
2025-11-11 00:54:31,040 - INFO - root - Page:23, Index:7, DynamicScaler: Seamless and Scalable Video Generation for Panoramic Scenes, https://arxiv.org/pdf/2412.11100, 2025-10-04
2025-11-11 00:54:31,040 - INFO - root - Page:23, Index:8, SnapGen-V: Generating a Five-Second Video within Five Seconds on a Mobile Device, https://arxiv.org/pdf/2412.10494, 2025-06-09
2025-11-11 00:54:31,040 - INFO - root - Page:23, Index:9, Mr. DETR++: Instructive Multi-Route Training for Detection Transformers with Mixture-of-Experts, https://arxiv.org/pdf/2412.10028, 2025-06-26
2025-11-11 00:54:31,041 - INFO - root - Page:23, Index:10, LinGen: Towards High-Resolution Minute-Length Text-to-Video Generation with Linear Computational Complexity, https://arxiv.org/pdf/2412.09856, 2025-05-24
2025-11-11 00:54:31,041 - INFO - root - Page:23, Index:11, Gaze-LLE: Gaze Target Estimation via Large-Scale Learned Encoders, https://arxiv.org/pdf/2412.09586, 2025-06-03
2025-11-11 00:54:31,041 - INFO - root - Fetching page 25 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=1200
2025-11-11 00:54:38,876 - INFO - root - get_all_titles_from_web 
2025-11-11 00:54:38,877 - INFO - root - Page:24, Index:0, From Slow Bidirectional to Fast Autoregressive Video Diffusion Models, https://arxiv.org/pdf/2412.07772, 2025-09-23
2025-11-11 00:54:38,878 - INFO - root - Page:24, Index:1, Rate-In: Information-Driven Adaptive Dropout Rates for Improved Inference-Time Uncertainty Estimation, https://arxiv.org/pdf/2412.07169, 2025-06-03
2025-11-11 00:54:38,878 - INFO - root - Page:24, Index:2, FIRE: Robust Detection of Diffusion-Generated Images via Frequency-Guided Reconstruction Error, https://arxiv.org/pdf/2412.07140, 2025-11-03
2025-11-11 00:54:38,878 - INFO - root - Page:24, Index:3, Birth and Death of a Rose, https://arxiv.org/pdf/2412.05278, 2025-06-05
2025-11-11 00:54:38,879 - INFO - root - Page:24, Index:4, DualPM: Dual Posed-Canonical Point Maps for 3D Shape and Pose Reconstruction, https://arxiv.org/pdf/2412.04464, 2025-08-14
2025-11-11 00:54:38,879 - INFO - root - Page:24, Index:5, SeeGround: See and Ground for Zero-Shot Open-Vocabulary 3D Visual Grounding, https://arxiv.org/pdf/2412.04383, 2025-05-29
2025-11-11 00:54:38,879 - INFO - root - ------------------------------------------------------------------------------------------------------------------------
2025-11-11 00:54:38,899 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\CVPR 2025\Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness.pdf
2025-11-11 00:54:38,907 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\CVPR 2025\OmniTrack++_ Omnidirectional Multi-Object Tracking by Learning Large-FoV Traject.pdf
2025-11-11 00:54:38,909 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\CVPR 2025\NeuCo-Bench_ A Novel Benchmark Framework for Neural Embeddings in Earth Observat.pdf
2025-11-11 00:54:38,910 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\CVPR 2025\NTIRE 2025 Challenge on Low Light Image Enhancement_ Methods and Results.pdf
2025-11-11 00:54:38,911 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\CVPR 2025\Class Prototypes based Contrastive Learning for Classifying Multi-Label and Fine.pdf
2025-11-11 00:54:38,913 - INFO - root - 跳过已处理论文 Learning to Seek Evidence: A Verifiable Reasoning Agent with Causal Faithfulness Analysis：d:\ChatPaper\academic Papers\CVPR 2025\Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness.pdf
2025-11-11 00:54:38,914 - INFO - root - 跳过已处理论文 OmniTrack++: Omnidirectional Multi-Object Tracking by Learning Large-FoV Trajectory Feedback：d:\ChatPaper\academic Papers\CVPR 2025\OmniTrack++_ Omnidirectional Multi-Object Tracking by Learning Large-FoV Traject.pdf
2025-11-11 00:54:38,914 - INFO - root - 跳过已处理论文 NeuCo-Bench: A Novel Benchmark Framework for Neural Embeddings in Earth Observation：d:\ChatPaper\academic Papers\CVPR 2025\NeuCo-Bench_ A Novel Benchmark Framework for Neural Embeddings in Earth Observat.pdf
2025-11-11 00:54:38,915 - INFO - root - 正在总结论文 4/5: NTIRE 2025 Challenge on Low Light Image Enhancement: Methods and Results
2025-11-11 00:57:12,888 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-11 00:57:12,891 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-11 00:57:12,893 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-11 00:57:13,950 - INFO - root - LLMClientManager: 指定使用客户端: Gemini
2025-11-11 00:57:14,646 - INFO - root - GeminiClient: trying model models/gemini-2.5-flash
2025-11-11 00:57:19,087 - INFO - root - GeminiClient: initialized model gemini-2.5-flash
2025-11-11 00:57:19,087 - INFO - root - LLMClientManager: Gemini 客户端初始化成功
2025-11-11 00:57:19,087 - INFO - root - LLMClientManager: switched to Gemini client
2025-11-11 00:57:19,088 - INFO - root - 已手动切换到 LLM 客户端: Gemini
2025-11-11 00:57:19,088 - INFO - root - 使用 LLM 模型: gemini-2.5-flash
2025-11-11 00:57:19,090 - INFO - root - 可用客户端: ['Gemini']
2025-11-11 00:57:19,091 - INFO - root - === 运行配置 ===
2025-11-11 00:57:19,091 - INFO - root - 处理模式: arxiv在线搜索
2025-11-11 00:57:19,092 - INFO - root - 关键词: CVPR
2025-11-11 00:57:19,093 - INFO - root - 查询: CVPR 2025
2025-11-11 00:57:19,095 - INFO - root - 排序: None
2025-11-11 00:57:19,097 - INFO - root - 最近天数: 180
2025-11-11 00:57:19,105 - INFO - root - 最大处理数量: 5
2025-11-11 00:57:19,106 - INFO - root - 保存图片: 是
2025-11-11 00:57:19,108 - INFO - root - 输出语言: 中文
2025-11-11 00:57:19,108 - INFO - root - 强制重新处理: 否
2025-11-11 00:57:19,109 - INFO - root - ====================
2025-11-11 00:57:19,109 - INFO - root - 使用 arXiv 搜索模式（通过 chat_arxiv 模块获取）
2025-11-11 00:57:19,111 - INFO - root - Fetching page 1 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50
2025-11-11 00:57:25,835 - INFO - root - get_all_titles_from_web 
2025-11-11 00:57:25,836 - INFO - root - Page:0, Index:0, Learning to Seek Evidence: A Verifiable Reasoning Agent with Causal Faithfulness Analysis, https://arxiv.org/pdf/2511.01425, 2025-11-03
2025-11-11 00:57:25,836 - INFO - root - Page:0, Index:1, OmniTrack++: Omnidirectional Multi-Object Tracking by Learning Large-FoV Trajectory Feedback, https://arxiv.org/pdf/2511.00510, 2025-11-01
2025-11-11 00:57:25,838 - INFO - root - Page:0, Index:2, NeuCo-Bench: A Novel Benchmark Framework for Neural Embeddings in Earth Observation, https://arxiv.org/pdf/2510.17914, 2025-10-19
2025-11-11 00:57:25,838 - INFO - root - Page:0, Index:3, NTIRE 2025 Challenge on Low Light Image Enhancement: Methods and Results, https://arxiv.org/pdf/2510.13670, 2025-10-15
2025-11-11 00:57:25,838 - INFO - root - Page:0, Index:4, Class Prototypes based Contrastive Learning for Classifying Multi-Label and Fine-Grained Educational Videos, https://arxiv.org/pdf/2510.11204, 2025-10-13
2025-11-11 00:57:25,839 - INFO - root - Page:0, Index:5, MIMO: A medical vision language model with visual referring multimodal input and pixel grounding multimodal output, https://arxiv.org/pdf/2510.10011, 2025-10-11
2025-11-11 00:57:25,839 - INFO - root - Page:0, Index:6, Vision Language Models: A Survey of 26K Papers, https://arxiv.org/pdf/2510.09586, 2025-10-10
2025-11-11 00:57:25,839 - INFO - root - Page:0, Index:7, DiT-VTON: Diffusion Transformer Framework for Unified Multi-Category Virtual Try-On and Virtual Try-All with Integrated Image Editing, https://arxiv.org/pdf/2510.04797, 2025-10-03
2025-11-11 00:57:25,841 - INFO - root - Page:0, Index:8, PatchVSR: Breaking Video Diffusion Resolution Limits with Patch-wise Video Super-Resolution, https://arxiv.org/pdf/2509.26025, 2025-09-30
2025-11-11 00:57:25,841 - INFO - root - Page:0, Index:9, FreqDebias: Towards Generalizable Deepfake Detection via Consistency-Driven Frequency Debiasing, https://arxiv.org/pdf/2509.22412, 2025-09-26
2025-11-11 00:57:25,841 - INFO - root - Page:0, Index:10, A Mutual Learning Method for Salient Object Detection with intertwined Multi-Supervision--Revised, https://arxiv.org/pdf/2509.21363, 2025-09-21
2025-11-11 00:57:25,842 - INFO - root - Page:0, Index:11, InstructVTON: Optimal Auto-Masking and Natural-Language-Guided Interactive Style Control for Inpainting-Based Virtual Try-On, https://arxiv.org/pdf/2509.20524, 2025-09-24
2025-11-11 00:57:25,843 - INFO - root - Page:0, Index:12, Efficient Encoder-Free Pose Conditioning and Pose Control for Virtual Try-On, https://arxiv.org/pdf/2509.20343, 2025-09-24
2025-11-11 00:57:25,844 - INFO - root - Page:0, Index:13, The Photographer Eye: Teaching Multimodal Large Language Models to Understand Image Aesthetics like Photographers, https://arxiv.org/pdf/2509.18582, 2025-10-22
2025-11-11 00:57:25,846 - INFO - root - Page:0, Index:14, ENSAM: an efficient foundation model for interactive segmentation of 3D medical images, https://arxiv.org/pdf/2509.15874, 2025-09-19
2025-11-11 00:57:25,846 - INFO - root - Page:0, Index:15, DEFT-VTON: Efficient Virtual Try-On with Consistent Generalised H-Transform, https://arxiv.org/pdf/2509.13506, 2025-09-16
2025-11-11 00:57:25,847 - INFO - root - Page:0, Index:16, Weakly and Self-Supervised Class-Agnostic Motion Prediction for Autonomous Driving, https://arxiv.org/pdf/2509.13116, 2025-09-16
2025-11-11 00:57:25,850 - INFO - root - Page:0, Index:17, Domain-Adaptive Pretraining Improves Primate Behavior Recognition, https://arxiv.org/pdf/2509.12193, 2025-09-15
2025-11-11 00:57:25,850 - INFO - root - Page:0, Index:18, The System Description of CPS Team for Track on Driving with Language of CVPR 2024 Autonomous Grand Challenge, https://arxiv.org/pdf/2509.11071, 2025-09-13
2025-11-11 00:57:25,850 - INFO - root - Page:0, Index:19, An HMM-based framework for identity-aware long-term multi-object tracking from sparse and uncertain identification: use case on long-term tracking in livestock, https://arxiv.org/pdf/2509.09962, 2025-09-12
2025-11-11 00:57:25,852 - INFO - root - Page:0, Index:20, InterAct: Advancing Large-Scale Versatile 3D Human-Object Interaction Generation, https://arxiv.org/pdf/2509.09555, 2025-09-11
2025-11-11 00:57:25,852 - INFO - root - Page:0, Index:21, Geospatial Foundational Embedder: Top-1 Winning Solution on EarthVision Embed2Scale Challenge (CVPR 2025), https://arxiv.org/pdf/2509.06993, 2025-09-03
2025-11-11 00:57:25,853 - INFO - root - Page:0, Index:22, 2nd Place Solution for CVPR2024 E2E Challenge: End-to-End Autonomous Driving Using Vision Language Model, https://arxiv.org/pdf/2509.02659, 2025-09-02
2025-11-11 00:57:25,855 - INFO - root - Page:0, Index:23, Unsupervised Training of Vision Transformers with Synthetic Negatives, https://arxiv.org/pdf/2509.02024, 2025-09-02
2025-11-11 00:57:25,860 - INFO - root - Page:0, Index:24, MV-SSM: Multi-View State Space Modeling for 3D Human Pose Estimation, https://arxiv.org/pdf/2509.00649, 2025-08-30
2025-11-11 00:57:25,860 - INFO - root - Page:0, Index:25, CryptoFace: End-to-End Encrypted Face Recognition, https://arxiv.org/pdf/2509.00332, 2025-08-29
2025-11-11 00:57:25,860 - INFO - root - Page:0, Index:26, ControlEchoSynth: Boosting Ejection Fraction Estimation Models via Controlled Video Diffusion, https://arxiv.org/pdf/2508.17631, 2025-08-26
2025-11-11 00:57:25,860 - INFO - root - Page:0, Index:27, Explain Before You Answer: A Survey on Compositional Visual Reasoning, https://arxiv.org/pdf/2508.17298, 2025-08-27
2025-11-11 00:57:25,861 - INFO - root - Page:0, Index:28, Investigating Different Geo Priors for Image Classification, https://arxiv.org/pdf/2508.15946, 2025-08-21
2025-11-11 00:57:25,861 - INFO - root - Page:0, Index:29, Towards Source-Free Machine Unlearning, https://arxiv.org/pdf/2508.15127, 2025-08-20
2025-11-11 00:57:25,861 - INFO - root - Page:0, Index:30, MR6D: Benchmarking 6D Pose Estimation for Mobile Robots, https://arxiv.org/pdf/2508.13775, 2025-08-19
2025-11-11 00:57:25,862 - INFO - root - Page:0, Index:31, Calibrating Biased Distribution in VFM-derived Latent Space via Cross-Domain Geometric Consistency, https://arxiv.org/pdf/2508.13518, 2025-08-19
2025-11-11 00:57:25,862 - INFO - root - Page:0, Index:32, SIS-Challenge: Event-based Spatio-temporal Instance Segmentation Challenge at the CVPR 2025 Event-based Vision Workshop, https://arxiv.org/pdf/2508.12813, 2025-08-18
2025-11-11 00:57:25,862 - INFO - root - Page:0, Index:33, Multi-Level Knowledge Distillation and Dynamic Self-Supervised Learning for Continual Learning, https://arxiv.org/pdf/2508.12692, 2025-08-22
2025-11-11 00:57:25,862 - INFO - root - Page:0, Index:34, Stochastic-based Patch Filtering for Few-Shot Learning, https://arxiv.org/pdf/2508.10066, 2025-08-13
2025-11-11 00:57:25,863 - INFO - root - Page:0, Index:35, Slot Attention-based Feature Filtering for Few-Shot Learning, https://arxiv.org/pdf/2508.09699, 2025-08-13
2025-11-11 00:57:25,863 - INFO - root - Page:0, Index:36, Comparison Reveals Commonality: Customized Image Generation through Contrastive Inversion, https://arxiv.org/pdf/2508.07755, 2025-08-11
2025-11-11 00:57:25,864 - INFO - root - Page:0, Index:37, SLRTP2025 Sign Language Production Challenge: Methodology, Results, and Future Work, https://arxiv.org/pdf/2508.06951, 2025-08-09
2025-11-11 00:57:25,864 - INFO - root - Page:0, Index:38, Exploring Fairness across Fine-Grained Attributes in Large Vision-Language Models, https://arxiv.org/pdf/2508.03079, 2025-08-05
2025-11-11 00:57:25,864 - INFO - root - Page:0, Index:39, Devil is in the Detail: Towards Injecting Fine Details of Image Prompt in Image Generation via Conflict-free Guidance and Stratified Attention, https://arxiv.org/pdf/2508.02004, 2025-08-03
2025-11-11 00:57:25,865 - INFO - root - Page:0, Index:40, IAUNet: Instance-Aware U-Net, https://arxiv.org/pdf/2508.01928, 2025-08-03
2025-11-11 00:57:25,865 - INFO - root - Page:0, Index:41, Gaussian Splatting Feature Fields for Privacy-Preserving Visual Localization, https://arxiv.org/pdf/2507.23569, 2025-08-26
2025-11-11 00:57:25,867 - INFO - root - Page:0, Index:42, From Scan to Action: Leveraging Realistic Scans for Embodied Scene Understanding, https://arxiv.org/pdf/2507.17585, 2025-07-23
2025-11-11 00:57:25,867 - INFO - root - Page:0, Index:43, LEAD: Exploring Logit Space Evolution for Model Selection, https://arxiv.org/pdf/2507.14559, 2025-07-19
2025-11-11 00:57:25,867 - INFO - root - Page:0, Index:44, HeCoFuse: Cross-Modal Complementary V2X Cooperative Perception with Heterogeneous Sensors, https://arxiv.org/pdf/2507.13677, 2025-07-18
2025-11-11 00:57:25,868 - INFO - root - Page:0, Index:45, OmniVec2 -- A Novel Transformer based Network for Large Scale Multimodal and Multitask Learning, https://arxiv.org/pdf/2507.13364, 2025-07-06
2025-11-11 00:57:25,868 - INFO - root - Page:0, Index:46, A Training-Free, Task-Agnostic Framework for Enhancing MLLM Performance on High-Resolution Images, https://arxiv.org/pdf/2507.10202, 2025-07-14
2025-11-11 00:57:25,868 - INFO - root - Page:0, Index:47, Quantum Federated Learning for Multimodal Data: A Modality-Agnostic Approach, https://arxiv.org/pdf/2507.08217, 2025-07-10
2025-11-11 00:57:25,869 - INFO - root - Page:0, Index:48, CuriosAI Submission to the EgoExo4D Proficiency Estimation Challenge 2025, https://arxiv.org/pdf/2507.08022, 2025-07-08
2025-11-11 00:57:25,869 - INFO - root - Page:0, Index:49, Rethinking Query-based Transformer for Continual Image Segmentation, https://arxiv.org/pdf/2507.07831, 2025-07-10
2025-11-11 00:57:25,869 - INFO - root - Fetching page 2 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=50
2025-11-11 00:57:32,170 - INFO - root - get_all_titles_from_web 
2025-11-11 00:57:32,170 - INFO - root - Page:1, Index:0, Scalable and Realistic Virtual Try-on Application for Foundation Makeup with Kubelka-Munk Theory, https://arxiv.org/pdf/2507.07333, 2025-07-09
2025-11-11 00:57:32,171 - INFO - root - Page:1, Index:1, Free on the Fly: Enhancing Flexibility in Test-Time Adaptation with Online EM, https://arxiv.org/pdf/2507.06973, 2025-07-09
2025-11-11 00:57:32,171 - INFO - root - Page:1, Index:2, Adaptive Part Learning for Fine-Grained Generalized Category Discovery: A Plug-and-Play Enhancement, https://arxiv.org/pdf/2507.06928, 2025-07-09
2025-11-11 00:57:32,171 - INFO - root - Page:1, Index:3, Grounded Gesture Generation: Language, Motion, and Space, https://arxiv.org/pdf/2507.04522, 2025-07-06
2025-11-11 00:57:32,172 - INFO - root - Page:1, Index:4, Comprehensive Information Bottleneck for Unveiling Universal Attribution to Interpret Vision Transformers, https://arxiv.org/pdf/2507.04388, 2025-07-06
2025-11-11 00:57:32,172 - INFO - root - Page:1, Index:5, ZERO: Industry-ready Vision Foundation Model with Multi-modal Prompts, https://arxiv.org/pdf/2507.04270, 2025-11-07
2025-11-11 00:57:32,172 - INFO - root - Page:1, Index:6, Beyond Accuracy: Metrics that Uncover What Makes a 'Good' Visual Descriptor, https://arxiv.org/pdf/2507.03542, 2025-07-08
2025-11-11 00:57:32,172 - INFO - root - Page:1, Index:7, ConceptMix++: Leveling the Playing Field in Text-to-Image Benchmarking via Iterative Prompt Optimization, https://arxiv.org/pdf/2507.03275, 2025-07-03
2025-11-11 00:57:32,173 - INFO - root - Page:1, Index:8, APT: Adaptive Personalized Training for Diffusion Models with Limited Data, https://arxiv.org/pdf/2507.02687, 2025-07-03
2025-11-11 00:57:32,173 - INFO - root - Page:1, Index:9, DreamComposer++: Empowering Diffusion Models with Multi-View Conditions for 3D Content Generation, https://arxiv.org/pdf/2507.02299, 2025-07-03
2025-11-11 00:57:32,173 - INFO - root - Page:1, Index:10, Soft Self-labeling and Potts Relaxations for Weakly-Supervised Segmentation, https://arxiv.org/pdf/2507.01721, 2025-07-02
2025-11-11 00:57:32,173 - INFO - root - Page:1, Index:11, Interpolation-Based Event Visual Data Filtering Algorithms, https://arxiv.org/pdf/2507.01557, 2025-07-02
2025-11-11 00:57:32,174 - INFO - root - Page:1, Index:12, AVC-DPO: Aligned Video Captioning via Direct Preference Optimization, https://arxiv.org/pdf/2507.01492, 2025-07-02
2025-11-11 00:57:32,174 - INFO - root - Page:1, Index:13, NN-Former: Rethinking Graph Structure in Neural Architecture Representation, https://arxiv.org/pdf/2507.00880, 2025-07-01
2025-11-11 00:57:32,174 - INFO - root - Page:1, Index:14, Instant Particle Size Distribution Measurement Using CNNs Trained on Synthetic Data, https://arxiv.org/pdf/2507.00822, 2025-07-01
2025-11-11 00:57:32,175 - INFO - root - Page:1, Index:15, Moment Sampling in Video LLMs for Long-Form Video QA, https://arxiv.org/pdf/2507.00033, 2025-06-17
2025-11-11 00:57:32,175 - INFO - root - Page:1, Index:16, Revisiting Audio-Visual Segmentation with Vision-Centric Transformer, https://arxiv.org/pdf/2506.23623, 2025-06-30
2025-11-11 00:57:32,175 - INFO - root - Page:1, Index:17, MTADiffusion: Mask Text Alignment Diffusion Model for Object Inpainting, https://arxiv.org/pdf/2506.23482, 2025-06-29
2025-11-11 00:57:32,176 - INFO - root - Page:1, Index:18, Benchmarking Generalizable Bimanual Manipulation: RoboTwin Dual-Arm Collaboration Challenge at CVPR 2025 MEIS Workshop, https://arxiv.org/pdf/2506.23351, 2025-07-02
2025-11-11 00:57:32,177 - INFO - root - Page:1, Index:19, Prompting without Panic: Attribute-aware, Zero-shot, Test-Time Calibration, https://arxiv.org/pdf/2506.22819, 2025-06-28
2025-11-11 00:57:32,177 - INFO - root - Page:1, Index:20, Analyzing and Fine-Tuning Whisper Models for Multilingual Pilot Speech Transcription in the Cockpit, https://arxiv.org/pdf/2506.21990, 2025-06-27
2025-11-11 00:57:32,177 - INFO - root - Page:1, Index:21, SceneDiffuser++: City-Scale Traffic Simulation via a Generative World Model, https://arxiv.org/pdf/2506.21976, 2025-06-27
2025-11-11 00:57:32,178 - INFO - root - Page:1, Index:22, DIVE: Deep-search Iterative Video Exploration A Technical Report for the CVRR Challenge at CVPR 2025, https://arxiv.org/pdf/2506.21891, 2025-06-27
2025-11-11 00:57:32,178 - INFO - root - Page:1, Index:23, End-to-End RGB-IR Joint Image Compression With Channel-wise Cross-modality Entropy Model, https://arxiv.org/pdf/2506.21851, 2025-06-26
2025-11-11 00:57:32,178 - INFO - root - Page:1, Index:24, Distilling Normalizing Flows, https://arxiv.org/pdf/2506.21003, 2025-06-26
2025-11-11 00:57:32,179 - INFO - root - Page:1, Index:25, Joint attitude estimation and 3D neural reconstruction of non-cooperative space objects, https://arxiv.org/pdf/2506.20638, 2025-06-25
2025-11-11 00:57:32,179 - INFO - root - Page:1, Index:26, Accept More, Reject Less: Reducing up to 19% Unnecessary Desk-Rejections over 11 Years of ICLR Data, https://arxiv.org/pdf/2506.20141, 2025-06-25
2025-11-11 00:57:32,179 - INFO - root - Page:1, Index:27, SceneCrafter: Controllable Multi-View Driving Scene Editing, https://arxiv.org/pdf/2506.19488, 2025-06-24
2025-11-11 00:57:32,179 - INFO - root - Page:1, Index:28, Emergence of Text Readability in Vision Language Models, https://arxiv.org/pdf/2506.19389, 2025-06-24
2025-11-11 00:57:32,180 - INFO - root - Page:1, Index:29, MedErr-CT: A Visual Question Answering Benchmark for Identifying and Correcting Errors in CT Reports, https://arxiv.org/pdf/2506.19217, 2025-06-23
2025-11-11 00:57:32,180 - INFO - root - Page:1, Index:30, RareSpot: Spotting Small and Rare Wildlife in Aerial Imagery with Multi-Scale Consistency and Context-Aware Augmentation, https://arxiv.org/pdf/2506.19087, 2025-06-23
2025-11-11 00:57:32,181 - INFO - root - Page:1, Index:31, Object-aware Sound Source Localization via Audio-Visual Scene Understanding, https://arxiv.org/pdf/2506.18557, 2025-06-23
2025-11-11 00:57:32,181 - INFO - root - Page:1, Index:32, Rethinking Decoder Design: Improving Biomarker Segmentation Using Depth-to-Space Restoration and Residual Linear Attention, https://arxiv.org/pdf/2506.18335, 2025-06-23
2025-11-11 00:57:32,181 - INFO - root - Page:1, Index:33, Relation3D: Enhancing Relation Modeling for Point Cloud Instance Segmentation, https://arxiv.org/pdf/2506.17891, 2025-06-21
2025-11-11 00:57:32,181 - INFO - root - Page:1, Index:34, HIRE: Lightweight High-Resolution Image Feature Enrichment for Multimodal LLMs, https://arxiv.org/pdf/2506.17608, 2025-06-21
2025-11-11 00:57:32,181 - INFO - root - Page:1, Index:35, Spatially-Aware Evaluation of Segmentation Uncertainty, https://arxiv.org/pdf/2506.16589, 2025-06-19
2025-11-11 00:57:32,183 - INFO - root - Page:1, Index:36, Tripartite Weight-Space Ensemble for Few-Shot Class-Incremental Learning, https://arxiv.org/pdf/2506.15720, 2025-06-03
2025-11-11 00:57:32,183 - INFO - root - Page:1, Index:37, PARC: A Quantitative Framework Uncovering the Symmetries within Vision Language Models, https://arxiv.org/pdf/2506.14808, 2025-06-03
2025-11-11 00:57:32,183 - INFO - root - Page:1, Index:38, Self-supervised Representation Learning with Local Aggregation for Image-based Profiling, https://arxiv.org/pdf/2506.14265, 2025-10-27
2025-11-11 00:57:32,183 - INFO - root - Page:1, Index:39, Towards Robust Learning to Optimize with Theoretical Guarantees, https://arxiv.org/pdf/2506.14263, 2025-06-17
2025-11-11 00:57:32,184 - INFO - root - Page:1, Index:40, Hidden Bias in the Machine: Stereotypes in Text-to-Image Models, https://arxiv.org/pdf/2506.13780, 2025-06-09
2025-11-11 00:57:32,184 - INFO - root - Page:1, Index:41, SmartHome-Bench: A Comprehensive Benchmark for Video Anomaly Detection in Smart Homes Using Multi-Modal Large Language Models, https://arxiv.org/pdf/2506.12992, 2025-06-15
2025-11-11 00:57:32,184 - INFO - root - Page:1, Index:42, Generative 4D Scene Gaussian Splatting with Object View-Synthesis Priors, https://arxiv.org/pdf/2506.12716, 2025-06-15
2025-11-11 00:57:32,184 - INFO - root - Page:1, Index:43, DejaVid: Encoder-Agnostic Learned Temporal Matching for Video Classification, https://arxiv.org/pdf/2506.12585, 2025-06-14
2025-11-11 00:57:32,185 - INFO - root - Page:1, Index:44, Pushing the Limits of Safety: A Technical Report on the ATLAS Challenge 2025, https://arxiv.org/pdf/2506.12430, 2025-07-10
2025-11-11 00:57:32,185 - INFO - root - Page:1, Index:45, FIMA-Q: Post-Training Quantization for Vision Transformers by Fisher Information Matrix Approximation, https://arxiv.org/pdf/2506.11543, 2025-06-13
2025-11-11 00:57:32,185 - INFO - root - Page:1, Index:46, Stop learning it all to mitigate visual hallucination, Focus on the hallucination target, https://arxiv.org/pdf/2506.11417, 2025-06-12
2025-11-11 00:57:32,185 - INFO - root - Page:1, Index:47, EfficientQuant: An Efficient Post-Training Quantization for CNN-Transformer Hybrid Models on Edge Devices, https://arxiv.org/pdf/2506.11093, 2025-06-05
2025-11-11 00:57:32,186 - INFO - root - Page:1, Index:48, HalLoc: Token-level Localization of Hallucinations for Vision Language Models, https://arxiv.org/pdf/2506.10286, 2025-06-11
2025-11-11 00:57:32,186 - INFO - root - Page:1, Index:49, DySS: Dynamic Queries and State-Space Learning for Efficient 3D Object Detection from Multi-Camera Videos, https://arxiv.org/pdf/2506.10242, 2025-06-11
2025-11-11 00:57:32,187 - INFO - root - Fetching page 3 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=100
2025-11-11 00:57:38,712 - INFO - root - get_all_titles_from_web 
2025-11-11 00:57:38,712 - INFO - root - Page:2, Index:0, Improving Personalized Search with Regularized Low-Rank Parameter Updates, https://arxiv.org/pdf/2506.10182, 2025-06-11
2025-11-11 00:57:38,713 - INFO - root - Page:2, Index:1, Hearing Hands: Generating Sounds from Physical Interactions in 3D Scenes, https://arxiv.org/pdf/2506.09989, 2025-06-11
2025-11-11 00:57:38,713 - INFO - root - Page:2, Index:2, UniPre3D: Unified Pre-training of 3D Point Cloud Models with Cross-Modal Gaussian Splatting, https://arxiv.org/pdf/2506.09952, 2025-06-11
2025-11-11 00:57:38,713 - INFO - root - Page:2, Index:3, Provoking Multi-modal Few-Shot LVLM via Exploration-Exploitation In-Context Learning, https://arxiv.org/pdf/2506.09473, 2025-06-11
2025-11-11 00:57:38,714 - INFO - root - Page:2, Index:4, Synthetic Human Action Video Data Generation with Pose Transfer, https://arxiv.org/pdf/2506.09411, 2025-06-11
2025-11-11 00:57:38,714 - INFO - root - Page:2, Index:5, ScaleLSD: Scalable Deep Line Segment Detection Streamlined, https://arxiv.org/pdf/2506.09369, 2025-06-10
2025-11-11 00:57:38,714 - INFO - root - Page:2, Index:6, CheckManual: A New Challenge and Benchmark for Manual-based Appliance Manipulation, https://arxiv.org/pdf/2506.09343, 2025-06-10
2025-11-11 00:57:38,714 - INFO - root - Page:2, Index:7, PatchGuard: Adversarially Robust Anomaly Detection and Localization through Vision Transformers and Pseudo Anomalies, https://arxiv.org/pdf/2506.09237, 2025-10-24
2025-11-11 00:57:38,715 - INFO - root - Page:2, Index:8, SILK: Smooth InterpoLation frameworK for motion in-betweening A Simplified Computational Approach, https://arxiv.org/pdf/2506.09075, 2025-06-09
2025-11-11 00:57:38,715 - INFO - root - Page:2, Index:9, BG-HOP: A Bimanual Generative Hand-Object Prior, https://arxiv.org/pdf/2506.09068, 2025-06-08
2025-11-11 00:57:38,715 - INFO - root - Page:2, Index:10, ORIDa: Object-centric Real-world Image Composition Dataset, https://arxiv.org/pdf/2506.08964, 2025-06-10
2025-11-11 00:57:38,715 - INFO - root - Page:2, Index:11, DiscoVLA: Discrepancy Reduction in Vision, Language, and Alignment for Parameter-Efficient Video-Text Retrieval, https://arxiv.org/pdf/2506.08887, 2025-06-10
2025-11-11 00:57:38,718 - INFO - root - Page:2, Index:12, A Comprehensive Study of Decoder-Only LLMs for Text-to-Image Generation, https://arxiv.org/pdf/2506.08210, 2025-06-09
2025-11-11 00:57:38,718 - INFO - root - Page:2, Index:13, Open World Scene Graph Generation using Vision Language Models, https://arxiv.org/pdf/2506.08189, 2025-06-09
2025-11-11 00:57:38,719 - INFO - root - Page:2, Index:14, Aligning Proteins and Language: A Foundation Model for Protein Retrieval, https://arxiv.org/pdf/2506.08023, 2025-05-27
2025-11-11 00:57:38,719 - INFO - root - Page:2, Index:15, UA-Pose: Uncertainty-Aware 6D Object Pose Estimation and Online Object Completion with Partial References, https://arxiv.org/pdf/2506.07996, 2025-06-09
2025-11-11 00:57:38,719 - INFO - root - Page:2, Index:16, Speedy Deformable 3D Gaussian Splatting: Fast Rendering and Compression of Dynamic Scenes, https://arxiv.org/pdf/2506.07917, 2025-06-09
2025-11-11 00:57:38,720 - INFO - root - Page:2, Index:17, GaussianVAE: Adaptive Learning Dynamics of 3D Gaussians for High-Fidelity Super-Resolution, https://arxiv.org/pdf/2506.07897, 2025-06-09
2025-11-11 00:57:38,720 - INFO - root - Page:2, Index:18, Spatio-Temporal State Space Model For Efficient Event-Based Optical Flow, https://arxiv.org/pdf/2506.07878, 2025-06-09
2025-11-11 00:57:38,720 - INFO - root - Page:2, Index:19, FreeGave: 3D Physics Learning from Dynamic Videos by Gaussian Velocity, https://arxiv.org/pdf/2506.07865, 2025-06-09
2025-11-11 00:57:38,721 - INFO - root - Page:2, Index:20, LogoSP: Local-global Grouping of Superpoints for Unsupervised Semantic Segmentation of 3D Point Clouds, https://arxiv.org/pdf/2506.07857, 2025-06-09
2025-11-11 00:57:38,721 - INFO - root - Page:2, Index:21, Difference Inversion: Interpolate and Isolate the Difference with Token Consistency for Image Analogy Generation, https://arxiv.org/pdf/2506.07750, 2025-06-09
2025-11-11 00:57:38,721 - INFO - root - Page:2, Index:22, Synthetic Visual Genome, https://arxiv.org/pdf/2506.07643, 2025-06-09
2025-11-11 00:57:38,721 - INFO - root - Page:2, Index:23, Fractional Collisions: A Framework for Risk Estimation of Counterfactual Conflicts using Autonomous Driving Behavior Simulations, https://arxiv.org/pdf/2506.07540, 2025-06-09
2025-11-11 00:57:38,722 - INFO - root - Page:2, Index:24, Multi-Step Guided Diffusion for Image Restoration on Edge Devices: Toward Lightweight Perception in Embodied AI, https://arxiv.org/pdf/2506.07286, 2025-06-08
2025-11-11 00:57:38,722 - INFO - root - Page:2, Index:25, LLM-Enhanced Rapid-Reflex Async-Reflect Embodied Agent for Real-Time Decision-Making in Dynamically Changing Environments, https://arxiv.org/pdf/2506.07223, 2025-06-08
2025-11-11 00:57:38,722 - INFO - root - Page:2, Index:26, UCOD-DPL: Unsupervised Camouflaged Object Detection via Dynamic Pseudo-label Learning, https://arxiv.org/pdf/2506.07087, 2025-06-08
2025-11-11 00:57:38,722 - INFO - root - Page:2, Index:27, BePo: Leveraging Birds Eye View and Sparse Points for Efficient and Accurate 3D Occupancy Prediction, https://arxiv.org/pdf/2506.07002, 2025-06-08
2025-11-11 00:57:38,723 - INFO - root - Page:2, Index:28, Reading in the Dark with Foveated Event Vision, https://arxiv.org/pdf/2506.06918, 2025-06-07
2025-11-11 00:57:38,725 - INFO - root - Page:2, Index:29, NSD-Imagery: A benchmark dataset for extending fMRI vision decoding methods to mental imagery, https://arxiv.org/pdf/2506.06898, 2025-06-07
2025-11-11 00:57:38,725 - INFO - root - Page:2, Index:30, Continuous-Time SO(3) Forecasting with Savitzky--Golay Neural Controlled Differential Equations, https://arxiv.org/pdf/2506.06780, 2025-06-07
2025-11-11 00:57:38,725 - INFO - root - Page:2, Index:31, Generalized Trajectory Scoring for End-to-end Multimodal Planning, https://arxiv.org/pdf/2506.06664, 2025-06-07
2025-11-11 00:57:38,727 - INFO - root - Page:2, Index:32, EV-LayerSegNet: Self-supervised Motion Segmentation using Event Cameras, https://arxiv.org/pdf/2506.06596, 2025-06-06
2025-11-11 00:57:38,727 - INFO - root - Page:2, Index:33, Vid2Sim: Generalizable, Video-based Reconstruction of Appearance, Geometry and Physics for Mesh-free Simulation, https://arxiv.org/pdf/2506.06440, 2025-06-06
2025-11-11 00:57:38,727 - INFO - root - Page:2, Index:34, FADE: Frequency-Aware Diffusion Model Factorization for Video Editing, https://arxiv.org/pdf/2506.05934, 2025-06-06
2025-11-11 00:57:38,728 - INFO - root - Page:2, Index:35, Unleashing the Potential of Consistency Learning for Detecting and Grounding Multi-Modal Media Manipulation, https://arxiv.org/pdf/2506.05890, 2025-06-06
2025-11-11 00:57:38,728 - INFO - root - Page:2, Index:36, DeformCL: Learning Deformable Centerline Representation for Vessel Extraction in 3D Medical Image, https://arxiv.org/pdf/2506.05820, 2025-06-06
2025-11-11 00:57:38,728 - INFO - root - Page:2, Index:37, NTIRE 2025 Challenge on HR Depth from Images of Specular and Transparent Surfaces, https://arxiv.org/pdf/2506.05815, 2025-06-06
2025-11-11 00:57:38,728 - INFO - root - Page:2, Index:38, GazeNLQ @ Ego4D Natural Language Queries Challenge 2025, https://arxiv.org/pdf/2506.05782, 2025-06-06
2025-11-11 00:57:38,730 - INFO - root - Page:2, Index:39, Robust sensor fusion against on-vehicle sensor staleness, https://arxiv.org/pdf/2506.05780, 2025-06-06
2025-11-11 00:57:38,730 - INFO - root - Page:2, Index:40, Where Is The Ball: 3D Ball Trajectory Estimation From 2D Monocular Tracking, https://arxiv.org/pdf/2506.05763, 2025-06-06
2025-11-11 00:57:38,730 - INFO - root - Page:2, Index:41, VoxelSplat: Dynamic Gaussian Splatting as an Effective Loss for Occupancy and Flow Prediction, https://arxiv.org/pdf/2506.05563, 2025-06-05
2025-11-11 00:57:38,730 - INFO - root - Page:2, Index:42, Gen4D: Synthesizing Humans and Scenes in the Wild, https://arxiv.org/pdf/2506.05397, 2025-06-03
2025-11-11 00:57:38,731 - INFO - root - Page:2, Index:43, Attacking Attention of Foundation Models Disrupts Downstream Tasks, https://arxiv.org/pdf/2506.05394, 2025-09-12
2025-11-11 00:57:38,731 - INFO - root - Page:2, Index:44, FreeTimeGS: Free Gaussian Primitives at Anytime and Anywhere for Dynamic Scene Reconstruction, https://arxiv.org/pdf/2506.05348, 2025-06-06
2025-11-11 00:57:38,731 - INFO - root - Page:2, Index:45, LotusFilter: Fast Diverse Nearest Neighbor Search via a Learned Cutoff Table, https://arxiv.org/pdf/2506.04790, 2025-06-05
2025-11-11 00:57:38,732 - INFO - root - Page:2, Index:46, Towards Holistic Visual Quality Assessment of AI-Generated Videos: A LLM-Based Multi-Dimensional Evaluation Model, https://arxiv.org/pdf/2506.04715, 2025-06-11
2025-11-11 00:57:38,732 - INFO - root - Page:2, Index:47, Gradient Inversion Attacks on Parameter-Efficient Fine-Tuning, https://arxiv.org/pdf/2506.04453, 2025-06-04
2025-11-11 00:57:38,732 - INFO - root - Page:2, Index:48, HMAR: Efficient Hierarchical Masked Auto-Regressive Image Generation, https://arxiv.org/pdf/2506.04421, 2025-06-04
2025-11-11 00:57:38,732 - INFO - root - Page:2, Index:49, Visualizing and Controlling Cortical Responses Using Voxel-Weighted Activation Maximization, https://arxiv.org/pdf/2506.04379, 2025-06-04
2025-11-11 00:57:38,733 - INFO - root - Fetching page 4 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=150
2025-11-11 00:57:45,581 - INFO - root - get_all_titles_from_web 
2025-11-11 00:57:45,601 - INFO - root - Page:3, Index:0, FlexGS: Train Once, Deploy Everywhere with Many-in-One Flexible 3D Gaussian Splatting, https://arxiv.org/pdf/2506.04174, 2025-06-04
2025-11-11 00:57:45,629 - INFO - root - Page:3, Index:1, Multi-view Surface Reconstruction Using Normal and Reflectance Cues, https://arxiv.org/pdf/2506.04115, 2025-06-04
2025-11-11 00:57:45,630 - INFO - root - Page:3, Index:2, Vocabulary-free few-shot learning for Vision-Language Models, https://arxiv.org/pdf/2506.04005, 2025-06-04
2025-11-11 00:57:45,631 - INFO - root - Page:3, Index:3, Learning from Noise: Enhancing DNNs for Event-Based Vision through Controlled Noise Injection, https://arxiv.org/pdf/2506.03918, 2025-06-04
2025-11-11 00:57:45,631 - INFO - root - Page:3, Index:4, Video, How Do Your Tokens Merge?, https://arxiv.org/pdf/2506.03885, 2025-06-04
2025-11-11 00:57:45,631 - INFO - root - Page:3, Index:5, OSGNet @ Ego4D Episodic Memory Challenge 2025, https://arxiv.org/pdf/2506.03710, 2025-06-04
2025-11-11 00:57:45,631 - INFO - root - Page:3, Index:6, AetherVision-Bench: An Open-Vocabulary RGB-Infrared Benchmark for Multi-Angle Segmentation across Aerial and Ground Perspectives, https://arxiv.org/pdf/2506.03709, 2025-06-04
2025-11-11 00:57:45,631 - INFO - root - Page:3, Index:7, OV-COAST: Cost Aggregation with Optimal Transport for Open-Vocabulary Semantic Segmentation, https://arxiv.org/pdf/2506.03706, 2025-06-04
2025-11-11 00:57:45,632 - INFO - root - Page:3, Index:8, Generating 6DoF Object Manipulation Trajectories from Action Description in Egocentric Vision, https://arxiv.org/pdf/2506.03605, 2025-06-04
2025-11-11 00:57:45,632 - INFO - root - Page:3, Index:9, SemNav: A Model-Based Planner for Zero-Shot Object Goal Navigation Using Vision-Foundation Models, https://arxiv.org/pdf/2506.03516, 2025-06-03
2025-11-11 00:57:45,632 - INFO - root - Page:3, Index:10, Heterogeneous Skeleton-Based Action Representation Learning, https://arxiv.org/pdf/2506.03481, 2025-06-03
2025-11-11 00:57:45,632 - INFO - root - Page:3, Index:11, Hybrid Ensemble of Segmentation-Assisted Classification and GBDT for Skin Cancer Detection with Engineered Metadata and Synthetic Lesions from ISIC 2024 Non-Dermoscopic 3D-TBP Images, https://arxiv.org/pdf/2506.03420, 2025-06-03
2025-11-11 00:57:45,634 - INFO - root - Page:3, Index:12, Self-Supervised Spatial Correspondence Across Modalities, https://arxiv.org/pdf/2506.03148, 2025-06-03
2025-11-11 00:57:45,635 - INFO - root - Page:3, Index:13, Dense Match Summarization for Faster Two-view Estimation, https://arxiv.org/pdf/2506.02893, 2025-06-03
2025-11-11 00:57:45,635 - INFO - root - Page:3, Index:14, NTIRE 2025 XGC Quality Assessment Challenge: Methods and Results, https://arxiv.org/pdf/2506.02875, 2025-06-03
2025-11-11 00:57:45,637 - INFO - root - Page:3, Index:15, FreeScene: Mixed Graph Diffusion for 3D Scene Synthesis from Free Prompts, https://arxiv.org/pdf/2506.02781, 2025-06-03
2025-11-11 00:57:45,639 - INFO - root - Page:3, Index:16, Technical Report for Ego4D Long-Term Action Anticipation Challenge 2025, https://arxiv.org/pdf/2506.02550, 2025-06-11
2025-11-11 00:57:45,641 - INFO - root - Page:3, Index:17, Probabilistic Online Event Downsampling, https://arxiv.org/pdf/2506.02547, 2025-09-23
2025-11-11 00:57:45,642 - INFO - root - Page:3, Index:18, Towards In-the-wild 3D Plane Reconstruction from a Single Image, https://arxiv.org/pdf/2506.02493, 2025-06-03
2025-11-11 00:57:45,644 - INFO - root - Page:3, Index:19, Efficient Test-time Adaptive Object Detection via Sensitivity-Guided Pruning, https://arxiv.org/pdf/2506.02462, 2025-06-03
2025-11-11 00:57:45,644 - INFO - root - Page:3, Index:20, EgoVIS@CVPR: PAIR-Net: Enhancing Egocentric Speaker Detection via Pretrained Audio-Visual Fusion and Alignment Loss, https://arxiv.org/pdf/2506.02247, 2025-09-26
2025-11-11 00:57:45,644 - INFO - root - Page:3, Index:21, Diff2Flow: Training Flow Matching Models via Diffusion Model Alignment, https://arxiv.org/pdf/2506.02221, 2025-06-02
2025-11-11 00:57:45,644 - INFO - root - Page:3, Index:22, NTIRE 2025 Challenge on RAW Image Restoration and Super-Resolution, https://arxiv.org/pdf/2506.02197, 2025-06-04
2025-11-11 00:57:45,646 - INFO - root - Page:3, Index:23, RAW Image Reconstruction from RGB on Smartphones. NTIRE 2025 Challenge Report, https://arxiv.org/pdf/2506.01947, 2025-06-02
2025-11-11 00:57:45,646 - INFO - root - Page:3, Index:24, Silence is Golden: Leveraging Adversarial Examples to Nullify Audio Control in LDM-based Talking-Head Generation, https://arxiv.org/pdf/2506.01591, 2025-06-02
2025-11-11 00:57:45,646 - INFO - root - Page:3, Index:25, SAM2-LOVE: Segment Anything Model 2 in Language-aided Audio-Visual Scenes, https://arxiv.org/pdf/2506.01558, 2025-06-02
2025-11-11 00:57:45,647 - INFO - root - Page:3, Index:26, Neural shape reconstruction from multiple views with static pattern projection, https://arxiv.org/pdf/2506.01389, 2025-06-02
2025-11-11 00:57:45,647 - INFO - root - Page:3, Index:27, SAM-I2V: Upgrading SAM to Support Promptable Video Segmentation with Less than 0.2% Training Cost, https://arxiv.org/pdf/2506.01304, 2025-06-02
2025-11-11 00:57:45,647 - INFO - root - Page:3, Index:28, Perceptual Inductive Bias Is What You Need Before Contrastive Learning, https://arxiv.org/pdf/2506.01201, 2025-06-01
2025-11-11 00:57:45,647 - INFO - root - Page:3, Index:29, Test Automation for Interactive Scenarios via Promptable Traffic Simulation, https://arxiv.org/pdf/2506.01199, 2025-06-04
2025-11-11 00:57:45,648 - INFO - root - Page:3, Index:30, GraphPad: Inference-Time 3D Scene Graph Updates for Embodied Question Answering, https://arxiv.org/pdf/2506.01174, 2025-06-01
2025-11-11 00:57:45,648 - INFO - root - Page:3, Index:31, Aligned Contrastive Loss for Long-Tailed Recognition, https://arxiv.org/pdf/2506.01071, 2025-06-01
2025-11-11 00:57:45,648 - INFO - root - Page:3, Index:32, Self-supervised ControlNet with Spatio-Temporal Mamba for Real-world Video Super-resolution, https://arxiv.org/pdf/2506.01037, 2025-06-01
2025-11-11 00:57:45,648 - INFO - root - Page:3, Index:33, ArtiScene: Language-Driven Artistic 3D Scene Generation Through Image Intermediary, https://arxiv.org/pdf/2506.00742, 2025-05-31
2025-11-11 00:57:45,653 - INFO - root - Page:3, Index:34, 3D Gaussian Splat Vulnerabilities, https://arxiv.org/pdf/2506.00280, 2025-05-30
2025-11-11 00:57:45,653 - INFO - root - Page:3, Index:35, EgoVIS@CVPR: What Changed and What Could Have Changed? State-Change Counterfactuals for Procedure-Aware Video Representation Learning, https://arxiv.org/pdf/2506.00101, 2025-09-26
2025-11-11 00:57:45,653 - INFO - root - Page:3, Index:36, CL-LoRA: Continual Low-Rank Adaptation for Rehearsal-Free Class-Incremental Learning, https://arxiv.org/pdf/2505.24816, 2025-05-30
2025-11-11 00:57:45,653 - INFO - root - Page:3, Index:37, PatchDEMUX: A Certifiably Robust Framework for Multi-label Classifiers Against Adversarial Patches, https://arxiv.org/pdf/2505.24703, 2025-05-30
2025-11-11 00:57:45,655 - INFO - root - Page:3, Index:38, Conformal Prediction for Zero-Shot Models, https://arxiv.org/pdf/2505.24693, 2025-05-30
2025-11-11 00:57:45,655 - INFO - root - Page:3, Index:39, Learning reusable concepts across different egocentric video understanding tasks, https://arxiv.org/pdf/2505.24690, 2025-05-30
2025-11-11 00:57:45,655 - INFO - root - Page:3, Index:40, Period-LLM: Extending the Periodic Capability of Multimodal Large Language Model, https://arxiv.org/pdf/2505.24476, 2025-05-30
2025-11-11 00:57:45,656 - INFO - root - Page:3, Index:41, PCIE_Interaction Solution for Ego4D Social Interaction Challenge, https://arxiv.org/pdf/2505.24404, 2025-05-30
2025-11-11 00:57:45,656 - INFO - root - Page:3, Index:42, Leadership Assessment in Pediatric Intensive Care Unit Team Training, https://arxiv.org/pdf/2505.24389, 2025-08-28
2025-11-11 00:57:45,656 - INFO - root - Page:3, Index:43, Interpreting Large Text-to-Image Diffusion Models with Dictionary Learning, https://arxiv.org/pdf/2505.24360, 2025-07-10
2025-11-11 00:57:45,656 - INFO - root - Page:3, Index:44, InteractAnything: Zero-shot Human Object Interaction Synthesis via LLM Feedback and Object Affordance Parsing, https://arxiv.org/pdf/2505.24315, 2025-05-30
2025-11-11 00:57:45,660 - INFO - root - Page:3, Index:45, MaskAdapt: Unsupervised Geometry-Aware Domain Adaptation Using Multimodal Contextual Learning and RGB-Depth Masking, https://arxiv.org/pdf/2505.24026, 2025-05-29
2025-11-11 00:57:45,662 - INFO - root - Page:3, Index:46, Argus: Vision-Centric Reasoning with Grounded Chain-of-Thought, https://arxiv.org/pdf/2505.23766, 2025-05-29
2025-11-11 00:57:45,662 - INFO - root - Page:3, Index:47, Sketch Down the FLOPs: Towards Efficient Networks for Human Sketch, https://arxiv.org/pdf/2505.23763, 2025-05-29
2025-11-11 00:57:45,664 - INFO - root - Page:3, Index:48, Boosting Domain Incremental Learning: Selecting the Optimal Parameters is All You Need, https://arxiv.org/pdf/2505.23744, 2025-05-29
2025-11-11 00:57:45,664 - INFO - root - Page:3, Index:49, DA-VPT: Semantic-Guided Visual Prompt Tuning for Vision Transformers, https://arxiv.org/pdf/2505.23694, 2025-06-01
2025-11-11 00:57:45,664 - INFO - root - Fetching page 5 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=200
2025-11-11 00:57:52,075 - INFO - root - get_all_titles_from_web 
2025-11-11 00:57:52,076 - INFO - root - Page:4, Index:0, Bridging Classical and Modern Computer Vision: PerceptiveNet for Tree Crown Semantic Segmentation, https://arxiv.org/pdf/2505.23597, 2025-05-29
2025-11-11 00:57:52,076 - INFO - root - Page:4, Index:1, Synthetic Generation and Latent Projection Denoising of Rim Lesions in Multiple Sclerosis, https://arxiv.org/pdf/2505.23353, 2025-05-29
2025-11-11 00:57:52,077 - INFO - root - Page:4, Index:2, Wav2Sem: Plug-and-Play Audio Semantic Decoupling for 3D Speech-Driven Facial Animation, https://arxiv.org/pdf/2505.23290, 2025-05-29
2025-11-11 00:57:52,077 - INFO - root - Page:4, Index:3, Proximal Algorithm Unrolling: Flexible and Efficient Reconstruction Networks for Single-Pixel Imaging, https://arxiv.org/pdf/2505.23180, 2025-05-29
2025-11-11 00:57:52,077 - INFO - root - Page:4, Index:4, HMAD: Advancing E2E Driving with Anchored Offset Proposals and Simulation-Supervised Multi-target Scoring, https://arxiv.org/pdf/2505.23129, 2025-05-29
2025-11-11 00:57:52,078 - INFO - root - Page:4, Index:5, URWKV: Unified RWKV Model with Multi-state Perspective for Low-light Image Restoration, https://arxiv.org/pdf/2505.23068, 2025-05-29
2025-11-11 00:57:52,078 - INFO - root - Page:4, Index:6, 4DTAM: Non-Rigid Tracking and Mapping via Dynamic Surface Gaussians, https://arxiv.org/pdf/2505.22859, 2025-05-28
2025-11-11 00:57:52,078 - INFO - root - Page:4, Index:7, A Probabilistic Jump-Diffusion Framework for Open-World Egocentric Activity Recognition, https://arxiv.org/pdf/2505.22858, 2025-05-28
2025-11-11 00:57:52,079 - INFO - root - Page:4, Index:8, PS4PRO: Pixel-to-pixel Supervision for Photorealistic Rendering and Optimization, https://arxiv.org/pdf/2505.22616, 2025-05-28
2025-11-11 00:57:52,080 - INFO - root - Page:4, Index:9, Universal Domain Adaptation for Semantic Segmentation, https://arxiv.org/pdf/2505.22458, 2025-06-05
2025-11-11 00:57:52,083 - INFO - root - Page:4, Index:10, Zero-Shot 3D Visual Grounding from Vision-Language Models, https://arxiv.org/pdf/2505.22429, 2025-05-28
2025-11-11 00:57:52,084 - INFO - root - Page:4, Index:11, RC-AutoCalib: An End-to-End Radar-Camera Automatic Calibration Network, https://arxiv.org/pdf/2505.22427, 2025-05-28
2025-11-11 00:57:52,084 - INFO - root - Page:4, Index:12, Bringing CLIP to the Clinic: Dynamic Soft Labels and Negation-Aware Learning for Medical Analysis, https://arxiv.org/pdf/2505.22079, 2025-05-28
2025-11-11 00:57:52,085 - INFO - root - Page:4, Index:13, Point-to-Region Loss for Semi-Supervised Point-Based Crowd Counting, https://arxiv.org/pdf/2505.21943, 2025-05-27
2025-11-11 00:57:52,086 - INFO - root - Page:4, Index:14, FRAMES-VQA: Benchmarking Fine-Tuning Robustness across Multi-Modal Shifts in Visual Question Answering, https://arxiv.org/pdf/2505.21755, 2025-06-20
2025-11-11 00:57:52,086 - INFO - root - Page:4, Index:15, Knowledge Distillation Approach for SOS Fusion Staging: Towards Fully Automated Skeletal Maturity Assessment, https://arxiv.org/pdf/2505.21561, 2025-05-26
2025-11-11 00:57:52,086 - INFO - root - Page:4, Index:16, Enhancing Vision Transformer Explainability Using Artificial Astrocytes, https://arxiv.org/pdf/2505.21513, 2025-05-20
2025-11-11 00:57:52,086 - INFO - root - Page:4, Index:17, Empowering Vector Graphics with Consistently Arbitrary Viewing and View-dependent Visibility, https://arxiv.org/pdf/2505.21377, 2025-05-27
2025-11-11 00:57:52,087 - INFO - root - Page:4, Index:18, Structure from Collision, https://arxiv.org/pdf/2505.21335, 2025-05-27
2025-11-11 00:57:52,087 - INFO - root - Page:4, Index:19, Boosting Adversarial Transferability via High-Frequency Augmentation and Hierarchical-Gradient Fusion, https://arxiv.org/pdf/2505.21181, 2025-05-27
2025-11-11 00:57:52,087 - INFO - root - Page:4, Index:20, RefAV: Towards Planning-Centric Scenario Mining, https://arxiv.org/pdf/2505.20981, 2025-06-18
2025-11-11 00:57:52,088 - INFO - root - Page:4, Index:21, PMA: Towards Parameter-Efficient Point Cloud Understanding via Point Mamba Adapter, https://arxiv.org/pdf/2505.20941, 2025-05-27
2025-11-11 00:57:52,090 - INFO - root - Page:4, Index:22, HuMoCon: Concept Discovery for Human Motion Understanding, https://arxiv.org/pdf/2505.20920, 2025-05-27
2025-11-11 00:57:52,090 - INFO - root - Page:4, Index:23, Exploring Timeline Control for Facial Motion Generation, https://arxiv.org/pdf/2505.20861, 2025-05-27
2025-11-11 00:57:52,091 - INFO - root - Page:4, Index:24, ConText-CIR: Learning from Concepts in Text for Composed Image Retrieval, https://arxiv.org/pdf/2505.20764, 2025-05-27
2025-11-11 00:57:52,091 - INFO - root - Page:4, Index:25, HCQA-1.5 @ Ego4D EgoSchema Challenge 2025, https://arxiv.org/pdf/2505.20644, 2025-05-26
2025-11-11 00:57:52,091 - INFO - root - Page:4, Index:26, Roboflow100-VL: A Multi-Domain Object Detection Benchmark for Vision-Language Models, https://arxiv.org/pdf/2505.20612, 2025-10-22
2025-11-11 00:57:52,091 - INFO - root - Page:4, Index:27, MotionPro: A Precise Motion Controller for Image-to-Video Generation, https://arxiv.org/pdf/2505.20287, 2025-05-26
2025-11-11 00:57:52,092 - INFO - root - Page:4, Index:28, Category-Agnostic Neural Object Rigging, https://arxiv.org/pdf/2505.20283, 2025-05-26
2025-11-11 00:57:52,093 - INFO - root - Page:4, Index:29, Towards Video to Piano Music Generation with Chain-of-Perform Support Benchmarks, https://arxiv.org/pdf/2505.20038, 2025-05-26
2025-11-11 00:57:52,094 - INFO - root - Page:4, Index:30, Can Visual Encoder Learn to See Arrows?, https://arxiv.org/pdf/2505.19944, 2025-05-26
2025-11-11 00:57:52,098 - INFO - root - Page:4, Index:31, GoLF-NRT: Integrating Global Context and Local Geometry for Few-Shot View Synthesis, https://arxiv.org/pdf/2505.19813, 2025-05-26
2025-11-11 00:57:52,099 - INFO - root - Page:4, Index:32, Depth-Guided Bundle Sampling for Efficient Generalizable Neural Radiance Field Reconstruction, https://arxiv.org/pdf/2505.19793, 2025-05-26
2025-11-11 00:57:52,100 - INFO - root - Page:4, Index:33, SuperAD: A Training-free Anomaly Classification and Segmentation Method for CVPR 2025 VAND 3.0 Workshop Challenge Track 1: Adapt & Detect, https://arxiv.org/pdf/2505.19750, 2025-05-27
2025-11-11 00:57:52,101 - INFO - root - Page:4, Index:34, Knowledge-Aligned Counterfactual-Enhancement Diffusion Perception for Unsupervised Cross-Domain Visual Emotion Recognition, https://arxiv.org/pdf/2505.19694, 2025-05-26
2025-11-11 00:57:52,102 - INFO - root - Page:4, Index:35, Rotation-Equivariant Self-Supervised Method in Image Denoising, https://arxiv.org/pdf/2505.19618, 2025-05-26
2025-11-11 00:57:52,104 - INFO - root - Page:4, Index:36, NTIRE 2025 Challenge on Video Quality Enhancement for Video Conferencing: Datasets, Methods and Results, https://arxiv.org/pdf/2505.18988, 2025-05-25
2025-11-11 00:57:52,105 - INFO - root - Page:4, Index:37, Geometry-guided Online 3D Video Synthesis with Multi-View Temporal Consistency, https://arxiv.org/pdf/2505.18932, 2025-05-24
2025-11-11 00:57:52,106 - INFO - root - Page:4, Index:38, Digital Overconsumption and Waste: A Closer Look at the Impacts of Generative AI, https://arxiv.org/pdf/2505.18894, 2025-05-24
2025-11-11 00:57:52,106 - INFO - root - Page:4, Index:39, VISTA: Vision-Language Inference for Training-Free Stock Time-Series Analysis, https://arxiv.org/pdf/2505.18570, 2025-06-11
2025-11-11 00:57:52,106 - INFO - root - Page:4, Index:40, Syn3DTxt: Embedding 3D Cues for Scene Text Generation, https://arxiv.org/pdf/2505.18479, 2025-05-23
2025-11-11 00:57:52,107 - INFO - root - Page:4, Index:41, CTRL-GS: Cascaded Temporal Residue Learning for 4D Gaussian Splatting, https://arxiv.org/pdf/2505.18306, 2025-05-31
2025-11-11 00:57:52,107 - INFO - root - Page:4, Index:42, DualTalk: Dual-Speaker Interaction for 3D Talking Head Conversations, https://arxiv.org/pdf/2505.18096, 2025-05-26
2025-11-11 00:57:52,108 - INFO - root - Page:4, Index:43, SeaLion: Semantic Part-Aware Latent Point Diffusion Models for 3D Generation, https://arxiv.org/pdf/2505.17721, 2025-07-07
2025-11-11 00:57:52,110 - INFO - root - Page:4, Index:44, PoseBH: Prototypical Multi-Dataset Training Beyond Human Pose Estimation, https://arxiv.org/pdf/2505.17475, 2025-05-23
2025-11-11 00:57:52,110 - INFO - root - Page:4, Index:45, Pursuing Temporal-Consistent Video Virtual Try-On via Dynamic Pose Interaction, https://arxiv.org/pdf/2505.16980, 2025-05-22
2025-11-11 00:57:52,111 - INFO - root - Page:4, Index:46, UniPhy: Learning a Unified Constitutive Model for Inverse Physics Simulation, https://arxiv.org/pdf/2505.16971, 2025-05-22
2025-11-11 00:57:52,112 - INFO - root - Page:4, Index:47, Tracking the Flight: Exploring a Computational Framework for Analyzing Escape Responses in Plains Zebra (Equus quagga), https://arxiv.org/pdf/2505.16882, 2025-05-23
2025-11-11 00:57:52,112 - INFO - root - Page:4, Index:48, Semi-Supervised State-Space Model with Dynamic Stacking Filter for Real-World Video Deraining, https://arxiv.org/pdf/2505.16811, 2025-05-22
2025-11-11 00:57:52,117 - INFO - root - Page:4, Index:49, SOLVE: Synergy of Language-Vision and End-to-End Networks for Autonomous Driving, https://arxiv.org/pdf/2505.16805, 2025-05-22
2025-11-11 00:57:52,120 - INFO - root - Fetching page 6 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=250
2025-11-11 00:58:00,047 - INFO - root - get_all_titles_from_web 
2025-11-11 00:58:00,059 - INFO - root - Page:5, Index:0, Four Eyes Are Better Than Two: Harnessing the Collaborative Potential of Large Models via Differentiated Thinking and Complementary Ensembles, https://arxiv.org/pdf/2505.16784, 2025-06-07
2025-11-11 00:58:00,067 - INFO - root - Page:5, Index:1, Single Domain Generalization for Few-Shot Counting via Universal Representation Matching, https://arxiv.org/pdf/2505.16778, 2025-05-22
2025-11-11 00:58:00,098 - INFO - root - Page:5, Index:2, Seeing Far and Clearly: Mitigating Hallucinations in MLLMs with Attention Causal Decoding, https://arxiv.org/pdf/2505.16652, 2025-06-07
2025-11-11 00:58:00,111 - INFO - root - Page:5, Index:3, Sketchy Bounding-box Supervision for 3D Instance Segmentation, https://arxiv.org/pdf/2505.16399, 2025-05-22
2025-11-11 00:58:00,114 - INFO - root - Page:5, Index:4, DeCafNet: Delegate and Conquer for Efficient Temporal Grounding in Long Videos, https://arxiv.org/pdf/2505.16376, 2025-05-22
2025-11-11 00:58:00,115 - INFO - root - Page:5, Index:5, NTIRE 2025 challenge on Text to Image Generation Model Quality Assessment, https://arxiv.org/pdf/2505.16314, 2025-05-22
2025-11-11 00:58:00,116 - INFO - root - Page:5, Index:6, Analyzing Hierarchical Structure in Vision Models with Sparse Autoencoders, https://arxiv.org/pdf/2505.15970, 2025-05-21
2025-11-11 00:58:00,117 - INFO - root - Page:5, Index:7, Efficient Data Driven Mixture-of-Expert Extraction from Trained Networks, https://arxiv.org/pdf/2505.15414, 2025-05-21
2025-11-11 00:58:00,118 - INFO - root - Page:5, Index:8, Mouse Lockbox Dataset: Behavior Recognition for Mice Solving Lockboxes, https://arxiv.org/pdf/2505.15408, 2025-06-17
2025-11-11 00:58:00,119 - INFO - root - Page:5, Index:9, Zero-Shot Gaze-based Volumetric Medical Image Segmentation, https://arxiv.org/pdf/2505.15256, 2025-06-10
2025-11-11 00:58:00,120 - INFO - root - Page:5, Index:10, Dual Precision Quantization for Efficient and Accurate Deep Neural Networks Inference, https://arxiv.org/pdf/2505.14638, 2025-05-20
2025-11-11 00:58:00,123 - INFO - root - Page:5, Index:11, Neural Video Compression with Context Modulation, https://arxiv.org/pdf/2505.14541, 2025-05-20
2025-11-11 00:58:00,129 - INFO - root - Page:5, Index:12, Selective Structured State Space for Multispectral-fused Small Target Detection, https://arxiv.org/pdf/2505.14043, 2025-05-23
2025-11-11 00:58:00,130 - INFO - root - Page:5, Index:13, OmniStyle: Filtering High Quality Style Transfer Data at Scale, https://arxiv.org/pdf/2505.14028, 2025-05-20
2025-11-11 00:58:00,131 - INFO - root - Page:5, Index:14, Domain Adaptation of VLM for Soccer Video Understanding, https://arxiv.org/pdf/2505.13860, 2025-07-07
2025-11-11 00:58:00,132 - INFO - root - Page:5, Index:15, Ground-V: Teaching VLMs to Ground Complex Instructions in Pixels, https://arxiv.org/pdf/2505.13788, 2025-05-19
2025-11-11 00:58:00,133 - INFO - root - Page:5, Index:16, FinePhys: Fine-grained Human Action Generation by Explicitly Incorporating Physical Laws for Effective Skeletal Guidance, https://arxiv.org/pdf/2505.13437, 2025-05-19
2025-11-11 00:58:00,134 - INFO - root - Page:5, Index:17, The Way Up: A Dataset for Hold Usage Detection in Sport Climbing, https://arxiv.org/pdf/2505.12854, 2025-05-19
2025-11-11 00:58:00,134 - INFO - root - Page:5, Index:18, PEER pressure: Model-to-Model Regularization for Single Source Domain Generalization, https://arxiv.org/pdf/2505.12745, 2025-05-19
2025-11-11 00:58:00,135 - INFO - root - Page:5, Index:19, Mamba-Adaptor: State Space Model Adaptor for Visual Recognition, https://arxiv.org/pdf/2505.12685, 2025-05-19
2025-11-11 00:58:00,136 - INFO - root - Page:5, Index:20, Scalable Video-to-Dataset Generation for Cross-Platform Mobile Agents, https://arxiv.org/pdf/2505.12632, 2025-05-18
2025-11-11 00:58:00,136 - INFO - root - Page:5, Index:21, Degradation-Aware Feature Perturbation for All-in-One Image Restoration, https://arxiv.org/pdf/2505.12630, 2025-05-18
2025-11-11 00:58:00,136 - INFO - root - Page:5, Index:22, Guiding Diffusion with Deep Geometric Moments: Balancing Fidelity and Variation, https://arxiv.org/pdf/2505.12486, 2025-05-18
2025-11-11 00:58:00,138 - INFO - root - Page:5, Index:23, Learning to Highlight Audio by Watching Movies, https://arxiv.org/pdf/2505.12154, 2025-05-17
2025-11-11 00:58:00,145 - INFO - root - Page:5, Index:24, Understanding the Capabilities of Molecular Graph Neural Networks in Materials Science Through Multimodal Learning and Physical Context Encoding, https://arxiv.org/pdf/2505.12137, 2025-05-17
2025-11-11 00:58:00,146 - INFO - root - Page:5, Index:25, iSegMan: Interactive Segment-and-Manipulate 3D Gaussians, https://arxiv.org/pdf/2505.11934, 2025-05-17
2025-11-11 00:58:00,146 - INFO - root - Page:5, Index:26, Self-Learning Hyperspectral and Multispectral Image Fusion via Adaptive Residual Guided Subspace Diffusion Model, https://arxiv.org/pdf/2505.11800, 2025-05-16
2025-11-11 00:58:00,146 - INFO - root - Page:5, Index:27, X-Edit: Detecting and Localizing Edits in Images Altered by Text-Guided Diffusion Models, https://arxiv.org/pdf/2505.11753, 2025-05-16
2025-11-11 00:58:00,147 - INFO - root - Page:5, Index:28, MTevent: A Multi-Task Event Camera Dataset for 6D Pose Estimation and Moving Object Detection, https://arxiv.org/pdf/2505.11282, 2025-06-02
2025-11-11 00:58:00,147 - INFO - root - Page:5, Index:29, Imputation-free and Alignment-free: Incomplete Multi-view Clustering Driven by Consensus Semantic Learning, https://arxiv.org/pdf/2505.11182, 2025-05-16
2025-11-11 00:58:00,148 - INFO - root - Page:5, Index:30, MultiLink: Multi-class Structure Recovery via Agglomerative Clustering and Model Selection, https://arxiv.org/pdf/2505.10874, 2025-05-16
2025-11-11 00:58:00,151 - INFO - root - Page:5, Index:31, RefPose: Leveraging Reference Geometric Correspondences for Accurate 6D Pose Estimation of Unseen Objects, https://arxiv.org/pdf/2505.10841, 2025-05-16
2025-11-11 00:58:00,151 - INFO - root - Page:5, Index:32, MoCLIP: Motion-Aware Fine-Tuning and Distillation of CLIP for Human Motion Generation, https://arxiv.org/pdf/2505.10810, 2025-05-15
2025-11-11 00:58:00,151 - INFO - root - Page:5, Index:33, Automated Detection of Salvin's Albatrosses: Improving Deep Learning Tools for Aerial Wildlife Surveys, https://arxiv.org/pdf/2505.10737, 2025-05-15
2025-11-11 00:58:00,152 - INFO - root - Page:5, Index:34, Advancing Multiple Instance Learning with Continual Learning for Whole Slide Imaging, https://arxiv.org/pdf/2505.10649, 2025-05-15
2025-11-11 00:58:00,152 - INFO - root - Page:5, Index:35, Inferring Driving Maps by Deep Learning-based Trail Map Extraction, https://arxiv.org/pdf/2505.10258, 2025-05-15
2025-11-11 00:58:00,152 - INFO - root - Page:5, Index:36, Behind Maya: Building a Multilingual Vision Language Model, https://arxiv.org/pdf/2505.08910, 2025-05-15
2025-11-11 00:58:00,152 - INFO - root - Page:5, Index:37, PosterO: Structuring Layout Trees to Enable Language Models in Generalized Content-Aware Layout Generation, https://arxiv.org/pdf/2505.07843, 2025-05-26
2025-11-11 00:58:00,153 - INFO - root - Page:5, Index:38, Prototype Augmented Hypernetworks for Continual Learning, https://arxiv.org/pdf/2505.07450, 2025-05-16
2025-11-11 00:58:00,153 - INFO - root - Fetching page 7 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=300
2025-11-11 00:58:06,842 - INFO - root - get_all_titles_from_web 
2025-11-11 00:58:06,842 - INFO - root - Page:6, Index:0, Convex Relaxation for Robust Vanishing Point Estimation in Manhattan World, https://arxiv.org/pdf/2505.04788, 2025-06-05
2025-11-11 00:58:06,843 - INFO - root - Page:6, Index:1, S3D: Sketch-Driven 3D Model Generation, https://arxiv.org/pdf/2505.04185, 2025-06-03
2025-11-11 00:58:06,843 - INFO - root - Page:6, Index:2, Generating Synthetic Data via Augmentations for Improved Facial Resemblance in DreamBooth and InstantID, https://arxiv.org/pdf/2505.03557, 2025-07-17
2025-11-11 00:58:06,843 - INFO - root - Page:6, Index:3, CAV-MAE Sync: Improving Contrastive Audio-Visual Mask Autoencoders via Fine-Grained Alignment, https://arxiv.org/pdf/2505.01237, 2025-05-21
2025-11-11 00:58:06,843 - INFO - root - Fetching page 8 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=350
2025-11-11 00:58:13,679 - INFO - root - get_all_titles_from_web 
2025-11-11 00:58:13,679 - INFO - root - Page:7, Index:0, Where's the liability in the Generative Era? Recovery-based Black-Box Detection of AI-Generated Content, https://arxiv.org/pdf/2505.01008, 2025-08-25
2025-11-11 00:58:13,681 - INFO - root - Page:7, Index:1, SpatialLLM: A Compound 3D-Informed Design towards Spatially-Intelligent Large Multimodal Models, https://arxiv.org/pdf/2505.00788, 2025-06-10
2025-11-11 00:58:13,681 - INFO - root - Page:7, Index:2, Prisma: An Open Source Toolkit for Mechanistic Interpretability in Vision and Video, https://arxiv.org/pdf/2504.19475, 2025-06-03
2025-11-11 00:58:13,681 - INFO - root - Page:7, Index:3, SSL4Eco: A Global Seasonal Dataset for Geospatial Foundation Models in Ecology, https://arxiv.org/pdf/2504.18256, 2025-10-20
2025-11-11 00:58:13,682 - INFO - root - Page:7, Index:4, Vision-Language Models Are Not Pragmatically Competent in Referring Expression Generation, https://arxiv.org/pdf/2504.16060, 2025-07-30
2025-11-11 00:58:13,682 - INFO - root - Fetching page 9 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=400
2025-11-11 00:58:20,387 - INFO - root - get_all_titles_from_web 
2025-11-11 00:58:20,388 - INFO - root - Page:8, Index:0, Leveraging Automatic CAD Annotations for Supervised Learning in 3D Scene Understanding, https://arxiv.org/pdf/2504.13580, 2025-05-16
2025-11-11 00:58:20,388 - INFO - root - Page:8, Index:1, CAP-Net: A Unified Network for 6D Pose and Size Estimation of Categorical Articulated Parts from a Single RGB-D Image, https://arxiv.org/pdf/2504.11230, 2025-06-02
2025-11-11 00:58:20,388 - INFO - root - Page:8, Index:2, Video Summarization with Large Language Models, https://arxiv.org/pdf/2504.11199, 2025-06-05
2025-11-11 00:58:20,389 - INFO - root - Page:8, Index:3, R-TPT: Improving Adversarial Robustness of Vision-Language Models through Test-Time Prompt Tuning, https://arxiv.org/pdf/2504.11195, 2025-08-27
2025-11-11 00:58:20,389 - INFO - root - Page:8, Index:4, TerraMesh: A Planetary Mosaic of Multimodal Earth Observation Data, https://arxiv.org/pdf/2504.11172, 2025-08-01
2025-11-11 00:58:20,389 - INFO - root - Page:8, Index:5, Seeing like a Cephalopod: Colour Vision with a Monochrome Event Camera, https://arxiv.org/pdf/2504.10984, 2025-06-06
2025-11-11 00:58:20,390 - INFO - root - Page:8, Index:6, Hearing Anywhere in Any Environment, https://arxiv.org/pdf/2504.10746, 2025-06-04
2025-11-11 00:58:20,390 - INFO - root - Fetching page 10 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=450
2025-11-11 00:58:26,634 - INFO - root - get_all_titles_from_web 
2025-11-11 00:58:26,634 - INFO - root - Page:9, Index:0, Correlative and Discriminative Label Grouping for Multi-Label Visual Prompt Tuning, https://arxiv.org/pdf/2504.09990, 2025-07-09
2025-11-11 00:58:26,635 - INFO - root - Page:9, Index:1, SPICE: A Synergistic, Precise, Iterative, and Customizable Image Editing Workflow, https://arxiv.org/pdf/2504.09697, 2025-10-16
2025-11-11 00:58:26,635 - INFO - root - Page:9, Index:2, Mimic In-Context Learning for Multimodal Tasks, https://arxiv.org/pdf/2504.08851, 2025-05-17
2025-11-11 00:58:26,635 - INFO - root - Page:9, Index:3, Digital Twin Catalog: A Large-Scale Photorealistic 3D Object Digital Twin Dataset, https://arxiv.org/pdf/2504.08541, 2025-05-18
2025-11-11 00:58:26,636 - INFO - root - Page:9, Index:4, MMLA: Multi-Environment, Multi-Species, Low-Altitude Drone Dataset, https://arxiv.org/pdf/2504.07744, 2025-10-22
2025-11-11 00:58:26,636 - INFO - root - Fetching page 11 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=500
2025-11-11 00:58:33,326 - INFO - root - get_all_titles_from_web 
2025-11-11 00:58:33,326 - INFO - root - Page:10, Index:0, PromptHMR: Promptable Human Mesh Recovery, https://arxiv.org/pdf/2504.06397, 2025-05-23
2025-11-11 00:58:33,327 - INFO - root - Page:10, Index:1, SCAM: A Real-World Typographic Robustness Evaluation for Multimodal Foundation Models, https://arxiv.org/pdf/2504.04893, 2025-09-26
2025-11-11 00:58:33,327 - INFO - root - Fetching page 12 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=550
2025-11-11 00:58:39,492 - INFO - root - get_all_titles_from_web 
2025-11-11 00:58:39,492 - INFO - root - Page:11, Index:0, Charm: The Missing Piece in ViT fine-tuning for Image Aesthetic Assessment, https://arxiv.org/pdf/2504.02522, 2025-05-15
2025-11-11 00:58:39,493 - INFO - root - Page:11, Index:1, T*: Re-thinking Temporal Search for Long-Form Video Understanding, https://arxiv.org/pdf/2504.02259, 2025-08-24
2025-11-11 00:58:39,495 - INFO - root - Page:11, Index:2, CoMatcher: Multi-View Collaborative Feature Matching, https://arxiv.org/pdf/2504.01872, 2025-08-20
2025-11-11 00:58:39,495 - INFO - root - Page:11, Index:3, Think Small, Act Big: Primitive Prompt Learning for Lifelong Robot Manipulation, https://arxiv.org/pdf/2504.00420, 2025-06-01
2025-11-11 00:58:39,496 - INFO - root - Fetching page 13 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=600
2025-11-11 00:58:45,898 - INFO - root - get_all_titles_from_web 
2025-11-11 00:58:45,900 - INFO - root - Page:12, Index:0, It's a (Blind) Match! Towards Vision-Language Correspondence without Parallel Data, https://arxiv.org/pdf/2503.24129, 2025-05-29
2025-11-11 00:58:45,902 - INFO - root - Page:12, Index:1, ReferDINO-Plus: 2nd Solution for 4th PVUW MeViS Challenge at CVPR 2025, https://arxiv.org/pdf/2503.23509, 2025-05-29
2025-11-11 00:58:45,903 - INFO - root - Page:12, Index:2, A Unified Image-Dense Annotation Generation Model for Underwater Scenes, https://arxiv.org/pdf/2503.21771, 2025-07-27
2025-11-11 00:58:45,904 - INFO - root - Fetching page 14 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=650
2025-11-11 00:58:52,615 - INFO - root - get_all_titles_from_web 
2025-11-11 00:58:52,615 - INFO - root - Page:13, Index:0, Learning Class Prototypes for Unified Sparse Supervised 3D Object Detection, https://arxiv.org/pdf/2503.21099, 2025-06-13
2025-11-11 00:58:52,616 - INFO - root - Page:13, Index:1, LATTE-MV: Learning to Anticipate Table Tennis Hits from Monocular Videos, https://arxiv.org/pdf/2503.20936, 2025-09-01
2025-11-11 00:58:52,616 - INFO - root - Page:13, Index:2, BizGen: Advancing Article-level Visual Text Rendering for Infographics Generation, https://arxiv.org/pdf/2503.20672, 2025-07-02
2025-11-11 00:58:52,616 - INFO - root - Page:13, Index:3, ITA-MDT: Image-Timestep-Adaptive Masked Diffusion Transformer Framework for Image-Based Virtual Try-On, https://arxiv.org/pdf/2503.20418, 2025-06-01
2025-11-11 00:58:52,616 - INFO - root - Page:13, Index:4, Faster Parameter-Efficient Tuning with Token Redundancy Reduction, https://arxiv.org/pdf/2503.20282, 2025-08-26
2025-11-11 00:58:52,616 - INFO - root - Page:13, Index:5, DINeMo: Learning Neural Mesh Models with no 3D Annotations, https://arxiv.org/pdf/2503.20220, 2025-06-09
2025-11-11 00:58:52,618 - INFO - root - Page:13, Index:6, Scaling Vision Pre-Training to 4K Resolution, https://arxiv.org/pdf/2503.19903, 2025-08-03
2025-11-11 00:58:52,618 - INFO - root - Page:13, Index:7, GENIUS: A Generative Framework for Universal Multimodal Search, https://arxiv.org/pdf/2503.19868, 2025-06-05
2025-11-11 00:58:52,618 - INFO - root - Fetching page 15 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=700
2025-11-11 00:58:58,870 - INFO - root - get_all_titles_from_web 
2025-11-11 00:58:58,870 - INFO - root - Page:14, Index:0, Galaxy Walker: Geometry-aware VLMs For Galaxy-scale Understanding, https://arxiv.org/pdf/2503.18578, 2025-05-25
2025-11-11 00:58:58,871 - INFO - root - Page:14, Index:1, LookCloser: Frequency-aware Radiance Field for Tiny-Detail Scene, https://arxiv.org/pdf/2503.18513, 2025-07-29
2025-11-11 00:58:58,871 - INFO - root - Fetching page 16 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=750
2025-11-11 00:59:05,345 - INFO - root - get_all_titles_from_web 
2025-11-11 00:59:05,345 - INFO - root - Page:15, Index:0, LoTUS: Large-Scale Machine Unlearning with a Taste of Uncertainty, https://arxiv.org/pdf/2503.18314, 2025-05-29
2025-11-11 00:59:05,346 - INFO - root - Page:15, Index:1, MammAlps: A multi-view video behavior monitoring dataset of wild mammals in the Swiss Alps, https://arxiv.org/pdf/2503.18223, 2025-06-04
2025-11-11 00:59:05,346 - INFO - root - Page:15, Index:2, Progressive Prompt Detailing for Improved Alignment in Text-to-Image Generative Models, https://arxiv.org/pdf/2503.17794, 2025-05-30
2025-11-11 00:59:05,346 - INFO - root - Page:15, Index:3, CountLLM: Towards Generalizable Repetitive Action Counting via Large Language Model, https://arxiv.org/pdf/2503.17690, 2025-06-29
2025-11-11 00:59:05,346 - INFO - root - Page:15, Index:4, TaoAvatar: Real-Time Lifelike Full-Body Talking Avatars for Augmented Reality via 3D Gaussian Splatting, https://arxiv.org/pdf/2503.17032, 2025-07-23
2025-11-11 00:59:05,346 - INFO - root - Page:15, Index:5, Generalized Few-shot 3D Point Cloud Segmentation with Vision-Language Model, https://arxiv.org/pdf/2503.16282, 2025-05-20
2025-11-11 00:59:05,347 - INFO - root - Fetching page 17 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=800
2025-11-11 00:59:11,615 - INFO - root - get_all_titles_from_web 
2025-11-11 00:59:11,616 - INFO - root - Page:16, Index:0, High Temporal Consistency through Semantic Similarity Propagation in Semi-Supervised Video Semantic Segmentation for Autonomous Flight, https://arxiv.org/pdf/2503.15676, 2025-06-26
2025-11-11 00:59:11,616 - INFO - root - Page:16, Index:1, DPFlow: Adaptive Optical Flow Estimation with a Dual-Pyramid Framework, https://arxiv.org/pdf/2503.14880, 2025-09-29
2025-11-11 00:59:11,616 - INFO - root - Fetching page 18 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=850
2025-11-11 00:59:18,054 - INFO - root - get_all_titles_from_web 
2025-11-11 00:59:18,054 - INFO - root - Page:17, Index:0, From Head to Tail: Towards Balanced Representation in Large Vision-Language Models through Adaptive Data Calibration, https://arxiv.org/pdf/2503.12821, 2025-05-29
2025-11-11 00:59:18,055 - INFO - root - Page:17, Index:1, MambaIC: State Space Models for High-Performance Learned Image Compression, https://arxiv.org/pdf/2503.12461, 2025-08-22
2025-11-11 00:59:18,055 - INFO - root - Page:17, Index:2, Localized Concept Erasure for Text-to-Image Diffusion Models Using Training-Free Gated Low-Rank Adaptation, https://arxiv.org/pdf/2503.12356, 2025-07-09
2025-11-11 00:59:18,055 - INFO - root - Page:17, Index:3, TASTE-Rob: Advancing Video Generation of Task-Oriented Hand-Object Interaction for Generalizable Robotic Manipulation, https://arxiv.org/pdf/2503.11423, 2025-06-05
2025-11-11 00:59:18,056 - INFO - root - Page:17, Index:4, Panopticon: Advancing Any-Sensor Foundation Models for Earth Observation, https://arxiv.org/pdf/2503.10845, 2025-08-01
2025-11-11 00:59:18,056 - INFO - root - Page:17, Index:5, Transformers without Normalization, https://arxiv.org/pdf/2503.10622, 2025-06-14
2025-11-11 00:59:18,056 - INFO - root - Page:17, Index:6, dFLMoE: Decentralized Federated Learning via Mixture of Experts for Medical Data Analysis, https://arxiv.org/pdf/2503.10412, 2025-05-19
2025-11-11 00:59:18,056 - INFO - root - Fetching page 19 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=900
2025-11-11 00:59:25,452 - INFO - root - get_all_titles_from_web 
2025-11-11 00:59:25,452 - INFO - root - Page:18, Index:0, Project-Probe-Aggregate: Efficient Fine-Tuning for Group Robustness, https://arxiv.org/pdf/2503.09487, 2025-08-26
2025-11-11 00:59:25,453 - INFO - root - Page:18, Index:1, VLog: Video-Language Models by Generative Retrieval of Narration Vocabulary, https://arxiv.org/pdf/2503.09402, 2025-06-09
2025-11-11 00:59:25,453 - INFO - root - Fetching page 20 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=950
2025-11-11 00:59:32,206 - INFO - root - get_all_titles_from_web 
2025-11-11 00:59:32,207 - INFO - root - Page:19, Index:0, Escaping Plato's Cave: Towards the Alignment of 3D and Text Latent Spaces, https://arxiv.org/pdf/2503.05283, 2025-06-04
2025-11-11 00:59:32,207 - INFO - root - Page:19, Index:1, FluidNexus: 3D Fluid Reconstruction and Prediction from a Single Video, https://arxiv.org/pdf/2503.04720, 2025-07-09
2025-11-11 00:59:32,207 - INFO - root - Page:19, Index:2, Question-Aware Gaussian Experts for Audio-Visual Question Answering, https://arxiv.org/pdf/2503.04459, 2025-06-11
2025-11-11 00:59:32,209 - INFO - root - Page:19, Index:3, Q-Eval-100K: Evaluating Visual Quality and Alignment Level for Text-to-Vision Content, https://arxiv.org/pdf/2503.02357, 2025-06-15
2025-11-11 00:59:32,209 - INFO - root - Fetching page 21 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=1000
2025-11-11 00:59:38,894 - INFO - root - get_all_titles_from_web 
2025-11-11 00:59:38,895 - INFO - root - Page:20, Index:0, Data Distributional Properties As Inductive Bias for Systematic Generalization, https://arxiv.org/pdf/2502.20499, 2025-06-17
2025-11-11 00:59:38,895 - INFO - root - Page:20, Index:1, Knowledge Bridger: Towards Training-free Missing Modality Completion, https://arxiv.org/pdf/2502.19834, 2025-06-17
2025-11-11 00:59:38,896 - INFO - root - Fetching page 22 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=1050
2025-11-11 00:59:45,487 - INFO - root - get_all_titles_from_web 
2025-11-11 00:59:45,488 - INFO - root - Page:21, Index:0, MALT Diffusion: Memory-Augmented Latent Transformers for Any-Length Video Generation, https://arxiv.org/pdf/2502.12632, 2025-07-08
2025-11-11 00:59:45,488 - INFO - root - Page:21, Index:1, ILIAS: Instance-Level Image retrieval At Scale, https://arxiv.org/pdf/2502.11748, 2025-06-23
2025-11-11 00:59:45,489 - INFO - root - Page:21, Index:2, Distraction is All You Need for Multimodal Large Language Model Jailbreaking, https://arxiv.org/pdf/2502.10794, 2025-06-16
2025-11-11 00:59:45,489 - INFO - root - Page:21, Index:3, Spatial457: A Diagnostic Benchmark for 6D Spatial Reasoning of Large Multimodal Models, https://arxiv.org/pdf/2502.08636, 2025-06-08
2025-11-11 00:59:45,489 - INFO - root - Page:21, Index:4, TRAVEL: Training-Free Retrieval and Alignment for Vision-and-Language Navigation, https://arxiv.org/pdf/2502.07306, 2025-06-09
2025-11-11 00:59:45,490 - INFO - root - Page:21, Index:5, DiTASK: Multi-Task Fine-Tuning with Diffeomorphic Transformations, https://arxiv.org/pdf/2502.06029, 2025-06-01
2025-11-11 00:59:45,490 - INFO - root - Page:21, Index:6, ConceptAttention: Diffusion Transformers Learn Highly Interpretable Features, https://arxiv.org/pdf/2502.04320, 2025-07-01
2025-11-11 00:59:45,490 - INFO - root - Page:21, Index:7, GCE-Pose: Global Context Enhancement for Category-level Object Pose Estimation, https://arxiv.org/pdf/2502.04293, 2025-06-24
2025-11-11 00:59:45,491 - INFO - root - Page:21, Index:8, Calibrated Multi-Preference Optimization for Aligning Diffusion Models, https://arxiv.org/pdf/2502.02588, 2025-09-26
2025-11-11 00:59:45,491 - INFO - root - Page:21, Index:9, Instruct-4DGS: Efficient Dynamic Scene Editing via 4D Gaussian-based Static-Dynamic Separation, https://arxiv.org/pdf/2502.02091, 2025-07-01
2025-11-11 00:59:45,494 - INFO - root - Page:21, Index:10, Low-Resource Video Super-Resolution using Memory, Wavelets, and Deformable Convolutions, https://arxiv.org/pdf/2502.01816, 2025-06-19
2025-11-11 00:59:45,494 - INFO - root - Page:21, Index:11, Bridging Text and Crystal Structures: Literature-driven Contrastive Learning for Materials Science, https://arxiv.org/pdf/2501.12919, 2025-06-18
2025-11-11 00:59:45,495 - INFO - root - Page:21, Index:12, T2ISafety: Benchmark for Assessing Fairness, Toxicity, and Privacy in Image Generation, https://arxiv.org/pdf/2501.12612, 2025-07-25
2025-11-11 00:59:45,495 - INFO - root - Page:21, Index:13, Fine-Grained Image-Text Correspondence with Cost Aggregation for Open-Vocabulary Part Segmentation, https://arxiv.org/pdf/2501.09688, 2025-08-08
2025-11-11 00:59:45,496 - INFO - root - Fetching page 23 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=1100
2025-11-11 00:59:52,080 - INFO - root - get_all_titles_from_web 
2025-11-11 00:59:52,081 - INFO - root - Page:22, Index:0, Bias for Action: Video Implicit Neural Representations with Bias Modulation, https://arxiv.org/pdf/2501.09277, 2025-06-06
2025-11-11 00:59:52,081 - INFO - root - Page:22, Index:1, MonSter++: Unified Stereo Matching, Multi-view Stereo, and Real-time Stereo with Monodepth Priors, https://arxiv.org/pdf/2501.08643, 2025-09-25
2025-11-11 00:59:52,081 - INFO - root - Page:22, Index:2, Go-with-the-Flow: Motion-Controllable Video Diffusion Models Using Real-Time Warped Noise, https://arxiv.org/pdf/2501.08331, 2025-08-06
2025-11-11 00:59:52,081 - INFO - root - Page:22, Index:3, Nonisotropic Gaussian Diffusion for Realistic 3D Human Motion Prediction, https://arxiv.org/pdf/2501.06035, 2025-07-08
2025-11-11 00:59:52,082 - INFO - root - Page:22, Index:4, Discovering Hidden Visual Concepts Beyond Linguistic Input in Infant Learning, https://arxiv.org/pdf/2501.05205, 2025-06-13
2025-11-11 00:59:52,082 - INFO - root - Page:22, Index:5, PERSE: Personalized 3D Generative Avatars from A Single Portrait, https://arxiv.org/pdf/2412.21206, 2025-09-28
2025-11-11 00:59:52,083 - INFO - root - Page:22, Index:6, MaskGaussian: Adaptive 3D Gaussian Representation from Probabilistic Masks, https://arxiv.org/pdf/2412.20522, 2025-06-14
2025-11-11 00:59:52,083 - INFO - root - Page:22, Index:7, SimLTD: Simple Supervised and Semi-Supervised Long-Tailed Object Detection, https://arxiv.org/pdf/2412.20047, 2025-06-09
2025-11-11 00:59:52,084 - INFO - root - Page:22, Index:8, Conditional Balance: Improving Multi-Conditioning Trade-Offs in Image Generation, https://arxiv.org/pdf/2412.19853, 2025-08-03
2025-11-11 00:59:52,084 - INFO - root - Fetching page 24 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=1150
2025-11-11 00:59:58,480 - INFO - root - get_all_titles_from_web 
2025-11-11 00:59:58,481 - INFO - root - Page:23, Index:0, CoCoGaussian: Leveraging Circle of Confusion for Gaussian Splatting from Defocused Images, https://arxiv.org/pdf/2412.16028, 2025-05-15
2025-11-11 00:59:58,481 - INFO - root - Page:23, Index:1, EnergyMoGen: Compositional Human Motion Generation with Energy-Based Diffusion Model in Latent Space, https://arxiv.org/pdf/2412.14706, 2025-06-04
2025-11-11 00:59:58,481 - INFO - root - Page:23, Index:2, DarkIR: Robust Low-Light Image Restoration, https://arxiv.org/pdf/2412.13443, 2025-10-14
2025-11-11 00:59:58,482 - INFO - root - Page:23, Index:3, FastVLM: Efficient Vision Encoding for Vision Language Models, https://arxiv.org/pdf/2412.13303, 2025-05-15
2025-11-11 00:59:58,482 - INFO - root - Page:23, Index:4, Real-time Free-view Human Rendering from Sparse-view RGB Videos using Double Unprojected Textures, https://arxiv.org/pdf/2412.13183, 2025-06-20
2025-11-11 00:59:58,482 - INFO - root - Page:23, Index:5, CondiMen: Conditional Multi-Person Mesh Recovery, https://arxiv.org/pdf/2412.13058, 2025-06-04
2025-11-11 00:59:58,483 - INFO - root - Page:23, Index:6, MASt3R-SLAM: Real-Time Dense SLAM with 3D Reconstruction Priors, https://arxiv.org/pdf/2412.12392, 2025-06-02
2025-11-11 00:59:58,483 - INFO - root - Page:23, Index:7, DynamicScaler: Seamless and Scalable Video Generation for Panoramic Scenes, https://arxiv.org/pdf/2412.11100, 2025-10-04
2025-11-11 00:59:58,483 - INFO - root - Page:23, Index:8, SnapGen-V: Generating a Five-Second Video within Five Seconds on a Mobile Device, https://arxiv.org/pdf/2412.10494, 2025-06-09
2025-11-11 00:59:58,485 - INFO - root - Page:23, Index:9, Mr. DETR++: Instructive Multi-Route Training for Detection Transformers with Mixture-of-Experts, https://arxiv.org/pdf/2412.10028, 2025-06-26
2025-11-11 00:59:58,485 - INFO - root - Page:23, Index:10, LinGen: Towards High-Resolution Minute-Length Text-to-Video Generation with Linear Computational Complexity, https://arxiv.org/pdf/2412.09856, 2025-05-24
2025-11-11 00:59:58,485 - INFO - root - Page:23, Index:11, Gaze-LLE: Gaze Target Estimation via Large-Scale Learned Encoders, https://arxiv.org/pdf/2412.09586, 2025-06-03
2025-11-11 00:59:58,486 - INFO - root - Fetching page 25 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=1200
2025-11-11 01:00:05,427 - INFO - root - get_all_titles_from_web 
2025-11-11 01:00:05,427 - INFO - root - Page:24, Index:0, From Slow Bidirectional to Fast Autoregressive Video Diffusion Models, https://arxiv.org/pdf/2412.07772, 2025-09-23
2025-11-11 01:00:05,428 - INFO - root - Page:24, Index:1, Rate-In: Information-Driven Adaptive Dropout Rates for Improved Inference-Time Uncertainty Estimation, https://arxiv.org/pdf/2412.07169, 2025-06-03
2025-11-11 01:00:05,428 - INFO - root - Page:24, Index:2, FIRE: Robust Detection of Diffusion-Generated Images via Frequency-Guided Reconstruction Error, https://arxiv.org/pdf/2412.07140, 2025-11-03
2025-11-11 01:00:05,430 - INFO - root - Page:24, Index:3, Birth and Death of a Rose, https://arxiv.org/pdf/2412.05278, 2025-06-05
2025-11-11 01:00:05,430 - INFO - root - Page:24, Index:4, DualPM: Dual Posed-Canonical Point Maps for 3D Shape and Pose Reconstruction, https://arxiv.org/pdf/2412.04464, 2025-08-14
2025-11-11 01:00:05,431 - INFO - root - Page:24, Index:5, SeeGround: See and Ground for Zero-Shot Open-Vocabulary 3D Visual Grounding, https://arxiv.org/pdf/2412.04383, 2025-05-29
2025-11-11 01:00:05,431 - INFO - root - ------------------------------------------------------------------------------------------------------------------------
2025-11-11 01:00:05,432 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\CVPR 2025\Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness.pdf
2025-11-11 01:00:05,458 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\CVPR 2025\OmniTrack++_ Omnidirectional Multi-Object Tracking by Learning Large-FoV Traject.pdf
2025-11-11 01:00:05,459 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\CVPR 2025\NeuCo-Bench_ A Novel Benchmark Framework for Neural Embeddings in Earth Observat.pdf
2025-11-11 01:00:05,460 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\CVPR 2025\NTIRE 2025 Challenge on Low Light Image Enhancement_ Methods and Results.pdf
2025-11-11 01:00:05,462 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\CVPR 2025\Class Prototypes based Contrastive Learning for Classifying Multi-Label and Fine.pdf
2025-11-11 01:00:05,466 - INFO - root - 正在总结论文 1/5: Learning to Seek Evidence: A Verifiable Reasoning Agent with Causal Faithfulness Analysis
2025-11-11 01:05:44,477 - INFO - root - 正在提取论文图片...
2025-11-11 01:05:44,633 - INFO - root - 已保存图片 1/10：./export\CVPR\images\figure_1_page2.jpeg
2025-11-11 01:05:44,640 - INFO - root - 已保存图片 2/10：./export\CVPR\images\figure_2_page2.jpeg
2025-11-11 01:05:44,647 - INFO - root - 已保存图片 3/10：./export\CVPR\images\figure_3_page2.jpeg
2025-11-11 01:05:44,657 - INFO - root - 已保存图片 4/10：./export\CVPR\images\figure_4_page2.jpeg
2025-11-11 01:05:44,663 - INFO - root - 已保存图片 5/10：./export\CVPR\images\figure_5_page2.jpeg
2025-11-11 01:05:44,673 - INFO - root - 已保存图片 6/10：./export\CVPR\images\figure_6_page2.jpeg
2025-11-11 01:05:44,688 - INFO - root - 已保存图片 7/10：./export\CVPR\images\figure_7_page2.jpeg
2025-11-11 01:05:44,696 - INFO - root - 已保存图片 8/10：./export\CVPR\images\figure_8_page2.jpeg
2025-11-11 01:05:44,727 - INFO - root - 已保存图片 9/10：./export\CVPR\images\figure_9_page2.jpeg
2025-11-11 01:05:44,738 - INFO - root - 已保存图片 10/10：./export\CVPR\images\figure_10_page2.jpeg
2025-11-11 01:05:44,739 - INFO - root - 成功添加图片 1：./export\CVPR\images\figure_1_page2.jpeg
2025-11-11 01:05:44,740 - INFO - root - 成功添加图片 2：./export\CVPR\images\figure_2_page2.jpeg
2025-11-11 01:05:44,740 - INFO - root - 成功添加图片 3：./export\CVPR\images\figure_3_page2.jpeg
2025-11-11 01:05:44,741 - INFO - root - 成功添加图片 4：./export\CVPR\images\figure_4_page2.jpeg
2025-11-11 01:05:44,741 - INFO - root - 成功添加图片 5：./export\CVPR\images\figure_5_page2.jpeg
2025-11-11 01:05:44,741 - INFO - root - 成功添加图片 6：./export\CVPR\images\figure_6_page2.jpeg
2025-11-11 01:05:44,741 - INFO - root - 成功添加图片 7：./export\CVPR\images\figure_7_page2.jpeg
2025-11-11 01:05:44,743 - INFO - root - 成功添加图片 8：./export\CVPR\images\figure_8_page2.jpeg
2025-11-11 01:05:44,743 - INFO - root - 成功添加图片 9：./export\CVPR\images\figure_9_page2.jpeg
2025-11-11 01:05:44,744 - INFO - root - 成功添加图片 10：./export\CVPR\images\figure_10_page2.jpeg
2025-11-11 01:05:44,745 - INFO - root - 论文《Learning to Seek Evidence: A Verifiable Reasoning Agent with Causal Faithfulness Analysis》的分析已保存到 ./export\CVPR\Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness.md
2025-11-11 01:05:44,748 - INFO - root - 正在总结论文 2/5: OmniTrack++: Omnidirectional Multi-Object Tracking by Learning Large-FoV Trajectory Feedback
2025-11-11 01:08:13,804 - INFO - root - 正在提取论文图片...
2025-11-11 01:08:14,324 - INFO - root - 已保存图片 1/10：./export\CVPR\images\figure_1_page13.jpeg
2025-11-11 01:08:14,403 - INFO - root - 已保存图片 2/10：./export\CVPR\images\figure_2_page13.jpeg
2025-11-11 01:08:14,460 - INFO - root - 已保存图片 3/10：./export\CVPR\images\figure_3_page13.jpeg
2025-11-11 01:08:14,525 - INFO - root - 已保存图片 4/10：./export\CVPR\images\figure_4_page2.jpeg
2025-11-11 01:08:14,586 - INFO - root - 已保存图片 5/10：./export\CVPR\images\figure_5_page5.png
2025-11-11 01:08:14,630 - INFO - root - 已保存图片 6/10：./export\CVPR\images\figure_6_page13.jpeg
2025-11-11 01:08:14,694 - INFO - root - 已保存图片 7/10：./export\CVPR\images\figure_7_page2.jpeg
2025-11-11 01:08:14,733 - INFO - root - 已保存图片 8/10：./export\CVPR\images\figure_8_page8.jpeg
2025-11-11 01:08:14,752 - INFO - root - 已保存图片 9/10：./export\CVPR\images\figure_9_page1.jpeg
2025-11-11 01:08:14,772 - INFO - root - 已保存图片 10/10：./export\CVPR\images\figure_10_page1.png
2025-11-11 01:08:14,779 - INFO - root - 成功添加图片 1：./export\CVPR\images\figure_1_page13.jpeg
2025-11-11 01:08:14,779 - INFO - root - 成功添加图片 2：./export\CVPR\images\figure_2_page13.jpeg
2025-11-11 01:08:14,780 - INFO - root - 成功添加图片 3：./export\CVPR\images\figure_3_page13.jpeg
2025-11-11 01:08:14,785 - INFO - root - 成功添加图片 4：./export\CVPR\images\figure_4_page2.jpeg
2025-11-11 01:08:14,786 - INFO - root - 成功添加图片 5：./export\CVPR\images\figure_5_page5.png
2025-11-11 01:08:14,787 - INFO - root - 成功添加图片 6：./export\CVPR\images\figure_6_page13.jpeg
2025-11-11 01:08:14,787 - INFO - root - 成功添加图片 7：./export\CVPR\images\figure_7_page2.jpeg
2025-11-11 01:08:14,787 - INFO - root - 成功添加图片 8：./export\CVPR\images\figure_8_page8.jpeg
2025-11-11 01:08:14,789 - INFO - root - 成功添加图片 9：./export\CVPR\images\figure_9_page1.jpeg
2025-11-11 01:08:14,789 - INFO - root - 成功添加图片 10：./export\CVPR\images\figure_10_page1.png
2025-11-11 01:08:14,792 - INFO - root - 论文《OmniTrack++: Omnidirectional Multi-Object Tracking by Learning Large-FoV Trajectory Feedback》的分析已保存到 ./export\CVPR\OmniTrack++_ Omnidirectional Multi-Object Tracking by Learning Large-FoV Traject.md
2025-11-11 01:08:14,796 - INFO - root - 正在总结论文 3/5: NeuCo-Bench: A Novel Benchmark Framework for Neural Embeddings in Earth Observation
2025-11-11 01:08:26,361 - INFO - root - LLMClient: rate limit reached, sleeping 20.0s
2025-11-11 01:10:01,803 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-11 01:10:01,804 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-11 01:10:01,807 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-11 01:10:04,399 - INFO - root - LLMClientManager: 指定使用客户端: Gemini
2025-11-11 01:10:05,827 - INFO - root - GeminiClient: trying model models/gemini-2.5-flash
2025-11-11 01:10:09,206 - INFO - root - GeminiClient: initialized model gemini-2.5-flash
2025-11-11 01:10:09,207 - INFO - root - LLMClientManager: Gemini 客户端初始化成功
2025-11-11 01:10:09,208 - INFO - root - LLMClientManager: switched to Gemini client
2025-11-11 01:10:09,208 - INFO - root - 已手动切换到 LLM 客户端: Gemini
2025-11-11 01:10:09,208 - INFO - root - 使用 LLM 模型: gemini-2.5-flash
2025-11-11 01:10:09,209 - INFO - root - 可用客户端: ['Gemini']
2025-11-11 01:10:09,209 - INFO - root - === 运行配置 ===
2025-11-11 01:10:09,210 - INFO - root - 处理模式: arxiv在线搜索
2025-11-11 01:10:09,211 - INFO - root - 关键词: CVPR
2025-11-11 01:10:09,211 - INFO - root - 查询: CVPR 2025
2025-11-11 01:10:09,211 - INFO - root - 排序: None
2025-11-11 01:10:09,217 - INFO - root - 最近天数: 180
2025-11-11 01:10:09,217 - INFO - root - 最大处理数量: 50
2025-11-11 01:10:09,219 - INFO - root - 保存图片: 是
2025-11-11 01:10:09,219 - INFO - root - 输出语言: 中文
2025-11-11 01:10:09,221 - INFO - root - 强制重新处理: 否
2025-11-11 01:10:09,222 - INFO - root - ====================
2025-11-11 01:10:09,222 - INFO - root - 使用 arXiv 搜索模式（通过 chat_arxiv 模块获取）
2025-11-11 01:10:09,222 - INFO - root - Fetching page 1 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50
2025-11-11 01:10:20,191 - INFO - root - get_all_titles_from_web 
2025-11-11 01:10:20,193 - INFO - root - Page:0, Index:0, Learning to Seek Evidence: A Verifiable Reasoning Agent with Causal Faithfulness Analysis, https://arxiv.org/pdf/2511.01425, 2025-11-03
2025-11-11 01:10:20,193 - INFO - root - Page:0, Index:1, OmniTrack++: Omnidirectional Multi-Object Tracking by Learning Large-FoV Trajectory Feedback, https://arxiv.org/pdf/2511.00510, 2025-11-01
2025-11-11 01:10:20,193 - INFO - root - Page:0, Index:2, NeuCo-Bench: A Novel Benchmark Framework for Neural Embeddings in Earth Observation, https://arxiv.org/pdf/2510.17914, 2025-10-19
2025-11-11 01:10:20,194 - INFO - root - Page:0, Index:3, NTIRE 2025 Challenge on Low Light Image Enhancement: Methods and Results, https://arxiv.org/pdf/2510.13670, 2025-10-15
2025-11-11 01:10:20,194 - INFO - root - Page:0, Index:4, Class Prototypes based Contrastive Learning for Classifying Multi-Label and Fine-Grained Educational Videos, https://arxiv.org/pdf/2510.11204, 2025-10-13
2025-11-11 01:10:20,194 - INFO - root - Page:0, Index:5, MIMO: A medical vision language model with visual referring multimodal input and pixel grounding multimodal output, https://arxiv.org/pdf/2510.10011, 2025-10-11
2025-11-11 01:10:20,194 - INFO - root - Page:0, Index:6, Vision Language Models: A Survey of 26K Papers, https://arxiv.org/pdf/2510.09586, 2025-10-10
2025-11-11 01:10:20,195 - INFO - root - Page:0, Index:7, DiT-VTON: Diffusion Transformer Framework for Unified Multi-Category Virtual Try-On and Virtual Try-All with Integrated Image Editing, https://arxiv.org/pdf/2510.04797, 2025-10-03
2025-11-11 01:10:20,195 - INFO - root - Page:0, Index:8, PatchVSR: Breaking Video Diffusion Resolution Limits with Patch-wise Video Super-Resolution, https://arxiv.org/pdf/2509.26025, 2025-09-30
2025-11-11 01:10:20,195 - INFO - root - Page:0, Index:9, FreqDebias: Towards Generalizable Deepfake Detection via Consistency-Driven Frequency Debiasing, https://arxiv.org/pdf/2509.22412, 2025-09-26
2025-11-11 01:10:20,195 - INFO - root - Page:0, Index:10, A Mutual Learning Method for Salient Object Detection with intertwined Multi-Supervision--Revised, https://arxiv.org/pdf/2509.21363, 2025-09-21
2025-11-11 01:10:20,195 - INFO - root - Page:0, Index:11, InstructVTON: Optimal Auto-Masking and Natural-Language-Guided Interactive Style Control for Inpainting-Based Virtual Try-On, https://arxiv.org/pdf/2509.20524, 2025-09-24
2025-11-11 01:10:20,196 - INFO - root - Page:0, Index:12, Efficient Encoder-Free Pose Conditioning and Pose Control for Virtual Try-On, https://arxiv.org/pdf/2509.20343, 2025-09-24
2025-11-11 01:10:20,196 - INFO - root - Page:0, Index:13, The Photographer Eye: Teaching Multimodal Large Language Models to Understand Image Aesthetics like Photographers, https://arxiv.org/pdf/2509.18582, 2025-10-22
2025-11-11 01:10:20,196 - INFO - root - Page:0, Index:14, ENSAM: an efficient foundation model for interactive segmentation of 3D medical images, https://arxiv.org/pdf/2509.15874, 2025-09-19
2025-11-11 01:10:20,196 - INFO - root - Page:0, Index:15, DEFT-VTON: Efficient Virtual Try-On with Consistent Generalised H-Transform, https://arxiv.org/pdf/2509.13506, 2025-09-16
2025-11-11 01:10:20,197 - INFO - root - Page:0, Index:16, Weakly and Self-Supervised Class-Agnostic Motion Prediction for Autonomous Driving, https://arxiv.org/pdf/2509.13116, 2025-09-16
2025-11-11 01:10:20,197 - INFO - root - Page:0, Index:17, Domain-Adaptive Pretraining Improves Primate Behavior Recognition, https://arxiv.org/pdf/2509.12193, 2025-09-15
2025-11-11 01:10:20,197 - INFO - root - Page:0, Index:18, The System Description of CPS Team for Track on Driving with Language of CVPR 2024 Autonomous Grand Challenge, https://arxiv.org/pdf/2509.11071, 2025-09-13
2025-11-11 01:10:20,197 - INFO - root - Page:0, Index:19, An HMM-based framework for identity-aware long-term multi-object tracking from sparse and uncertain identification: use case on long-term tracking in livestock, https://arxiv.org/pdf/2509.09962, 2025-09-12
2025-11-11 01:10:20,198 - INFO - root - Page:0, Index:20, InterAct: Advancing Large-Scale Versatile 3D Human-Object Interaction Generation, https://arxiv.org/pdf/2509.09555, 2025-09-11
2025-11-11 01:10:20,198 - INFO - root - Page:0, Index:21, Geospatial Foundational Embedder: Top-1 Winning Solution on EarthVision Embed2Scale Challenge (CVPR 2025), https://arxiv.org/pdf/2509.06993, 2025-09-03
2025-11-11 01:10:20,198 - INFO - root - Page:0, Index:22, 2nd Place Solution for CVPR2024 E2E Challenge: End-to-End Autonomous Driving Using Vision Language Model, https://arxiv.org/pdf/2509.02659, 2025-09-02
2025-11-11 01:10:20,198 - INFO - root - Page:0, Index:23, Unsupervised Training of Vision Transformers with Synthetic Negatives, https://arxiv.org/pdf/2509.02024, 2025-09-02
2025-11-11 01:10:20,198 - INFO - root - Page:0, Index:24, MV-SSM: Multi-View State Space Modeling for 3D Human Pose Estimation, https://arxiv.org/pdf/2509.00649, 2025-08-30
2025-11-11 01:10:20,198 - INFO - root - Page:0, Index:25, CryptoFace: End-to-End Encrypted Face Recognition, https://arxiv.org/pdf/2509.00332, 2025-08-29
2025-11-11 01:10:20,199 - INFO - root - Page:0, Index:26, ControlEchoSynth: Boosting Ejection Fraction Estimation Models via Controlled Video Diffusion, https://arxiv.org/pdf/2508.17631, 2025-08-26
2025-11-11 01:10:20,199 - INFO - root - Page:0, Index:27, Explain Before You Answer: A Survey on Compositional Visual Reasoning, https://arxiv.org/pdf/2508.17298, 2025-08-27
2025-11-11 01:10:20,199 - INFO - root - Page:0, Index:28, Investigating Different Geo Priors for Image Classification, https://arxiv.org/pdf/2508.15946, 2025-08-21
2025-11-11 01:10:20,199 - INFO - root - Page:0, Index:29, Towards Source-Free Machine Unlearning, https://arxiv.org/pdf/2508.15127, 2025-08-20
2025-11-11 01:10:20,199 - INFO - root - Page:0, Index:30, MR6D: Benchmarking 6D Pose Estimation for Mobile Robots, https://arxiv.org/pdf/2508.13775, 2025-08-19
2025-11-11 01:10:20,199 - INFO - root - Page:0, Index:31, Calibrating Biased Distribution in VFM-derived Latent Space via Cross-Domain Geometric Consistency, https://arxiv.org/pdf/2508.13518, 2025-08-19
2025-11-11 01:10:20,199 - INFO - root - Page:0, Index:32, SIS-Challenge: Event-based Spatio-temporal Instance Segmentation Challenge at the CVPR 2025 Event-based Vision Workshop, https://arxiv.org/pdf/2508.12813, 2025-08-18
2025-11-11 01:10:20,200 - INFO - root - Page:0, Index:33, Multi-Level Knowledge Distillation and Dynamic Self-Supervised Learning for Continual Learning, https://arxiv.org/pdf/2508.12692, 2025-08-22
2025-11-11 01:10:20,201 - INFO - root - Page:0, Index:34, Stochastic-based Patch Filtering for Few-Shot Learning, https://arxiv.org/pdf/2508.10066, 2025-08-13
2025-11-11 01:10:20,202 - INFO - root - Page:0, Index:35, Slot Attention-based Feature Filtering for Few-Shot Learning, https://arxiv.org/pdf/2508.09699, 2025-08-13
2025-11-11 01:10:20,204 - INFO - root - Page:0, Index:36, Comparison Reveals Commonality: Customized Image Generation through Contrastive Inversion, https://arxiv.org/pdf/2508.07755, 2025-08-11
2025-11-11 01:10:20,204 - INFO - root - Page:0, Index:37, SLRTP2025 Sign Language Production Challenge: Methodology, Results, and Future Work, https://arxiv.org/pdf/2508.06951, 2025-08-09
2025-11-11 01:10:20,205 - INFO - root - Page:0, Index:38, Exploring Fairness across Fine-Grained Attributes in Large Vision-Language Models, https://arxiv.org/pdf/2508.03079, 2025-08-05
2025-11-11 01:10:20,205 - INFO - root - Page:0, Index:39, Devil is in the Detail: Towards Injecting Fine Details of Image Prompt in Image Generation via Conflict-free Guidance and Stratified Attention, https://arxiv.org/pdf/2508.02004, 2025-08-03
2025-11-11 01:10:20,205 - INFO - root - Page:0, Index:40, IAUNet: Instance-Aware U-Net, https://arxiv.org/pdf/2508.01928, 2025-08-03
2025-11-11 01:10:20,208 - INFO - root - Page:0, Index:41, Gaussian Splatting Feature Fields for Privacy-Preserving Visual Localization, https://arxiv.org/pdf/2507.23569, 2025-08-26
2025-11-11 01:10:20,208 - INFO - root - Page:0, Index:42, From Scan to Action: Leveraging Realistic Scans for Embodied Scene Understanding, https://arxiv.org/pdf/2507.17585, 2025-07-23
2025-11-11 01:10:20,210 - INFO - root - Page:0, Index:43, LEAD: Exploring Logit Space Evolution for Model Selection, https://arxiv.org/pdf/2507.14559, 2025-07-19
2025-11-11 01:10:20,211 - INFO - root - Page:0, Index:44, HeCoFuse: Cross-Modal Complementary V2X Cooperative Perception with Heterogeneous Sensors, https://arxiv.org/pdf/2507.13677, 2025-07-18
2025-11-11 01:10:20,211 - INFO - root - Page:0, Index:45, OmniVec2 -- A Novel Transformer based Network for Large Scale Multimodal and Multitask Learning, https://arxiv.org/pdf/2507.13364, 2025-07-06
2025-11-11 01:10:20,211 - INFO - root - Page:0, Index:46, A Training-Free, Task-Agnostic Framework for Enhancing MLLM Performance on High-Resolution Images, https://arxiv.org/pdf/2507.10202, 2025-07-14
2025-11-11 01:10:20,212 - INFO - root - Page:0, Index:47, Quantum Federated Learning for Multimodal Data: A Modality-Agnostic Approach, https://arxiv.org/pdf/2507.08217, 2025-07-10
2025-11-11 01:10:20,212 - INFO - root - Page:0, Index:48, CuriosAI Submission to the EgoExo4D Proficiency Estimation Challenge 2025, https://arxiv.org/pdf/2507.08022, 2025-07-08
2025-11-11 01:10:20,212 - INFO - root - Page:0, Index:49, Rethinking Query-based Transformer for Continual Image Segmentation, https://arxiv.org/pdf/2507.07831, 2025-07-10
2025-11-11 01:10:20,212 - INFO - root - Fetching page 2 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=50
2025-11-11 01:10:30,495 - INFO - root - get_all_titles_from_web 
2025-11-11 01:10:30,495 - INFO - root - Page:1, Index:0, Scalable and Realistic Virtual Try-on Application for Foundation Makeup with Kubelka-Munk Theory, https://arxiv.org/pdf/2507.07333, 2025-07-09
2025-11-11 01:10:30,496 - INFO - root - Page:1, Index:1, Free on the Fly: Enhancing Flexibility in Test-Time Adaptation with Online EM, https://arxiv.org/pdf/2507.06973, 2025-07-09
2025-11-11 01:10:30,496 - INFO - root - Page:1, Index:2, Adaptive Part Learning for Fine-Grained Generalized Category Discovery: A Plug-and-Play Enhancement, https://arxiv.org/pdf/2507.06928, 2025-07-09
2025-11-11 01:10:30,496 - INFO - root - Page:1, Index:3, Grounded Gesture Generation: Language, Motion, and Space, https://arxiv.org/pdf/2507.04522, 2025-07-06
2025-11-11 01:10:30,497 - INFO - root - Page:1, Index:4, Comprehensive Information Bottleneck for Unveiling Universal Attribution to Interpret Vision Transformers, https://arxiv.org/pdf/2507.04388, 2025-07-06
2025-11-11 01:10:30,497 - INFO - root - Page:1, Index:5, ZERO: Industry-ready Vision Foundation Model with Multi-modal Prompts, https://arxiv.org/pdf/2507.04270, 2025-11-07
2025-11-11 01:10:30,498 - INFO - root - Page:1, Index:6, Beyond Accuracy: Metrics that Uncover What Makes a 'Good' Visual Descriptor, https://arxiv.org/pdf/2507.03542, 2025-07-08
2025-11-11 01:10:30,498 - INFO - root - Page:1, Index:7, ConceptMix++: Leveling the Playing Field in Text-to-Image Benchmarking via Iterative Prompt Optimization, https://arxiv.org/pdf/2507.03275, 2025-07-03
2025-11-11 01:10:30,498 - INFO - root - Page:1, Index:8, APT: Adaptive Personalized Training for Diffusion Models with Limited Data, https://arxiv.org/pdf/2507.02687, 2025-07-03
2025-11-11 01:10:30,498 - INFO - root - Page:1, Index:9, DreamComposer++: Empowering Diffusion Models with Multi-View Conditions for 3D Content Generation, https://arxiv.org/pdf/2507.02299, 2025-07-03
2025-11-11 01:10:30,499 - INFO - root - Page:1, Index:10, Soft Self-labeling and Potts Relaxations for Weakly-Supervised Segmentation, https://arxiv.org/pdf/2507.01721, 2025-07-02
2025-11-11 01:10:30,499 - INFO - root - Page:1, Index:11, Interpolation-Based Event Visual Data Filtering Algorithms, https://arxiv.org/pdf/2507.01557, 2025-07-02
2025-11-11 01:10:30,499 - INFO - root - Page:1, Index:12, AVC-DPO: Aligned Video Captioning via Direct Preference Optimization, https://arxiv.org/pdf/2507.01492, 2025-07-02
2025-11-11 01:10:30,499 - INFO - root - Page:1, Index:13, NN-Former: Rethinking Graph Structure in Neural Architecture Representation, https://arxiv.org/pdf/2507.00880, 2025-07-01
2025-11-11 01:10:30,499 - INFO - root - Page:1, Index:14, Instant Particle Size Distribution Measurement Using CNNs Trained on Synthetic Data, https://arxiv.org/pdf/2507.00822, 2025-07-01
2025-11-11 01:10:30,500 - INFO - root - Page:1, Index:15, Moment Sampling in Video LLMs for Long-Form Video QA, https://arxiv.org/pdf/2507.00033, 2025-06-17
2025-11-11 01:10:30,502 - INFO - root - Page:1, Index:16, Revisiting Audio-Visual Segmentation with Vision-Centric Transformer, https://arxiv.org/pdf/2506.23623, 2025-06-30
2025-11-11 01:10:30,502 - INFO - root - Page:1, Index:17, MTADiffusion: Mask Text Alignment Diffusion Model for Object Inpainting, https://arxiv.org/pdf/2506.23482, 2025-06-29
2025-11-11 01:10:30,502 - INFO - root - Page:1, Index:18, Benchmarking Generalizable Bimanual Manipulation: RoboTwin Dual-Arm Collaboration Challenge at CVPR 2025 MEIS Workshop, https://arxiv.org/pdf/2506.23351, 2025-07-02
2025-11-11 01:10:30,502 - INFO - root - Page:1, Index:19, Prompting without Panic: Attribute-aware, Zero-shot, Test-Time Calibration, https://arxiv.org/pdf/2506.22819, 2025-06-28
2025-11-11 01:10:30,503 - INFO - root - Page:1, Index:20, Analyzing and Fine-Tuning Whisper Models for Multilingual Pilot Speech Transcription in the Cockpit, https://arxiv.org/pdf/2506.21990, 2025-06-27
2025-11-11 01:10:30,503 - INFO - root - Page:1, Index:21, SceneDiffuser++: City-Scale Traffic Simulation via a Generative World Model, https://arxiv.org/pdf/2506.21976, 2025-06-27
2025-11-11 01:10:30,504 - INFO - root - Page:1, Index:22, DIVE: Deep-search Iterative Video Exploration A Technical Report for the CVRR Challenge at CVPR 2025, https://arxiv.org/pdf/2506.21891, 2025-06-27
2025-11-11 01:10:30,504 - INFO - root - Page:1, Index:23, End-to-End RGB-IR Joint Image Compression With Channel-wise Cross-modality Entropy Model, https://arxiv.org/pdf/2506.21851, 2025-06-26
2025-11-11 01:10:30,505 - INFO - root - Page:1, Index:24, Distilling Normalizing Flows, https://arxiv.org/pdf/2506.21003, 2025-06-26
2025-11-11 01:10:30,508 - INFO - root - Page:1, Index:25, Joint attitude estimation and 3D neural reconstruction of non-cooperative space objects, https://arxiv.org/pdf/2506.20638, 2025-06-25
2025-11-11 01:10:30,508 - INFO - root - Page:1, Index:26, Accept More, Reject Less: Reducing up to 19% Unnecessary Desk-Rejections over 11 Years of ICLR Data, https://arxiv.org/pdf/2506.20141, 2025-06-25
2025-11-11 01:10:30,509 - INFO - root - Page:1, Index:27, SceneCrafter: Controllable Multi-View Driving Scene Editing, https://arxiv.org/pdf/2506.19488, 2025-06-24
2025-11-11 01:10:30,509 - INFO - root - Page:1, Index:28, Emergence of Text Readability in Vision Language Models, https://arxiv.org/pdf/2506.19389, 2025-06-24
2025-11-11 01:10:30,509 - INFO - root - Page:1, Index:29, MedErr-CT: A Visual Question Answering Benchmark for Identifying and Correcting Errors in CT Reports, https://arxiv.org/pdf/2506.19217, 2025-06-23
2025-11-11 01:10:30,510 - INFO - root - Page:1, Index:30, RareSpot: Spotting Small and Rare Wildlife in Aerial Imagery with Multi-Scale Consistency and Context-Aware Augmentation, https://arxiv.org/pdf/2506.19087, 2025-06-23
2025-11-11 01:10:30,510 - INFO - root - Page:1, Index:31, Object-aware Sound Source Localization via Audio-Visual Scene Understanding, https://arxiv.org/pdf/2506.18557, 2025-06-23
2025-11-11 01:10:30,510 - INFO - root - Page:1, Index:32, Rethinking Decoder Design: Improving Biomarker Segmentation Using Depth-to-Space Restoration and Residual Linear Attention, https://arxiv.org/pdf/2506.18335, 2025-06-23
2025-11-11 01:10:30,511 - INFO - root - Page:1, Index:33, Relation3D: Enhancing Relation Modeling for Point Cloud Instance Segmentation, https://arxiv.org/pdf/2506.17891, 2025-06-21
2025-11-11 01:10:30,511 - INFO - root - Page:1, Index:34, HIRE: Lightweight High-Resolution Image Feature Enrichment for Multimodal LLMs, https://arxiv.org/pdf/2506.17608, 2025-06-21
2025-11-11 01:10:30,511 - INFO - root - Page:1, Index:35, Spatially-Aware Evaluation of Segmentation Uncertainty, https://arxiv.org/pdf/2506.16589, 2025-06-19
2025-11-11 01:10:30,511 - INFO - root - Page:1, Index:36, Tripartite Weight-Space Ensemble for Few-Shot Class-Incremental Learning, https://arxiv.org/pdf/2506.15720, 2025-06-03
2025-11-11 01:10:30,512 - INFO - root - Page:1, Index:37, PARC: A Quantitative Framework Uncovering the Symmetries within Vision Language Models, https://arxiv.org/pdf/2506.14808, 2025-06-03
2025-11-11 01:10:30,512 - INFO - root - Page:1, Index:38, Self-supervised Representation Learning with Local Aggregation for Image-based Profiling, https://arxiv.org/pdf/2506.14265, 2025-10-27
2025-11-11 01:10:30,512 - INFO - root - Page:1, Index:39, Towards Robust Learning to Optimize with Theoretical Guarantees, https://arxiv.org/pdf/2506.14263, 2025-06-17
2025-11-11 01:10:30,513 - INFO - root - Page:1, Index:40, Hidden Bias in the Machine: Stereotypes in Text-to-Image Models, https://arxiv.org/pdf/2506.13780, 2025-06-09
2025-11-11 01:10:30,513 - INFO - root - Page:1, Index:41, SmartHome-Bench: A Comprehensive Benchmark for Video Anomaly Detection in Smart Homes Using Multi-Modal Large Language Models, https://arxiv.org/pdf/2506.12992, 2025-06-15
2025-11-11 01:10:30,513 - INFO - root - Page:1, Index:42, Generative 4D Scene Gaussian Splatting with Object View-Synthesis Priors, https://arxiv.org/pdf/2506.12716, 2025-06-15
2025-11-11 01:10:30,514 - INFO - root - Page:1, Index:43, DejaVid: Encoder-Agnostic Learned Temporal Matching for Video Classification, https://arxiv.org/pdf/2506.12585, 2025-06-14
2025-11-11 01:10:30,514 - INFO - root - Page:1, Index:44, Pushing the Limits of Safety: A Technical Report on the ATLAS Challenge 2025, https://arxiv.org/pdf/2506.12430, 2025-07-10
2025-11-11 01:10:30,514 - INFO - root - Page:1, Index:45, FIMA-Q: Post-Training Quantization for Vision Transformers by Fisher Information Matrix Approximation, https://arxiv.org/pdf/2506.11543, 2025-06-13
2025-11-11 01:10:30,515 - INFO - root - Page:1, Index:46, Stop learning it all to mitigate visual hallucination, Focus on the hallucination target, https://arxiv.org/pdf/2506.11417, 2025-06-12
2025-11-11 01:10:30,515 - INFO - root - Page:1, Index:47, EfficientQuant: An Efficient Post-Training Quantization for CNN-Transformer Hybrid Models on Edge Devices, https://arxiv.org/pdf/2506.11093, 2025-06-05
2025-11-11 01:10:30,516 - INFO - root - Page:1, Index:48, HalLoc: Token-level Localization of Hallucinations for Vision Language Models, https://arxiv.org/pdf/2506.10286, 2025-06-11
2025-11-11 01:10:30,523 - INFO - root - Page:1, Index:49, DySS: Dynamic Queries and State-Space Learning for Efficient 3D Object Detection from Multi-Camera Videos, https://arxiv.org/pdf/2506.10242, 2025-06-11
2025-11-11 01:10:30,524 - INFO - root - Fetching page 3 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=100
2025-11-11 01:10:41,785 - INFO - root - get_all_titles_from_web 
2025-11-11 01:10:41,786 - INFO - root - Page:2, Index:0, Improving Personalized Search with Regularized Low-Rank Parameter Updates, https://arxiv.org/pdf/2506.10182, 2025-06-11
2025-11-11 01:10:41,786 - INFO - root - Page:2, Index:1, Hearing Hands: Generating Sounds from Physical Interactions in 3D Scenes, https://arxiv.org/pdf/2506.09989, 2025-06-11
2025-11-11 01:10:41,786 - INFO - root - Page:2, Index:2, UniPre3D: Unified Pre-training of 3D Point Cloud Models with Cross-Modal Gaussian Splatting, https://arxiv.org/pdf/2506.09952, 2025-06-11
2025-11-11 01:10:41,786 - INFO - root - Page:2, Index:3, Provoking Multi-modal Few-Shot LVLM via Exploration-Exploitation In-Context Learning, https://arxiv.org/pdf/2506.09473, 2025-06-11
2025-11-11 01:10:41,788 - INFO - root - Page:2, Index:4, Synthetic Human Action Video Data Generation with Pose Transfer, https://arxiv.org/pdf/2506.09411, 2025-06-11
2025-11-11 01:10:41,788 - INFO - root - Page:2, Index:5, ScaleLSD: Scalable Deep Line Segment Detection Streamlined, https://arxiv.org/pdf/2506.09369, 2025-06-10
2025-11-11 01:10:41,788 - INFO - root - Page:2, Index:6, CheckManual: A New Challenge and Benchmark for Manual-based Appliance Manipulation, https://arxiv.org/pdf/2506.09343, 2025-06-10
2025-11-11 01:10:41,788 - INFO - root - Page:2, Index:7, PatchGuard: Adversarially Robust Anomaly Detection and Localization through Vision Transformers and Pseudo Anomalies, https://arxiv.org/pdf/2506.09237, 2025-10-24
2025-11-11 01:10:41,789 - INFO - root - Page:2, Index:8, SILK: Smooth InterpoLation frameworK for motion in-betweening A Simplified Computational Approach, https://arxiv.org/pdf/2506.09075, 2025-06-09
2025-11-11 01:10:41,789 - INFO - root - Page:2, Index:9, BG-HOP: A Bimanual Generative Hand-Object Prior, https://arxiv.org/pdf/2506.09068, 2025-06-08
2025-11-11 01:10:41,789 - INFO - root - Page:2, Index:10, ORIDa: Object-centric Real-world Image Composition Dataset, https://arxiv.org/pdf/2506.08964, 2025-06-10
2025-11-11 01:10:41,790 - INFO - root - Page:2, Index:11, DiscoVLA: Discrepancy Reduction in Vision, Language, and Alignment for Parameter-Efficient Video-Text Retrieval, https://arxiv.org/pdf/2506.08887, 2025-06-10
2025-11-11 01:10:41,790 - INFO - root - Page:2, Index:12, A Comprehensive Study of Decoder-Only LLMs for Text-to-Image Generation, https://arxiv.org/pdf/2506.08210, 2025-06-09
2025-11-11 01:10:41,790 - INFO - root - Page:2, Index:13, Open World Scene Graph Generation using Vision Language Models, https://arxiv.org/pdf/2506.08189, 2025-06-09
2025-11-11 01:10:41,791 - INFO - root - Page:2, Index:14, Aligning Proteins and Language: A Foundation Model for Protein Retrieval, https://arxiv.org/pdf/2506.08023, 2025-05-27
2025-11-11 01:10:41,791 - INFO - root - Page:2, Index:15, UA-Pose: Uncertainty-Aware 6D Object Pose Estimation and Online Object Completion with Partial References, https://arxiv.org/pdf/2506.07996, 2025-06-09
2025-11-11 01:10:41,791 - INFO - root - Page:2, Index:16, Speedy Deformable 3D Gaussian Splatting: Fast Rendering and Compression of Dynamic Scenes, https://arxiv.org/pdf/2506.07917, 2025-06-09
2025-11-11 01:10:41,791 - INFO - root - Page:2, Index:17, GaussianVAE: Adaptive Learning Dynamics of 3D Gaussians for High-Fidelity Super-Resolution, https://arxiv.org/pdf/2506.07897, 2025-06-09
2025-11-11 01:10:41,792 - INFO - root - Page:2, Index:18, Spatio-Temporal State Space Model For Efficient Event-Based Optical Flow, https://arxiv.org/pdf/2506.07878, 2025-06-09
2025-11-11 01:10:41,792 - INFO - root - Page:2, Index:19, FreeGave: 3D Physics Learning from Dynamic Videos by Gaussian Velocity, https://arxiv.org/pdf/2506.07865, 2025-06-09
2025-11-11 01:10:41,793 - INFO - root - Page:2, Index:20, LogoSP: Local-global Grouping of Superpoints for Unsupervised Semantic Segmentation of 3D Point Clouds, https://arxiv.org/pdf/2506.07857, 2025-06-09
2025-11-11 01:10:41,793 - INFO - root - Page:2, Index:21, Difference Inversion: Interpolate and Isolate the Difference with Token Consistency for Image Analogy Generation, https://arxiv.org/pdf/2506.07750, 2025-06-09
2025-11-11 01:10:41,793 - INFO - root - Page:2, Index:22, Synthetic Visual Genome, https://arxiv.org/pdf/2506.07643, 2025-06-09
2025-11-11 01:10:41,794 - INFO - root - Page:2, Index:23, Fractional Collisions: A Framework for Risk Estimation of Counterfactual Conflicts using Autonomous Driving Behavior Simulations, https://arxiv.org/pdf/2506.07540, 2025-06-09
2025-11-11 01:10:41,794 - INFO - root - Page:2, Index:24, Multi-Step Guided Diffusion for Image Restoration on Edge Devices: Toward Lightweight Perception in Embodied AI, https://arxiv.org/pdf/2506.07286, 2025-06-08
2025-11-11 01:10:41,795 - INFO - root - Page:2, Index:25, LLM-Enhanced Rapid-Reflex Async-Reflect Embodied Agent for Real-Time Decision-Making in Dynamically Changing Environments, https://arxiv.org/pdf/2506.07223, 2025-06-08
2025-11-11 01:10:41,795 - INFO - root - Page:2, Index:26, UCOD-DPL: Unsupervised Camouflaged Object Detection via Dynamic Pseudo-label Learning, https://arxiv.org/pdf/2506.07087, 2025-06-08
2025-11-11 01:10:41,796 - INFO - root - Page:2, Index:27, BePo: Leveraging Birds Eye View and Sparse Points for Efficient and Accurate 3D Occupancy Prediction, https://arxiv.org/pdf/2506.07002, 2025-06-08
2025-11-11 01:10:41,796 - INFO - root - Page:2, Index:28, Reading in the Dark with Foveated Event Vision, https://arxiv.org/pdf/2506.06918, 2025-06-07
2025-11-11 01:10:41,799 - INFO - root - Page:2, Index:29, NSD-Imagery: A benchmark dataset for extending fMRI vision decoding methods to mental imagery, https://arxiv.org/pdf/2506.06898, 2025-06-07
2025-11-11 01:10:41,801 - INFO - root - Page:2, Index:30, Continuous-Time SO(3) Forecasting with Savitzky--Golay Neural Controlled Differential Equations, https://arxiv.org/pdf/2506.06780, 2025-06-07
2025-11-11 01:10:41,801 - INFO - root - Page:2, Index:31, Generalized Trajectory Scoring for End-to-end Multimodal Planning, https://arxiv.org/pdf/2506.06664, 2025-06-07
2025-11-11 01:10:41,801 - INFO - root - Page:2, Index:32, EV-LayerSegNet: Self-supervised Motion Segmentation using Event Cameras, https://arxiv.org/pdf/2506.06596, 2025-06-06
2025-11-11 01:10:41,801 - INFO - root - Page:2, Index:33, Vid2Sim: Generalizable, Video-based Reconstruction of Appearance, Geometry and Physics for Mesh-free Simulation, https://arxiv.org/pdf/2506.06440, 2025-06-06
2025-11-11 01:10:41,801 - INFO - root - Page:2, Index:34, FADE: Frequency-Aware Diffusion Model Factorization for Video Editing, https://arxiv.org/pdf/2506.05934, 2025-06-06
2025-11-11 01:10:41,803 - INFO - root - Page:2, Index:35, Unleashing the Potential of Consistency Learning for Detecting and Grounding Multi-Modal Media Manipulation, https://arxiv.org/pdf/2506.05890, 2025-06-06
2025-11-11 01:10:41,803 - INFO - root - Page:2, Index:36, DeformCL: Learning Deformable Centerline Representation for Vessel Extraction in 3D Medical Image, https://arxiv.org/pdf/2506.05820, 2025-06-06
2025-11-11 01:10:41,803 - INFO - root - Page:2, Index:37, NTIRE 2025 Challenge on HR Depth from Images of Specular and Transparent Surfaces, https://arxiv.org/pdf/2506.05815, 2025-06-06
2025-11-11 01:10:41,804 - INFO - root - Page:2, Index:38, GazeNLQ @ Ego4D Natural Language Queries Challenge 2025, https://arxiv.org/pdf/2506.05782, 2025-06-06
2025-11-11 01:10:41,804 - INFO - root - Page:2, Index:39, Robust sensor fusion against on-vehicle sensor staleness, https://arxiv.org/pdf/2506.05780, 2025-06-06
2025-11-11 01:10:41,804 - INFO - root - Page:2, Index:40, Where Is The Ball: 3D Ball Trajectory Estimation From 2D Monocular Tracking, https://arxiv.org/pdf/2506.05763, 2025-06-06
2025-11-11 01:10:41,804 - INFO - root - Page:2, Index:41, VoxelSplat: Dynamic Gaussian Splatting as an Effective Loss for Occupancy and Flow Prediction, https://arxiv.org/pdf/2506.05563, 2025-06-05
2025-11-11 01:10:41,806 - INFO - root - Page:2, Index:42, Gen4D: Synthesizing Humans and Scenes in the Wild, https://arxiv.org/pdf/2506.05397, 2025-06-03
2025-11-11 01:10:41,806 - INFO - root - Page:2, Index:43, Attacking Attention of Foundation Models Disrupts Downstream Tasks, https://arxiv.org/pdf/2506.05394, 2025-09-12
2025-11-11 01:10:41,829 - INFO - root - Page:2, Index:44, FreeTimeGS: Free Gaussian Primitives at Anytime and Anywhere for Dynamic Scene Reconstruction, https://arxiv.org/pdf/2506.05348, 2025-06-06
2025-11-11 01:10:41,830 - INFO - root - Page:2, Index:45, LotusFilter: Fast Diverse Nearest Neighbor Search via a Learned Cutoff Table, https://arxiv.org/pdf/2506.04790, 2025-06-05
2025-11-11 01:10:41,831 - INFO - root - Page:2, Index:46, Towards Holistic Visual Quality Assessment of AI-Generated Videos: A LLM-Based Multi-Dimensional Evaluation Model, https://arxiv.org/pdf/2506.04715, 2025-06-11
2025-11-11 01:10:41,832 - INFO - root - Page:2, Index:47, Gradient Inversion Attacks on Parameter-Efficient Fine-Tuning, https://arxiv.org/pdf/2506.04453, 2025-06-04
2025-11-11 01:10:41,832 - INFO - root - Page:2, Index:48, HMAR: Efficient Hierarchical Masked Auto-Regressive Image Generation, https://arxiv.org/pdf/2506.04421, 2025-06-04
2025-11-11 01:10:41,834 - INFO - root - Page:2, Index:49, Visualizing and Controlling Cortical Responses Using Voxel-Weighted Activation Maximization, https://arxiv.org/pdf/2506.04379, 2025-06-04
2025-11-11 01:10:41,834 - INFO - root - Fetching page 4 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=150
2025-11-11 01:10:48,226 - INFO - root - get_all_titles_from_web 
2025-11-11 01:10:48,226 - INFO - root - Page:3, Index:0, FlexGS: Train Once, Deploy Everywhere with Many-in-One Flexible 3D Gaussian Splatting, https://arxiv.org/pdf/2506.04174, 2025-06-04
2025-11-11 01:10:48,226 - INFO - root - Page:3, Index:1, Multi-view Surface Reconstruction Using Normal and Reflectance Cues, https://arxiv.org/pdf/2506.04115, 2025-06-04
2025-11-11 01:10:48,226 - INFO - root - Page:3, Index:2, Vocabulary-free few-shot learning for Vision-Language Models, https://arxiv.org/pdf/2506.04005, 2025-06-04
2025-11-11 01:10:48,228 - INFO - root - Page:3, Index:3, Learning from Noise: Enhancing DNNs for Event-Based Vision through Controlled Noise Injection, https://arxiv.org/pdf/2506.03918, 2025-06-04
2025-11-11 01:10:48,228 - INFO - root - Page:3, Index:4, Video, How Do Your Tokens Merge?, https://arxiv.org/pdf/2506.03885, 2025-06-04
2025-11-11 01:10:48,228 - INFO - root - Page:3, Index:5, OSGNet @ Ego4D Episodic Memory Challenge 2025, https://arxiv.org/pdf/2506.03710, 2025-06-04
2025-11-11 01:10:48,228 - INFO - root - Page:3, Index:6, AetherVision-Bench: An Open-Vocabulary RGB-Infrared Benchmark for Multi-Angle Segmentation across Aerial and Ground Perspectives, https://arxiv.org/pdf/2506.03709, 2025-06-04
2025-11-11 01:10:48,229 - INFO - root - Page:3, Index:7, OV-COAST: Cost Aggregation with Optimal Transport for Open-Vocabulary Semantic Segmentation, https://arxiv.org/pdf/2506.03706, 2025-06-04
2025-11-11 01:10:48,229 - INFO - root - Page:3, Index:8, Generating 6DoF Object Manipulation Trajectories from Action Description in Egocentric Vision, https://arxiv.org/pdf/2506.03605, 2025-06-04
2025-11-11 01:10:48,229 - INFO - root - Page:3, Index:9, SemNav: A Model-Based Planner for Zero-Shot Object Goal Navigation Using Vision-Foundation Models, https://arxiv.org/pdf/2506.03516, 2025-06-03
2025-11-11 01:10:48,230 - INFO - root - Page:3, Index:10, Heterogeneous Skeleton-Based Action Representation Learning, https://arxiv.org/pdf/2506.03481, 2025-06-03
2025-11-11 01:10:48,230 - INFO - root - Page:3, Index:11, Hybrid Ensemble of Segmentation-Assisted Classification and GBDT for Skin Cancer Detection with Engineered Metadata and Synthetic Lesions from ISIC 2024 Non-Dermoscopic 3D-TBP Images, https://arxiv.org/pdf/2506.03420, 2025-06-03
2025-11-11 01:10:48,230 - INFO - root - Page:3, Index:12, Self-Supervised Spatial Correspondence Across Modalities, https://arxiv.org/pdf/2506.03148, 2025-06-03
2025-11-11 01:10:48,230 - INFO - root - Page:3, Index:13, Dense Match Summarization for Faster Two-view Estimation, https://arxiv.org/pdf/2506.02893, 2025-06-03
2025-11-11 01:10:48,231 - INFO - root - Page:3, Index:14, NTIRE 2025 XGC Quality Assessment Challenge: Methods and Results, https://arxiv.org/pdf/2506.02875, 2025-06-03
2025-11-11 01:10:48,231 - INFO - root - Page:3, Index:15, FreeScene: Mixed Graph Diffusion for 3D Scene Synthesis from Free Prompts, https://arxiv.org/pdf/2506.02781, 2025-06-03
2025-11-11 01:10:48,231 - INFO - root - Page:3, Index:16, Technical Report for Ego4D Long-Term Action Anticipation Challenge 2025, https://arxiv.org/pdf/2506.02550, 2025-06-11
2025-11-11 01:10:48,231 - INFO - root - Page:3, Index:17, Probabilistic Online Event Downsampling, https://arxiv.org/pdf/2506.02547, 2025-09-23
2025-11-11 01:10:48,232 - INFO - root - Page:3, Index:18, Towards In-the-wild 3D Plane Reconstruction from a Single Image, https://arxiv.org/pdf/2506.02493, 2025-06-03
2025-11-11 01:10:48,232 - INFO - root - Page:3, Index:19, Efficient Test-time Adaptive Object Detection via Sensitivity-Guided Pruning, https://arxiv.org/pdf/2506.02462, 2025-06-03
2025-11-11 01:10:48,232 - INFO - root - Page:3, Index:20, EgoVIS@CVPR: PAIR-Net: Enhancing Egocentric Speaker Detection via Pretrained Audio-Visual Fusion and Alignment Loss, https://arxiv.org/pdf/2506.02247, 2025-09-26
2025-11-11 01:10:48,233 - INFO - root - Page:3, Index:21, Diff2Flow: Training Flow Matching Models via Diffusion Model Alignment, https://arxiv.org/pdf/2506.02221, 2025-06-02
2025-11-11 01:10:48,233 - INFO - root - Page:3, Index:22, NTIRE 2025 Challenge on RAW Image Restoration and Super-Resolution, https://arxiv.org/pdf/2506.02197, 2025-06-04
2025-11-11 01:10:48,233 - INFO - root - Page:3, Index:23, RAW Image Reconstruction from RGB on Smartphones. NTIRE 2025 Challenge Report, https://arxiv.org/pdf/2506.01947, 2025-06-02
2025-11-11 01:10:48,234 - INFO - root - Page:3, Index:24, Silence is Golden: Leveraging Adversarial Examples to Nullify Audio Control in LDM-based Talking-Head Generation, https://arxiv.org/pdf/2506.01591, 2025-06-02
2025-11-11 01:10:48,234 - INFO - root - Page:3, Index:25, SAM2-LOVE: Segment Anything Model 2 in Language-aided Audio-Visual Scenes, https://arxiv.org/pdf/2506.01558, 2025-06-02
2025-11-11 01:10:48,235 - INFO - root - Page:3, Index:26, Neural shape reconstruction from multiple views with static pattern projection, https://arxiv.org/pdf/2506.01389, 2025-06-02
2025-11-11 01:10:48,235 - INFO - root - Page:3, Index:27, SAM-I2V: Upgrading SAM to Support Promptable Video Segmentation with Less than 0.2% Training Cost, https://arxiv.org/pdf/2506.01304, 2025-06-02
2025-11-11 01:10:48,235 - INFO - root - Page:3, Index:28, Perceptual Inductive Bias Is What You Need Before Contrastive Learning, https://arxiv.org/pdf/2506.01201, 2025-06-01
2025-11-11 01:10:48,236 - INFO - root - Page:3, Index:29, Test Automation for Interactive Scenarios via Promptable Traffic Simulation, https://arxiv.org/pdf/2506.01199, 2025-06-04
2025-11-11 01:10:48,236 - INFO - root - Page:3, Index:30, GraphPad: Inference-Time 3D Scene Graph Updates for Embodied Question Answering, https://arxiv.org/pdf/2506.01174, 2025-06-01
2025-11-11 01:10:48,236 - INFO - root - Page:3, Index:31, Aligned Contrastive Loss for Long-Tailed Recognition, https://arxiv.org/pdf/2506.01071, 2025-06-01
2025-11-11 01:10:48,237 - INFO - root - Page:3, Index:32, Self-supervised ControlNet with Spatio-Temporal Mamba for Real-world Video Super-resolution, https://arxiv.org/pdf/2506.01037, 2025-06-01
2025-11-11 01:10:48,237 - INFO - root - Page:3, Index:33, ArtiScene: Language-Driven Artistic 3D Scene Generation Through Image Intermediary, https://arxiv.org/pdf/2506.00742, 2025-05-31
2025-11-11 01:10:48,237 - INFO - root - Page:3, Index:34, 3D Gaussian Splat Vulnerabilities, https://arxiv.org/pdf/2506.00280, 2025-05-30
2025-11-11 01:10:48,238 - INFO - root - Page:3, Index:35, EgoVIS@CVPR: What Changed and What Could Have Changed? State-Change Counterfactuals for Procedure-Aware Video Representation Learning, https://arxiv.org/pdf/2506.00101, 2025-09-26
2025-11-11 01:10:48,240 - INFO - root - Page:3, Index:36, CL-LoRA: Continual Low-Rank Adaptation for Rehearsal-Free Class-Incremental Learning, https://arxiv.org/pdf/2505.24816, 2025-05-30
2025-11-11 01:10:48,241 - INFO - root - Page:3, Index:37, PatchDEMUX: A Certifiably Robust Framework for Multi-label Classifiers Against Adversarial Patches, https://arxiv.org/pdf/2505.24703, 2025-05-30
2025-11-11 01:10:48,242 - INFO - root - Page:3, Index:38, Conformal Prediction for Zero-Shot Models, https://arxiv.org/pdf/2505.24693, 2025-05-30
2025-11-11 01:10:48,244 - INFO - root - Page:3, Index:39, Learning reusable concepts across different egocentric video understanding tasks, https://arxiv.org/pdf/2505.24690, 2025-05-30
2025-11-11 01:10:48,244 - INFO - root - Page:3, Index:40, Period-LLM: Extending the Periodic Capability of Multimodal Large Language Model, https://arxiv.org/pdf/2505.24476, 2025-05-30
2025-11-11 01:10:48,244 - INFO - root - Page:3, Index:41, PCIE_Interaction Solution for Ego4D Social Interaction Challenge, https://arxiv.org/pdf/2505.24404, 2025-05-30
2025-11-11 01:10:48,244 - INFO - root - Page:3, Index:42, Leadership Assessment in Pediatric Intensive Care Unit Team Training, https://arxiv.org/pdf/2505.24389, 2025-08-28
2025-11-11 01:10:48,245 - INFO - root - Page:3, Index:43, Interpreting Large Text-to-Image Diffusion Models with Dictionary Learning, https://arxiv.org/pdf/2505.24360, 2025-07-10
2025-11-11 01:10:48,245 - INFO - root - Page:3, Index:44, InteractAnything: Zero-shot Human Object Interaction Synthesis via LLM Feedback and Object Affordance Parsing, https://arxiv.org/pdf/2505.24315, 2025-05-30
2025-11-11 01:10:48,245 - INFO - root - Page:3, Index:45, MaskAdapt: Unsupervised Geometry-Aware Domain Adaptation Using Multimodal Contextual Learning and RGB-Depth Masking, https://arxiv.org/pdf/2505.24026, 2025-05-29
2025-11-11 01:10:48,246 - INFO - root - Page:3, Index:46, Argus: Vision-Centric Reasoning with Grounded Chain-of-Thought, https://arxiv.org/pdf/2505.23766, 2025-05-29
2025-11-11 01:10:48,246 - INFO - root - Page:3, Index:47, Sketch Down the FLOPs: Towards Efficient Networks for Human Sketch, https://arxiv.org/pdf/2505.23763, 2025-05-29
2025-11-11 01:10:48,246 - INFO - root - Page:3, Index:48, Boosting Domain Incremental Learning: Selecting the Optimal Parameters is All You Need, https://arxiv.org/pdf/2505.23744, 2025-05-29
2025-11-11 01:10:48,246 - INFO - root - Page:3, Index:49, DA-VPT: Semantic-Guided Visual Prompt Tuning for Vision Transformers, https://arxiv.org/pdf/2505.23694, 2025-06-01
2025-11-11 01:10:48,246 - INFO - root - Fetching page 5 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=200
2025-11-11 01:10:54,742 - INFO - root - get_all_titles_from_web 
2025-11-11 01:10:54,742 - INFO - root - Page:4, Index:0, Bridging Classical and Modern Computer Vision: PerceptiveNet for Tree Crown Semantic Segmentation, https://arxiv.org/pdf/2505.23597, 2025-05-29
2025-11-11 01:10:54,744 - INFO - root - Page:4, Index:1, Synthetic Generation and Latent Projection Denoising of Rim Lesions in Multiple Sclerosis, https://arxiv.org/pdf/2505.23353, 2025-05-29
2025-11-11 01:10:54,744 - INFO - root - Page:4, Index:2, Wav2Sem: Plug-and-Play Audio Semantic Decoupling for 3D Speech-Driven Facial Animation, https://arxiv.org/pdf/2505.23290, 2025-05-29
2025-11-11 01:10:54,744 - INFO - root - Page:4, Index:3, Proximal Algorithm Unrolling: Flexible and Efficient Reconstruction Networks for Single-Pixel Imaging, https://arxiv.org/pdf/2505.23180, 2025-05-29
2025-11-11 01:10:54,745 - INFO - root - Page:4, Index:4, HMAD: Advancing E2E Driving with Anchored Offset Proposals and Simulation-Supervised Multi-target Scoring, https://arxiv.org/pdf/2505.23129, 2025-05-29
2025-11-11 01:10:54,745 - INFO - root - Page:4, Index:5, URWKV: Unified RWKV Model with Multi-state Perspective for Low-light Image Restoration, https://arxiv.org/pdf/2505.23068, 2025-05-29
2025-11-11 01:10:54,745 - INFO - root - Page:4, Index:6, 4DTAM: Non-Rigid Tracking and Mapping via Dynamic Surface Gaussians, https://arxiv.org/pdf/2505.22859, 2025-05-28
2025-11-11 01:10:54,745 - INFO - root - Page:4, Index:7, A Probabilistic Jump-Diffusion Framework for Open-World Egocentric Activity Recognition, https://arxiv.org/pdf/2505.22858, 2025-05-28
2025-11-11 01:10:54,746 - INFO - root - Page:4, Index:8, PS4PRO: Pixel-to-pixel Supervision for Photorealistic Rendering and Optimization, https://arxiv.org/pdf/2505.22616, 2025-05-28
2025-11-11 01:10:54,746 - INFO - root - Page:4, Index:9, Universal Domain Adaptation for Semantic Segmentation, https://arxiv.org/pdf/2505.22458, 2025-06-05
2025-11-11 01:10:54,746 - INFO - root - Page:4, Index:10, Zero-Shot 3D Visual Grounding from Vision-Language Models, https://arxiv.org/pdf/2505.22429, 2025-05-28
2025-11-11 01:10:54,746 - INFO - root - Page:4, Index:11, RC-AutoCalib: An End-to-End Radar-Camera Automatic Calibration Network, https://arxiv.org/pdf/2505.22427, 2025-05-28
2025-11-11 01:10:54,747 - INFO - root - Page:4, Index:12, Bringing CLIP to the Clinic: Dynamic Soft Labels and Negation-Aware Learning for Medical Analysis, https://arxiv.org/pdf/2505.22079, 2025-05-28
2025-11-11 01:10:54,747 - INFO - root - Page:4, Index:13, Point-to-Region Loss for Semi-Supervised Point-Based Crowd Counting, https://arxiv.org/pdf/2505.21943, 2025-05-27
2025-11-11 01:10:54,747 - INFO - root - Page:4, Index:14, FRAMES-VQA: Benchmarking Fine-Tuning Robustness across Multi-Modal Shifts in Visual Question Answering, https://arxiv.org/pdf/2505.21755, 2025-06-20
2025-11-11 01:10:54,747 - INFO - root - Page:4, Index:15, Knowledge Distillation Approach for SOS Fusion Staging: Towards Fully Automated Skeletal Maturity Assessment, https://arxiv.org/pdf/2505.21561, 2025-05-26
2025-11-11 01:10:54,747 - INFO - root - Page:4, Index:16, Enhancing Vision Transformer Explainability Using Artificial Astrocytes, https://arxiv.org/pdf/2505.21513, 2025-05-20
2025-11-11 01:10:54,748 - INFO - root - Page:4, Index:17, Empowering Vector Graphics with Consistently Arbitrary Viewing and View-dependent Visibility, https://arxiv.org/pdf/2505.21377, 2025-05-27
2025-11-11 01:10:54,748 - INFO - root - Page:4, Index:18, Structure from Collision, https://arxiv.org/pdf/2505.21335, 2025-05-27
2025-11-11 01:10:54,750 - INFO - root - Page:4, Index:19, Boosting Adversarial Transferability via High-Frequency Augmentation and Hierarchical-Gradient Fusion, https://arxiv.org/pdf/2505.21181, 2025-05-27
2025-11-11 01:10:54,750 - INFO - root - Page:4, Index:20, RefAV: Towards Planning-Centric Scenario Mining, https://arxiv.org/pdf/2505.20981, 2025-06-18
2025-11-11 01:10:54,751 - INFO - root - Page:4, Index:21, PMA: Towards Parameter-Efficient Point Cloud Understanding via Point Mamba Adapter, https://arxiv.org/pdf/2505.20941, 2025-05-27
2025-11-11 01:10:54,751 - INFO - root - Page:4, Index:22, HuMoCon: Concept Discovery for Human Motion Understanding, https://arxiv.org/pdf/2505.20920, 2025-05-27
2025-11-11 01:10:54,752 - INFO - root - Page:4, Index:23, Exploring Timeline Control for Facial Motion Generation, https://arxiv.org/pdf/2505.20861, 2025-05-27
2025-11-11 01:10:54,752 - INFO - root - Page:4, Index:24, ConText-CIR: Learning from Concepts in Text for Composed Image Retrieval, https://arxiv.org/pdf/2505.20764, 2025-05-27
2025-11-11 01:10:54,754 - INFO - root - Page:4, Index:25, HCQA-1.5 @ Ego4D EgoSchema Challenge 2025, https://arxiv.org/pdf/2505.20644, 2025-05-26
2025-11-11 01:10:54,757 - INFO - root - Page:4, Index:26, Roboflow100-VL: A Multi-Domain Object Detection Benchmark for Vision-Language Models, https://arxiv.org/pdf/2505.20612, 2025-10-22
2025-11-11 01:10:54,757 - INFO - root - Page:4, Index:27, MotionPro: A Precise Motion Controller for Image-to-Video Generation, https://arxiv.org/pdf/2505.20287, 2025-05-26
2025-11-11 01:10:54,757 - INFO - root - Page:4, Index:28, Category-Agnostic Neural Object Rigging, https://arxiv.org/pdf/2505.20283, 2025-05-26
2025-11-11 01:10:54,759 - INFO - root - Page:4, Index:29, Towards Video to Piano Music Generation with Chain-of-Perform Support Benchmarks, https://arxiv.org/pdf/2505.20038, 2025-05-26
2025-11-11 01:10:54,760 - INFO - root - Page:4, Index:30, Can Visual Encoder Learn to See Arrows?, https://arxiv.org/pdf/2505.19944, 2025-05-26
2025-11-11 01:10:54,761 - INFO - root - Page:4, Index:31, GoLF-NRT: Integrating Global Context and Local Geometry for Few-Shot View Synthesis, https://arxiv.org/pdf/2505.19813, 2025-05-26
2025-11-11 01:10:54,761 - INFO - root - Page:4, Index:32, Depth-Guided Bundle Sampling for Efficient Generalizable Neural Radiance Field Reconstruction, https://arxiv.org/pdf/2505.19793, 2025-05-26
2025-11-11 01:10:54,762 - INFO - root - Page:4, Index:33, SuperAD: A Training-free Anomaly Classification and Segmentation Method for CVPR 2025 VAND 3.0 Workshop Challenge Track 1: Adapt & Detect, https://arxiv.org/pdf/2505.19750, 2025-05-27
2025-11-11 01:10:54,764 - INFO - root - Page:4, Index:34, Knowledge-Aligned Counterfactual-Enhancement Diffusion Perception for Unsupervised Cross-Domain Visual Emotion Recognition, https://arxiv.org/pdf/2505.19694, 2025-05-26
2025-11-11 01:10:54,764 - INFO - root - Page:4, Index:35, Rotation-Equivariant Self-Supervised Method in Image Denoising, https://arxiv.org/pdf/2505.19618, 2025-05-26
2025-11-11 01:10:54,765 - INFO - root - Page:4, Index:36, NTIRE 2025 Challenge on Video Quality Enhancement for Video Conferencing: Datasets, Methods and Results, https://arxiv.org/pdf/2505.18988, 2025-05-25
2025-11-11 01:10:54,765 - INFO - root - Page:4, Index:37, Geometry-guided Online 3D Video Synthesis with Multi-View Temporal Consistency, https://arxiv.org/pdf/2505.18932, 2025-05-24
2025-11-11 01:10:54,766 - INFO - root - Page:4, Index:38, Digital Overconsumption and Waste: A Closer Look at the Impacts of Generative AI, https://arxiv.org/pdf/2505.18894, 2025-05-24
2025-11-11 01:10:54,766 - INFO - root - Page:4, Index:39, VISTA: Vision-Language Inference for Training-Free Stock Time-Series Analysis, https://arxiv.org/pdf/2505.18570, 2025-06-11
2025-11-11 01:10:54,766 - INFO - root - Page:4, Index:40, Syn3DTxt: Embedding 3D Cues for Scene Text Generation, https://arxiv.org/pdf/2505.18479, 2025-05-23
2025-11-11 01:10:54,766 - INFO - root - Page:4, Index:41, CTRL-GS: Cascaded Temporal Residue Learning for 4D Gaussian Splatting, https://arxiv.org/pdf/2505.18306, 2025-05-31
2025-11-11 01:10:54,767 - INFO - root - Page:4, Index:42, DualTalk: Dual-Speaker Interaction for 3D Talking Head Conversations, https://arxiv.org/pdf/2505.18096, 2025-05-26
2025-11-11 01:10:54,767 - INFO - root - Page:4, Index:43, SeaLion: Semantic Part-Aware Latent Point Diffusion Models for 3D Generation, https://arxiv.org/pdf/2505.17721, 2025-07-07
2025-11-11 01:10:54,767 - INFO - root - Page:4, Index:44, PoseBH: Prototypical Multi-Dataset Training Beyond Human Pose Estimation, https://arxiv.org/pdf/2505.17475, 2025-05-23
2025-11-11 01:10:54,767 - INFO - root - Page:4, Index:45, Pursuing Temporal-Consistent Video Virtual Try-On via Dynamic Pose Interaction, https://arxiv.org/pdf/2505.16980, 2025-05-22
2025-11-11 01:10:54,768 - INFO - root - Page:4, Index:46, UniPhy: Learning a Unified Constitutive Model for Inverse Physics Simulation, https://arxiv.org/pdf/2505.16971, 2025-05-22
2025-11-11 01:10:54,768 - INFO - root - Page:4, Index:47, Tracking the Flight: Exploring a Computational Framework for Analyzing Escape Responses in Plains Zebra (Equus quagga), https://arxiv.org/pdf/2505.16882, 2025-05-23
2025-11-11 01:10:54,769 - INFO - root - Page:4, Index:48, Semi-Supervised State-Space Model with Dynamic Stacking Filter for Real-World Video Deraining, https://arxiv.org/pdf/2505.16811, 2025-05-22
2025-11-11 01:10:54,769 - INFO - root - Page:4, Index:49, SOLVE: Synergy of Language-Vision and End-to-End Networks for Autonomous Driving, https://arxiv.org/pdf/2505.16805, 2025-05-22
2025-11-11 01:10:54,771 - INFO - root - Fetching page 6 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=250
2025-11-11 01:11:02,085 - INFO - root - get_all_titles_from_web 
2025-11-11 01:11:02,086 - INFO - root - Page:5, Index:0, Four Eyes Are Better Than Two: Harnessing the Collaborative Potential of Large Models via Differentiated Thinking and Complementary Ensembles, https://arxiv.org/pdf/2505.16784, 2025-06-07
2025-11-11 01:11:02,086 - INFO - root - Page:5, Index:1, Single Domain Generalization for Few-Shot Counting via Universal Representation Matching, https://arxiv.org/pdf/2505.16778, 2025-05-22
2025-11-11 01:11:02,086 - INFO - root - Page:5, Index:2, Seeing Far and Clearly: Mitigating Hallucinations in MLLMs with Attention Causal Decoding, https://arxiv.org/pdf/2505.16652, 2025-06-07
2025-11-11 01:11:02,086 - INFO - root - Page:5, Index:3, Sketchy Bounding-box Supervision for 3D Instance Segmentation, https://arxiv.org/pdf/2505.16399, 2025-05-22
2025-11-11 01:11:02,087 - INFO - root - Page:5, Index:4, DeCafNet: Delegate and Conquer for Efficient Temporal Grounding in Long Videos, https://arxiv.org/pdf/2505.16376, 2025-05-22
2025-11-11 01:11:02,087 - INFO - root - Page:5, Index:5, NTIRE 2025 challenge on Text to Image Generation Model Quality Assessment, https://arxiv.org/pdf/2505.16314, 2025-05-22
2025-11-11 01:11:02,088 - INFO - root - Page:5, Index:6, Analyzing Hierarchical Structure in Vision Models with Sparse Autoencoders, https://arxiv.org/pdf/2505.15970, 2025-05-21
2025-11-11 01:11:02,088 - INFO - root - Page:5, Index:7, Efficient Data Driven Mixture-of-Expert Extraction from Trained Networks, https://arxiv.org/pdf/2505.15414, 2025-05-21
2025-11-11 01:11:02,088 - INFO - root - Page:5, Index:8, Mouse Lockbox Dataset: Behavior Recognition for Mice Solving Lockboxes, https://arxiv.org/pdf/2505.15408, 2025-06-17
2025-11-11 01:11:02,088 - INFO - root - Page:5, Index:9, Zero-Shot Gaze-based Volumetric Medical Image Segmentation, https://arxiv.org/pdf/2505.15256, 2025-06-10
2025-11-11 01:11:02,090 - INFO - root - Page:5, Index:10, Dual Precision Quantization for Efficient and Accurate Deep Neural Networks Inference, https://arxiv.org/pdf/2505.14638, 2025-05-20
2025-11-11 01:11:02,090 - INFO - root - Page:5, Index:11, Neural Video Compression with Context Modulation, https://arxiv.org/pdf/2505.14541, 2025-05-20
2025-11-11 01:11:02,090 - INFO - root - Page:5, Index:12, Selective Structured State Space for Multispectral-fused Small Target Detection, https://arxiv.org/pdf/2505.14043, 2025-05-23
2025-11-11 01:11:02,090 - INFO - root - Page:5, Index:13, OmniStyle: Filtering High Quality Style Transfer Data at Scale, https://arxiv.org/pdf/2505.14028, 2025-05-20
2025-11-11 01:11:02,091 - INFO - root - Page:5, Index:14, Domain Adaptation of VLM for Soccer Video Understanding, https://arxiv.org/pdf/2505.13860, 2025-07-07
2025-11-11 01:11:02,091 - INFO - root - Page:5, Index:15, Ground-V: Teaching VLMs to Ground Complex Instructions in Pixels, https://arxiv.org/pdf/2505.13788, 2025-05-19
2025-11-11 01:11:02,091 - INFO - root - Page:5, Index:16, FinePhys: Fine-grained Human Action Generation by Explicitly Incorporating Physical Laws for Effective Skeletal Guidance, https://arxiv.org/pdf/2505.13437, 2025-05-19
2025-11-11 01:11:02,092 - INFO - root - Page:5, Index:17, The Way Up: A Dataset for Hold Usage Detection in Sport Climbing, https://arxiv.org/pdf/2505.12854, 2025-05-19
2025-11-11 01:11:02,092 - INFO - root - Page:5, Index:18, PEER pressure: Model-to-Model Regularization for Single Source Domain Generalization, https://arxiv.org/pdf/2505.12745, 2025-05-19
2025-11-11 01:11:02,092 - INFO - root - Page:5, Index:19, Mamba-Adaptor: State Space Model Adaptor for Visual Recognition, https://arxiv.org/pdf/2505.12685, 2025-05-19
2025-11-11 01:11:02,092 - INFO - root - Page:5, Index:20, Scalable Video-to-Dataset Generation for Cross-Platform Mobile Agents, https://arxiv.org/pdf/2505.12632, 2025-05-18
2025-11-11 01:11:02,092 - INFO - root - Page:5, Index:21, Degradation-Aware Feature Perturbation for All-in-One Image Restoration, https://arxiv.org/pdf/2505.12630, 2025-05-18
2025-11-11 01:11:02,094 - INFO - root - Page:5, Index:22, Guiding Diffusion with Deep Geometric Moments: Balancing Fidelity and Variation, https://arxiv.org/pdf/2505.12486, 2025-05-18
2025-11-11 01:11:02,094 - INFO - root - Page:5, Index:23, Learning to Highlight Audio by Watching Movies, https://arxiv.org/pdf/2505.12154, 2025-05-17
2025-11-11 01:11:02,094 - INFO - root - Page:5, Index:24, Understanding the Capabilities of Molecular Graph Neural Networks in Materials Science Through Multimodal Learning and Physical Context Encoding, https://arxiv.org/pdf/2505.12137, 2025-05-17
2025-11-11 01:11:02,095 - INFO - root - Page:5, Index:25, iSegMan: Interactive Segment-and-Manipulate 3D Gaussians, https://arxiv.org/pdf/2505.11934, 2025-05-17
2025-11-11 01:11:02,095 - INFO - root - Page:5, Index:26, Self-Learning Hyperspectral and Multispectral Image Fusion via Adaptive Residual Guided Subspace Diffusion Model, https://arxiv.org/pdf/2505.11800, 2025-05-16
2025-11-11 01:11:02,096 - INFO - root - Page:5, Index:27, X-Edit: Detecting and Localizing Edits in Images Altered by Text-Guided Diffusion Models, https://arxiv.org/pdf/2505.11753, 2025-05-16
2025-11-11 01:11:02,096 - INFO - root - Page:5, Index:28, MTevent: A Multi-Task Event Camera Dataset for 6D Pose Estimation and Moving Object Detection, https://arxiv.org/pdf/2505.11282, 2025-06-02
2025-11-11 01:11:02,096 - INFO - root - Page:5, Index:29, Imputation-free and Alignment-free: Incomplete Multi-view Clustering Driven by Consensus Semantic Learning, https://arxiv.org/pdf/2505.11182, 2025-05-16
2025-11-11 01:11:02,098 - INFO - root - Page:5, Index:30, MultiLink: Multi-class Structure Recovery via Agglomerative Clustering and Model Selection, https://arxiv.org/pdf/2505.10874, 2025-05-16
2025-11-11 01:11:02,101 - INFO - root - Page:5, Index:31, RefPose: Leveraging Reference Geometric Correspondences for Accurate 6D Pose Estimation of Unseen Objects, https://arxiv.org/pdf/2505.10841, 2025-05-16
2025-11-11 01:11:02,104 - INFO - root - Page:5, Index:32, MoCLIP: Motion-Aware Fine-Tuning and Distillation of CLIP for Human Motion Generation, https://arxiv.org/pdf/2505.10810, 2025-05-15
2025-11-11 01:11:02,104 - INFO - root - Page:5, Index:33, Automated Detection of Salvin's Albatrosses: Improving Deep Learning Tools for Aerial Wildlife Surveys, https://arxiv.org/pdf/2505.10737, 2025-05-15
2025-11-11 01:11:02,106 - INFO - root - Page:5, Index:34, Advancing Multiple Instance Learning with Continual Learning for Whole Slide Imaging, https://arxiv.org/pdf/2505.10649, 2025-05-15
2025-11-11 01:11:02,106 - INFO - root - Page:5, Index:35, Inferring Driving Maps by Deep Learning-based Trail Map Extraction, https://arxiv.org/pdf/2505.10258, 2025-05-15
2025-11-11 01:11:02,106 - INFO - root - Page:5, Index:36, Behind Maya: Building a Multilingual Vision Language Model, https://arxiv.org/pdf/2505.08910, 2025-05-15
2025-11-11 01:11:02,107 - INFO - root - Page:5, Index:37, PosterO: Structuring Layout Trees to Enable Language Models in Generalized Content-Aware Layout Generation, https://arxiv.org/pdf/2505.07843, 2025-05-26
2025-11-11 01:11:02,107 - INFO - root - Page:5, Index:38, Prototype Augmented Hypernetworks for Continual Learning, https://arxiv.org/pdf/2505.07450, 2025-05-16
2025-11-11 01:11:02,107 - INFO - root - Fetching page 7 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=300
2025-11-11 01:11:08,917 - INFO - root - get_all_titles_from_web 
2025-11-11 01:11:08,917 - INFO - root - Page:6, Index:0, Convex Relaxation for Robust Vanishing Point Estimation in Manhattan World, https://arxiv.org/pdf/2505.04788, 2025-06-05
2025-11-11 01:11:08,918 - INFO - root - Page:6, Index:1, S3D: Sketch-Driven 3D Model Generation, https://arxiv.org/pdf/2505.04185, 2025-06-03
2025-11-11 01:11:08,918 - INFO - root - Page:6, Index:2, Generating Synthetic Data via Augmentations for Improved Facial Resemblance in DreamBooth and InstantID, https://arxiv.org/pdf/2505.03557, 2025-07-17
2025-11-11 01:11:08,918 - INFO - root - Page:6, Index:3, CAV-MAE Sync: Improving Contrastive Audio-Visual Mask Autoencoders via Fine-Grained Alignment, https://arxiv.org/pdf/2505.01237, 2025-05-21
2025-11-11 01:11:08,919 - INFO - root - Fetching page 8 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=350
2025-11-11 01:11:15,576 - INFO - root - get_all_titles_from_web 
2025-11-11 01:11:15,577 - INFO - root - Page:7, Index:0, Where's the liability in the Generative Era? Recovery-based Black-Box Detection of AI-Generated Content, https://arxiv.org/pdf/2505.01008, 2025-08-25
2025-11-11 01:11:15,577 - INFO - root - Page:7, Index:1, SpatialLLM: A Compound 3D-Informed Design towards Spatially-Intelligent Large Multimodal Models, https://arxiv.org/pdf/2505.00788, 2025-06-10
2025-11-11 01:11:15,580 - INFO - root - Page:7, Index:2, Prisma: An Open Source Toolkit for Mechanistic Interpretability in Vision and Video, https://arxiv.org/pdf/2504.19475, 2025-06-03
2025-11-11 01:11:15,580 - INFO - root - Page:7, Index:3, SSL4Eco: A Global Seasonal Dataset for Geospatial Foundation Models in Ecology, https://arxiv.org/pdf/2504.18256, 2025-10-20
2025-11-11 01:11:15,581 - INFO - root - Page:7, Index:4, Vision-Language Models Are Not Pragmatically Competent in Referring Expression Generation, https://arxiv.org/pdf/2504.16060, 2025-07-30
2025-11-11 01:11:15,582 - INFO - root - Fetching page 9 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=400
2025-11-11 01:11:21,875 - INFO - root - get_all_titles_from_web 
2025-11-11 01:11:21,875 - INFO - root - Page:8, Index:0, Leveraging Automatic CAD Annotations for Supervised Learning in 3D Scene Understanding, https://arxiv.org/pdf/2504.13580, 2025-05-16
2025-11-11 01:11:21,876 - INFO - root - Page:8, Index:1, CAP-Net: A Unified Network for 6D Pose and Size Estimation of Categorical Articulated Parts from a Single RGB-D Image, https://arxiv.org/pdf/2504.11230, 2025-06-02
2025-11-11 01:11:21,876 - INFO - root - Page:8, Index:2, Video Summarization with Large Language Models, https://arxiv.org/pdf/2504.11199, 2025-06-05
2025-11-11 01:11:21,876 - INFO - root - Page:8, Index:3, R-TPT: Improving Adversarial Robustness of Vision-Language Models through Test-Time Prompt Tuning, https://arxiv.org/pdf/2504.11195, 2025-08-27
2025-11-11 01:11:21,876 - INFO - root - Page:8, Index:4, TerraMesh: A Planetary Mosaic of Multimodal Earth Observation Data, https://arxiv.org/pdf/2504.11172, 2025-08-01
2025-11-11 01:11:21,877 - INFO - root - Page:8, Index:5, Seeing like a Cephalopod: Colour Vision with a Monochrome Event Camera, https://arxiv.org/pdf/2504.10984, 2025-06-06
2025-11-11 01:11:21,877 - INFO - root - Page:8, Index:6, Hearing Anywhere in Any Environment, https://arxiv.org/pdf/2504.10746, 2025-06-04
2025-11-11 01:11:21,877 - INFO - root - Fetching page 10 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=450
2025-11-11 01:11:28,785 - INFO - root - get_all_titles_from_web 
2025-11-11 01:11:28,785 - INFO - root - Page:9, Index:0, Correlative and Discriminative Label Grouping for Multi-Label Visual Prompt Tuning, https://arxiv.org/pdf/2504.09990, 2025-07-09
2025-11-11 01:11:28,785 - INFO - root - Page:9, Index:1, SPICE: A Synergistic, Precise, Iterative, and Customizable Image Editing Workflow, https://arxiv.org/pdf/2504.09697, 2025-10-16
2025-11-11 01:11:28,785 - INFO - root - Page:9, Index:2, Mimic In-Context Learning for Multimodal Tasks, https://arxiv.org/pdf/2504.08851, 2025-05-17
2025-11-11 01:11:28,786 - INFO - root - Page:9, Index:3, Digital Twin Catalog: A Large-Scale Photorealistic 3D Object Digital Twin Dataset, https://arxiv.org/pdf/2504.08541, 2025-05-18
2025-11-11 01:11:28,786 - INFO - root - Page:9, Index:4, MMLA: Multi-Environment, Multi-Species, Low-Altitude Drone Dataset, https://arxiv.org/pdf/2504.07744, 2025-10-22
2025-11-11 01:11:28,786 - INFO - root - Fetching page 11 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=500
2025-11-11 01:11:35,559 - INFO - root - get_all_titles_from_web 
2025-11-11 01:11:35,559 - INFO - root - Page:10, Index:0, PromptHMR: Promptable Human Mesh Recovery, https://arxiv.org/pdf/2504.06397, 2025-05-23
2025-11-11 01:11:35,560 - INFO - root - Page:10, Index:1, SCAM: A Real-World Typographic Robustness Evaluation for Multimodal Foundation Models, https://arxiv.org/pdf/2504.04893, 2025-09-26
2025-11-11 01:11:35,560 - INFO - root - Fetching page 12 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=550
2025-11-11 01:11:42,367 - INFO - root - get_all_titles_from_web 
2025-11-11 01:11:42,367 - INFO - root - Page:11, Index:0, Charm: The Missing Piece in ViT fine-tuning for Image Aesthetic Assessment, https://arxiv.org/pdf/2504.02522, 2025-05-15
2025-11-11 01:11:42,368 - INFO - root - Page:11, Index:1, T*: Re-thinking Temporal Search for Long-Form Video Understanding, https://arxiv.org/pdf/2504.02259, 2025-08-24
2025-11-11 01:11:42,368 - INFO - root - Page:11, Index:2, CoMatcher: Multi-View Collaborative Feature Matching, https://arxiv.org/pdf/2504.01872, 2025-08-20
2025-11-11 01:11:42,368 - INFO - root - Page:11, Index:3, Think Small, Act Big: Primitive Prompt Learning for Lifelong Robot Manipulation, https://arxiv.org/pdf/2504.00420, 2025-06-01
2025-11-11 01:11:42,369 - INFO - root - Fetching page 13 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=600
2025-11-11 01:11:48,637 - INFO - root - get_all_titles_from_web 
2025-11-11 01:11:48,638 - INFO - root - Page:12, Index:0, It's a (Blind) Match! Towards Vision-Language Correspondence without Parallel Data, https://arxiv.org/pdf/2503.24129, 2025-05-29
2025-11-11 01:11:48,638 - INFO - root - Page:12, Index:1, ReferDINO-Plus: 2nd Solution for 4th PVUW MeViS Challenge at CVPR 2025, https://arxiv.org/pdf/2503.23509, 2025-05-29
2025-11-11 01:11:48,638 - INFO - root - Page:12, Index:2, A Unified Image-Dense Annotation Generation Model for Underwater Scenes, https://arxiv.org/pdf/2503.21771, 2025-07-27
2025-11-11 01:11:48,638 - INFO - root - Fetching page 14 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=650
2025-11-11 01:11:55,657 - INFO - root - get_all_titles_from_web 
2025-11-11 01:11:55,658 - INFO - root - Page:13, Index:0, Learning Class Prototypes for Unified Sparse Supervised 3D Object Detection, https://arxiv.org/pdf/2503.21099, 2025-06-13
2025-11-11 01:11:55,658 - INFO - root - Page:13, Index:1, LATTE-MV: Learning to Anticipate Table Tennis Hits from Monocular Videos, https://arxiv.org/pdf/2503.20936, 2025-09-01
2025-11-11 01:11:55,658 - INFO - root - Page:13, Index:2, BizGen: Advancing Article-level Visual Text Rendering for Infographics Generation, https://arxiv.org/pdf/2503.20672, 2025-07-02
2025-11-11 01:11:55,658 - INFO - root - Page:13, Index:3, ITA-MDT: Image-Timestep-Adaptive Masked Diffusion Transformer Framework for Image-Based Virtual Try-On, https://arxiv.org/pdf/2503.20418, 2025-06-01
2025-11-11 01:11:55,659 - INFO - root - Page:13, Index:4, Faster Parameter-Efficient Tuning with Token Redundancy Reduction, https://arxiv.org/pdf/2503.20282, 2025-08-26
2025-11-11 01:11:55,659 - INFO - root - Page:13, Index:5, DINeMo: Learning Neural Mesh Models with no 3D Annotations, https://arxiv.org/pdf/2503.20220, 2025-06-09
2025-11-11 01:11:55,659 - INFO - root - Page:13, Index:6, Scaling Vision Pre-Training to 4K Resolution, https://arxiv.org/pdf/2503.19903, 2025-08-03
2025-11-11 01:11:55,660 - INFO - root - Page:13, Index:7, GENIUS: A Generative Framework for Universal Multimodal Search, https://arxiv.org/pdf/2503.19868, 2025-06-05
2025-11-11 01:11:55,660 - INFO - root - Fetching page 15 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=700
2025-11-11 01:12:02,084 - INFO - root - get_all_titles_from_web 
2025-11-11 01:12:02,084 - INFO - root - Page:14, Index:0, Galaxy Walker: Geometry-aware VLMs For Galaxy-scale Understanding, https://arxiv.org/pdf/2503.18578, 2025-05-25
2025-11-11 01:12:02,084 - INFO - root - Page:14, Index:1, LookCloser: Frequency-aware Radiance Field for Tiny-Detail Scene, https://arxiv.org/pdf/2503.18513, 2025-07-29
2025-11-11 01:12:02,085 - INFO - root - Fetching page 16 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=750
2025-11-11 01:12:08,341 - INFO - root - get_all_titles_from_web 
2025-11-11 01:12:08,342 - INFO - root - Page:15, Index:0, LoTUS: Large-Scale Machine Unlearning with a Taste of Uncertainty, https://arxiv.org/pdf/2503.18314, 2025-05-29
2025-11-11 01:12:08,342 - INFO - root - Page:15, Index:1, MammAlps: A multi-view video behavior monitoring dataset of wild mammals in the Swiss Alps, https://arxiv.org/pdf/2503.18223, 2025-06-04
2025-11-11 01:12:08,342 - INFO - root - Page:15, Index:2, Progressive Prompt Detailing for Improved Alignment in Text-to-Image Generative Models, https://arxiv.org/pdf/2503.17794, 2025-05-30
2025-11-11 01:12:08,342 - INFO - root - Page:15, Index:3, CountLLM: Towards Generalizable Repetitive Action Counting via Large Language Model, https://arxiv.org/pdf/2503.17690, 2025-06-29
2025-11-11 01:12:08,343 - INFO - root - Page:15, Index:4, TaoAvatar: Real-Time Lifelike Full-Body Talking Avatars for Augmented Reality via 3D Gaussian Splatting, https://arxiv.org/pdf/2503.17032, 2025-07-23
2025-11-11 01:12:08,343 - INFO - root - Page:15, Index:5, Generalized Few-shot 3D Point Cloud Segmentation with Vision-Language Model, https://arxiv.org/pdf/2503.16282, 2025-05-20
2025-11-11 01:12:08,344 - INFO - root - Fetching page 17 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=800
2025-11-11 01:12:15,159 - INFO - root - get_all_titles_from_web 
2025-11-11 01:12:15,161 - INFO - root - Page:16, Index:0, High Temporal Consistency through Semantic Similarity Propagation in Semi-Supervised Video Semantic Segmentation for Autonomous Flight, https://arxiv.org/pdf/2503.15676, 2025-06-26
2025-11-11 01:12:15,161 - INFO - root - Page:16, Index:1, DPFlow: Adaptive Optical Flow Estimation with a Dual-Pyramid Framework, https://arxiv.org/pdf/2503.14880, 2025-09-29
2025-11-11 01:12:15,161 - INFO - root - Fetching page 18 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=850
2025-11-11 01:12:21,840 - INFO - root - get_all_titles_from_web 
2025-11-11 01:12:21,841 - INFO - root - Page:17, Index:0, From Head to Tail: Towards Balanced Representation in Large Vision-Language Models through Adaptive Data Calibration, https://arxiv.org/pdf/2503.12821, 2025-05-29
2025-11-11 01:12:21,841 - INFO - root - Page:17, Index:1, MambaIC: State Space Models for High-Performance Learned Image Compression, https://arxiv.org/pdf/2503.12461, 2025-08-22
2025-11-11 01:12:21,841 - INFO - root - Page:17, Index:2, Localized Concept Erasure for Text-to-Image Diffusion Models Using Training-Free Gated Low-Rank Adaptation, https://arxiv.org/pdf/2503.12356, 2025-07-09
2025-11-11 01:12:21,841 - INFO - root - Page:17, Index:3, TASTE-Rob: Advancing Video Generation of Task-Oriented Hand-Object Interaction for Generalizable Robotic Manipulation, https://arxiv.org/pdf/2503.11423, 2025-06-05
2025-11-11 01:12:21,842 - INFO - root - Page:17, Index:4, Panopticon: Advancing Any-Sensor Foundation Models for Earth Observation, https://arxiv.org/pdf/2503.10845, 2025-08-01
2025-11-11 01:12:21,842 - INFO - root - Page:17, Index:5, Transformers without Normalization, https://arxiv.org/pdf/2503.10622, 2025-06-14
2025-11-11 01:12:21,842 - INFO - root - Page:17, Index:6, dFLMoE: Decentralized Federated Learning via Mixture of Experts for Medical Data Analysis, https://arxiv.org/pdf/2503.10412, 2025-05-19
2025-11-11 01:12:21,842 - INFO - root - Fetching page 19 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=900
2025-11-11 01:12:28,848 - INFO - root - get_all_titles_from_web 
2025-11-11 01:12:28,848 - INFO - root - Page:18, Index:0, Project-Probe-Aggregate: Efficient Fine-Tuning for Group Robustness, https://arxiv.org/pdf/2503.09487, 2025-08-26
2025-11-11 01:12:28,848 - INFO - root - Page:18, Index:1, VLog: Video-Language Models by Generative Retrieval of Narration Vocabulary, https://arxiv.org/pdf/2503.09402, 2025-06-09
2025-11-11 01:12:28,848 - INFO - root - Fetching page 20 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=950
2025-11-11 01:12:35,427 - INFO - root - get_all_titles_from_web 
2025-11-11 01:12:35,429 - INFO - root - Page:19, Index:0, Escaping Plato's Cave: Towards the Alignment of 3D and Text Latent Spaces, https://arxiv.org/pdf/2503.05283, 2025-06-04
2025-11-11 01:12:35,429 - INFO - root - Page:19, Index:1, FluidNexus: 3D Fluid Reconstruction and Prediction from a Single Video, https://arxiv.org/pdf/2503.04720, 2025-07-09
2025-11-11 01:12:35,429 - INFO - root - Page:19, Index:2, Question-Aware Gaussian Experts for Audio-Visual Question Answering, https://arxiv.org/pdf/2503.04459, 2025-06-11
2025-11-11 01:12:35,430 - INFO - root - Page:19, Index:3, Q-Eval-100K: Evaluating Visual Quality and Alignment Level for Text-to-Vision Content, https://arxiv.org/pdf/2503.02357, 2025-06-15
2025-11-11 01:12:35,430 - INFO - root - Fetching page 21 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=1000
2025-11-11 01:12:41,998 - INFO - root - get_all_titles_from_web 
2025-11-11 01:12:41,999 - INFO - root - Page:20, Index:0, Data Distributional Properties As Inductive Bias for Systematic Generalization, https://arxiv.org/pdf/2502.20499, 2025-06-17
2025-11-11 01:12:41,999 - INFO - root - Page:20, Index:1, Knowledge Bridger: Towards Training-free Missing Modality Completion, https://arxiv.org/pdf/2502.19834, 2025-06-17
2025-11-11 01:12:41,999 - INFO - root - Fetching page 22 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=1050
2025-11-11 01:12:48,247 - INFO - root - get_all_titles_from_web 
2025-11-11 01:12:48,247 - INFO - root - Page:21, Index:0, MALT Diffusion: Memory-Augmented Latent Transformers for Any-Length Video Generation, https://arxiv.org/pdf/2502.12632, 2025-07-08
2025-11-11 01:12:48,248 - INFO - root - Page:21, Index:1, ILIAS: Instance-Level Image retrieval At Scale, https://arxiv.org/pdf/2502.11748, 2025-06-23
2025-11-11 01:12:48,248 - INFO - root - Page:21, Index:2, Distraction is All You Need for Multimodal Large Language Model Jailbreaking, https://arxiv.org/pdf/2502.10794, 2025-06-16
2025-11-11 01:12:48,248 - INFO - root - Page:21, Index:3, Spatial457: A Diagnostic Benchmark for 6D Spatial Reasoning of Large Multimodal Models, https://arxiv.org/pdf/2502.08636, 2025-06-08
2025-11-11 01:12:48,248 - INFO - root - Page:21, Index:4, TRAVEL: Training-Free Retrieval and Alignment for Vision-and-Language Navigation, https://arxiv.org/pdf/2502.07306, 2025-06-09
2025-11-11 01:12:48,249 - INFO - root - Page:21, Index:5, DiTASK: Multi-Task Fine-Tuning with Diffeomorphic Transformations, https://arxiv.org/pdf/2502.06029, 2025-06-01
2025-11-11 01:12:48,249 - INFO - root - Page:21, Index:6, ConceptAttention: Diffusion Transformers Learn Highly Interpretable Features, https://arxiv.org/pdf/2502.04320, 2025-07-01
2025-11-11 01:12:48,251 - INFO - root - Page:21, Index:7, GCE-Pose: Global Context Enhancement for Category-level Object Pose Estimation, https://arxiv.org/pdf/2502.04293, 2025-06-24
2025-11-11 01:12:48,251 - INFO - root - Page:21, Index:8, Calibrated Multi-Preference Optimization for Aligning Diffusion Models, https://arxiv.org/pdf/2502.02588, 2025-09-26
2025-11-11 01:12:48,251 - INFO - root - Page:21, Index:9, Instruct-4DGS: Efficient Dynamic Scene Editing via 4D Gaussian-based Static-Dynamic Separation, https://arxiv.org/pdf/2502.02091, 2025-07-01
2025-11-11 01:12:48,252 - INFO - root - Page:21, Index:10, Low-Resource Video Super-Resolution using Memory, Wavelets, and Deformable Convolutions, https://arxiv.org/pdf/2502.01816, 2025-06-19
2025-11-11 01:12:48,252 - INFO - root - Page:21, Index:11, Bridging Text and Crystal Structures: Literature-driven Contrastive Learning for Materials Science, https://arxiv.org/pdf/2501.12919, 2025-06-18
2025-11-11 01:12:48,252 - INFO - root - Page:21, Index:12, T2ISafety: Benchmark for Assessing Fairness, Toxicity, and Privacy in Image Generation, https://arxiv.org/pdf/2501.12612, 2025-07-25
2025-11-11 01:12:48,252 - INFO - root - Page:21, Index:13, Fine-Grained Image-Text Correspondence with Cost Aggregation for Open-Vocabulary Part Segmentation, https://arxiv.org/pdf/2501.09688, 2025-08-08
2025-11-11 01:12:48,252 - INFO - root - Fetching page 23 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=1100
2025-11-11 01:12:54,464 - INFO - root - get_all_titles_from_web 
2025-11-11 01:12:54,464 - INFO - root - Page:22, Index:0, Bias for Action: Video Implicit Neural Representations with Bias Modulation, https://arxiv.org/pdf/2501.09277, 2025-06-06
2025-11-11 01:12:54,465 - INFO - root - Page:22, Index:1, MonSter++: Unified Stereo Matching, Multi-view Stereo, and Real-time Stereo with Monodepth Priors, https://arxiv.org/pdf/2501.08643, 2025-09-25
2025-11-11 01:12:54,466 - INFO - root - Page:22, Index:2, Go-with-the-Flow: Motion-Controllable Video Diffusion Models Using Real-Time Warped Noise, https://arxiv.org/pdf/2501.08331, 2025-08-06
2025-11-11 01:12:54,466 - INFO - root - Page:22, Index:3, Nonisotropic Gaussian Diffusion for Realistic 3D Human Motion Prediction, https://arxiv.org/pdf/2501.06035, 2025-07-08
2025-11-11 01:12:54,466 - INFO - root - Page:22, Index:4, Discovering Hidden Visual Concepts Beyond Linguistic Input in Infant Learning, https://arxiv.org/pdf/2501.05205, 2025-06-13
2025-11-11 01:12:54,467 - INFO - root - Page:22, Index:5, PERSE: Personalized 3D Generative Avatars from A Single Portrait, https://arxiv.org/pdf/2412.21206, 2025-09-28
2025-11-11 01:12:54,467 - INFO - root - Page:22, Index:6, MaskGaussian: Adaptive 3D Gaussian Representation from Probabilistic Masks, https://arxiv.org/pdf/2412.20522, 2025-06-14
2025-11-11 01:12:54,467 - INFO - root - Page:22, Index:7, SimLTD: Simple Supervised and Semi-Supervised Long-Tailed Object Detection, https://arxiv.org/pdf/2412.20047, 2025-06-09
2025-11-11 01:12:54,467 - INFO - root - Page:22, Index:8, Conditional Balance: Improving Multi-Conditioning Trade-Offs in Image Generation, https://arxiv.org/pdf/2412.19853, 2025-08-03
2025-11-11 01:12:54,468 - INFO - root - Fetching page 24 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=1150
2025-11-11 01:13:01,429 - INFO - root - get_all_titles_from_web 
2025-11-11 01:13:01,430 - INFO - root - Page:23, Index:0, CoCoGaussian: Leveraging Circle of Confusion for Gaussian Splatting from Defocused Images, https://arxiv.org/pdf/2412.16028, 2025-05-15
2025-11-11 01:13:01,430 - INFO - root - Page:23, Index:1, EnergyMoGen: Compositional Human Motion Generation with Energy-Based Diffusion Model in Latent Space, https://arxiv.org/pdf/2412.14706, 2025-06-04
2025-11-11 01:13:01,430 - INFO - root - Page:23, Index:2, DarkIR: Robust Low-Light Image Restoration, https://arxiv.org/pdf/2412.13443, 2025-10-14
2025-11-11 01:13:01,430 - INFO - root - Page:23, Index:3, FastVLM: Efficient Vision Encoding for Vision Language Models, https://arxiv.org/pdf/2412.13303, 2025-05-15
2025-11-11 01:13:01,430 - INFO - root - Page:23, Index:4, Real-time Free-view Human Rendering from Sparse-view RGB Videos using Double Unprojected Textures, https://arxiv.org/pdf/2412.13183, 2025-06-20
2025-11-11 01:13:01,432 - INFO - root - Page:23, Index:5, CondiMen: Conditional Multi-Person Mesh Recovery, https://arxiv.org/pdf/2412.13058, 2025-06-04
2025-11-11 01:13:01,432 - INFO - root - Page:23, Index:6, MASt3R-SLAM: Real-Time Dense SLAM with 3D Reconstruction Priors, https://arxiv.org/pdf/2412.12392, 2025-06-02
2025-11-11 01:13:01,432 - INFO - root - Page:23, Index:7, DynamicScaler: Seamless and Scalable Video Generation for Panoramic Scenes, https://arxiv.org/pdf/2412.11100, 2025-10-04
2025-11-11 01:13:01,432 - INFO - root - Page:23, Index:8, SnapGen-V: Generating a Five-Second Video within Five Seconds on a Mobile Device, https://arxiv.org/pdf/2412.10494, 2025-06-09
2025-11-11 01:13:01,432 - INFO - root - Page:23, Index:9, Mr. DETR++: Instructive Multi-Route Training for Detection Transformers with Mixture-of-Experts, https://arxiv.org/pdf/2412.10028, 2025-06-26
2025-11-11 01:13:01,433 - INFO - root - Page:23, Index:10, LinGen: Towards High-Resolution Minute-Length Text-to-Video Generation with Linear Computational Complexity, https://arxiv.org/pdf/2412.09856, 2025-05-24
2025-11-11 01:13:01,434 - INFO - root - Page:23, Index:11, Gaze-LLE: Gaze Target Estimation via Large-Scale Learned Encoders, https://arxiv.org/pdf/2412.09586, 2025-06-03
2025-11-11 01:13:01,434 - INFO - root - Fetching page 25 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=1200
2025-11-11 01:13:08,050 - INFO - root - get_all_titles_from_web 
2025-11-11 01:13:08,050 - INFO - root - Page:24, Index:0, From Slow Bidirectional to Fast Autoregressive Video Diffusion Models, https://arxiv.org/pdf/2412.07772, 2025-09-23
2025-11-11 01:13:08,051 - INFO - root - Page:24, Index:1, Rate-In: Information-Driven Adaptive Dropout Rates for Improved Inference-Time Uncertainty Estimation, https://arxiv.org/pdf/2412.07169, 2025-06-03
2025-11-11 01:13:08,051 - INFO - root - Page:24, Index:2, FIRE: Robust Detection of Diffusion-Generated Images via Frequency-Guided Reconstruction Error, https://arxiv.org/pdf/2412.07140, 2025-11-03
2025-11-11 01:13:08,052 - INFO - root - Page:24, Index:3, Birth and Death of a Rose, https://arxiv.org/pdf/2412.05278, 2025-06-05
2025-11-11 01:13:08,052 - INFO - root - Page:24, Index:4, DualPM: Dual Posed-Canonical Point Maps for 3D Shape and Pose Reconstruction, https://arxiv.org/pdf/2412.04464, 2025-08-14
2025-11-11 01:13:08,052 - INFO - root - Page:24, Index:5, SeeGround: See and Ground for Zero-Shot Open-Vocabulary 3D Visual Grounding, https://arxiv.org/pdf/2412.04383, 2025-05-29
2025-11-11 01:13:08,052 - INFO - root - ------------------------------------------------------------------------------------------------------------------------
2025-11-11 01:13:08,054 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\CVPR 2025\Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness.pdf
2025-11-11 01:13:08,101 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\CVPR 2025\OmniTrack++_ Omnidirectional Multi-Object Tracking by Learning Large-FoV Traject.pdf
2025-11-11 01:13:08,104 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\CVPR 2025\NeuCo-Bench_ A Novel Benchmark Framework for Neural Embeddings in Earth Observat.pdf
2025-11-11 01:13:08,106 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\CVPR 2025\NTIRE 2025 Challenge on Low Light Image Enhancement_ Methods and Results.pdf
2025-11-11 01:13:08,111 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\CVPR 2025\Class Prototypes based Contrastive Learning for Classifying Multi-Label and Fine.pdf
2025-11-11 23:23:05,962 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-11 23:23:05,962 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-11 23:23:05,962 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-11 23:24:04,569 - ERROR - root - GeminiClient: error during initialization: Timeout of 60.0s exceeded, last exception: 503 failed to connect to all addresses; last error: UNKNOWN: ipv4:142.250.73.74:443: tcp handshaker shutdown
2025-11-11 23:24:04,571 - WARNING - root - LLMClientManager: Gemini client initialization failed
2025-11-11 23:24:04,571 - INFO - root - DeepSeekClient: API key found: 9f9e270e-b...
2025-11-11 23:24:04,571 - INFO - root - DeepSeekClient: 使用模式: 火山引擎
2025-11-11 23:24:04,571 - INFO - root - DeepSeekClient: 模型名称: deepseek-v3-1-terminus
2025-11-11 23:24:08,321 - INFO - openai._base_client - Retrying request to /chat/completions in 0.376830 seconds
2025-11-11 23:24:10,736 - INFO - openai._base_client - Retrying request to /chat/completions in 0.852865 seconds
2025-11-11 23:24:13,647 - ERROR - root - DeepSeekClient: error during initialization: Connection error.
2025-11-11 23:24:13,647 - WARNING - root - LLMClientManager: DeepSeek client initialization failed
2025-11-11 23:24:13,647 - WARNING - root - KimiClient: API key not provided. LLM disabled.
2025-11-11 23:24:13,647 - WARNING - root - LLMClientManager: Kimi client initialization failed
2025-11-11 23:24:13,647 - WARNING - root - QwenClient: API key not provided. LLM disabled.
2025-11-11 23:24:13,647 - WARNING - root - LLMClientManager: Qwen client initialization failed
2025-11-11 23:24:13,647 - INFO - root - DoubaoClient: API key found: 9f9e270e-b...
2025-11-11 23:24:16,655 - INFO - openai._base_client - Retrying request to /chat/completions in 0.461263 seconds
2025-11-11 23:24:19,131 - INFO - openai._base_client - Retrying request to /chat/completions in 0.772790 seconds
2025-11-11 23:24:21,936 - ERROR - root - DoubaoClient: error during initialization: Connection error.
2025-11-11 23:24:21,936 - WARNING - root - LLMClientManager: Doubao client initialization failed
2025-11-11 23:24:21,936 - WARNING - root - LLMClientManager: no LLM client available
2025-11-11 23:24:21,936 - INFO - root - LLM 未初始化或不可用，后续生成将返回备用消息
2025-11-11 23:24:21,936 - INFO - root - === 运行配置 ===
2025-11-11 23:24:21,936 - INFO - root - 处理模式: 本地PDF文件
2025-11-11 23:24:21,936 - INFO - root - PDF目录: d:\ChatPaper\myPapers
2025-11-11 23:24:21,936 - INFO - root - 最大处理数量: 2
2025-11-11 23:24:21,965 - INFO - root - 保存图片: 是
2025-11-11 23:24:21,967 - INFO - root - 输出语言: 中文
2025-11-11 23:24:21,969 - INFO - root - 强制重新处理: 否
2025-11-11 23:24:21,969 - INFO - root - ====================
2025-11-11 23:24:21,972 - INFO - root - 从本地目录读取PDF文件：d:\ChatPaper\myPapers
2025-11-11 23:24:23,324 - INFO - root - 成功加载PDF文件：A Compute&Memory Efficient Model-Driven Neural 5G Receiver for Edge AI-assisted.pdf
2025-11-11 23:24:25,137 - INFO - root - 成功加载PDF文件：AMLA_ MUL by ADD in FlashAttention Rescaling.pdf
2025-11-11 23:24:25,137 - INFO - root - 已达到最大处理数量限制 (2)，停止加载更多PDF文件
2025-11-11 23:24:25,137 - INFO - root - 正在总结论文 1/2: A Compute&Memory Efficient Model-Driven Neural
2025-11-11 23:24:25,137 - INFO - root - 正在提取论文图片...
2025-11-11 23:24:25,733 - INFO - root - 已保存图片 1/10：./export\GPT robot\images\figure_1_page6.png
2025-11-11 23:24:25,813 - INFO - root - 已保存图片 2/10：./export\GPT robot\images\figure_2_page6.png
2025-11-11 23:24:25,885 - INFO - root - 已保存图片 3/10：./export\GPT robot\images\figure_3_page2.png
2025-11-11 23:24:25,923 - INFO - root - 已保存图片 4/10：./export\GPT robot\images\figure_4_page2.png
2025-11-11 23:24:25,966 - INFO - root - 已保存图片 5/10：./export\GPT robot\images\figure_5_page3.png
2025-11-11 23:24:25,972 - INFO - root - 成功添加图片 1：./export\GPT robot\images\figure_1_page6.png
2025-11-11 23:24:25,972 - INFO - root - 成功添加图片 2：./export\GPT robot\images\figure_2_page6.png
2025-11-11 23:24:25,973 - INFO - root - 成功添加图片 3：./export\GPT robot\images\figure_3_page2.png
2025-11-11 23:24:25,974 - INFO - root - 成功添加图片 4：./export\GPT robot\images\figure_4_page2.png
2025-11-11 23:24:25,974 - INFO - root - 成功添加图片 5：./export\GPT robot\images\figure_5_page3.png
2025-11-11 23:24:25,976 - WARNING - root - 图片文件不存在: images/figure_5_page3.png
2025-11-11 23:24:25,977 - WARNING - root - 图片在任何位置都不存在: figure_5_page3.png
2025-11-11 23:24:25,977 - WARNING - root - 图片文件不存在: images/figure_4_page2.png
2025-11-11 23:24:25,977 - WARNING - root - 图片在任何位置都不存在: figure_4_page2.png
2025-11-11 23:24:25,977 - WARNING - root - 图片文件不存在: images/figure_3_page2.png
2025-11-11 23:24:25,979 - WARNING - root - 图片在任何位置都不存在: figure_3_page2.png
2025-11-11 23:24:25,979 - WARNING - root - 图片文件不存在: images/figure_2_page6.png
2025-11-11 23:24:25,980 - WARNING - root - 图片在任何位置都不存在: figure_2_page6.png
2025-11-11 23:24:25,980 - WARNING - root - 图片文件不存在: images/figure_1_page6.png
2025-11-11 23:24:25,981 - WARNING - root - 图片在任何位置都不存在: figure_1_page6.png
2025-11-11 23:24:25,981 - INFO - root - 已按文献标题重新组织图片存储
2025-11-11 23:24:25,982 - INFO - root - 论文《A Compute&Memory Efficient Model-Driven Neural》的分析已保存到 ./export\GPT robot\A Compute&Memory Efficient Model-Driven Neural.md
2025-11-11 23:24:25,983 - INFO - root - 正在总结论文 2/2: AMLA: MUL by ADD in FlashAttention Rescaling
2025-11-11 23:24:25,984 - INFO - root - 正在提取论文图片...
2025-11-11 23:24:26,806 - INFO - root - 已保存图片 1/10：./export\GPT robot\images\figure_1_page15.png
2025-11-11 23:24:26,844 - INFO - root - 已保存图片 2/10：./export\GPT robot\images\figure_2_page4.jpeg
2025-11-11 23:24:26,876 - INFO - root - 已保存图片 3/10：./export\GPT robot\images\figure_3_page8.jpeg
2025-11-11 23:24:26,883 - INFO - root - 成功添加图片 1：./export\GPT robot\images\figure_1_page15.png
2025-11-11 23:24:26,883 - INFO - root - 成功添加图片 2：./export\GPT robot\images\figure_2_page4.jpeg
2025-11-11 23:24:26,884 - INFO - root - 成功添加图片 3：./export\GPT robot\images\figure_3_page8.jpeg
2025-11-11 23:24:26,885 - WARNING - root - 图片文件不存在: images/figure_3_page8.jpeg
2025-11-11 23:24:26,886 - WARNING - root - 图片在任何位置都不存在: figure_3_page8.jpeg
2025-11-11 23:24:26,886 - WARNING - root - 图片文件不存在: images/figure_2_page4.jpeg
2025-11-11 23:24:26,887 - WARNING - root - 图片在任何位置都不存在: figure_2_page4.jpeg
2025-11-11 23:24:26,887 - WARNING - root - 图片文件不存在: images/figure_1_page15.png
2025-11-11 23:24:26,887 - WARNING - root - 图片在任何位置都不存在: figure_1_page15.png
2025-11-11 23:24:26,887 - INFO - root - 已按文献标题重新组织图片存储
2025-11-11 23:24:26,889 - INFO - root - 论文《AMLA: MUL by ADD in FlashAttention Rescaling》的分析已保存到 ./export\GPT robot\AMLA_ MUL by ADD in FlashAttention Rescaling.md
2025-11-11 23:24:27,139 - INFO - root - 已生成汇总Excel表格: export\GPT robot\论文汇总_GPT robot_20251111_232426.xlsx
2025-11-11 23:24:27,139 - INFO - root - 已生成汇总Excel表格: export\GPT robot\论文汇总_GPT robot_20251111_232426.xlsx
2025-11-11 23:24:27,139 - INFO - root - summary time: 81.18 seconds
2025-11-11 23:26:51,001 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-11 23:26:51,002 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-11 23:26:51,002 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-11 23:26:51,700 - INFO - root - LLMClientManager: 指定使用客户端: Gemini
2025-11-11 23:27:49,669 - ERROR - root - GeminiClient: error during initialization: Timeout of 60.0s exceeded, last exception: 503 failed to connect to all addresses; last error: UNKNOWN: ipv4:142.250.217.106:443: socket is null
2025-11-11 23:27:49,672 - ERROR - root - LLMClientManager: 指定的客户端 Gemini 初始化失败
2025-11-11 23:27:49,675 - WARNING - root - LLMClientManager: 指定的客户端 Gemini 不可用，将尝试其他客户端
2025-11-11 23:27:49,675 - INFO - root - DeepSeekClient: API key found: 9f9e270e-b...
2025-11-11 23:27:49,675 - INFO - root - DeepSeekClient: 使用模式: 火山引擎
2025-11-11 23:27:49,675 - INFO - root - DeepSeekClient: 模型名称: deepseek-v3-1-terminus
2025-11-11 23:27:53,293 - INFO - openai._base_client - Retrying request to /chat/completions in 0.483283 seconds
2025-11-11 23:27:55,801 - INFO - openai._base_client - Retrying request to /chat/completions in 0.888375 seconds
2025-11-11 23:27:58,716 - ERROR - root - DeepSeekClient: error during initialization: Connection error.
2025-11-11 23:27:58,716 - WARNING - root - LLMClientManager: DeepSeek client initialization failed
2025-11-11 23:27:58,716 - WARNING - root - KimiClient: API key not provided. LLM disabled.
2025-11-11 23:27:58,716 - WARNING - root - LLMClientManager: Kimi client initialization failed
2025-11-11 23:27:58,716 - WARNING - root - QwenClient: API key not provided. LLM disabled.
2025-11-11 23:27:58,716 - WARNING - root - LLMClientManager: Qwen client initialization failed
2025-11-11 23:27:58,716 - INFO - root - DoubaoClient: API key found: 9f9e270e-b...
2025-11-11 23:28:01,725 - INFO - openai._base_client - Retrying request to /chat/completions in 0.453611 seconds
2025-11-11 23:28:04,214 - INFO - openai._base_client - Retrying request to /chat/completions in 0.829240 seconds
2025-11-11 23:28:07,073 - ERROR - root - DoubaoClient: error during initialization: Connection error.
2025-11-11 23:28:07,073 - WARNING - root - LLMClientManager: Doubao client initialization failed
2025-11-11 23:28:07,073 - WARNING - root - LLMClientManager: no LLM client available
2025-11-11 23:28:07,076 - WARNING - root - LLMClientManager: client Gemini not available. Available clients: []
2025-11-11 23:28:07,076 - WARNING - root - 无法切换到指定的客户端 Gemini，将使用默认客户端
2025-11-11 23:28:07,076 - INFO - root - 可用客户端: []
2025-11-11 23:28:07,076 - INFO - root - LLM 未初始化或不可用，后续生成将返回备用消息
2025-11-11 23:28:07,076 - INFO - root - === 运行配置 ===
2025-11-11 23:28:07,076 - INFO - root - 处理模式: arxiv在线搜索
2025-11-11 23:28:07,084 - INFO - root - 关键词: QCVPR 2025
2025-11-11 23:28:07,085 - INFO - root - 查询: CVPR 2025
2025-11-11 23:28:07,086 - INFO - root - 排序: None
2025-11-11 23:28:07,087 - INFO - root - 最近天数: 180
2025-11-11 23:28:07,090 - INFO - root - 最大处理数量: 2
2025-11-11 23:28:07,090 - INFO - root - 保存图片: 是
2025-11-11 23:28:07,092 - INFO - root - 输出语言: 中文
2025-11-11 23:28:07,093 - INFO - root - 强制重新处理: 否
2025-11-11 23:28:07,094 - INFO - root - ====================
2025-11-11 23:28:07,095 - INFO - root - 使用 arXiv 搜索模式（通过 chat_arxiv 模块获取）
2025-11-11 23:28:07,096 - INFO - root - Fetching page 1 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50
2025-11-11 23:28:09,138 - ERROR - root - 从 chat_arxiv 获取论文列表失败: HTTPSConnectionPool(host='arxiv.org', port=443): Max retries exceeded with url: /search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50 (Caused by ProxyError('Unable to connect to proxy', NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x000001DFF83EA210>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。')))
2025-11-11 23:28:09,138 - INFO - root - 没有找到要处理的论文，程序退出
2025-11-11 23:28:09,138 - INFO - root - summary time: 78.14 seconds
2025-11-11 23:32:08,230 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-11 23:32:08,231 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-11 23:32:08,233 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-11 23:32:09,039 - INFO - root - LLMClientManager: 指定使用客户端: Gemini
2025-11-11 23:32:10,376 - INFO - root - GeminiClient: trying model models/gemini-2.5-flash
2025-11-11 23:32:20,368 - INFO - root - GeminiClient: initialized model gemini-2.5-flash
2025-11-11 23:32:20,370 - INFO - root - LLMClientManager: Gemini 客户端初始化成功
2025-11-11 23:32:20,371 - INFO - root - LLMClientManager: switched to Gemini client
2025-11-11 23:32:20,372 - INFO - root - 已手动切换到 LLM 客户端: Gemini
2025-11-11 23:32:20,373 - INFO - root - 使用 LLM 模型: gemini-2.5-flash
2025-11-11 23:32:20,374 - INFO - root - 可用客户端: ['Gemini']
2025-11-11 23:32:20,375 - INFO - root - === 运行配置 ===
2025-11-11 23:32:20,376 - INFO - root - 处理模式: arxiv在线搜索
2025-11-11 23:32:20,378 - INFO - root - 关键词: QCVPR 2025
2025-11-11 23:32:20,379 - INFO - root - 查询: CVPR 2025
2025-11-11 23:32:20,380 - INFO - root - 排序: None
2025-11-11 23:32:20,383 - INFO - root - 最近天数: 180
2025-11-11 23:32:20,389 - INFO - root - 最大处理数量: 2
2025-11-11 23:32:20,391 - INFO - root - 保存图片: 是
2025-11-11 23:32:20,393 - INFO - root - 输出语言: 中文
2025-11-11 23:32:20,395 - INFO - root - 强制重新处理: 否
2025-11-11 23:32:20,396 - INFO - root - ====================
2025-11-11 23:32:20,398 - INFO - root - 使用 arXiv 搜索模式（通过 chat_arxiv 模块获取）
2025-11-11 23:32:20,404 - INFO - root - Fetching page 1 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50
2025-11-11 23:32:51,314 - INFO - root - get_all_titles_from_web 
2025-11-11 23:32:51,314 - INFO - root - Page:0, Index:0, Learning to Seek Evidence: A Verifiable Reasoning Agent with Causal Faithfulness Analysis, https://arxiv.org/pdf/2511.01425, 2025-11-03
2025-11-11 23:32:51,315 - INFO - root - Page:0, Index:1, OmniTrack++: Omnidirectional Multi-Object Tracking by Learning Large-FoV Trajectory Feedback, https://arxiv.org/pdf/2511.00510, 2025-11-01
2025-11-11 23:32:51,315 - INFO - root - Page:0, Index:2, NeuCo-Bench: A Novel Benchmark Framework for Neural Embeddings in Earth Observation, https://arxiv.org/pdf/2510.17914, 2025-10-19
2025-11-11 23:32:51,315 - INFO - root - Page:0, Index:3, NTIRE 2025 Challenge on Low Light Image Enhancement: Methods and Results, https://arxiv.org/pdf/2510.13670, 2025-10-15
2025-11-11 23:32:51,316 - INFO - root - Page:0, Index:4, Class Prototypes based Contrastive Learning for Classifying Multi-Label and Fine-Grained Educational Videos, https://arxiv.org/pdf/2510.11204, 2025-10-13
2025-11-11 23:32:51,316 - INFO - root - Page:0, Index:5, MIMO: A medical vision language model with visual referring multimodal input and pixel grounding multimodal output, https://arxiv.org/pdf/2510.10011, 2025-10-11
2025-11-11 23:32:51,316 - INFO - root - Page:0, Index:6, Vision Language Models: A Survey of 26K Papers, https://arxiv.org/pdf/2510.09586, 2025-10-10
2025-11-11 23:32:51,316 - INFO - root - Page:0, Index:7, DiT-VTON: Diffusion Transformer Framework for Unified Multi-Category Virtual Try-On and Virtual Try-All with Integrated Image Editing, https://arxiv.org/pdf/2510.04797, 2025-10-03
2025-11-11 23:32:51,317 - INFO - root - Page:0, Index:8, PatchVSR: Breaking Video Diffusion Resolution Limits with Patch-wise Video Super-Resolution, https://arxiv.org/pdf/2509.26025, 2025-09-30
2025-11-11 23:32:51,317 - INFO - root - Page:0, Index:9, FreqDebias: Towards Generalizable Deepfake Detection via Consistency-Driven Frequency Debiasing, https://arxiv.org/pdf/2509.22412, 2025-09-26
2025-11-11 23:32:51,317 - INFO - root - Page:0, Index:10, A Mutual Learning Method for Salient Object Detection with intertwined Multi-Supervision--Revised, https://arxiv.org/pdf/2509.21363, 2025-09-21
2025-11-11 23:32:51,317 - INFO - root - Page:0, Index:11, InstructVTON: Optimal Auto-Masking and Natural-Language-Guided Interactive Style Control for Inpainting-Based Virtual Try-On, https://arxiv.org/pdf/2509.20524, 2025-09-24
2025-11-11 23:32:51,318 - INFO - root - Page:0, Index:12, Efficient Encoder-Free Pose Conditioning and Pose Control for Virtual Try-On, https://arxiv.org/pdf/2509.20343, 2025-09-24
2025-11-11 23:32:51,318 - INFO - root - Page:0, Index:13, The Photographer Eye: Teaching Multimodal Large Language Models to Understand Image Aesthetics like Photographers, https://arxiv.org/pdf/2509.18582, 2025-10-22
2025-11-11 23:32:51,318 - INFO - root - Page:0, Index:14, ENSAM: an efficient foundation model for interactive segmentation of 3D medical images, https://arxiv.org/pdf/2509.15874, 2025-09-19
2025-11-11 23:32:51,319 - INFO - root - Page:0, Index:15, DEFT-VTON: Efficient Virtual Try-On with Consistent Generalised H-Transform, https://arxiv.org/pdf/2509.13506, 2025-09-16
2025-11-11 23:32:51,319 - INFO - root - Page:0, Index:16, Weakly and Self-Supervised Class-Agnostic Motion Prediction for Autonomous Driving, https://arxiv.org/pdf/2509.13116, 2025-09-16
2025-11-11 23:32:51,321 - INFO - root - Page:0, Index:17, Domain-Adaptive Pretraining Improves Primate Behavior Recognition, https://arxiv.org/pdf/2509.12193, 2025-09-15
2025-11-11 23:32:51,321 - INFO - root - Page:0, Index:18, The System Description of CPS Team for Track on Driving with Language of CVPR 2024 Autonomous Grand Challenge, https://arxiv.org/pdf/2509.11071, 2025-09-13
2025-11-11 23:32:51,322 - INFO - root - Page:0, Index:19, An HMM-based framework for identity-aware long-term multi-object tracking from sparse and uncertain identification: use case on long-term tracking in livestock, https://arxiv.org/pdf/2509.09962, 2025-09-12
2025-11-11 23:32:51,323 - INFO - root - Page:0, Index:20, InterAct: Advancing Large-Scale Versatile 3D Human-Object Interaction Generation, https://arxiv.org/pdf/2509.09555, 2025-09-11
2025-11-11 23:32:51,323 - INFO - root - Page:0, Index:21, Geospatial Foundational Embedder: Top-1 Winning Solution on EarthVision Embed2Scale Challenge (CVPR 2025), https://arxiv.org/pdf/2509.06993, 2025-09-03
2025-11-11 23:32:51,323 - INFO - root - Page:0, Index:22, 2nd Place Solution for CVPR2024 E2E Challenge: End-to-End Autonomous Driving Using Vision Language Model, https://arxiv.org/pdf/2509.02659, 2025-09-02
2025-11-11 23:32:51,324 - INFO - root - Page:0, Index:23, Unsupervised Training of Vision Transformers with Synthetic Negatives, https://arxiv.org/pdf/2509.02024, 2025-09-02
2025-11-11 23:32:51,325 - INFO - root - Page:0, Index:24, MV-SSM: Multi-View State Space Modeling for 3D Human Pose Estimation, https://arxiv.org/pdf/2509.00649, 2025-08-30
2025-11-11 23:32:51,328 - INFO - root - Page:0, Index:25, CryptoFace: End-to-End Encrypted Face Recognition, https://arxiv.org/pdf/2509.00332, 2025-08-29
2025-11-11 23:32:51,329 - INFO - root - Page:0, Index:26, ControlEchoSynth: Boosting Ejection Fraction Estimation Models via Controlled Video Diffusion, https://arxiv.org/pdf/2508.17631, 2025-08-26
2025-11-11 23:32:51,329 - INFO - root - Page:0, Index:27, Explain Before You Answer: A Survey on Compositional Visual Reasoning, https://arxiv.org/pdf/2508.17298, 2025-08-27
2025-11-11 23:32:51,338 - INFO - root - Page:0, Index:28, Investigating Different Geo Priors for Image Classification, https://arxiv.org/pdf/2508.15946, 2025-08-21
2025-11-11 23:32:51,339 - INFO - root - Page:0, Index:29, Towards Source-Free Machine Unlearning, https://arxiv.org/pdf/2508.15127, 2025-08-20
2025-11-11 23:32:51,339 - INFO - root - Page:0, Index:30, MR6D: Benchmarking 6D Pose Estimation for Mobile Robots, https://arxiv.org/pdf/2508.13775, 2025-08-19
2025-11-11 23:32:51,342 - INFO - root - Page:0, Index:31, Calibrating Biased Distribution in VFM-derived Latent Space via Cross-Domain Geometric Consistency, https://arxiv.org/pdf/2508.13518, 2025-08-19
2025-11-11 23:32:51,342 - INFO - root - Page:0, Index:32, SIS-Challenge: Event-based Spatio-temporal Instance Segmentation Challenge at the CVPR 2025 Event-based Vision Workshop, https://arxiv.org/pdf/2508.12813, 2025-08-18
2025-11-11 23:32:51,343 - INFO - root - Page:0, Index:33, Multi-Level Knowledge Distillation and Dynamic Self-Supervised Learning for Continual Learning, https://arxiv.org/pdf/2508.12692, 2025-08-22
2025-11-11 23:32:51,344 - INFO - root - Page:0, Index:34, Stochastic-based Patch Filtering for Few-Shot Learning, https://arxiv.org/pdf/2508.10066, 2025-08-13
2025-11-11 23:32:51,344 - INFO - root - Page:0, Index:35, Slot Attention-based Feature Filtering for Few-Shot Learning, https://arxiv.org/pdf/2508.09699, 2025-08-13
2025-11-11 23:32:51,344 - INFO - root - Page:0, Index:36, Comparison Reveals Commonality: Customized Image Generation through Contrastive Inversion, https://arxiv.org/pdf/2508.07755, 2025-08-11
2025-11-11 23:32:51,344 - INFO - root - Page:0, Index:37, SLRTP2025 Sign Language Production Challenge: Methodology, Results, and Future Work, https://arxiv.org/pdf/2508.06951, 2025-08-09
2025-11-11 23:32:51,344 - INFO - root - Page:0, Index:38, Exploring Fairness across Fine-Grained Attributes in Large Vision-Language Models, https://arxiv.org/pdf/2508.03079, 2025-08-05
2025-11-11 23:32:51,348 - INFO - root - Page:0, Index:39, Devil is in the Detail: Towards Injecting Fine Details of Image Prompt in Image Generation via Conflict-free Guidance and Stratified Attention, https://arxiv.org/pdf/2508.02004, 2025-08-03
2025-11-11 23:32:51,350 - INFO - root - Page:0, Index:40, IAUNet: Instance-Aware U-Net, https://arxiv.org/pdf/2508.01928, 2025-08-03
2025-11-11 23:32:51,350 - INFO - root - Page:0, Index:41, Gaussian Splatting Feature Fields for Privacy-Preserving Visual Localization, https://arxiv.org/pdf/2507.23569, 2025-08-26
2025-11-11 23:32:51,351 - INFO - root - Page:0, Index:42, From Scan to Action: Leveraging Realistic Scans for Embodied Scene Understanding, https://arxiv.org/pdf/2507.17585, 2025-07-23
2025-11-11 23:32:51,351 - INFO - root - Page:0, Index:43, LEAD: Exploring Logit Space Evolution for Model Selection, https://arxiv.org/pdf/2507.14559, 2025-07-19
2025-11-11 23:32:51,351 - INFO - root - Page:0, Index:44, HeCoFuse: Cross-Modal Complementary V2X Cooperative Perception with Heterogeneous Sensors, https://arxiv.org/pdf/2507.13677, 2025-07-18
2025-11-11 23:32:51,351 - INFO - root - Page:0, Index:45, OmniVec2 -- A Novel Transformer based Network for Large Scale Multimodal and Multitask Learning, https://arxiv.org/pdf/2507.13364, 2025-07-06
2025-11-11 23:32:51,352 - INFO - root - Page:0, Index:46, A Training-Free, Task-Agnostic Framework for Enhancing MLLM Performance on High-Resolution Images, https://arxiv.org/pdf/2507.10202, 2025-07-14
2025-11-11 23:32:51,352 - INFO - root - Page:0, Index:47, Quantum Federated Learning for Multimodal Data: A Modality-Agnostic Approach, https://arxiv.org/pdf/2507.08217, 2025-07-10
2025-11-11 23:32:51,352 - INFO - root - Page:0, Index:48, CuriosAI Submission to the EgoExo4D Proficiency Estimation Challenge 2025, https://arxiv.org/pdf/2507.08022, 2025-07-08
2025-11-11 23:32:51,352 - INFO - root - Page:0, Index:49, Rethinking Query-based Transformer for Continual Image Segmentation, https://arxiv.org/pdf/2507.07831, 2025-07-10
2025-11-11 23:32:51,354 - INFO - root - Fetching page 2 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=50
2025-11-11 23:33:21,809 - INFO - root - get_all_titles_from_web 
2025-11-11 23:33:21,812 - INFO - root - Page:1, Index:0, Scalable and Realistic Virtual Try-on Application for Foundation Makeup with Kubelka-Munk Theory, https://arxiv.org/pdf/2507.07333, 2025-07-09
2025-11-11 23:33:21,812 - INFO - root - Page:1, Index:1, Free on the Fly: Enhancing Flexibility in Test-Time Adaptation with Online EM, https://arxiv.org/pdf/2507.06973, 2025-07-09
2025-11-11 23:33:21,812 - INFO - root - Page:1, Index:2, Adaptive Part Learning for Fine-Grained Generalized Category Discovery: A Plug-and-Play Enhancement, https://arxiv.org/pdf/2507.06928, 2025-07-09
2025-11-11 23:33:21,812 - INFO - root - Page:1, Index:3, Grounded Gesture Generation: Language, Motion, and Space, https://arxiv.org/pdf/2507.04522, 2025-07-06
2025-11-11 23:33:21,812 - INFO - root - Page:1, Index:4, Comprehensive Information Bottleneck for Unveiling Universal Attribution to Interpret Vision Transformers, https://arxiv.org/pdf/2507.04388, 2025-07-06
2025-11-11 23:33:21,812 - INFO - root - Page:1, Index:5, ZERO: Industry-ready Vision Foundation Model with Multi-modal Prompts, https://arxiv.org/pdf/2507.04270, 2025-11-07
2025-11-11 23:33:21,812 - INFO - root - Page:1, Index:6, Beyond Accuracy: Metrics that Uncover What Makes a 'Good' Visual Descriptor, https://arxiv.org/pdf/2507.03542, 2025-07-08
2025-11-11 23:33:21,812 - INFO - root - Page:1, Index:7, ConceptMix++: Leveling the Playing Field in Text-to-Image Benchmarking via Iterative Prompt Optimization, https://arxiv.org/pdf/2507.03275, 2025-07-03
2025-11-11 23:33:21,817 - INFO - root - Page:1, Index:8, APT: Adaptive Personalized Training for Diffusion Models with Limited Data, https://arxiv.org/pdf/2507.02687, 2025-07-03
2025-11-11 23:33:21,819 - INFO - root - Page:1, Index:9, DreamComposer++: Empowering Diffusion Models with Multi-View Conditions for 3D Content Generation, https://arxiv.org/pdf/2507.02299, 2025-07-03
2025-11-11 23:33:21,819 - INFO - root - Page:1, Index:10, Soft Self-labeling and Potts Relaxations for Weakly-Supervised Segmentation, https://arxiv.org/pdf/2507.01721, 2025-07-02
2025-11-11 23:33:21,819 - INFO - root - Page:1, Index:11, Interpolation-Based Event Visual Data Filtering Algorithms, https://arxiv.org/pdf/2507.01557, 2025-07-02
2025-11-11 23:33:21,819 - INFO - root - Page:1, Index:12, AVC-DPO: Aligned Video Captioning via Direct Preference Optimization, https://arxiv.org/pdf/2507.01492, 2025-07-02
2025-11-11 23:33:21,819 - INFO - root - Page:1, Index:13, NN-Former: Rethinking Graph Structure in Neural Architecture Representation, https://arxiv.org/pdf/2507.00880, 2025-07-01
2025-11-11 23:33:21,819 - INFO - root - Page:1, Index:14, Instant Particle Size Distribution Measurement Using CNNs Trained on Synthetic Data, https://arxiv.org/pdf/2507.00822, 2025-07-01
2025-11-11 23:33:21,819 - INFO - root - Page:1, Index:15, Moment Sampling in Video LLMs for Long-Form Video QA, https://arxiv.org/pdf/2507.00033, 2025-06-17
2025-11-11 23:33:21,819 - INFO - root - Page:1, Index:16, Revisiting Audio-Visual Segmentation with Vision-Centric Transformer, https://arxiv.org/pdf/2506.23623, 2025-06-30
2025-11-11 23:33:21,825 - INFO - root - Page:1, Index:17, MTADiffusion: Mask Text Alignment Diffusion Model for Object Inpainting, https://arxiv.org/pdf/2506.23482, 2025-06-29
2025-11-11 23:33:21,825 - INFO - root - Page:1, Index:18, Benchmarking Generalizable Bimanual Manipulation: RoboTwin Dual-Arm Collaboration Challenge at CVPR 2025 MEIS Workshop, https://arxiv.org/pdf/2506.23351, 2025-07-02
2025-11-11 23:33:21,830 - INFO - root - Page:1, Index:19, Prompting without Panic: Attribute-aware, Zero-shot, Test-Time Calibration, https://arxiv.org/pdf/2506.22819, 2025-06-28
2025-11-11 23:33:21,833 - INFO - root - Page:1, Index:20, Analyzing and Fine-Tuning Whisper Models for Multilingual Pilot Speech Transcription in the Cockpit, https://arxiv.org/pdf/2506.21990, 2025-06-27
2025-11-11 23:33:21,833 - INFO - root - Page:1, Index:21, SceneDiffuser++: City-Scale Traffic Simulation via a Generative World Model, https://arxiv.org/pdf/2506.21976, 2025-06-27
2025-11-11 23:33:21,835 - INFO - root - Page:1, Index:22, DIVE: Deep-search Iterative Video Exploration A Technical Report for the CVRR Challenge at CVPR 2025, https://arxiv.org/pdf/2506.21891, 2025-06-27
2025-11-11 23:33:21,835 - INFO - root - Page:1, Index:23, End-to-End RGB-IR Joint Image Compression With Channel-wise Cross-modality Entropy Model, https://arxiv.org/pdf/2506.21851, 2025-06-26
2025-11-11 23:33:21,836 - INFO - root - Page:1, Index:24, Distilling Normalizing Flows, https://arxiv.org/pdf/2506.21003, 2025-06-26
2025-11-11 23:33:21,836 - INFO - root - Page:1, Index:25, Joint attitude estimation and 3D neural reconstruction of non-cooperative space objects, https://arxiv.org/pdf/2506.20638, 2025-06-25
2025-11-11 23:33:21,836 - INFO - root - Page:1, Index:26, Accept More, Reject Less: Reducing up to 19% Unnecessary Desk-Rejections over 11 Years of ICLR Data, https://arxiv.org/pdf/2506.20141, 2025-06-25
2025-11-11 23:33:21,837 - INFO - root - Page:1, Index:27, SceneCrafter: Controllable Multi-View Driving Scene Editing, https://arxiv.org/pdf/2506.19488, 2025-06-24
2025-11-11 23:33:21,837 - INFO - root - Page:1, Index:28, Emergence of Text Readability in Vision Language Models, https://arxiv.org/pdf/2506.19389, 2025-06-24
2025-11-11 23:33:21,837 - INFO - root - Page:1, Index:29, MedErr-CT: A Visual Question Answering Benchmark for Identifying and Correcting Errors in CT Reports, https://arxiv.org/pdf/2506.19217, 2025-06-23
2025-11-11 23:33:21,838 - INFO - root - Page:1, Index:30, RareSpot: Spotting Small and Rare Wildlife in Aerial Imagery with Multi-Scale Consistency and Context-Aware Augmentation, https://arxiv.org/pdf/2506.19087, 2025-06-23
2025-11-11 23:33:21,838 - INFO - root - Page:1, Index:31, Object-aware Sound Source Localization via Audio-Visual Scene Understanding, https://arxiv.org/pdf/2506.18557, 2025-06-23
2025-11-11 23:33:21,839 - INFO - root - Page:1, Index:32, Rethinking Decoder Design: Improving Biomarker Segmentation Using Depth-to-Space Restoration and Residual Linear Attention, https://arxiv.org/pdf/2506.18335, 2025-06-23
2025-11-11 23:33:21,840 - INFO - root - Page:1, Index:33, Relation3D: Enhancing Relation Modeling for Point Cloud Instance Segmentation, https://arxiv.org/pdf/2506.17891, 2025-06-21
2025-11-11 23:33:21,840 - INFO - root - Page:1, Index:34, HIRE: Lightweight High-Resolution Image Feature Enrichment for Multimodal LLMs, https://arxiv.org/pdf/2506.17608, 2025-06-21
2025-11-11 23:33:21,840 - INFO - root - Page:1, Index:35, Spatially-Aware Evaluation of Segmentation Uncertainty, https://arxiv.org/pdf/2506.16589, 2025-06-19
2025-11-11 23:33:21,841 - INFO - root - Page:1, Index:36, Tripartite Weight-Space Ensemble for Few-Shot Class-Incremental Learning, https://arxiv.org/pdf/2506.15720, 2025-06-03
2025-11-11 23:33:21,841 - INFO - root - Page:1, Index:37, PARC: A Quantitative Framework Uncovering the Symmetries within Vision Language Models, https://arxiv.org/pdf/2506.14808, 2025-06-03
2025-11-11 23:33:21,841 - INFO - root - Page:1, Index:38, Self-supervised Representation Learning with Local Aggregation for Image-based Profiling, https://arxiv.org/pdf/2506.14265, 2025-10-27
2025-11-11 23:33:21,842 - INFO - root - Page:1, Index:39, Towards Robust Learning to Optimize with Theoretical Guarantees, https://arxiv.org/pdf/2506.14263, 2025-06-17
2025-11-11 23:33:21,847 - INFO - root - Page:1, Index:40, Hidden Bias in the Machine: Stereotypes in Text-to-Image Models, https://arxiv.org/pdf/2506.13780, 2025-06-09
2025-11-11 23:33:21,848 - INFO - root - Page:1, Index:41, SmartHome-Bench: A Comprehensive Benchmark for Video Anomaly Detection in Smart Homes Using Multi-Modal Large Language Models, https://arxiv.org/pdf/2506.12992, 2025-06-15
2025-11-11 23:33:21,850 - INFO - root - Page:1, Index:42, Generative 4D Scene Gaussian Splatting with Object View-Synthesis Priors, https://arxiv.org/pdf/2506.12716, 2025-06-15
2025-11-11 23:33:21,852 - INFO - root - Page:1, Index:43, DejaVid: Encoder-Agnostic Learned Temporal Matching for Video Classification, https://arxiv.org/pdf/2506.12585, 2025-06-14
2025-11-11 23:33:21,853 - INFO - root - Page:1, Index:44, Pushing the Limits of Safety: A Technical Report on the ATLAS Challenge 2025, https://arxiv.org/pdf/2506.12430, 2025-07-10
2025-11-11 23:33:21,861 - INFO - root - Page:1, Index:45, FIMA-Q: Post-Training Quantization for Vision Transformers by Fisher Information Matrix Approximation, https://arxiv.org/pdf/2506.11543, 2025-06-13
2025-11-11 23:33:21,862 - INFO - root - Page:1, Index:46, Stop learning it all to mitigate visual hallucination, Focus on the hallucination target, https://arxiv.org/pdf/2506.11417, 2025-06-12
2025-11-11 23:33:21,863 - INFO - root - Page:1, Index:47, EfficientQuant: An Efficient Post-Training Quantization for CNN-Transformer Hybrid Models on Edge Devices, https://arxiv.org/pdf/2506.11093, 2025-06-05
2025-11-11 23:33:21,864 - INFO - root - Page:1, Index:48, HalLoc: Token-level Localization of Hallucinations for Vision Language Models, https://arxiv.org/pdf/2506.10286, 2025-06-11
2025-11-11 23:33:21,864 - INFO - root - Page:1, Index:49, DySS: Dynamic Queries and State-Space Learning for Efficient 3D Object Detection from Multi-Camera Videos, https://arxiv.org/pdf/2506.10242, 2025-06-11
2025-11-11 23:33:21,864 - INFO - root - Fetching page 3 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=100
2025-11-11 23:33:46,517 - INFO - root - get_all_titles_from_web 
2025-11-11 23:33:46,518 - INFO - root - Page:2, Index:0, Improving Personalized Search with Regularized Low-Rank Parameter Updates, https://arxiv.org/pdf/2506.10182, 2025-06-11
2025-11-11 23:33:46,520 - INFO - root - Page:2, Index:1, Hearing Hands: Generating Sounds from Physical Interactions in 3D Scenes, https://arxiv.org/pdf/2506.09989, 2025-06-11
2025-11-11 23:33:46,520 - INFO - root - Page:2, Index:2, UniPre3D: Unified Pre-training of 3D Point Cloud Models with Cross-Modal Gaussian Splatting, https://arxiv.org/pdf/2506.09952, 2025-06-11
2025-11-11 23:33:46,520 - INFO - root - Page:2, Index:3, Provoking Multi-modal Few-Shot LVLM via Exploration-Exploitation In-Context Learning, https://arxiv.org/pdf/2506.09473, 2025-06-11
2025-11-11 23:33:46,520 - INFO - root - Page:2, Index:4, Synthetic Human Action Video Data Generation with Pose Transfer, https://arxiv.org/pdf/2506.09411, 2025-06-11
2025-11-11 23:33:46,520 - INFO - root - Page:2, Index:5, ScaleLSD: Scalable Deep Line Segment Detection Streamlined, https://arxiv.org/pdf/2506.09369, 2025-06-10
2025-11-11 23:33:46,520 - INFO - root - Page:2, Index:6, CheckManual: A New Challenge and Benchmark for Manual-based Appliance Manipulation, https://arxiv.org/pdf/2506.09343, 2025-06-10
2025-11-11 23:33:46,521 - INFO - root - Page:2, Index:7, PatchGuard: Adversarially Robust Anomaly Detection and Localization through Vision Transformers and Pseudo Anomalies, https://arxiv.org/pdf/2506.09237, 2025-10-24
2025-11-11 23:33:46,521 - INFO - root - Page:2, Index:8, SILK: Smooth InterpoLation frameworK for motion in-betweening A Simplified Computational Approach, https://arxiv.org/pdf/2506.09075, 2025-06-09
2025-11-11 23:33:46,521 - INFO - root - Page:2, Index:9, BG-HOP: A Bimanual Generative Hand-Object Prior, https://arxiv.org/pdf/2506.09068, 2025-06-08
2025-11-11 23:33:46,521 - INFO - root - Page:2, Index:10, ORIDa: Object-centric Real-world Image Composition Dataset, https://arxiv.org/pdf/2506.08964, 2025-06-10
2025-11-11 23:33:46,522 - INFO - root - Page:2, Index:11, DiscoVLA: Discrepancy Reduction in Vision, Language, and Alignment for Parameter-Efficient Video-Text Retrieval, https://arxiv.org/pdf/2506.08887, 2025-06-10
2025-11-11 23:33:46,522 - INFO - root - Page:2, Index:12, A Comprehensive Study of Decoder-Only LLMs for Text-to-Image Generation, https://arxiv.org/pdf/2506.08210, 2025-06-09
2025-11-11 23:33:46,522 - INFO - root - Page:2, Index:13, Open World Scene Graph Generation using Vision Language Models, https://arxiv.org/pdf/2506.08189, 2025-06-09
2025-11-11 23:33:46,522 - INFO - root - Page:2, Index:14, Aligning Proteins and Language: A Foundation Model for Protein Retrieval, https://arxiv.org/pdf/2506.08023, 2025-05-27
2025-11-11 23:33:46,524 - INFO - root - Page:2, Index:15, UA-Pose: Uncertainty-Aware 6D Object Pose Estimation and Online Object Completion with Partial References, https://arxiv.org/pdf/2506.07996, 2025-06-09
2025-11-11 23:33:46,524 - INFO - root - Page:2, Index:16, Speedy Deformable 3D Gaussian Splatting: Fast Rendering and Compression of Dynamic Scenes, https://arxiv.org/pdf/2506.07917, 2025-06-09
2025-11-11 23:33:46,524 - INFO - root - Page:2, Index:17, GaussianVAE: Adaptive Learning Dynamics of 3D Gaussians for High-Fidelity Super-Resolution, https://arxiv.org/pdf/2506.07897, 2025-06-09
2025-11-11 23:33:46,525 - INFO - root - Page:2, Index:18, Spatio-Temporal State Space Model For Efficient Event-Based Optical Flow, https://arxiv.org/pdf/2506.07878, 2025-06-09
2025-11-11 23:33:46,525 - INFO - root - Page:2, Index:19, FreeGave: 3D Physics Learning from Dynamic Videos by Gaussian Velocity, https://arxiv.org/pdf/2506.07865, 2025-06-09
2025-11-11 23:33:46,525 - INFO - root - Page:2, Index:20, LogoSP: Local-global Grouping of Superpoints for Unsupervised Semantic Segmentation of 3D Point Clouds, https://arxiv.org/pdf/2506.07857, 2025-06-09
2025-11-11 23:33:46,526 - INFO - root - Page:2, Index:21, Difference Inversion: Interpolate and Isolate the Difference with Token Consistency for Image Analogy Generation, https://arxiv.org/pdf/2506.07750, 2025-06-09
2025-11-11 23:33:46,526 - INFO - root - Page:2, Index:22, Synthetic Visual Genome, https://arxiv.org/pdf/2506.07643, 2025-06-09
2025-11-11 23:33:46,526 - INFO - root - Page:2, Index:23, Fractional Collisions: A Framework for Risk Estimation of Counterfactual Conflicts using Autonomous Driving Behavior Simulations, https://arxiv.org/pdf/2506.07540, 2025-06-09
2025-11-11 23:33:46,526 - INFO - root - Page:2, Index:24, Multi-Step Guided Diffusion for Image Restoration on Edge Devices: Toward Lightweight Perception in Embodied AI, https://arxiv.org/pdf/2506.07286, 2025-06-08
2025-11-11 23:33:46,527 - INFO - root - Page:2, Index:25, LLM-Enhanced Rapid-Reflex Async-Reflect Embodied Agent for Real-Time Decision-Making in Dynamically Changing Environments, https://arxiv.org/pdf/2506.07223, 2025-06-08
2025-11-11 23:33:46,527 - INFO - root - Page:2, Index:26, UCOD-DPL: Unsupervised Camouflaged Object Detection via Dynamic Pseudo-label Learning, https://arxiv.org/pdf/2506.07087, 2025-06-08
2025-11-11 23:33:46,527 - INFO - root - Page:2, Index:27, BePo: Leveraging Birds Eye View and Sparse Points for Efficient and Accurate 3D Occupancy Prediction, https://arxiv.org/pdf/2506.07002, 2025-06-08
2025-11-11 23:33:46,527 - INFO - root - Page:2, Index:28, Reading in the Dark with Foveated Event Vision, https://arxiv.org/pdf/2506.06918, 2025-06-07
2025-11-11 23:33:46,528 - INFO - root - Page:2, Index:29, NSD-Imagery: A benchmark dataset for extending fMRI vision decoding methods to mental imagery, https://arxiv.org/pdf/2506.06898, 2025-06-07
2025-11-11 23:33:46,528 - INFO - root - Page:2, Index:30, Continuous-Time SO(3) Forecasting with Savitzky--Golay Neural Controlled Differential Equations, https://arxiv.org/pdf/2506.06780, 2025-06-07
2025-11-11 23:33:46,528 - INFO - root - Page:2, Index:31, Generalized Trajectory Scoring for End-to-end Multimodal Planning, https://arxiv.org/pdf/2506.06664, 2025-06-07
2025-11-11 23:33:46,528 - INFO - root - Page:2, Index:32, EV-LayerSegNet: Self-supervised Motion Segmentation using Event Cameras, https://arxiv.org/pdf/2506.06596, 2025-06-06
2025-11-11 23:33:46,529 - INFO - root - Page:2, Index:33, Vid2Sim: Generalizable, Video-based Reconstruction of Appearance, Geometry and Physics for Mesh-free Simulation, https://arxiv.org/pdf/2506.06440, 2025-06-06
2025-11-11 23:33:46,529 - INFO - root - Page:2, Index:34, FADE: Frequency-Aware Diffusion Model Factorization for Video Editing, https://arxiv.org/pdf/2506.05934, 2025-06-06
2025-11-11 23:33:46,530 - INFO - root - Page:2, Index:35, Unleashing the Potential of Consistency Learning for Detecting and Grounding Multi-Modal Media Manipulation, https://arxiv.org/pdf/2506.05890, 2025-06-06
2025-11-11 23:33:46,530 - INFO - root - Page:2, Index:36, DeformCL: Learning Deformable Centerline Representation for Vessel Extraction in 3D Medical Image, https://arxiv.org/pdf/2506.05820, 2025-06-06
2025-11-11 23:33:46,530 - INFO - root - Page:2, Index:37, NTIRE 2025 Challenge on HR Depth from Images of Specular and Transparent Surfaces, https://arxiv.org/pdf/2506.05815, 2025-06-06
2025-11-11 23:33:46,530 - INFO - root - Page:2, Index:38, GazeNLQ @ Ego4D Natural Language Queries Challenge 2025, https://arxiv.org/pdf/2506.05782, 2025-06-06
2025-11-11 23:33:46,531 - INFO - root - Page:2, Index:39, Robust sensor fusion against on-vehicle sensor staleness, https://arxiv.org/pdf/2506.05780, 2025-06-06
2025-11-11 23:33:46,531 - INFO - root - Page:2, Index:40, Where Is The Ball: 3D Ball Trajectory Estimation From 2D Monocular Tracking, https://arxiv.org/pdf/2506.05763, 2025-06-06
2025-11-11 23:33:46,531 - INFO - root - Page:2, Index:41, VoxelSplat: Dynamic Gaussian Splatting as an Effective Loss for Occupancy and Flow Prediction, https://arxiv.org/pdf/2506.05563, 2025-06-05
2025-11-11 23:33:46,533 - INFO - root - Page:2, Index:42, Gen4D: Synthesizing Humans and Scenes in the Wild, https://arxiv.org/pdf/2506.05397, 2025-06-03
2025-11-11 23:33:46,533 - INFO - root - Page:2, Index:43, Attacking Attention of Foundation Models Disrupts Downstream Tasks, https://arxiv.org/pdf/2506.05394, 2025-09-12
2025-11-11 23:33:46,533 - INFO - root - Page:2, Index:44, FreeTimeGS: Free Gaussian Primitives at Anytime and Anywhere for Dynamic Scene Reconstruction, https://arxiv.org/pdf/2506.05348, 2025-06-06
2025-11-11 23:33:46,534 - INFO - root - Page:2, Index:45, LotusFilter: Fast Diverse Nearest Neighbor Search via a Learned Cutoff Table, https://arxiv.org/pdf/2506.04790, 2025-06-05
2025-11-11 23:33:46,538 - INFO - root - Page:2, Index:46, Towards Holistic Visual Quality Assessment of AI-Generated Videos: A LLM-Based Multi-Dimensional Evaluation Model, https://arxiv.org/pdf/2506.04715, 2025-06-11
2025-11-11 23:33:46,538 - INFO - root - Page:2, Index:47, Gradient Inversion Attacks on Parameter-Efficient Fine-Tuning, https://arxiv.org/pdf/2506.04453, 2025-06-04
2025-11-11 23:33:46,539 - INFO - root - Page:2, Index:48, HMAR: Efficient Hierarchical Masked Auto-Regressive Image Generation, https://arxiv.org/pdf/2506.04421, 2025-06-04
2025-11-11 23:33:46,539 - INFO - root - Page:2, Index:49, Visualizing and Controlling Cortical Responses Using Voxel-Weighted Activation Maximization, https://arxiv.org/pdf/2506.04379, 2025-06-04
2025-11-11 23:33:46,540 - INFO - root - Fetching page 4 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=150
2025-11-11 23:33:56,999 - INFO - root - get_all_titles_from_web 
2025-11-11 23:33:56,999 - INFO - root - Page:3, Index:0, FlexGS: Train Once, Deploy Everywhere with Many-in-One Flexible 3D Gaussian Splatting, https://arxiv.org/pdf/2506.04174, 2025-06-04
2025-11-11 23:33:56,999 - INFO - root - Page:3, Index:1, Multi-view Surface Reconstruction Using Normal and Reflectance Cues, https://arxiv.org/pdf/2506.04115, 2025-06-04
2025-11-11 23:33:56,999 - INFO - root - Page:3, Index:2, Vocabulary-free few-shot learning for Vision-Language Models, https://arxiv.org/pdf/2506.04005, 2025-06-04
2025-11-11 23:33:56,999 - INFO - root - Page:3, Index:3, Learning from Noise: Enhancing DNNs for Event-Based Vision through Controlled Noise Injection, https://arxiv.org/pdf/2506.03918, 2025-06-04
2025-11-11 23:33:56,999 - INFO - root - Page:3, Index:4, Video, How Do Your Tokens Merge?, https://arxiv.org/pdf/2506.03885, 2025-06-04
2025-11-11 23:33:56,999 - INFO - root - Page:3, Index:5, OSGNet @ Ego4D Episodic Memory Challenge 2025, https://arxiv.org/pdf/2506.03710, 2025-06-04
2025-11-11 23:33:56,999 - INFO - root - Page:3, Index:6, AetherVision-Bench: An Open-Vocabulary RGB-Infrared Benchmark for Multi-Angle Segmentation across Aerial and Ground Perspectives, https://arxiv.org/pdf/2506.03709, 2025-06-04
2025-11-11 23:33:56,999 - INFO - root - Page:3, Index:7, OV-COAST: Cost Aggregation with Optimal Transport for Open-Vocabulary Semantic Segmentation, https://arxiv.org/pdf/2506.03706, 2025-06-04
2025-11-11 23:33:56,999 - INFO - root - Page:3, Index:8, Generating 6DoF Object Manipulation Trajectories from Action Description in Egocentric Vision, https://arxiv.org/pdf/2506.03605, 2025-06-04
2025-11-11 23:33:56,999 - INFO - root - Page:3, Index:9, SemNav: A Model-Based Planner for Zero-Shot Object Goal Navigation Using Vision-Foundation Models, https://arxiv.org/pdf/2506.03516, 2025-06-03
2025-11-11 23:33:56,999 - INFO - root - Page:3, Index:10, Heterogeneous Skeleton-Based Action Representation Learning, https://arxiv.org/pdf/2506.03481, 2025-06-03
2025-11-11 23:33:56,999 - INFO - root - Page:3, Index:11, Hybrid Ensemble of Segmentation-Assisted Classification and GBDT for Skin Cancer Detection with Engineered Metadata and Synthetic Lesions from ISIC 2024 Non-Dermoscopic 3D-TBP Images, https://arxiv.org/pdf/2506.03420, 2025-06-03
2025-11-11 23:33:56,999 - INFO - root - Page:3, Index:12, Self-Supervised Spatial Correspondence Across Modalities, https://arxiv.org/pdf/2506.03148, 2025-06-03
2025-11-11 23:33:56,999 - INFO - root - Page:3, Index:13, Dense Match Summarization for Faster Two-view Estimation, https://arxiv.org/pdf/2506.02893, 2025-06-03
2025-11-11 23:33:56,999 - INFO - root - Page:3, Index:14, NTIRE 2025 XGC Quality Assessment Challenge: Methods and Results, https://arxiv.org/pdf/2506.02875, 2025-06-03
2025-11-11 23:33:57,004 - INFO - root - Page:3, Index:15, FreeScene: Mixed Graph Diffusion for 3D Scene Synthesis from Free Prompts, https://arxiv.org/pdf/2506.02781, 2025-06-03
2025-11-11 23:33:57,005 - INFO - root - Page:3, Index:16, Technical Report for Ego4D Long-Term Action Anticipation Challenge 2025, https://arxiv.org/pdf/2506.02550, 2025-06-11
2025-11-11 23:33:57,005 - INFO - root - Page:3, Index:17, Probabilistic Online Event Downsampling, https://arxiv.org/pdf/2506.02547, 2025-09-23
2025-11-11 23:33:57,005 - INFO - root - Page:3, Index:18, Towards In-the-wild 3D Plane Reconstruction from a Single Image, https://arxiv.org/pdf/2506.02493, 2025-06-03
2025-11-11 23:33:57,005 - INFO - root - Page:3, Index:19, Efficient Test-time Adaptive Object Detection via Sensitivity-Guided Pruning, https://arxiv.org/pdf/2506.02462, 2025-06-03
2025-11-11 23:33:57,005 - INFO - root - Page:3, Index:20, EgoVIS@CVPR: PAIR-Net: Enhancing Egocentric Speaker Detection via Pretrained Audio-Visual Fusion and Alignment Loss, https://arxiv.org/pdf/2506.02247, 2025-09-26
2025-11-11 23:33:57,005 - INFO - root - Page:3, Index:21, Diff2Flow: Training Flow Matching Models via Diffusion Model Alignment, https://arxiv.org/pdf/2506.02221, 2025-06-02
2025-11-11 23:33:57,007 - INFO - root - Page:3, Index:22, NTIRE 2025 Challenge on RAW Image Restoration and Super-Resolution, https://arxiv.org/pdf/2506.02197, 2025-06-04
2025-11-11 23:33:57,007 - INFO - root - Page:3, Index:23, RAW Image Reconstruction from RGB on Smartphones. NTIRE 2025 Challenge Report, https://arxiv.org/pdf/2506.01947, 2025-06-02
2025-11-11 23:33:57,007 - INFO - root - Page:3, Index:24, Silence is Golden: Leveraging Adversarial Examples to Nullify Audio Control in LDM-based Talking-Head Generation, https://arxiv.org/pdf/2506.01591, 2025-06-02
2025-11-11 23:33:57,007 - INFO - root - Page:3, Index:25, SAM2-LOVE: Segment Anything Model 2 in Language-aided Audio-Visual Scenes, https://arxiv.org/pdf/2506.01558, 2025-06-02
2025-11-11 23:33:57,007 - INFO - root - Page:3, Index:26, Neural shape reconstruction from multiple views with static pattern projection, https://arxiv.org/pdf/2506.01389, 2025-06-02
2025-11-11 23:33:57,007 - INFO - root - Page:3, Index:27, SAM-I2V: Upgrading SAM to Support Promptable Video Segmentation with Less than 0.2% Training Cost, https://arxiv.org/pdf/2506.01304, 2025-06-02
2025-11-11 23:33:57,007 - INFO - root - Page:3, Index:28, Perceptual Inductive Bias Is What You Need Before Contrastive Learning, https://arxiv.org/pdf/2506.01201, 2025-06-01
2025-11-11 23:33:57,007 - INFO - root - Page:3, Index:29, Test Automation for Interactive Scenarios via Promptable Traffic Simulation, https://arxiv.org/pdf/2506.01199, 2025-06-04
2025-11-11 23:33:57,007 - INFO - root - Page:3, Index:30, GraphPad: Inference-Time 3D Scene Graph Updates for Embodied Question Answering, https://arxiv.org/pdf/2506.01174, 2025-06-01
2025-11-11 23:33:57,007 - INFO - root - Page:3, Index:31, Aligned Contrastive Loss for Long-Tailed Recognition, https://arxiv.org/pdf/2506.01071, 2025-06-01
2025-11-11 23:33:57,012 - INFO - root - Page:3, Index:32, Self-supervised ControlNet with Spatio-Temporal Mamba for Real-world Video Super-resolution, https://arxiv.org/pdf/2506.01037, 2025-06-01
2025-11-11 23:33:57,013 - INFO - root - Page:3, Index:33, ArtiScene: Language-Driven Artistic 3D Scene Generation Through Image Intermediary, https://arxiv.org/pdf/2506.00742, 2025-05-31
2025-11-11 23:33:57,013 - INFO - root - Page:3, Index:34, 3D Gaussian Splat Vulnerabilities, https://arxiv.org/pdf/2506.00280, 2025-05-30
2025-11-11 23:33:57,013 - INFO - root - Page:3, Index:35, EgoVIS@CVPR: What Changed and What Could Have Changed? State-Change Counterfactuals for Procedure-Aware Video Representation Learning, https://arxiv.org/pdf/2506.00101, 2025-09-26
2025-11-11 23:33:57,015 - INFO - root - Page:3, Index:36, CL-LoRA: Continual Low-Rank Adaptation for Rehearsal-Free Class-Incremental Learning, https://arxiv.org/pdf/2505.24816, 2025-05-30
2025-11-11 23:33:57,015 - INFO - root - Page:3, Index:37, PatchDEMUX: A Certifiably Robust Framework for Multi-label Classifiers Against Adversarial Patches, https://arxiv.org/pdf/2505.24703, 2025-05-30
2025-11-11 23:33:57,015 - INFO - root - Page:3, Index:38, Conformal Prediction for Zero-Shot Models, https://arxiv.org/pdf/2505.24693, 2025-05-30
2025-11-11 23:33:57,016 - INFO - root - Page:3, Index:39, Learning reusable concepts across different egocentric video understanding tasks, https://arxiv.org/pdf/2505.24690, 2025-05-30
2025-11-11 23:33:57,017 - INFO - root - Page:3, Index:40, Period-LLM: Extending the Periodic Capability of Multimodal Large Language Model, https://arxiv.org/pdf/2505.24476, 2025-05-30
2025-11-11 23:33:57,018 - INFO - root - Page:3, Index:41, PCIE_Interaction Solution for Ego4D Social Interaction Challenge, https://arxiv.org/pdf/2505.24404, 2025-05-30
2025-11-11 23:33:57,019 - INFO - root - Page:3, Index:42, Leadership Assessment in Pediatric Intensive Care Unit Team Training, https://arxiv.org/pdf/2505.24389, 2025-08-28
2025-11-11 23:33:57,020 - INFO - root - Page:3, Index:43, Interpreting Large Text-to-Image Diffusion Models with Dictionary Learning, https://arxiv.org/pdf/2505.24360, 2025-07-10
2025-11-11 23:33:57,021 - INFO - root - Page:3, Index:44, InteractAnything: Zero-shot Human Object Interaction Synthesis via LLM Feedback and Object Affordance Parsing, https://arxiv.org/pdf/2505.24315, 2025-05-30
2025-11-11 23:33:57,021 - INFO - root - Page:3, Index:45, MaskAdapt: Unsupervised Geometry-Aware Domain Adaptation Using Multimodal Contextual Learning and RGB-Depth Masking, https://arxiv.org/pdf/2505.24026, 2025-05-29
2025-11-11 23:33:57,021 - INFO - root - Page:3, Index:46, Argus: Vision-Centric Reasoning with Grounded Chain-of-Thought, https://arxiv.org/pdf/2505.23766, 2025-05-29
2025-11-11 23:33:57,022 - INFO - root - Page:3, Index:47, Sketch Down the FLOPs: Towards Efficient Networks for Human Sketch, https://arxiv.org/pdf/2505.23763, 2025-05-29
2025-11-11 23:33:57,022 - INFO - root - Page:3, Index:48, Boosting Domain Incremental Learning: Selecting the Optimal Parameters is All You Need, https://arxiv.org/pdf/2505.23744, 2025-05-29
2025-11-11 23:33:57,022 - INFO - root - Page:3, Index:49, DA-VPT: Semantic-Guided Visual Prompt Tuning for Vision Transformers, https://arxiv.org/pdf/2505.23694, 2025-06-01
2025-11-11 23:33:57,024 - INFO - root - Fetching page 5 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=200
2025-11-11 23:34:06,879 - INFO - root - get_all_titles_from_web 
2025-11-11 23:34:06,879 - INFO - root - Page:4, Index:0, Bridging Classical and Modern Computer Vision: PerceptiveNet for Tree Crown Semantic Segmentation, https://arxiv.org/pdf/2505.23597, 2025-05-29
2025-11-11 23:34:06,879 - INFO - root - Page:4, Index:1, Synthetic Generation and Latent Projection Denoising of Rim Lesions in Multiple Sclerosis, https://arxiv.org/pdf/2505.23353, 2025-05-29
2025-11-11 23:34:06,879 - INFO - root - Page:4, Index:2, Wav2Sem: Plug-and-Play Audio Semantic Decoupling for 3D Speech-Driven Facial Animation, https://arxiv.org/pdf/2505.23290, 2025-05-29
2025-11-11 23:34:06,879 - INFO - root - Page:4, Index:3, Proximal Algorithm Unrolling: Flexible and Efficient Reconstruction Networks for Single-Pixel Imaging, https://arxiv.org/pdf/2505.23180, 2025-05-29
2025-11-11 23:34:06,879 - INFO - root - Page:4, Index:4, HMAD: Advancing E2E Driving with Anchored Offset Proposals and Simulation-Supervised Multi-target Scoring, https://arxiv.org/pdf/2505.23129, 2025-05-29
2025-11-11 23:34:06,879 - INFO - root - Page:4, Index:5, URWKV: Unified RWKV Model with Multi-state Perspective for Low-light Image Restoration, https://arxiv.org/pdf/2505.23068, 2025-05-29
2025-11-11 23:34:06,879 - INFO - root - Page:4, Index:6, 4DTAM: Non-Rigid Tracking and Mapping via Dynamic Surface Gaussians, https://arxiv.org/pdf/2505.22859, 2025-05-28
2025-11-11 23:34:06,879 - INFO - root - Page:4, Index:7, A Probabilistic Jump-Diffusion Framework for Open-World Egocentric Activity Recognition, https://arxiv.org/pdf/2505.22858, 2025-05-28
2025-11-11 23:34:06,879 - INFO - root - Page:4, Index:8, PS4PRO: Pixel-to-pixel Supervision for Photorealistic Rendering and Optimization, https://arxiv.org/pdf/2505.22616, 2025-05-28
2025-11-11 23:34:06,879 - INFO - root - Page:4, Index:9, Universal Domain Adaptation for Semantic Segmentation, https://arxiv.org/pdf/2505.22458, 2025-06-05
2025-11-11 23:34:06,879 - INFO - root - Page:4, Index:10, Zero-Shot 3D Visual Grounding from Vision-Language Models, https://arxiv.org/pdf/2505.22429, 2025-05-28
2025-11-11 23:34:06,879 - INFO - root - Page:4, Index:11, RC-AutoCalib: An End-to-End Radar-Camera Automatic Calibration Network, https://arxiv.org/pdf/2505.22427, 2025-05-28
2025-11-11 23:34:06,879 - INFO - root - Page:4, Index:12, Bringing CLIP to the Clinic: Dynamic Soft Labels and Negation-Aware Learning for Medical Analysis, https://arxiv.org/pdf/2505.22079, 2025-05-28
2025-11-11 23:34:06,879 - INFO - root - Page:4, Index:13, Point-to-Region Loss for Semi-Supervised Point-Based Crowd Counting, https://arxiv.org/pdf/2505.21943, 2025-05-27
2025-11-11 23:34:06,879 - INFO - root - Page:4, Index:14, FRAMES-VQA: Benchmarking Fine-Tuning Robustness across Multi-Modal Shifts in Visual Question Answering, https://arxiv.org/pdf/2505.21755, 2025-06-20
2025-11-11 23:34:06,879 - INFO - root - Page:4, Index:15, Knowledge Distillation Approach for SOS Fusion Staging: Towards Fully Automated Skeletal Maturity Assessment, https://arxiv.org/pdf/2505.21561, 2025-05-26
2025-11-11 23:34:06,879 - INFO - root - Page:4, Index:16, Enhancing Vision Transformer Explainability Using Artificial Astrocytes, https://arxiv.org/pdf/2505.21513, 2025-05-20
2025-11-11 23:34:06,879 - INFO - root - Page:4, Index:17, Empowering Vector Graphics with Consistently Arbitrary Viewing and View-dependent Visibility, https://arxiv.org/pdf/2505.21377, 2025-05-27
2025-11-11 23:34:06,879 - INFO - root - Page:4, Index:18, Structure from Collision, https://arxiv.org/pdf/2505.21335, 2025-05-27
2025-11-11 23:34:06,879 - INFO - root - Page:4, Index:19, Boosting Adversarial Transferability via High-Frequency Augmentation and Hierarchical-Gradient Fusion, https://arxiv.org/pdf/2505.21181, 2025-05-27
2025-11-11 23:34:06,879 - INFO - root - Page:4, Index:20, RefAV: Towards Planning-Centric Scenario Mining, https://arxiv.org/pdf/2505.20981, 2025-06-18
2025-11-11 23:34:06,879 - INFO - root - Page:4, Index:21, PMA: Towards Parameter-Efficient Point Cloud Understanding via Point Mamba Adapter, https://arxiv.org/pdf/2505.20941, 2025-05-27
2025-11-11 23:34:06,879 - INFO - root - Page:4, Index:22, HuMoCon: Concept Discovery for Human Motion Understanding, https://arxiv.org/pdf/2505.20920, 2025-05-27
2025-11-11 23:34:06,879 - INFO - root - Page:4, Index:23, Exploring Timeline Control for Facial Motion Generation, https://arxiv.org/pdf/2505.20861, 2025-05-27
2025-11-11 23:34:06,888 - INFO - root - Page:4, Index:24, ConText-CIR: Learning from Concepts in Text for Composed Image Retrieval, https://arxiv.org/pdf/2505.20764, 2025-05-27
2025-11-11 23:34:06,889 - INFO - root - Page:4, Index:25, HCQA-1.5 @ Ego4D EgoSchema Challenge 2025, https://arxiv.org/pdf/2505.20644, 2025-05-26
2025-11-11 23:34:06,889 - INFO - root - Page:4, Index:26, Roboflow100-VL: A Multi-Domain Object Detection Benchmark for Vision-Language Models, https://arxiv.org/pdf/2505.20612, 2025-10-22
2025-11-11 23:34:06,890 - INFO - root - Page:4, Index:27, MotionPro: A Precise Motion Controller for Image-to-Video Generation, https://arxiv.org/pdf/2505.20287, 2025-05-26
2025-11-11 23:34:06,890 - INFO - root - Page:4, Index:28, Category-Agnostic Neural Object Rigging, https://arxiv.org/pdf/2505.20283, 2025-05-26
2025-11-11 23:34:06,890 - INFO - root - Page:4, Index:29, Towards Video to Piano Music Generation with Chain-of-Perform Support Benchmarks, https://arxiv.org/pdf/2505.20038, 2025-05-26
2025-11-11 23:34:06,891 - INFO - root - Page:4, Index:30, Can Visual Encoder Learn to See Arrows?, https://arxiv.org/pdf/2505.19944, 2025-05-26
2025-11-11 23:34:06,892 - INFO - root - Page:4, Index:31, GoLF-NRT: Integrating Global Context and Local Geometry for Few-Shot View Synthesis, https://arxiv.org/pdf/2505.19813, 2025-05-26
2025-11-11 23:34:06,892 - INFO - root - Page:4, Index:32, Depth-Guided Bundle Sampling for Efficient Generalizable Neural Radiance Field Reconstruction, https://arxiv.org/pdf/2505.19793, 2025-05-26
2025-11-11 23:34:06,894 - INFO - root - Page:4, Index:33, SuperAD: A Training-free Anomaly Classification and Segmentation Method for CVPR 2025 VAND 3.0 Workshop Challenge Track 1: Adapt & Detect, https://arxiv.org/pdf/2505.19750, 2025-05-27
2025-11-11 23:34:06,895 - INFO - root - Page:4, Index:34, Knowledge-Aligned Counterfactual-Enhancement Diffusion Perception for Unsupervised Cross-Domain Visual Emotion Recognition, https://arxiv.org/pdf/2505.19694, 2025-05-26
2025-11-11 23:34:06,897 - INFO - root - Page:4, Index:35, Rotation-Equivariant Self-Supervised Method in Image Denoising, https://arxiv.org/pdf/2505.19618, 2025-05-26
2025-11-11 23:34:06,899 - INFO - root - Page:4, Index:36, NTIRE 2025 Challenge on Video Quality Enhancement for Video Conferencing: Datasets, Methods and Results, https://arxiv.org/pdf/2505.18988, 2025-05-25
2025-11-11 23:34:06,900 - INFO - root - Page:4, Index:37, Geometry-guided Online 3D Video Synthesis with Multi-View Temporal Consistency, https://arxiv.org/pdf/2505.18932, 2025-05-24
2025-11-11 23:34:06,900 - INFO - root - Page:4, Index:38, Digital Overconsumption and Waste: A Closer Look at the Impacts of Generative AI, https://arxiv.org/pdf/2505.18894, 2025-05-24
2025-11-11 23:34:06,901 - INFO - root - Page:4, Index:39, VISTA: Vision-Language Inference for Training-Free Stock Time-Series Analysis, https://arxiv.org/pdf/2505.18570, 2025-06-11
2025-11-11 23:34:06,901 - INFO - root - Page:4, Index:40, Syn3DTxt: Embedding 3D Cues for Scene Text Generation, https://arxiv.org/pdf/2505.18479, 2025-05-23
2025-11-11 23:34:06,902 - INFO - root - Page:4, Index:41, CTRL-GS: Cascaded Temporal Residue Learning for 4D Gaussian Splatting, https://arxiv.org/pdf/2505.18306, 2025-05-31
2025-11-11 23:34:06,902 - INFO - root - Page:4, Index:42, DualTalk: Dual-Speaker Interaction for 3D Talking Head Conversations, https://arxiv.org/pdf/2505.18096, 2025-05-26
2025-11-11 23:34:06,902 - INFO - root - Page:4, Index:43, SeaLion: Semantic Part-Aware Latent Point Diffusion Models for 3D Generation, https://arxiv.org/pdf/2505.17721, 2025-07-07
2025-11-11 23:34:06,904 - INFO - root - Page:4, Index:44, PoseBH: Prototypical Multi-Dataset Training Beyond Human Pose Estimation, https://arxiv.org/pdf/2505.17475, 2025-05-23
2025-11-11 23:34:06,904 - INFO - root - Page:4, Index:45, Pursuing Temporal-Consistent Video Virtual Try-On via Dynamic Pose Interaction, https://arxiv.org/pdf/2505.16980, 2025-05-22
2025-11-11 23:34:06,905 - INFO - root - Page:4, Index:46, UniPhy: Learning a Unified Constitutive Model for Inverse Physics Simulation, https://arxiv.org/pdf/2505.16971, 2025-05-22
2025-11-11 23:34:06,906 - INFO - root - Page:4, Index:47, Tracking the Flight: Exploring a Computational Framework for Analyzing Escape Responses in Plains Zebra (Equus quagga), https://arxiv.org/pdf/2505.16882, 2025-05-23
2025-11-11 23:34:06,908 - INFO - root - Page:4, Index:48, Semi-Supervised State-Space Model with Dynamic Stacking Filter for Real-World Video Deraining, https://arxiv.org/pdf/2505.16811, 2025-05-22
2025-11-11 23:34:06,910 - INFO - root - Page:4, Index:49, SOLVE: Synergy of Language-Vision and End-to-End Networks for Autonomous Driving, https://arxiv.org/pdf/2505.16805, 2025-05-22
2025-11-11 23:34:06,910 - INFO - root - Fetching page 6 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=250
2025-11-11 23:34:21,503 - INFO - root - get_all_titles_from_web 
2025-11-11 23:34:21,503 - INFO - root - Page:5, Index:0, Four Eyes Are Better Than Two: Harnessing the Collaborative Potential of Large Models via Differentiated Thinking and Complementary Ensembles, https://arxiv.org/pdf/2505.16784, 2025-06-07
2025-11-11 23:34:21,503 - INFO - root - Page:5, Index:1, Single Domain Generalization for Few-Shot Counting via Universal Representation Matching, https://arxiv.org/pdf/2505.16778, 2025-05-22
2025-11-11 23:34:21,505 - INFO - root - Page:5, Index:2, Seeing Far and Clearly: Mitigating Hallucinations in MLLMs with Attention Causal Decoding, https://arxiv.org/pdf/2505.16652, 2025-06-07
2025-11-11 23:34:21,505 - INFO - root - Page:5, Index:3, Sketchy Bounding-box Supervision for 3D Instance Segmentation, https://arxiv.org/pdf/2505.16399, 2025-05-22
2025-11-11 23:34:21,505 - INFO - root - Page:5, Index:4, DeCafNet: Delegate and Conquer for Efficient Temporal Grounding in Long Videos, https://arxiv.org/pdf/2505.16376, 2025-05-22
2025-11-11 23:34:21,505 - INFO - root - Page:5, Index:5, NTIRE 2025 challenge on Text to Image Generation Model Quality Assessment, https://arxiv.org/pdf/2505.16314, 2025-05-22
2025-11-11 23:34:21,506 - INFO - root - Page:5, Index:6, Analyzing Hierarchical Structure in Vision Models with Sparse Autoencoders, https://arxiv.org/pdf/2505.15970, 2025-05-21
2025-11-11 23:34:21,506 - INFO - root - Page:5, Index:7, Efficient Data Driven Mixture-of-Expert Extraction from Trained Networks, https://arxiv.org/pdf/2505.15414, 2025-05-21
2025-11-11 23:34:21,507 - INFO - root - Page:5, Index:8, Mouse Lockbox Dataset: Behavior Recognition for Mice Solving Lockboxes, https://arxiv.org/pdf/2505.15408, 2025-06-17
2025-11-11 23:34:21,508 - INFO - root - Page:5, Index:9, Zero-Shot Gaze-based Volumetric Medical Image Segmentation, https://arxiv.org/pdf/2505.15256, 2025-06-10
2025-11-11 23:34:21,508 - INFO - root - Page:5, Index:10, Dual Precision Quantization for Efficient and Accurate Deep Neural Networks Inference, https://arxiv.org/pdf/2505.14638, 2025-05-20
2025-11-11 23:34:21,508 - INFO - root - Page:5, Index:11, Neural Video Compression with Context Modulation, https://arxiv.org/pdf/2505.14541, 2025-05-20
2025-11-11 23:34:21,509 - INFO - root - Page:5, Index:12, Selective Structured State Space for Multispectral-fused Small Target Detection, https://arxiv.org/pdf/2505.14043, 2025-05-23
2025-11-11 23:34:21,509 - INFO - root - Page:5, Index:13, OmniStyle: Filtering High Quality Style Transfer Data at Scale, https://arxiv.org/pdf/2505.14028, 2025-05-20
2025-11-11 23:34:21,510 - INFO - root - Page:5, Index:14, Domain Adaptation of VLM for Soccer Video Understanding, https://arxiv.org/pdf/2505.13860, 2025-07-07
2025-11-11 23:34:21,511 - INFO - root - Page:5, Index:15, Ground-V: Teaching VLMs to Ground Complex Instructions in Pixels, https://arxiv.org/pdf/2505.13788, 2025-05-19
2025-11-11 23:34:21,512 - INFO - root - Page:5, Index:16, FinePhys: Fine-grained Human Action Generation by Explicitly Incorporating Physical Laws for Effective Skeletal Guidance, https://arxiv.org/pdf/2505.13437, 2025-05-19
2025-11-11 23:34:21,512 - INFO - root - Page:5, Index:17, The Way Up: A Dataset for Hold Usage Detection in Sport Climbing, https://arxiv.org/pdf/2505.12854, 2025-05-19
2025-11-11 23:34:21,513 - INFO - root - Page:5, Index:18, PEER pressure: Model-to-Model Regularization for Single Source Domain Generalization, https://arxiv.org/pdf/2505.12745, 2025-05-19
2025-11-11 23:34:21,513 - INFO - root - Page:5, Index:19, Mamba-Adaptor: State Space Model Adaptor for Visual Recognition, https://arxiv.org/pdf/2505.12685, 2025-05-19
2025-11-11 23:34:21,514 - INFO - root - Page:5, Index:20, Scalable Video-to-Dataset Generation for Cross-Platform Mobile Agents, https://arxiv.org/pdf/2505.12632, 2025-05-18
2025-11-11 23:34:21,515 - INFO - root - Page:5, Index:21, Degradation-Aware Feature Perturbation for All-in-One Image Restoration, https://arxiv.org/pdf/2505.12630, 2025-05-18
2025-11-11 23:34:21,515 - INFO - root - Page:5, Index:22, Guiding Diffusion with Deep Geometric Moments: Balancing Fidelity and Variation, https://arxiv.org/pdf/2505.12486, 2025-05-18
2025-11-11 23:34:21,516 - INFO - root - Page:5, Index:23, Learning to Highlight Audio by Watching Movies, https://arxiv.org/pdf/2505.12154, 2025-05-17
2025-11-11 23:34:21,523 - INFO - root - Page:5, Index:24, Understanding the Capabilities of Molecular Graph Neural Networks in Materials Science Through Multimodal Learning and Physical Context Encoding, https://arxiv.org/pdf/2505.12137, 2025-05-17
2025-11-11 23:34:21,524 - INFO - root - Page:5, Index:25, iSegMan: Interactive Segment-and-Manipulate 3D Gaussians, https://arxiv.org/pdf/2505.11934, 2025-05-17
2025-11-11 23:34:21,524 - INFO - root - Page:5, Index:26, Self-Learning Hyperspectral and Multispectral Image Fusion via Adaptive Residual Guided Subspace Diffusion Model, https://arxiv.org/pdf/2505.11800, 2025-05-16
2025-11-11 23:34:21,525 - INFO - root - Page:5, Index:27, X-Edit: Detecting and Localizing Edits in Images Altered by Text-Guided Diffusion Models, https://arxiv.org/pdf/2505.11753, 2025-05-16
2025-11-11 23:34:21,525 - INFO - root - Page:5, Index:28, MTevent: A Multi-Task Event Camera Dataset for 6D Pose Estimation and Moving Object Detection, https://arxiv.org/pdf/2505.11282, 2025-06-02
2025-11-11 23:34:21,526 - INFO - root - Page:5, Index:29, Imputation-free and Alignment-free: Incomplete Multi-view Clustering Driven by Consensus Semantic Learning, https://arxiv.org/pdf/2505.11182, 2025-05-16
2025-11-11 23:34:21,526 - INFO - root - Page:5, Index:30, MultiLink: Multi-class Structure Recovery via Agglomerative Clustering and Model Selection, https://arxiv.org/pdf/2505.10874, 2025-05-16
2025-11-11 23:34:21,527 - INFO - root - Page:5, Index:31, RefPose: Leveraging Reference Geometric Correspondences for Accurate 6D Pose Estimation of Unseen Objects, https://arxiv.org/pdf/2505.10841, 2025-05-16
2025-11-11 23:34:21,534 - INFO - root - Page:5, Index:32, MoCLIP: Motion-Aware Fine-Tuning and Distillation of CLIP for Human Motion Generation, https://arxiv.org/pdf/2505.10810, 2025-05-15
2025-11-11 23:34:21,534 - INFO - root - Page:5, Index:33, Automated Detection of Salvin's Albatrosses: Improving Deep Learning Tools for Aerial Wildlife Surveys, https://arxiv.org/pdf/2505.10737, 2025-05-15
2025-11-11 23:34:21,535 - INFO - root - Page:5, Index:34, Advancing Multiple Instance Learning with Continual Learning for Whole Slide Imaging, https://arxiv.org/pdf/2505.10649, 2025-05-15
2025-11-11 23:34:21,535 - INFO - root - Page:5, Index:35, Inferring Driving Maps by Deep Learning-based Trail Map Extraction, https://arxiv.org/pdf/2505.10258, 2025-05-15
2025-11-11 23:34:21,535 - INFO - root - Page:5, Index:36, Behind Maya: Building a Multilingual Vision Language Model, https://arxiv.org/pdf/2505.08910, 2025-05-15
2025-11-11 23:34:21,536 - INFO - root - Page:5, Index:37, PosterO: Structuring Layout Trees to Enable Language Models in Generalized Content-Aware Layout Generation, https://arxiv.org/pdf/2505.07843, 2025-05-26
2025-11-11 23:34:21,536 - INFO - root - Page:5, Index:38, Prototype Augmented Hypernetworks for Continual Learning, https://arxiv.org/pdf/2505.07450, 2025-05-16
2025-11-11 23:34:21,536 - INFO - root - Fetching page 7 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=300
2025-11-11 23:34:30,230 - INFO - root - get_all_titles_from_web 
2025-11-11 23:34:30,230 - INFO - root - Page:6, Index:0, Convex Relaxation for Robust Vanishing Point Estimation in Manhattan World, https://arxiv.org/pdf/2505.04788, 2025-06-05
2025-11-11 23:34:30,230 - INFO - root - Page:6, Index:1, S3D: Sketch-Driven 3D Model Generation, https://arxiv.org/pdf/2505.04185, 2025-06-03
2025-11-11 23:34:30,231 - INFO - root - Page:6, Index:2, Generating Synthetic Data via Augmentations for Improved Facial Resemblance in DreamBooth and InstantID, https://arxiv.org/pdf/2505.03557, 2025-07-17
2025-11-11 23:34:30,231 - INFO - root - Page:6, Index:3, CAV-MAE Sync: Improving Contrastive Audio-Visual Mask Autoencoders via Fine-Grained Alignment, https://arxiv.org/pdf/2505.01237, 2025-05-21
2025-11-11 23:34:30,231 - INFO - root - Fetching page 8 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=350
2025-11-11 23:34:38,416 - INFO - root - get_all_titles_from_web 
2025-11-11 23:34:38,417 - INFO - root - Page:7, Index:0, Where's the liability in the Generative Era? Recovery-based Black-Box Detection of AI-Generated Content, https://arxiv.org/pdf/2505.01008, 2025-08-25
2025-11-11 23:34:38,417 - INFO - root - Page:7, Index:1, SpatialLLM: A Compound 3D-Informed Design towards Spatially-Intelligent Large Multimodal Models, https://arxiv.org/pdf/2505.00788, 2025-06-10
2025-11-11 23:34:38,418 - INFO - root - Page:7, Index:2, Prisma: An Open Source Toolkit for Mechanistic Interpretability in Vision and Video, https://arxiv.org/pdf/2504.19475, 2025-06-03
2025-11-11 23:34:38,418 - INFO - root - Page:7, Index:3, SSL4Eco: A Global Seasonal Dataset for Geospatial Foundation Models in Ecology, https://arxiv.org/pdf/2504.18256, 2025-10-20
2025-11-11 23:34:38,418 - INFO - root - Page:7, Index:4, Vision-Language Models Are Not Pragmatically Competent in Referring Expression Generation, https://arxiv.org/pdf/2504.16060, 2025-07-30
2025-11-11 23:34:38,419 - INFO - root - Fetching page 9 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=400
2025-11-11 23:34:47,609 - INFO - root - get_all_titles_from_web 
2025-11-11 23:34:47,609 - INFO - root - Page:8, Index:0, Leveraging Automatic CAD Annotations for Supervised Learning in 3D Scene Understanding, https://arxiv.org/pdf/2504.13580, 2025-05-16
2025-11-11 23:34:47,611 - INFO - root - Page:8, Index:1, CAP-Net: A Unified Network for 6D Pose and Size Estimation of Categorical Articulated Parts from a Single RGB-D Image, https://arxiv.org/pdf/2504.11230, 2025-06-02
2025-11-11 23:34:47,611 - INFO - root - Page:8, Index:2, Video Summarization with Large Language Models, https://arxiv.org/pdf/2504.11199, 2025-06-05
2025-11-11 23:34:47,613 - INFO - root - Page:8, Index:3, R-TPT: Improving Adversarial Robustness of Vision-Language Models through Test-Time Prompt Tuning, https://arxiv.org/pdf/2504.11195, 2025-08-27
2025-11-11 23:34:47,614 - INFO - root - Page:8, Index:4, TerraMesh: A Planetary Mosaic of Multimodal Earth Observation Data, https://arxiv.org/pdf/2504.11172, 2025-08-01
2025-11-11 23:34:47,615 - INFO - root - Page:8, Index:5, Seeing like a Cephalopod: Colour Vision with a Monochrome Event Camera, https://arxiv.org/pdf/2504.10984, 2025-06-06
2025-11-11 23:34:47,616 - INFO - root - Page:8, Index:6, Hearing Anywhere in Any Environment, https://arxiv.org/pdf/2504.10746, 2025-06-04
2025-11-11 23:34:47,617 - INFO - root - Fetching page 10 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=450
2025-11-11 23:34:56,990 - INFO - root - get_all_titles_from_web 
2025-11-11 23:34:56,990 - INFO - root - Page:9, Index:0, Correlative and Discriminative Label Grouping for Multi-Label Visual Prompt Tuning, https://arxiv.org/pdf/2504.09990, 2025-07-09
2025-11-11 23:34:56,991 - INFO - root - Page:9, Index:1, SPICE: A Synergistic, Precise, Iterative, and Customizable Image Editing Workflow, https://arxiv.org/pdf/2504.09697, 2025-10-16
2025-11-11 23:34:56,991 - INFO - root - Page:9, Index:2, Mimic In-Context Learning for Multimodal Tasks, https://arxiv.org/pdf/2504.08851, 2025-05-17
2025-11-11 23:34:56,991 - INFO - root - Page:9, Index:3, Digital Twin Catalog: A Large-Scale Photorealistic 3D Object Digital Twin Dataset, https://arxiv.org/pdf/2504.08541, 2025-05-18
2025-11-11 23:34:56,991 - INFO - root - Page:9, Index:4, MMLA: Multi-Environment, Multi-Species, Low-Altitude Drone Dataset, https://arxiv.org/pdf/2504.07744, 2025-10-22
2025-11-11 23:34:56,993 - INFO - root - Fetching page 11 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=500
2025-11-11 23:35:06,788 - INFO - root - get_all_titles_from_web 
2025-11-11 23:35:06,788 - INFO - root - Page:10, Index:0, PromptHMR: Promptable Human Mesh Recovery, https://arxiv.org/pdf/2504.06397, 2025-05-23
2025-11-11 23:35:06,788 - INFO - root - Page:10, Index:1, SCAM: A Real-World Typographic Robustness Evaluation for Multimodal Foundation Models, https://arxiv.org/pdf/2504.04893, 2025-09-26
2025-11-11 23:35:06,788 - INFO - root - Fetching page 12 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=550
2025-11-11 23:35:15,358 - INFO - root - get_all_titles_from_web 
2025-11-11 23:35:15,359 - INFO - root - Page:11, Index:0, Charm: The Missing Piece in ViT fine-tuning for Image Aesthetic Assessment, https://arxiv.org/pdf/2504.02522, 2025-05-15
2025-11-11 23:35:15,359 - INFO - root - Page:11, Index:1, T*: Re-thinking Temporal Search for Long-Form Video Understanding, https://arxiv.org/pdf/2504.02259, 2025-08-24
2025-11-11 23:35:15,359 - INFO - root - Page:11, Index:2, CoMatcher: Multi-View Collaborative Feature Matching, https://arxiv.org/pdf/2504.01872, 2025-08-20
2025-11-11 23:35:15,360 - INFO - root - Page:11, Index:3, Think Small, Act Big: Primitive Prompt Learning for Lifelong Robot Manipulation, https://arxiv.org/pdf/2504.00420, 2025-06-01
2025-11-11 23:35:15,360 - INFO - root - Fetching page 13 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=600
2025-11-11 23:35:24,405 - INFO - root - get_all_titles_from_web 
2025-11-11 23:35:24,405 - INFO - root - Page:12, Index:0, It's a (Blind) Match! Towards Vision-Language Correspondence without Parallel Data, https://arxiv.org/pdf/2503.24129, 2025-05-29
2025-11-11 23:35:24,405 - INFO - root - Page:12, Index:1, ReferDINO-Plus: 2nd Solution for 4th PVUW MeViS Challenge at CVPR 2025, https://arxiv.org/pdf/2503.23509, 2025-05-29
2025-11-11 23:35:24,405 - INFO - root - Page:12, Index:2, A Unified Image-Dense Annotation Generation Model for Underwater Scenes, https://arxiv.org/pdf/2503.21771, 2025-07-27
2025-11-11 23:35:24,405 - INFO - root - Fetching page 14 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=650
2025-11-11 23:35:31,390 - INFO - root - get_all_titles_from_web 
2025-11-11 23:35:31,391 - INFO - root - Page:13, Index:0, Learning Class Prototypes for Unified Sparse Supervised 3D Object Detection, https://arxiv.org/pdf/2503.21099, 2025-06-13
2025-11-11 23:35:31,391 - INFO - root - Page:13, Index:1, LATTE-MV: Learning to Anticipate Table Tennis Hits from Monocular Videos, https://arxiv.org/pdf/2503.20936, 2025-09-01
2025-11-11 23:35:31,391 - INFO - root - Page:13, Index:2, BizGen: Advancing Article-level Visual Text Rendering for Infographics Generation, https://arxiv.org/pdf/2503.20672, 2025-07-02
2025-11-11 23:35:31,392 - INFO - root - Page:13, Index:3, ITA-MDT: Image-Timestep-Adaptive Masked Diffusion Transformer Framework for Image-Based Virtual Try-On, https://arxiv.org/pdf/2503.20418, 2025-06-01
2025-11-11 23:35:31,392 - INFO - root - Page:13, Index:4, Faster Parameter-Efficient Tuning with Token Redundancy Reduction, https://arxiv.org/pdf/2503.20282, 2025-08-26
2025-11-11 23:35:31,392 - INFO - root - Page:13, Index:5, DINeMo: Learning Neural Mesh Models with no 3D Annotations, https://arxiv.org/pdf/2503.20220, 2025-06-09
2025-11-11 23:35:31,392 - INFO - root - Page:13, Index:6, Scaling Vision Pre-Training to 4K Resolution, https://arxiv.org/pdf/2503.19903, 2025-08-03
2025-11-11 23:35:31,392 - INFO - root - Page:13, Index:7, GENIUS: A Generative Framework for Universal Multimodal Search, https://arxiv.org/pdf/2503.19868, 2025-06-05
2025-11-11 23:35:31,393 - INFO - root - Fetching page 15 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=700
2025-11-11 23:35:41,282 - INFO - root - get_all_titles_from_web 
2025-11-11 23:35:41,282 - INFO - root - Page:14, Index:0, Galaxy Walker: Geometry-aware VLMs For Galaxy-scale Understanding, https://arxiv.org/pdf/2503.18578, 2025-05-25
2025-11-11 23:35:41,284 - INFO - root - Page:14, Index:1, LookCloser: Frequency-aware Radiance Field for Tiny-Detail Scene, https://arxiv.org/pdf/2503.18513, 2025-07-29
2025-11-11 23:35:41,284 - INFO - root - Fetching page 16 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=750
2025-11-11 23:35:50,534 - INFO - root - get_all_titles_from_web 
2025-11-11 23:35:50,534 - INFO - root - Page:15, Index:0, LoTUS: Large-Scale Machine Unlearning with a Taste of Uncertainty, https://arxiv.org/pdf/2503.18314, 2025-05-29
2025-11-11 23:35:50,535 - INFO - root - Page:15, Index:1, MammAlps: A multi-view video behavior monitoring dataset of wild mammals in the Swiss Alps, https://arxiv.org/pdf/2503.18223, 2025-06-04
2025-11-11 23:35:50,535 - INFO - root - Page:15, Index:2, Progressive Prompt Detailing for Improved Alignment in Text-to-Image Generative Models, https://arxiv.org/pdf/2503.17794, 2025-05-30
2025-11-11 23:35:50,535 - INFO - root - Page:15, Index:3, CountLLM: Towards Generalizable Repetitive Action Counting via Large Language Model, https://arxiv.org/pdf/2503.17690, 2025-06-29
2025-11-11 23:35:50,535 - INFO - root - Page:15, Index:4, TaoAvatar: Real-Time Lifelike Full-Body Talking Avatars for Augmented Reality via 3D Gaussian Splatting, https://arxiv.org/pdf/2503.17032, 2025-07-23
2025-11-11 23:35:50,535 - INFO - root - Page:15, Index:5, Generalized Few-shot 3D Point Cloud Segmentation with Vision-Language Model, https://arxiv.org/pdf/2503.16282, 2025-05-20
2025-11-11 23:35:50,535 - INFO - root - Fetching page 17 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=800
2025-11-11 23:36:01,199 - INFO - root - get_all_titles_from_web 
2025-11-11 23:36:01,199 - INFO - root - Page:16, Index:0, High Temporal Consistency through Semantic Similarity Propagation in Semi-Supervised Video Semantic Segmentation for Autonomous Flight, https://arxiv.org/pdf/2503.15676, 2025-06-26
2025-11-11 23:36:01,199 - INFO - root - Page:16, Index:1, DPFlow: Adaptive Optical Flow Estimation with a Dual-Pyramid Framework, https://arxiv.org/pdf/2503.14880, 2025-09-29
2025-11-11 23:36:01,199 - INFO - root - Fetching page 18 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=850
2025-11-11 23:36:08,706 - INFO - root - get_all_titles_from_web 
2025-11-11 23:36:08,706 - INFO - root - Page:17, Index:0, From Head to Tail: Towards Balanced Representation in Large Vision-Language Models through Adaptive Data Calibration, https://arxiv.org/pdf/2503.12821, 2025-05-29
2025-11-11 23:36:08,707 - INFO - root - Page:17, Index:1, MambaIC: State Space Models for High-Performance Learned Image Compression, https://arxiv.org/pdf/2503.12461, 2025-08-22
2025-11-11 23:36:08,707 - INFO - root - Page:17, Index:2, Localized Concept Erasure for Text-to-Image Diffusion Models Using Training-Free Gated Low-Rank Adaptation, https://arxiv.org/pdf/2503.12356, 2025-07-09
2025-11-11 23:36:08,707 - INFO - root - Page:17, Index:3, TASTE-Rob: Advancing Video Generation of Task-Oriented Hand-Object Interaction for Generalizable Robotic Manipulation, https://arxiv.org/pdf/2503.11423, 2025-06-05
2025-11-11 23:36:08,707 - INFO - root - Page:17, Index:4, Panopticon: Advancing Any-Sensor Foundation Models for Earth Observation, https://arxiv.org/pdf/2503.10845, 2025-08-01
2025-11-11 23:36:08,707 - INFO - root - Page:17, Index:5, Transformers without Normalization, https://arxiv.org/pdf/2503.10622, 2025-06-14
2025-11-11 23:36:08,708 - INFO - root - Page:17, Index:6, dFLMoE: Decentralized Federated Learning via Mixture of Experts for Medical Data Analysis, https://arxiv.org/pdf/2503.10412, 2025-05-19
2025-11-11 23:36:08,708 - INFO - root - Fetching page 19 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=900
2025-11-11 23:36:19,545 - INFO - root - get_all_titles_from_web 
2025-11-11 23:36:19,545 - INFO - root - Page:18, Index:0, Project-Probe-Aggregate: Efficient Fine-Tuning for Group Robustness, https://arxiv.org/pdf/2503.09487, 2025-08-26
2025-11-11 23:36:19,545 - INFO - root - Page:18, Index:1, VLog: Video-Language Models by Generative Retrieval of Narration Vocabulary, https://arxiv.org/pdf/2503.09402, 2025-06-09
2025-11-11 23:36:19,545 - INFO - root - Fetching page 20 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=950
2025-11-11 23:36:29,778 - INFO - root - get_all_titles_from_web 
2025-11-11 23:36:29,778 - INFO - root - Page:19, Index:0, Escaping Plato's Cave: Towards the Alignment of 3D and Text Latent Spaces, https://arxiv.org/pdf/2503.05283, 2025-06-04
2025-11-11 23:36:29,779 - INFO - root - Page:19, Index:1, FluidNexus: 3D Fluid Reconstruction and Prediction from a Single Video, https://arxiv.org/pdf/2503.04720, 2025-07-09
2025-11-11 23:36:29,779 - INFO - root - Page:19, Index:2, Question-Aware Gaussian Experts for Audio-Visual Question Answering, https://arxiv.org/pdf/2503.04459, 2025-06-11
2025-11-11 23:36:29,779 - INFO - root - Page:19, Index:3, Q-Eval-100K: Evaluating Visual Quality and Alignment Level for Text-to-Vision Content, https://arxiv.org/pdf/2503.02357, 2025-06-15
2025-11-11 23:36:29,780 - INFO - root - Fetching page 21 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=1000
2025-11-11 23:36:38,865 - INFO - root - get_all_titles_from_web 
2025-11-11 23:36:38,865 - INFO - root - Page:20, Index:0, Data Distributional Properties As Inductive Bias for Systematic Generalization, https://arxiv.org/pdf/2502.20499, 2025-06-17
2025-11-11 23:36:38,865 - INFO - root - Page:20, Index:1, Knowledge Bridger: Towards Training-free Missing Modality Completion, https://arxiv.org/pdf/2502.19834, 2025-06-17
2025-11-11 23:36:38,865 - INFO - root - Fetching page 22 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=1050
2025-11-11 23:36:49,367 - INFO - root - get_all_titles_from_web 
2025-11-11 23:36:49,367 - INFO - root - Page:21, Index:0, MALT Diffusion: Memory-Augmented Latent Transformers for Any-Length Video Generation, https://arxiv.org/pdf/2502.12632, 2025-07-08
2025-11-11 23:36:49,368 - INFO - root - Page:21, Index:1, ILIAS: Instance-Level Image retrieval At Scale, https://arxiv.org/pdf/2502.11748, 2025-06-23
2025-11-11 23:36:49,368 - INFO - root - Page:21, Index:2, Distraction is All You Need for Multimodal Large Language Model Jailbreaking, https://arxiv.org/pdf/2502.10794, 2025-06-16
2025-11-11 23:36:49,369 - INFO - root - Page:21, Index:3, Spatial457: A Diagnostic Benchmark for 6D Spatial Reasoning of Large Multimodal Models, https://arxiv.org/pdf/2502.08636, 2025-06-08
2025-11-11 23:36:49,369 - INFO - root - Page:21, Index:4, TRAVEL: Training-Free Retrieval and Alignment for Vision-and-Language Navigation, https://arxiv.org/pdf/2502.07306, 2025-06-09
2025-11-11 23:36:49,369 - INFO - root - Page:21, Index:5, DiTASK: Multi-Task Fine-Tuning with Diffeomorphic Transformations, https://arxiv.org/pdf/2502.06029, 2025-06-01
2025-11-11 23:36:49,369 - INFO - root - Page:21, Index:6, ConceptAttention: Diffusion Transformers Learn Highly Interpretable Features, https://arxiv.org/pdf/2502.04320, 2025-07-01
2025-11-11 23:36:49,369 - INFO - root - Page:21, Index:7, GCE-Pose: Global Context Enhancement for Category-level Object Pose Estimation, https://arxiv.org/pdf/2502.04293, 2025-06-24
2025-11-11 23:36:49,369 - INFO - root - Page:21, Index:8, Calibrated Multi-Preference Optimization for Aligning Diffusion Models, https://arxiv.org/pdf/2502.02588, 2025-09-26
2025-11-11 23:36:49,369 - INFO - root - Page:21, Index:9, Instruct-4DGS: Efficient Dynamic Scene Editing via 4D Gaussian-based Static-Dynamic Separation, https://arxiv.org/pdf/2502.02091, 2025-07-01
2025-11-11 23:36:49,372 - INFO - root - Page:21, Index:10, Low-Resource Video Super-Resolution using Memory, Wavelets, and Deformable Convolutions, https://arxiv.org/pdf/2502.01816, 2025-06-19
2025-11-11 23:36:49,372 - INFO - root - Page:21, Index:11, Bridging Text and Crystal Structures: Literature-driven Contrastive Learning for Materials Science, https://arxiv.org/pdf/2501.12919, 2025-06-18
2025-11-11 23:36:49,372 - INFO - root - Page:21, Index:12, T2ISafety: Benchmark for Assessing Fairness, Toxicity, and Privacy in Image Generation, https://arxiv.org/pdf/2501.12612, 2025-07-25
2025-11-11 23:36:49,372 - INFO - root - Page:21, Index:13, Fine-Grained Image-Text Correspondence with Cost Aggregation for Open-Vocabulary Part Segmentation, https://arxiv.org/pdf/2501.09688, 2025-08-08
2025-11-11 23:36:49,372 - INFO - root - Fetching page 23 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=1100
2025-11-11 23:37:01,009 - INFO - root - get_all_titles_from_web 
2025-11-11 23:37:01,010 - INFO - root - Page:22, Index:0, Bias for Action: Video Implicit Neural Representations with Bias Modulation, https://arxiv.org/pdf/2501.09277, 2025-06-06
2025-11-11 23:37:01,010 - INFO - root - Page:22, Index:1, MonSter++: Unified Stereo Matching, Multi-view Stereo, and Real-time Stereo with Monodepth Priors, https://arxiv.org/pdf/2501.08643, 2025-09-25
2025-11-11 23:37:01,010 - INFO - root - Page:22, Index:2, Go-with-the-Flow: Motion-Controllable Video Diffusion Models Using Real-Time Warped Noise, https://arxiv.org/pdf/2501.08331, 2025-08-06
2025-11-11 23:37:01,010 - INFO - root - Page:22, Index:3, Nonisotropic Gaussian Diffusion for Realistic 3D Human Motion Prediction, https://arxiv.org/pdf/2501.06035, 2025-07-08
2025-11-11 23:37:01,010 - INFO - root - Page:22, Index:4, Discovering Hidden Visual Concepts Beyond Linguistic Input in Infant Learning, https://arxiv.org/pdf/2501.05205, 2025-06-13
2025-11-11 23:37:01,010 - INFO - root - Page:22, Index:5, PERSE: Personalized 3D Generative Avatars from A Single Portrait, https://arxiv.org/pdf/2412.21206, 2025-09-28
2025-11-11 23:37:01,012 - INFO - root - Page:22, Index:6, MaskGaussian: Adaptive 3D Gaussian Representation from Probabilistic Masks, https://arxiv.org/pdf/2412.20522, 2025-06-14
2025-11-11 23:37:01,013 - INFO - root - Page:22, Index:7, SimLTD: Simple Supervised and Semi-Supervised Long-Tailed Object Detection, https://arxiv.org/pdf/2412.20047, 2025-06-09
2025-11-11 23:37:01,013 - INFO - root - Page:22, Index:8, Conditional Balance: Improving Multi-Conditioning Trade-Offs in Image Generation, https://arxiv.org/pdf/2412.19853, 2025-08-03
2025-11-11 23:37:01,013 - INFO - root - Fetching page 24 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=1150
2025-11-11 23:37:12,627 - INFO - root - get_all_titles_from_web 
2025-11-11 23:37:12,627 - INFO - root - Page:23, Index:0, CoCoGaussian: Leveraging Circle of Confusion for Gaussian Splatting from Defocused Images, https://arxiv.org/pdf/2412.16028, 2025-05-15
2025-11-11 23:37:12,628 - INFO - root - Page:23, Index:1, EnergyMoGen: Compositional Human Motion Generation with Energy-Based Diffusion Model in Latent Space, https://arxiv.org/pdf/2412.14706, 2025-06-04
2025-11-11 23:37:12,628 - INFO - root - Page:23, Index:2, DarkIR: Robust Low-Light Image Restoration, https://arxiv.org/pdf/2412.13443, 2025-10-14
2025-11-11 23:37:12,628 - INFO - root - Page:23, Index:3, FastVLM: Efficient Vision Encoding for Vision Language Models, https://arxiv.org/pdf/2412.13303, 2025-05-15
2025-11-11 23:37:12,628 - INFO - root - Page:23, Index:4, Real-time Free-view Human Rendering from Sparse-view RGB Videos using Double Unprojected Textures, https://arxiv.org/pdf/2412.13183, 2025-06-20
2025-11-11 23:37:12,629 - INFO - root - Page:23, Index:5, CondiMen: Conditional Multi-Person Mesh Recovery, https://arxiv.org/pdf/2412.13058, 2025-06-04
2025-11-11 23:37:12,629 - INFO - root - Page:23, Index:6, MASt3R-SLAM: Real-Time Dense SLAM with 3D Reconstruction Priors, https://arxiv.org/pdf/2412.12392, 2025-06-02
2025-11-11 23:37:12,629 - INFO - root - Page:23, Index:7, DynamicScaler: Seamless and Scalable Video Generation for Panoramic Scenes, https://arxiv.org/pdf/2412.11100, 2025-10-04
2025-11-11 23:37:12,629 - INFO - root - Page:23, Index:8, SnapGen-V: Generating a Five-Second Video within Five Seconds on a Mobile Device, https://arxiv.org/pdf/2412.10494, 2025-06-09
2025-11-11 23:37:12,630 - INFO - root - Page:23, Index:9, Mr. DETR++: Instructive Multi-Route Training for Detection Transformers with Mixture-of-Experts, https://arxiv.org/pdf/2412.10028, 2025-06-26
2025-11-11 23:37:12,630 - INFO - root - Page:23, Index:10, LinGen: Towards High-Resolution Minute-Length Text-to-Video Generation with Linear Computational Complexity, https://arxiv.org/pdf/2412.09856, 2025-05-24
2025-11-11 23:37:12,630 - INFO - root - Page:23, Index:11, Gaze-LLE: Gaze Target Estimation via Large-Scale Learned Encoders, https://arxiv.org/pdf/2412.09586, 2025-06-03
2025-11-11 23:37:12,630 - INFO - root - Fetching page 25 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=1200
2025-11-11 23:37:22,795 - INFO - root - get_all_titles_from_web 
2025-11-11 23:37:22,795 - INFO - root - Page:24, Index:0, From Slow Bidirectional to Fast Autoregressive Video Diffusion Models, https://arxiv.org/pdf/2412.07772, 2025-09-23
2025-11-11 23:37:22,795 - INFO - root - Page:24, Index:1, Rate-In: Information-Driven Adaptive Dropout Rates for Improved Inference-Time Uncertainty Estimation, https://arxiv.org/pdf/2412.07169, 2025-06-03
2025-11-11 23:37:22,795 - INFO - root - Page:24, Index:2, FIRE: Robust Detection of Diffusion-Generated Images via Frequency-Guided Reconstruction Error, https://arxiv.org/pdf/2412.07140, 2025-11-03
2025-11-11 23:37:22,795 - INFO - root - Page:24, Index:3, Birth and Death of a Rose, https://arxiv.org/pdf/2412.05278, 2025-06-05
2025-11-11 23:37:22,795 - INFO - root - Page:24, Index:4, DualPM: Dual Posed-Canonical Point Maps for 3D Shape and Pose Reconstruction, https://arxiv.org/pdf/2412.04464, 2025-08-14
2025-11-11 23:37:22,795 - INFO - root - Page:24, Index:5, SeeGround: See and Ground for Zero-Shot Open-Vocabulary 3D Visual Grounding, https://arxiv.org/pdf/2412.04383, 2025-05-29
2025-11-11 23:37:22,795 - INFO - root - ------------------------------------------------------------------------------------------------------------------------
2025-11-11 23:37:46,346 - INFO - root - 正在总结论文 1/2: Learning to Seek Evidence: A Verifiable Reasoning Agent with Causal Faithfulness Analysis
2025-11-11 23:38:37,471 - INFO - root - LLMClient: rate limit reached, sleeping 8.9s
2025-11-11 23:39:47,471 - INFO - root - 正在提取论文图片...
2025-11-11 23:39:47,566 - INFO - root - 已保存图片 1/10：./export\QCVPR 2025\images\figure_1_page2.jpeg
2025-11-11 23:39:47,586 - INFO - root - 已保存图片 2/10：./export\QCVPR 2025\images\figure_2_page2.jpeg
2025-11-11 23:39:47,591 - INFO - root - 已保存图片 3/10：./export\QCVPR 2025\images\figure_3_page2.jpeg
2025-11-11 23:39:47,601 - INFO - root - 已保存图片 4/10：./export\QCVPR 2025\images\figure_4_page2.jpeg
2025-11-11 23:39:47,607 - INFO - root - 已保存图片 5/10：./export\QCVPR 2025\images\figure_5_page2.jpeg
2025-11-11 23:39:47,617 - INFO - root - 已保存图片 6/10：./export\QCVPR 2025\images\figure_6_page2.jpeg
2025-11-11 23:39:47,625 - INFO - root - 已保存图片 7/10：./export\QCVPR 2025\images\figure_7_page2.jpeg
2025-11-11 23:39:47,631 - INFO - root - 已保存图片 8/10：./export\QCVPR 2025\images\figure_8_page2.jpeg
2025-11-11 23:39:47,678 - INFO - root - 已保存图片 9/10：./export\QCVPR 2025\images\figure_9_page2.jpeg
2025-11-11 23:39:47,699 - INFO - root - 已保存图片 10/10：./export\QCVPR 2025\images\figure_10_page2.jpeg
2025-11-11 23:39:47,704 - INFO - root - 成功添加图片 1：./export\QCVPR 2025\images\figure_1_page2.jpeg
2025-11-11 23:39:47,708 - INFO - root - 成功添加图片 2：./export\QCVPR 2025\images\figure_2_page2.jpeg
2025-11-11 23:39:47,710 - INFO - root - 成功添加图片 3：./export\QCVPR 2025\images\figure_3_page2.jpeg
2025-11-11 23:39:47,716 - INFO - root - 成功添加图片 4：./export\QCVPR 2025\images\figure_4_page2.jpeg
2025-11-11 23:39:47,718 - INFO - root - 成功添加图片 5：./export\QCVPR 2025\images\figure_5_page2.jpeg
2025-11-11 23:39:47,722 - INFO - root - 成功添加图片 6：./export\QCVPR 2025\images\figure_6_page2.jpeg
2025-11-11 23:39:47,724 - INFO - root - 成功添加图片 7：./export\QCVPR 2025\images\figure_7_page2.jpeg
2025-11-11 23:39:47,727 - INFO - root - 成功添加图片 8：./export\QCVPR 2025\images\figure_8_page2.jpeg
2025-11-11 23:39:47,730 - INFO - root - 成功添加图片 9：./export\QCVPR 2025\images\figure_9_page2.jpeg
2025-11-11 23:39:47,738 - INFO - root - 成功添加图片 10：./export\QCVPR 2025\images\figure_10_page2.jpeg
2025-11-11 23:39:47,739 - WARNING - root - 图片文件不存在: images/figure_10_page2.jpeg
2025-11-11 23:39:47,742 - WARNING - root - 图片在任何位置都不存在: figure_10_page2.jpeg
2025-11-11 23:39:47,742 - WARNING - root - 图片文件不存在: images/figure_9_page2.jpeg
2025-11-11 23:39:47,743 - WARNING - root - 图片在任何位置都不存在: figure_9_page2.jpeg
2025-11-11 23:39:47,743 - WARNING - root - 图片文件不存在: images/figure_8_page2.jpeg
2025-11-11 23:39:47,743 - WARNING - root - 图片在任何位置都不存在: figure_8_page2.jpeg
2025-11-11 23:39:47,743 - WARNING - root - 图片文件不存在: images/figure_7_page2.jpeg
2025-11-11 23:39:47,743 - WARNING - root - 图片在任何位置都不存在: figure_7_page2.jpeg
2025-11-11 23:39:47,743 - WARNING - root - 图片文件不存在: images/figure_6_page2.jpeg
2025-11-11 23:39:47,743 - WARNING - root - 图片在任何位置都不存在: figure_6_page2.jpeg
2025-11-11 23:39:47,743 - WARNING - root - 图片文件不存在: images/figure_5_page2.jpeg
2025-11-11 23:39:47,743 - WARNING - root - 图片在任何位置都不存在: figure_5_page2.jpeg
2025-11-11 23:39:47,743 - WARNING - root - 图片文件不存在: images/figure_4_page2.jpeg
2025-11-11 23:39:47,743 - WARNING - root - 图片在任何位置都不存在: figure_4_page2.jpeg
2025-11-11 23:39:47,747 - WARNING - root - 图片文件不存在: images/figure_3_page2.jpeg
2025-11-11 23:39:47,747 - WARNING - root - 图片在任何位置都不存在: figure_3_page2.jpeg
2025-11-11 23:39:47,747 - WARNING - root - 图片文件不存在: images/figure_2_page2.jpeg
2025-11-11 23:39:47,748 - WARNING - root - 图片在任何位置都不存在: figure_2_page2.jpeg
2025-11-11 23:39:47,748 - WARNING - root - 图片文件不存在: images/figure_1_page2.jpeg
2025-11-11 23:39:47,750 - WARNING - root - 图片在任何位置都不存在: figure_1_page2.jpeg
2025-11-11 23:39:47,750 - INFO - root - 已按文献标题重新组织图片存储
2025-11-11 23:39:47,755 - INFO - root - 论文《Learning to Seek Evidence: A Verifiable Reasoning Agent with Causal Faithfulness Analysis》的分析已保存到 ./export\QCVPR 2025\Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness.md
2025-11-11 23:39:47,762 - INFO - root - 正在总结论文 2/2: OmniTrack++: Omnidirectional Multi-Object Tracking by Learning Large-FoV Trajectory Feedback
2025-11-11 23:43:40,935 - INFO - root - 正在提取论文图片...
2025-11-11 23:43:41,333 - INFO - root - 已保存图片 1/10：./export\QCVPR 2025\images\figure_1_page13.jpeg
2025-11-11 23:43:41,387 - INFO - root - 已保存图片 2/10：./export\QCVPR 2025\images\figure_2_page13.jpeg
2025-11-11 23:43:41,442 - INFO - root - 已保存图片 3/10：./export\QCVPR 2025\images\figure_3_page13.jpeg
2025-11-11 23:43:41,492 - INFO - root - 已保存图片 4/10：./export\QCVPR 2025\images\figure_4_page2.jpeg
2025-11-11 23:43:41,541 - INFO - root - 已保存图片 5/10：./export\QCVPR 2025\images\figure_5_page5.png
2025-11-11 23:43:41,567 - INFO - root - 已保存图片 6/10：./export\QCVPR 2025\images\figure_6_page13.jpeg
2025-11-11 23:43:41,596 - INFO - root - 已保存图片 7/10：./export\QCVPR 2025\images\figure_7_page2.jpeg
2025-11-11 23:43:41,626 - INFO - root - 已保存图片 8/10：./export\QCVPR 2025\images\figure_8_page8.jpeg
2025-11-11 23:43:41,642 - INFO - root - 已保存图片 9/10：./export\QCVPR 2025\images\figure_9_page1.jpeg
2025-11-11 23:43:41,659 - INFO - root - 已保存图片 10/10：./export\QCVPR 2025\images\figure_10_page1.png
2025-11-11 23:43:41,667 - INFO - root - 成功添加图片 1：./export\QCVPR 2025\images\figure_1_page13.jpeg
2025-11-11 23:43:41,668 - INFO - root - 成功添加图片 2：./export\QCVPR 2025\images\figure_2_page13.jpeg
2025-11-11 23:43:41,668 - INFO - root - 成功添加图片 3：./export\QCVPR 2025\images\figure_3_page13.jpeg
2025-11-11 23:43:41,668 - INFO - root - 成功添加图片 4：./export\QCVPR 2025\images\figure_4_page2.jpeg
2025-11-11 23:43:41,669 - INFO - root - 成功添加图片 5：./export\QCVPR 2025\images\figure_5_page5.png
2025-11-11 23:43:41,669 - INFO - root - 成功添加图片 6：./export\QCVPR 2025\images\figure_6_page13.jpeg
2025-11-11 23:43:41,670 - INFO - root - 成功添加图片 7：./export\QCVPR 2025\images\figure_7_page2.jpeg
2025-11-11 23:43:41,671 - INFO - root - 成功添加图片 8：./export\QCVPR 2025\images\figure_8_page8.jpeg
2025-11-11 23:43:41,671 - INFO - root - 成功添加图片 9：./export\QCVPR 2025\images\figure_9_page1.jpeg
2025-11-11 23:43:41,671 - INFO - root - 成功添加图片 10：./export\QCVPR 2025\images\figure_10_page1.png
2025-11-11 23:43:41,673 - WARNING - root - 图片文件不存在: images/figure_10_page1.png
2025-11-11 23:43:41,674 - WARNING - root - 图片在任何位置都不存在: figure_10_page1.png
2025-11-11 23:43:41,674 - WARNING - root - 图片文件不存在: images/figure_9_page1.jpeg
2025-11-11 23:43:41,674 - WARNING - root - 图片在任何位置都不存在: figure_9_page1.jpeg
2025-11-11 23:43:41,675 - WARNING - root - 图片文件不存在: images/figure_8_page8.jpeg
2025-11-11 23:43:41,675 - WARNING - root - 图片在任何位置都不存在: figure_8_page8.jpeg
2025-11-11 23:43:41,675 - WARNING - root - 图片文件不存在: images/figure_7_page2.jpeg
2025-11-11 23:43:41,676 - WARNING - root - 图片在任何位置都不存在: figure_7_page2.jpeg
2025-11-11 23:43:41,676 - WARNING - root - 图片文件不存在: images/figure_6_page13.jpeg
2025-11-11 23:43:41,676 - WARNING - root - 图片在任何位置都不存在: figure_6_page13.jpeg
2025-11-11 23:43:41,677 - WARNING - root - 图片文件不存在: images/figure_5_page5.png
2025-11-11 23:43:41,677 - WARNING - root - 图片在任何位置都不存在: figure_5_page5.png
2025-11-11 23:43:41,677 - WARNING - root - 图片文件不存在: images/figure_4_page2.jpeg
2025-11-11 23:43:41,679 - WARNING - root - 图片在任何位置都不存在: figure_4_page2.jpeg
2025-11-11 23:43:41,679 - WARNING - root - 图片文件不存在: images/figure_3_page13.jpeg
2025-11-11 23:43:41,679 - WARNING - root - 图片在任何位置都不存在: figure_3_page13.jpeg
2025-11-11 23:43:41,679 - WARNING - root - 图片文件不存在: images/figure_2_page13.jpeg
2025-11-11 23:43:41,680 - WARNING - root - 图片在任何位置都不存在: figure_2_page13.jpeg
2025-11-11 23:43:41,680 - WARNING - root - 图片文件不存在: images/figure_1_page13.jpeg
2025-11-11 23:43:41,680 - WARNING - root - 图片在任何位置都不存在: figure_1_page13.jpeg
2025-11-11 23:43:41,681 - INFO - root - 已按文献标题重新组织图片存储
2025-11-11 23:43:41,685 - INFO - root - 论文《OmniTrack++: Omnidirectional Multi-Object Tracking by Learning Large-FoV Trajectory Feedback》的分析已保存到 ./export\QCVPR 2025\OmniTrack++_ Omnidirectional Multi-Object Tracking by Learning Large-FoV Traject.md
2025-11-11 23:43:41,987 - INFO - root - 已生成汇总Excel表格: export\QCVPR 2025\论文汇总_QCVPR 2025_20251111_234341.xlsx
2025-11-11 23:43:41,987 - INFO - root - 已生成汇总Excel表格: export\QCVPR 2025\论文汇总_QCVPR 2025_20251111_234341.xlsx
2025-11-11 23:43:41,987 - INFO - root - summary time: 693.76 seconds
2025-11-11 23:50:00,716 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-11 23:50:00,716 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-11 23:50:00,716 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-11 23:50:01,720 - INFO - root - LLMClientManager: 指定使用客户端: DeepSeek
2025-11-11 23:50:01,721 - INFO - root - DeepSeekClient: API key found: 9f9e270e-b...
2025-11-11 23:50:01,721 - INFO - root - DeepSeekClient: 使用模式: 火山引擎
2025-11-11 23:50:01,721 - INFO - root - DeepSeekClient: 模型名称: deepseek-v3-1-terminus
2025-11-11 23:50:05,349 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-11 23:50:05,389 - INFO - root - DeepSeekClient: initialized successfully with model deepseek-v3-1-terminus
2025-11-11 23:50:05,389 - INFO - root - LLMClientManager: DeepSeek 客户端初始化成功
2025-11-11 23:50:05,389 - INFO - root - LLMClientManager: switched to DeepSeek client
2025-11-11 23:50:05,389 - INFO - root - 已手动切换到 LLM 客户端: DeepSeek
2025-11-11 23:50:05,389 - INFO - root - 使用 LLM 模型: deepseek-v3-1-terminus
2025-11-11 23:50:05,389 - INFO - root - 可用客户端: ['DeepSeek']
2025-11-11 23:50:05,394 - INFO - root - === 运行配置 ===
2025-11-11 23:50:05,394 - INFO - root - 处理模式: arxiv在线搜索
2025-11-11 23:50:05,394 - INFO - root - 关键词: QCVPR 2025
2025-11-11 23:50:05,394 - INFO - root - 查询: CVPR 2025
2025-11-11 23:50:05,395 - INFO - root - 排序: None
2025-11-11 23:50:05,395 - INFO - root - 最近天数: 180
2025-11-11 23:50:05,395 - INFO - root - 最大处理数量: 2
2025-11-11 23:50:05,395 - INFO - root - 保存图片: 是
2025-11-11 23:50:05,395 - INFO - root - 输出语言: 中文
2025-11-11 23:50:05,395 - INFO - root - 强制重新处理: 否
2025-11-11 23:50:05,398 - INFO - root - ====================
2025-11-11 23:50:05,398 - INFO - root - 使用 arXiv 搜索模式（通过 chat_arxiv 模块获取）
2025-11-11 23:50:05,398 - INFO - root - Fetching page 1 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50
2025-11-11 23:50:17,537 - INFO - root - get_all_titles_from_web 
2025-11-11 23:50:17,537 - INFO - root - Page:0, Index:0, Learning to Seek Evidence: A Verifiable Reasoning Agent with Causal Faithfulness Analysis, https://arxiv.org/pdf/2511.01425, 2025-11-03
2025-11-11 23:50:17,538 - INFO - root - Page:0, Index:1, OmniTrack++: Omnidirectional Multi-Object Tracking by Learning Large-FoV Trajectory Feedback, https://arxiv.org/pdf/2511.00510, 2025-11-01
2025-11-11 23:50:17,538 - INFO - root - Page:0, Index:2, NeuCo-Bench: A Novel Benchmark Framework for Neural Embeddings in Earth Observation, https://arxiv.org/pdf/2510.17914, 2025-10-19
2025-11-11 23:50:17,538 - INFO - root - Page:0, Index:3, NTIRE 2025 Challenge on Low Light Image Enhancement: Methods and Results, https://arxiv.org/pdf/2510.13670, 2025-10-15
2025-11-11 23:50:17,538 - INFO - root - Page:0, Index:4, Class Prototypes based Contrastive Learning for Classifying Multi-Label and Fine-Grained Educational Videos, https://arxiv.org/pdf/2510.11204, 2025-10-13
2025-11-11 23:50:17,540 - INFO - root - Page:0, Index:5, MIMO: A medical vision language model with visual referring multimodal input and pixel grounding multimodal output, https://arxiv.org/pdf/2510.10011, 2025-10-11
2025-11-11 23:50:17,540 - INFO - root - Page:0, Index:6, Vision Language Models: A Survey of 26K Papers, https://arxiv.org/pdf/2510.09586, 2025-10-10
2025-11-11 23:50:17,540 - INFO - root - Page:0, Index:7, DiT-VTON: Diffusion Transformer Framework for Unified Multi-Category Virtual Try-On and Virtual Try-All with Integrated Image Editing, https://arxiv.org/pdf/2510.04797, 2025-10-03
2025-11-11 23:50:17,540 - INFO - root - Page:0, Index:8, PatchVSR: Breaking Video Diffusion Resolution Limits with Patch-wise Video Super-Resolution, https://arxiv.org/pdf/2509.26025, 2025-09-30
2025-11-11 23:50:17,541 - INFO - root - Page:0, Index:9, FreqDebias: Towards Generalizable Deepfake Detection via Consistency-Driven Frequency Debiasing, https://arxiv.org/pdf/2509.22412, 2025-09-26
2025-11-11 23:50:17,541 - INFO - root - Page:0, Index:10, A Mutual Learning Method for Salient Object Detection with intertwined Multi-Supervision--Revised, https://arxiv.org/pdf/2509.21363, 2025-09-21
2025-11-11 23:50:17,541 - INFO - root - Page:0, Index:11, InstructVTON: Optimal Auto-Masking and Natural-Language-Guided Interactive Style Control for Inpainting-Based Virtual Try-On, https://arxiv.org/pdf/2509.20524, 2025-09-24
2025-11-11 23:50:17,541 - INFO - root - Page:0, Index:12, Efficient Encoder-Free Pose Conditioning and Pose Control for Virtual Try-On, https://arxiv.org/pdf/2509.20343, 2025-09-24
2025-11-11 23:50:17,541 - INFO - root - Page:0, Index:13, The Photographer Eye: Teaching Multimodal Large Language Models to Understand Image Aesthetics like Photographers, https://arxiv.org/pdf/2509.18582, 2025-10-22
2025-11-11 23:50:17,542 - INFO - root - Page:0, Index:14, ENSAM: an efficient foundation model for interactive segmentation of 3D medical images, https://arxiv.org/pdf/2509.15874, 2025-09-19
2025-11-11 23:50:17,542 - INFO - root - Page:0, Index:15, DEFT-VTON: Efficient Virtual Try-On with Consistent Generalised H-Transform, https://arxiv.org/pdf/2509.13506, 2025-09-16
2025-11-11 23:50:17,542 - INFO - root - Page:0, Index:16, Weakly and Self-Supervised Class-Agnostic Motion Prediction for Autonomous Driving, https://arxiv.org/pdf/2509.13116, 2025-09-16
2025-11-11 23:50:17,542 - INFO - root - Page:0, Index:17, Domain-Adaptive Pretraining Improves Primate Behavior Recognition, https://arxiv.org/pdf/2509.12193, 2025-09-15
2025-11-11 23:50:17,543 - INFO - root - Page:0, Index:18, The System Description of CPS Team for Track on Driving with Language of CVPR 2024 Autonomous Grand Challenge, https://arxiv.org/pdf/2509.11071, 2025-09-13
2025-11-11 23:50:17,543 - INFO - root - Page:0, Index:19, An HMM-based framework for identity-aware long-term multi-object tracking from sparse and uncertain identification: use case on long-term tracking in livestock, https://arxiv.org/pdf/2509.09962, 2025-09-12
2025-11-11 23:50:17,543 - INFO - root - Page:0, Index:20, InterAct: Advancing Large-Scale Versatile 3D Human-Object Interaction Generation, https://arxiv.org/pdf/2509.09555, 2025-09-11
2025-11-11 23:50:17,544 - INFO - root - Page:0, Index:21, Geospatial Foundational Embedder: Top-1 Winning Solution on EarthVision Embed2Scale Challenge (CVPR 2025), https://arxiv.org/pdf/2509.06993, 2025-09-03
2025-11-11 23:50:17,544 - INFO - root - Page:0, Index:22, 2nd Place Solution for CVPR2024 E2E Challenge: End-to-End Autonomous Driving Using Vision Language Model, https://arxiv.org/pdf/2509.02659, 2025-09-02
2025-11-11 23:50:17,545 - INFO - root - Page:0, Index:23, Unsupervised Training of Vision Transformers with Synthetic Negatives, https://arxiv.org/pdf/2509.02024, 2025-09-02
2025-11-11 23:50:17,545 - INFO - root - Page:0, Index:24, MV-SSM: Multi-View State Space Modeling for 3D Human Pose Estimation, https://arxiv.org/pdf/2509.00649, 2025-08-30
2025-11-11 23:50:17,546 - INFO - root - Page:0, Index:25, CryptoFace: End-to-End Encrypted Face Recognition, https://arxiv.org/pdf/2509.00332, 2025-08-29
2025-11-11 23:50:17,548 - INFO - root - Page:0, Index:26, ControlEchoSynth: Boosting Ejection Fraction Estimation Models via Controlled Video Diffusion, https://arxiv.org/pdf/2508.17631, 2025-08-26
2025-11-11 23:50:17,550 - INFO - root - Page:0, Index:27, Explain Before You Answer: A Survey on Compositional Visual Reasoning, https://arxiv.org/pdf/2508.17298, 2025-08-27
2025-11-11 23:50:17,551 - INFO - root - Page:0, Index:28, Investigating Different Geo Priors for Image Classification, https://arxiv.org/pdf/2508.15946, 2025-08-21
2025-11-11 23:50:17,551 - INFO - root - Page:0, Index:29, Towards Source-Free Machine Unlearning, https://arxiv.org/pdf/2508.15127, 2025-08-20
2025-11-11 23:50:17,551 - INFO - root - Page:0, Index:30, MR6D: Benchmarking 6D Pose Estimation for Mobile Robots, https://arxiv.org/pdf/2508.13775, 2025-08-19
2025-11-11 23:50:17,553 - INFO - root - Page:0, Index:31, Calibrating Biased Distribution in VFM-derived Latent Space via Cross-Domain Geometric Consistency, https://arxiv.org/pdf/2508.13518, 2025-08-19
2025-11-11 23:50:17,553 - INFO - root - Page:0, Index:32, SIS-Challenge: Event-based Spatio-temporal Instance Segmentation Challenge at the CVPR 2025 Event-based Vision Workshop, https://arxiv.org/pdf/2508.12813, 2025-08-18
2025-11-11 23:50:17,553 - INFO - root - Page:0, Index:33, Multi-Level Knowledge Distillation and Dynamic Self-Supervised Learning for Continual Learning, https://arxiv.org/pdf/2508.12692, 2025-08-22
2025-11-11 23:50:17,554 - INFO - root - Page:0, Index:34, Stochastic-based Patch Filtering for Few-Shot Learning, https://arxiv.org/pdf/2508.10066, 2025-08-13
2025-11-11 23:50:17,554 - INFO - root - Page:0, Index:35, Slot Attention-based Feature Filtering for Few-Shot Learning, https://arxiv.org/pdf/2508.09699, 2025-08-13
2025-11-11 23:50:17,554 - INFO - root - Page:0, Index:36, Comparison Reveals Commonality: Customized Image Generation through Contrastive Inversion, https://arxiv.org/pdf/2508.07755, 2025-08-11
2025-11-11 23:50:17,554 - INFO - root - Page:0, Index:37, SLRTP2025 Sign Language Production Challenge: Methodology, Results, and Future Work, https://arxiv.org/pdf/2508.06951, 2025-08-09
2025-11-11 23:50:17,555 - INFO - root - Page:0, Index:38, Exploring Fairness across Fine-Grained Attributes in Large Vision-Language Models, https://arxiv.org/pdf/2508.03079, 2025-08-05
2025-11-11 23:50:17,555 - INFO - root - Page:0, Index:39, Devil is in the Detail: Towards Injecting Fine Details of Image Prompt in Image Generation via Conflict-free Guidance and Stratified Attention, https://arxiv.org/pdf/2508.02004, 2025-08-03
2025-11-11 23:50:17,555 - INFO - root - Page:0, Index:40, IAUNet: Instance-Aware U-Net, https://arxiv.org/pdf/2508.01928, 2025-08-03
2025-11-11 23:50:17,556 - INFO - root - Page:0, Index:41, Gaussian Splatting Feature Fields for Privacy-Preserving Visual Localization, https://arxiv.org/pdf/2507.23569, 2025-08-26
2025-11-11 23:50:17,556 - INFO - root - Page:0, Index:42, From Scan to Action: Leveraging Realistic Scans for Embodied Scene Understanding, https://arxiv.org/pdf/2507.17585, 2025-07-23
2025-11-11 23:50:17,558 - INFO - root - Page:0, Index:43, LEAD: Exploring Logit Space Evolution for Model Selection, https://arxiv.org/pdf/2507.14559, 2025-07-19
2025-11-11 23:50:17,558 - INFO - root - Page:0, Index:44, HeCoFuse: Cross-Modal Complementary V2X Cooperative Perception with Heterogeneous Sensors, https://arxiv.org/pdf/2507.13677, 2025-07-18
2025-11-11 23:50:17,559 - INFO - root - Page:0, Index:45, OmniVec2 -- A Novel Transformer based Network for Large Scale Multimodal and Multitask Learning, https://arxiv.org/pdf/2507.13364, 2025-07-06
2025-11-11 23:50:17,559 - INFO - root - Page:0, Index:46, A Training-Free, Task-Agnostic Framework for Enhancing MLLM Performance on High-Resolution Images, https://arxiv.org/pdf/2507.10202, 2025-07-14
2025-11-11 23:50:17,559 - INFO - root - Page:0, Index:47, Quantum Federated Learning for Multimodal Data: A Modality-Agnostic Approach, https://arxiv.org/pdf/2507.08217, 2025-07-10
2025-11-11 23:50:17,559 - INFO - root - Page:0, Index:48, CuriosAI Submission to the EgoExo4D Proficiency Estimation Challenge 2025, https://arxiv.org/pdf/2507.08022, 2025-07-08
2025-11-11 23:50:17,560 - INFO - root - Page:0, Index:49, Rethinking Query-based Transformer for Continual Image Segmentation, https://arxiv.org/pdf/2507.07831, 2025-07-10
2025-11-11 23:50:17,561 - INFO - root - Fetching page 2 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=50
2025-11-11 23:50:27,079 - INFO - root - get_all_titles_from_web 
2025-11-11 23:50:27,079 - INFO - root - Page:1, Index:0, Scalable and Realistic Virtual Try-on Application for Foundation Makeup with Kubelka-Munk Theory, https://arxiv.org/pdf/2507.07333, 2025-07-09
2025-11-11 23:50:27,080 - INFO - root - Page:1, Index:1, Free on the Fly: Enhancing Flexibility in Test-Time Adaptation with Online EM, https://arxiv.org/pdf/2507.06973, 2025-07-09
2025-11-11 23:50:27,080 - INFO - root - Page:1, Index:2, Adaptive Part Learning for Fine-Grained Generalized Category Discovery: A Plug-and-Play Enhancement, https://arxiv.org/pdf/2507.06928, 2025-07-09
2025-11-11 23:50:27,080 - INFO - root - Page:1, Index:3, Grounded Gesture Generation: Language, Motion, and Space, https://arxiv.org/pdf/2507.04522, 2025-07-06
2025-11-11 23:50:27,080 - INFO - root - Page:1, Index:4, Comprehensive Information Bottleneck for Unveiling Universal Attribution to Interpret Vision Transformers, https://arxiv.org/pdf/2507.04388, 2025-07-06
2025-11-11 23:50:27,080 - INFO - root - Page:1, Index:5, ZERO: Industry-ready Vision Foundation Model with Multi-modal Prompts, https://arxiv.org/pdf/2507.04270, 2025-11-07
2025-11-11 23:50:27,080 - INFO - root - Page:1, Index:6, Beyond Accuracy: Metrics that Uncover What Makes a 'Good' Visual Descriptor, https://arxiv.org/pdf/2507.03542, 2025-07-08
2025-11-11 23:50:27,080 - INFO - root - Page:1, Index:7, ConceptMix++: Leveling the Playing Field in Text-to-Image Benchmarking via Iterative Prompt Optimization, https://arxiv.org/pdf/2507.03275, 2025-07-03
2025-11-11 23:50:27,080 - INFO - root - Page:1, Index:8, APT: Adaptive Personalized Training for Diffusion Models with Limited Data, https://arxiv.org/pdf/2507.02687, 2025-07-03
2025-11-11 23:50:27,080 - INFO - root - Page:1, Index:9, DreamComposer++: Empowering Diffusion Models with Multi-View Conditions for 3D Content Generation, https://arxiv.org/pdf/2507.02299, 2025-07-03
2025-11-11 23:50:27,080 - INFO - root - Page:1, Index:10, Soft Self-labeling and Potts Relaxations for Weakly-Supervised Segmentation, https://arxiv.org/pdf/2507.01721, 2025-07-02
2025-11-11 23:50:27,080 - INFO - root - Page:1, Index:11, Interpolation-Based Event Visual Data Filtering Algorithms, https://arxiv.org/pdf/2507.01557, 2025-07-02
2025-11-11 23:50:27,080 - INFO - root - Page:1, Index:12, AVC-DPO: Aligned Video Captioning via Direct Preference Optimization, https://arxiv.org/pdf/2507.01492, 2025-07-02
2025-11-11 23:50:27,080 - INFO - root - Page:1, Index:13, NN-Former: Rethinking Graph Structure in Neural Architecture Representation, https://arxiv.org/pdf/2507.00880, 2025-07-01
2025-11-11 23:50:27,080 - INFO - root - Page:1, Index:14, Instant Particle Size Distribution Measurement Using CNNs Trained on Synthetic Data, https://arxiv.org/pdf/2507.00822, 2025-07-01
2025-11-11 23:50:27,080 - INFO - root - Page:1, Index:15, Moment Sampling in Video LLMs for Long-Form Video QA, https://arxiv.org/pdf/2507.00033, 2025-06-17
2025-11-11 23:50:27,080 - INFO - root - Page:1, Index:16, Revisiting Audio-Visual Segmentation with Vision-Centric Transformer, https://arxiv.org/pdf/2506.23623, 2025-06-30
2025-11-11 23:50:27,084 - INFO - root - Page:1, Index:17, MTADiffusion: Mask Text Alignment Diffusion Model for Object Inpainting, https://arxiv.org/pdf/2506.23482, 2025-06-29
2025-11-11 23:50:27,085 - INFO - root - Page:1, Index:18, Benchmarking Generalizable Bimanual Manipulation: RoboTwin Dual-Arm Collaboration Challenge at CVPR 2025 MEIS Workshop, https://arxiv.org/pdf/2506.23351, 2025-07-02
2025-11-11 23:50:27,085 - INFO - root - Page:1, Index:19, Prompting without Panic: Attribute-aware, Zero-shot, Test-Time Calibration, https://arxiv.org/pdf/2506.22819, 2025-06-28
2025-11-11 23:50:27,086 - INFO - root - Page:1, Index:20, Analyzing and Fine-Tuning Whisper Models for Multilingual Pilot Speech Transcription in the Cockpit, https://arxiv.org/pdf/2506.21990, 2025-06-27
2025-11-11 23:50:27,086 - INFO - root - Page:1, Index:21, SceneDiffuser++: City-Scale Traffic Simulation via a Generative World Model, https://arxiv.org/pdf/2506.21976, 2025-06-27
2025-11-11 23:50:27,086 - INFO - root - Page:1, Index:22, DIVE: Deep-search Iterative Video Exploration A Technical Report for the CVRR Challenge at CVPR 2025, https://arxiv.org/pdf/2506.21891, 2025-06-27
2025-11-11 23:50:27,088 - INFO - root - Page:1, Index:23, End-to-End RGB-IR Joint Image Compression With Channel-wise Cross-modality Entropy Model, https://arxiv.org/pdf/2506.21851, 2025-06-26
2025-11-11 23:50:27,089 - INFO - root - Page:1, Index:24, Distilling Normalizing Flows, https://arxiv.org/pdf/2506.21003, 2025-06-26
2025-11-11 23:50:27,093 - INFO - root - Page:1, Index:25, Joint attitude estimation and 3D neural reconstruction of non-cooperative space objects, https://arxiv.org/pdf/2506.20638, 2025-06-25
2025-11-11 23:50:27,093 - INFO - root - Page:1, Index:26, Accept More, Reject Less: Reducing up to 19% Unnecessary Desk-Rejections over 11 Years of ICLR Data, https://arxiv.org/pdf/2506.20141, 2025-06-25
2025-11-11 23:50:27,094 - INFO - root - Page:1, Index:27, SceneCrafter: Controllable Multi-View Driving Scene Editing, https://arxiv.org/pdf/2506.19488, 2025-06-24
2025-11-11 23:50:27,094 - INFO - root - Page:1, Index:28, Emergence of Text Readability in Vision Language Models, https://arxiv.org/pdf/2506.19389, 2025-06-24
2025-11-11 23:50:27,094 - INFO - root - Page:1, Index:29, MedErr-CT: A Visual Question Answering Benchmark for Identifying and Correcting Errors in CT Reports, https://arxiv.org/pdf/2506.19217, 2025-06-23
2025-11-11 23:50:27,095 - INFO - root - Page:1, Index:30, RareSpot: Spotting Small and Rare Wildlife in Aerial Imagery with Multi-Scale Consistency and Context-Aware Augmentation, https://arxiv.org/pdf/2506.19087, 2025-06-23
2025-11-11 23:50:27,095 - INFO - root - Page:1, Index:31, Object-aware Sound Source Localization via Audio-Visual Scene Understanding, https://arxiv.org/pdf/2506.18557, 2025-06-23
2025-11-11 23:50:27,095 - INFO - root - Page:1, Index:32, Rethinking Decoder Design: Improving Biomarker Segmentation Using Depth-to-Space Restoration and Residual Linear Attention, https://arxiv.org/pdf/2506.18335, 2025-06-23
2025-11-11 23:50:27,095 - INFO - root - Page:1, Index:33, Relation3D: Enhancing Relation Modeling for Point Cloud Instance Segmentation, https://arxiv.org/pdf/2506.17891, 2025-06-21
2025-11-11 23:50:27,096 - INFO - root - Page:1, Index:34, HIRE: Lightweight High-Resolution Image Feature Enrichment for Multimodal LLMs, https://arxiv.org/pdf/2506.17608, 2025-06-21
2025-11-11 23:50:27,096 - INFO - root - Page:1, Index:35, Spatially-Aware Evaluation of Segmentation Uncertainty, https://arxiv.org/pdf/2506.16589, 2025-06-19
2025-11-11 23:50:27,096 - INFO - root - Page:1, Index:36, Tripartite Weight-Space Ensemble for Few-Shot Class-Incremental Learning, https://arxiv.org/pdf/2506.15720, 2025-06-03
2025-11-11 23:50:27,097 - INFO - root - Page:1, Index:37, PARC: A Quantitative Framework Uncovering the Symmetries within Vision Language Models, https://arxiv.org/pdf/2506.14808, 2025-06-03
2025-11-11 23:50:27,097 - INFO - root - Page:1, Index:38, Self-supervised Representation Learning with Local Aggregation for Image-based Profiling, https://arxiv.org/pdf/2506.14265, 2025-10-27
2025-11-11 23:50:27,097 - INFO - root - Page:1, Index:39, Towards Robust Learning to Optimize with Theoretical Guarantees, https://arxiv.org/pdf/2506.14263, 2025-06-17
2025-11-11 23:50:27,097 - INFO - root - Page:1, Index:40, Hidden Bias in the Machine: Stereotypes in Text-to-Image Models, https://arxiv.org/pdf/2506.13780, 2025-06-09
2025-11-11 23:50:27,098 - INFO - root - Page:1, Index:41, SmartHome-Bench: A Comprehensive Benchmark for Video Anomaly Detection in Smart Homes Using Multi-Modal Large Language Models, https://arxiv.org/pdf/2506.12992, 2025-06-15
2025-11-11 23:50:27,099 - INFO - root - Page:1, Index:42, Generative 4D Scene Gaussian Splatting with Object View-Synthesis Priors, https://arxiv.org/pdf/2506.12716, 2025-06-15
2025-11-11 23:50:27,099 - INFO - root - Page:1, Index:43, DejaVid: Encoder-Agnostic Learned Temporal Matching for Video Classification, https://arxiv.org/pdf/2506.12585, 2025-06-14
2025-11-11 23:50:27,100 - INFO - root - Page:1, Index:44, Pushing the Limits of Safety: A Technical Report on the ATLAS Challenge 2025, https://arxiv.org/pdf/2506.12430, 2025-07-10
2025-11-11 23:50:27,100 - INFO - root - Page:1, Index:45, FIMA-Q: Post-Training Quantization for Vision Transformers by Fisher Information Matrix Approximation, https://arxiv.org/pdf/2506.11543, 2025-06-13
2025-11-11 23:50:27,100 - INFO - root - Page:1, Index:46, Stop learning it all to mitigate visual hallucination, Focus on the hallucination target, https://arxiv.org/pdf/2506.11417, 2025-06-12
2025-11-11 23:50:27,101 - INFO - root - Page:1, Index:47, EfficientQuant: An Efficient Post-Training Quantization for CNN-Transformer Hybrid Models on Edge Devices, https://arxiv.org/pdf/2506.11093, 2025-06-05
2025-11-11 23:50:27,101 - INFO - root - Page:1, Index:48, HalLoc: Token-level Localization of Hallucinations for Vision Language Models, https://arxiv.org/pdf/2506.10286, 2025-06-11
2025-11-11 23:50:27,101 - INFO - root - Page:1, Index:49, DySS: Dynamic Queries and State-Space Learning for Efficient 3D Object Detection from Multi-Camera Videos, https://arxiv.org/pdf/2506.10242, 2025-06-11
2025-11-11 23:50:27,101 - INFO - root - Fetching page 3 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=100
2025-11-11 23:50:35,984 - INFO - root - get_all_titles_from_web 
2025-11-11 23:50:35,984 - INFO - root - Page:2, Index:0, Improving Personalized Search with Regularized Low-Rank Parameter Updates, https://arxiv.org/pdf/2506.10182, 2025-06-11
2025-11-11 23:50:35,986 - INFO - root - Page:2, Index:1, Hearing Hands: Generating Sounds from Physical Interactions in 3D Scenes, https://arxiv.org/pdf/2506.09989, 2025-06-11
2025-11-11 23:50:35,986 - INFO - root - Page:2, Index:2, UniPre3D: Unified Pre-training of 3D Point Cloud Models with Cross-Modal Gaussian Splatting, https://arxiv.org/pdf/2506.09952, 2025-06-11
2025-11-11 23:50:35,986 - INFO - root - Page:2, Index:3, Provoking Multi-modal Few-Shot LVLM via Exploration-Exploitation In-Context Learning, https://arxiv.org/pdf/2506.09473, 2025-06-11
2025-11-11 23:50:35,986 - INFO - root - Page:2, Index:4, Synthetic Human Action Video Data Generation with Pose Transfer, https://arxiv.org/pdf/2506.09411, 2025-06-11
2025-11-11 23:50:35,986 - INFO - root - Page:2, Index:5, ScaleLSD: Scalable Deep Line Segment Detection Streamlined, https://arxiv.org/pdf/2506.09369, 2025-06-10
2025-11-11 23:50:35,987 - INFO - root - Page:2, Index:6, CheckManual: A New Challenge and Benchmark for Manual-based Appliance Manipulation, https://arxiv.org/pdf/2506.09343, 2025-06-10
2025-11-11 23:50:35,987 - INFO - root - Page:2, Index:7, PatchGuard: Adversarially Robust Anomaly Detection and Localization through Vision Transformers and Pseudo Anomalies, https://arxiv.org/pdf/2506.09237, 2025-10-24
2025-11-11 23:50:35,987 - INFO - root - Page:2, Index:8, SILK: Smooth InterpoLation frameworK for motion in-betweening A Simplified Computational Approach, https://arxiv.org/pdf/2506.09075, 2025-06-09
2025-11-11 23:50:35,987 - INFO - root - Page:2, Index:9, BG-HOP: A Bimanual Generative Hand-Object Prior, https://arxiv.org/pdf/2506.09068, 2025-06-08
2025-11-11 23:50:35,988 - INFO - root - Page:2, Index:10, ORIDa: Object-centric Real-world Image Composition Dataset, https://arxiv.org/pdf/2506.08964, 2025-06-10
2025-11-11 23:50:35,988 - INFO - root - Page:2, Index:11, DiscoVLA: Discrepancy Reduction in Vision, Language, and Alignment for Parameter-Efficient Video-Text Retrieval, https://arxiv.org/pdf/2506.08887, 2025-06-10
2025-11-11 23:50:35,988 - INFO - root - Page:2, Index:12, A Comprehensive Study of Decoder-Only LLMs for Text-to-Image Generation, https://arxiv.org/pdf/2506.08210, 2025-06-09
2025-11-11 23:50:35,988 - INFO - root - Page:2, Index:13, Open World Scene Graph Generation using Vision Language Models, https://arxiv.org/pdf/2506.08189, 2025-06-09
2025-11-11 23:50:35,989 - INFO - root - Page:2, Index:14, Aligning Proteins and Language: A Foundation Model for Protein Retrieval, https://arxiv.org/pdf/2506.08023, 2025-05-27
2025-11-11 23:50:35,989 - INFO - root - Page:2, Index:15, UA-Pose: Uncertainty-Aware 6D Object Pose Estimation and Online Object Completion with Partial References, https://arxiv.org/pdf/2506.07996, 2025-06-09
2025-11-11 23:50:35,989 - INFO - root - Page:2, Index:16, Speedy Deformable 3D Gaussian Splatting: Fast Rendering and Compression of Dynamic Scenes, https://arxiv.org/pdf/2506.07917, 2025-06-09
2025-11-11 23:50:35,989 - INFO - root - Page:2, Index:17, GaussianVAE: Adaptive Learning Dynamics of 3D Gaussians for High-Fidelity Super-Resolution, https://arxiv.org/pdf/2506.07897, 2025-06-09
2025-11-11 23:50:35,991 - INFO - root - Page:2, Index:18, Spatio-Temporal State Space Model For Efficient Event-Based Optical Flow, https://arxiv.org/pdf/2506.07878, 2025-06-09
2025-11-11 23:50:35,991 - INFO - root - Page:2, Index:19, FreeGave: 3D Physics Learning from Dynamic Videos by Gaussian Velocity, https://arxiv.org/pdf/2506.07865, 2025-06-09
2025-11-11 23:50:35,991 - INFO - root - Page:2, Index:20, LogoSP: Local-global Grouping of Superpoints for Unsupervised Semantic Segmentation of 3D Point Clouds, https://arxiv.org/pdf/2506.07857, 2025-06-09
2025-11-11 23:50:35,991 - INFO - root - Page:2, Index:21, Difference Inversion: Interpolate and Isolate the Difference with Token Consistency for Image Analogy Generation, https://arxiv.org/pdf/2506.07750, 2025-06-09
2025-11-11 23:50:35,991 - INFO - root - Page:2, Index:22, Synthetic Visual Genome, https://arxiv.org/pdf/2506.07643, 2025-06-09
2025-11-11 23:50:35,992 - INFO - root - Page:2, Index:23, Fractional Collisions: A Framework for Risk Estimation of Counterfactual Conflicts using Autonomous Driving Behavior Simulations, https://arxiv.org/pdf/2506.07540, 2025-06-09
2025-11-11 23:50:35,994 - INFO - root - Page:2, Index:24, Multi-Step Guided Diffusion for Image Restoration on Edge Devices: Toward Lightweight Perception in Embodied AI, https://arxiv.org/pdf/2506.07286, 2025-06-08
2025-11-11 23:50:35,994 - INFO - root - Page:2, Index:25, LLM-Enhanced Rapid-Reflex Async-Reflect Embodied Agent for Real-Time Decision-Making in Dynamically Changing Environments, https://arxiv.org/pdf/2506.07223, 2025-06-08
2025-11-11 23:50:35,996 - INFO - root - Page:2, Index:26, UCOD-DPL: Unsupervised Camouflaged Object Detection via Dynamic Pseudo-label Learning, https://arxiv.org/pdf/2506.07087, 2025-06-08
2025-11-11 23:50:35,996 - INFO - root - Page:2, Index:27, BePo: Leveraging Birds Eye View and Sparse Points for Efficient and Accurate 3D Occupancy Prediction, https://arxiv.org/pdf/2506.07002, 2025-06-08
2025-11-11 23:50:35,996 - INFO - root - Page:2, Index:28, Reading in the Dark with Foveated Event Vision, https://arxiv.org/pdf/2506.06918, 2025-06-07
2025-11-11 23:50:35,997 - INFO - root - Page:2, Index:29, NSD-Imagery: A benchmark dataset for extending fMRI vision decoding methods to mental imagery, https://arxiv.org/pdf/2506.06898, 2025-06-07
2025-11-11 23:50:35,997 - INFO - root - Page:2, Index:30, Continuous-Time SO(3) Forecasting with Savitzky--Golay Neural Controlled Differential Equations, https://arxiv.org/pdf/2506.06780, 2025-06-07
2025-11-11 23:50:35,997 - INFO - root - Page:2, Index:31, Generalized Trajectory Scoring for End-to-end Multimodal Planning, https://arxiv.org/pdf/2506.06664, 2025-06-07
2025-11-11 23:50:35,999 - INFO - root - Page:2, Index:32, EV-LayerSegNet: Self-supervised Motion Segmentation using Event Cameras, https://arxiv.org/pdf/2506.06596, 2025-06-06
2025-11-11 23:50:35,999 - INFO - root - Page:2, Index:33, Vid2Sim: Generalizable, Video-based Reconstruction of Appearance, Geometry and Physics for Mesh-free Simulation, https://arxiv.org/pdf/2506.06440, 2025-06-06
2025-11-11 23:50:35,999 - INFO - root - Page:2, Index:34, FADE: Frequency-Aware Diffusion Model Factorization for Video Editing, https://arxiv.org/pdf/2506.05934, 2025-06-06
2025-11-11 23:50:36,001 - INFO - root - Page:2, Index:35, Unleashing the Potential of Consistency Learning for Detecting and Grounding Multi-Modal Media Manipulation, https://arxiv.org/pdf/2506.05890, 2025-06-06
2025-11-11 23:50:36,002 - INFO - root - Page:2, Index:36, DeformCL: Learning Deformable Centerline Representation for Vessel Extraction in 3D Medical Image, https://arxiv.org/pdf/2506.05820, 2025-06-06
2025-11-11 23:50:36,003 - INFO - root - Page:2, Index:37, NTIRE 2025 Challenge on HR Depth from Images of Specular and Transparent Surfaces, https://arxiv.org/pdf/2506.05815, 2025-06-06
2025-11-11 23:50:36,003 - INFO - root - Page:2, Index:38, GazeNLQ @ Ego4D Natural Language Queries Challenge 2025, https://arxiv.org/pdf/2506.05782, 2025-06-06
2025-11-11 23:50:36,003 - INFO - root - Page:2, Index:39, Robust sensor fusion against on-vehicle sensor staleness, https://arxiv.org/pdf/2506.05780, 2025-06-06
2025-11-11 23:50:36,004 - INFO - root - Page:2, Index:40, Where Is The Ball: 3D Ball Trajectory Estimation From 2D Monocular Tracking, https://arxiv.org/pdf/2506.05763, 2025-06-06
2025-11-11 23:50:36,004 - INFO - root - Page:2, Index:41, VoxelSplat: Dynamic Gaussian Splatting as an Effective Loss for Occupancy and Flow Prediction, https://arxiv.org/pdf/2506.05563, 2025-06-05
2025-11-11 23:50:36,004 - INFO - root - Page:2, Index:42, Gen4D: Synthesizing Humans and Scenes in the Wild, https://arxiv.org/pdf/2506.05397, 2025-06-03
2025-11-11 23:50:36,004 - INFO - root - Page:2, Index:43, Attacking Attention of Foundation Models Disrupts Downstream Tasks, https://arxiv.org/pdf/2506.05394, 2025-09-12
2025-11-11 23:50:36,005 - INFO - root - Page:2, Index:44, FreeTimeGS: Free Gaussian Primitives at Anytime and Anywhere for Dynamic Scene Reconstruction, https://arxiv.org/pdf/2506.05348, 2025-06-06
2025-11-11 23:50:36,005 - INFO - root - Page:2, Index:45, LotusFilter: Fast Diverse Nearest Neighbor Search via a Learned Cutoff Table, https://arxiv.org/pdf/2506.04790, 2025-06-05
2025-11-11 23:50:36,005 - INFO - root - Page:2, Index:46, Towards Holistic Visual Quality Assessment of AI-Generated Videos: A LLM-Based Multi-Dimensional Evaluation Model, https://arxiv.org/pdf/2506.04715, 2025-06-11
2025-11-11 23:50:36,006 - INFO - root - Page:2, Index:47, Gradient Inversion Attacks on Parameter-Efficient Fine-Tuning, https://arxiv.org/pdf/2506.04453, 2025-06-04
2025-11-11 23:50:36,006 - INFO - root - Page:2, Index:48, HMAR: Efficient Hierarchical Masked Auto-Regressive Image Generation, https://arxiv.org/pdf/2506.04421, 2025-06-04
2025-11-11 23:50:36,006 - INFO - root - Page:2, Index:49, Visualizing and Controlling Cortical Responses Using Voxel-Weighted Activation Maximization, https://arxiv.org/pdf/2506.04379, 2025-06-04
2025-11-11 23:50:36,007 - INFO - root - Fetching page 4 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=150
2025-11-11 23:50:43,970 - INFO - root - get_all_titles_from_web 
2025-11-11 23:50:43,971 - INFO - root - Page:3, Index:0, FlexGS: Train Once, Deploy Everywhere with Many-in-One Flexible 3D Gaussian Splatting, https://arxiv.org/pdf/2506.04174, 2025-06-04
2025-11-11 23:50:43,971 - INFO - root - Page:3, Index:1, Multi-view Surface Reconstruction Using Normal and Reflectance Cues, https://arxiv.org/pdf/2506.04115, 2025-06-04
2025-11-11 23:50:43,971 - INFO - root - Page:3, Index:2, Vocabulary-free few-shot learning for Vision-Language Models, https://arxiv.org/pdf/2506.04005, 2025-06-04
2025-11-11 23:50:43,971 - INFO - root - Page:3, Index:3, Learning from Noise: Enhancing DNNs for Event-Based Vision through Controlled Noise Injection, https://arxiv.org/pdf/2506.03918, 2025-06-04
2025-11-11 23:50:43,972 - INFO - root - Page:3, Index:4, Video, How Do Your Tokens Merge?, https://arxiv.org/pdf/2506.03885, 2025-06-04
2025-11-11 23:50:43,972 - INFO - root - Page:3, Index:5, OSGNet @ Ego4D Episodic Memory Challenge 2025, https://arxiv.org/pdf/2506.03710, 2025-06-04
2025-11-11 23:50:43,975 - INFO - root - Page:3, Index:6, AetherVision-Bench: An Open-Vocabulary RGB-Infrared Benchmark for Multi-Angle Segmentation across Aerial and Ground Perspectives, https://arxiv.org/pdf/2506.03709, 2025-06-04
2025-11-11 23:50:43,975 - INFO - root - Page:3, Index:7, OV-COAST: Cost Aggregation with Optimal Transport for Open-Vocabulary Semantic Segmentation, https://arxiv.org/pdf/2506.03706, 2025-06-04
2025-11-11 23:50:43,975 - INFO - root - Page:3, Index:8, Generating 6DoF Object Manipulation Trajectories from Action Description in Egocentric Vision, https://arxiv.org/pdf/2506.03605, 2025-06-04
2025-11-11 23:50:43,975 - INFO - root - Page:3, Index:9, SemNav: A Model-Based Planner for Zero-Shot Object Goal Navigation Using Vision-Foundation Models, https://arxiv.org/pdf/2506.03516, 2025-06-03
2025-11-11 23:50:43,975 - INFO - root - Page:3, Index:10, Heterogeneous Skeleton-Based Action Representation Learning, https://arxiv.org/pdf/2506.03481, 2025-06-03
2025-11-11 23:50:43,975 - INFO - root - Page:3, Index:11, Hybrid Ensemble of Segmentation-Assisted Classification and GBDT for Skin Cancer Detection with Engineered Metadata and Synthetic Lesions from ISIC 2024 Non-Dermoscopic 3D-TBP Images, https://arxiv.org/pdf/2506.03420, 2025-06-03
2025-11-11 23:50:43,977 - INFO - root - Page:3, Index:12, Self-Supervised Spatial Correspondence Across Modalities, https://arxiv.org/pdf/2506.03148, 2025-06-03
2025-11-11 23:50:43,977 - INFO - root - Page:3, Index:13, Dense Match Summarization for Faster Two-view Estimation, https://arxiv.org/pdf/2506.02893, 2025-06-03
2025-11-11 23:50:43,977 - INFO - root - Page:3, Index:14, NTIRE 2025 XGC Quality Assessment Challenge: Methods and Results, https://arxiv.org/pdf/2506.02875, 2025-06-03
2025-11-11 23:50:43,977 - INFO - root - Page:3, Index:15, FreeScene: Mixed Graph Diffusion for 3D Scene Synthesis from Free Prompts, https://arxiv.org/pdf/2506.02781, 2025-06-03
2025-11-11 23:50:43,978 - INFO - root - Page:3, Index:16, Technical Report for Ego4D Long-Term Action Anticipation Challenge 2025, https://arxiv.org/pdf/2506.02550, 2025-06-11
2025-11-11 23:50:43,978 - INFO - root - Page:3, Index:17, Probabilistic Online Event Downsampling, https://arxiv.org/pdf/2506.02547, 2025-09-23
2025-11-11 23:50:43,978 - INFO - root - Page:3, Index:18, Towards In-the-wild 3D Plane Reconstruction from a Single Image, https://arxiv.org/pdf/2506.02493, 2025-06-03
2025-11-11 23:50:43,978 - INFO - root - Page:3, Index:19, Efficient Test-time Adaptive Object Detection via Sensitivity-Guided Pruning, https://arxiv.org/pdf/2506.02462, 2025-06-03
2025-11-11 23:50:43,979 - INFO - root - Page:3, Index:20, EgoVIS@CVPR: PAIR-Net: Enhancing Egocentric Speaker Detection via Pretrained Audio-Visual Fusion and Alignment Loss, https://arxiv.org/pdf/2506.02247, 2025-09-26
2025-11-11 23:50:43,979 - INFO - root - Page:3, Index:21, Diff2Flow: Training Flow Matching Models via Diffusion Model Alignment, https://arxiv.org/pdf/2506.02221, 2025-06-02
2025-11-11 23:50:43,979 - INFO - root - Page:3, Index:22, NTIRE 2025 Challenge on RAW Image Restoration and Super-Resolution, https://arxiv.org/pdf/2506.02197, 2025-06-04
2025-11-11 23:50:43,979 - INFO - root - Page:3, Index:23, RAW Image Reconstruction from RGB on Smartphones. NTIRE 2025 Challenge Report, https://arxiv.org/pdf/2506.01947, 2025-06-02
2025-11-11 23:50:43,980 - INFO - root - Page:3, Index:24, Silence is Golden: Leveraging Adversarial Examples to Nullify Audio Control in LDM-based Talking-Head Generation, https://arxiv.org/pdf/2506.01591, 2025-06-02
2025-11-11 23:50:43,980 - INFO - root - Page:3, Index:25, SAM2-LOVE: Segment Anything Model 2 in Language-aided Audio-Visual Scenes, https://arxiv.org/pdf/2506.01558, 2025-06-02
2025-11-11 23:50:43,981 - INFO - root - Page:3, Index:26, Neural shape reconstruction from multiple views with static pattern projection, https://arxiv.org/pdf/2506.01389, 2025-06-02
2025-11-11 23:50:43,981 - INFO - root - Page:3, Index:27, SAM-I2V: Upgrading SAM to Support Promptable Video Segmentation with Less than 0.2% Training Cost, https://arxiv.org/pdf/2506.01304, 2025-06-02
2025-11-11 23:50:43,982 - INFO - root - Page:3, Index:28, Perceptual Inductive Bias Is What You Need Before Contrastive Learning, https://arxiv.org/pdf/2506.01201, 2025-06-01
2025-11-11 23:50:43,982 - INFO - root - Page:3, Index:29, Test Automation for Interactive Scenarios via Promptable Traffic Simulation, https://arxiv.org/pdf/2506.01199, 2025-06-04
2025-11-11 23:50:43,982 - INFO - root - Page:3, Index:30, GraphPad: Inference-Time 3D Scene Graph Updates for Embodied Question Answering, https://arxiv.org/pdf/2506.01174, 2025-06-01
2025-11-11 23:50:43,982 - INFO - root - Page:3, Index:31, Aligned Contrastive Loss for Long-Tailed Recognition, https://arxiv.org/pdf/2506.01071, 2025-06-01
2025-11-11 23:50:43,982 - INFO - root - Page:3, Index:32, Self-supervised ControlNet with Spatio-Temporal Mamba for Real-world Video Super-resolution, https://arxiv.org/pdf/2506.01037, 2025-06-01
2025-11-11 23:50:43,982 - INFO - root - Page:3, Index:33, ArtiScene: Language-Driven Artistic 3D Scene Generation Through Image Intermediary, https://arxiv.org/pdf/2506.00742, 2025-05-31
2025-11-11 23:50:43,982 - INFO - root - Page:3, Index:34, 3D Gaussian Splat Vulnerabilities, https://arxiv.org/pdf/2506.00280, 2025-05-30
2025-11-11 23:50:43,982 - INFO - root - Page:3, Index:35, EgoVIS@CVPR: What Changed and What Could Have Changed? State-Change Counterfactuals for Procedure-Aware Video Representation Learning, https://arxiv.org/pdf/2506.00101, 2025-09-26
2025-11-11 23:50:43,982 - INFO - root - Page:3, Index:36, CL-LoRA: Continual Low-Rank Adaptation for Rehearsal-Free Class-Incremental Learning, https://arxiv.org/pdf/2505.24816, 2025-05-30
2025-11-11 23:50:43,982 - INFO - root - Page:3, Index:37, PatchDEMUX: A Certifiably Robust Framework for Multi-label Classifiers Against Adversarial Patches, https://arxiv.org/pdf/2505.24703, 2025-05-30
2025-11-11 23:50:43,982 - INFO - root - Page:3, Index:38, Conformal Prediction for Zero-Shot Models, https://arxiv.org/pdf/2505.24693, 2025-05-30
2025-11-11 23:50:43,982 - INFO - root - Page:3, Index:39, Learning reusable concepts across different egocentric video understanding tasks, https://arxiv.org/pdf/2505.24690, 2025-05-30
2025-11-11 23:50:43,982 - INFO - root - Page:3, Index:40, Period-LLM: Extending the Periodic Capability of Multimodal Large Language Model, https://arxiv.org/pdf/2505.24476, 2025-05-30
2025-11-11 23:50:43,982 - INFO - root - Page:3, Index:41, PCIE_Interaction Solution for Ego4D Social Interaction Challenge, https://arxiv.org/pdf/2505.24404, 2025-05-30
2025-11-11 23:50:43,982 - INFO - root - Page:3, Index:42, Leadership Assessment in Pediatric Intensive Care Unit Team Training, https://arxiv.org/pdf/2505.24389, 2025-08-28
2025-11-11 23:50:43,982 - INFO - root - Page:3, Index:43, Interpreting Large Text-to-Image Diffusion Models with Dictionary Learning, https://arxiv.org/pdf/2505.24360, 2025-07-10
2025-11-11 23:50:43,982 - INFO - root - Page:3, Index:44, InteractAnything: Zero-shot Human Object Interaction Synthesis via LLM Feedback and Object Affordance Parsing, https://arxiv.org/pdf/2505.24315, 2025-05-30
2025-11-11 23:50:43,987 - INFO - root - Page:3, Index:45, MaskAdapt: Unsupervised Geometry-Aware Domain Adaptation Using Multimodal Contextual Learning and RGB-Depth Masking, https://arxiv.org/pdf/2505.24026, 2025-05-29
2025-11-11 23:50:43,987 - INFO - root - Page:3, Index:46, Argus: Vision-Centric Reasoning with Grounded Chain-of-Thought, https://arxiv.org/pdf/2505.23766, 2025-05-29
2025-11-11 23:50:43,987 - INFO - root - Page:3, Index:47, Sketch Down the FLOPs: Towards Efficient Networks for Human Sketch, https://arxiv.org/pdf/2505.23763, 2025-05-29
2025-11-11 23:50:43,987 - INFO - root - Page:3, Index:48, Boosting Domain Incremental Learning: Selecting the Optimal Parameters is All You Need, https://arxiv.org/pdf/2505.23744, 2025-05-29
2025-11-11 23:50:43,988 - INFO - root - Page:3, Index:49, DA-VPT: Semantic-Guided Visual Prompt Tuning for Vision Transformers, https://arxiv.org/pdf/2505.23694, 2025-06-01
2025-11-11 23:50:43,988 - INFO - root - Fetching page 5 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=200
2025-11-11 23:50:54,926 - INFO - root - get_all_titles_from_web 
2025-11-11 23:50:54,926 - INFO - root - Page:4, Index:0, Bridging Classical and Modern Computer Vision: PerceptiveNet for Tree Crown Semantic Segmentation, https://arxiv.org/pdf/2505.23597, 2025-05-29
2025-11-11 23:50:54,926 - INFO - root - Page:4, Index:1, Synthetic Generation and Latent Projection Denoising of Rim Lesions in Multiple Sclerosis, https://arxiv.org/pdf/2505.23353, 2025-05-29
2025-11-11 23:50:54,926 - INFO - root - Page:4, Index:2, Wav2Sem: Plug-and-Play Audio Semantic Decoupling for 3D Speech-Driven Facial Animation, https://arxiv.org/pdf/2505.23290, 2025-05-29
2025-11-11 23:50:54,926 - INFO - root - Page:4, Index:3, Proximal Algorithm Unrolling: Flexible and Efficient Reconstruction Networks for Single-Pixel Imaging, https://arxiv.org/pdf/2505.23180, 2025-05-29
2025-11-11 23:50:54,926 - INFO - root - Page:4, Index:4, HMAD: Advancing E2E Driving with Anchored Offset Proposals and Simulation-Supervised Multi-target Scoring, https://arxiv.org/pdf/2505.23129, 2025-05-29
2025-11-11 23:50:54,928 - INFO - root - Page:4, Index:5, URWKV: Unified RWKV Model with Multi-state Perspective for Low-light Image Restoration, https://arxiv.org/pdf/2505.23068, 2025-05-29
2025-11-11 23:50:54,928 - INFO - root - Page:4, Index:6, 4DTAM: Non-Rigid Tracking and Mapping via Dynamic Surface Gaussians, https://arxiv.org/pdf/2505.22859, 2025-05-28
2025-11-11 23:50:54,928 - INFO - root - Page:4, Index:7, A Probabilistic Jump-Diffusion Framework for Open-World Egocentric Activity Recognition, https://arxiv.org/pdf/2505.22858, 2025-05-28
2025-11-11 23:50:54,928 - INFO - root - Page:4, Index:8, PS4PRO: Pixel-to-pixel Supervision for Photorealistic Rendering and Optimization, https://arxiv.org/pdf/2505.22616, 2025-05-28
2025-11-11 23:50:54,928 - INFO - root - Page:4, Index:9, Universal Domain Adaptation for Semantic Segmentation, https://arxiv.org/pdf/2505.22458, 2025-06-05
2025-11-11 23:50:54,928 - INFO - root - Page:4, Index:10, Zero-Shot 3D Visual Grounding from Vision-Language Models, https://arxiv.org/pdf/2505.22429, 2025-05-28
2025-11-11 23:50:54,930 - INFO - root - Page:4, Index:11, RC-AutoCalib: An End-to-End Radar-Camera Automatic Calibration Network, https://arxiv.org/pdf/2505.22427, 2025-05-28
2025-11-11 23:50:54,930 - INFO - root - Page:4, Index:12, Bringing CLIP to the Clinic: Dynamic Soft Labels and Negation-Aware Learning for Medical Analysis, https://arxiv.org/pdf/2505.22079, 2025-05-28
2025-11-11 23:50:54,930 - INFO - root - Page:4, Index:13, Point-to-Region Loss for Semi-Supervised Point-Based Crowd Counting, https://arxiv.org/pdf/2505.21943, 2025-05-27
2025-11-11 23:50:54,930 - INFO - root - Page:4, Index:14, FRAMES-VQA: Benchmarking Fine-Tuning Robustness across Multi-Modal Shifts in Visual Question Answering, https://arxiv.org/pdf/2505.21755, 2025-06-20
2025-11-11 23:50:54,930 - INFO - root - Page:4, Index:15, Knowledge Distillation Approach for SOS Fusion Staging: Towards Fully Automated Skeletal Maturity Assessment, https://arxiv.org/pdf/2505.21561, 2025-05-26
2025-11-11 23:50:54,930 - INFO - root - Page:4, Index:16, Enhancing Vision Transformer Explainability Using Artificial Astrocytes, https://arxiv.org/pdf/2505.21513, 2025-05-20
2025-11-11 23:50:54,930 - INFO - root - Page:4, Index:17, Empowering Vector Graphics with Consistently Arbitrary Viewing and View-dependent Visibility, https://arxiv.org/pdf/2505.21377, 2025-05-27
2025-11-11 23:50:54,930 - INFO - root - Page:4, Index:18, Structure from Collision, https://arxiv.org/pdf/2505.21335, 2025-05-27
2025-11-11 23:50:54,932 - INFO - root - Page:4, Index:19, Boosting Adversarial Transferability via High-Frequency Augmentation and Hierarchical-Gradient Fusion, https://arxiv.org/pdf/2505.21181, 2025-05-27
2025-11-11 23:50:54,932 - INFO - root - Page:4, Index:20, RefAV: Towards Planning-Centric Scenario Mining, https://arxiv.org/pdf/2505.20981, 2025-06-18
2025-11-11 23:50:54,932 - INFO - root - Page:4, Index:21, PMA: Towards Parameter-Efficient Point Cloud Understanding via Point Mamba Adapter, https://arxiv.org/pdf/2505.20941, 2025-05-27
2025-11-11 23:50:54,936 - INFO - root - Page:4, Index:22, HuMoCon: Concept Discovery for Human Motion Understanding, https://arxiv.org/pdf/2505.20920, 2025-05-27
2025-11-11 23:50:54,937 - INFO - root - Page:4, Index:23, Exploring Timeline Control for Facial Motion Generation, https://arxiv.org/pdf/2505.20861, 2025-05-27
2025-11-11 23:50:54,937 - INFO - root - Page:4, Index:24, ConText-CIR: Learning from Concepts in Text for Composed Image Retrieval, https://arxiv.org/pdf/2505.20764, 2025-05-27
2025-11-11 23:50:54,938 - INFO - root - Page:4, Index:25, HCQA-1.5 @ Ego4D EgoSchema Challenge 2025, https://arxiv.org/pdf/2505.20644, 2025-05-26
2025-11-11 23:50:54,938 - INFO - root - Page:4, Index:26, Roboflow100-VL: A Multi-Domain Object Detection Benchmark for Vision-Language Models, https://arxiv.org/pdf/2505.20612, 2025-10-22
2025-11-11 23:50:54,938 - INFO - root - Page:4, Index:27, MotionPro: A Precise Motion Controller for Image-to-Video Generation, https://arxiv.org/pdf/2505.20287, 2025-05-26
2025-11-11 23:50:54,939 - INFO - root - Page:4, Index:28, Category-Agnostic Neural Object Rigging, https://arxiv.org/pdf/2505.20283, 2025-05-26
2025-11-11 23:50:54,939 - INFO - root - Page:4, Index:29, Towards Video to Piano Music Generation with Chain-of-Perform Support Benchmarks, https://arxiv.org/pdf/2505.20038, 2025-05-26
2025-11-11 23:50:54,939 - INFO - root - Page:4, Index:30, Can Visual Encoder Learn to See Arrows?, https://arxiv.org/pdf/2505.19944, 2025-05-26
2025-11-11 23:50:54,939 - INFO - root - Page:4, Index:31, GoLF-NRT: Integrating Global Context and Local Geometry for Few-Shot View Synthesis, https://arxiv.org/pdf/2505.19813, 2025-05-26
2025-11-11 23:50:54,940 - INFO - root - Page:4, Index:32, Depth-Guided Bundle Sampling for Efficient Generalizable Neural Radiance Field Reconstruction, https://arxiv.org/pdf/2505.19793, 2025-05-26
2025-11-11 23:50:54,940 - INFO - root - Page:4, Index:33, SuperAD: A Training-free Anomaly Classification and Segmentation Method for CVPR 2025 VAND 3.0 Workshop Challenge Track 1: Adapt & Detect, https://arxiv.org/pdf/2505.19750, 2025-05-27
2025-11-11 23:50:54,941 - INFO - root - Page:4, Index:34, Knowledge-Aligned Counterfactual-Enhancement Diffusion Perception for Unsupervised Cross-Domain Visual Emotion Recognition, https://arxiv.org/pdf/2505.19694, 2025-05-26
2025-11-11 23:50:54,942 - INFO - root - Page:4, Index:35, Rotation-Equivariant Self-Supervised Method in Image Denoising, https://arxiv.org/pdf/2505.19618, 2025-05-26
2025-11-11 23:50:54,943 - INFO - root - Page:4, Index:36, NTIRE 2025 Challenge on Video Quality Enhancement for Video Conferencing: Datasets, Methods and Results, https://arxiv.org/pdf/2505.18988, 2025-05-25
2025-11-11 23:50:54,943 - INFO - root - Page:4, Index:37, Geometry-guided Online 3D Video Synthesis with Multi-View Temporal Consistency, https://arxiv.org/pdf/2505.18932, 2025-05-24
2025-11-11 23:50:54,943 - INFO - root - Page:4, Index:38, Digital Overconsumption and Waste: A Closer Look at the Impacts of Generative AI, https://arxiv.org/pdf/2505.18894, 2025-05-24
2025-11-11 23:50:54,944 - INFO - root - Page:4, Index:39, VISTA: Vision-Language Inference for Training-Free Stock Time-Series Analysis, https://arxiv.org/pdf/2505.18570, 2025-06-11
2025-11-11 23:50:54,944 - INFO - root - Page:4, Index:40, Syn3DTxt: Embedding 3D Cues for Scene Text Generation, https://arxiv.org/pdf/2505.18479, 2025-05-23
2025-11-11 23:50:54,944 - INFO - root - Page:4, Index:41, CTRL-GS: Cascaded Temporal Residue Learning for 4D Gaussian Splatting, https://arxiv.org/pdf/2505.18306, 2025-05-31
2025-11-11 23:50:54,944 - INFO - root - Page:4, Index:42, DualTalk: Dual-Speaker Interaction for 3D Talking Head Conversations, https://arxiv.org/pdf/2505.18096, 2025-05-26
2025-11-11 23:50:54,944 - INFO - root - Page:4, Index:43, SeaLion: Semantic Part-Aware Latent Point Diffusion Models for 3D Generation, https://arxiv.org/pdf/2505.17721, 2025-07-07
2025-11-11 23:50:54,945 - INFO - root - Page:4, Index:44, PoseBH: Prototypical Multi-Dataset Training Beyond Human Pose Estimation, https://arxiv.org/pdf/2505.17475, 2025-05-23
2025-11-11 23:50:54,945 - INFO - root - Page:4, Index:45, Pursuing Temporal-Consistent Video Virtual Try-On via Dynamic Pose Interaction, https://arxiv.org/pdf/2505.16980, 2025-05-22
2025-11-11 23:50:54,945 - INFO - root - Page:4, Index:46, UniPhy: Learning a Unified Constitutive Model for Inverse Physics Simulation, https://arxiv.org/pdf/2505.16971, 2025-05-22
2025-11-11 23:50:54,945 - INFO - root - Page:4, Index:47, Tracking the Flight: Exploring a Computational Framework for Analyzing Escape Responses in Plains Zebra (Equus quagga), https://arxiv.org/pdf/2505.16882, 2025-05-23
2025-11-11 23:50:54,946 - INFO - root - Page:4, Index:48, Semi-Supervised State-Space Model with Dynamic Stacking Filter for Real-World Video Deraining, https://arxiv.org/pdf/2505.16811, 2025-05-22
2025-11-11 23:50:54,946 - INFO - root - Page:4, Index:49, SOLVE: Synergy of Language-Vision and End-to-End Networks for Autonomous Driving, https://arxiv.org/pdf/2505.16805, 2025-05-22
2025-11-11 23:50:54,946 - INFO - root - Fetching page 6 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=250
2025-11-11 23:51:03,554 - INFO - root - get_all_titles_from_web 
2025-11-11 23:51:03,724 - INFO - root - Page:5, Index:0, Four Eyes Are Better Than Two: Harnessing the Collaborative Potential of Large Models via Differentiated Thinking and Complementary Ensembles, https://arxiv.org/pdf/2505.16784, 2025-06-07
2025-11-11 23:51:03,860 - INFO - root - Page:5, Index:1, Single Domain Generalization for Few-Shot Counting via Universal Representation Matching, https://arxiv.org/pdf/2505.16778, 2025-05-22
2025-11-11 23:51:03,892 - INFO - root - Page:5, Index:2, Seeing Far and Clearly: Mitigating Hallucinations in MLLMs with Attention Causal Decoding, https://arxiv.org/pdf/2505.16652, 2025-06-07
2025-11-11 23:51:03,940 - INFO - root - Page:5, Index:3, Sketchy Bounding-box Supervision for 3D Instance Segmentation, https://arxiv.org/pdf/2505.16399, 2025-05-22
2025-11-11 23:51:04,008 - INFO - root - Page:5, Index:4, DeCafNet: Delegate and Conquer for Efficient Temporal Grounding in Long Videos, https://arxiv.org/pdf/2505.16376, 2025-05-22
2025-11-11 23:51:04,052 - INFO - root - Page:5, Index:5, NTIRE 2025 challenge on Text to Image Generation Model Quality Assessment, https://arxiv.org/pdf/2505.16314, 2025-05-22
2025-11-11 23:51:04,085 - INFO - root - Page:5, Index:6, Analyzing Hierarchical Structure in Vision Models with Sparse Autoencoders, https://arxiv.org/pdf/2505.15970, 2025-05-21
2025-11-11 23:51:04,098 - INFO - root - Page:5, Index:7, Efficient Data Driven Mixture-of-Expert Extraction from Trained Networks, https://arxiv.org/pdf/2505.15414, 2025-05-21
2025-11-11 23:51:04,121 - INFO - root - Page:5, Index:8, Mouse Lockbox Dataset: Behavior Recognition for Mice Solving Lockboxes, https://arxiv.org/pdf/2505.15408, 2025-06-17
2025-11-11 23:51:04,151 - INFO - root - Page:5, Index:9, Zero-Shot Gaze-based Volumetric Medical Image Segmentation, https://arxiv.org/pdf/2505.15256, 2025-06-10
2025-11-11 23:51:04,173 - INFO - root - Page:5, Index:10, Dual Precision Quantization for Efficient and Accurate Deep Neural Networks Inference, https://arxiv.org/pdf/2505.14638, 2025-05-20
2025-11-11 23:51:04,188 - INFO - root - Page:5, Index:11, Neural Video Compression with Context Modulation, https://arxiv.org/pdf/2505.14541, 2025-05-20
2025-11-11 23:51:04,197 - INFO - root - Page:5, Index:12, Selective Structured State Space for Multispectral-fused Small Target Detection, https://arxiv.org/pdf/2505.14043, 2025-05-23
2025-11-11 23:51:04,215 - INFO - root - Page:5, Index:13, OmniStyle: Filtering High Quality Style Transfer Data at Scale, https://arxiv.org/pdf/2505.14028, 2025-05-20
2025-11-11 23:51:04,232 - INFO - root - Page:5, Index:14, Domain Adaptation of VLM for Soccer Video Understanding, https://arxiv.org/pdf/2505.13860, 2025-07-07
2025-11-11 23:51:04,240 - INFO - root - Page:5, Index:15, Ground-V: Teaching VLMs to Ground Complex Instructions in Pixels, https://arxiv.org/pdf/2505.13788, 2025-05-19
2025-11-11 23:51:04,254 - INFO - root - Page:5, Index:16, FinePhys: Fine-grained Human Action Generation by Explicitly Incorporating Physical Laws for Effective Skeletal Guidance, https://arxiv.org/pdf/2505.13437, 2025-05-19
2025-11-11 23:51:04,264 - INFO - root - Page:5, Index:17, The Way Up: A Dataset for Hold Usage Detection in Sport Climbing, https://arxiv.org/pdf/2505.12854, 2025-05-19
2025-11-11 23:51:04,281 - INFO - root - Page:5, Index:18, PEER pressure: Model-to-Model Regularization for Single Source Domain Generalization, https://arxiv.org/pdf/2505.12745, 2025-05-19
2025-11-11 23:51:04,289 - INFO - root - Page:5, Index:19, Mamba-Adaptor: State Space Model Adaptor for Visual Recognition, https://arxiv.org/pdf/2505.12685, 2025-05-19
2025-11-11 23:51:04,328 - INFO - root - Page:5, Index:20, Scalable Video-to-Dataset Generation for Cross-Platform Mobile Agents, https://arxiv.org/pdf/2505.12632, 2025-05-18
2025-11-11 23:51:04,363 - INFO - root - Page:5, Index:21, Degradation-Aware Feature Perturbation for All-in-One Image Restoration, https://arxiv.org/pdf/2505.12630, 2025-05-18
2025-11-11 23:51:04,392 - INFO - root - Page:5, Index:22, Guiding Diffusion with Deep Geometric Moments: Balancing Fidelity and Variation, https://arxiv.org/pdf/2505.12486, 2025-05-18
2025-11-11 23:51:04,396 - INFO - root - Page:5, Index:23, Learning to Highlight Audio by Watching Movies, https://arxiv.org/pdf/2505.12154, 2025-05-17
2025-11-11 23:51:04,398 - INFO - root - Page:5, Index:24, Understanding the Capabilities of Molecular Graph Neural Networks in Materials Science Through Multimodal Learning and Physical Context Encoding, https://arxiv.org/pdf/2505.12137, 2025-05-17
2025-11-11 23:51:04,400 - INFO - root - Page:5, Index:25, iSegMan: Interactive Segment-and-Manipulate 3D Gaussians, https://arxiv.org/pdf/2505.11934, 2025-05-17
2025-11-11 23:51:04,401 - INFO - root - Page:5, Index:26, Self-Learning Hyperspectral and Multispectral Image Fusion via Adaptive Residual Guided Subspace Diffusion Model, https://arxiv.org/pdf/2505.11800, 2025-05-16
2025-11-11 23:51:04,416 - INFO - root - Page:5, Index:27, X-Edit: Detecting and Localizing Edits in Images Altered by Text-Guided Diffusion Models, https://arxiv.org/pdf/2505.11753, 2025-05-16
2025-11-11 23:51:04,418 - INFO - root - Page:5, Index:28, MTevent: A Multi-Task Event Camera Dataset for 6D Pose Estimation and Moving Object Detection, https://arxiv.org/pdf/2505.11282, 2025-06-02
2025-11-11 23:51:04,419 - INFO - root - Page:5, Index:29, Imputation-free and Alignment-free: Incomplete Multi-view Clustering Driven by Consensus Semantic Learning, https://arxiv.org/pdf/2505.11182, 2025-05-16
2025-11-11 23:51:04,420 - INFO - root - Page:5, Index:30, MultiLink: Multi-class Structure Recovery via Agglomerative Clustering and Model Selection, https://arxiv.org/pdf/2505.10874, 2025-05-16
2025-11-11 23:51:04,421 - INFO - root - Page:5, Index:31, RefPose: Leveraging Reference Geometric Correspondences for Accurate 6D Pose Estimation of Unseen Objects, https://arxiv.org/pdf/2505.10841, 2025-05-16
2025-11-11 23:51:04,422 - INFO - root - Page:5, Index:32, MoCLIP: Motion-Aware Fine-Tuning and Distillation of CLIP for Human Motion Generation, https://arxiv.org/pdf/2505.10810, 2025-05-15
2025-11-11 23:51:04,424 - INFO - root - Page:5, Index:33, Automated Detection of Salvin's Albatrosses: Improving Deep Learning Tools for Aerial Wildlife Surveys, https://arxiv.org/pdf/2505.10737, 2025-05-15
2025-11-11 23:51:04,425 - INFO - root - Page:5, Index:34, Advancing Multiple Instance Learning with Continual Learning for Whole Slide Imaging, https://arxiv.org/pdf/2505.10649, 2025-05-15
2025-11-11 23:51:04,433 - INFO - root - Page:5, Index:35, Inferring Driving Maps by Deep Learning-based Trail Map Extraction, https://arxiv.org/pdf/2505.10258, 2025-05-15
2025-11-11 23:51:04,439 - INFO - root - Page:5, Index:36, Behind Maya: Building a Multilingual Vision Language Model, https://arxiv.org/pdf/2505.08910, 2025-05-15
2025-11-11 23:51:04,448 - INFO - root - Page:5, Index:37, PosterO: Structuring Layout Trees to Enable Language Models in Generalized Content-Aware Layout Generation, https://arxiv.org/pdf/2505.07843, 2025-05-26
2025-11-11 23:51:04,471 - INFO - root - Page:5, Index:38, Prototype Augmented Hypernetworks for Continual Learning, https://arxiv.org/pdf/2505.07450, 2025-05-16
2025-11-11 23:51:04,499 - INFO - root - Fetching page 7 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=300
2025-11-11 23:51:11,952 - INFO - root - get_all_titles_from_web 
2025-11-11 23:51:11,952 - INFO - root - Page:6, Index:0, Convex Relaxation for Robust Vanishing Point Estimation in Manhattan World, https://arxiv.org/pdf/2505.04788, 2025-06-05
2025-11-11 23:51:11,954 - INFO - root - Page:6, Index:1, S3D: Sketch-Driven 3D Model Generation, https://arxiv.org/pdf/2505.04185, 2025-06-03
2025-11-11 23:51:11,954 - INFO - root - Page:6, Index:2, Generating Synthetic Data via Augmentations for Improved Facial Resemblance in DreamBooth and InstantID, https://arxiv.org/pdf/2505.03557, 2025-07-17
2025-11-11 23:51:11,954 - INFO - root - Page:6, Index:3, CAV-MAE Sync: Improving Contrastive Audio-Visual Mask Autoencoders via Fine-Grained Alignment, https://arxiv.org/pdf/2505.01237, 2025-05-21
2025-11-11 23:51:11,955 - INFO - root - Fetching page 8 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=350
2025-11-11 23:51:19,023 - INFO - root - get_all_titles_from_web 
2025-11-11 23:51:19,023 - INFO - root - Page:7, Index:0, Where's the liability in the Generative Era? Recovery-based Black-Box Detection of AI-Generated Content, https://arxiv.org/pdf/2505.01008, 2025-08-25
2025-11-11 23:51:19,023 - INFO - root - Page:7, Index:1, SpatialLLM: A Compound 3D-Informed Design towards Spatially-Intelligent Large Multimodal Models, https://arxiv.org/pdf/2505.00788, 2025-06-10
2025-11-11 23:51:19,025 - INFO - root - Page:7, Index:2, Prisma: An Open Source Toolkit for Mechanistic Interpretability in Vision and Video, https://arxiv.org/pdf/2504.19475, 2025-06-03
2025-11-11 23:51:19,025 - INFO - root - Page:7, Index:3, SSL4Eco: A Global Seasonal Dataset for Geospatial Foundation Models in Ecology, https://arxiv.org/pdf/2504.18256, 2025-10-20
2025-11-11 23:51:19,025 - INFO - root - Page:7, Index:4, Vision-Language Models Are Not Pragmatically Competent in Referring Expression Generation, https://arxiv.org/pdf/2504.16060, 2025-07-30
2025-11-11 23:51:19,026 - INFO - root - Fetching page 9 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=400
2025-11-11 23:51:26,155 - INFO - root - get_all_titles_from_web 
2025-11-11 23:51:26,155 - INFO - root - Page:8, Index:0, Leveraging Automatic CAD Annotations for Supervised Learning in 3D Scene Understanding, https://arxiv.org/pdf/2504.13580, 2025-05-16
2025-11-11 23:51:26,155 - INFO - root - Page:8, Index:1, CAP-Net: A Unified Network for 6D Pose and Size Estimation of Categorical Articulated Parts from a Single RGB-D Image, https://arxiv.org/pdf/2504.11230, 2025-06-02
2025-11-11 23:51:26,156 - INFO - root - Page:8, Index:2, Video Summarization with Large Language Models, https://arxiv.org/pdf/2504.11199, 2025-06-05
2025-11-11 23:51:26,156 - INFO - root - Page:8, Index:3, R-TPT: Improving Adversarial Robustness of Vision-Language Models through Test-Time Prompt Tuning, https://arxiv.org/pdf/2504.11195, 2025-08-27
2025-11-11 23:51:26,156 - INFO - root - Page:8, Index:4, TerraMesh: A Planetary Mosaic of Multimodal Earth Observation Data, https://arxiv.org/pdf/2504.11172, 2025-08-01
2025-11-11 23:51:26,157 - INFO - root - Page:8, Index:5, Seeing like a Cephalopod: Colour Vision with a Monochrome Event Camera, https://arxiv.org/pdf/2504.10984, 2025-06-06
2025-11-11 23:51:26,157 - INFO - root - Page:8, Index:6, Hearing Anywhere in Any Environment, https://arxiv.org/pdf/2504.10746, 2025-06-04
2025-11-11 23:51:26,157 - INFO - root - Fetching page 10 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=450
2025-11-11 23:51:35,722 - INFO - root - get_all_titles_from_web 
2025-11-11 23:51:35,723 - INFO - root - Page:9, Index:0, Correlative and Discriminative Label Grouping for Multi-Label Visual Prompt Tuning, https://arxiv.org/pdf/2504.09990, 2025-07-09
2025-11-11 23:51:35,723 - INFO - root - Page:9, Index:1, SPICE: A Synergistic, Precise, Iterative, and Customizable Image Editing Workflow, https://arxiv.org/pdf/2504.09697, 2025-10-16
2025-11-11 23:51:35,723 - INFO - root - Page:9, Index:2, Mimic In-Context Learning for Multimodal Tasks, https://arxiv.org/pdf/2504.08851, 2025-05-17
2025-11-11 23:51:35,723 - INFO - root - Page:9, Index:3, Digital Twin Catalog: A Large-Scale Photorealistic 3D Object Digital Twin Dataset, https://arxiv.org/pdf/2504.08541, 2025-05-18
2025-11-11 23:51:35,724 - INFO - root - Page:9, Index:4, MMLA: Multi-Environment, Multi-Species, Low-Altitude Drone Dataset, https://arxiv.org/pdf/2504.07744, 2025-10-22
2025-11-11 23:51:35,724 - INFO - root - Fetching page 11 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=500
2025-11-11 23:51:46,300 - INFO - root - get_all_titles_from_web 
2025-11-11 23:51:46,300 - INFO - root - Page:10, Index:0, PromptHMR: Promptable Human Mesh Recovery, https://arxiv.org/pdf/2504.06397, 2025-05-23
2025-11-11 23:51:46,301 - INFO - root - Page:10, Index:1, SCAM: A Real-World Typographic Robustness Evaluation for Multimodal Foundation Models, https://arxiv.org/pdf/2504.04893, 2025-09-26
2025-11-11 23:51:46,301 - INFO - root - Fetching page 12 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=550
2025-11-11 23:51:58,989 - INFO - root - get_all_titles_from_web 
2025-11-11 23:51:58,990 - INFO - root - Page:11, Index:0, Charm: The Missing Piece in ViT fine-tuning for Image Aesthetic Assessment, https://arxiv.org/pdf/2504.02522, 2025-05-15
2025-11-11 23:51:58,990 - INFO - root - Page:11, Index:1, T*: Re-thinking Temporal Search for Long-Form Video Understanding, https://arxiv.org/pdf/2504.02259, 2025-08-24
2025-11-11 23:51:58,990 - INFO - root - Page:11, Index:2, CoMatcher: Multi-View Collaborative Feature Matching, https://arxiv.org/pdf/2504.01872, 2025-08-20
2025-11-11 23:51:58,990 - INFO - root - Page:11, Index:3, Think Small, Act Big: Primitive Prompt Learning for Lifelong Robot Manipulation, https://arxiv.org/pdf/2504.00420, 2025-06-01
2025-11-11 23:51:58,991 - INFO - root - Fetching page 13 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=600
2025-11-11 23:52:07,681 - INFO - root - get_all_titles_from_web 
2025-11-11 23:52:07,681 - INFO - root - Page:12, Index:0, It's a (Blind) Match! Towards Vision-Language Correspondence without Parallel Data, https://arxiv.org/pdf/2503.24129, 2025-05-29
2025-11-11 23:52:07,682 - INFO - root - Page:12, Index:1, ReferDINO-Plus: 2nd Solution for 4th PVUW MeViS Challenge at CVPR 2025, https://arxiv.org/pdf/2503.23509, 2025-05-29
2025-11-11 23:52:07,682 - INFO - root - Page:12, Index:2, A Unified Image-Dense Annotation Generation Model for Underwater Scenes, https://arxiv.org/pdf/2503.21771, 2025-07-27
2025-11-11 23:52:07,682 - INFO - root - Fetching page 14 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=650
2025-11-11 23:52:14,273 - INFO - root - get_all_titles_from_web 
2025-11-11 23:52:14,273 - INFO - root - Page:13, Index:0, Learning Class Prototypes for Unified Sparse Supervised 3D Object Detection, https://arxiv.org/pdf/2503.21099, 2025-06-13
2025-11-11 23:52:14,273 - INFO - root - Page:13, Index:1, LATTE-MV: Learning to Anticipate Table Tennis Hits from Monocular Videos, https://arxiv.org/pdf/2503.20936, 2025-09-01
2025-11-11 23:52:14,273 - INFO - root - Page:13, Index:2, BizGen: Advancing Article-level Visual Text Rendering for Infographics Generation, https://arxiv.org/pdf/2503.20672, 2025-07-02
2025-11-11 23:52:14,273 - INFO - root - Page:13, Index:3, ITA-MDT: Image-Timestep-Adaptive Masked Diffusion Transformer Framework for Image-Based Virtual Try-On, https://arxiv.org/pdf/2503.20418, 2025-06-01
2025-11-11 23:52:14,273 - INFO - root - Page:13, Index:4, Faster Parameter-Efficient Tuning with Token Redundancy Reduction, https://arxiv.org/pdf/2503.20282, 2025-08-26
2025-11-11 23:52:14,273 - INFO - root - Page:13, Index:5, DINeMo: Learning Neural Mesh Models with no 3D Annotations, https://arxiv.org/pdf/2503.20220, 2025-06-09
2025-11-11 23:52:14,273 - INFO - root - Page:13, Index:6, Scaling Vision Pre-Training to 4K Resolution, https://arxiv.org/pdf/2503.19903, 2025-08-03
2025-11-11 23:52:14,273 - INFO - root - Page:13, Index:7, GENIUS: A Generative Framework for Universal Multimodal Search, https://arxiv.org/pdf/2503.19868, 2025-06-05
2025-11-11 23:52:14,273 - INFO - root - Fetching page 15 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=700
2025-11-11 23:52:24,813 - INFO - root - get_all_titles_from_web 
2025-11-11 23:52:24,813 - INFO - root - Page:14, Index:0, Galaxy Walker: Geometry-aware VLMs For Galaxy-scale Understanding, https://arxiv.org/pdf/2503.18578, 2025-05-25
2025-11-11 23:52:24,814 - INFO - root - Page:14, Index:1, LookCloser: Frequency-aware Radiance Field for Tiny-Detail Scene, https://arxiv.org/pdf/2503.18513, 2025-07-29
2025-11-11 23:52:24,814 - INFO - root - Fetching page 16 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=750
2025-11-11 23:52:34,357 - INFO - root - get_all_titles_from_web 
2025-11-11 23:52:34,370 - INFO - root - Page:15, Index:0, LoTUS: Large-Scale Machine Unlearning with a Taste of Uncertainty, https://arxiv.org/pdf/2503.18314, 2025-05-29
2025-11-11 23:52:34,386 - INFO - root - Page:15, Index:1, MammAlps: A multi-view video behavior monitoring dataset of wild mammals in the Swiss Alps, https://arxiv.org/pdf/2503.18223, 2025-06-04
2025-11-11 23:52:34,393 - INFO - root - Page:15, Index:2, Progressive Prompt Detailing for Improved Alignment in Text-to-Image Generative Models, https://arxiv.org/pdf/2503.17794, 2025-05-30
2025-11-11 23:52:34,399 - INFO - root - Page:15, Index:3, CountLLM: Towards Generalizable Repetitive Action Counting via Large Language Model, https://arxiv.org/pdf/2503.17690, 2025-06-29
2025-11-11 23:52:34,399 - INFO - root - Page:15, Index:4, TaoAvatar: Real-Time Lifelike Full-Body Talking Avatars for Augmented Reality via 3D Gaussian Splatting, https://arxiv.org/pdf/2503.17032, 2025-07-23
2025-11-11 23:52:34,403 - INFO - root - Page:15, Index:5, Generalized Few-shot 3D Point Cloud Segmentation with Vision-Language Model, https://arxiv.org/pdf/2503.16282, 2025-05-20
2025-11-11 23:52:34,403 - INFO - root - Fetching page 17 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=800
2025-11-11 23:52:43,987 - INFO - root - get_all_titles_from_web 
2025-11-11 23:52:43,987 - INFO - root - Page:16, Index:0, High Temporal Consistency through Semantic Similarity Propagation in Semi-Supervised Video Semantic Segmentation for Autonomous Flight, https://arxiv.org/pdf/2503.15676, 2025-06-26
2025-11-11 23:52:43,988 - INFO - root - Page:16, Index:1, DPFlow: Adaptive Optical Flow Estimation with a Dual-Pyramid Framework, https://arxiv.org/pdf/2503.14880, 2025-09-29
2025-11-11 23:52:43,988 - INFO - root - Fetching page 18 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=850
2025-11-11 23:52:52,692 - INFO - root - get_all_titles_from_web 
2025-11-11 23:52:52,692 - INFO - root - Page:17, Index:0, From Head to Tail: Towards Balanced Representation in Large Vision-Language Models through Adaptive Data Calibration, https://arxiv.org/pdf/2503.12821, 2025-05-29
2025-11-11 23:52:52,692 - INFO - root - Page:17, Index:1, MambaIC: State Space Models for High-Performance Learned Image Compression, https://arxiv.org/pdf/2503.12461, 2025-08-22
2025-11-11 23:52:52,694 - INFO - root - Page:17, Index:2, Localized Concept Erasure for Text-to-Image Diffusion Models Using Training-Free Gated Low-Rank Adaptation, https://arxiv.org/pdf/2503.12356, 2025-07-09
2025-11-11 23:52:52,694 - INFO - root - Page:17, Index:3, TASTE-Rob: Advancing Video Generation of Task-Oriented Hand-Object Interaction for Generalizable Robotic Manipulation, https://arxiv.org/pdf/2503.11423, 2025-06-05
2025-11-11 23:52:52,694 - INFO - root - Page:17, Index:4, Panopticon: Advancing Any-Sensor Foundation Models for Earth Observation, https://arxiv.org/pdf/2503.10845, 2025-08-01
2025-11-11 23:52:52,694 - INFO - root - Page:17, Index:5, Transformers without Normalization, https://arxiv.org/pdf/2503.10622, 2025-06-14
2025-11-11 23:52:52,694 - INFO - root - Page:17, Index:6, dFLMoE: Decentralized Federated Learning via Mixture of Experts for Medical Data Analysis, https://arxiv.org/pdf/2503.10412, 2025-05-19
2025-11-11 23:52:52,694 - INFO - root - Fetching page 19 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=900
2025-11-11 23:53:02,470 - INFO - root - get_all_titles_from_web 
2025-11-11 23:53:02,470 - INFO - root - Page:18, Index:0, Project-Probe-Aggregate: Efficient Fine-Tuning for Group Robustness, https://arxiv.org/pdf/2503.09487, 2025-08-26
2025-11-11 23:53:02,470 - INFO - root - Page:18, Index:1, VLog: Video-Language Models by Generative Retrieval of Narration Vocabulary, https://arxiv.org/pdf/2503.09402, 2025-06-09
2025-11-11 23:53:02,470 - INFO - root - Fetching page 20 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=950
2025-11-11 23:53:13,220 - INFO - root - get_all_titles_from_web 
2025-11-11 23:53:13,222 - INFO - root - Page:19, Index:0, Escaping Plato's Cave: Towards the Alignment of 3D and Text Latent Spaces, https://arxiv.org/pdf/2503.05283, 2025-06-04
2025-11-11 23:53:13,225 - INFO - root - Page:19, Index:1, FluidNexus: 3D Fluid Reconstruction and Prediction from a Single Video, https://arxiv.org/pdf/2503.04720, 2025-07-09
2025-11-11 23:53:13,226 - INFO - root - Page:19, Index:2, Question-Aware Gaussian Experts for Audio-Visual Question Answering, https://arxiv.org/pdf/2503.04459, 2025-06-11
2025-11-11 23:53:13,226 - INFO - root - Page:19, Index:3, Q-Eval-100K: Evaluating Visual Quality and Alignment Level for Text-to-Vision Content, https://arxiv.org/pdf/2503.02357, 2025-06-15
2025-11-11 23:53:13,226 - INFO - root - Fetching page 21 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=1000
2025-11-11 23:53:22,051 - INFO - root - get_all_titles_from_web 
2025-11-11 23:53:22,051 - INFO - root - Page:20, Index:0, Data Distributional Properties As Inductive Bias for Systematic Generalization, https://arxiv.org/pdf/2502.20499, 2025-06-17
2025-11-11 23:53:22,052 - INFO - root - Page:20, Index:1, Knowledge Bridger: Towards Training-free Missing Modality Completion, https://arxiv.org/pdf/2502.19834, 2025-06-17
2025-11-11 23:53:22,052 - INFO - root - Fetching page 22 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=1050
2025-11-11 23:53:32,215 - INFO - root - get_all_titles_from_web 
2025-11-11 23:53:32,215 - INFO - root - Page:21, Index:0, MALT Diffusion: Memory-Augmented Latent Transformers for Any-Length Video Generation, https://arxiv.org/pdf/2502.12632, 2025-07-08
2025-11-11 23:53:32,215 - INFO - root - Page:21, Index:1, ILIAS: Instance-Level Image retrieval At Scale, https://arxiv.org/pdf/2502.11748, 2025-06-23
2025-11-11 23:53:32,215 - INFO - root - Page:21, Index:2, Distraction is All You Need for Multimodal Large Language Model Jailbreaking, https://arxiv.org/pdf/2502.10794, 2025-06-16
2025-11-11 23:53:32,215 - INFO - root - Page:21, Index:3, Spatial457: A Diagnostic Benchmark for 6D Spatial Reasoning of Large Multimodal Models, https://arxiv.org/pdf/2502.08636, 2025-06-08
2025-11-11 23:53:32,215 - INFO - root - Page:21, Index:4, TRAVEL: Training-Free Retrieval and Alignment for Vision-and-Language Navigation, https://arxiv.org/pdf/2502.07306, 2025-06-09
2025-11-11 23:53:32,215 - INFO - root - Page:21, Index:5, DiTASK: Multi-Task Fine-Tuning with Diffeomorphic Transformations, https://arxiv.org/pdf/2502.06029, 2025-06-01
2025-11-11 23:53:32,215 - INFO - root - Page:21, Index:6, ConceptAttention: Diffusion Transformers Learn Highly Interpretable Features, https://arxiv.org/pdf/2502.04320, 2025-07-01
2025-11-11 23:53:32,215 - INFO - root - Page:21, Index:7, GCE-Pose: Global Context Enhancement for Category-level Object Pose Estimation, https://arxiv.org/pdf/2502.04293, 2025-06-24
2025-11-11 23:53:32,215 - INFO - root - Page:21, Index:8, Calibrated Multi-Preference Optimization for Aligning Diffusion Models, https://arxiv.org/pdf/2502.02588, 2025-09-26
2025-11-11 23:53:32,215 - INFO - root - Page:21, Index:9, Instruct-4DGS: Efficient Dynamic Scene Editing via 4D Gaussian-based Static-Dynamic Separation, https://arxiv.org/pdf/2502.02091, 2025-07-01
2025-11-11 23:53:32,215 - INFO - root - Page:21, Index:10, Low-Resource Video Super-Resolution using Memory, Wavelets, and Deformable Convolutions, https://arxiv.org/pdf/2502.01816, 2025-06-19
2025-11-11 23:53:32,215 - INFO - root - Page:21, Index:11, Bridging Text and Crystal Structures: Literature-driven Contrastive Learning for Materials Science, https://arxiv.org/pdf/2501.12919, 2025-06-18
2025-11-11 23:53:32,215 - INFO - root - Page:21, Index:12, T2ISafety: Benchmark for Assessing Fairness, Toxicity, and Privacy in Image Generation, https://arxiv.org/pdf/2501.12612, 2025-07-25
2025-11-11 23:53:32,215 - INFO - root - Page:21, Index:13, Fine-Grained Image-Text Correspondence with Cost Aggregation for Open-Vocabulary Part Segmentation, https://arxiv.org/pdf/2501.09688, 2025-08-08
2025-11-11 23:53:32,215 - INFO - root - Fetching page 23 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=1100
2025-11-11 23:53:42,745 - INFO - root - get_all_titles_from_web 
2025-11-11 23:53:42,745 - INFO - root - Page:22, Index:0, Bias for Action: Video Implicit Neural Representations with Bias Modulation, https://arxiv.org/pdf/2501.09277, 2025-06-06
2025-11-11 23:53:42,746 - INFO - root - Page:22, Index:1, MonSter++: Unified Stereo Matching, Multi-view Stereo, and Real-time Stereo with Monodepth Priors, https://arxiv.org/pdf/2501.08643, 2025-09-25
2025-11-11 23:53:42,746 - INFO - root - Page:22, Index:2, Go-with-the-Flow: Motion-Controllable Video Diffusion Models Using Real-Time Warped Noise, https://arxiv.org/pdf/2501.08331, 2025-08-06
2025-11-11 23:53:42,746 - INFO - root - Page:22, Index:3, Nonisotropic Gaussian Diffusion for Realistic 3D Human Motion Prediction, https://arxiv.org/pdf/2501.06035, 2025-07-08
2025-11-11 23:53:42,746 - INFO - root - Page:22, Index:4, Discovering Hidden Visual Concepts Beyond Linguistic Input in Infant Learning, https://arxiv.org/pdf/2501.05205, 2025-06-13
2025-11-11 23:53:42,746 - INFO - root - Page:22, Index:5, PERSE: Personalized 3D Generative Avatars from A Single Portrait, https://arxiv.org/pdf/2412.21206, 2025-09-28
2025-11-11 23:53:42,748 - INFO - root - Page:22, Index:6, MaskGaussian: Adaptive 3D Gaussian Representation from Probabilistic Masks, https://arxiv.org/pdf/2412.20522, 2025-06-14
2025-11-11 23:53:42,748 - INFO - root - Page:22, Index:7, SimLTD: Simple Supervised and Semi-Supervised Long-Tailed Object Detection, https://arxiv.org/pdf/2412.20047, 2025-06-09
2025-11-11 23:53:42,748 - INFO - root - Page:22, Index:8, Conditional Balance: Improving Multi-Conditioning Trade-Offs in Image Generation, https://arxiv.org/pdf/2412.19853, 2025-08-03
2025-11-11 23:53:42,748 - INFO - root - Fetching page 24 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=1150
2025-11-11 23:53:52,043 - INFO - root - get_all_titles_from_web 
2025-11-11 23:53:52,043 - INFO - root - Page:23, Index:0, CoCoGaussian: Leveraging Circle of Confusion for Gaussian Splatting from Defocused Images, https://arxiv.org/pdf/2412.16028, 2025-05-15
2025-11-11 23:53:52,044 - INFO - root - Page:23, Index:1, EnergyMoGen: Compositional Human Motion Generation with Energy-Based Diffusion Model in Latent Space, https://arxiv.org/pdf/2412.14706, 2025-06-04
2025-11-11 23:53:52,044 - INFO - root - Page:23, Index:2, DarkIR: Robust Low-Light Image Restoration, https://arxiv.org/pdf/2412.13443, 2025-10-14
2025-11-11 23:53:52,044 - INFO - root - Page:23, Index:3, FastVLM: Efficient Vision Encoding for Vision Language Models, https://arxiv.org/pdf/2412.13303, 2025-05-15
2025-11-11 23:53:52,044 - INFO - root - Page:23, Index:4, Real-time Free-view Human Rendering from Sparse-view RGB Videos using Double Unprojected Textures, https://arxiv.org/pdf/2412.13183, 2025-06-20
2025-11-11 23:53:52,045 - INFO - root - Page:23, Index:5, CondiMen: Conditional Multi-Person Mesh Recovery, https://arxiv.org/pdf/2412.13058, 2025-06-04
2025-11-11 23:53:52,045 - INFO - root - Page:23, Index:6, MASt3R-SLAM: Real-Time Dense SLAM with 3D Reconstruction Priors, https://arxiv.org/pdf/2412.12392, 2025-06-02
2025-11-11 23:53:52,046 - INFO - root - Page:23, Index:7, DynamicScaler: Seamless and Scalable Video Generation for Panoramic Scenes, https://arxiv.org/pdf/2412.11100, 2025-10-04
2025-11-11 23:53:52,046 - INFO - root - Page:23, Index:8, SnapGen-V: Generating a Five-Second Video within Five Seconds on a Mobile Device, https://arxiv.org/pdf/2412.10494, 2025-06-09
2025-11-11 23:53:52,046 - INFO - root - Page:23, Index:9, Mr. DETR++: Instructive Multi-Route Training for Detection Transformers with Mixture-of-Experts, https://arxiv.org/pdf/2412.10028, 2025-06-26
2025-11-11 23:53:52,046 - INFO - root - Page:23, Index:10, LinGen: Towards High-Resolution Minute-Length Text-to-Video Generation with Linear Computational Complexity, https://arxiv.org/pdf/2412.09856, 2025-05-24
2025-11-11 23:53:52,046 - INFO - root - Page:23, Index:11, Gaze-LLE: Gaze Target Estimation via Large-Scale Learned Encoders, https://arxiv.org/pdf/2412.09586, 2025-06-03
2025-11-11 23:53:52,046 - INFO - root - Fetching page 25 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=1200
2025-11-11 23:53:59,801 - INFO - root - get_all_titles_from_web 
2025-11-11 23:53:59,801 - INFO - root - Page:24, Index:0, From Slow Bidirectional to Fast Autoregressive Video Diffusion Models, https://arxiv.org/pdf/2412.07772, 2025-09-23
2025-11-11 23:53:59,801 - INFO - root - Page:24, Index:1, Rate-In: Information-Driven Adaptive Dropout Rates for Improved Inference-Time Uncertainty Estimation, https://arxiv.org/pdf/2412.07169, 2025-06-03
2025-11-11 23:53:59,803 - INFO - root - Page:24, Index:2, FIRE: Robust Detection of Diffusion-Generated Images via Frequency-Guided Reconstruction Error, https://arxiv.org/pdf/2412.07140, 2025-11-03
2025-11-11 23:53:59,803 - INFO - root - Page:24, Index:3, Birth and Death of a Rose, https://arxiv.org/pdf/2412.05278, 2025-06-05
2025-11-11 23:53:59,804 - INFO - root - Page:24, Index:4, DualPM: Dual Posed-Canonical Point Maps for 3D Shape and Pose Reconstruction, https://arxiv.org/pdf/2412.04464, 2025-08-14
2025-11-11 23:53:59,804 - INFO - root - Page:24, Index:5, SeeGround: See and Ground for Zero-Shot Open-Vocabulary 3D Visual Grounding, https://arxiv.org/pdf/2412.04383, 2025-05-29
2025-11-11 23:53:59,804 - INFO - root - ------------------------------------------------------------------------------------------------------------------------
2025-11-11 23:53:59,805 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\CVPR 2025\Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness.pdf
2025-11-11 23:53:59,813 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\CVPR 2025\OmniTrack++_ Omnidirectional Multi-Object Tracking by Learning Large-FoV Traject.pdf
2025-11-11 23:53:59,814 - INFO - root - 跳过已处理论文 Learning to Seek Evidence: A Verifiable Reasoning Agent with Causal Faithfulness Analysis：d:\ChatPaper\academic Papers\CVPR 2025\Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness.pdf
2025-11-11 23:53:59,815 - INFO - root - 跳过已处理论文 OmniTrack++: Omnidirectional Multi-Object Tracking by Learning Large-FoV Trajectory Feedback：d:\ChatPaper\academic Papers\CVPR 2025\OmniTrack++_ Omnidirectional Multi-Object Tracking by Learning Large-FoV Traject.pdf
2025-11-11 23:54:00,167 - INFO - root - 已生成汇总Excel表格: export\QCVPR 2025\论文汇总_QCVPR 2025_20251111_235359.xlsx
2025-11-11 23:54:00,173 - INFO - root - 已生成汇总Excel表格: export\QCVPR 2025\论文汇总_QCVPR 2025_20251111_235359.xlsx
2025-11-11 23:54:00,175 - INFO - root - summary time: 239.46 seconds
2025-11-11 23:55:17,186 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-11 23:55:17,187 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-11 23:55:17,189 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-11 23:55:17,946 - INFO - root - LLMClientManager: 指定使用客户端: DeepSeek
2025-11-11 23:55:17,946 - INFO - root - DeepSeekClient: API key found: 9f9e270e-b...
2025-11-11 23:55:17,946 - INFO - root - DeepSeekClient: 使用模式: 火山引擎
2025-11-11 23:55:17,946 - INFO - root - DeepSeekClient: 模型名称: deepseek-v3-1-terminus
2025-11-11 23:55:21,908 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-11 23:55:21,927 - INFO - root - DeepSeekClient: initialized successfully with model deepseek-v3-1-terminus
2025-11-11 23:55:21,927 - INFO - root - LLMClientManager: DeepSeek 客户端初始化成功
2025-11-11 23:55:21,928 - INFO - root - LLMClientManager: switched to DeepSeek client
2025-11-11 23:55:21,928 - INFO - root - 已手动切换到 LLM 客户端: DeepSeek
2025-11-11 23:55:21,928 - INFO - root - 使用 LLM 模型: deepseek-v3-1-terminus
2025-11-11 23:55:21,929 - INFO - root - 可用客户端: ['DeepSeek']
2025-11-11 23:55:21,929 - INFO - root - === 运行配置 ===
2025-11-11 23:55:21,930 - INFO - root - 处理模式: arxiv在线搜索
2025-11-11 23:55:21,930 - INFO - root - 关键词: CVPR 2026
2025-11-11 23:55:21,931 - INFO - root - 查询: CVPR 2026
2025-11-11 23:55:21,931 - INFO - root - 排序: None
2025-11-11 23:55:21,931 - INFO - root - 最近天数: 180
2025-11-11 23:55:21,932 - INFO - root - 最大处理数量: 2
2025-11-11 23:55:21,932 - INFO - root - 保存图片: 是
2025-11-11 23:55:21,933 - INFO - root - 输出语言: 中文
2025-11-11 23:55:21,934 - INFO - root - 强制重新处理: 否
2025-11-11 23:55:21,934 - INFO - root - ====================
2025-11-11 23:55:21,938 - INFO - root - 使用 arXiv 搜索模式（通过 chat_arxiv 模块获取）
2025-11-11 23:55:21,942 - INFO - root - Fetching page 1 with URL: https://arxiv.org/search/?query=CVPR+2026&searchtype=all&abstracts=show&order=-announced_date_first&size=50
2025-11-11 23:55:31,165 - INFO - root - get_all_titles_from_web 
2025-11-11 23:55:31,165 - INFO - root - Page:0, Index:0, Learning to Seek Evidence: A Verifiable Reasoning Agent with Causal Faithfulness Analysis, https://arxiv.org/pdf/2511.01425, 2025-11-03
2025-11-11 23:55:31,166 - INFO - root - Fetching page 2 with URL: https://arxiv.org/search/?query=CVPR+2026&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=50
2025-11-11 23:55:49,758 - INFO - root - ------------------------------------------------------------------------------------------------------------------------
2025-11-11 23:55:56,170 - INFO - root - 正在总结论文 1/1: Learning to Seek Evidence: A Verifiable Reasoning Agent with Causal Faithfulness Analysis
2025-11-11 23:56:04,598 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-11 23:56:48,675 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-11 23:56:48,675 - INFO - root - LLMClient: rate limit reached, sleeping 7.5s
2025-11-11 23:57:23,086 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-11 23:57:23,088 - INFO - root - 正在提取论文图片...
2025-11-11 23:57:23,282 - INFO - root - 已保存图片 1/10：./export\CVPR 2026\images\figure_1_page2.jpeg
2025-11-11 23:57:23,308 - INFO - root - 已保存图片 2/10：./export\CVPR 2026\images\figure_2_page2.jpeg
2025-11-11 23:57:23,329 - INFO - root - 已保存图片 3/10：./export\CVPR 2026\images\figure_3_page2.jpeg
2025-11-11 23:57:23,410 - INFO - root - 已保存图片 4/10：./export\CVPR 2026\images\figure_4_page2.jpeg
2025-11-11 23:57:23,732 - INFO - root - 已保存图片 5/10：./export\CVPR 2026\images\figure_5_page2.jpeg
2025-11-11 23:57:23,763 - INFO - root - 已保存图片 6/10：./export\CVPR 2026\images\figure_6_page2.jpeg
2025-11-11 23:57:23,780 - INFO - root - 已保存图片 7/10：./export\CVPR 2026\images\figure_7_page2.jpeg
2025-11-11 23:57:23,800 - INFO - root - 已保存图片 8/10：./export\CVPR 2026\images\figure_8_page2.jpeg
2025-11-11 23:57:23,867 - INFO - root - 已保存图片 9/10：./export\CVPR 2026\images\figure_9_page2.jpeg
2025-11-11 23:57:23,880 - INFO - root - 已保存图片 10/10：./export\CVPR 2026\images\figure_10_page2.jpeg
2025-11-11 23:57:23,882 - INFO - root - 成功添加图片 1：./export\CVPR 2026\images\figure_1_page2.jpeg
2025-11-11 23:57:23,882 - INFO - root - 成功添加图片 2：./export\CVPR 2026\images\figure_2_page2.jpeg
2025-11-11 23:57:23,882 - INFO - root - 成功添加图片 3：./export\CVPR 2026\images\figure_3_page2.jpeg
2025-11-11 23:57:23,882 - INFO - root - 成功添加图片 4：./export\CVPR 2026\images\figure_4_page2.jpeg
2025-11-11 23:57:23,883 - INFO - root - 成功添加图片 5：./export\CVPR 2026\images\figure_5_page2.jpeg
2025-11-11 23:57:23,883 - INFO - root - 成功添加图片 6：./export\CVPR 2026\images\figure_6_page2.jpeg
2025-11-11 23:57:23,883 - INFO - root - 成功添加图片 7：./export\CVPR 2026\images\figure_7_page2.jpeg
2025-11-11 23:57:23,883 - INFO - root - 成功添加图片 8：./export\CVPR 2026\images\figure_8_page2.jpeg
2025-11-11 23:57:23,883 - INFO - root - 成功添加图片 9：./export\CVPR 2026\images\figure_9_page2.jpeg
2025-11-11 23:57:23,883 - INFO - root - 成功添加图片 10：./export\CVPR 2026\images\figure_10_page2.jpeg
2025-11-11 23:57:23,883 - WARNING - root - 图片文件不存在: images/figure_10_page2.jpeg
2025-11-11 23:57:23,883 - WARNING - root - 图片在任何位置都不存在: figure_10_page2.jpeg
2025-11-11 23:57:23,883 - WARNING - root - 图片文件不存在: images/figure_9_page2.jpeg
2025-11-11 23:57:23,889 - WARNING - root - 图片在任何位置都不存在: figure_9_page2.jpeg
2025-11-11 23:57:23,889 - WARNING - root - 图片文件不存在: images/figure_8_page2.jpeg
2025-11-11 23:57:23,890 - WARNING - root - 图片在任何位置都不存在: figure_8_page2.jpeg
2025-11-11 23:57:23,890 - WARNING - root - 图片文件不存在: images/figure_7_page2.jpeg
2025-11-11 23:57:23,891 - WARNING - root - 图片在任何位置都不存在: figure_7_page2.jpeg
2025-11-11 23:57:23,894 - WARNING - root - 图片文件不存在: images/figure_6_page2.jpeg
2025-11-11 23:57:23,895 - WARNING - root - 图片在任何位置都不存在: figure_6_page2.jpeg
2025-11-11 23:57:23,896 - WARNING - root - 图片文件不存在: images/figure_5_page2.jpeg
2025-11-11 23:57:23,896 - WARNING - root - 图片在任何位置都不存在: figure_5_page2.jpeg
2025-11-11 23:57:23,896 - WARNING - root - 图片文件不存在: images/figure_4_page2.jpeg
2025-11-11 23:57:23,897 - WARNING - root - 图片在任何位置都不存在: figure_4_page2.jpeg
2025-11-11 23:57:23,897 - WARNING - root - 图片文件不存在: images/figure_3_page2.jpeg
2025-11-11 23:57:23,898 - WARNING - root - 图片在任何位置都不存在: figure_3_page2.jpeg
2025-11-11 23:57:23,899 - WARNING - root - 图片文件不存在: images/figure_2_page2.jpeg
2025-11-11 23:57:23,899 - WARNING - root - 图片在任何位置都不存在: figure_2_page2.jpeg
2025-11-11 23:57:23,899 - WARNING - root - 图片文件不存在: images/figure_1_page2.jpeg
2025-11-11 23:57:23,900 - WARNING - root - 图片在任何位置都不存在: figure_1_page2.jpeg
2025-11-11 23:57:23,900 - INFO - root - 已按文献标题重新组织图片存储
2025-11-11 23:57:23,902 - INFO - root - 论文《Learning to Seek Evidence: A Verifiable Reasoning Agent with Causal Faithfulness Analysis》的分析已保存到 ./export\CVPR 2026\Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness.md
2025-11-11 23:57:24,156 - INFO - root - 已生成汇总Excel表格: export\CVPR 2026\论文汇总_CVPR 2026_20251111_235723.xlsx
2025-11-11 23:57:24,157 - INFO - root - 已生成汇总Excel表格: export\CVPR 2026\论文汇总_CVPR 2026_20251111_235723.xlsx
2025-11-11 23:57:24,157 - INFO - root - summary time: 126.97 seconds
2025-11-12 00:05:42,953 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-12 00:05:42,954 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-12 00:05:42,955 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-12 00:05:44,203 - INFO - root - LLMClientManager: 指定使用客户端: DeepSeek
2025-11-12 00:05:44,204 - INFO - root - DeepSeekClient: API key found: 9f9e270e-b...
2025-11-12 00:05:44,204 - INFO - root - DeepSeekClient: 使用模式: 火山引擎
2025-11-12 00:05:44,204 - INFO - root - DeepSeekClient: 模型名称: deepseek-v3-1-terminus
2025-11-12 00:05:47,503 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 00:05:47,545 - INFO - root - DeepSeekClient: initialized successfully with model deepseek-v3-1-terminus
2025-11-12 00:05:47,546 - INFO - root - LLMClientManager: DeepSeek 客户端初始化成功
2025-11-12 00:05:47,547 - INFO - root - LLMClientManager: switched to DeepSeek client
2025-11-12 00:05:47,548 - INFO - root - 已手动切换到 LLM 客户端: DeepSeek
2025-11-12 00:05:47,548 - INFO - root - 使用 LLM 模型: deepseek-v3-1-terminus
2025-11-12 00:05:47,549 - INFO - root - 可用客户端: ['DeepSeek']
2025-11-12 00:05:47,549 - INFO - root - === 运行配置 ===
2025-11-12 00:05:47,550 - INFO - root - 处理模式: arxiv在线搜索
2025-11-12 00:05:47,550 - INFO - root - 关键词: CVPR 2026
2025-11-12 00:05:47,551 - INFO - root - 查询: CVPR 2026
2025-11-12 00:05:47,551 - INFO - root - 排序: None
2025-11-12 00:05:47,551 - INFO - root - 最近天数: 180
2025-11-12 00:05:47,552 - INFO - root - 最大处理数量: 2
2025-11-12 00:05:47,553 - INFO - root - 保存图片: 是
2025-11-12 00:05:47,553 - INFO - root - 输出语言: 中文
2025-11-12 00:05:47,553 - INFO - root - 强制重新处理: 否
2025-11-12 00:05:47,555 - INFO - root - ====================
2025-11-12 00:05:47,555 - INFO - root - 使用 arXiv 搜索模式（通过 chat_arxiv 模块获取）
2025-11-12 00:05:47,557 - INFO - root - Fetching page 1 with URL: https://arxiv.org/search/?query=CVPR+2026&searchtype=all&abstracts=show&order=-announced_date_first&size=50
2025-11-12 00:05:53,535 - INFO - root - get_all_titles_from_web 
2025-11-12 00:05:53,551 - INFO - root - Page:0, Index:0, Learning to Seek Evidence: A Verifiable Reasoning Agent with Causal Faithfulness Analysis, https://arxiv.org/pdf/2511.01425, 2025-11-03
2025-11-12 00:05:53,553 - INFO - root - Fetching page 2 with URL: https://arxiv.org/search/?query=CVPR+2026&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=50
2025-11-12 00:06:01,269 - INFO - root - ------------------------------------------------------------------------------------------------------------------------
2025-11-12 00:06:01,269 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\CVPR 2026\Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness.pdf
2025-11-12 00:06:01,289 - INFO - root - 跳过已处理论文 Learning to Seek Evidence: A Verifiable Reasoning Agent with Causal Faithfulness Analysis：d:\ChatPaper\academic Papers\CVPR 2026\Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness.pdf
2025-11-12 00:06:01,477 - INFO - root - 已生成汇总Excel表格: export\CVPR 2026\论文汇总_CVPR 2026_20251112_000601.xlsx
2025-11-12 00:06:01,477 - INFO - root - 已生成汇总Excel表格: export\CVPR 2026\论文汇总_CVPR 2026_20251112_000601.xlsx
2025-11-12 00:06:01,477 - INFO - root - summary time: 18.52 seconds
2025-11-12 00:08:42,185 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-12 00:08:42,188 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-12 00:08:42,190 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-12 00:08:44,079 - INFO - root - LLMClientManager: 指定使用客户端: DeepSeek
2025-11-12 00:08:44,085 - INFO - root - DeepSeekClient: API key found: 9f9e270e-b...
2025-11-12 00:08:44,087 - INFO - root - DeepSeekClient: 使用模式: 火山引擎
2025-11-12 00:08:44,094 - INFO - root - DeepSeekClient: 模型名称: deepseek-v3-1-terminus
2025-11-12 00:08:48,343 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 00:08:48,361 - INFO - root - DeepSeekClient: initialized successfully with model deepseek-v3-1-terminus
2025-11-12 00:08:48,364 - INFO - root - LLMClientManager: DeepSeek 客户端初始化成功
2025-11-12 00:08:48,369 - INFO - root - LLMClientManager: switched to DeepSeek client
2025-11-12 00:08:48,374 - INFO - root - 已手动切换到 LLM 客户端: DeepSeek
2025-11-12 00:08:48,374 - INFO - root - 使用 LLM 模型: deepseek-v3-1-terminus
2025-11-12 00:08:48,375 - INFO - root - 可用客户端: ['DeepSeek']
2025-11-12 00:08:48,376 - INFO - root - === 运行配置 ===
2025-11-12 00:08:48,386 - INFO - root - 处理模式: arxiv在线搜索
2025-11-12 00:08:48,387 - INFO - root - 关键词: CVPR 2026
2025-11-12 00:08:48,387 - INFO - root - 查询: CVPR 2026
2025-11-12 00:08:48,388 - INFO - root - 排序: None
2025-11-12 00:08:48,388 - INFO - root - 最近天数: 180
2025-11-12 00:08:48,389 - INFO - root - 最大处理数量: 2
2025-11-12 00:08:48,389 - INFO - root - 保存图片: 是
2025-11-12 00:08:48,390 - INFO - root - 输出语言: 中文
2025-11-12 00:08:48,391 - INFO - root - 强制重新处理: 否
2025-11-12 00:08:48,392 - INFO - root - ====================
2025-11-12 00:08:48,397 - INFO - root - 使用 arXiv 搜索模式（通过 chat_arxiv 模块获取）
2025-11-12 00:08:48,398 - INFO - root - Fetching page 1 with URL: https://arxiv.org/search/?query=CVPR+2026&searchtype=all&abstracts=show&order=-announced_date_first&size=50
2025-11-12 00:08:58,484 - INFO - root - get_all_titles_from_web 
2025-11-12 00:08:58,582 - INFO - root - Page:0, Index:0, Learning to Seek Evidence: A Verifiable Reasoning Agent with Causal Faithfulness Analysis, https://arxiv.org/pdf/2511.01425, 2025-11-03
2025-11-12 00:08:58,639 - INFO - root - Fetching page 2 with URL: https://arxiv.org/search/?query=CVPR+2026&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=50
2025-11-12 00:09:05,757 - INFO - root - ------------------------------------------------------------------------------------------------------------------------
2025-11-12 00:09:05,759 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\CVPR 2026\Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness.pdf
2025-11-12 00:09:05,767 - INFO - root - 正在总结论文 1/1: Learning to Seek Evidence: A Verifiable Reasoning Agent with Causal Faithfulness Analysis
2025-11-12 00:09:17,854 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 00:10:13,982 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 00:10:48,729 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 00:10:48,740 - INFO - root - 正在提取论文图片到目录: ./export\CVPR 2026\images\Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness
2025-11-12 00:10:49,005 - INFO - root - 已保存图片 1/10：./export\CVPR 2026\images\Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness\figure_1_page2.jpeg
2025-11-12 00:10:49,020 - INFO - root - 已保存图片 2/10：./export\CVPR 2026\images\Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness\figure_2_page2.jpeg
2025-11-12 00:10:49,027 - INFO - root - 已保存图片 3/10：./export\CVPR 2026\images\Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness\figure_3_page2.jpeg
2025-11-12 00:10:49,036 - INFO - root - 已保存图片 4/10：./export\CVPR 2026\images\Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness\figure_4_page2.jpeg
2025-11-12 00:10:49,043 - INFO - root - 已保存图片 5/10：./export\CVPR 2026\images\Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness\figure_5_page2.jpeg
2025-11-12 00:10:49,052 - INFO - root - 已保存图片 6/10：./export\CVPR 2026\images\Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness\figure_6_page2.jpeg
2025-11-12 00:10:49,058 - INFO - root - 已保存图片 7/10：./export\CVPR 2026\images\Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness\figure_7_page2.jpeg
2025-11-12 00:10:49,069 - INFO - root - 已保存图片 8/10：./export\CVPR 2026\images\Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness\figure_8_page2.jpeg
2025-11-12 00:10:49,107 - INFO - root - 已保存图片 9/10：./export\CVPR 2026\images\Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness\figure_9_page2.jpeg
2025-11-12 00:10:49,115 - INFO - root - 已保存图片 10/10：./export\CVPR 2026\images\Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness\figure_10_page2.jpeg
2025-11-12 00:10:49,120 - INFO - root - 成功添加图片 1：./export\CVPR 2026\images\Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness\figure_1_page2.jpeg
2025-11-12 00:10:49,121 - INFO - root - 成功添加图片 2：./export\CVPR 2026\images\Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness\figure_2_page2.jpeg
2025-11-12 00:10:49,121 - INFO - root - 成功添加图片 3：./export\CVPR 2026\images\Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness\figure_3_page2.jpeg
2025-11-12 00:10:49,121 - INFO - root - 成功添加图片 4：./export\CVPR 2026\images\Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness\figure_4_page2.jpeg
2025-11-12 00:10:49,122 - INFO - root - 成功添加图片 5：./export\CVPR 2026\images\Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness\figure_5_page2.jpeg
2025-11-12 00:10:49,122 - INFO - root - 成功添加图片 6：./export\CVPR 2026\images\Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness\figure_6_page2.jpeg
2025-11-12 00:10:49,123 - INFO - root - 成功添加图片 7：./export\CVPR 2026\images\Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness\figure_7_page2.jpeg
2025-11-12 00:10:49,124 - INFO - root - 成功添加图片 8：./export\CVPR 2026\images\Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness\figure_8_page2.jpeg
2025-11-12 00:10:49,124 - INFO - root - 成功添加图片 9：./export\CVPR 2026\images\Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness\figure_9_page2.jpeg
2025-11-12 00:10:49,125 - INFO - root - 成功添加图片 10：./export\CVPR 2026\images\Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness\figure_10_page2.jpeg
2025-11-12 00:10:49,127 - WARNING - root - 图片文件不存在: images/Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness/figure_10_page2.jpeg
2025-11-12 00:10:49,127 - WARNING - root - 图片在任何位置都不存在: figure_10_page2.jpeg
2025-11-12 00:10:49,127 - WARNING - root - 图片文件不存在: images/Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness/figure_9_page2.jpeg
2025-11-12 00:10:49,129 - WARNING - root - 图片在任何位置都不存在: figure_9_page2.jpeg
2025-11-12 00:10:49,129 - WARNING - root - 图片文件不存在: images/Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness/figure_8_page2.jpeg
2025-11-12 00:10:49,129 - WARNING - root - 图片在任何位置都不存在: figure_8_page2.jpeg
2025-11-12 00:10:49,131 - WARNING - root - 图片文件不存在: images/Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness/figure_7_page2.jpeg
2025-11-12 00:10:49,132 - WARNING - root - 图片在任何位置都不存在: figure_7_page2.jpeg
2025-11-12 00:10:49,134 - WARNING - root - 图片文件不存在: images/Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness/figure_6_page2.jpeg
2025-11-12 00:10:49,136 - WARNING - root - 图片在任何位置都不存在: figure_6_page2.jpeg
2025-11-12 00:10:49,136 - WARNING - root - 图片文件不存在: images/Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness/figure_5_page2.jpeg
2025-11-12 00:10:49,136 - WARNING - root - 图片在任何位置都不存在: figure_5_page2.jpeg
2025-11-12 00:10:49,137 - WARNING - root - 图片文件不存在: images/Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness/figure_4_page2.jpeg
2025-11-12 00:10:49,137 - WARNING - root - 图片在任何位置都不存在: figure_4_page2.jpeg
2025-11-12 00:10:49,137 - WARNING - root - 图片文件不存在: images/Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness/figure_3_page2.jpeg
2025-11-12 00:10:49,138 - WARNING - root - 图片在任何位置都不存在: figure_3_page2.jpeg
2025-11-12 00:10:49,139 - WARNING - root - 图片文件不存在: images/Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness/figure_2_page2.jpeg
2025-11-12 00:10:49,139 - WARNING - root - 图片在任何位置都不存在: figure_2_page2.jpeg
2025-11-12 00:10:49,141 - WARNING - root - 图片文件不存在: images/Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness/figure_1_page2.jpeg
2025-11-12 00:10:49,141 - WARNING - root - 图片在任何位置都不存在: figure_1_page2.jpeg
2025-11-12 00:10:49,141 - INFO - root - 已按文献标题重新组织图片存储
2025-11-12 00:10:49,149 - INFO - root - 论文《Learning to Seek Evidence: A Verifiable Reasoning Agent with Causal Faithfulness Analysis》的分析已保存到 ./export\CVPR 2026\Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness.md
2025-11-12 00:10:49,437 - INFO - root - 已生成汇总Excel表格: export\CVPR 2026\论文汇总_CVPR 2026_20251112_001049.xlsx
2025-11-12 00:10:49,437 - INFO - root - 已生成汇总Excel表格: export\CVPR 2026\论文汇总_CVPR 2026_20251112_001049.xlsx
2025-11-12 00:10:49,438 - INFO - root - summary time: 127.25 seconds
2025-11-12 00:16:06,628 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-12 00:16:06,629 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-12 00:16:06,631 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-12 00:16:07,840 - INFO - root - LLMClientManager: 指定使用客户端: DeepSeek
2025-11-12 00:16:07,843 - INFO - root - DeepSeekClient: API key found: 9f9e270e-b...
2025-11-12 00:16:07,843 - INFO - root - DeepSeekClient: 使用模式: 火山引擎
2025-11-12 00:16:07,843 - INFO - root - DeepSeekClient: 模型名称: deepseek-v3-1-terminus
2025-11-12 00:16:11,803 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 00:16:11,816 - INFO - root - DeepSeekClient: initialized successfully with model deepseek-v3-1-terminus
2025-11-12 00:16:11,816 - INFO - root - LLMClientManager: DeepSeek 客户端初始化成功
2025-11-12 00:16:11,816 - INFO - root - LLMClientManager: switched to DeepSeek client
2025-11-12 00:16:11,816 - INFO - root - 已手动切换到 LLM 客户端: DeepSeek
2025-11-12 00:16:11,819 - INFO - root - 使用 LLM 模型: deepseek-v3-1-terminus
2025-11-12 00:16:11,819 - INFO - root - 可用客户端: ['DeepSeek']
2025-11-12 00:16:11,820 - INFO - root - === 运行配置 ===
2025-11-12 00:16:11,822 - INFO - root - 处理模式: arxiv在线搜索
2025-11-12 00:16:11,822 - INFO - root - 关键词: CVPR 2026
2025-11-12 00:16:11,822 - INFO - root - 查询: CVPR 2026
2025-11-12 00:16:11,823 - INFO - root - 排序: None
2025-11-12 00:16:11,823 - INFO - root - 最近天数: 180
2025-11-12 00:16:11,824 - INFO - root - 最大处理数量: 2
2025-11-12 00:16:11,824 - INFO - root - 保存图片: 是
2025-11-12 00:16:11,825 - INFO - root - 输出语言: 中文
2025-11-12 00:16:11,825 - INFO - root - 强制重新处理: 否
2025-11-12 00:16:11,825 - INFO - root - ====================
2025-11-12 00:16:11,825 - INFO - root - 使用 arXiv 搜索模式（通过 chat_arxiv 模块获取）
2025-11-12 00:16:11,826 - INFO - root - Fetching page 1 with URL: https://arxiv.org/search/?query=CVPR+2026&searchtype=all&abstracts=show&order=-announced_date_first&size=50
2025-11-12 00:16:38,017 - INFO - root - get_all_titles_from_web 
2025-11-12 00:16:38,017 - INFO - root - Page:0, Index:0, Learning to Seek Evidence: A Verifiable Reasoning Agent with Causal Faithfulness Analysis, https://arxiv.org/pdf/2511.01425, 2025-11-03
2025-11-12 00:16:38,018 - INFO - root - Fetching page 2 with URL: https://arxiv.org/search/?query=CVPR+2026&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=50
2025-11-12 00:16:44,927 - INFO - root - ------------------------------------------------------------------------------------------------------------------------
2025-11-12 00:16:44,928 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\CVPR 2026\Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness.pdf
2025-11-12 00:16:44,929 - INFO - root - 跳过已处理论文 Learning to Seek Evidence: A Verifiable Reasoning Agent with Causal Faithfulness Analysis：d:\ChatPaper\academic Papers\CVPR 2026\Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness.pdf
2025-11-12 00:16:45,195 - INFO - root - 已生成汇总Excel表格: export\CVPR 2026\论文汇总_CVPR 2026_20251112_001644.xlsx
2025-11-12 00:16:45,196 - INFO - root - 已生成汇总Excel表格: export\CVPR 2026\论文汇总_CVPR 2026_20251112_001644.xlsx
2025-11-12 00:16:45,196 - INFO - root - summary time: 38.57 seconds
2025-11-12 00:17:09,718 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-12 00:17:09,719 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-12 00:17:09,721 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-12 00:17:10,686 - INFO - root - LLMClientManager: 指定使用客户端: DeepSeek
2025-11-12 00:17:10,686 - INFO - root - DeepSeekClient: API key found: 9f9e270e-b...
2025-11-12 00:17:10,686 - INFO - root - DeepSeekClient: 使用模式: 火山引擎
2025-11-12 00:17:10,686 - INFO - root - DeepSeekClient: 模型名称: deepseek-v3-1-terminus
2025-11-12 00:17:13,501 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 00:17:13,523 - INFO - root - DeepSeekClient: initialized successfully with model deepseek-v3-1-terminus
2025-11-12 00:17:13,576 - INFO - root - LLMClientManager: DeepSeek 客户端初始化成功
2025-11-12 00:17:13,641 - INFO - root - LLMClientManager: switched to DeepSeek client
2025-11-12 00:17:13,642 - INFO - root - 已手动切换到 LLM 客户端: DeepSeek
2025-11-12 00:17:13,644 - INFO - root - 使用 LLM 模型: deepseek-v3-1-terminus
2025-11-12 00:17:13,644 - INFO - root - 可用客户端: ['DeepSeek']
2025-11-12 00:17:13,646 - INFO - root - === 运行配置 ===
2025-11-12 00:17:13,647 - INFO - root - 处理模式: arxiv在线搜索
2025-11-12 00:17:13,648 - INFO - root - 关键词: CVPR 2026
2025-11-12 00:17:13,649 - INFO - root - 查询: CVPR 2026
2025-11-12 00:17:13,651 - INFO - root - 排序: None
2025-11-12 00:17:13,652 - INFO - root - 最近天数: 180
2025-11-12 00:17:13,686 - INFO - root - 最大处理数量: 2
2025-11-12 00:17:13,688 - INFO - root - 保存图片: 是
2025-11-12 00:17:13,688 - INFO - root - 输出语言: 中文
2025-11-12 00:17:13,688 - INFO - root - 强制重新处理: 否
2025-11-12 00:17:13,689 - INFO - root - ====================
2025-11-12 00:17:13,689 - INFO - root - 使用 arXiv 搜索模式（通过 chat_arxiv 模块获取）
2025-11-12 00:17:13,689 - INFO - root - Fetching page 1 with URL: https://arxiv.org/search/?query=CVPR+2026&searchtype=all&abstracts=show&order=-announced_date_first&size=50
2025-11-12 00:17:34,741 - INFO - root - get_all_titles_from_web 
2025-11-12 00:17:34,742 - INFO - root - Page:0, Index:0, Learning to Seek Evidence: A Verifiable Reasoning Agent with Causal Faithfulness Analysis, https://arxiv.org/pdf/2511.01425, 2025-11-03
2025-11-12 00:17:34,742 - INFO - root - Fetching page 2 with URL: https://arxiv.org/search/?query=CVPR+2026&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=50
2025-11-12 00:17:57,390 - INFO - root - ------------------------------------------------------------------------------------------------------------------------
2025-11-12 00:17:57,395 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\CVPR 2026\Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness.pdf
2025-11-12 00:17:57,400 - INFO - root - 正在总结论文 1/1: Learning to Seek Evidence: A Verifiable Reasoning Agent with Causal Faithfulness Analysis
2025-11-12 00:18:07,899 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 00:18:57,238 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 00:18:57,239 - INFO - root - LLMClient: rate limit reached, sleeping 0.2s
2025-11-12 00:19:22,839 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 00:19:22,841 - INFO - root - 正在提取论文图片到目录: ./export\CVPR 2026\images\Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness
2025-11-12 00:19:22,931 - INFO - root - 已保存图片 1/10：./export\CVPR 2026\images\Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness\figure_1_page2.jpeg
2025-11-12 00:19:22,940 - INFO - root - 已保存图片 2/10：./export\CVPR 2026\images\Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness\figure_2_page2.jpeg
2025-11-12 00:19:22,955 - INFO - root - 已保存图片 3/10：./export\CVPR 2026\images\Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness\figure_3_page2.jpeg
2025-11-12 00:19:22,971 - INFO - root - 已保存图片 4/10：./export\CVPR 2026\images\Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness\figure_4_page2.jpeg
2025-11-12 00:19:22,994 - INFO - root - 已保存图片 5/10：./export\CVPR 2026\images\Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness\figure_5_page2.jpeg
2025-11-12 00:19:23,007 - INFO - root - 已保存图片 6/10：./export\CVPR 2026\images\Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness\figure_6_page2.jpeg
2025-11-12 00:19:23,023 - INFO - root - 已保存图片 7/10：./export\CVPR 2026\images\Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness\figure_7_page2.jpeg
2025-11-12 00:19:23,037 - INFO - root - 已保存图片 8/10：./export\CVPR 2026\images\Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness\figure_8_page2.jpeg
2025-11-12 00:19:23,084 - INFO - root - 已保存图片 9/10：./export\CVPR 2026\images\Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness\figure_9_page2.jpeg
2025-11-12 00:19:23,094 - INFO - root - 已保存图片 10/10：./export\CVPR 2026\images\Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness\figure_10_page2.jpeg
2025-11-12 00:19:23,098 - INFO - root - 成功添加图片 1：./export\CVPR 2026\images\Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness\figure_1_page2.jpeg
2025-11-12 00:19:23,098 - INFO - root - 成功添加图片 2：./export\CVPR 2026\images\Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness\figure_2_page2.jpeg
2025-11-12 00:19:23,098 - INFO - root - 成功添加图片 3：./export\CVPR 2026\images\Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness\figure_3_page2.jpeg
2025-11-12 00:19:23,100 - INFO - root - 成功添加图片 4：./export\CVPR 2026\images\Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness\figure_4_page2.jpeg
2025-11-12 00:19:23,100 - INFO - root - 成功添加图片 5：./export\CVPR 2026\images\Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness\figure_5_page2.jpeg
2025-11-12 00:19:23,102 - INFO - root - 成功添加图片 6：./export\CVPR 2026\images\Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness\figure_6_page2.jpeg
2025-11-12 00:19:23,104 - INFO - root - 成功添加图片 7：./export\CVPR 2026\images\Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness\figure_7_page2.jpeg
2025-11-12 00:19:23,106 - INFO - root - 成功添加图片 8：./export\CVPR 2026\images\Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness\figure_8_page2.jpeg
2025-11-12 00:19:23,107 - INFO - root - 成功添加图片 9：./export\CVPR 2026\images\Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness\figure_9_page2.jpeg
2025-11-12 00:19:23,107 - INFO - root - 成功添加图片 10：./export\CVPR 2026\images\Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness\figure_10_page2.jpeg
2025-11-12 00:19:23,117 - WARNING - root - 图片在任何位置都不存在: figure_10_page2.jpeg
2025-11-12 00:19:23,118 - WARNING - root - 图片在任何位置都不存在: figure_9_page2.jpeg
2025-11-12 00:19:23,119 - WARNING - root - 图片在任何位置都不存在: figure_8_page2.jpeg
2025-11-12 00:19:23,121 - WARNING - root - 图片在任何位置都不存在: figure_7_page2.jpeg
2025-11-12 00:19:23,122 - WARNING - root - 图片在任何位置都不存在: figure_6_page2.jpeg
2025-11-12 00:19:23,123 - WARNING - root - 图片在任何位置都不存在: figure_5_page2.jpeg
2025-11-12 00:19:23,124 - WARNING - root - 图片在任何位置都不存在: figure_4_page2.jpeg
2025-11-12 00:19:23,125 - WARNING - root - 图片在任何位置都不存在: figure_3_page2.jpeg
2025-11-12 00:19:23,127 - WARNING - root - 图片在任何位置都不存在: figure_2_page2.jpeg
2025-11-12 00:19:23,128 - WARNING - root - 图片在任何位置都不存在: figure_1_page2.jpeg
2025-11-12 00:19:23,132 - INFO - root - 已按文献标题重新组织图片存储
2025-11-12 00:19:23,134 - INFO - root - 论文《Learning to Seek Evidence: A Verifiable Reasoning Agent with Causal Faithfulness Analysis》的分析已保存到 ./export\CVPR 2026\Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness.md
2025-11-12 00:19:24,030 - INFO - root - 已生成汇总Excel表格: export\CVPR 2026\论文汇总_CVPR 2026_20251112_001923.xlsx
2025-11-12 00:19:24,032 - INFO - root - 已生成汇总Excel表格: export\CVPR 2026\论文汇总_CVPR 2026_20251112_001923.xlsx
2025-11-12 00:19:24,034 - INFO - root - summary time: 134.32 seconds
2025-11-12 00:24:37,248 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-12 00:24:37,248 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-12 00:24:37,248 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-12 00:24:38,015 - INFO - root - LLMClientManager: 指定使用客户端: DeepSeek
2025-11-12 00:24:38,015 - INFO - root - DeepSeekClient: API key found: 9f9e270e-b...
2025-11-12 00:24:38,016 - INFO - root - DeepSeekClient: 使用模式: 火山引擎
2025-11-12 00:24:38,016 - INFO - root - DeepSeekClient: 模型名称: deepseek-v3-1-terminus
2025-11-12 00:24:41,709 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 00:24:41,726 - INFO - root - DeepSeekClient: initialized successfully with model deepseek-v3-1-terminus
2025-11-12 00:24:41,761 - INFO - root - LLMClientManager: DeepSeek 客户端初始化成功
2025-11-12 00:24:41,777 - INFO - root - LLMClientManager: switched to DeepSeek client
2025-11-12 00:24:41,778 - INFO - root - 已手动切换到 LLM 客户端: DeepSeek
2025-11-12 00:24:41,779 - INFO - root - 使用 LLM 模型: deepseek-v3-1-terminus
2025-11-12 00:24:41,779 - INFO - root - 可用客户端: ['DeepSeek']
2025-11-12 00:24:41,780 - INFO - root - === 运行配置 ===
2025-11-12 00:24:41,783 - INFO - root - 处理模式: arxiv在线搜索
2025-11-12 00:24:41,796 - INFO - root - 关键词: CVPR 2026
2025-11-12 00:24:41,796 - INFO - root - 查询: CVPR 2026
2025-11-12 00:24:41,797 - INFO - root - 排序: None
2025-11-12 00:24:41,797 - INFO - root - 最近天数: 180
2025-11-12 00:24:41,837 - INFO - root - 最大处理数量: 2
2025-11-12 00:24:41,843 - INFO - root - 保存图片: 是
2025-11-12 00:24:41,852 - INFO - root - 输出语言: 中文
2025-11-12 00:24:41,854 - INFO - root - 强制重新处理: 否
2025-11-12 00:24:41,854 - INFO - root - ====================
2025-11-12 00:24:41,855 - INFO - root - 使用 arXiv 搜索模式（通过 chat_arxiv 模块获取）
2025-11-12 00:24:41,885 - INFO - root - Fetching page 1 with URL: https://arxiv.org/search/?query=CVPR+2026&searchtype=all&abstracts=show&order=-announced_date_first&size=50
2025-11-12 00:25:04,951 - INFO - root - get_all_titles_from_web 
2025-11-12 00:25:04,951 - INFO - root - Page:0, Index:0, Learning to Seek Evidence: A Verifiable Reasoning Agent with Causal Faithfulness Analysis, https://arxiv.org/pdf/2511.01425, 2025-11-03
2025-11-12 00:25:04,951 - INFO - root - Fetching page 2 with URL: https://arxiv.org/search/?query=CVPR+2026&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=50
2025-11-12 00:25:29,728 - INFO - root - ------------------------------------------------------------------------------------------------------------------------
2025-11-12 00:25:29,729 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\CVPR 2026\Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness.pdf
2025-11-12 00:25:29,756 - INFO - root - 正在总结论文 1/1: Learning to Seek Evidence: A Verifiable Reasoning Agent with Causal Faithfulness Analysis
2025-11-12 00:25:43,124 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 00:26:17,973 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 00:26:17,976 - INFO - root - LLMClient: rate limit reached, sleeping 11.8s
2025-11-12 00:26:59,302 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 00:26:59,305 - INFO - root - 正在提取论文图片到目录: ./export\CVPR 2026\images\Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness
2025-11-12 00:26:59,434 - INFO - root - 已保存图片 1/10：./export\CVPR 2026\images\Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness\figure_1_page2.jpeg
2025-11-12 00:26:59,456 - INFO - root - 已保存图片 2/10：./export\CVPR 2026\images\Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness\figure_2_page2.jpeg
2025-11-12 00:26:59,464 - INFO - root - 已保存图片 3/10：./export\CVPR 2026\images\Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness\figure_3_page2.jpeg
2025-11-12 00:26:59,483 - INFO - root - 已保存图片 4/10：./export\CVPR 2026\images\Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness\figure_4_page2.jpeg
2025-11-12 00:26:59,501 - INFO - root - 已保存图片 5/10：./export\CVPR 2026\images\Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness\figure_5_page2.jpeg
2025-11-12 00:26:59,517 - INFO - root - 已保存图片 6/10：./export\CVPR 2026\images\Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness\figure_6_page2.jpeg
2025-11-12 00:26:59,525 - INFO - root - 已保存图片 7/10：./export\CVPR 2026\images\Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness\figure_7_page2.jpeg
2025-11-12 00:26:59,538 - INFO - root - 已保存图片 8/10：./export\CVPR 2026\images\Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness\figure_8_page2.jpeg
2025-11-12 00:26:59,595 - INFO - root - 已保存图片 9/10：./export\CVPR 2026\images\Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness\figure_9_page2.jpeg
2025-11-12 00:26:59,607 - INFO - root - 已保存图片 10/10：./export\CVPR 2026\images\Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness\figure_10_page2.jpeg
2025-11-12 00:26:59,609 - INFO - root - 成功添加图片 1：./export\CVPR 2026\images\Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness\figure_1_page2.jpeg
2025-11-12 00:26:59,609 - INFO - root - 成功添加图片 2：./export\CVPR 2026\images\Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness\figure_2_page2.jpeg
2025-11-12 00:26:59,610 - INFO - root - 成功添加图片 3：./export\CVPR 2026\images\Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness\figure_3_page2.jpeg
2025-11-12 00:26:59,611 - INFO - root - 成功添加图片 4：./export\CVPR 2026\images\Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness\figure_4_page2.jpeg
2025-11-12 00:26:59,611 - INFO - root - 成功添加图片 5：./export\CVPR 2026\images\Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness\figure_5_page2.jpeg
2025-11-12 00:26:59,612 - INFO - root - 成功添加图片 6：./export\CVPR 2026\images\Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness\figure_6_page2.jpeg
2025-11-12 00:26:59,612 - INFO - root - 成功添加图片 7：./export\CVPR 2026\images\Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness\figure_7_page2.jpeg
2025-11-12 00:26:59,613 - INFO - root - 成功添加图片 8：./export\CVPR 2026\images\Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness\figure_8_page2.jpeg
2025-11-12 00:26:59,613 - INFO - root - 成功添加图片 9：./export\CVPR 2026\images\Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness\figure_9_page2.jpeg
2025-11-12 00:26:59,614 - INFO - root - 成功添加图片 10：./export\CVPR 2026\images\Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness\figure_10_page2.jpeg
2025-11-12 00:26:59,618 - WARNING - root - 图片在任何位置都不存在: figure_10_page2.jpeg
2025-11-12 00:26:59,622 - WARNING - root - 图片在任何位置都不存在: figure_9_page2.jpeg
2025-11-12 00:26:59,625 - WARNING - root - 图片在任何位置都不存在: figure_8_page2.jpeg
2025-11-12 00:26:59,626 - WARNING - root - 图片在任何位置都不存在: figure_7_page2.jpeg
2025-11-12 00:26:59,626 - WARNING - root - 图片在任何位置都不存在: figure_6_page2.jpeg
2025-11-12 00:26:59,627 - WARNING - root - 图片在任何位置都不存在: figure_5_page2.jpeg
2025-11-12 00:26:59,627 - WARNING - root - 图片在任何位置都不存在: figure_4_page2.jpeg
2025-11-12 00:26:59,628 - WARNING - root - 图片在任何位置都不存在: figure_3_page2.jpeg
2025-11-12 00:26:59,628 - WARNING - root - 图片在任何位置都不存在: figure_2_page2.jpeg
2025-11-12 00:26:59,630 - WARNING - root - 图片在任何位置都不存在: figure_1_page2.jpeg
2025-11-12 00:26:59,631 - INFO - root - 已按文献标题重新组织图片存储
2025-11-12 00:26:59,639 - INFO - root - 论文《Learning to Seek Evidence: A Verifiable Reasoning Agent with Causal Faithfulness Analysis》的分析已保存到 ./export\CVPR 2026\Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness.md
2025-11-12 00:26:59,997 - INFO - root - 已生成汇总Excel表格: export\CVPR 2026\论文汇总_CVPR 2026_20251112_002659.xlsx
2025-11-12 00:27:00,001 - INFO - root - 已生成汇总Excel表格: export\CVPR 2026\论文汇总_CVPR 2026_20251112_002659.xlsx
2025-11-12 00:27:00,001 - INFO - root - summary time: 142.75 seconds
2025-11-12 00:33:17,961 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-12 00:33:17,962 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-12 00:33:17,963 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-12 00:33:19,210 - INFO - root - LLMClientManager: 指定使用客户端: DeepSeek
2025-11-12 00:33:19,210 - INFO - root - DeepSeekClient: API key found: 9f9e270e-b...
2025-11-12 00:33:19,210 - INFO - root - DeepSeekClient: 使用模式: 火山引擎
2025-11-12 00:33:19,210 - INFO - root - DeepSeekClient: 模型名称: deepseek-v3-1-terminus
2025-11-12 00:33:22,044 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 00:33:22,052 - INFO - root - DeepSeekClient: initialized successfully with model deepseek-v3-1-terminus
2025-11-12 00:33:22,053 - INFO - root - LLMClientManager: DeepSeek 客户端初始化成功
2025-11-12 00:33:22,059 - INFO - root - LLMClientManager: switched to DeepSeek client
2025-11-12 00:33:22,059 - INFO - root - 已手动切换到 LLM 客户端: DeepSeek
2025-11-12 00:33:22,060 - INFO - root - 使用 LLM 模型: deepseek-v3-1-terminus
2025-11-12 00:33:22,060 - INFO - root - 可用客户端: ['DeepSeek']
2025-11-12 00:33:22,062 - INFO - root - === 运行配置 ===
2025-11-12 00:33:22,064 - INFO - root - 处理模式: arxiv在线搜索
2025-11-12 00:33:22,064 - INFO - root - 关键词: CVPR 2026
2025-11-12 00:33:22,064 - INFO - root - 查询: CVPR 2026
2025-11-12 00:33:22,065 - INFO - root - 排序: None
2025-11-12 00:33:22,065 - INFO - root - 最近天数: 180
2025-11-12 00:33:22,065 - INFO - root - 最大处理数量: 2
2025-11-12 00:33:22,067 - INFO - root - 保存图片: 是
2025-11-12 00:33:22,067 - INFO - root - 输出语言: 中文
2025-11-12 00:33:22,067 - INFO - root - 强制重新处理: 否
2025-11-12 00:33:22,067 - INFO - root - ====================
2025-11-12 00:33:22,068 - INFO - root - 使用 arXiv 搜索模式（通过 chat_arxiv 模块获取）
2025-11-12 00:33:22,068 - INFO - root - Fetching page 1 with URL: https://arxiv.org/search/?query=CVPR+2026&searchtype=all&abstracts=show&order=-announced_date_first&size=50
2025-11-12 00:34:10,799 - INFO - root - get_all_titles_from_web 
2025-11-12 00:34:10,799 - INFO - root - Page:0, Index:0, Learning to Seek Evidence: A Verifiable Reasoning Agent with Causal Faithfulness Analysis, https://arxiv.org/pdf/2511.01425, 2025-11-03
2025-11-12 00:34:10,801 - INFO - root - Fetching page 2 with URL: https://arxiv.org/search/?query=CVPR+2026&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=50
2025-11-12 00:34:34,925 - INFO - root - ------------------------------------------------------------------------------------------------------------------------
2025-11-12 00:34:34,927 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\CVPR 2026\Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness.pdf
2025-11-12 00:34:34,958 - INFO - root - 正在总结论文 1/1: Learning to Seek Evidence: A Verifiable Reasoning Agent with Causal Faithfulness Analysis
2025-11-12 00:34:49,310 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 00:35:31,870 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 00:35:31,871 - INFO - root - LLMClient: rate limit reached, sleeping 3.1s
2025-11-12 00:36:00,833 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 00:36:00,836 - INFO - root - 正在提取论文图片到目录: ./export\CVPR 2026\images\Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness
2025-11-12 00:36:00,898 - INFO - root - 已保存图片 1/10：./export\CVPR 2026\images\Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness\figure_1_page2.jpeg
2025-11-12 00:36:00,904 - INFO - root - 已保存图片 2/10：./export\CVPR 2026\images\Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness\figure_2_page2.jpeg
2025-11-12 00:36:00,909 - INFO - root - 已保存图片 3/10：./export\CVPR 2026\images\Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness\figure_3_page2.jpeg
2025-11-12 00:36:00,920 - INFO - root - 已保存图片 4/10：./export\CVPR 2026\images\Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness\figure_4_page2.jpeg
2025-11-12 00:36:00,941 - INFO - root - 已保存图片 5/10：./export\CVPR 2026\images\Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness\figure_5_page2.jpeg
2025-11-12 00:36:00,949 - INFO - root - 已保存图片 6/10：./export\CVPR 2026\images\Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness\figure_6_page2.jpeg
2025-11-12 00:36:00,956 - INFO - root - 已保存图片 7/10：./export\CVPR 2026\images\Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness\figure_7_page2.jpeg
2025-11-12 00:36:00,964 - INFO - root - 已保存图片 8/10：./export\CVPR 2026\images\Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness\figure_8_page2.jpeg
2025-11-12 00:36:00,987 - INFO - root - 已保存图片 9/10：./export\CVPR 2026\images\Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness\figure_9_page2.jpeg
2025-11-12 00:36:01,003 - INFO - root - 已保存图片 10/10：./export\CVPR 2026\images\Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness\figure_10_page2.jpeg
2025-11-12 00:36:01,005 - INFO - root - 成功添加图片 1：./export\CVPR 2026\images\Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness\figure_1_page2.jpeg
2025-11-12 00:36:01,005 - INFO - root - 成功添加图片 2：./export\CVPR 2026\images\Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness\figure_2_page2.jpeg
2025-11-12 00:36:01,006 - INFO - root - 成功添加图片 3：./export\CVPR 2026\images\Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness\figure_3_page2.jpeg
2025-11-12 00:36:01,006 - INFO - root - 成功添加图片 4：./export\CVPR 2026\images\Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness\figure_4_page2.jpeg
2025-11-12 00:36:01,006 - INFO - root - 成功添加图片 5：./export\CVPR 2026\images\Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness\figure_5_page2.jpeg
2025-11-12 00:36:01,006 - INFO - root - 成功添加图片 6：./export\CVPR 2026\images\Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness\figure_6_page2.jpeg
2025-11-12 00:36:01,008 - INFO - root - 成功添加图片 7：./export\CVPR 2026\images\Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness\figure_7_page2.jpeg
2025-11-12 00:36:01,008 - INFO - root - 成功添加图片 8：./export\CVPR 2026\images\Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness\figure_8_page2.jpeg
2025-11-12 00:36:01,008 - INFO - root - 成功添加图片 9：./export\CVPR 2026\images\Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness\figure_9_page2.jpeg
2025-11-12 00:36:01,008 - INFO - root - 成功添加图片 10：./export\CVPR 2026\images\Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness\figure_10_page2.jpeg
2025-11-12 00:36:01,012 - WARNING - root - 图片在任何位置都不存在: figure_10_page2.jpeg
2025-11-12 00:36:01,014 - WARNING - root - 图片在任何位置都不存在: figure_9_page2.jpeg
2025-11-12 00:36:01,015 - WARNING - root - 图片在任何位置都不存在: figure_8_page2.jpeg
2025-11-12 00:36:01,017 - WARNING - root - 图片在任何位置都不存在: figure_7_page2.jpeg
2025-11-12 00:36:01,018 - WARNING - root - 图片在任何位置都不存在: figure_6_page2.jpeg
2025-11-12 00:36:01,018 - WARNING - root - 图片在任何位置都不存在: figure_5_page2.jpeg
2025-11-12 00:36:01,019 - WARNING - root - 图片在任何位置都不存在: figure_4_page2.jpeg
2025-11-12 00:36:01,019 - WARNING - root - 图片在任何位置都不存在: figure_3_page2.jpeg
2025-11-12 00:36:01,020 - WARNING - root - 图片在任何位置都不存在: figure_2_page2.jpeg
2025-11-12 00:36:01,020 - WARNING - root - 图片在任何位置都不存在: figure_1_page2.jpeg
2025-11-12 00:36:01,020 - INFO - root - 已按文献标题重新组织图片存储
2025-11-12 00:36:01,023 - INFO - root - 论文《Learning to Seek Evidence: A Verifiable Reasoning Agent with Causal Faithfulness Analysis》的分析已保存到 ./export\CVPR 2026\Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness.md
2025-11-12 00:36:01,284 - INFO - root - 已生成汇总Excel表格: export\CVPR 2026\论文汇总_CVPR 2026_20251112_003601.xlsx
2025-11-12 00:36:01,284 - INFO - root - 已生成汇总Excel表格: export\CVPR 2026\论文汇总_CVPR 2026_20251112_003601.xlsx
2025-11-12 00:36:01,286 - INFO - root - summary time: 163.33 seconds
2025-11-12 00:42:31,420 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-12 00:42:31,423 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-12 00:42:31,425 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-12 00:42:32,945 - INFO - root - LLMClientManager: 指定使用客户端: DeepSeek
2025-11-12 00:42:32,946 - INFO - root - DeepSeekClient: API key found: 9f9e270e-b...
2025-11-12 00:42:32,946 - INFO - root - DeepSeekClient: 使用模式: 火山引擎
2025-11-12 00:42:32,946 - INFO - root - DeepSeekClient: 模型名称: deepseek-v3-1-terminus
2025-11-12 00:42:37,467 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 00:42:37,487 - INFO - root - DeepSeekClient: initialized successfully with model deepseek-v3-1-terminus
2025-11-12 00:42:37,488 - INFO - root - LLMClientManager: DeepSeek 客户端初始化成功
2025-11-12 00:42:37,489 - INFO - root - LLMClientManager: switched to DeepSeek client
2025-11-12 00:42:37,490 - INFO - root - 已手动切换到 LLM 客户端: DeepSeek
2025-11-12 00:42:37,490 - INFO - root - 使用 LLM 模型: deepseek-v3-1-terminus
2025-11-12 00:42:37,491 - INFO - root - 可用客户端: ['DeepSeek']
2025-11-12 00:42:37,492 - INFO - root - === 运行配置 ===
2025-11-12 00:42:37,492 - INFO - root - 处理模式: arxiv在线搜索
2025-11-12 00:42:37,497 - INFO - root - 关键词: CVPR 2026
2025-11-12 00:42:37,497 - INFO - root - 查询: CVPR 2026
2025-11-12 00:42:37,499 - INFO - root - 排序: None
2025-11-12 00:42:37,499 - INFO - root - 最近天数: 180
2025-11-12 00:42:37,500 - INFO - root - 最大处理数量: 2
2025-11-12 00:42:37,500 - INFO - root - 保存图片: 是
2025-11-12 00:42:37,500 - INFO - root - 输出语言: 中文
2025-11-12 00:42:37,500 - INFO - root - 强制重新处理: 否
2025-11-12 00:42:37,501 - INFO - root - ====================
2025-11-12 00:42:37,502 - INFO - root - 使用 arXiv 搜索模式（通过 chat_arxiv 模块获取）
2025-11-12 00:42:37,503 - INFO - root - Fetching page 1 with URL: https://arxiv.org/search/?query=CVPR+2026&searchtype=all&abstracts=show&order=-announced_date_first&size=50
2025-11-12 00:42:55,634 - INFO - root - get_all_titles_from_web 
2025-11-12 00:42:55,634 - INFO - root - Page:0, Index:0, Learning to Seek Evidence: A Verifiable Reasoning Agent with Causal Faithfulness Analysis, https://arxiv.org/pdf/2511.01425, 2025-11-03
2025-11-12 00:42:55,635 - INFO - root - Fetching page 2 with URL: https://arxiv.org/search/?query=CVPR+2026&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=50
2025-11-12 00:43:17,118 - INFO - root - ------------------------------------------------------------------------------------------------------------------------
2025-11-12 00:43:17,118 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\CVPR 2026\Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness.pdf
2025-11-12 00:43:17,118 - INFO - root - 正在总结论文 1/1: Learning to Seek Evidence: A Verifiable Reasoning Agent with Causal Faithfulness Analysis
2025-11-12 00:43:30,296 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 00:44:17,859 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 00:44:55,083 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 00:44:55,086 - INFO - root - 正在提取论文图片到目录: ./export\CVPR 2026\images\Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness
2025-11-12 00:44:55,204 - INFO - root - 已保存图片 1/10：./export\CVPR 2026\images\Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness\figure_1_page2.jpeg
2025-11-12 00:44:55,219 - INFO - root - 已保存图片 2/10：./export\CVPR 2026\images\Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness\figure_2_page2.jpeg
2025-11-12 00:44:55,234 - INFO - root - 已保存图片 3/10：./export\CVPR 2026\images\Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness\figure_3_page2.jpeg
2025-11-12 00:44:55,253 - INFO - root - 已保存图片 4/10：./export\CVPR 2026\images\Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness\figure_4_page2.jpeg
2025-11-12 00:44:55,270 - INFO - root - 已保存图片 5/10：./export\CVPR 2026\images\Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness\figure_5_page2.jpeg
2025-11-12 00:44:55,285 - INFO - root - 已保存图片 6/10：./export\CVPR 2026\images\Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness\figure_6_page2.jpeg
2025-11-12 00:44:55,321 - INFO - root - 已保存图片 7/10：./export\CVPR 2026\images\Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness\figure_7_page2.jpeg
2025-11-12 00:44:55,337 - INFO - root - 已保存图片 8/10：./export\CVPR 2026\images\Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness\figure_8_page2.jpeg
2025-11-12 00:44:55,378 - INFO - root - 已保存图片 9/10：./export\CVPR 2026\images\Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness\figure_9_page2.jpeg
2025-11-12 00:44:55,396 - INFO - root - 已保存图片 10/10：./export\CVPR 2026\images\Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness\figure_10_page2.jpeg
2025-11-12 00:44:55,397 - INFO - root - 成功添加图片 1：./export\CVPR 2026\images\Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness\figure_1_page2.jpeg
2025-11-12 00:44:55,401 - INFO - root - 成功添加图片 2：./export\CVPR 2026\images\Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness\figure_2_page2.jpeg
2025-11-12 00:44:55,402 - INFO - root - 成功添加图片 3：./export\CVPR 2026\images\Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness\figure_3_page2.jpeg
2025-11-12 00:44:55,403 - INFO - root - 成功添加图片 4：./export\CVPR 2026\images\Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness\figure_4_page2.jpeg
2025-11-12 00:44:55,403 - INFO - root - 成功添加图片 5：./export\CVPR 2026\images\Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness\figure_5_page2.jpeg
2025-11-12 00:44:55,403 - INFO - root - 成功添加图片 6：./export\CVPR 2026\images\Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness\figure_6_page2.jpeg
2025-11-12 00:44:55,404 - INFO - root - 成功添加图片 7：./export\CVPR 2026\images\Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness\figure_7_page2.jpeg
2025-11-12 00:44:55,404 - INFO - root - 成功添加图片 8：./export\CVPR 2026\images\Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness\figure_8_page2.jpeg
2025-11-12 00:44:55,405 - INFO - root - 成功添加图片 9：./export\CVPR 2026\images\Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness\figure_9_page2.jpeg
2025-11-12 00:44:55,405 - INFO - root - 成功添加图片 10：./export\CVPR 2026\images\Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness\figure_10_page2.jpeg
2025-11-12 00:44:55,425 - INFO - root - 已按文献标题重新组织图片存储
2025-11-12 00:44:55,429 - INFO - root - 论文《Learning to Seek Evidence: A Verifiable Reasoning Agent with Causal Faithfulness Analysis》的分析已保存到 ./export\CVPR 2026\Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness.md
2025-11-12 00:44:55,810 - INFO - root - 已生成汇总Excel表格: export\CVPR 2026\论文汇总_CVPR 2026_20251112_004455.xlsx
2025-11-12 00:44:55,811 - INFO - root - 已生成汇总Excel表格: export\CVPR 2026\论文汇总_CVPR 2026_20251112_004455.xlsx
2025-11-12 00:44:55,811 - INFO - root - summary time: 144.39 seconds
2025-11-12 00:48:06,259 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-12 00:48:06,261 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-12 00:48:06,263 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-12 00:48:07,982 - INFO - root - LLMClientManager: 指定使用客户端: DeepSeek
2025-11-12 00:48:07,982 - INFO - root - DeepSeekClient: API key found: 9f9e270e-b...
2025-11-12 00:48:07,982 - INFO - root - DeepSeekClient: 使用模式: 火山引擎
2025-11-12 00:48:07,982 - INFO - root - DeepSeekClient: 模型名称: deepseek-v3-1-terminus
2025-11-12 00:48:12,312 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 00:48:12,333 - INFO - root - DeepSeekClient: initialized successfully with model deepseek-v3-1-terminus
2025-11-12 00:48:12,333 - INFO - root - LLMClientManager: DeepSeek 客户端初始化成功
2025-11-12 00:48:12,334 - INFO - root - LLMClientManager: switched to DeepSeek client
2025-11-12 00:48:12,334 - INFO - root - 已手动切换到 LLM 客户端: DeepSeek
2025-11-12 00:48:12,334 - INFO - root - 使用 LLM 模型: deepseek-v3-1-terminus
2025-11-12 00:48:12,334 - INFO - root - 可用客户端: ['DeepSeek']
2025-11-12 00:48:12,335 - INFO - root - === 运行配置 ===
2025-11-12 00:48:12,335 - INFO - root - 处理模式: arxiv在线搜索
2025-11-12 00:48:12,335 - INFO - root - 关键词: CVPR 2026
2025-11-12 00:48:12,336 - INFO - root - 查询: CVPR 2026
2025-11-12 00:48:12,336 - INFO - root - 排序: None
2025-11-12 00:48:12,336 - INFO - root - 最近天数: 180
2025-11-12 00:48:12,337 - INFO - root - 最大处理数量: 2
2025-11-12 00:48:12,337 - INFO - root - 保存图片: 是
2025-11-12 00:48:12,337 - INFO - root - 输出语言: 中文
2025-11-12 00:48:12,338 - INFO - root - 强制重新处理: 否
2025-11-12 00:48:12,338 - INFO - root - ====================
2025-11-12 00:48:12,338 - INFO - root - 使用 arXiv 搜索模式（通过 chat_arxiv 模块获取）
2025-11-12 00:48:12,339 - INFO - root - Fetching page 1 with URL: https://arxiv.org/search/?query=CVPR+2026&searchtype=all&abstracts=show&order=-announced_date_first&size=50
2025-11-12 00:48:40,218 - INFO - root - get_all_titles_from_web 
2025-11-12 00:48:40,218 - INFO - root - Page:0, Index:0, Learning to Seek Evidence: A Verifiable Reasoning Agent with Causal Faithfulness Analysis, https://arxiv.org/pdf/2511.01425, 2025-11-03
2025-11-12 00:48:40,219 - INFO - root - Fetching page 2 with URL: https://arxiv.org/search/?query=CVPR+2026&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=50
2025-11-12 00:49:12,169 - INFO - root - ------------------------------------------------------------------------------------------------------------------------
2025-11-12 00:49:12,178 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\CVPR 2026\Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness.pdf
2025-11-12 00:49:12,207 - INFO - root - 正在总结论文 1/1: Learning to Seek Evidence: A Verifiable Reasoning Agent with Causal Faithfulness Analysis
2025-11-12 00:49:25,664 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 00:50:14,589 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 00:50:49,239 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 00:50:49,241 - INFO - root - 正在提取论文图片到目录: ./export\CVPR 2026\images
2025-11-12 00:50:49,484 - INFO - root - 已保存图片 1/10：./export\CVPR 2026\images\figure_1_page2.jpeg
2025-11-12 00:50:49,492 - INFO - root - 已保存图片 2/10：./export\CVPR 2026\images\figure_2_page2.jpeg
2025-11-12 00:50:49,510 - INFO - root - 已保存图片 3/10：./export\CVPR 2026\images\figure_3_page2.jpeg
2025-11-12 00:50:49,529 - INFO - root - 已保存图片 4/10：./export\CVPR 2026\images\figure_4_page2.jpeg
2025-11-12 00:50:49,546 - INFO - root - 已保存图片 5/10：./export\CVPR 2026\images\figure_5_page2.jpeg
2025-11-12 00:50:49,562 - INFO - root - 已保存图片 6/10：./export\CVPR 2026\images\figure_6_page2.jpeg
2025-11-12 00:50:49,572 - INFO - root - 已保存图片 7/10：./export\CVPR 2026\images\figure_7_page2.jpeg
2025-11-12 00:50:49,584 - INFO - root - 已保存图片 8/10：./export\CVPR 2026\images\figure_8_page2.jpeg
2025-11-12 00:50:49,617 - INFO - root - 已保存图片 9/10：./export\CVPR 2026\images\figure_9_page2.jpeg
2025-11-12 00:50:49,630 - INFO - root - 已保存图片 10/10：./export\CVPR 2026\images\figure_10_page2.jpeg
2025-11-12 00:50:49,632 - INFO - root - 成功添加图片 1：./export\CVPR 2026\images\figure_1_page2.jpeg
2025-11-12 00:50:49,632 - INFO - root - 成功添加图片 2：./export\CVPR 2026\images\figure_2_page2.jpeg
2025-11-12 00:50:49,632 - INFO - root - 成功添加图片 3：./export\CVPR 2026\images\figure_3_page2.jpeg
2025-11-12 00:50:49,633 - INFO - root - 成功添加图片 4：./export\CVPR 2026\images\figure_4_page2.jpeg
2025-11-12 00:50:49,633 - INFO - root - 成功添加图片 5：./export\CVPR 2026\images\figure_5_page2.jpeg
2025-11-12 00:50:49,633 - INFO - root - 成功添加图片 6：./export\CVPR 2026\images\figure_6_page2.jpeg
2025-11-12 00:50:49,633 - INFO - root - 成功添加图片 7：./export\CVPR 2026\images\figure_7_page2.jpeg
2025-11-12 00:50:49,634 - INFO - root - 成功添加图片 8：./export\CVPR 2026\images\figure_8_page2.jpeg
2025-11-12 00:50:49,634 - INFO - root - 成功添加图片 9：./export\CVPR 2026\images\figure_9_page2.jpeg
2025-11-12 00:50:49,634 - INFO - root - 成功添加图片 10：./export\CVPR 2026\images\figure_10_page2.jpeg
2025-11-12 00:50:49,640 - INFO - root - 已按文献标题重新组织图片存储
2025-11-12 00:50:49,643 - WARNING - root - 强制复制图片失败: name 'shutil' is not defined
2025-11-12 00:50:49,644 - WARNING - root - 强制复制图片失败: name 'shutil' is not defined
2025-11-12 00:50:49,644 - WARNING - root - 强制复制图片失败: name 'shutil' is not defined
2025-11-12 00:50:49,645 - WARNING - root - 强制复制图片失败: name 'shutil' is not defined
2025-11-12 00:50:49,645 - WARNING - root - 强制复制图片失败: name 'shutil' is not defined
2025-11-12 00:50:49,646 - WARNING - root - 强制复制图片失败: name 'shutil' is not defined
2025-11-12 00:50:49,646 - WARNING - root - 强制复制图片失败: name 'shutil' is not defined
2025-11-12 00:50:49,647 - WARNING - root - 强制复制图片失败: name 'shutil' is not defined
2025-11-12 00:50:49,648 - WARNING - root - 强制复制图片失败: name 'shutil' is not defined
2025-11-12 00:50:49,649 - WARNING - root - 强制复制图片失败: name 'shutil' is not defined
2025-11-12 00:50:49,651 - INFO - root - 论文《Learning to Seek Evidence: A Verifiable Reasoning Agent with Causal Faithfulness Analysis》的分析已保存到 ./export\CVPR 2026\Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness.md
2025-11-12 00:50:50,026 - INFO - root - 已生成汇总Excel表格: export\CVPR 2026\论文汇总_CVPR 2026_20251112_005049.xlsx
2025-11-12 00:50:50,027 - INFO - root - 已生成汇总Excel表格: export\CVPR 2026\论文汇总_CVPR 2026_20251112_005049.xlsx
2025-11-12 00:50:50,027 - INFO - root - summary time: 163.77 seconds
2025-11-12 00:56:36,925 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-12 00:56:36,928 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-12 00:56:36,930 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-12 00:56:38,513 - INFO - root - LLMClientManager: 指定使用客户端: DeepSeek
2025-11-12 00:56:38,514 - INFO - root - DeepSeekClient: API key found: 9f9e270e-b...
2025-11-12 00:56:38,514 - INFO - root - DeepSeekClient: 使用模式: 火山引擎
2025-11-12 00:56:38,516 - INFO - root - DeepSeekClient: 模型名称: deepseek-v3-1-terminus
2025-11-12 00:56:42,841 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 00:56:42,889 - INFO - root - DeepSeekClient: initialized successfully with model deepseek-v3-1-terminus
2025-11-12 00:56:42,893 - INFO - root - LLMClientManager: DeepSeek 客户端初始化成功
2025-11-12 00:56:42,894 - INFO - root - LLMClientManager: switched to DeepSeek client
2025-11-12 00:56:42,894 - INFO - root - 已手动切换到 LLM 客户端: DeepSeek
2025-11-12 00:56:42,895 - INFO - root - 使用 LLM 模型: deepseek-v3-1-terminus
2025-11-12 00:56:42,896 - INFO - root - 可用客户端: ['DeepSeek']
2025-11-12 00:56:42,897 - INFO - root - === 运行配置 ===
2025-11-12 00:56:42,897 - INFO - root - 处理模式: arxiv在线搜索
2025-11-12 00:56:42,898 - INFO - root - 关键词: CVPR 2026
2025-11-12 00:56:42,899 - INFO - root - 查询: CVPR 2026
2025-11-12 00:56:42,899 - INFO - root - 排序: None
2025-11-12 00:56:42,902 - INFO - root - 最近天数: 180
2025-11-12 00:56:42,904 - INFO - root - 最大处理数量: 2
2025-11-12 00:56:42,905 - INFO - root - 保存图片: 是
2025-11-12 00:56:42,905 - INFO - root - 输出语言: 中文
2025-11-12 00:56:42,905 - INFO - root - 强制重新处理: 否
2025-11-12 00:56:42,906 - INFO - root - ====================
2025-11-12 00:56:42,907 - INFO - root - 使用 arXiv 搜索模式（通过 chat_arxiv 模块获取）
2025-11-12 00:56:42,908 - INFO - root - Fetching page 1 with URL: https://arxiv.org/search/?query=CVPR+2026&searchtype=all&abstracts=show&order=-announced_date_first&size=50
2025-11-12 00:57:03,233 - INFO - root - get_all_titles_from_web 
2025-11-12 00:57:03,234 - INFO - root - Page:0, Index:0, Learning to Seek Evidence: A Verifiable Reasoning Agent with Causal Faithfulness Analysis, https://arxiv.org/pdf/2511.01425, 2025-11-03
2025-11-12 00:57:03,235 - INFO - root - Fetching page 2 with URL: https://arxiv.org/search/?query=CVPR+2026&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=50
2025-11-12 00:57:16,532 - INFO - root - ------------------------------------------------------------------------------------------------------------------------
2025-11-12 00:57:16,533 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\CVPR 2026\Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness.pdf
2025-11-12 00:57:16,561 - INFO - root - 正在总结论文 1/1: Learning to Seek Evidence: A Verifiable Reasoning Agent with Causal Faithfulness Analysis
2025-11-12 00:57:26,097 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 00:57:59,938 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 00:57:59,939 - INFO - root - LLMClient: rate limit reached, sleeping 16.6s
2025-11-12 00:58:42,546 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 00:58:42,587 - INFO - root - 正在提取论文图片到目录: ./export\CVPR 2026\images
2025-11-12 00:58:42,779 - INFO - root - 已保存图片 1/10：./export\CVPR 2026\images\figure_1_page2.jpeg
2025-11-12 00:58:42,787 - INFO - root - 已保存图片 2/10：./export\CVPR 2026\images\figure_2_page2.jpeg
2025-11-12 00:58:42,796 - INFO - root - 已保存图片 3/10：./export\CVPR 2026\images\figure_3_page2.jpeg
2025-11-12 00:58:42,802 - INFO - root - 已保存图片 4/10：./export\CVPR 2026\images\figure_4_page2.jpeg
2025-11-12 00:58:42,810 - INFO - root - 已保存图片 5/10：./export\CVPR 2026\images\figure_5_page2.jpeg
2025-11-12 00:58:42,821 - INFO - root - 已保存图片 6/10：./export\CVPR 2026\images\figure_6_page2.jpeg
2025-11-12 00:58:42,831 - INFO - root - 已保存图片 7/10：./export\CVPR 2026\images\figure_7_page2.jpeg
2025-11-12 00:58:42,836 - INFO - root - 已保存图片 8/10：./export\CVPR 2026\images\figure_8_page2.jpeg
2025-11-12 00:58:42,881 - INFO - root - 已保存图片 9/10：./export\CVPR 2026\images\figure_9_page2.jpeg
2025-11-12 00:58:42,911 - INFO - root - 已保存图片 10/10：./export\CVPR 2026\images\figure_10_page2.jpeg
2025-11-12 00:58:42,914 - INFO - root - 成功添加图片 1：./export\CVPR 2026\images\figure_1_page2.jpeg
2025-11-12 00:58:42,916 - INFO - root - 成功添加图片 2：./export\CVPR 2026\images\figure_2_page2.jpeg
2025-11-12 00:58:42,916 - INFO - root - 成功添加图片 3：./export\CVPR 2026\images\figure_3_page2.jpeg
2025-11-12 00:58:42,917 - INFO - root - 成功添加图片 4：./export\CVPR 2026\images\figure_4_page2.jpeg
2025-11-12 00:58:42,917 - INFO - root - 成功添加图片 5：./export\CVPR 2026\images\figure_5_page2.jpeg
2025-11-12 00:58:42,917 - INFO - root - 成功添加图片 6：./export\CVPR 2026\images\figure_6_page2.jpeg
2025-11-12 00:58:42,918 - INFO - root - 成功添加图片 7：./export\CVPR 2026\images\figure_7_page2.jpeg
2025-11-12 00:58:42,918 - INFO - root - 成功添加图片 8：./export\CVPR 2026\images\figure_8_page2.jpeg
2025-11-12 00:58:42,919 - INFO - root - 成功添加图片 9：./export\CVPR 2026\images\figure_9_page2.jpeg
2025-11-12 00:58:42,920 - INFO - root - 成功添加图片 10：./export\CVPR 2026\images\figure_10_page2.jpeg
2025-11-12 00:58:42,923 - INFO - root - 已更新图片链接
2025-11-12 00:58:42,924 - INFO - root - 论文《Learning to Seek Evidence: A Verifiable Reasoning Agent with Causal Faithfulness Analysis》的分析已保存到 ./export\CVPR 2026\Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness.md
2025-11-12 00:58:43,285 - INFO - root - 已生成汇总Excel表格: export\CVPR 2026\论文汇总_CVPR 2026_20251112_005842.xlsx
2025-11-12 00:58:43,289 - INFO - root - 已生成汇总Excel表格: export\CVPR 2026\论文汇总_CVPR 2026_20251112_005842.xlsx
2025-11-12 00:58:43,289 - INFO - root - summary time: 126.36 seconds
2025-11-12 01:00:02,771 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-12 01:00:02,798 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-12 01:00:02,887 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-12 01:00:09,723 - INFO - root - LLMClientManager: 指定使用客户端: Gemini
2025-11-12 01:00:11,271 - INFO - root - GeminiClient: trying model models/gemini-2.5-flash
2025-11-12 01:00:25,168 - INFO - root - GeminiClient: initialized model gemini-2.5-flash
2025-11-12 01:00:25,169 - INFO - root - LLMClientManager: Gemini 客户端初始化成功
2025-11-12 01:00:25,170 - INFO - root - LLMClientManager: switched to Gemini client
2025-11-12 01:00:25,172 - INFO - root - 已手动切换到 LLM 客户端: Gemini
2025-11-12 01:00:25,172 - INFO - root - 使用 LLM 模型: gemini-2.5-flash
2025-11-12 01:00:25,173 - INFO - root - 可用客户端: ['Gemini']
2025-11-12 01:00:25,173 - INFO - root - === 运行配置 ===
2025-11-12 01:00:25,173 - INFO - root - 处理模式: arxiv在线搜索
2025-11-12 01:00:25,174 - INFO - root - 关键词: CVPR 2026
2025-11-12 01:00:25,174 - INFO - root - 查询: CVPR 2025
2025-11-12 01:00:25,175 - INFO - root - 排序: None
2025-11-12 01:00:25,176 - INFO - root - 最近天数: 180
2025-11-12 01:00:25,178 - INFO - root - 最大处理数量: 30
2025-11-12 01:00:25,182 - INFO - root - 保存图片: 是
2025-11-12 01:00:25,183 - INFO - root - 输出语言: 中文
2025-11-12 01:00:25,183 - INFO - root - 强制重新处理: 否
2025-11-12 01:00:25,185 - INFO - root - ====================
2025-11-12 01:00:25,185 - INFO - root - 使用 arXiv 搜索模式（通过 chat_arxiv 模块获取）
2025-11-12 01:00:25,186 - INFO - root - Fetching page 1 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50
2025-11-12 01:00:34,777 - INFO - root - get_all_titles_from_web 
2025-11-12 01:00:34,777 - INFO - root - Page:0, Index:0, Learning to Seek Evidence: A Verifiable Reasoning Agent with Causal Faithfulness Analysis, https://arxiv.org/pdf/2511.01425, 2025-11-03
2025-11-12 01:00:34,778 - INFO - root - Page:0, Index:1, OmniTrack++: Omnidirectional Multi-Object Tracking by Learning Large-FoV Trajectory Feedback, https://arxiv.org/pdf/2511.00510, 2025-11-01
2025-11-12 01:00:34,778 - INFO - root - Page:0, Index:2, NeuCo-Bench: A Novel Benchmark Framework for Neural Embeddings in Earth Observation, https://arxiv.org/pdf/2510.17914, 2025-10-19
2025-11-12 01:00:34,778 - INFO - root - Page:0, Index:3, NTIRE 2025 Challenge on Low Light Image Enhancement: Methods and Results, https://arxiv.org/pdf/2510.13670, 2025-10-15
2025-11-12 01:00:34,778 - INFO - root - Page:0, Index:4, Class Prototypes based Contrastive Learning for Classifying Multi-Label and Fine-Grained Educational Videos, https://arxiv.org/pdf/2510.11204, 2025-10-13
2025-11-12 01:00:34,779 - INFO - root - Page:0, Index:5, MIMO: A medical vision language model with visual referring multimodal input and pixel grounding multimodal output, https://arxiv.org/pdf/2510.10011, 2025-10-11
2025-11-12 01:00:34,779 - INFO - root - Page:0, Index:6, Vision Language Models: A Survey of 26K Papers, https://arxiv.org/pdf/2510.09586, 2025-10-10
2025-11-12 01:00:34,779 - INFO - root - Page:0, Index:7, DiT-VTON: Diffusion Transformer Framework for Unified Multi-Category Virtual Try-On and Virtual Try-All with Integrated Image Editing, https://arxiv.org/pdf/2510.04797, 2025-10-03
2025-11-12 01:00:34,780 - INFO - root - Page:0, Index:8, PatchVSR: Breaking Video Diffusion Resolution Limits with Patch-wise Video Super-Resolution, https://arxiv.org/pdf/2509.26025, 2025-09-30
2025-11-12 01:00:34,780 - INFO - root - Page:0, Index:9, FreqDebias: Towards Generalizable Deepfake Detection via Consistency-Driven Frequency Debiasing, https://arxiv.org/pdf/2509.22412, 2025-09-26
2025-11-12 01:00:34,780 - INFO - root - Page:0, Index:10, A Mutual Learning Method for Salient Object Detection with intertwined Multi-Supervision--Revised, https://arxiv.org/pdf/2509.21363, 2025-09-21
2025-11-12 01:00:34,780 - INFO - root - Page:0, Index:11, InstructVTON: Optimal Auto-Masking and Natural-Language-Guided Interactive Style Control for Inpainting-Based Virtual Try-On, https://arxiv.org/pdf/2509.20524, 2025-09-24
2025-11-12 01:00:34,780 - INFO - root - Page:0, Index:12, Efficient Encoder-Free Pose Conditioning and Pose Control for Virtual Try-On, https://arxiv.org/pdf/2509.20343, 2025-09-24
2025-11-12 01:00:34,782 - INFO - root - Page:0, Index:13, The Photographer Eye: Teaching Multimodal Large Language Models to Understand Image Aesthetics like Photographers, https://arxiv.org/pdf/2509.18582, 2025-10-22
2025-11-12 01:00:34,782 - INFO - root - Page:0, Index:14, ENSAM: an efficient foundation model for interactive segmentation of 3D medical images, https://arxiv.org/pdf/2509.15874, 2025-09-19
2025-11-12 01:00:34,782 - INFO - root - Page:0, Index:15, DEFT-VTON: Efficient Virtual Try-On with Consistent Generalised H-Transform, https://arxiv.org/pdf/2509.13506, 2025-09-16
2025-11-12 01:00:34,782 - INFO - root - Page:0, Index:16, Weakly and Self-Supervised Class-Agnostic Motion Prediction for Autonomous Driving, https://arxiv.org/pdf/2509.13116, 2025-09-16
2025-11-12 01:00:34,783 - INFO - root - Page:0, Index:17, Domain-Adaptive Pretraining Improves Primate Behavior Recognition, https://arxiv.org/pdf/2509.12193, 2025-09-15
2025-11-12 01:00:34,783 - INFO - root - Page:0, Index:18, The System Description of CPS Team for Track on Driving with Language of CVPR 2024 Autonomous Grand Challenge, https://arxiv.org/pdf/2509.11071, 2025-09-13
2025-11-12 01:00:34,784 - INFO - root - Page:0, Index:19, An HMM-based framework for identity-aware long-term multi-object tracking from sparse and uncertain identification: use case on long-term tracking in livestock, https://arxiv.org/pdf/2509.09962, 2025-09-12
2025-11-12 01:00:34,784 - INFO - root - Page:0, Index:20, InterAct: Advancing Large-Scale Versatile 3D Human-Object Interaction Generation, https://arxiv.org/pdf/2509.09555, 2025-09-11
2025-11-12 01:00:34,784 - INFO - root - Page:0, Index:21, Geospatial Foundational Embedder: Top-1 Winning Solution on EarthVision Embed2Scale Challenge (CVPR 2025), https://arxiv.org/pdf/2509.06993, 2025-09-03
2025-11-12 01:00:34,785 - INFO - root - Page:0, Index:22, 2nd Place Solution for CVPR2024 E2E Challenge: End-to-End Autonomous Driving Using Vision Language Model, https://arxiv.org/pdf/2509.02659, 2025-09-02
2025-11-12 01:00:34,785 - INFO - root - Page:0, Index:23, Unsupervised Training of Vision Transformers with Synthetic Negatives, https://arxiv.org/pdf/2509.02024, 2025-09-02
2025-11-12 01:00:34,785 - INFO - root - Page:0, Index:24, MV-SSM: Multi-View State Space Modeling for 3D Human Pose Estimation, https://arxiv.org/pdf/2509.00649, 2025-08-30
2025-11-12 01:00:34,786 - INFO - root - Page:0, Index:25, CryptoFace: End-to-End Encrypted Face Recognition, https://arxiv.org/pdf/2509.00332, 2025-08-29
2025-11-12 01:00:34,786 - INFO - root - Page:0, Index:26, ControlEchoSynth: Boosting Ejection Fraction Estimation Models via Controlled Video Diffusion, https://arxiv.org/pdf/2508.17631, 2025-08-26
2025-11-12 01:00:34,786 - INFO - root - Page:0, Index:27, Explain Before You Answer: A Survey on Compositional Visual Reasoning, https://arxiv.org/pdf/2508.17298, 2025-08-27
2025-11-12 01:00:34,786 - INFO - root - Page:0, Index:28, Investigating Different Geo Priors for Image Classification, https://arxiv.org/pdf/2508.15946, 2025-08-21
2025-11-12 01:00:34,787 - INFO - root - Page:0, Index:29, Towards Source-Free Machine Unlearning, https://arxiv.org/pdf/2508.15127, 2025-08-20
2025-11-12 01:00:34,787 - INFO - root - Page:0, Index:30, MR6D: Benchmarking 6D Pose Estimation for Mobile Robots, https://arxiv.org/pdf/2508.13775, 2025-08-19
2025-11-12 01:00:34,787 - INFO - root - Page:0, Index:31, Calibrating Biased Distribution in VFM-derived Latent Space via Cross-Domain Geometric Consistency, https://arxiv.org/pdf/2508.13518, 2025-08-19
2025-11-12 01:00:34,788 - INFO - root - Page:0, Index:32, SIS-Challenge: Event-based Spatio-temporal Instance Segmentation Challenge at the CVPR 2025 Event-based Vision Workshop, https://arxiv.org/pdf/2508.12813, 2025-08-18
2025-11-12 01:00:34,792 - INFO - root - Page:0, Index:33, Multi-Level Knowledge Distillation and Dynamic Self-Supervised Learning for Continual Learning, https://arxiv.org/pdf/2508.12692, 2025-08-22
2025-11-12 01:00:34,792 - INFO - root - Page:0, Index:34, Stochastic-based Patch Filtering for Few-Shot Learning, https://arxiv.org/pdf/2508.10066, 2025-08-13
2025-11-12 01:00:34,793 - INFO - root - Page:0, Index:35, Slot Attention-based Feature Filtering for Few-Shot Learning, https://arxiv.org/pdf/2508.09699, 2025-08-13
2025-11-12 01:00:34,793 - INFO - root - Page:0, Index:36, Comparison Reveals Commonality: Customized Image Generation through Contrastive Inversion, https://arxiv.org/pdf/2508.07755, 2025-08-11
2025-11-12 01:00:34,794 - INFO - root - Page:0, Index:37, SLRTP2025 Sign Language Production Challenge: Methodology, Results, and Future Work, https://arxiv.org/pdf/2508.06951, 2025-08-09
2025-11-12 01:00:34,794 - INFO - root - Page:0, Index:38, Exploring Fairness across Fine-Grained Attributes in Large Vision-Language Models, https://arxiv.org/pdf/2508.03079, 2025-08-05
2025-11-12 01:00:34,794 - INFO - root - Page:0, Index:39, Devil is in the Detail: Towards Injecting Fine Details of Image Prompt in Image Generation via Conflict-free Guidance and Stratified Attention, https://arxiv.org/pdf/2508.02004, 2025-08-03
2025-11-12 01:00:34,795 - INFO - root - Page:0, Index:40, IAUNet: Instance-Aware U-Net, https://arxiv.org/pdf/2508.01928, 2025-08-03
2025-11-12 01:00:34,795 - INFO - root - Page:0, Index:41, Gaussian Splatting Feature Fields for Privacy-Preserving Visual Localization, https://arxiv.org/pdf/2507.23569, 2025-08-26
2025-11-12 01:00:34,796 - INFO - root - Page:0, Index:42, From Scan to Action: Leveraging Realistic Scans for Embodied Scene Understanding, https://arxiv.org/pdf/2507.17585, 2025-07-23
2025-11-12 01:00:34,796 - INFO - root - Page:0, Index:43, LEAD: Exploring Logit Space Evolution for Model Selection, https://arxiv.org/pdf/2507.14559, 2025-07-19
2025-11-12 01:00:34,796 - INFO - root - Page:0, Index:44, HeCoFuse: Cross-Modal Complementary V2X Cooperative Perception with Heterogeneous Sensors, https://arxiv.org/pdf/2507.13677, 2025-07-18
2025-11-12 01:00:34,797 - INFO - root - Page:0, Index:45, OmniVec2 -- A Novel Transformer based Network for Large Scale Multimodal and Multitask Learning, https://arxiv.org/pdf/2507.13364, 2025-07-06
2025-11-12 01:00:34,797 - INFO - root - Page:0, Index:46, A Training-Free, Task-Agnostic Framework for Enhancing MLLM Performance on High-Resolution Images, https://arxiv.org/pdf/2507.10202, 2025-07-14
2025-11-12 01:00:34,797 - INFO - root - Page:0, Index:47, Quantum Federated Learning for Multimodal Data: A Modality-Agnostic Approach, https://arxiv.org/pdf/2507.08217, 2025-07-10
2025-11-12 01:00:34,798 - INFO - root - Page:0, Index:48, CuriosAI Submission to the EgoExo4D Proficiency Estimation Challenge 2025, https://arxiv.org/pdf/2507.08022, 2025-07-08
2025-11-12 01:00:34,798 - INFO - root - Page:0, Index:49, Rethinking Query-based Transformer for Continual Image Segmentation, https://arxiv.org/pdf/2507.07831, 2025-07-10
2025-11-12 01:00:34,798 - INFO - root - Fetching page 2 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=50
2025-11-12 01:00:44,541 - INFO - root - get_all_titles_from_web 
2025-11-12 01:00:44,541 - INFO - root - Page:1, Index:0, Scalable and Realistic Virtual Try-on Application for Foundation Makeup with Kubelka-Munk Theory, https://arxiv.org/pdf/2507.07333, 2025-07-09
2025-11-12 01:00:44,542 - INFO - root - Page:1, Index:1, Free on the Fly: Enhancing Flexibility in Test-Time Adaptation with Online EM, https://arxiv.org/pdf/2507.06973, 2025-07-09
2025-11-12 01:00:44,542 - INFO - root - Page:1, Index:2, Adaptive Part Learning for Fine-Grained Generalized Category Discovery: A Plug-and-Play Enhancement, https://arxiv.org/pdf/2507.06928, 2025-07-09
2025-11-12 01:00:44,542 - INFO - root - Page:1, Index:3, Grounded Gesture Generation: Language, Motion, and Space, https://arxiv.org/pdf/2507.04522, 2025-07-06
2025-11-12 01:00:44,543 - INFO - root - Page:1, Index:4, Comprehensive Information Bottleneck for Unveiling Universal Attribution to Interpret Vision Transformers, https://arxiv.org/pdf/2507.04388, 2025-07-06
2025-11-12 01:00:44,543 - INFO - root - Page:1, Index:5, ZERO: Industry-ready Vision Foundation Model with Multi-modal Prompts, https://arxiv.org/pdf/2507.04270, 2025-11-07
2025-11-12 01:00:44,543 - INFO - root - Page:1, Index:6, Beyond Accuracy: Metrics that Uncover What Makes a 'Good' Visual Descriptor, https://arxiv.org/pdf/2507.03542, 2025-07-08
2025-11-12 01:00:44,544 - INFO - root - Page:1, Index:7, ConceptMix++: Leveling the Playing Field in Text-to-Image Benchmarking via Iterative Prompt Optimization, https://arxiv.org/pdf/2507.03275, 2025-07-03
2025-11-12 01:00:44,544 - INFO - root - Page:1, Index:8, APT: Adaptive Personalized Training for Diffusion Models with Limited Data, https://arxiv.org/pdf/2507.02687, 2025-07-03
2025-11-12 01:00:44,544 - INFO - root - Page:1, Index:9, DreamComposer++: Empowering Diffusion Models with Multi-View Conditions for 3D Content Generation, https://arxiv.org/pdf/2507.02299, 2025-07-03
2025-11-12 01:00:44,545 - INFO - root - Page:1, Index:10, Soft Self-labeling and Potts Relaxations for Weakly-Supervised Segmentation, https://arxiv.org/pdf/2507.01721, 2025-07-02
2025-11-12 01:00:44,545 - INFO - root - Page:1, Index:11, Interpolation-Based Event Visual Data Filtering Algorithms, https://arxiv.org/pdf/2507.01557, 2025-07-02
2025-11-12 01:00:44,545 - INFO - root - Page:1, Index:12, AVC-DPO: Aligned Video Captioning via Direct Preference Optimization, https://arxiv.org/pdf/2507.01492, 2025-07-02
2025-11-12 01:00:44,545 - INFO - root - Page:1, Index:13, NN-Former: Rethinking Graph Structure in Neural Architecture Representation, https://arxiv.org/pdf/2507.00880, 2025-07-01
2025-11-12 01:00:44,546 - INFO - root - Page:1, Index:14, Instant Particle Size Distribution Measurement Using CNNs Trained on Synthetic Data, https://arxiv.org/pdf/2507.00822, 2025-07-01
2025-11-12 01:00:44,546 - INFO - root - Page:1, Index:15, Moment Sampling in Video LLMs for Long-Form Video QA, https://arxiv.org/pdf/2507.00033, 2025-06-17
2025-11-12 01:00:44,548 - INFO - root - Page:1, Index:16, Revisiting Audio-Visual Segmentation with Vision-Centric Transformer, https://arxiv.org/pdf/2506.23623, 2025-06-30
2025-11-12 01:00:44,548 - INFO - root - Page:1, Index:17, MTADiffusion: Mask Text Alignment Diffusion Model for Object Inpainting, https://arxiv.org/pdf/2506.23482, 2025-06-29
2025-11-12 01:00:44,550 - INFO - root - Page:1, Index:18, Benchmarking Generalizable Bimanual Manipulation: RoboTwin Dual-Arm Collaboration Challenge at CVPR 2025 MEIS Workshop, https://arxiv.org/pdf/2506.23351, 2025-07-02
2025-11-12 01:00:44,550 - INFO - root - Page:1, Index:19, Prompting without Panic: Attribute-aware, Zero-shot, Test-Time Calibration, https://arxiv.org/pdf/2506.22819, 2025-06-28
2025-11-12 01:00:44,551 - INFO - root - Page:1, Index:20, Analyzing and Fine-Tuning Whisper Models for Multilingual Pilot Speech Transcription in the Cockpit, https://arxiv.org/pdf/2506.21990, 2025-06-27
2025-11-12 01:00:44,552 - INFO - root - Page:1, Index:21, SceneDiffuser++: City-Scale Traffic Simulation via a Generative World Model, https://arxiv.org/pdf/2506.21976, 2025-06-27
2025-11-12 01:00:44,553 - INFO - root - Page:1, Index:22, DIVE: Deep-search Iterative Video Exploration A Technical Report for the CVRR Challenge at CVPR 2025, https://arxiv.org/pdf/2506.21891, 2025-06-27
2025-11-12 01:00:44,553 - INFO - root - Page:1, Index:23, End-to-End RGB-IR Joint Image Compression With Channel-wise Cross-modality Entropy Model, https://arxiv.org/pdf/2506.21851, 2025-06-26
2025-11-12 01:00:44,553 - INFO - root - Page:1, Index:24, Distilling Normalizing Flows, https://arxiv.org/pdf/2506.21003, 2025-06-26
2025-11-12 01:00:44,554 - INFO - root - Page:1, Index:25, Joint attitude estimation and 3D neural reconstruction of non-cooperative space objects, https://arxiv.org/pdf/2506.20638, 2025-06-25
2025-11-12 01:00:44,554 - INFO - root - Page:1, Index:26, Accept More, Reject Less: Reducing up to 19% Unnecessary Desk-Rejections over 11 Years of ICLR Data, https://arxiv.org/pdf/2506.20141, 2025-06-25
2025-11-12 01:00:44,554 - INFO - root - Page:1, Index:27, SceneCrafter: Controllable Multi-View Driving Scene Editing, https://arxiv.org/pdf/2506.19488, 2025-06-24
2025-11-12 01:00:44,556 - INFO - root - Page:1, Index:28, Emergence of Text Readability in Vision Language Models, https://arxiv.org/pdf/2506.19389, 2025-06-24
2025-11-12 01:00:44,556 - INFO - root - Page:1, Index:29, MedErr-CT: A Visual Question Answering Benchmark for Identifying and Correcting Errors in CT Reports, https://arxiv.org/pdf/2506.19217, 2025-06-23
2025-11-12 01:00:44,556 - INFO - root - Page:1, Index:30, RareSpot: Spotting Small and Rare Wildlife in Aerial Imagery with Multi-Scale Consistency and Context-Aware Augmentation, https://arxiv.org/pdf/2506.19087, 2025-06-23
2025-11-12 01:00:44,556 - INFO - root - Page:1, Index:31, Object-aware Sound Source Localization via Audio-Visual Scene Understanding, https://arxiv.org/pdf/2506.18557, 2025-06-23
2025-11-12 01:00:44,557 - INFO - root - Page:1, Index:32, Rethinking Decoder Design: Improving Biomarker Segmentation Using Depth-to-Space Restoration and Residual Linear Attention, https://arxiv.org/pdf/2506.18335, 2025-06-23
2025-11-12 01:00:44,557 - INFO - root - Page:1, Index:33, Relation3D: Enhancing Relation Modeling for Point Cloud Instance Segmentation, https://arxiv.org/pdf/2506.17891, 2025-06-21
2025-11-12 01:00:44,557 - INFO - root - Page:1, Index:34, HIRE: Lightweight High-Resolution Image Feature Enrichment for Multimodal LLMs, https://arxiv.org/pdf/2506.17608, 2025-06-21
2025-11-12 01:00:44,557 - INFO - root - Page:1, Index:35, Spatially-Aware Evaluation of Segmentation Uncertainty, https://arxiv.org/pdf/2506.16589, 2025-06-19
2025-11-12 01:00:44,558 - INFO - root - Page:1, Index:36, Tripartite Weight-Space Ensemble for Few-Shot Class-Incremental Learning, https://arxiv.org/pdf/2506.15720, 2025-06-03
2025-11-12 01:00:44,558 - INFO - root - Page:1, Index:37, PARC: A Quantitative Framework Uncovering the Symmetries within Vision Language Models, https://arxiv.org/pdf/2506.14808, 2025-06-03
2025-11-12 01:00:44,563 - INFO - root - Page:1, Index:38, Self-supervised Representation Learning with Local Aggregation for Image-based Profiling, https://arxiv.org/pdf/2506.14265, 2025-10-27
2025-11-12 01:00:44,564 - INFO - root - Page:1, Index:39, Towards Robust Learning to Optimize with Theoretical Guarantees, https://arxiv.org/pdf/2506.14263, 2025-06-17
2025-11-12 01:00:44,564 - INFO - root - Page:1, Index:40, Hidden Bias in the Machine: Stereotypes in Text-to-Image Models, https://arxiv.org/pdf/2506.13780, 2025-06-09
2025-11-12 01:00:44,566 - INFO - root - Page:1, Index:41, SmartHome-Bench: A Comprehensive Benchmark for Video Anomaly Detection in Smart Homes Using Multi-Modal Large Language Models, https://arxiv.org/pdf/2506.12992, 2025-06-15
2025-11-12 01:00:44,568 - INFO - root - Page:1, Index:42, Generative 4D Scene Gaussian Splatting with Object View-Synthesis Priors, https://arxiv.org/pdf/2506.12716, 2025-06-15
2025-11-12 01:00:44,570 - INFO - root - Page:1, Index:43, DejaVid: Encoder-Agnostic Learned Temporal Matching for Video Classification, https://arxiv.org/pdf/2506.12585, 2025-06-14
2025-11-12 01:00:44,570 - INFO - root - Page:1, Index:44, Pushing the Limits of Safety: A Technical Report on the ATLAS Challenge 2025, https://arxiv.org/pdf/2506.12430, 2025-07-10
2025-11-12 01:00:44,570 - INFO - root - Page:1, Index:45, FIMA-Q: Post-Training Quantization for Vision Transformers by Fisher Information Matrix Approximation, https://arxiv.org/pdf/2506.11543, 2025-06-13
2025-11-12 01:00:44,571 - INFO - root - Page:1, Index:46, Stop learning it all to mitigate visual hallucination, Focus on the hallucination target, https://arxiv.org/pdf/2506.11417, 2025-06-12
2025-11-12 01:00:44,571 - INFO - root - Page:1, Index:47, EfficientQuant: An Efficient Post-Training Quantization for CNN-Transformer Hybrid Models on Edge Devices, https://arxiv.org/pdf/2506.11093, 2025-06-05
2025-11-12 01:00:44,571 - INFO - root - Page:1, Index:48, HalLoc: Token-level Localization of Hallucinations for Vision Language Models, https://arxiv.org/pdf/2506.10286, 2025-06-11
2025-11-12 01:00:44,573 - INFO - root - Page:1, Index:49, DySS: Dynamic Queries and State-Space Learning for Efficient 3D Object Detection from Multi-Camera Videos, https://arxiv.org/pdf/2506.10242, 2025-06-11
2025-11-12 01:00:44,573 - INFO - root - Fetching page 3 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=100
2025-11-12 01:00:56,431 - INFO - root - get_all_titles_from_web 
2025-11-12 01:00:56,432 - INFO - root - Page:2, Index:0, Improving Personalized Search with Regularized Low-Rank Parameter Updates, https://arxiv.org/pdf/2506.10182, 2025-06-11
2025-11-12 01:00:56,432 - INFO - root - Page:2, Index:1, Hearing Hands: Generating Sounds from Physical Interactions in 3D Scenes, https://arxiv.org/pdf/2506.09989, 2025-06-11
2025-11-12 01:00:56,432 - INFO - root - Page:2, Index:2, UniPre3D: Unified Pre-training of 3D Point Cloud Models with Cross-Modal Gaussian Splatting, https://arxiv.org/pdf/2506.09952, 2025-06-11
2025-11-12 01:00:56,433 - INFO - root - Page:2, Index:3, Provoking Multi-modal Few-Shot LVLM via Exploration-Exploitation In-Context Learning, https://arxiv.org/pdf/2506.09473, 2025-06-11
2025-11-12 01:00:56,433 - INFO - root - Page:2, Index:4, Synthetic Human Action Video Data Generation with Pose Transfer, https://arxiv.org/pdf/2506.09411, 2025-06-11
2025-11-12 01:00:56,433 - INFO - root - Page:2, Index:5, ScaleLSD: Scalable Deep Line Segment Detection Streamlined, https://arxiv.org/pdf/2506.09369, 2025-06-10
2025-11-12 01:00:56,434 - INFO - root - Page:2, Index:6, CheckManual: A New Challenge and Benchmark for Manual-based Appliance Manipulation, https://arxiv.org/pdf/2506.09343, 2025-06-10
2025-11-12 01:00:56,434 - INFO - root - Page:2, Index:7, PatchGuard: Adversarially Robust Anomaly Detection and Localization through Vision Transformers and Pseudo Anomalies, https://arxiv.org/pdf/2506.09237, 2025-10-24
2025-11-12 01:00:56,434 - INFO - root - Page:2, Index:8, SILK: Smooth InterpoLation frameworK for motion in-betweening A Simplified Computational Approach, https://arxiv.org/pdf/2506.09075, 2025-06-09
2025-11-12 01:00:56,435 - INFO - root - Page:2, Index:9, BG-HOP: A Bimanual Generative Hand-Object Prior, https://arxiv.org/pdf/2506.09068, 2025-06-08
2025-11-12 01:00:56,435 - INFO - root - Page:2, Index:10, ORIDa: Object-centric Real-world Image Composition Dataset, https://arxiv.org/pdf/2506.08964, 2025-06-10
2025-11-12 01:00:56,435 - INFO - root - Page:2, Index:11, DiscoVLA: Discrepancy Reduction in Vision, Language, and Alignment for Parameter-Efficient Video-Text Retrieval, https://arxiv.org/pdf/2506.08887, 2025-06-10
2025-11-12 01:00:56,436 - INFO - root - Page:2, Index:12, A Comprehensive Study of Decoder-Only LLMs for Text-to-Image Generation, https://arxiv.org/pdf/2506.08210, 2025-06-09
2025-11-12 01:00:56,436 - INFO - root - Page:2, Index:13, Open World Scene Graph Generation using Vision Language Models, https://arxiv.org/pdf/2506.08189, 2025-06-09
2025-11-12 01:00:56,436 - INFO - root - Page:2, Index:14, Aligning Proteins and Language: A Foundation Model for Protein Retrieval, https://arxiv.org/pdf/2506.08023, 2025-05-27
2025-11-12 01:00:56,437 - INFO - root - Page:2, Index:15, UA-Pose: Uncertainty-Aware 6D Object Pose Estimation and Online Object Completion with Partial References, https://arxiv.org/pdf/2506.07996, 2025-06-09
2025-11-12 01:00:56,438 - INFO - root - Page:2, Index:16, Speedy Deformable 3D Gaussian Splatting: Fast Rendering and Compression of Dynamic Scenes, https://arxiv.org/pdf/2506.07917, 2025-06-09
2025-11-12 01:00:56,438 - INFO - root - Page:2, Index:17, GaussianVAE: Adaptive Learning Dynamics of 3D Gaussians for High-Fidelity Super-Resolution, https://arxiv.org/pdf/2506.07897, 2025-06-09
2025-11-12 01:00:56,439 - INFO - root - Page:2, Index:18, Spatio-Temporal State Space Model For Efficient Event-Based Optical Flow, https://arxiv.org/pdf/2506.07878, 2025-06-09
2025-11-12 01:00:56,439 - INFO - root - Page:2, Index:19, FreeGave: 3D Physics Learning from Dynamic Videos by Gaussian Velocity, https://arxiv.org/pdf/2506.07865, 2025-06-09
2025-11-12 01:00:56,441 - INFO - root - Page:2, Index:20, LogoSP: Local-global Grouping of Superpoints for Unsupervised Semantic Segmentation of 3D Point Clouds, https://arxiv.org/pdf/2506.07857, 2025-06-09
2025-11-12 01:00:56,441 - INFO - root - Page:2, Index:21, Difference Inversion: Interpolate and Isolate the Difference with Token Consistency for Image Analogy Generation, https://arxiv.org/pdf/2506.07750, 2025-06-09
2025-11-12 01:00:56,442 - INFO - root - Page:2, Index:22, Synthetic Visual Genome, https://arxiv.org/pdf/2506.07643, 2025-06-09
2025-11-12 01:00:56,445 - INFO - root - Page:2, Index:23, Fractional Collisions: A Framework for Risk Estimation of Counterfactual Conflicts using Autonomous Driving Behavior Simulations, https://arxiv.org/pdf/2506.07540, 2025-06-09
2025-11-12 01:00:56,445 - INFO - root - Page:2, Index:24, Multi-Step Guided Diffusion for Image Restoration on Edge Devices: Toward Lightweight Perception in Embodied AI, https://arxiv.org/pdf/2506.07286, 2025-06-08
2025-11-12 01:00:56,446 - INFO - root - Page:2, Index:25, LLM-Enhanced Rapid-Reflex Async-Reflect Embodied Agent for Real-Time Decision-Making in Dynamically Changing Environments, https://arxiv.org/pdf/2506.07223, 2025-06-08
2025-11-12 01:00:56,446 - INFO - root - Page:2, Index:26, UCOD-DPL: Unsupervised Camouflaged Object Detection via Dynamic Pseudo-label Learning, https://arxiv.org/pdf/2506.07087, 2025-06-08
2025-11-12 01:00:56,447 - INFO - root - Page:2, Index:27, BePo: Leveraging Birds Eye View and Sparse Points for Efficient and Accurate 3D Occupancy Prediction, https://arxiv.org/pdf/2506.07002, 2025-06-08
2025-11-12 01:00:56,447 - INFO - root - Page:2, Index:28, Reading in the Dark with Foveated Event Vision, https://arxiv.org/pdf/2506.06918, 2025-06-07
2025-11-12 01:00:56,447 - INFO - root - Page:2, Index:29, NSD-Imagery: A benchmark dataset for extending fMRI vision decoding methods to mental imagery, https://arxiv.org/pdf/2506.06898, 2025-06-07
2025-11-12 01:00:56,447 - INFO - root - Page:2, Index:30, Continuous-Time SO(3) Forecasting with Savitzky--Golay Neural Controlled Differential Equations, https://arxiv.org/pdf/2506.06780, 2025-06-07
2025-11-12 01:00:56,449 - INFO - root - Page:2, Index:31, Generalized Trajectory Scoring for End-to-end Multimodal Planning, https://arxiv.org/pdf/2506.06664, 2025-06-07
2025-11-12 01:00:56,449 - INFO - root - Page:2, Index:32, EV-LayerSegNet: Self-supervised Motion Segmentation using Event Cameras, https://arxiv.org/pdf/2506.06596, 2025-06-06
2025-11-12 01:00:56,449 - INFO - root - Page:2, Index:33, Vid2Sim: Generalizable, Video-based Reconstruction of Appearance, Geometry and Physics for Mesh-free Simulation, https://arxiv.org/pdf/2506.06440, 2025-06-06
2025-11-12 01:00:56,450 - INFO - root - Page:2, Index:34, FADE: Frequency-Aware Diffusion Model Factorization for Video Editing, https://arxiv.org/pdf/2506.05934, 2025-06-06
2025-11-12 01:00:56,450 - INFO - root - Page:2, Index:35, Unleashing the Potential of Consistency Learning for Detecting and Grounding Multi-Modal Media Manipulation, https://arxiv.org/pdf/2506.05890, 2025-06-06
2025-11-12 01:00:56,450 - INFO - root - Page:2, Index:36, DeformCL: Learning Deformable Centerline Representation for Vessel Extraction in 3D Medical Image, https://arxiv.org/pdf/2506.05820, 2025-06-06
2025-11-12 01:00:56,450 - INFO - root - Page:2, Index:37, NTIRE 2025 Challenge on HR Depth from Images of Specular and Transparent Surfaces, https://arxiv.org/pdf/2506.05815, 2025-06-06
2025-11-12 01:00:56,451 - INFO - root - Page:2, Index:38, GazeNLQ @ Ego4D Natural Language Queries Challenge 2025, https://arxiv.org/pdf/2506.05782, 2025-06-06
2025-11-12 01:00:56,451 - INFO - root - Page:2, Index:39, Robust sensor fusion against on-vehicle sensor staleness, https://arxiv.org/pdf/2506.05780, 2025-06-06
2025-11-12 01:00:56,451 - INFO - root - Page:2, Index:40, Where Is The Ball: 3D Ball Trajectory Estimation From 2D Monocular Tracking, https://arxiv.org/pdf/2506.05763, 2025-06-06
2025-11-12 01:00:56,452 - INFO - root - Page:2, Index:41, VoxelSplat: Dynamic Gaussian Splatting as an Effective Loss for Occupancy and Flow Prediction, https://arxiv.org/pdf/2506.05563, 2025-06-05
2025-11-12 01:00:56,452 - INFO - root - Page:2, Index:42, Gen4D: Synthesizing Humans and Scenes in the Wild, https://arxiv.org/pdf/2506.05397, 2025-06-03
2025-11-12 01:00:56,454 - INFO - root - Page:2, Index:43, Attacking Attention of Foundation Models Disrupts Downstream Tasks, https://arxiv.org/pdf/2506.05394, 2025-09-12
2025-11-12 01:00:56,454 - INFO - root - Page:2, Index:44, FreeTimeGS: Free Gaussian Primitives at Anytime and Anywhere for Dynamic Scene Reconstruction, https://arxiv.org/pdf/2506.05348, 2025-06-06
2025-11-12 01:00:56,454 - INFO - root - Page:2, Index:45, LotusFilter: Fast Diverse Nearest Neighbor Search via a Learned Cutoff Table, https://arxiv.org/pdf/2506.04790, 2025-06-05
2025-11-12 01:00:56,455 - INFO - root - Page:2, Index:46, Towards Holistic Visual Quality Assessment of AI-Generated Videos: A LLM-Based Multi-Dimensional Evaluation Model, https://arxiv.org/pdf/2506.04715, 2025-06-11
2025-11-12 01:00:56,456 - INFO - root - Page:2, Index:47, Gradient Inversion Attacks on Parameter-Efficient Fine-Tuning, https://arxiv.org/pdf/2506.04453, 2025-06-04
2025-11-12 01:00:56,458 - INFO - root - Page:2, Index:48, HMAR: Efficient Hierarchical Masked Auto-Regressive Image Generation, https://arxiv.org/pdf/2506.04421, 2025-06-04
2025-11-12 01:00:56,462 - INFO - root - Page:2, Index:49, Visualizing and Controlling Cortical Responses Using Voxel-Weighted Activation Maximization, https://arxiv.org/pdf/2506.04379, 2025-06-04
2025-11-12 01:00:56,463 - INFO - root - Fetching page 4 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=150
2025-11-12 01:01:06,986 - INFO - root - get_all_titles_from_web 
2025-11-12 01:01:06,988 - INFO - root - Page:3, Index:0, FlexGS: Train Once, Deploy Everywhere with Many-in-One Flexible 3D Gaussian Splatting, https://arxiv.org/pdf/2506.04174, 2025-06-04
2025-11-12 01:01:06,990 - INFO - root - Page:3, Index:1, Multi-view Surface Reconstruction Using Normal and Reflectance Cues, https://arxiv.org/pdf/2506.04115, 2025-06-04
2025-11-12 01:01:06,991 - INFO - root - Page:3, Index:2, Vocabulary-free few-shot learning for Vision-Language Models, https://arxiv.org/pdf/2506.04005, 2025-06-04
2025-11-12 01:01:06,991 - INFO - root - Page:3, Index:3, Learning from Noise: Enhancing DNNs for Event-Based Vision through Controlled Noise Injection, https://arxiv.org/pdf/2506.03918, 2025-06-04
2025-11-12 01:01:06,992 - INFO - root - Page:3, Index:4, Video, How Do Your Tokens Merge?, https://arxiv.org/pdf/2506.03885, 2025-06-04
2025-11-12 01:01:06,992 - INFO - root - Page:3, Index:5, OSGNet @ Ego4D Episodic Memory Challenge 2025, https://arxiv.org/pdf/2506.03710, 2025-06-04
2025-11-12 01:01:06,993 - INFO - root - Page:3, Index:6, AetherVision-Bench: An Open-Vocabulary RGB-Infrared Benchmark for Multi-Angle Segmentation across Aerial and Ground Perspectives, https://arxiv.org/pdf/2506.03709, 2025-06-04
2025-11-12 01:01:06,995 - INFO - root - Page:3, Index:7, OV-COAST: Cost Aggregation with Optimal Transport for Open-Vocabulary Semantic Segmentation, https://arxiv.org/pdf/2506.03706, 2025-06-04
2025-11-12 01:01:06,997 - INFO - root - Page:3, Index:8, Generating 6DoF Object Manipulation Trajectories from Action Description in Egocentric Vision, https://arxiv.org/pdf/2506.03605, 2025-06-04
2025-11-12 01:01:07,001 - INFO - root - Page:3, Index:9, SemNav: A Model-Based Planner for Zero-Shot Object Goal Navigation Using Vision-Foundation Models, https://arxiv.org/pdf/2506.03516, 2025-06-03
2025-11-12 01:01:07,001 - INFO - root - Page:3, Index:10, Heterogeneous Skeleton-Based Action Representation Learning, https://arxiv.org/pdf/2506.03481, 2025-06-03
2025-11-12 01:01:07,003 - INFO - root - Page:3, Index:11, Hybrid Ensemble of Segmentation-Assisted Classification and GBDT for Skin Cancer Detection with Engineered Metadata and Synthetic Lesions from ISIC 2024 Non-Dermoscopic 3D-TBP Images, https://arxiv.org/pdf/2506.03420, 2025-06-03
2025-11-12 01:01:07,003 - INFO - root - Page:3, Index:12, Self-Supervised Spatial Correspondence Across Modalities, https://arxiv.org/pdf/2506.03148, 2025-06-03
2025-11-12 01:01:07,003 - INFO - root - Page:3, Index:13, Dense Match Summarization for Faster Two-view Estimation, https://arxiv.org/pdf/2506.02893, 2025-06-03
2025-11-12 01:01:07,009 - INFO - root - Page:3, Index:14, NTIRE 2025 XGC Quality Assessment Challenge: Methods and Results, https://arxiv.org/pdf/2506.02875, 2025-06-03
2025-11-12 01:01:07,010 - INFO - root - Page:3, Index:15, FreeScene: Mixed Graph Diffusion for 3D Scene Synthesis from Free Prompts, https://arxiv.org/pdf/2506.02781, 2025-06-03
2025-11-12 01:01:07,010 - INFO - root - Page:3, Index:16, Technical Report for Ego4D Long-Term Action Anticipation Challenge 2025, https://arxiv.org/pdf/2506.02550, 2025-06-11
2025-11-12 01:01:07,010 - INFO - root - Page:3, Index:17, Probabilistic Online Event Downsampling, https://arxiv.org/pdf/2506.02547, 2025-09-23
2025-11-12 01:01:07,011 - INFO - root - Page:3, Index:18, Towards In-the-wild 3D Plane Reconstruction from a Single Image, https://arxiv.org/pdf/2506.02493, 2025-06-03
2025-11-12 01:01:07,011 - INFO - root - Page:3, Index:19, Efficient Test-time Adaptive Object Detection via Sensitivity-Guided Pruning, https://arxiv.org/pdf/2506.02462, 2025-06-03
2025-11-12 01:01:07,012 - INFO - root - Page:3, Index:20, EgoVIS@CVPR: PAIR-Net: Enhancing Egocentric Speaker Detection via Pretrained Audio-Visual Fusion and Alignment Loss, https://arxiv.org/pdf/2506.02247, 2025-09-26
2025-11-12 01:01:07,013 - INFO - root - Page:3, Index:21, Diff2Flow: Training Flow Matching Models via Diffusion Model Alignment, https://arxiv.org/pdf/2506.02221, 2025-06-02
2025-11-12 01:01:07,013 - INFO - root - Page:3, Index:22, NTIRE 2025 Challenge on RAW Image Restoration and Super-Resolution, https://arxiv.org/pdf/2506.02197, 2025-06-04
2025-11-12 01:01:07,014 - INFO - root - Page:3, Index:23, RAW Image Reconstruction from RGB on Smartphones. NTIRE 2025 Challenge Report, https://arxiv.org/pdf/2506.01947, 2025-06-02
2025-11-12 01:01:07,017 - INFO - root - Page:3, Index:24, Silence is Golden: Leveraging Adversarial Examples to Nullify Audio Control in LDM-based Talking-Head Generation, https://arxiv.org/pdf/2506.01591, 2025-06-02
2025-11-12 01:01:07,017 - INFO - root - Page:3, Index:25, SAM2-LOVE: Segment Anything Model 2 in Language-aided Audio-Visual Scenes, https://arxiv.org/pdf/2506.01558, 2025-06-02
2025-11-12 01:01:07,017 - INFO - root - Page:3, Index:26, Neural shape reconstruction from multiple views with static pattern projection, https://arxiv.org/pdf/2506.01389, 2025-06-02
2025-11-12 01:01:07,019 - INFO - root - Page:3, Index:27, SAM-I2V: Upgrading SAM to Support Promptable Video Segmentation with Less than 0.2% Training Cost, https://arxiv.org/pdf/2506.01304, 2025-06-02
2025-11-12 01:01:07,019 - INFO - root - Page:3, Index:28, Perceptual Inductive Bias Is What You Need Before Contrastive Learning, https://arxiv.org/pdf/2506.01201, 2025-06-01
2025-11-12 01:01:07,019 - INFO - root - Page:3, Index:29, Test Automation for Interactive Scenarios via Promptable Traffic Simulation, https://arxiv.org/pdf/2506.01199, 2025-06-04
2025-11-12 01:01:07,019 - INFO - root - Page:3, Index:30, GraphPad: Inference-Time 3D Scene Graph Updates for Embodied Question Answering, https://arxiv.org/pdf/2506.01174, 2025-06-01
2025-11-12 01:01:07,019 - INFO - root - Page:3, Index:31, Aligned Contrastive Loss for Long-Tailed Recognition, https://arxiv.org/pdf/2506.01071, 2025-06-01
2025-11-12 01:01:07,019 - INFO - root - Page:3, Index:32, Self-supervised ControlNet with Spatio-Temporal Mamba for Real-world Video Super-resolution, https://arxiv.org/pdf/2506.01037, 2025-06-01
2025-11-12 01:01:07,022 - INFO - root - Page:3, Index:33, ArtiScene: Language-Driven Artistic 3D Scene Generation Through Image Intermediary, https://arxiv.org/pdf/2506.00742, 2025-05-31
2025-11-12 01:01:07,023 - INFO - root - Page:3, Index:34, 3D Gaussian Splat Vulnerabilities, https://arxiv.org/pdf/2506.00280, 2025-05-30
2025-11-12 01:01:07,025 - INFO - root - Page:3, Index:35, EgoVIS@CVPR: What Changed and What Could Have Changed? State-Change Counterfactuals for Procedure-Aware Video Representation Learning, https://arxiv.org/pdf/2506.00101, 2025-09-26
2025-11-12 01:01:07,026 - INFO - root - Page:3, Index:36, CL-LoRA: Continual Low-Rank Adaptation for Rehearsal-Free Class-Incremental Learning, https://arxiv.org/pdf/2505.24816, 2025-05-30
2025-11-12 01:01:07,026 - INFO - root - Page:3, Index:37, PatchDEMUX: A Certifiably Robust Framework for Multi-label Classifiers Against Adversarial Patches, https://arxiv.org/pdf/2505.24703, 2025-05-30
2025-11-12 01:01:07,027 - INFO - root - Page:3, Index:38, Conformal Prediction for Zero-Shot Models, https://arxiv.org/pdf/2505.24693, 2025-05-30
2025-11-12 01:01:07,027 - INFO - root - Page:3, Index:39, Learning reusable concepts across different egocentric video understanding tasks, https://arxiv.org/pdf/2505.24690, 2025-05-30
2025-11-12 01:01:07,027 - INFO - root - Page:3, Index:40, Period-LLM: Extending the Periodic Capability of Multimodal Large Language Model, https://arxiv.org/pdf/2505.24476, 2025-05-30
2025-11-12 01:01:07,028 - INFO - root - Page:3, Index:41, PCIE_Interaction Solution for Ego4D Social Interaction Challenge, https://arxiv.org/pdf/2505.24404, 2025-05-30
2025-11-12 01:01:07,028 - INFO - root - Page:3, Index:42, Leadership Assessment in Pediatric Intensive Care Unit Team Training, https://arxiv.org/pdf/2505.24389, 2025-08-28
2025-11-12 01:01:07,028 - INFO - root - Page:3, Index:43, Interpreting Large Text-to-Image Diffusion Models with Dictionary Learning, https://arxiv.org/pdf/2505.24360, 2025-07-10
2025-11-12 01:01:07,028 - INFO - root - Page:3, Index:44, InteractAnything: Zero-shot Human Object Interaction Synthesis via LLM Feedback and Object Affordance Parsing, https://arxiv.org/pdf/2505.24315, 2025-05-30
2025-11-12 01:01:07,029 - INFO - root - Page:3, Index:45, MaskAdapt: Unsupervised Geometry-Aware Domain Adaptation Using Multimodal Contextual Learning and RGB-Depth Masking, https://arxiv.org/pdf/2505.24026, 2025-05-29
2025-11-12 01:01:07,029 - INFO - root - Page:3, Index:46, Argus: Vision-Centric Reasoning with Grounded Chain-of-Thought, https://arxiv.org/pdf/2505.23766, 2025-05-29
2025-11-12 01:01:07,029 - INFO - root - Page:3, Index:47, Sketch Down the FLOPs: Towards Efficient Networks for Human Sketch, https://arxiv.org/pdf/2505.23763, 2025-05-29
2025-11-12 01:01:07,030 - INFO - root - Page:3, Index:48, Boosting Domain Incremental Learning: Selecting the Optimal Parameters is All You Need, https://arxiv.org/pdf/2505.23744, 2025-05-29
2025-11-12 01:01:07,031 - INFO - root - Page:3, Index:49, DA-VPT: Semantic-Guided Visual Prompt Tuning for Vision Transformers, https://arxiv.org/pdf/2505.23694, 2025-06-01
2025-11-12 01:01:07,031 - INFO - root - Fetching page 5 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=200
2025-11-12 01:01:34,291 - INFO - root - get_all_titles_from_web 
2025-11-12 01:01:34,335 - INFO - root - Page:4, Index:0, Bridging Classical and Modern Computer Vision: PerceptiveNet for Tree Crown Semantic Segmentation, https://arxiv.org/pdf/2505.23597, 2025-05-29
2025-11-12 01:01:34,376 - INFO - root - Page:4, Index:1, Synthetic Generation and Latent Projection Denoising of Rim Lesions in Multiple Sclerosis, https://arxiv.org/pdf/2505.23353, 2025-05-29
2025-11-12 01:01:34,386 - INFO - root - Page:4, Index:2, Wav2Sem: Plug-and-Play Audio Semantic Decoupling for 3D Speech-Driven Facial Animation, https://arxiv.org/pdf/2505.23290, 2025-05-29
2025-11-12 01:01:34,387 - INFO - root - Page:4, Index:3, Proximal Algorithm Unrolling: Flexible and Efficient Reconstruction Networks for Single-Pixel Imaging, https://arxiv.org/pdf/2505.23180, 2025-05-29
2025-11-12 01:01:34,387 - INFO - root - Page:4, Index:4, HMAD: Advancing E2E Driving with Anchored Offset Proposals and Simulation-Supervised Multi-target Scoring, https://arxiv.org/pdf/2505.23129, 2025-05-29
2025-11-12 01:01:34,387 - INFO - root - Page:4, Index:5, URWKV: Unified RWKV Model with Multi-state Perspective for Low-light Image Restoration, https://arxiv.org/pdf/2505.23068, 2025-05-29
2025-11-12 01:01:34,388 - INFO - root - Page:4, Index:6, 4DTAM: Non-Rigid Tracking and Mapping via Dynamic Surface Gaussians, https://arxiv.org/pdf/2505.22859, 2025-05-28
2025-11-12 01:01:34,388 - INFO - root - Page:4, Index:7, A Probabilistic Jump-Diffusion Framework for Open-World Egocentric Activity Recognition, https://arxiv.org/pdf/2505.22858, 2025-05-28
2025-11-12 01:01:34,388 - INFO - root - Page:4, Index:8, PS4PRO: Pixel-to-pixel Supervision for Photorealistic Rendering and Optimization, https://arxiv.org/pdf/2505.22616, 2025-05-28
2025-11-12 01:01:34,389 - INFO - root - Page:4, Index:9, Universal Domain Adaptation for Semantic Segmentation, https://arxiv.org/pdf/2505.22458, 2025-06-05
2025-11-12 01:01:34,389 - INFO - root - Page:4, Index:10, Zero-Shot 3D Visual Grounding from Vision-Language Models, https://arxiv.org/pdf/2505.22429, 2025-05-28
2025-11-12 01:01:34,390 - INFO - root - Page:4, Index:11, RC-AutoCalib: An End-to-End Radar-Camera Automatic Calibration Network, https://arxiv.org/pdf/2505.22427, 2025-05-28
2025-11-12 01:01:34,390 - INFO - root - Page:4, Index:12, Bringing CLIP to the Clinic: Dynamic Soft Labels and Negation-Aware Learning for Medical Analysis, https://arxiv.org/pdf/2505.22079, 2025-05-28
2025-11-12 01:01:34,390 - INFO - root - Page:4, Index:13, Point-to-Region Loss for Semi-Supervised Point-Based Crowd Counting, https://arxiv.org/pdf/2505.21943, 2025-05-27
2025-11-12 01:01:34,391 - INFO - root - Page:4, Index:14, FRAMES-VQA: Benchmarking Fine-Tuning Robustness across Multi-Modal Shifts in Visual Question Answering, https://arxiv.org/pdf/2505.21755, 2025-06-20
2025-11-12 01:01:34,392 - INFO - root - Page:4, Index:15, Knowledge Distillation Approach for SOS Fusion Staging: Towards Fully Automated Skeletal Maturity Assessment, https://arxiv.org/pdf/2505.21561, 2025-05-26
2025-11-12 01:01:34,395 - INFO - root - Page:4, Index:16, Enhancing Vision Transformer Explainability Using Artificial Astrocytes, https://arxiv.org/pdf/2505.21513, 2025-05-20
2025-11-12 01:01:34,396 - INFO - root - Page:4, Index:17, Empowering Vector Graphics with Consistently Arbitrary Viewing and View-dependent Visibility, https://arxiv.org/pdf/2505.21377, 2025-05-27
2025-11-12 01:01:34,397 - INFO - root - Page:4, Index:18, Structure from Collision, https://arxiv.org/pdf/2505.21335, 2025-05-27
2025-11-12 01:01:34,403 - INFO - root - Page:4, Index:19, Boosting Adversarial Transferability via High-Frequency Augmentation and Hierarchical-Gradient Fusion, https://arxiv.org/pdf/2505.21181, 2025-05-27
2025-11-12 01:01:34,403 - INFO - root - Page:4, Index:20, RefAV: Towards Planning-Centric Scenario Mining, https://arxiv.org/pdf/2505.20981, 2025-06-18
2025-11-12 01:01:34,404 - INFO - root - Page:4, Index:21, PMA: Towards Parameter-Efficient Point Cloud Understanding via Point Mamba Adapter, https://arxiv.org/pdf/2505.20941, 2025-05-27
2025-11-12 01:01:34,404 - INFO - root - Page:4, Index:22, HuMoCon: Concept Discovery for Human Motion Understanding, https://arxiv.org/pdf/2505.20920, 2025-05-27
2025-11-12 01:01:34,405 - INFO - root - Page:4, Index:23, Exploring Timeline Control for Facial Motion Generation, https://arxiv.org/pdf/2505.20861, 2025-05-27
2025-11-12 01:01:34,405 - INFO - root - Page:4, Index:24, ConText-CIR: Learning from Concepts in Text for Composed Image Retrieval, https://arxiv.org/pdf/2505.20764, 2025-05-27
2025-11-12 01:01:34,406 - INFO - root - Page:4, Index:25, HCQA-1.5 @ Ego4D EgoSchema Challenge 2025, https://arxiv.org/pdf/2505.20644, 2025-05-26
2025-11-12 01:01:34,406 - INFO - root - Page:4, Index:26, Roboflow100-VL: A Multi-Domain Object Detection Benchmark for Vision-Language Models, https://arxiv.org/pdf/2505.20612, 2025-10-22
2025-11-12 01:01:34,407 - INFO - root - Page:4, Index:27, MotionPro: A Precise Motion Controller for Image-to-Video Generation, https://arxiv.org/pdf/2505.20287, 2025-05-26
2025-11-12 01:01:34,408 - INFO - root - Page:4, Index:28, Category-Agnostic Neural Object Rigging, https://arxiv.org/pdf/2505.20283, 2025-05-26
2025-11-12 01:01:34,411 - INFO - root - Page:4, Index:29, Towards Video to Piano Music Generation with Chain-of-Perform Support Benchmarks, https://arxiv.org/pdf/2505.20038, 2025-05-26
2025-11-12 01:01:34,411 - INFO - root - Page:4, Index:30, Can Visual Encoder Learn to See Arrows?, https://arxiv.org/pdf/2505.19944, 2025-05-26
2025-11-12 01:01:34,413 - INFO - root - Page:4, Index:31, GoLF-NRT: Integrating Global Context and Local Geometry for Few-Shot View Synthesis, https://arxiv.org/pdf/2505.19813, 2025-05-26
2025-11-12 01:01:34,414 - INFO - root - Page:4, Index:32, Depth-Guided Bundle Sampling for Efficient Generalizable Neural Radiance Field Reconstruction, https://arxiv.org/pdf/2505.19793, 2025-05-26
2025-11-12 01:01:34,421 - INFO - root - Page:4, Index:33, SuperAD: A Training-free Anomaly Classification and Segmentation Method for CVPR 2025 VAND 3.0 Workshop Challenge Track 1: Adapt & Detect, https://arxiv.org/pdf/2505.19750, 2025-05-27
2025-11-12 01:01:34,422 - INFO - root - Page:4, Index:34, Knowledge-Aligned Counterfactual-Enhancement Diffusion Perception for Unsupervised Cross-Domain Visual Emotion Recognition, https://arxiv.org/pdf/2505.19694, 2025-05-26
2025-11-12 01:01:34,422 - INFO - root - Page:4, Index:35, Rotation-Equivariant Self-Supervised Method in Image Denoising, https://arxiv.org/pdf/2505.19618, 2025-05-26
2025-11-12 01:01:34,423 - INFO - root - Page:4, Index:36, NTIRE 2025 Challenge on Video Quality Enhancement for Video Conferencing: Datasets, Methods and Results, https://arxiv.org/pdf/2505.18988, 2025-05-25
2025-11-12 01:01:34,423 - INFO - root - Page:4, Index:37, Geometry-guided Online 3D Video Synthesis with Multi-View Temporal Consistency, https://arxiv.org/pdf/2505.18932, 2025-05-24
2025-11-12 01:01:34,424 - INFO - root - Page:4, Index:38, Digital Overconsumption and Waste: A Closer Look at the Impacts of Generative AI, https://arxiv.org/pdf/2505.18894, 2025-05-24
2025-11-12 01:01:34,424 - INFO - root - Page:4, Index:39, VISTA: Vision-Language Inference for Training-Free Stock Time-Series Analysis, https://arxiv.org/pdf/2505.18570, 2025-06-11
2025-11-12 01:01:34,425 - INFO - root - Page:4, Index:40, Syn3DTxt: Embedding 3D Cues for Scene Text Generation, https://arxiv.org/pdf/2505.18479, 2025-05-23
2025-11-12 01:01:34,426 - INFO - root - Page:4, Index:41, CTRL-GS: Cascaded Temporal Residue Learning for 4D Gaussian Splatting, https://arxiv.org/pdf/2505.18306, 2025-05-31
2025-11-12 01:01:34,428 - INFO - root - Page:4, Index:42, DualTalk: Dual-Speaker Interaction for 3D Talking Head Conversations, https://arxiv.org/pdf/2505.18096, 2025-05-26
2025-11-12 01:01:34,429 - INFO - root - Page:4, Index:43, SeaLion: Semantic Part-Aware Latent Point Diffusion Models for 3D Generation, https://arxiv.org/pdf/2505.17721, 2025-07-07
2025-11-12 01:01:34,429 - INFO - root - Page:4, Index:44, PoseBH: Prototypical Multi-Dataset Training Beyond Human Pose Estimation, https://arxiv.org/pdf/2505.17475, 2025-05-23
2025-11-12 01:01:34,430 - INFO - root - Page:4, Index:45, Pursuing Temporal-Consistent Video Virtual Try-On via Dynamic Pose Interaction, https://arxiv.org/pdf/2505.16980, 2025-05-22
2025-11-12 01:01:34,439 - INFO - root - Page:4, Index:46, UniPhy: Learning a Unified Constitutive Model for Inverse Physics Simulation, https://arxiv.org/pdf/2505.16971, 2025-05-22
2025-11-12 01:01:34,440 - INFO - root - Page:4, Index:47, Tracking the Flight: Exploring a Computational Framework for Analyzing Escape Responses in Plains Zebra (Equus quagga), https://arxiv.org/pdf/2505.16882, 2025-05-23
2025-11-12 01:01:34,441 - INFO - root - Page:4, Index:48, Semi-Supervised State-Space Model with Dynamic Stacking Filter for Real-World Video Deraining, https://arxiv.org/pdf/2505.16811, 2025-05-22
2025-11-12 01:01:34,442 - INFO - root - Page:4, Index:49, SOLVE: Synergy of Language-Vision and End-to-End Networks for Autonomous Driving, https://arxiv.org/pdf/2505.16805, 2025-05-22
2025-11-12 01:01:34,442 - INFO - root - Fetching page 6 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=250
2025-11-12 01:01:48,600 - INFO - root - get_all_titles_from_web 
2025-11-12 01:01:48,601 - INFO - root - Page:5, Index:0, Four Eyes Are Better Than Two: Harnessing the Collaborative Potential of Large Models via Differentiated Thinking and Complementary Ensembles, https://arxiv.org/pdf/2505.16784, 2025-06-07
2025-11-12 01:01:48,601 - INFO - root - Page:5, Index:1, Single Domain Generalization for Few-Shot Counting via Universal Representation Matching, https://arxiv.org/pdf/2505.16778, 2025-05-22
2025-11-12 01:01:48,602 - INFO - root - Page:5, Index:2, Seeing Far and Clearly: Mitigating Hallucinations in MLLMs with Attention Causal Decoding, https://arxiv.org/pdf/2505.16652, 2025-06-07
2025-11-12 01:01:48,602 - INFO - root - Page:5, Index:3, Sketchy Bounding-box Supervision for 3D Instance Segmentation, https://arxiv.org/pdf/2505.16399, 2025-05-22
2025-11-12 01:01:48,603 - INFO - root - Page:5, Index:4, DeCafNet: Delegate and Conquer for Efficient Temporal Grounding in Long Videos, https://arxiv.org/pdf/2505.16376, 2025-05-22
2025-11-12 01:01:48,603 - INFO - root - Page:5, Index:5, NTIRE 2025 challenge on Text to Image Generation Model Quality Assessment, https://arxiv.org/pdf/2505.16314, 2025-05-22
2025-11-12 01:01:48,603 - INFO - root - Page:5, Index:6, Analyzing Hierarchical Structure in Vision Models with Sparse Autoencoders, https://arxiv.org/pdf/2505.15970, 2025-05-21
2025-11-12 01:01:48,603 - INFO - root - Page:5, Index:7, Efficient Data Driven Mixture-of-Expert Extraction from Trained Networks, https://arxiv.org/pdf/2505.15414, 2025-05-21
2025-11-12 01:01:48,604 - INFO - root - Page:5, Index:8, Mouse Lockbox Dataset: Behavior Recognition for Mice Solving Lockboxes, https://arxiv.org/pdf/2505.15408, 2025-06-17
2025-11-12 01:01:48,604 - INFO - root - Page:5, Index:9, Zero-Shot Gaze-based Volumetric Medical Image Segmentation, https://arxiv.org/pdf/2505.15256, 2025-06-10
2025-11-12 01:01:48,604 - INFO - root - Page:5, Index:10, Dual Precision Quantization for Efficient and Accurate Deep Neural Networks Inference, https://arxiv.org/pdf/2505.14638, 2025-05-20
2025-11-12 01:01:48,605 - INFO - root - Page:5, Index:11, Neural Video Compression with Context Modulation, https://arxiv.org/pdf/2505.14541, 2025-05-20
2025-11-12 01:01:48,606 - INFO - root - Page:5, Index:12, Selective Structured State Space for Multispectral-fused Small Target Detection, https://arxiv.org/pdf/2505.14043, 2025-05-23
2025-11-12 01:01:48,607 - INFO - root - Page:5, Index:13, OmniStyle: Filtering High Quality Style Transfer Data at Scale, https://arxiv.org/pdf/2505.14028, 2025-05-20
2025-11-12 01:01:48,607 - INFO - root - Page:5, Index:14, Domain Adaptation of VLM for Soccer Video Understanding, https://arxiv.org/pdf/2505.13860, 2025-07-07
2025-11-12 01:01:48,608 - INFO - root - Page:5, Index:15, Ground-V: Teaching VLMs to Ground Complex Instructions in Pixels, https://arxiv.org/pdf/2505.13788, 2025-05-19
2025-11-12 01:01:48,608 - INFO - root - Page:5, Index:16, FinePhys: Fine-grained Human Action Generation by Explicitly Incorporating Physical Laws for Effective Skeletal Guidance, https://arxiv.org/pdf/2505.13437, 2025-05-19
2025-11-12 01:01:48,609 - INFO - root - Page:5, Index:17, The Way Up: A Dataset for Hold Usage Detection in Sport Climbing, https://arxiv.org/pdf/2505.12854, 2025-05-19
2025-11-12 01:01:48,609 - INFO - root - Page:5, Index:18, PEER pressure: Model-to-Model Regularization for Single Source Domain Generalization, https://arxiv.org/pdf/2505.12745, 2025-05-19
2025-11-12 01:01:48,610 - INFO - root - Page:5, Index:19, Mamba-Adaptor: State Space Model Adaptor for Visual Recognition, https://arxiv.org/pdf/2505.12685, 2025-05-19
2025-11-12 01:01:48,611 - INFO - root - Page:5, Index:20, Scalable Video-to-Dataset Generation for Cross-Platform Mobile Agents, https://arxiv.org/pdf/2505.12632, 2025-05-18
2025-11-12 01:01:48,611 - INFO - root - Page:5, Index:21, Degradation-Aware Feature Perturbation for All-in-One Image Restoration, https://arxiv.org/pdf/2505.12630, 2025-05-18
2025-11-12 01:01:48,614 - INFO - root - Page:5, Index:22, Guiding Diffusion with Deep Geometric Moments: Balancing Fidelity and Variation, https://arxiv.org/pdf/2505.12486, 2025-05-18
2025-11-12 01:01:48,615 - INFO - root - Page:5, Index:23, Learning to Highlight Audio by Watching Movies, https://arxiv.org/pdf/2505.12154, 2025-05-17
2025-11-12 01:01:48,615 - INFO - root - Page:5, Index:24, Understanding the Capabilities of Molecular Graph Neural Networks in Materials Science Through Multimodal Learning and Physical Context Encoding, https://arxiv.org/pdf/2505.12137, 2025-05-17
2025-11-12 01:01:48,615 - INFO - root - Page:5, Index:25, iSegMan: Interactive Segment-and-Manipulate 3D Gaussians, https://arxiv.org/pdf/2505.11934, 2025-05-17
2025-11-12 01:01:48,617 - INFO - root - Page:5, Index:26, Self-Learning Hyperspectral and Multispectral Image Fusion via Adaptive Residual Guided Subspace Diffusion Model, https://arxiv.org/pdf/2505.11800, 2025-05-16
2025-11-12 01:01:48,617 - INFO - root - Page:5, Index:27, X-Edit: Detecting and Localizing Edits in Images Altered by Text-Guided Diffusion Models, https://arxiv.org/pdf/2505.11753, 2025-05-16
2025-11-12 01:01:48,617 - INFO - root - Page:5, Index:28, MTevent: A Multi-Task Event Camera Dataset for 6D Pose Estimation and Moving Object Detection, https://arxiv.org/pdf/2505.11282, 2025-06-02
2025-11-12 01:01:48,618 - INFO - root - Page:5, Index:29, Imputation-free and Alignment-free: Incomplete Multi-view Clustering Driven by Consensus Semantic Learning, https://arxiv.org/pdf/2505.11182, 2025-05-16
2025-11-12 01:01:48,618 - INFO - root - Page:5, Index:30, MultiLink: Multi-class Structure Recovery via Agglomerative Clustering and Model Selection, https://arxiv.org/pdf/2505.10874, 2025-05-16
2025-11-12 01:01:48,618 - INFO - root - Page:5, Index:31, RefPose: Leveraging Reference Geometric Correspondences for Accurate 6D Pose Estimation of Unseen Objects, https://arxiv.org/pdf/2505.10841, 2025-05-16
2025-11-12 01:01:48,619 - INFO - root - Page:5, Index:32, PosterO: Structuring Layout Trees to Enable Language Models in Generalized Content-Aware Layout Generation, https://arxiv.org/pdf/2505.07843, 2025-05-26
2025-11-12 01:01:48,619 - INFO - root - Page:5, Index:33, Prototype Augmented Hypernetworks for Continual Learning, https://arxiv.org/pdf/2505.07450, 2025-05-16
2025-11-12 01:01:48,619 - INFO - root - Fetching page 7 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=300
2025-11-12 01:02:05,883 - INFO - root - get_all_titles_from_web 
2025-11-12 01:02:05,883 - INFO - root - Page:6, Index:0, Convex Relaxation for Robust Vanishing Point Estimation in Manhattan World, https://arxiv.org/pdf/2505.04788, 2025-06-05
2025-11-12 01:02:05,884 - INFO - root - Page:6, Index:1, S3D: Sketch-Driven 3D Model Generation, https://arxiv.org/pdf/2505.04185, 2025-06-03
2025-11-12 01:02:05,884 - INFO - root - Page:6, Index:2, Generating Synthetic Data via Augmentations for Improved Facial Resemblance in DreamBooth and InstantID, https://arxiv.org/pdf/2505.03557, 2025-07-17
2025-11-12 01:02:05,884 - INFO - root - Page:6, Index:3, CAV-MAE Sync: Improving Contrastive Audio-Visual Mask Autoencoders via Fine-Grained Alignment, https://arxiv.org/pdf/2505.01237, 2025-05-21
2025-11-12 01:02:05,885 - INFO - root - Fetching page 8 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=350
2025-11-12 01:02:15,527 - INFO - root - get_all_titles_from_web 
2025-11-12 01:02:15,527 - INFO - root - Page:7, Index:0, Where's the liability in the Generative Era? Recovery-based Black-Box Detection of AI-Generated Content, https://arxiv.org/pdf/2505.01008, 2025-08-25
2025-11-12 01:02:15,528 - INFO - root - Page:7, Index:1, SpatialLLM: A Compound 3D-Informed Design towards Spatially-Intelligent Large Multimodal Models, https://arxiv.org/pdf/2505.00788, 2025-06-10
2025-11-12 01:02:15,528 - INFO - root - Page:7, Index:2, Prisma: An Open Source Toolkit for Mechanistic Interpretability in Vision and Video, https://arxiv.org/pdf/2504.19475, 2025-06-03
2025-11-12 01:02:15,528 - INFO - root - Page:7, Index:3, SSL4Eco: A Global Seasonal Dataset for Geospatial Foundation Models in Ecology, https://arxiv.org/pdf/2504.18256, 2025-10-20
2025-11-12 01:02:15,529 - INFO - root - Page:7, Index:4, Vision-Language Models Are Not Pragmatically Competent in Referring Expression Generation, https://arxiv.org/pdf/2504.16060, 2025-07-30
2025-11-12 01:02:15,529 - INFO - root - Fetching page 9 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=400
2025-11-12 01:02:32,628 - INFO - root - get_all_titles_from_web 
2025-11-12 01:02:32,628 - INFO - root - Page:8, Index:0, Leveraging Automatic CAD Annotations for Supervised Learning in 3D Scene Understanding, https://arxiv.org/pdf/2504.13580, 2025-05-16
2025-11-12 01:02:32,628 - INFO - root - Page:8, Index:1, CAP-Net: A Unified Network for 6D Pose and Size Estimation of Categorical Articulated Parts from a Single RGB-D Image, https://arxiv.org/pdf/2504.11230, 2025-06-02
2025-11-12 01:02:32,629 - INFO - root - Page:8, Index:2, Video Summarization with Large Language Models, https://arxiv.org/pdf/2504.11199, 2025-06-05
2025-11-12 01:02:32,629 - INFO - root - Page:8, Index:3, R-TPT: Improving Adversarial Robustness of Vision-Language Models through Test-Time Prompt Tuning, https://arxiv.org/pdf/2504.11195, 2025-08-27
2025-11-12 01:02:32,630 - INFO - root - Page:8, Index:4, TerraMesh: A Planetary Mosaic of Multimodal Earth Observation Data, https://arxiv.org/pdf/2504.11172, 2025-08-01
2025-11-12 01:02:32,631 - INFO - root - Page:8, Index:5, Seeing like a Cephalopod: Colour Vision with a Monochrome Event Camera, https://arxiv.org/pdf/2504.10984, 2025-06-06
2025-11-12 01:02:32,631 - INFO - root - Page:8, Index:6, Hearing Anywhere in Any Environment, https://arxiv.org/pdf/2504.10746, 2025-06-04
2025-11-12 01:02:32,632 - INFO - root - Fetching page 10 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=450
2025-11-12 01:02:53,750 - INFO - root - get_all_titles_from_web 
2025-11-12 01:02:53,750 - INFO - root - Page:9, Index:0, Correlative and Discriminative Label Grouping for Multi-Label Visual Prompt Tuning, https://arxiv.org/pdf/2504.09990, 2025-07-09
2025-11-12 01:02:53,751 - INFO - root - Page:9, Index:1, SPICE: A Synergistic, Precise, Iterative, and Customizable Image Editing Workflow, https://arxiv.org/pdf/2504.09697, 2025-10-16
2025-11-12 01:02:53,751 - INFO - root - Page:9, Index:2, Mimic In-Context Learning for Multimodal Tasks, https://arxiv.org/pdf/2504.08851, 2025-05-17
2025-11-12 01:02:53,751 - INFO - root - Page:9, Index:3, Digital Twin Catalog: A Large-Scale Photorealistic 3D Object Digital Twin Dataset, https://arxiv.org/pdf/2504.08541, 2025-05-18
2025-11-12 01:02:53,752 - INFO - root - Page:9, Index:4, MMLA: Multi-Environment, Multi-Species, Low-Altitude Drone Dataset, https://arxiv.org/pdf/2504.07744, 2025-10-22
2025-11-12 01:02:53,752 - INFO - root - Fetching page 11 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=500
2025-11-12 01:03:14,358 - INFO - root - get_all_titles_from_web 
2025-11-12 01:03:14,360 - INFO - root - Page:10, Index:0, PromptHMR: Promptable Human Mesh Recovery, https://arxiv.org/pdf/2504.06397, 2025-05-23
2025-11-12 01:03:14,360 - INFO - root - Page:10, Index:1, SCAM: A Real-World Typographic Robustness Evaluation for Multimodal Foundation Models, https://arxiv.org/pdf/2504.04893, 2025-09-26
2025-11-12 01:03:14,361 - INFO - root - Fetching page 12 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=550
2025-11-12 01:03:22,718 - INFO - root - get_all_titles_from_web 
2025-11-12 01:03:22,719 - INFO - root - Page:11, Index:0, T*: Re-thinking Temporal Search for Long-Form Video Understanding, https://arxiv.org/pdf/2504.02259, 2025-08-24
2025-11-12 01:03:22,719 - INFO - root - Page:11, Index:1, CoMatcher: Multi-View Collaborative Feature Matching, https://arxiv.org/pdf/2504.01872, 2025-08-20
2025-11-12 01:03:22,719 - INFO - root - Page:11, Index:2, Think Small, Act Big: Primitive Prompt Learning for Lifelong Robot Manipulation, https://arxiv.org/pdf/2504.00420, 2025-06-01
2025-11-12 01:03:22,721 - INFO - root - Fetching page 13 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=600
2025-11-12 01:03:30,007 - INFO - root - get_all_titles_from_web 
2025-11-12 01:03:30,007 - INFO - root - Page:12, Index:0, It's a (Blind) Match! Towards Vision-Language Correspondence without Parallel Data, https://arxiv.org/pdf/2503.24129, 2025-05-29
2025-11-12 01:03:30,009 - INFO - root - Page:12, Index:1, ReferDINO-Plus: 2nd Solution for 4th PVUW MeViS Challenge at CVPR 2025, https://arxiv.org/pdf/2503.23509, 2025-05-29
2025-11-12 01:03:30,009 - INFO - root - Page:12, Index:2, A Unified Image-Dense Annotation Generation Model for Underwater Scenes, https://arxiv.org/pdf/2503.21771, 2025-07-27
2025-11-12 01:03:30,009 - INFO - root - Fetching page 14 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=650
2025-11-12 01:03:36,602 - INFO - root - get_all_titles_from_web 
2025-11-12 01:03:36,602 - INFO - root - Page:13, Index:0, Learning Class Prototypes for Unified Sparse Supervised 3D Object Detection, https://arxiv.org/pdf/2503.21099, 2025-06-13
2025-11-12 01:03:36,603 - INFO - root - Page:13, Index:1, LATTE-MV: Learning to Anticipate Table Tennis Hits from Monocular Videos, https://arxiv.org/pdf/2503.20936, 2025-09-01
2025-11-12 01:03:36,604 - INFO - root - Page:13, Index:2, BizGen: Advancing Article-level Visual Text Rendering for Infographics Generation, https://arxiv.org/pdf/2503.20672, 2025-07-02
2025-11-12 01:03:36,604 - INFO - root - Page:13, Index:3, ITA-MDT: Image-Timestep-Adaptive Masked Diffusion Transformer Framework for Image-Based Virtual Try-On, https://arxiv.org/pdf/2503.20418, 2025-06-01
2025-11-12 01:03:36,605 - INFO - root - Page:13, Index:4, Faster Parameter-Efficient Tuning with Token Redundancy Reduction, https://arxiv.org/pdf/2503.20282, 2025-08-26
2025-11-12 01:03:36,605 - INFO - root - Page:13, Index:5, DINeMo: Learning Neural Mesh Models with no 3D Annotations, https://arxiv.org/pdf/2503.20220, 2025-06-09
2025-11-12 01:03:36,605 - INFO - root - Page:13, Index:6, Scaling Vision Pre-Training to 4K Resolution, https://arxiv.org/pdf/2503.19903, 2025-08-03
2025-11-12 01:03:36,606 - INFO - root - Page:13, Index:7, GENIUS: A Generative Framework for Universal Multimodal Search, https://arxiv.org/pdf/2503.19868, 2025-06-05
2025-11-12 01:03:36,606 - INFO - root - Fetching page 15 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=700
2025-11-12 01:03:44,798 - INFO - root - get_all_titles_from_web 
2025-11-12 01:03:44,798 - INFO - root - Page:14, Index:0, Galaxy Walker: Geometry-aware VLMs For Galaxy-scale Understanding, https://arxiv.org/pdf/2503.18578, 2025-05-25
2025-11-12 01:03:44,798 - INFO - root - Page:14, Index:1, LookCloser: Frequency-aware Radiance Field for Tiny-Detail Scene, https://arxiv.org/pdf/2503.18513, 2025-07-29
2025-11-12 01:03:44,798 - INFO - root - Fetching page 16 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=750
2025-11-12 01:03:55,296 - INFO - root - get_all_titles_from_web 
2025-11-12 01:03:55,298 - INFO - root - Page:15, Index:0, LoTUS: Large-Scale Machine Unlearning with a Taste of Uncertainty, https://arxiv.org/pdf/2503.18314, 2025-05-29
2025-11-12 01:03:55,298 - INFO - root - Page:15, Index:1, MammAlps: A multi-view video behavior monitoring dataset of wild mammals in the Swiss Alps, https://arxiv.org/pdf/2503.18223, 2025-06-04
2025-11-12 01:03:55,298 - INFO - root - Page:15, Index:2, Progressive Prompt Detailing for Improved Alignment in Text-to-Image Generative Models, https://arxiv.org/pdf/2503.17794, 2025-05-30
2025-11-12 01:03:55,299 - INFO - root - Page:15, Index:3, CountLLM: Towards Generalizable Repetitive Action Counting via Large Language Model, https://arxiv.org/pdf/2503.17690, 2025-06-29
2025-11-12 01:03:55,299 - INFO - root - Page:15, Index:4, TaoAvatar: Real-Time Lifelike Full-Body Talking Avatars for Augmented Reality via 3D Gaussian Splatting, https://arxiv.org/pdf/2503.17032, 2025-07-23
2025-11-12 01:03:55,299 - INFO - root - Page:15, Index:5, Generalized Few-shot 3D Point Cloud Segmentation with Vision-Language Model, https://arxiv.org/pdf/2503.16282, 2025-05-20
2025-11-12 01:03:55,300 - INFO - root - Fetching page 17 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=800
2025-11-12 01:04:04,906 - INFO - root - get_all_titles_from_web 
2025-11-12 01:04:04,908 - INFO - root - Page:16, Index:0, High Temporal Consistency through Semantic Similarity Propagation in Semi-Supervised Video Semantic Segmentation for Autonomous Flight, https://arxiv.org/pdf/2503.15676, 2025-06-26
2025-11-12 01:04:04,908 - INFO - root - Page:16, Index:1, DPFlow: Adaptive Optical Flow Estimation with a Dual-Pyramid Framework, https://arxiv.org/pdf/2503.14880, 2025-09-29
2025-11-12 01:04:04,908 - INFO - root - Fetching page 18 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=850
2025-11-12 01:04:20,660 - INFO - root - get_all_titles_from_web 
2025-11-12 01:04:20,661 - INFO - root - Page:17, Index:0, From Head to Tail: Towards Balanced Representation in Large Vision-Language Models through Adaptive Data Calibration, https://arxiv.org/pdf/2503.12821, 2025-05-29
2025-11-12 01:04:20,662 - INFO - root - Page:17, Index:1, MambaIC: State Space Models for High-Performance Learned Image Compression, https://arxiv.org/pdf/2503.12461, 2025-08-22
2025-11-12 01:04:20,662 - INFO - root - Page:17, Index:2, Localized Concept Erasure for Text-to-Image Diffusion Models Using Training-Free Gated Low-Rank Adaptation, https://arxiv.org/pdf/2503.12356, 2025-07-09
2025-11-12 01:04:20,662 - INFO - root - Page:17, Index:3, TASTE-Rob: Advancing Video Generation of Task-Oriented Hand-Object Interaction for Generalizable Robotic Manipulation, https://arxiv.org/pdf/2503.11423, 2025-06-05
2025-11-12 01:04:20,662 - INFO - root - Page:17, Index:4, Panopticon: Advancing Any-Sensor Foundation Models for Earth Observation, https://arxiv.org/pdf/2503.10845, 2025-08-01
2025-11-12 01:04:20,663 - INFO - root - Page:17, Index:5, Transformers without Normalization, https://arxiv.org/pdf/2503.10622, 2025-06-14
2025-11-12 01:04:20,663 - INFO - root - Page:17, Index:6, dFLMoE: Decentralized Federated Learning via Mixture of Experts for Medical Data Analysis, https://arxiv.org/pdf/2503.10412, 2025-05-19
2025-11-12 01:04:20,664 - INFO - root - Fetching page 19 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=900
2025-11-12 01:04:30,184 - INFO - root - get_all_titles_from_web 
2025-11-12 01:04:30,184 - INFO - root - Page:18, Index:0, Project-Probe-Aggregate: Efficient Fine-Tuning for Group Robustness, https://arxiv.org/pdf/2503.09487, 2025-08-26
2025-11-12 01:04:30,185 - INFO - root - Page:18, Index:1, VLog: Video-Language Models by Generative Retrieval of Narration Vocabulary, https://arxiv.org/pdf/2503.09402, 2025-06-09
2025-11-12 01:04:30,185 - INFO - root - Fetching page 20 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=950
2025-11-12 01:04:47,022 - INFO - root - get_all_titles_from_web 
2025-11-12 01:04:47,023 - INFO - root - Page:19, Index:0, Escaping Plato's Cave: Towards the Alignment of 3D and Text Latent Spaces, https://arxiv.org/pdf/2503.05283, 2025-06-04
2025-11-12 01:04:47,027 - INFO - root - Page:19, Index:1, FluidNexus: 3D Fluid Reconstruction and Prediction from a Single Video, https://arxiv.org/pdf/2503.04720, 2025-07-09
2025-11-12 01:04:47,028 - INFO - root - Page:19, Index:2, Question-Aware Gaussian Experts for Audio-Visual Question Answering, https://arxiv.org/pdf/2503.04459, 2025-06-11
2025-11-12 01:04:47,029 - INFO - root - Page:19, Index:3, Q-Eval-100K: Evaluating Visual Quality and Alignment Level for Text-to-Vision Content, https://arxiv.org/pdf/2503.02357, 2025-06-15
2025-11-12 01:04:47,030 - INFO - root - Fetching page 21 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=1000
2025-11-12 01:04:56,215 - INFO - root - get_all_titles_from_web 
2025-11-12 01:04:56,216 - INFO - root - Page:20, Index:0, Data Distributional Properties As Inductive Bias for Systematic Generalization, https://arxiv.org/pdf/2502.20499, 2025-06-17
2025-11-12 01:04:56,217 - INFO - root - Page:20, Index:1, Knowledge Bridger: Towards Training-free Missing Modality Completion, https://arxiv.org/pdf/2502.19834, 2025-06-17
2025-11-12 01:04:56,217 - INFO - root - Fetching page 22 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=1050
2025-11-12 01:05:06,127 - INFO - root - get_all_titles_from_web 
2025-11-12 01:05:06,127 - INFO - root - Page:21, Index:0, MALT Diffusion: Memory-Augmented Latent Transformers for Any-Length Video Generation, https://arxiv.org/pdf/2502.12632, 2025-07-08
2025-11-12 01:05:06,127 - INFO - root - Page:21, Index:1, ILIAS: Instance-Level Image retrieval At Scale, https://arxiv.org/pdf/2502.11748, 2025-06-23
2025-11-12 01:05:06,128 - INFO - root - Page:21, Index:2, Distraction is All You Need for Multimodal Large Language Model Jailbreaking, https://arxiv.org/pdf/2502.10794, 2025-06-16
2025-11-12 01:05:06,128 - INFO - root - Page:21, Index:3, Spatial457: A Diagnostic Benchmark for 6D Spatial Reasoning of Large Multimodal Models, https://arxiv.org/pdf/2502.08636, 2025-06-08
2025-11-12 01:05:06,129 - INFO - root - Page:21, Index:4, TRAVEL: Training-Free Retrieval and Alignment for Vision-and-Language Navigation, https://arxiv.org/pdf/2502.07306, 2025-06-09
2025-11-12 01:05:06,129 - INFO - root - Page:21, Index:5, DiTASK: Multi-Task Fine-Tuning with Diffeomorphic Transformations, https://arxiv.org/pdf/2502.06029, 2025-06-01
2025-11-12 01:05:06,129 - INFO - root - Page:21, Index:6, ConceptAttention: Diffusion Transformers Learn Highly Interpretable Features, https://arxiv.org/pdf/2502.04320, 2025-07-01
2025-11-12 01:05:06,130 - INFO - root - Page:21, Index:7, GCE-Pose: Global Context Enhancement for Category-level Object Pose Estimation, https://arxiv.org/pdf/2502.04293, 2025-06-24
2025-11-12 01:05:06,130 - INFO - root - Page:21, Index:8, Calibrated Multi-Preference Optimization for Aligning Diffusion Models, https://arxiv.org/pdf/2502.02588, 2025-09-26
2025-11-12 01:05:06,131 - INFO - root - Page:21, Index:9, Instruct-4DGS: Efficient Dynamic Scene Editing via 4D Gaussian-based Static-Dynamic Separation, https://arxiv.org/pdf/2502.02091, 2025-07-01
2025-11-12 01:05:06,131 - INFO - root - Page:21, Index:10, Low-Resource Video Super-Resolution using Memory, Wavelets, and Deformable Convolutions, https://arxiv.org/pdf/2502.01816, 2025-06-19
2025-11-12 01:05:06,131 - INFO - root - Page:21, Index:11, Bridging Text and Crystal Structures: Literature-driven Contrastive Learning for Materials Science, https://arxiv.org/pdf/2501.12919, 2025-06-18
2025-11-12 01:05:06,132 - INFO - root - Page:21, Index:12, T2ISafety: Benchmark for Assessing Fairness, Toxicity, and Privacy in Image Generation, https://arxiv.org/pdf/2501.12612, 2025-07-25
2025-11-12 01:05:06,134 - INFO - root - Page:21, Index:13, Fine-Grained Image-Text Correspondence with Cost Aggregation for Open-Vocabulary Part Segmentation, https://arxiv.org/pdf/2501.09688, 2025-08-08
2025-11-12 01:05:06,135 - INFO - root - Fetching page 23 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=1100
2025-11-12 01:05:14,972 - INFO - root - get_all_titles_from_web 
2025-11-12 01:05:14,974 - INFO - root - Page:22, Index:0, Bias for Action: Video Implicit Neural Representations with Bias Modulation, https://arxiv.org/pdf/2501.09277, 2025-06-06
2025-11-12 01:05:14,974 - INFO - root - Page:22, Index:1, MonSter++: Unified Stereo Matching, Multi-view Stereo, and Real-time Stereo with Monodepth Priors, https://arxiv.org/pdf/2501.08643, 2025-09-25
2025-11-12 01:05:14,974 - INFO - root - Page:22, Index:2, Go-with-the-Flow: Motion-Controllable Video Diffusion Models Using Real-Time Warped Noise, https://arxiv.org/pdf/2501.08331, 2025-08-06
2025-11-12 01:05:14,974 - INFO - root - Page:22, Index:3, Nonisotropic Gaussian Diffusion for Realistic 3D Human Motion Prediction, https://arxiv.org/pdf/2501.06035, 2025-07-08
2025-11-12 01:05:14,975 - INFO - root - Page:22, Index:4, Discovering Hidden Visual Concepts Beyond Linguistic Input in Infant Learning, https://arxiv.org/pdf/2501.05205, 2025-06-13
2025-11-12 01:05:14,975 - INFO - root - Page:22, Index:5, PERSE: Personalized 3D Generative Avatars from A Single Portrait, https://arxiv.org/pdf/2412.21206, 2025-09-28
2025-11-12 01:05:14,975 - INFO - root - Page:22, Index:6, MaskGaussian: Adaptive 3D Gaussian Representation from Probabilistic Masks, https://arxiv.org/pdf/2412.20522, 2025-06-14
2025-11-12 01:05:14,976 - INFO - root - Page:22, Index:7, SimLTD: Simple Supervised and Semi-Supervised Long-Tailed Object Detection, https://arxiv.org/pdf/2412.20047, 2025-06-09
2025-11-12 01:05:14,976 - INFO - root - Page:22, Index:8, Conditional Balance: Improving Multi-Conditioning Trade-Offs in Image Generation, https://arxiv.org/pdf/2412.19853, 2025-08-03
2025-11-12 01:05:14,976 - INFO - root - Fetching page 24 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=1150
2025-11-12 01:05:23,985 - INFO - root - get_all_titles_from_web 
2025-11-12 01:05:23,985 - INFO - root - Page:23, Index:0, EnergyMoGen: Compositional Human Motion Generation with Energy-Based Diffusion Model in Latent Space, https://arxiv.org/pdf/2412.14706, 2025-06-04
2025-11-12 01:05:23,985 - INFO - root - Page:23, Index:1, DarkIR: Robust Low-Light Image Restoration, https://arxiv.org/pdf/2412.13443, 2025-10-14
2025-11-12 01:05:23,986 - INFO - root - Page:23, Index:2, Real-time Free-view Human Rendering from Sparse-view RGB Videos using Double Unprojected Textures, https://arxiv.org/pdf/2412.13183, 2025-06-20
2025-11-12 01:05:23,986 - INFO - root - Page:23, Index:3, CondiMen: Conditional Multi-Person Mesh Recovery, https://arxiv.org/pdf/2412.13058, 2025-06-04
2025-11-12 01:05:23,986 - INFO - root - Page:23, Index:4, MASt3R-SLAM: Real-Time Dense SLAM with 3D Reconstruction Priors, https://arxiv.org/pdf/2412.12392, 2025-06-02
2025-11-12 01:05:23,986 - INFO - root - Page:23, Index:5, DynamicScaler: Seamless and Scalable Video Generation for Panoramic Scenes, https://arxiv.org/pdf/2412.11100, 2025-10-04
2025-11-12 01:05:23,987 - INFO - root - Page:23, Index:6, SnapGen-V: Generating a Five-Second Video within Five Seconds on a Mobile Device, https://arxiv.org/pdf/2412.10494, 2025-06-09
2025-11-12 01:05:23,987 - INFO - root - Page:23, Index:7, Mr. DETR++: Instructive Multi-Route Training for Detection Transformers with Mixture-of-Experts, https://arxiv.org/pdf/2412.10028, 2025-06-26
2025-11-12 01:05:23,987 - INFO - root - Page:23, Index:8, LinGen: Towards High-Resolution Minute-Length Text-to-Video Generation with Linear Computational Complexity, https://arxiv.org/pdf/2412.09856, 2025-05-24
2025-11-12 01:05:23,988 - INFO - root - Page:23, Index:9, Gaze-LLE: Gaze Target Estimation via Large-Scale Learned Encoders, https://arxiv.org/pdf/2412.09586, 2025-06-03
2025-11-12 01:05:23,988 - INFO - root - Fetching page 25 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=1200
2025-11-12 01:05:44,021 - INFO - root - get_all_titles_from_web 
2025-11-12 01:05:44,021 - INFO - root - Page:24, Index:0, From Slow Bidirectional to Fast Autoregressive Video Diffusion Models, https://arxiv.org/pdf/2412.07772, 2025-09-23
2025-11-12 01:05:44,021 - INFO - root - Page:24, Index:1, Rate-In: Information-Driven Adaptive Dropout Rates for Improved Inference-Time Uncertainty Estimation, https://arxiv.org/pdf/2412.07169, 2025-06-03
2025-11-12 01:05:44,021 - INFO - root - Page:24, Index:2, FIRE: Robust Detection of Diffusion-Generated Images via Frequency-Guided Reconstruction Error, https://arxiv.org/pdf/2412.07140, 2025-11-03
2025-11-12 01:05:44,021 - INFO - root - Page:24, Index:3, Birth and Death of a Rose, https://arxiv.org/pdf/2412.05278, 2025-06-05
2025-11-12 01:05:44,021 - INFO - root - Page:24, Index:4, DualPM: Dual Posed-Canonical Point Maps for 3D Shape and Pose Reconstruction, https://arxiv.org/pdf/2412.04464, 2025-08-14
2025-11-12 01:05:44,021 - INFO - root - Page:24, Index:5, SeeGround: See and Ground for Zero-Shot Open-Vocabulary 3D Visual Grounding, https://arxiv.org/pdf/2412.04383, 2025-05-29
2025-11-12 01:05:44,021 - INFO - root - ------------------------------------------------------------------------------------------------------------------------
2025-11-12 01:05:44,101 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\CVPR 2025\Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness.pdf
2025-11-12 01:05:44,180 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\CVPR 2025\OmniTrack++_ Omnidirectional Multi-Object Tracking by Learning Large-FoV Traject.pdf
2025-11-12 01:10:36,425 - INFO - root - 跳过已处理论文 Learning to Seek Evidence: A Verifiable Reasoning Agent with Causal Faithfulness Analysis：d:\ChatPaper\academic Papers\CVPR 2025\Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness.pdf
2025-11-12 01:10:36,426 - INFO - root - 正在总结论文 2/30: OmniTrack++: Omnidirectional Multi-Object Tracking by Learning Large-FoV Trajectory Feedback
2025-11-12 01:13:39,644 - INFO - root - 正在提取论文图片到目录: ./export\CVPR 2026\images
2025-11-12 01:13:40,348 - INFO - root - 已保存图片 1/10：./export\CVPR 2026\images\figure_1_page13.jpeg
2025-11-12 01:13:40,421 - INFO - root - 已保存图片 2/10：./export\CVPR 2026\images\figure_2_page13.jpeg
2025-11-12 01:13:40,493 - INFO - root - 已保存图片 3/10：./export\CVPR 2026\images\figure_3_page13.jpeg
2025-11-12 01:13:40,562 - INFO - root - 已保存图片 4/10：./export\CVPR 2026\images\figure_4_page2.jpeg
2025-11-12 01:13:40,633 - INFO - root - 已保存图片 5/10：./export\CVPR 2026\images\figure_5_page5.png
2025-11-12 01:13:40,667 - INFO - root - 已保存图片 6/10：./export\CVPR 2026\images\figure_6_page13.jpeg
2025-11-12 01:13:40,713 - INFO - root - 已保存图片 7/10：./export\CVPR 2026\images\figure_7_page2.jpeg
2025-11-12 01:13:40,751 - INFO - root - 已保存图片 8/10：./export\CVPR 2026\images\figure_8_page8.jpeg
2025-11-12 01:13:40,767 - INFO - root - 已保存图片 9/10：./export\CVPR 2026\images\figure_9_page1.jpeg
2025-11-12 01:13:40,788 - INFO - root - 已保存图片 10/10：./export\CVPR 2026\images\figure_10_page1.png
2025-11-12 01:13:40,797 - INFO - root - 成功添加图片 1：./export\CVPR 2026\images\figure_1_page13.jpeg
2025-11-12 01:13:40,797 - INFO - root - 成功添加图片 2：./export\CVPR 2026\images\figure_2_page13.jpeg
2025-11-12 01:13:40,799 - INFO - root - 成功添加图片 3：./export\CVPR 2026\images\figure_3_page13.jpeg
2025-11-12 01:13:40,799 - INFO - root - 成功添加图片 4：./export\CVPR 2026\images\figure_4_page2.jpeg
2025-11-12 01:13:40,800 - INFO - root - 成功添加图片 5：./export\CVPR 2026\images\figure_5_page5.png
2025-11-12 01:13:40,800 - INFO - root - 成功添加图片 6：./export\CVPR 2026\images\figure_6_page13.jpeg
2025-11-12 01:13:40,800 - INFO - root - 成功添加图片 7：./export\CVPR 2026\images\figure_7_page2.jpeg
2025-11-12 01:13:40,801 - INFO - root - 成功添加图片 8：./export\CVPR 2026\images\figure_8_page8.jpeg
2025-11-12 01:13:40,801 - INFO - root - 成功添加图片 9：./export\CVPR 2026\images\figure_9_page1.jpeg
2025-11-12 01:13:40,801 - INFO - root - 成功添加图片 10：./export\CVPR 2026\images\figure_10_page1.png
2025-11-12 01:13:40,803 - INFO - root - 已更新图片链接
2025-11-12 01:13:40,807 - INFO - root - 论文《OmniTrack++: Omnidirectional Multi-Object Tracking by Learning Large-FoV Trajectory Feedback》的分析已保存到 ./export\CVPR 2026\OmniTrack++_ Omnidirectional Multi-Object Tracking by Learning Large-FoV Traject.md
2025-11-12 01:13:40,812 - INFO - root - 正在总结论文 3/30: NeuCo-Bench: A Novel Benchmark Framework for Neural Embeddings in Earth Observation
2025-11-12 01:13:54,665 - INFO - root - LLMClient: rate limit reached, sleeping 22.7s
2025-11-12 01:15:25,838 - INFO - root - 正在提取论文图片到目录: ./export\CVPR 2026\images
2025-11-12 01:15:27,884 - INFO - root - 已保存图片 1/10：./export\CVPR 2026\images\figure_1_page30.png
2025-11-12 01:15:28,085 - INFO - root - 已保存图片 2/10：./export\CVPR 2026\images\figure_2_page33.png
2025-11-12 01:15:28,288 - INFO - root - 已保存图片 3/10：./export\CVPR 2026\images\figure_3_page33.png
2025-11-12 01:15:28,483 - INFO - root - 已保存图片 4/10：./export\CVPR 2026\images\figure_4_page30.jpeg
2025-11-12 01:15:28,753 - INFO - root - 已保存图片 5/10：./export\CVPR 2026\images\figure_5_page24.png
2025-11-12 01:15:29,237 - INFO - root - 已保存图片 6/10：./export\CVPR 2026\images\figure_6_page34.png
2025-11-12 01:15:29,535 - INFO - root - 已保存图片 7/10：./export\CVPR 2026\images\figure_7_page32.png
2025-11-12 01:15:29,742 - INFO - root - 已保存图片 8/10：./export\CVPR 2026\images\figure_8_page29.jpeg
2025-11-12 01:15:29,927 - INFO - root - 已保存图片 9/10：./export\CVPR 2026\images\figure_9_page29.jpeg
2025-11-12 01:15:30,109 - INFO - root - 已保存图片 10/10：./export\CVPR 2026\images\figure_10_page29.jpeg
2025-11-12 01:15:30,174 - INFO - root - 成功添加图片 1：./export\CVPR 2026\images\figure_1_page30.png
2025-11-12 01:15:30,233 - INFO - root - 成功添加图片 2：./export\CVPR 2026\images\figure_2_page33.png
2025-11-12 01:15:30,271 - INFO - root - 成功添加图片 3：./export\CVPR 2026\images\figure_3_page33.png
2025-11-12 01:15:30,279 - INFO - root - 成功添加图片 4：./export\CVPR 2026\images\figure_4_page30.jpeg
2025-11-12 01:15:30,281 - INFO - root - 成功添加图片 5：./export\CVPR 2026\images\figure_5_page24.png
2025-11-12 01:15:30,282 - INFO - root - 成功添加图片 6：./export\CVPR 2026\images\figure_6_page34.png
2025-11-12 01:15:30,290 - INFO - root - 成功添加图片 7：./export\CVPR 2026\images\figure_7_page32.png
2025-11-12 01:15:30,297 - INFO - root - 成功添加图片 8：./export\CVPR 2026\images\figure_8_page29.jpeg
2025-11-12 01:15:30,304 - INFO - root - 成功添加图片 9：./export\CVPR 2026\images\figure_9_page29.jpeg
2025-11-12 01:15:30,309 - INFO - root - 成功添加图片 10：./export\CVPR 2026\images\figure_10_page29.jpeg
2025-11-12 01:15:30,312 - INFO - root - 已更新图片链接
2025-11-12 01:15:30,324 - INFO - root - 论文《NeuCo-Bench: A Novel Benchmark Framework for Neural Embeddings in Earth Observation》的分析已保存到 ./export\CVPR 2026\NeuCo-Bench_ A Novel Benchmark Framework for Neural Embeddings in Earth Observat.md
2025-11-12 01:15:30,327 - INFO - root - 正在总结论文 4/30: NTIRE 2025 Challenge on Low Light Image Enhancement: Methods and Results
2025-11-12 01:15:42,357 - INFO - root - LLMClient: rate limit reached, sleeping 10.6s
2025-11-12 01:17:26,438 - INFO - root - 正在提取论文图片到目录: ./export\CVPR 2026\images
2025-11-12 01:17:31,703 - INFO - root - 已保存图片 1/10：./export\CVPR 2026\images\figure_1_page16.png
2025-11-12 01:17:32,180 - INFO - root - 已保存图片 2/10：./export\CVPR 2026\images\figure_2_page17.jpeg
2025-11-12 01:17:32,332 - INFO - root - 已保存图片 3/10：./export\CVPR 2026\images\figure_3_page16.png
2025-11-12 01:17:32,464 - INFO - root - 已保存图片 4/10：./export\CVPR 2026\images\figure_4_page17.png
2025-11-12 01:17:32,571 - INFO - root - 已保存图片 5/10：./export\CVPR 2026\images\figure_5_page16.png
2025-11-12 01:17:32,687 - INFO - root - 已保存图片 6/10：./export\CVPR 2026\images\figure_6_page18.png
2025-11-12 01:17:32,815 - INFO - root - 已保存图片 7/10：./export\CVPR 2026\images\figure_7_page18.png
2025-11-12 01:17:32,916 - INFO - root - 已保存图片 8/10：./export\CVPR 2026\images\figure_8_page18.png
2025-11-12 01:17:33,013 - INFO - root - 已保存图片 9/10：./export\CVPR 2026\images\figure_9_page17.png
2025-11-12 01:17:33,099 - INFO - root - 已保存图片 10/10：./export\CVPR 2026\images\figure_10_page15.jpeg
2025-11-12 01:17:33,150 - INFO - root - 成功添加图片 1：./export\CVPR 2026\images\figure_1_page16.png
2025-11-12 01:17:33,151 - INFO - root - 成功添加图片 2：./export\CVPR 2026\images\figure_2_page17.jpeg
2025-11-12 01:17:33,155 - INFO - root - 成功添加图片 3：./export\CVPR 2026\images\figure_3_page16.png
2025-11-12 01:17:33,156 - INFO - root - 成功添加图片 4：./export\CVPR 2026\images\figure_4_page17.png
2025-11-12 01:17:33,159 - INFO - root - 成功添加图片 5：./export\CVPR 2026\images\figure_5_page16.png
2025-11-12 01:17:33,161 - INFO - root - 成功添加图片 6：./export\CVPR 2026\images\figure_6_page18.png
2025-11-12 01:17:33,163 - INFO - root - 成功添加图片 7：./export\CVPR 2026\images\figure_7_page18.png
2025-11-12 01:17:33,164 - INFO - root - 成功添加图片 8：./export\CVPR 2026\images\figure_8_page18.png
2025-11-12 01:17:33,166 - INFO - root - 成功添加图片 9：./export\CVPR 2026\images\figure_9_page17.png
2025-11-12 01:17:33,166 - INFO - root - 成功添加图片 10：./export\CVPR 2026\images\figure_10_page15.jpeg
2025-11-12 01:17:33,169 - INFO - root - 已更新图片链接
2025-11-12 01:17:33,178 - INFO - root - 论文《NTIRE 2025 Challenge on Low Light Image Enhancement: Methods and Results》的分析已保存到 ./export\CVPR 2026\NTIRE 2025 Challenge on Low Light Image Enhancement_ Methods and Results.md
2025-11-12 01:17:33,182 - INFO - root - 正在总结论文 5/30: Class Prototypes based Contrastive Learning for Classifying Multi-Label and Fine-Grained Educational Videos
2025-11-12 01:18:17,142 - INFO - root - LLMClient: rate limit reached, sleeping 16.0s
2025-11-12 01:18:55,908 - INFO - root - 正在提取论文图片到目录: ./export\CVPR 2026\images
2025-11-12 01:18:56,145 - INFO - root - 已保存图片 1/10：./export\CVPR 2026\images\figure_1_page12.png
2025-11-12 01:18:56,186 - INFO - root - 已保存图片 2/10：./export\CVPR 2026\images\figure_2_page3.jpeg
2025-11-12 01:18:56,224 - INFO - root - 已保存图片 3/10：./export\CVPR 2026\images\figure_3_page3.jpeg
2025-11-12 01:18:56,268 - INFO - root - 已保存图片 4/10：./export\CVPR 2026\images\figure_4_page3.jpeg
2025-11-12 01:18:56,317 - INFO - root - 已保存图片 5/10：./export\CVPR 2026\images\figure_5_page10.jpeg
2025-11-12 01:18:56,359 - INFO - root - 已保存图片 6/10：./export\CVPR 2026\images\figure_6_page10.jpeg
2025-11-12 01:18:56,413 - INFO - root - 已保存图片 7/10：./export\CVPR 2026\images\figure_7_page10.jpeg
2025-11-12 01:18:56,460 - INFO - root - 已保存图片 8/10：./export\CVPR 2026\images\figure_8_page10.jpeg
2025-11-12 01:18:56,510 - INFO - root - 已保存图片 9/10：./export\CVPR 2026\images\figure_9_page10.jpeg
2025-11-12 01:18:56,556 - INFO - root - 已保存图片 10/10：./export\CVPR 2026\images\figure_10_page10.jpeg
2025-11-12 01:18:56,561 - INFO - root - 成功添加图片 1：./export\CVPR 2026\images\figure_1_page12.png
2025-11-12 01:18:56,562 - INFO - root - 成功添加图片 2：./export\CVPR 2026\images\figure_2_page3.jpeg
2025-11-12 01:18:56,562 - INFO - root - 成功添加图片 3：./export\CVPR 2026\images\figure_3_page3.jpeg
2025-11-12 01:18:56,564 - INFO - root - 成功添加图片 4：./export\CVPR 2026\images\figure_4_page3.jpeg
2025-11-12 01:18:56,565 - INFO - root - 成功添加图片 5：./export\CVPR 2026\images\figure_5_page10.jpeg
2025-11-12 01:18:56,565 - INFO - root - 成功添加图片 6：./export\CVPR 2026\images\figure_6_page10.jpeg
2025-11-12 01:18:56,565 - INFO - root - 成功添加图片 7：./export\CVPR 2026\images\figure_7_page10.jpeg
2025-11-12 01:18:56,566 - INFO - root - 成功添加图片 8：./export\CVPR 2026\images\figure_8_page10.jpeg
2025-11-12 01:18:56,566 - INFO - root - 成功添加图片 9：./export\CVPR 2026\images\figure_9_page10.jpeg
2025-11-12 01:18:56,566 - INFO - root - 成功添加图片 10：./export\CVPR 2026\images\figure_10_page10.jpeg
2025-11-12 01:18:56,569 - INFO - root - 已更新图片链接
2025-11-12 01:18:56,572 - INFO - root - 论文《Class Prototypes based Contrastive Learning for Classifying Multi-Label and Fine-Grained Educational Videos》的分析已保存到 ./export\CVPR 2026\Class Prototypes based Contrastive Learning for Classifying Multi-Label and Fine.md
2025-11-12 01:18:56,576 - INFO - root - 正在总结论文 6/30: MIMO: A medical vision language model with visual referring multimodal input and pixel grounding multimodal output
2025-11-12 01:19:12,657 - INFO - root - LLMClient: rate limit reached, sleeping 20.5s
2025-11-12 01:21:28,398 - INFO - root - 正在提取论文图片到目录: ./export\CVPR 2026\images
2025-11-12 01:21:40,084 - INFO - root - 已保存图片 1/10：./export\CVPR 2026\images\figure_1_page20.png
2025-11-12 01:21:40,679 - INFO - root - 已保存图片 2/10：./export\CVPR 2026\images\figure_2_page21.png
2025-11-12 01:21:41,358 - INFO - root - 已保存图片 3/10：./export\CVPR 2026\images\figure_3_page22.png
2025-11-12 01:21:41,837 - INFO - root - 已保存图片 4/10：./export\CVPR 2026\images\figure_4_page19.png
2025-11-12 01:21:42,284 - INFO - root - 已保存图片 5/10：./export\CVPR 2026\images\figure_5_page19.png
2025-11-12 01:21:42,350 - INFO - root - 已保存图片 6/10：./export\CVPR 2026\images\figure_6_page1.jpeg
2025-11-12 01:21:42,420 - INFO - root - 已保存图片 7/10：./export\CVPR 2026\images\figure_7_page1.jpeg
2025-11-12 01:21:42,492 - INFO - root - 已保存图片 8/10：./export\CVPR 2026\images\figure_8_page3.jpeg
2025-11-12 01:21:42,565 - INFO - root - 已保存图片 9/10：./export\CVPR 2026\images\figure_9_page3.jpeg
2025-11-12 01:21:42,889 - INFO - root - 已保存图片 10/10：./export\CVPR 2026\images\figure_10_page24.png
2025-11-12 01:21:42,977 - INFO - root - 成功添加图片 1：./export\CVPR 2026\images\figure_1_page20.png
2025-11-12 01:21:42,977 - INFO - root - 成功添加图片 2：./export\CVPR 2026\images\figure_2_page21.png
2025-11-12 01:21:42,977 - INFO - root - 成功添加图片 3：./export\CVPR 2026\images\figure_3_page22.png
2025-11-12 01:21:42,978 - INFO - root - 成功添加图片 4：./export\CVPR 2026\images\figure_4_page19.png
2025-11-12 01:21:42,978 - INFO - root - 成功添加图片 5：./export\CVPR 2026\images\figure_5_page19.png
2025-11-12 01:21:42,978 - INFO - root - 成功添加图片 6：./export\CVPR 2026\images\figure_6_page1.jpeg
2025-11-12 01:21:42,979 - INFO - root - 成功添加图片 7：./export\CVPR 2026\images\figure_7_page1.jpeg
2025-11-12 01:21:42,979 - INFO - root - 成功添加图片 8：./export\CVPR 2026\images\figure_8_page3.jpeg
2025-11-12 01:21:42,980 - INFO - root - 成功添加图片 9：./export\CVPR 2026\images\figure_9_page3.jpeg
2025-11-12 01:21:42,980 - INFO - root - 成功添加图片 10：./export\CVPR 2026\images\figure_10_page24.png
2025-11-12 01:21:42,983 - INFO - root - 已更新图片链接
2025-11-12 01:21:42,994 - INFO - root - 论文《MIMO: A medical vision language model with visual referring multimodal input and pixel grounding multimodal output》的分析已保存到 ./export\CVPR 2026\MIMO_ A medical vision language model with visual referring multimodal input and.md
2025-11-12 01:21:42,996 - INFO - root - 正在总结论文 7/30: Vision Language Models: A Survey of 26K Papers
2025-11-12 01:22:28,543 - INFO - root - LLMClient: rate limit reached, sleeping 14.5s
2025-11-12 01:23:09,599 - INFO - root - 正在提取论文图片到目录: ./export\CVPR 2026\images
2025-11-12 01:23:10,421 - INFO - root - 已保存图片 1/10：./export\CVPR 2026\images\figure_1_page2.png
2025-11-12 01:23:10,525 - INFO - root - 已保存图片 2/10：./export\CVPR 2026\images\figure_2_page5.png
2025-11-12 01:23:10,660 - INFO - root - 已保存图片 3/10：./export\CVPR 2026\images\figure_3_page3.png
2025-11-12 01:23:10,668 - INFO - root - 成功添加图片 1：./export\CVPR 2026\images\figure_1_page2.png
2025-11-12 01:23:10,675 - INFO - root - 成功添加图片 2：./export\CVPR 2026\images\figure_2_page5.png
2025-11-12 01:23:10,675 - INFO - root - 成功添加图片 3：./export\CVPR 2026\images\figure_3_page3.png
2025-11-12 01:23:10,682 - INFO - root - 已更新图片链接
2025-11-12 01:23:10,684 - INFO - root - 论文《Vision Language Models: A Survey of 26K Papers》的分析已保存到 ./export\CVPR 2026\Vision Language Models_ A Survey of 26K Papers.md
2025-11-12 01:23:10,685 - INFO - root - 正在总结论文 8/30: DiT-VTON: Diffusion Transformer Framework for Unified Multi-Category Virtual Try-On and Virtual Try-All with Integrated Image Editing
2025-11-12 01:23:30,488 - INFO - root - LLMClient: rate limit reached, sleeping 12.5s
2025-11-12 01:24:59,115 - INFO - root - 正在提取论文图片到目录: ./export\CVPR 2026\images
2025-11-12 01:25:20,361 - INFO - root - 已保存图片 1/10：./export\CVPR 2026\images\figure_1_page13.png
2025-11-12 01:25:20,888 - INFO - root - 已保存图片 2/10：./export\CVPR 2026\images\figure_2_page12.png
2025-11-12 01:25:21,273 - INFO - root - 已保存图片 3/10：./export\CVPR 2026\images\figure_3_page19.png
2025-11-12 01:25:21,637 - INFO - root - 已保存图片 4/10：./export\CVPR 2026\images\figure_4_page2.png
2025-11-12 01:25:22,034 - INFO - root - 已保存图片 5/10：./export\CVPR 2026\images\figure_5_page8.png
2025-11-12 01:25:22,423 - INFO - root - 已保存图片 6/10：./export\CVPR 2026\images\figure_6_page17.png
2025-11-12 01:25:22,690 - INFO - root - 已保存图片 7/10：./export\CVPR 2026\images\figure_7_page6.png
2025-11-12 01:25:23,253 - INFO - root - 已保存图片 8/10：./export\CVPR 2026\images\figure_8_page17.png
2025-11-12 01:25:23,970 - INFO - root - 已保存图片 9/10：./export\CVPR 2026\images\figure_9_page15.png
2025-11-12 01:25:24,889 - INFO - root - 已保存图片 10/10：./export\CVPR 2026\images\figure_10_page14.png
2025-11-12 01:25:24,948 - INFO - root - 成功添加图片 1：./export\CVPR 2026\images\figure_1_page13.png
2025-11-12 01:25:24,950 - INFO - root - 成功添加图片 2：./export\CVPR 2026\images\figure_2_page12.png
2025-11-12 01:25:24,950 - INFO - root - 成功添加图片 3：./export\CVPR 2026\images\figure_3_page19.png
2025-11-12 01:25:24,950 - INFO - root - 成功添加图片 4：./export\CVPR 2026\images\figure_4_page2.png
2025-11-12 01:25:24,951 - INFO - root - 成功添加图片 5：./export\CVPR 2026\images\figure_5_page8.png
2025-11-12 01:25:24,951 - INFO - root - 成功添加图片 6：./export\CVPR 2026\images\figure_6_page17.png
2025-11-12 01:25:24,952 - INFO - root - 成功添加图片 7：./export\CVPR 2026\images\figure_7_page6.png
2025-11-12 01:25:24,952 - INFO - root - 成功添加图片 8：./export\CVPR 2026\images\figure_8_page17.png
2025-11-12 01:25:24,952 - INFO - root - 成功添加图片 9：./export\CVPR 2026\images\figure_9_page15.png
2025-11-12 01:25:24,953 - INFO - root - 成功添加图片 10：./export\CVPR 2026\images\figure_10_page14.png
2025-11-12 01:25:24,956 - INFO - root - 已更新图片链接
2025-11-12 01:25:24,958 - INFO - root - 论文《DiT-VTON: Diffusion Transformer Framework for Unified Multi-Category Virtual Try-On and Virtual Try-All with Integrated Image Editing》的分析已保存到 ./export\CVPR 2026\DiT-VTON_ Diffusion Transformer Framework for Unified Multi-Category Virtual Try.md
2025-11-12 01:25:24,965 - INFO - root - 正在总结论文 9/30: PatchVSR: Breaking Video Diffusion Resolution Limits with Patch-wise Video Super-Resolution
2025-11-12 01:26:07,696 - INFO - root - LLMClient: rate limit reached, sleeping 17.3s
2025-11-12 01:26:53,868 - INFO - root - 正在提取论文图片到目录: ./export\CVPR 2026\images
2025-11-12 01:26:55,346 - INFO - root - 已保存图片 1/10：./export\CVPR 2026\images\figure_1_page16.jpeg
2025-11-12 01:26:56,028 - INFO - root - 已保存图片 2/10：./export\CVPR 2026\images\figure_2_page16.jpeg
2025-11-12 01:26:57,662 - INFO - root - 已保存图片 3/10：./export\CVPR 2026\images\figure_3_page16.jpeg
2025-11-12 01:26:58,069 - INFO - root - 已保存图片 4/10：./export\CVPR 2026\images\figure_4_page16.jpeg
2025-11-12 01:26:58,915 - INFO - root - 已保存图片 5/10：./export\CVPR 2026\images\figure_5_page15.jpeg
2025-11-12 01:26:59,915 - INFO - root - 已保存图片 6/10：./export\CVPR 2026\images\figure_6_page15.jpeg
2025-11-12 01:27:00,972 - INFO - root - 已保存图片 7/10：./export\CVPR 2026\images\figure_7_page5.jpeg
2025-11-12 01:27:01,914 - INFO - root - 已保存图片 8/10：./export\CVPR 2026\images\figure_8_page5.jpeg
2025-11-12 01:27:03,170 - INFO - root - 已保存图片 9/10：./export\CVPR 2026\images\figure_9_page17.jpeg
2025-11-12 01:27:04,172 - INFO - root - 已保存图片 10/10：./export\CVPR 2026\images\figure_10_page14.jpeg
2025-11-12 01:27:04,337 - INFO - root - 成功添加图片 1：./export\CVPR 2026\images\figure_1_page16.jpeg
2025-11-12 01:27:04,411 - INFO - root - 成功添加图片 2：./export\CVPR 2026\images\figure_2_page16.jpeg
2025-11-12 01:27:04,534 - INFO - root - 成功添加图片 3：./export\CVPR 2026\images\figure_3_page16.jpeg
2025-11-12 01:27:04,624 - INFO - root - 成功添加图片 4：./export\CVPR 2026\images\figure_4_page16.jpeg
2025-11-12 01:27:04,739 - INFO - root - 成功添加图片 5：./export\CVPR 2026\images\figure_5_page15.jpeg
2025-11-12 01:27:04,970 - INFO - root - 成功添加图片 6：./export\CVPR 2026\images\figure_6_page15.jpeg
2025-11-12 01:27:05,072 - INFO - root - 成功添加图片 7：./export\CVPR 2026\images\figure_7_page5.jpeg
2025-11-12 01:27:05,211 - INFO - root - 成功添加图片 8：./export\CVPR 2026\images\figure_8_page5.jpeg
2025-11-12 01:27:05,326 - INFO - root - 成功添加图片 9：./export\CVPR 2026\images\figure_9_page17.jpeg
2025-11-12 01:27:05,423 - INFO - root - 成功添加图片 10：./export\CVPR 2026\images\figure_10_page14.jpeg
2025-11-12 01:27:05,559 - INFO - root - 已更新图片链接
2025-11-12 01:27:05,705 - INFO - root - 论文《PatchVSR: Breaking Video Diffusion Resolution Limits with Patch-wise Video Super-Resolution》的分析已保存到 ./export\CVPR 2026\PatchVSR_ Breaking Video Diffusion Resolution Limits with Patch-wise Video Super.md
2025-11-12 01:27:05,710 - INFO - root - 正在总结论文 10/30: FreqDebias: Towards Generalizable Deepfake Detection via Consistency-Driven Frequency Debiasing
2025-11-12 01:27:17,136 - INFO - root - LLMClient: rate limit reached, sleeping 7.8s
2025-11-12 01:27:58,628 - INFO - root - LLMClient: rate limit reached, sleeping 7.1s
2025-11-12 01:28:45,120 - INFO - root - 正在提取论文图片到目录: ./export\CVPR 2026\images
2025-11-12 01:28:48,932 - INFO - root - 已保存图片 1/10：./export\CVPR 2026\images\figure_1_page8.png
2025-11-12 01:28:49,482 - INFO - root - 已保存图片 2/10：./export\CVPR 2026\images\figure_2_page8.png
2025-11-12 01:28:50,078 - INFO - root - 已保存图片 3/10：./export\CVPR 2026\images\figure_3_page8.png
2025-11-12 01:28:51,074 - INFO - root - 已保存图片 4/10：./export\CVPR 2026\images\figure_4_page4.png
2025-11-12 01:28:52,253 - INFO - root - 已保存图片 5/10：./export\CVPR 2026\images\figure_5_page8.png
2025-11-12 01:28:53,486 - INFO - root - 已保存图片 6/10：./export\CVPR 2026\images\figure_6_page8.png
2025-11-12 01:28:54,783 - INFO - root - 已保存图片 7/10：./export\CVPR 2026\images\figure_7_page8.png
2025-11-12 01:28:55,660 - INFO - root - 已保存图片 8/10：./export\CVPR 2026\images\figure_8_page8.png
2025-11-12 01:28:56,264 - INFO - root - 已保存图片 9/10：./export\CVPR 2026\images\figure_9_page8.png
2025-11-12 01:28:56,707 - INFO - root - 已保存图片 10/10：./export\CVPR 2026\images\figure_10_page8.png
2025-11-12 01:28:56,763 - INFO - root - 成功添加图片 1：./export\CVPR 2026\images\figure_1_page8.png
2025-11-12 01:28:56,779 - INFO - root - 成功添加图片 2：./export\CVPR 2026\images\figure_2_page8.png
2025-11-12 01:28:56,785 - INFO - root - 成功添加图片 3：./export\CVPR 2026\images\figure_3_page8.png
2025-11-12 01:28:56,796 - INFO - root - 成功添加图片 4：./export\CVPR 2026\images\figure_4_page4.png
2025-11-12 01:28:56,802 - INFO - root - 成功添加图片 5：./export\CVPR 2026\images\figure_5_page8.png
2025-11-12 01:28:56,815 - INFO - root - 成功添加图片 6：./export\CVPR 2026\images\figure_6_page8.png
2025-11-12 01:28:56,822 - INFO - root - 成功添加图片 7：./export\CVPR 2026\images\figure_7_page8.png
2025-11-12 01:28:56,831 - INFO - root - 成功添加图片 8：./export\CVPR 2026\images\figure_8_page8.png
2025-11-12 01:28:56,836 - INFO - root - 成功添加图片 9：./export\CVPR 2026\images\figure_9_page8.png
2025-11-12 01:28:56,848 - INFO - root - 成功添加图片 10：./export\CVPR 2026\images\figure_10_page8.png
2025-11-12 01:28:56,866 - INFO - root - 已更新图片链接
2025-11-12 01:28:56,914 - INFO - root - 论文《FreqDebias: Towards Generalizable Deepfake Detection via Consistency-Driven Frequency Debiasing》的分析已保存到 ./export\CVPR 2026\FreqDebias_ Towards Generalizable Deepfake Detection via Consistency-Driven Freq.md
2025-11-12 01:28:56,927 - INFO - root - 正在总结论文 11/30: A Mutual Learning Method for Salient Object Detection with intertwined Multi-Supervision--Revised
2025-11-12 01:31:29,694 - INFO - root - 正在提取论文图片到目录: ./export\CVPR 2026\images
2025-11-12 01:31:29,760 - INFO - root - 已保存图片 1/10：./export\CVPR 2026\images\figure_1_page1.jpeg
2025-11-12 01:31:29,798 - INFO - root - 已保存图片 2/10：./export\CVPR 2026\images\figure_2_page1.png
2025-11-12 01:31:29,824 - INFO - root - 已保存图片 3/10：./export\CVPR 2026\images\figure_3_page1.jpeg
2025-11-12 01:31:29,859 - INFO - root - 已保存图片 4/10：./export\CVPR 2026\images\figure_4_page1.png
2025-11-12 01:31:29,889 - INFO - root - 已保存图片 5/10：./export\CVPR 2026\images\figure_5_page1.png
2025-11-12 01:31:29,890 - INFO - root - 成功添加图片 1：./export\CVPR 2026\images\figure_1_page1.jpeg
2025-11-12 01:31:29,890 - INFO - root - 成功添加图片 2：./export\CVPR 2026\images\figure_2_page1.png
2025-11-12 01:31:29,890 - INFO - root - 成功添加图片 3：./export\CVPR 2026\images\figure_3_page1.jpeg
2025-11-12 01:31:29,891 - INFO - root - 成功添加图片 4：./export\CVPR 2026\images\figure_4_page1.png
2025-11-12 01:31:29,891 - INFO - root - 成功添加图片 5：./export\CVPR 2026\images\figure_5_page1.png
2025-11-12 01:31:29,893 - INFO - root - 已更新图片链接
2025-11-12 01:31:29,897 - INFO - root - 论文《A Mutual Learning Method for Salient Object Detection with intertwined Multi-Supervision--Revised》的分析已保存到 ./export\CVPR 2026\A Mutual Learning Method for Salient Object Detection with intertwined Multi-Sup.md
2025-11-12 01:31:29,899 - INFO - root - 正在总结论文 12/30: InstructVTON: Optimal Auto-Masking and Natural-Language-Guided Interactive Style Control for Inpainting-Based Virtual Try-On
2025-11-12 01:32:25,935 - INFO - root - LLMClient: rate limit reached, sleeping 4.0s
2025-11-12 01:32:56,161 - INFO - root - 正在提取论文图片到目录: ./export\CVPR 2026\images
2025-11-12 01:33:01,856 - INFO - root - 已保存图片 1/10：./export\CVPR 2026\images\figure_1_page7.png
2025-11-12 01:33:02,191 - INFO - root - 已保存图片 2/10：./export\CVPR 2026\images\figure_2_page2.png
2025-11-12 01:33:02,580 - INFO - root - 已保存图片 3/10：./export\CVPR 2026\images\figure_3_page8.png
2025-11-12 01:33:02,843 - INFO - root - 已保存图片 4/10：./export\CVPR 2026\images\figure_4_page9.png
2025-11-12 01:33:03,160 - INFO - root - 已保存图片 5/10：./export\CVPR 2026\images\figure_5_page9.png
2025-11-12 01:33:03,267 - INFO - root - 已保存图片 6/10：./export\CVPR 2026\images\figure_6_page5.png
2025-11-12 01:33:03,353 - INFO - root - 已保存图片 7/10：./export\CVPR 2026\images\figure_7_page6.png
2025-11-12 01:33:03,449 - INFO - root - 已保存图片 8/10：./export\CVPR 2026\images\figure_8_page4.png
2025-11-12 01:33:03,490 - INFO - root - 成功添加图片 1：./export\CVPR 2026\images\figure_1_page7.png
2025-11-12 01:33:03,491 - INFO - root - 成功添加图片 2：./export\CVPR 2026\images\figure_2_page2.png
2025-11-12 01:33:03,491 - INFO - root - 成功添加图片 3：./export\CVPR 2026\images\figure_3_page8.png
2025-11-12 01:33:03,491 - INFO - root - 成功添加图片 4：./export\CVPR 2026\images\figure_4_page9.png
2025-11-12 01:33:03,492 - INFO - root - 成功添加图片 5：./export\CVPR 2026\images\figure_5_page9.png
2025-11-12 01:33:03,492 - INFO - root - 成功添加图片 6：./export\CVPR 2026\images\figure_6_page5.png
2025-11-12 01:33:03,493 - INFO - root - 成功添加图片 7：./export\CVPR 2026\images\figure_7_page6.png
2025-11-12 01:33:03,493 - INFO - root - 成功添加图片 8：./export\CVPR 2026\images\figure_8_page4.png
2025-11-12 01:33:03,498 - INFO - root - 已更新图片链接
2025-11-12 01:33:03,500 - INFO - root - 论文《InstructVTON: Optimal Auto-Masking and Natural-Language-Guided Interactive Style Control for Inpainting-Based Virtual Try-On》的分析已保存到 ./export\CVPR 2026\InstructVTON_ Optimal Auto-Masking and Natural-Language-Guided Interactive Style.md
2025-11-12 01:33:03,502 - INFO - root - 正在总结论文 13/30: Efficient Encoder-Free Pose Conditioning and Pose Control for Virtual Try-On
2025-11-12 01:35:05,450 - INFO - root - 正在提取论文图片到目录: ./export\CVPR 2026\images
2025-11-12 01:35:09,356 - INFO - root - 已保存图片 1/10：./export\CVPR 2026\images\figure_1_page2.png
2025-11-12 01:35:09,585 - INFO - root - 已保存图片 2/10：./export\CVPR 2026\images\figure_2_page8.png
2025-11-12 01:35:09,764 - INFO - root - 已保存图片 3/10：./export\CVPR 2026\images\figure_3_page8.png
2025-11-12 01:35:09,893 - INFO - root - 已保存图片 4/10：./export\CVPR 2026\images\figure_4_page6.png
2025-11-12 01:35:10,045 - INFO - root - 已保存图片 5/10：./export\CVPR 2026\images\figure_5_page9.png
2025-11-12 01:35:10,214 - INFO - root - 已保存图片 6/10：./export\CVPR 2026\images\figure_6_page10.png
2025-11-12 01:35:10,303 - INFO - root - 已保存图片 7/10：./export\CVPR 2026\images\figure_7_page4.png
2025-11-12 01:35:10,415 - INFO - root - 已保存图片 8/10：./export\CVPR 2026\images\figure_8_page3.png
2025-11-12 01:35:10,471 - INFO - root - 已保存图片 9/10：./export\CVPR 2026\images\figure_9_page6.png
2025-11-12 01:35:10,495 - INFO - root - 成功添加图片 1：./export\CVPR 2026\images\figure_1_page2.png
2025-11-12 01:35:10,495 - INFO - root - 成功添加图片 2：./export\CVPR 2026\images\figure_2_page8.png
2025-11-12 01:35:10,495 - INFO - root - 成功添加图片 3：./export\CVPR 2026\images\figure_3_page8.png
2025-11-12 01:35:10,496 - INFO - root - 成功添加图片 4：./export\CVPR 2026\images\figure_4_page6.png
2025-11-12 01:35:10,496 - INFO - root - 成功添加图片 5：./export\CVPR 2026\images\figure_5_page9.png
2025-11-12 01:35:10,496 - INFO - root - 成功添加图片 6：./export\CVPR 2026\images\figure_6_page10.png
2025-11-12 01:35:10,497 - INFO - root - 成功添加图片 7：./export\CVPR 2026\images\figure_7_page4.png
2025-11-12 01:35:10,497 - INFO - root - 成功添加图片 8：./export\CVPR 2026\images\figure_8_page3.png
2025-11-12 01:35:10,497 - INFO - root - 成功添加图片 9：./export\CVPR 2026\images\figure_9_page6.png
2025-11-12 01:35:10,504 - INFO - root - 已更新图片链接
2025-11-12 01:35:10,505 - INFO - root - 论文《Efficient Encoder-Free Pose Conditioning and Pose Control for Virtual Try-On》的分析已保存到 ./export\CVPR 2026\Efficient Encoder-Free Pose Conditioning and Pose Control for Virtual Try-On.md
2025-11-12 01:35:10,507 - INFO - root - 正在总结论文 14/30: The Photographer Eye: Teaching Multimodal Large Language Models to Understand Image Aesthetics like Photographers
2025-11-12 01:35:20,805 - INFO - root - LLMClient: rate limit reached, sleeping 21.8s
2025-11-12 01:36:37,771 - INFO - root - 正在提取论文图片到目录: ./export\CVPR 2026\images
2025-11-12 01:36:38,179 - INFO - root - 已保存图片 1/10：./export\CVPR 2026\images\figure_1_page7.jpeg
2025-11-12 01:36:38,293 - INFO - root - 已保存图片 2/10：./export\CVPR 2026\images\figure_2_page1.jpeg
2025-11-12 01:36:38,392 - INFO - root - 已保存图片 3/10：./export\CVPR 2026\images\figure_3_page1.jpeg
2025-11-12 01:36:38,684 - INFO - root - 已保存图片 4/10：./export\CVPR 2026\images\figure_4_page1.jpeg
2025-11-12 01:36:38,850 - INFO - root - 已保存图片 5/10：./export\CVPR 2026\images\figure_5_page1.jpeg
2025-11-12 01:36:38,969 - INFO - root - 已保存图片 6/10：./export\CVPR 2026\images\figure_6_page1.jpeg
2025-11-12 01:36:39,294 - INFO - root - 已保存图片 7/10：./export\CVPR 2026\images\figure_7_page5.jpeg
2025-11-12 01:36:39,521 - INFO - root - 已保存图片 8/10：./export\CVPR 2026\images\figure_8_page5.jpeg
2025-11-12 01:36:39,704 - INFO - root - 已保存图片 9/10：./export\CVPR 2026\images\figure_9_page5.jpeg
2025-11-12 01:36:39,963 - INFO - root - 已保存图片 10/10：./export\CVPR 2026\images\figure_10_page5.jpeg
2025-11-12 01:36:39,974 - INFO - root - 成功添加图片 1：./export\CVPR 2026\images\figure_1_page7.jpeg
2025-11-12 01:36:39,974 - INFO - root - 成功添加图片 2：./export\CVPR 2026\images\figure_2_page1.jpeg
2025-11-12 01:36:39,974 - INFO - root - 成功添加图片 3：./export\CVPR 2026\images\figure_3_page1.jpeg
2025-11-12 01:36:39,974 - INFO - root - 成功添加图片 4：./export\CVPR 2026\images\figure_4_page1.jpeg
2025-11-12 01:36:39,975 - INFO - root - 成功添加图片 5：./export\CVPR 2026\images\figure_5_page1.jpeg
2025-11-12 01:36:39,976 - INFO - root - 成功添加图片 6：./export\CVPR 2026\images\figure_6_page1.jpeg
2025-11-12 01:36:39,976 - INFO - root - 成功添加图片 7：./export\CVPR 2026\images\figure_7_page5.jpeg
2025-11-12 01:36:39,977 - INFO - root - 成功添加图片 8：./export\CVPR 2026\images\figure_8_page5.jpeg
2025-11-12 01:36:39,978 - INFO - root - 成功添加图片 9：./export\CVPR 2026\images\figure_9_page5.jpeg
2025-11-12 01:36:39,978 - INFO - root - 成功添加图片 10：./export\CVPR 2026\images\figure_10_page5.jpeg
2025-11-12 01:36:39,983 - INFO - root - 已更新图片链接
2025-11-12 01:36:39,988 - INFO - root - 论文《The Photographer Eye: Teaching Multimodal Large Language Models to Understand Image Aesthetics like Photographers》的分析已保存到 ./export\CVPR 2026\The Photographer Eye_ Teaching Multimodal Large Language Models to Understand Im.md
2025-11-12 01:36:39,997 - INFO - root - 正在总结论文 15/30: ENSAM: an efficient foundation model for interactive segmentation of 3D medical images
2025-11-12 01:36:39,997 - INFO - root - LLMClient: rate limit reached, sleeping 2.6s
2025-11-12 01:36:51,407 - INFO - root - LLMClient: rate limit reached, sleeping 19.3s
2025-11-12 01:38:15,922 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-12 01:38:15,924 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-12 01:38:15,927 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-12 01:38:17,775 - INFO - root - LLMClientManager: 指定使用客户端: DeepSeek
2025-11-12 01:38:17,779 - INFO - root - DeepSeekClient: API key found: 9f9e270e-b...
2025-11-12 01:38:17,780 - INFO - root - DeepSeekClient: 使用模式: 火山引擎
2025-11-12 01:38:17,781 - INFO - root - DeepSeekClient: 模型名称: deepseek-v3-1-terminus
2025-11-12 01:38:27,160 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 01:38:27,202 - INFO - root - DeepSeekClient: initialized successfully with model deepseek-v3-1-terminus
2025-11-12 01:38:27,203 - INFO - root - LLMClientManager: DeepSeek 客户端初始化成功
2025-11-12 01:38:27,203 - INFO - root - LLMClientManager: switched to DeepSeek client
2025-11-12 01:38:27,204 - INFO - root - 已手动切换到 LLM 客户端: DeepSeek
2025-11-12 01:38:27,204 - INFO - root - 使用 LLM 模型: deepseek-v3-1-terminus
2025-11-12 01:38:27,204 - INFO - root - 可用客户端: ['DeepSeek']
2025-11-12 01:38:27,204 - INFO - root - === 运行配置 ===
2025-11-12 01:38:27,205 - INFO - root - 处理模式: arxiv在线搜索
2025-11-12 01:38:27,205 - INFO - root - 关键词: CVPR 2026
2025-11-12 01:38:27,205 - INFO - root - 查询: CVPR 2025
2025-11-12 01:38:27,205 - INFO - root - 排序: None
2025-11-12 01:38:27,207 - INFO - root - 最近天数: 180
2025-11-12 01:38:27,207 - INFO - root - 最大处理数量: 30
2025-11-12 01:38:27,207 - INFO - root - 保存图片: 是
2025-11-12 01:38:27,207 - INFO - root - 输出语言: 中文
2025-11-12 01:38:27,207 - INFO - root - 强制重新处理: 否
2025-11-12 01:38:27,208 - INFO - root - ====================
2025-11-12 01:38:27,208 - INFO - root - 使用 arXiv 搜索模式（通过 chat_arxiv 模块获取）
2025-11-12 01:38:27,208 - INFO - root - Fetching page 1 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50
2025-11-12 01:38:55,317 - INFO - root - get_all_titles_from_web 
2025-11-12 01:38:55,323 - INFO - root - Page:0, Index:0, Learning to Seek Evidence: A Verifiable Reasoning Agent with Causal Faithfulness Analysis, https://arxiv.org/pdf/2511.01425, 2025-11-03
2025-11-12 01:38:55,331 - INFO - root - Page:0, Index:1, OmniTrack++: Omnidirectional Multi-Object Tracking by Learning Large-FoV Trajectory Feedback, https://arxiv.org/pdf/2511.00510, 2025-11-01
2025-11-12 01:38:55,336 - INFO - root - Page:0, Index:2, NeuCo-Bench: A Novel Benchmark Framework for Neural Embeddings in Earth Observation, https://arxiv.org/pdf/2510.17914, 2025-10-19
2025-11-12 01:38:55,340 - INFO - root - Page:0, Index:3, NTIRE 2025 Challenge on Low Light Image Enhancement: Methods and Results, https://arxiv.org/pdf/2510.13670, 2025-10-15
2025-11-12 01:38:55,352 - INFO - root - Page:0, Index:4, Class Prototypes based Contrastive Learning for Classifying Multi-Label and Fine-Grained Educational Videos, https://arxiv.org/pdf/2510.11204, 2025-10-13
2025-11-12 01:38:55,380 - INFO - root - Page:0, Index:5, MIMO: A medical vision language model with visual referring multimodal input and pixel grounding multimodal output, https://arxiv.org/pdf/2510.10011, 2025-10-11
2025-11-12 01:38:55,386 - INFO - root - Page:0, Index:6, Vision Language Models: A Survey of 26K Papers, https://arxiv.org/pdf/2510.09586, 2025-10-10
2025-11-12 01:38:55,389 - INFO - root - Page:0, Index:7, DiT-VTON: Diffusion Transformer Framework for Unified Multi-Category Virtual Try-On and Virtual Try-All with Integrated Image Editing, https://arxiv.org/pdf/2510.04797, 2025-10-03
2025-11-12 01:38:55,398 - INFO - root - Page:0, Index:8, PatchVSR: Breaking Video Diffusion Resolution Limits with Patch-wise Video Super-Resolution, https://arxiv.org/pdf/2509.26025, 2025-09-30
2025-11-12 01:38:55,401 - INFO - root - Page:0, Index:9, FreqDebias: Towards Generalizable Deepfake Detection via Consistency-Driven Frequency Debiasing, https://arxiv.org/pdf/2509.22412, 2025-09-26
2025-11-12 01:38:55,402 - INFO - root - Page:0, Index:10, A Mutual Learning Method for Salient Object Detection with intertwined Multi-Supervision--Revised, https://arxiv.org/pdf/2509.21363, 2025-09-21
2025-11-12 01:38:55,404 - INFO - root - Page:0, Index:11, InstructVTON: Optimal Auto-Masking and Natural-Language-Guided Interactive Style Control for Inpainting-Based Virtual Try-On, https://arxiv.org/pdf/2509.20524, 2025-09-24
2025-11-12 01:38:55,411 - INFO - root - Page:0, Index:12, Efficient Encoder-Free Pose Conditioning and Pose Control for Virtual Try-On, https://arxiv.org/pdf/2509.20343, 2025-09-24
2025-11-12 01:38:55,415 - INFO - root - Page:0, Index:13, The Photographer Eye: Teaching Multimodal Large Language Models to Understand Image Aesthetics like Photographers, https://arxiv.org/pdf/2509.18582, 2025-10-22
2025-11-12 01:38:55,416 - INFO - root - Page:0, Index:14, ENSAM: an efficient foundation model for interactive segmentation of 3D medical images, https://arxiv.org/pdf/2509.15874, 2025-09-19
2025-11-12 01:38:55,418 - INFO - root - Page:0, Index:15, DEFT-VTON: Efficient Virtual Try-On with Consistent Generalised H-Transform, https://arxiv.org/pdf/2509.13506, 2025-09-16
2025-11-12 01:38:55,422 - INFO - root - Page:0, Index:16, Weakly and Self-Supervised Class-Agnostic Motion Prediction for Autonomous Driving, https://arxiv.org/pdf/2509.13116, 2025-09-16
2025-11-12 01:38:55,429 - INFO - root - Page:0, Index:17, Domain-Adaptive Pretraining Improves Primate Behavior Recognition, https://arxiv.org/pdf/2509.12193, 2025-09-15
2025-11-12 01:38:55,438 - INFO - root - Page:0, Index:18, The System Description of CPS Team for Track on Driving with Language of CVPR 2024 Autonomous Grand Challenge, https://arxiv.org/pdf/2509.11071, 2025-09-13
2025-11-12 01:38:55,448 - INFO - root - Page:0, Index:19, An HMM-based framework for identity-aware long-term multi-object tracking from sparse and uncertain identification: use case on long-term tracking in livestock, https://arxiv.org/pdf/2509.09962, 2025-09-12
2025-11-12 01:38:55,455 - INFO - root - Page:0, Index:20, InterAct: Advancing Large-Scale Versatile 3D Human-Object Interaction Generation, https://arxiv.org/pdf/2509.09555, 2025-09-11
2025-11-12 01:38:55,464 - INFO - root - Page:0, Index:21, Geospatial Foundational Embedder: Top-1 Winning Solution on EarthVision Embed2Scale Challenge (CVPR 2025), https://arxiv.org/pdf/2509.06993, 2025-09-03
2025-11-12 01:38:55,468 - INFO - root - Page:0, Index:22, 2nd Place Solution for CVPR2024 E2E Challenge: End-to-End Autonomous Driving Using Vision Language Model, https://arxiv.org/pdf/2509.02659, 2025-09-02
2025-11-12 01:38:55,470 - INFO - root - Page:0, Index:23, Unsupervised Training of Vision Transformers with Synthetic Negatives, https://arxiv.org/pdf/2509.02024, 2025-09-02
2025-11-12 01:38:55,473 - INFO - root - Page:0, Index:24, MV-SSM: Multi-View State Space Modeling for 3D Human Pose Estimation, https://arxiv.org/pdf/2509.00649, 2025-08-30
2025-11-12 01:38:55,475 - INFO - root - Page:0, Index:25, CryptoFace: End-to-End Encrypted Face Recognition, https://arxiv.org/pdf/2509.00332, 2025-08-29
2025-11-12 01:38:55,483 - INFO - root - Page:0, Index:26, ControlEchoSynth: Boosting Ejection Fraction Estimation Models via Controlled Video Diffusion, https://arxiv.org/pdf/2508.17631, 2025-08-26
2025-11-12 01:38:55,484 - INFO - root - Page:0, Index:27, Explain Before You Answer: A Survey on Compositional Visual Reasoning, https://arxiv.org/pdf/2508.17298, 2025-08-27
2025-11-12 01:38:55,486 - INFO - root - Page:0, Index:28, Investigating Different Geo Priors for Image Classification, https://arxiv.org/pdf/2508.15946, 2025-08-21
2025-11-12 01:38:55,487 - INFO - root - Page:0, Index:29, Towards Source-Free Machine Unlearning, https://arxiv.org/pdf/2508.15127, 2025-08-20
2025-11-12 01:38:55,488 - INFO - root - Page:0, Index:30, MR6D: Benchmarking 6D Pose Estimation for Mobile Robots, https://arxiv.org/pdf/2508.13775, 2025-08-19
2025-11-12 01:38:55,489 - INFO - root - Page:0, Index:31, Calibrating Biased Distribution in VFM-derived Latent Space via Cross-Domain Geometric Consistency, https://arxiv.org/pdf/2508.13518, 2025-08-19
2025-11-12 01:38:55,489 - INFO - root - Page:0, Index:32, SIS-Challenge: Event-based Spatio-temporal Instance Segmentation Challenge at the CVPR 2025 Event-based Vision Workshop, https://arxiv.org/pdf/2508.12813, 2025-08-18
2025-11-12 01:38:55,490 - INFO - root - Page:0, Index:33, Multi-Level Knowledge Distillation and Dynamic Self-Supervised Learning for Continual Learning, https://arxiv.org/pdf/2508.12692, 2025-08-22
2025-11-12 01:38:55,490 - INFO - root - Page:0, Index:34, Stochastic-based Patch Filtering for Few-Shot Learning, https://arxiv.org/pdf/2508.10066, 2025-08-13
2025-11-12 01:38:55,491 - INFO - root - Page:0, Index:35, Slot Attention-based Feature Filtering for Few-Shot Learning, https://arxiv.org/pdf/2508.09699, 2025-08-13
2025-11-12 01:38:55,497 - INFO - root - Page:0, Index:36, Comparison Reveals Commonality: Customized Image Generation through Contrastive Inversion, https://arxiv.org/pdf/2508.07755, 2025-08-11
2025-11-12 01:38:55,498 - INFO - root - Page:0, Index:37, SLRTP2025 Sign Language Production Challenge: Methodology, Results, and Future Work, https://arxiv.org/pdf/2508.06951, 2025-08-09
2025-11-12 01:38:55,498 - INFO - root - Page:0, Index:38, Exploring Fairness across Fine-Grained Attributes in Large Vision-Language Models, https://arxiv.org/pdf/2508.03079, 2025-08-05
2025-11-12 01:38:55,499 - INFO - root - Page:0, Index:39, Devil is in the Detail: Towards Injecting Fine Details of Image Prompt in Image Generation via Conflict-free Guidance and Stratified Attention, https://arxiv.org/pdf/2508.02004, 2025-08-03
2025-11-12 01:38:55,500 - INFO - root - Page:0, Index:40, IAUNet: Instance-Aware U-Net, https://arxiv.org/pdf/2508.01928, 2025-08-03
2025-11-12 01:38:55,500 - INFO - root - Page:0, Index:41, Gaussian Splatting Feature Fields for Privacy-Preserving Visual Localization, https://arxiv.org/pdf/2507.23569, 2025-08-26
2025-11-12 01:38:55,500 - INFO - root - Page:0, Index:42, From Scan to Action: Leveraging Realistic Scans for Embodied Scene Understanding, https://arxiv.org/pdf/2507.17585, 2025-07-23
2025-11-12 01:38:55,500 - INFO - root - Page:0, Index:43, LEAD: Exploring Logit Space Evolution for Model Selection, https://arxiv.org/pdf/2507.14559, 2025-07-19
2025-11-12 01:38:55,501 - INFO - root - Page:0, Index:44, HeCoFuse: Cross-Modal Complementary V2X Cooperative Perception with Heterogeneous Sensors, https://arxiv.org/pdf/2507.13677, 2025-07-18
2025-11-12 01:38:55,502 - INFO - root - Page:0, Index:45, OmniVec2 -- A Novel Transformer based Network for Large Scale Multimodal and Multitask Learning, https://arxiv.org/pdf/2507.13364, 2025-07-06
2025-11-12 01:38:55,502 - INFO - root - Page:0, Index:46, A Training-Free, Task-Agnostic Framework for Enhancing MLLM Performance on High-Resolution Images, https://arxiv.org/pdf/2507.10202, 2025-07-14
2025-11-12 01:38:55,502 - INFO - root - Page:0, Index:47, Quantum Federated Learning for Multimodal Data: A Modality-Agnostic Approach, https://arxiv.org/pdf/2507.08217, 2025-07-10
2025-11-12 01:38:55,505 - INFO - root - Page:0, Index:48, CuriosAI Submission to the EgoExo4D Proficiency Estimation Challenge 2025, https://arxiv.org/pdf/2507.08022, 2025-07-08
2025-11-12 01:38:55,505 - INFO - root - Page:0, Index:49, Rethinking Query-based Transformer for Continual Image Segmentation, https://arxiv.org/pdf/2507.07831, 2025-07-10
2025-11-12 01:38:55,506 - INFO - root - Fetching page 2 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=50
2025-11-12 01:39:26,391 - INFO - root - get_all_titles_from_web 
2025-11-12 01:39:26,391 - INFO - root - Page:1, Index:0, Scalable and Realistic Virtual Try-on Application for Foundation Makeup with Kubelka-Munk Theory, https://arxiv.org/pdf/2507.07333, 2025-07-09
2025-11-12 01:39:26,393 - INFO - root - Page:1, Index:1, Free on the Fly: Enhancing Flexibility in Test-Time Adaptation with Online EM, https://arxiv.org/pdf/2507.06973, 2025-07-09
2025-11-12 01:39:26,393 - INFO - root - Page:1, Index:2, Adaptive Part Learning for Fine-Grained Generalized Category Discovery: A Plug-and-Play Enhancement, https://arxiv.org/pdf/2507.06928, 2025-07-09
2025-11-12 01:39:26,394 - INFO - root - Page:1, Index:3, Grounded Gesture Generation: Language, Motion, and Space, https://arxiv.org/pdf/2507.04522, 2025-07-06
2025-11-12 01:39:26,394 - INFO - root - Page:1, Index:4, Comprehensive Information Bottleneck for Unveiling Universal Attribution to Interpret Vision Transformers, https://arxiv.org/pdf/2507.04388, 2025-07-06
2025-11-12 01:39:26,395 - INFO - root - Page:1, Index:5, ZERO: Industry-ready Vision Foundation Model with Multi-modal Prompts, https://arxiv.org/pdf/2507.04270, 2025-11-07
2025-11-12 01:39:26,395 - INFO - root - Page:1, Index:6, Beyond Accuracy: Metrics that Uncover What Makes a 'Good' Visual Descriptor, https://arxiv.org/pdf/2507.03542, 2025-07-08
2025-11-12 01:39:26,396 - INFO - root - Page:1, Index:7, ConceptMix++: Leveling the Playing Field in Text-to-Image Benchmarking via Iterative Prompt Optimization, https://arxiv.org/pdf/2507.03275, 2025-07-03
2025-11-12 01:39:26,396 - INFO - root - Page:1, Index:8, APT: Adaptive Personalized Training for Diffusion Models with Limited Data, https://arxiv.org/pdf/2507.02687, 2025-07-03
2025-11-12 01:39:26,396 - INFO - root - Page:1, Index:9, DreamComposer++: Empowering Diffusion Models with Multi-View Conditions for 3D Content Generation, https://arxiv.org/pdf/2507.02299, 2025-07-03
2025-11-12 01:39:26,397 - INFO - root - Page:1, Index:10, Soft Self-labeling and Potts Relaxations for Weakly-Supervised Segmentation, https://arxiv.org/pdf/2507.01721, 2025-07-02
2025-11-12 01:39:26,397 - INFO - root - Page:1, Index:11, Interpolation-Based Event Visual Data Filtering Algorithms, https://arxiv.org/pdf/2507.01557, 2025-07-02
2025-11-12 01:39:26,397 - INFO - root - Page:1, Index:12, AVC-DPO: Aligned Video Captioning via Direct Preference Optimization, https://arxiv.org/pdf/2507.01492, 2025-07-02
2025-11-12 01:39:26,398 - INFO - root - Page:1, Index:13, NN-Former: Rethinking Graph Structure in Neural Architecture Representation, https://arxiv.org/pdf/2507.00880, 2025-07-01
2025-11-12 01:39:26,398 - INFO - root - Page:1, Index:14, Instant Particle Size Distribution Measurement Using CNNs Trained on Synthetic Data, https://arxiv.org/pdf/2507.00822, 2025-07-01
2025-11-12 01:39:26,399 - INFO - root - Page:1, Index:15, Moment Sampling in Video LLMs for Long-Form Video QA, https://arxiv.org/pdf/2507.00033, 2025-06-17
2025-11-12 01:39:26,400 - INFO - root - Page:1, Index:16, Revisiting Audio-Visual Segmentation with Vision-Centric Transformer, https://arxiv.org/pdf/2506.23623, 2025-06-30
2025-11-12 01:39:26,410 - INFO - root - Page:1, Index:17, MTADiffusion: Mask Text Alignment Diffusion Model for Object Inpainting, https://arxiv.org/pdf/2506.23482, 2025-06-29
2025-11-12 01:39:26,411 - INFO - root - Page:1, Index:18, Benchmarking Generalizable Bimanual Manipulation: RoboTwin Dual-Arm Collaboration Challenge at CVPR 2025 MEIS Workshop, https://arxiv.org/pdf/2506.23351, 2025-07-02
2025-11-12 01:39:26,413 - INFO - root - Page:1, Index:19, Prompting without Panic: Attribute-aware, Zero-shot, Test-Time Calibration, https://arxiv.org/pdf/2506.22819, 2025-06-28
2025-11-12 01:39:26,413 - INFO - root - Page:1, Index:20, Analyzing and Fine-Tuning Whisper Models for Multilingual Pilot Speech Transcription in the Cockpit, https://arxiv.org/pdf/2506.21990, 2025-06-27
2025-11-12 01:39:26,413 - INFO - root - Page:1, Index:21, SceneDiffuser++: City-Scale Traffic Simulation via a Generative World Model, https://arxiv.org/pdf/2506.21976, 2025-06-27
2025-11-12 01:39:26,414 - INFO - root - Page:1, Index:22, DIVE: Deep-search Iterative Video Exploration A Technical Report for the CVRR Challenge at CVPR 2025, https://arxiv.org/pdf/2506.21891, 2025-06-27
2025-11-12 01:39:26,414 - INFO - root - Page:1, Index:23, End-to-End RGB-IR Joint Image Compression With Channel-wise Cross-modality Entropy Model, https://arxiv.org/pdf/2506.21851, 2025-06-26
2025-11-12 01:39:26,415 - INFO - root - Page:1, Index:24, Distilling Normalizing Flows, https://arxiv.org/pdf/2506.21003, 2025-06-26
2025-11-12 01:39:26,417 - INFO - root - Page:1, Index:25, Joint attitude estimation and 3D neural reconstruction of non-cooperative space objects, https://arxiv.org/pdf/2506.20638, 2025-06-25
2025-11-12 01:39:26,419 - INFO - root - Page:1, Index:26, Accept More, Reject Less: Reducing up to 19% Unnecessary Desk-Rejections over 11 Years of ICLR Data, https://arxiv.org/pdf/2506.20141, 2025-06-25
2025-11-12 01:39:26,420 - INFO - root - Page:1, Index:27, SceneCrafter: Controllable Multi-View Driving Scene Editing, https://arxiv.org/pdf/2506.19488, 2025-06-24
2025-11-12 01:39:26,420 - INFO - root - Page:1, Index:28, Emergence of Text Readability in Vision Language Models, https://arxiv.org/pdf/2506.19389, 2025-06-24
2025-11-12 01:39:26,421 - INFO - root - Page:1, Index:29, MedErr-CT: A Visual Question Answering Benchmark for Identifying and Correcting Errors in CT Reports, https://arxiv.org/pdf/2506.19217, 2025-06-23
2025-11-12 01:39:26,421 - INFO - root - Page:1, Index:30, RareSpot: Spotting Small and Rare Wildlife in Aerial Imagery with Multi-Scale Consistency and Context-Aware Augmentation, https://arxiv.org/pdf/2506.19087, 2025-06-23
2025-11-12 01:39:26,421 - INFO - root - Page:1, Index:31, Object-aware Sound Source Localization via Audio-Visual Scene Understanding, https://arxiv.org/pdf/2506.18557, 2025-06-23
2025-11-12 01:39:26,427 - INFO - root - Page:1, Index:32, Rethinking Decoder Design: Improving Biomarker Segmentation Using Depth-to-Space Restoration and Residual Linear Attention, https://arxiv.org/pdf/2506.18335, 2025-06-23
2025-11-12 01:39:26,427 - INFO - root - Page:1, Index:33, Relation3D: Enhancing Relation Modeling for Point Cloud Instance Segmentation, https://arxiv.org/pdf/2506.17891, 2025-06-21
2025-11-12 01:39:26,428 - INFO - root - Page:1, Index:34, HIRE: Lightweight High-Resolution Image Feature Enrichment for Multimodal LLMs, https://arxiv.org/pdf/2506.17608, 2025-06-21
2025-11-12 01:39:26,429 - INFO - root - Page:1, Index:35, Spatially-Aware Evaluation of Segmentation Uncertainty, https://arxiv.org/pdf/2506.16589, 2025-06-19
2025-11-12 01:39:26,429 - INFO - root - Page:1, Index:36, Tripartite Weight-Space Ensemble for Few-Shot Class-Incremental Learning, https://arxiv.org/pdf/2506.15720, 2025-06-03
2025-11-12 01:39:26,429 - INFO - root - Page:1, Index:37, PARC: A Quantitative Framework Uncovering the Symmetries within Vision Language Models, https://arxiv.org/pdf/2506.14808, 2025-06-03
2025-11-12 01:39:26,430 - INFO - root - Page:1, Index:38, Self-supervised Representation Learning with Local Aggregation for Image-based Profiling, https://arxiv.org/pdf/2506.14265, 2025-10-27
2025-11-12 01:39:26,430 - INFO - root - Page:1, Index:39, Towards Robust Learning to Optimize with Theoretical Guarantees, https://arxiv.org/pdf/2506.14263, 2025-06-17
2025-11-12 01:39:26,430 - INFO - root - Page:1, Index:40, Hidden Bias in the Machine: Stereotypes in Text-to-Image Models, https://arxiv.org/pdf/2506.13780, 2025-06-09
2025-11-12 01:39:26,431 - INFO - root - Page:1, Index:41, SmartHome-Bench: A Comprehensive Benchmark for Video Anomaly Detection in Smart Homes Using Multi-Modal Large Language Models, https://arxiv.org/pdf/2506.12992, 2025-06-15
2025-11-12 01:39:26,432 - INFO - root - Page:1, Index:42, Generative 4D Scene Gaussian Splatting with Object View-Synthesis Priors, https://arxiv.org/pdf/2506.12716, 2025-06-15
2025-11-12 01:39:26,433 - INFO - root - Page:1, Index:43, DejaVid: Encoder-Agnostic Learned Temporal Matching for Video Classification, https://arxiv.org/pdf/2506.12585, 2025-06-14
2025-11-12 01:39:26,434 - INFO - root - Page:1, Index:44, Pushing the Limits of Safety: A Technical Report on the ATLAS Challenge 2025, https://arxiv.org/pdf/2506.12430, 2025-07-10
2025-11-12 01:39:26,434 - INFO - root - Page:1, Index:45, FIMA-Q: Post-Training Quantization for Vision Transformers by Fisher Information Matrix Approximation, https://arxiv.org/pdf/2506.11543, 2025-06-13
2025-11-12 01:39:26,434 - INFO - root - Page:1, Index:46, Stop learning it all to mitigate visual hallucination, Focus on the hallucination target, https://arxiv.org/pdf/2506.11417, 2025-06-12
2025-11-12 01:39:26,435 - INFO - root - Page:1, Index:47, EfficientQuant: An Efficient Post-Training Quantization for CNN-Transformer Hybrid Models on Edge Devices, https://arxiv.org/pdf/2506.11093, 2025-06-05
2025-11-12 01:39:26,436 - INFO - root - Page:1, Index:48, HalLoc: Token-level Localization of Hallucinations for Vision Language Models, https://arxiv.org/pdf/2506.10286, 2025-06-11
2025-11-12 01:39:26,436 - INFO - root - Page:1, Index:49, DySS: Dynamic Queries and State-Space Learning for Efficient 3D Object Detection from Multi-Camera Videos, https://arxiv.org/pdf/2506.10242, 2025-06-11
2025-11-12 01:39:26,437 - INFO - root - Fetching page 3 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=100
2025-11-12 01:39:59,646 - INFO - root - get_all_titles_from_web 
2025-11-12 01:39:59,646 - INFO - root - Page:2, Index:0, Improving Personalized Search with Regularized Low-Rank Parameter Updates, https://arxiv.org/pdf/2506.10182, 2025-06-11
2025-11-12 01:39:59,646 - INFO - root - Page:2, Index:1, Hearing Hands: Generating Sounds from Physical Interactions in 3D Scenes, https://arxiv.org/pdf/2506.09989, 2025-06-11
2025-11-12 01:39:59,646 - INFO - root - Page:2, Index:2, UniPre3D: Unified Pre-training of 3D Point Cloud Models with Cross-Modal Gaussian Splatting, https://arxiv.org/pdf/2506.09952, 2025-06-11
2025-11-12 01:39:59,646 - INFO - root - Page:2, Index:3, Provoking Multi-modal Few-Shot LVLM via Exploration-Exploitation In-Context Learning, https://arxiv.org/pdf/2506.09473, 2025-06-11
2025-11-12 01:39:59,646 - INFO - root - Page:2, Index:4, Synthetic Human Action Video Data Generation with Pose Transfer, https://arxiv.org/pdf/2506.09411, 2025-06-11
2025-11-12 01:39:59,646 - INFO - root - Page:2, Index:5, ScaleLSD: Scalable Deep Line Segment Detection Streamlined, https://arxiv.org/pdf/2506.09369, 2025-06-10
2025-11-12 01:39:59,646 - INFO - root - Page:2, Index:6, CheckManual: A New Challenge and Benchmark for Manual-based Appliance Manipulation, https://arxiv.org/pdf/2506.09343, 2025-06-10
2025-11-12 01:39:59,646 - INFO - root - Page:2, Index:7, PatchGuard: Adversarially Robust Anomaly Detection and Localization through Vision Transformers and Pseudo Anomalies, https://arxiv.org/pdf/2506.09237, 2025-10-24
2025-11-12 01:39:59,646 - INFO - root - Page:2, Index:8, SILK: Smooth InterpoLation frameworK for motion in-betweening A Simplified Computational Approach, https://arxiv.org/pdf/2506.09075, 2025-06-09
2025-11-12 01:39:59,646 - INFO - root - Page:2, Index:9, BG-HOP: A Bimanual Generative Hand-Object Prior, https://arxiv.org/pdf/2506.09068, 2025-06-08
2025-11-12 01:39:59,646 - INFO - root - Page:2, Index:10, ORIDa: Object-centric Real-world Image Composition Dataset, https://arxiv.org/pdf/2506.08964, 2025-06-10
2025-11-12 01:39:59,646 - INFO - root - Page:2, Index:11, DiscoVLA: Discrepancy Reduction in Vision, Language, and Alignment for Parameter-Efficient Video-Text Retrieval, https://arxiv.org/pdf/2506.08887, 2025-06-10
2025-11-12 01:39:59,646 - INFO - root - Page:2, Index:12, A Comprehensive Study of Decoder-Only LLMs for Text-to-Image Generation, https://arxiv.org/pdf/2506.08210, 2025-06-09
2025-11-12 01:39:59,646 - INFO - root - Page:2, Index:13, Open World Scene Graph Generation using Vision Language Models, https://arxiv.org/pdf/2506.08189, 2025-06-09
2025-11-12 01:39:59,646 - INFO - root - Page:2, Index:14, Aligning Proteins and Language: A Foundation Model for Protein Retrieval, https://arxiv.org/pdf/2506.08023, 2025-05-27
2025-11-12 01:39:59,646 - INFO - root - Page:2, Index:15, UA-Pose: Uncertainty-Aware 6D Object Pose Estimation and Online Object Completion with Partial References, https://arxiv.org/pdf/2506.07996, 2025-06-09
2025-11-12 01:39:59,646 - INFO - root - Page:2, Index:16, Speedy Deformable 3D Gaussian Splatting: Fast Rendering and Compression of Dynamic Scenes, https://arxiv.org/pdf/2506.07917, 2025-06-09
2025-11-12 01:39:59,646 - INFO - root - Page:2, Index:17, GaussianVAE: Adaptive Learning Dynamics of 3D Gaussians for High-Fidelity Super-Resolution, https://arxiv.org/pdf/2506.07897, 2025-06-09
2025-11-12 01:39:59,646 - INFO - root - Page:2, Index:18, Spatio-Temporal State Space Model For Efficient Event-Based Optical Flow, https://arxiv.org/pdf/2506.07878, 2025-06-09
2025-11-12 01:39:59,646 - INFO - root - Page:2, Index:19, FreeGave: 3D Physics Learning from Dynamic Videos by Gaussian Velocity, https://arxiv.org/pdf/2506.07865, 2025-06-09
2025-11-12 01:39:59,646 - INFO - root - Page:2, Index:20, LogoSP: Local-global Grouping of Superpoints for Unsupervised Semantic Segmentation of 3D Point Clouds, https://arxiv.org/pdf/2506.07857, 2025-06-09
2025-11-12 01:39:59,698 - INFO - root - Page:2, Index:21, Difference Inversion: Interpolate and Isolate the Difference with Token Consistency for Image Analogy Generation, https://arxiv.org/pdf/2506.07750, 2025-06-09
2025-11-12 01:39:59,745 - INFO - root - Page:2, Index:22, Synthetic Visual Genome, https://arxiv.org/pdf/2506.07643, 2025-06-09
2025-11-12 01:39:59,763 - INFO - root - Page:2, Index:23, Fractional Collisions: A Framework for Risk Estimation of Counterfactual Conflicts using Autonomous Driving Behavior Simulations, https://arxiv.org/pdf/2506.07540, 2025-06-09
2025-11-12 01:39:59,765 - INFO - root - Page:2, Index:24, Multi-Step Guided Diffusion for Image Restoration on Edge Devices: Toward Lightweight Perception in Embodied AI, https://arxiv.org/pdf/2506.07286, 2025-06-08
2025-11-12 01:39:59,765 - INFO - root - Page:2, Index:25, LLM-Enhanced Rapid-Reflex Async-Reflect Embodied Agent for Real-Time Decision-Making in Dynamically Changing Environments, https://arxiv.org/pdf/2506.07223, 2025-06-08
2025-11-12 01:39:59,767 - INFO - root - Page:2, Index:26, UCOD-DPL: Unsupervised Camouflaged Object Detection via Dynamic Pseudo-label Learning, https://arxiv.org/pdf/2506.07087, 2025-06-08
2025-11-12 01:39:59,767 - INFO - root - Page:2, Index:27, BePo: Leveraging Birds Eye View and Sparse Points for Efficient and Accurate 3D Occupancy Prediction, https://arxiv.org/pdf/2506.07002, 2025-06-08
2025-11-12 01:39:59,768 - INFO - root - Page:2, Index:28, Reading in the Dark with Foveated Event Vision, https://arxiv.org/pdf/2506.06918, 2025-06-07
2025-11-12 01:39:59,768 - INFO - root - Page:2, Index:29, NSD-Imagery: A benchmark dataset for extending fMRI vision decoding methods to mental imagery, https://arxiv.org/pdf/2506.06898, 2025-06-07
2025-11-12 01:39:59,768 - INFO - root - Page:2, Index:30, Continuous-Time SO(3) Forecasting with Savitzky--Golay Neural Controlled Differential Equations, https://arxiv.org/pdf/2506.06780, 2025-06-07
2025-11-12 01:39:59,770 - INFO - root - Page:2, Index:31, Generalized Trajectory Scoring for End-to-end Multimodal Planning, https://arxiv.org/pdf/2506.06664, 2025-06-07
2025-11-12 01:39:59,774 - INFO - root - Page:2, Index:32, EV-LayerSegNet: Self-supervised Motion Segmentation using Event Cameras, https://arxiv.org/pdf/2506.06596, 2025-06-06
2025-11-12 01:39:59,775 - INFO - root - Page:2, Index:33, Vid2Sim: Generalizable, Video-based Reconstruction of Appearance, Geometry and Physics for Mesh-free Simulation, https://arxiv.org/pdf/2506.06440, 2025-06-06
2025-11-12 01:39:59,776 - INFO - root - Page:2, Index:34, FADE: Frequency-Aware Diffusion Model Factorization for Video Editing, https://arxiv.org/pdf/2506.05934, 2025-06-06
2025-11-12 01:39:59,777 - INFO - root - Page:2, Index:35, Unleashing the Potential of Consistency Learning for Detecting and Grounding Multi-Modal Media Manipulation, https://arxiv.org/pdf/2506.05890, 2025-06-06
2025-11-12 01:39:59,778 - INFO - root - Page:2, Index:36, DeformCL: Learning Deformable Centerline Representation for Vessel Extraction in 3D Medical Image, https://arxiv.org/pdf/2506.05820, 2025-06-06
2025-11-12 01:39:59,779 - INFO - root - Page:2, Index:37, NTIRE 2025 Challenge on HR Depth from Images of Specular and Transparent Surfaces, https://arxiv.org/pdf/2506.05815, 2025-06-06
2025-11-12 01:39:59,780 - INFO - root - Page:2, Index:38, GazeNLQ @ Ego4D Natural Language Queries Challenge 2025, https://arxiv.org/pdf/2506.05782, 2025-06-06
2025-11-12 01:39:59,780 - INFO - root - Page:2, Index:39, Robust sensor fusion against on-vehicle sensor staleness, https://arxiv.org/pdf/2506.05780, 2025-06-06
2025-11-12 01:39:59,781 - INFO - root - Page:2, Index:40, Where Is The Ball: 3D Ball Trajectory Estimation From 2D Monocular Tracking, https://arxiv.org/pdf/2506.05763, 2025-06-06
2025-11-12 01:39:59,782 - INFO - root - Page:2, Index:41, VoxelSplat: Dynamic Gaussian Splatting as an Effective Loss for Occupancy and Flow Prediction, https://arxiv.org/pdf/2506.05563, 2025-06-05
2025-11-12 01:39:59,803 - INFO - root - Page:2, Index:42, Gen4D: Synthesizing Humans and Scenes in the Wild, https://arxiv.org/pdf/2506.05397, 2025-06-03
2025-11-12 01:39:59,804 - INFO - root - Page:2, Index:43, Attacking Attention of Foundation Models Disrupts Downstream Tasks, https://arxiv.org/pdf/2506.05394, 2025-09-12
2025-11-12 01:39:59,804 - INFO - root - Page:2, Index:44, FreeTimeGS: Free Gaussian Primitives at Anytime and Anywhere for Dynamic Scene Reconstruction, https://arxiv.org/pdf/2506.05348, 2025-06-06
2025-11-12 01:39:59,804 - INFO - root - Page:2, Index:45, LotusFilter: Fast Diverse Nearest Neighbor Search via a Learned Cutoff Table, https://arxiv.org/pdf/2506.04790, 2025-06-05
2025-11-12 01:39:59,805 - INFO - root - Page:2, Index:46, Towards Holistic Visual Quality Assessment of AI-Generated Videos: A LLM-Based Multi-Dimensional Evaluation Model, https://arxiv.org/pdf/2506.04715, 2025-06-11
2025-11-12 01:39:59,805 - INFO - root - Page:2, Index:47, Gradient Inversion Attacks on Parameter-Efficient Fine-Tuning, https://arxiv.org/pdf/2506.04453, 2025-06-04
2025-11-12 01:39:59,805 - INFO - root - Page:2, Index:48, HMAR: Efficient Hierarchical Masked Auto-Regressive Image Generation, https://arxiv.org/pdf/2506.04421, 2025-06-04
2025-11-12 01:39:59,806 - INFO - root - Page:2, Index:49, Visualizing and Controlling Cortical Responses Using Voxel-Weighted Activation Maximization, https://arxiv.org/pdf/2506.04379, 2025-06-04
2025-11-12 01:39:59,807 - INFO - root - Fetching page 4 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=150
2025-11-12 01:40:37,863 - INFO - root - get_all_titles_from_web 
2025-11-12 01:40:37,863 - INFO - root - Page:3, Index:0, FlexGS: Train Once, Deploy Everywhere with Many-in-One Flexible 3D Gaussian Splatting, https://arxiv.org/pdf/2506.04174, 2025-06-04
2025-11-12 01:40:37,863 - INFO - root - Page:3, Index:1, Multi-view Surface Reconstruction Using Normal and Reflectance Cues, https://arxiv.org/pdf/2506.04115, 2025-06-04
2025-11-12 01:40:37,864 - INFO - root - Page:3, Index:2, Vocabulary-free few-shot learning for Vision-Language Models, https://arxiv.org/pdf/2506.04005, 2025-06-04
2025-11-12 01:40:37,864 - INFO - root - Page:3, Index:3, Learning from Noise: Enhancing DNNs for Event-Based Vision through Controlled Noise Injection, https://arxiv.org/pdf/2506.03918, 2025-06-04
2025-11-12 01:40:37,864 - INFO - root - Page:3, Index:4, Video, How Do Your Tokens Merge?, https://arxiv.org/pdf/2506.03885, 2025-06-04
2025-11-12 01:40:37,864 - INFO - root - Page:3, Index:5, OSGNet @ Ego4D Episodic Memory Challenge 2025, https://arxiv.org/pdf/2506.03710, 2025-06-04
2025-11-12 01:40:37,864 - INFO - root - Page:3, Index:6, AetherVision-Bench: An Open-Vocabulary RGB-Infrared Benchmark for Multi-Angle Segmentation across Aerial and Ground Perspectives, https://arxiv.org/pdf/2506.03709, 2025-06-04
2025-11-12 01:40:37,865 - INFO - root - Page:3, Index:7, OV-COAST: Cost Aggregation with Optimal Transport for Open-Vocabulary Semantic Segmentation, https://arxiv.org/pdf/2506.03706, 2025-06-04
2025-11-12 01:40:37,865 - INFO - root - Page:3, Index:8, Generating 6DoF Object Manipulation Trajectories from Action Description in Egocentric Vision, https://arxiv.org/pdf/2506.03605, 2025-06-04
2025-11-12 01:40:37,865 - INFO - root - Page:3, Index:9, SemNav: A Model-Based Planner for Zero-Shot Object Goal Navigation Using Vision-Foundation Models, https://arxiv.org/pdf/2506.03516, 2025-06-03
2025-11-12 01:40:37,866 - INFO - root - Page:3, Index:10, Heterogeneous Skeleton-Based Action Representation Learning, https://arxiv.org/pdf/2506.03481, 2025-06-03
2025-11-12 01:40:37,866 - INFO - root - Page:3, Index:11, Hybrid Ensemble of Segmentation-Assisted Classification and GBDT for Skin Cancer Detection with Engineered Metadata and Synthetic Lesions from ISIC 2024 Non-Dermoscopic 3D-TBP Images, https://arxiv.org/pdf/2506.03420, 2025-06-03
2025-11-12 01:40:37,867 - INFO - root - Page:3, Index:12, Self-Supervised Spatial Correspondence Across Modalities, https://arxiv.org/pdf/2506.03148, 2025-06-03
2025-11-12 01:40:37,867 - INFO - root - Page:3, Index:13, Dense Match Summarization for Faster Two-view Estimation, https://arxiv.org/pdf/2506.02893, 2025-06-03
2025-11-12 01:40:37,867 - INFO - root - Page:3, Index:14, NTIRE 2025 XGC Quality Assessment Challenge: Methods and Results, https://arxiv.org/pdf/2506.02875, 2025-06-03
2025-11-12 01:40:37,867 - INFO - root - Page:3, Index:15, FreeScene: Mixed Graph Diffusion for 3D Scene Synthesis from Free Prompts, https://arxiv.org/pdf/2506.02781, 2025-06-03
2025-11-12 01:40:37,868 - INFO - root - Page:3, Index:16, Technical Report for Ego4D Long-Term Action Anticipation Challenge 2025, https://arxiv.org/pdf/2506.02550, 2025-06-11
2025-11-12 01:40:37,868 - INFO - root - Page:3, Index:17, Probabilistic Online Event Downsampling, https://arxiv.org/pdf/2506.02547, 2025-09-23
2025-11-12 01:40:37,868 - INFO - root - Page:3, Index:18, Towards In-the-wild 3D Plane Reconstruction from a Single Image, https://arxiv.org/pdf/2506.02493, 2025-06-03
2025-11-12 01:40:37,869 - INFO - root - Page:3, Index:19, Efficient Test-time Adaptive Object Detection via Sensitivity-Guided Pruning, https://arxiv.org/pdf/2506.02462, 2025-06-03
2025-11-12 01:40:37,869 - INFO - root - Page:3, Index:20, EgoVIS@CVPR: PAIR-Net: Enhancing Egocentric Speaker Detection via Pretrained Audio-Visual Fusion and Alignment Loss, https://arxiv.org/pdf/2506.02247, 2025-09-26
2025-11-12 01:40:37,869 - INFO - root - Page:3, Index:21, Diff2Flow: Training Flow Matching Models via Diffusion Model Alignment, https://arxiv.org/pdf/2506.02221, 2025-06-02
2025-11-12 01:40:37,869 - INFO - root - Page:3, Index:22, NTIRE 2025 Challenge on RAW Image Restoration and Super-Resolution, https://arxiv.org/pdf/2506.02197, 2025-06-04
2025-11-12 01:40:37,869 - INFO - root - Page:3, Index:23, RAW Image Reconstruction from RGB on Smartphones. NTIRE 2025 Challenge Report, https://arxiv.org/pdf/2506.01947, 2025-06-02
2025-11-12 01:40:37,875 - INFO - root - Page:3, Index:24, Silence is Golden: Leveraging Adversarial Examples to Nullify Audio Control in LDM-based Talking-Head Generation, https://arxiv.org/pdf/2506.01591, 2025-06-02
2025-11-12 01:40:37,882 - INFO - root - Page:3, Index:25, SAM2-LOVE: Segment Anything Model 2 in Language-aided Audio-Visual Scenes, https://arxiv.org/pdf/2506.01558, 2025-06-02
2025-11-12 01:40:37,890 - INFO - root - Page:3, Index:26, Neural shape reconstruction from multiple views with static pattern projection, https://arxiv.org/pdf/2506.01389, 2025-06-02
2025-11-12 01:40:37,905 - INFO - root - Page:3, Index:27, SAM-I2V: Upgrading SAM to Support Promptable Video Segmentation with Less than 0.2% Training Cost, https://arxiv.org/pdf/2506.01304, 2025-06-02
2025-11-12 01:40:37,925 - INFO - root - Page:3, Index:28, Perceptual Inductive Bias Is What You Need Before Contrastive Learning, https://arxiv.org/pdf/2506.01201, 2025-06-01
2025-11-12 01:40:37,943 - INFO - root - Page:3, Index:29, Test Automation for Interactive Scenarios via Promptable Traffic Simulation, https://arxiv.org/pdf/2506.01199, 2025-06-04
2025-11-12 01:40:37,971 - INFO - root - Page:3, Index:30, GraphPad: Inference-Time 3D Scene Graph Updates for Embodied Question Answering, https://arxiv.org/pdf/2506.01174, 2025-06-01
2025-11-12 01:40:37,979 - INFO - root - Page:3, Index:31, Aligned Contrastive Loss for Long-Tailed Recognition, https://arxiv.org/pdf/2506.01071, 2025-06-01
2025-11-12 01:40:37,985 - INFO - root - Page:3, Index:32, Self-supervised ControlNet with Spatio-Temporal Mamba for Real-world Video Super-resolution, https://arxiv.org/pdf/2506.01037, 2025-06-01
2025-11-12 01:40:37,987 - INFO - root - Page:3, Index:33, ArtiScene: Language-Driven Artistic 3D Scene Generation Through Image Intermediary, https://arxiv.org/pdf/2506.00742, 2025-05-31
2025-11-12 01:40:37,992 - INFO - root - Page:3, Index:34, 3D Gaussian Splat Vulnerabilities, https://arxiv.org/pdf/2506.00280, 2025-05-30
2025-11-12 01:40:37,998 - INFO - root - Page:3, Index:35, EgoVIS@CVPR: What Changed and What Could Have Changed? State-Change Counterfactuals for Procedure-Aware Video Representation Learning, https://arxiv.org/pdf/2506.00101, 2025-09-26
2025-11-12 01:40:37,999 - INFO - root - Page:3, Index:36, CL-LoRA: Continual Low-Rank Adaptation for Rehearsal-Free Class-Incremental Learning, https://arxiv.org/pdf/2505.24816, 2025-05-30
2025-11-12 01:40:38,001 - INFO - root - Page:3, Index:37, PatchDEMUX: A Certifiably Robust Framework for Multi-label Classifiers Against Adversarial Patches, https://arxiv.org/pdf/2505.24703, 2025-05-30
2025-11-12 01:40:38,001 - INFO - root - Page:3, Index:38, Conformal Prediction for Zero-Shot Models, https://arxiv.org/pdf/2505.24693, 2025-05-30
2025-11-12 01:40:38,001 - INFO - root - Page:3, Index:39, Learning reusable concepts across different egocentric video understanding tasks, https://arxiv.org/pdf/2505.24690, 2025-05-30
2025-11-12 01:40:38,002 - INFO - root - Page:3, Index:40, Period-LLM: Extending the Periodic Capability of Multimodal Large Language Model, https://arxiv.org/pdf/2505.24476, 2025-05-30
2025-11-12 01:40:38,002 - INFO - root - Page:3, Index:41, PCIE_Interaction Solution for Ego4D Social Interaction Challenge, https://arxiv.org/pdf/2505.24404, 2025-05-30
2025-11-12 01:40:38,003 - INFO - root - Page:3, Index:42, Leadership Assessment in Pediatric Intensive Care Unit Team Training, https://arxiv.org/pdf/2505.24389, 2025-08-28
2025-11-12 01:40:38,003 - INFO - root - Page:3, Index:43, Interpreting Large Text-to-Image Diffusion Models with Dictionary Learning, https://arxiv.org/pdf/2505.24360, 2025-07-10
2025-11-12 01:40:38,003 - INFO - root - Page:3, Index:44, InteractAnything: Zero-shot Human Object Interaction Synthesis via LLM Feedback and Object Affordance Parsing, https://arxiv.org/pdf/2505.24315, 2025-05-30
2025-11-12 01:40:38,005 - INFO - root - Page:3, Index:45, MaskAdapt: Unsupervised Geometry-Aware Domain Adaptation Using Multimodal Contextual Learning and RGB-Depth Masking, https://arxiv.org/pdf/2505.24026, 2025-05-29
2025-11-12 01:40:38,005 - INFO - root - Page:3, Index:46, Argus: Vision-Centric Reasoning with Grounded Chain-of-Thought, https://arxiv.org/pdf/2505.23766, 2025-05-29
2025-11-12 01:40:38,005 - INFO - root - Page:3, Index:47, Sketch Down the FLOPs: Towards Efficient Networks for Human Sketch, https://arxiv.org/pdf/2505.23763, 2025-05-29
2025-11-12 01:40:38,006 - INFO - root - Page:3, Index:48, Boosting Domain Incremental Learning: Selecting the Optimal Parameters is All You Need, https://arxiv.org/pdf/2505.23744, 2025-05-29
2025-11-12 01:40:38,006 - INFO - root - Page:3, Index:49, DA-VPT: Semantic-Guided Visual Prompt Tuning for Vision Transformers, https://arxiv.org/pdf/2505.23694, 2025-06-01
2025-11-12 01:40:38,006 - INFO - root - Fetching page 5 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=200
2025-11-12 01:41:09,137 - INFO - root - get_all_titles_from_web 
2025-11-12 01:41:09,137 - INFO - root - Page:4, Index:0, Bridging Classical and Modern Computer Vision: PerceptiveNet for Tree Crown Semantic Segmentation, https://arxiv.org/pdf/2505.23597, 2025-05-29
2025-11-12 01:41:09,137 - INFO - root - Page:4, Index:1, Synthetic Generation and Latent Projection Denoising of Rim Lesions in Multiple Sclerosis, https://arxiv.org/pdf/2505.23353, 2025-05-29
2025-11-12 01:41:09,138 - INFO - root - Page:4, Index:2, Wav2Sem: Plug-and-Play Audio Semantic Decoupling for 3D Speech-Driven Facial Animation, https://arxiv.org/pdf/2505.23290, 2025-05-29
2025-11-12 01:41:09,138 - INFO - root - Page:4, Index:3, Proximal Algorithm Unrolling: Flexible and Efficient Reconstruction Networks for Single-Pixel Imaging, https://arxiv.org/pdf/2505.23180, 2025-05-29
2025-11-12 01:41:09,138 - INFO - root - Page:4, Index:4, HMAD: Advancing E2E Driving with Anchored Offset Proposals and Simulation-Supervised Multi-target Scoring, https://arxiv.org/pdf/2505.23129, 2025-05-29
2025-11-12 01:41:09,138 - INFO - root - Page:4, Index:5, URWKV: Unified RWKV Model with Multi-state Perspective for Low-light Image Restoration, https://arxiv.org/pdf/2505.23068, 2025-05-29
2025-11-12 01:41:09,139 - INFO - root - Page:4, Index:6, 4DTAM: Non-Rigid Tracking and Mapping via Dynamic Surface Gaussians, https://arxiv.org/pdf/2505.22859, 2025-05-28
2025-11-12 01:41:09,139 - INFO - root - Page:4, Index:7, A Probabilistic Jump-Diffusion Framework for Open-World Egocentric Activity Recognition, https://arxiv.org/pdf/2505.22858, 2025-05-28
2025-11-12 01:41:09,139 - INFO - root - Page:4, Index:8, PS4PRO: Pixel-to-pixel Supervision for Photorealistic Rendering and Optimization, https://arxiv.org/pdf/2505.22616, 2025-05-28
2025-11-12 01:41:09,139 - INFO - root - Page:4, Index:9, Universal Domain Adaptation for Semantic Segmentation, https://arxiv.org/pdf/2505.22458, 2025-06-05
2025-11-12 01:41:09,140 - INFO - root - Page:4, Index:10, Zero-Shot 3D Visual Grounding from Vision-Language Models, https://arxiv.org/pdf/2505.22429, 2025-05-28
2025-11-12 01:41:09,140 - INFO - root - Page:4, Index:11, RC-AutoCalib: An End-to-End Radar-Camera Automatic Calibration Network, https://arxiv.org/pdf/2505.22427, 2025-05-28
2025-11-12 01:41:09,140 - INFO - root - Page:4, Index:12, Bringing CLIP to the Clinic: Dynamic Soft Labels and Negation-Aware Learning for Medical Analysis, https://arxiv.org/pdf/2505.22079, 2025-05-28
2025-11-12 01:41:09,140 - INFO - root - Page:4, Index:13, Point-to-Region Loss for Semi-Supervised Point-Based Crowd Counting, https://arxiv.org/pdf/2505.21943, 2025-05-27
2025-11-12 01:41:09,141 - INFO - root - Page:4, Index:14, FRAMES-VQA: Benchmarking Fine-Tuning Robustness across Multi-Modal Shifts in Visual Question Answering, https://arxiv.org/pdf/2505.21755, 2025-06-20
2025-11-12 01:41:09,142 - INFO - root - Page:4, Index:15, Knowledge Distillation Approach for SOS Fusion Staging: Towards Fully Automated Skeletal Maturity Assessment, https://arxiv.org/pdf/2505.21561, 2025-05-26
2025-11-12 01:41:09,142 - INFO - root - Page:4, Index:16, Enhancing Vision Transformer Explainability Using Artificial Astrocytes, https://arxiv.org/pdf/2505.21513, 2025-05-20
2025-11-12 01:41:09,143 - INFO - root - Page:4, Index:17, Empowering Vector Graphics with Consistently Arbitrary Viewing and View-dependent Visibility, https://arxiv.org/pdf/2505.21377, 2025-05-27
2025-11-12 01:41:09,143 - INFO - root - Page:4, Index:18, Structure from Collision, https://arxiv.org/pdf/2505.21335, 2025-05-27
2025-11-12 01:41:09,143 - INFO - root - Page:4, Index:19, Boosting Adversarial Transferability via High-Frequency Augmentation and Hierarchical-Gradient Fusion, https://arxiv.org/pdf/2505.21181, 2025-05-27
2025-11-12 01:41:09,144 - INFO - root - Page:4, Index:20, RefAV: Towards Planning-Centric Scenario Mining, https://arxiv.org/pdf/2505.20981, 2025-06-18
2025-11-12 01:41:09,144 - INFO - root - Page:4, Index:21, PMA: Towards Parameter-Efficient Point Cloud Understanding via Point Mamba Adapter, https://arxiv.org/pdf/2505.20941, 2025-05-27
2025-11-12 01:41:09,144 - INFO - root - Page:4, Index:22, HuMoCon: Concept Discovery for Human Motion Understanding, https://arxiv.org/pdf/2505.20920, 2025-05-27
2025-11-12 01:41:09,146 - INFO - root - Page:4, Index:23, Exploring Timeline Control for Facial Motion Generation, https://arxiv.org/pdf/2505.20861, 2025-05-27
2025-11-12 01:41:09,146 - INFO - root - Page:4, Index:24, ConText-CIR: Learning from Concepts in Text for Composed Image Retrieval, https://arxiv.org/pdf/2505.20764, 2025-05-27
2025-11-12 01:41:09,147 - INFO - root - Page:4, Index:25, HCQA-1.5 @ Ego4D EgoSchema Challenge 2025, https://arxiv.org/pdf/2505.20644, 2025-05-26
2025-11-12 01:41:09,148 - INFO - root - Page:4, Index:26, Roboflow100-VL: A Multi-Domain Object Detection Benchmark for Vision-Language Models, https://arxiv.org/pdf/2505.20612, 2025-10-22
2025-11-12 01:41:09,149 - INFO - root - Page:4, Index:27, MotionPro: A Precise Motion Controller for Image-to-Video Generation, https://arxiv.org/pdf/2505.20287, 2025-05-26
2025-11-12 01:41:09,150 - INFO - root - Page:4, Index:28, Category-Agnostic Neural Object Rigging, https://arxiv.org/pdf/2505.20283, 2025-05-26
2025-11-12 01:41:09,150 - INFO - root - Page:4, Index:29, Towards Video to Piano Music Generation with Chain-of-Perform Support Benchmarks, https://arxiv.org/pdf/2505.20038, 2025-05-26
2025-11-12 01:41:09,153 - INFO - root - Page:4, Index:30, Can Visual Encoder Learn to See Arrows?, https://arxiv.org/pdf/2505.19944, 2025-05-26
2025-11-12 01:41:09,154 - INFO - root - Page:4, Index:31, GoLF-NRT: Integrating Global Context and Local Geometry for Few-Shot View Synthesis, https://arxiv.org/pdf/2505.19813, 2025-05-26
2025-11-12 01:41:09,155 - INFO - root - Page:4, Index:32, Depth-Guided Bundle Sampling for Efficient Generalizable Neural Radiance Field Reconstruction, https://arxiv.org/pdf/2505.19793, 2025-05-26
2025-11-12 01:41:09,155 - INFO - root - Page:4, Index:33, SuperAD: A Training-free Anomaly Classification and Segmentation Method for CVPR 2025 VAND 3.0 Workshop Challenge Track 1: Adapt & Detect, https://arxiv.org/pdf/2505.19750, 2025-05-27
2025-11-12 01:41:09,156 - INFO - root - Page:4, Index:34, Knowledge-Aligned Counterfactual-Enhancement Diffusion Perception for Unsupervised Cross-Domain Visual Emotion Recognition, https://arxiv.org/pdf/2505.19694, 2025-05-26
2025-11-12 01:41:09,156 - INFO - root - Page:4, Index:35, Rotation-Equivariant Self-Supervised Method in Image Denoising, https://arxiv.org/pdf/2505.19618, 2025-05-26
2025-11-12 01:41:09,156 - INFO - root - Page:4, Index:36, NTIRE 2025 Challenge on Video Quality Enhancement for Video Conferencing: Datasets, Methods and Results, https://arxiv.org/pdf/2505.18988, 2025-05-25
2025-11-12 01:41:09,157 - INFO - root - Page:4, Index:37, Geometry-guided Online 3D Video Synthesis with Multi-View Temporal Consistency, https://arxiv.org/pdf/2505.18932, 2025-05-24
2025-11-12 01:41:09,158 - INFO - root - Page:4, Index:38, Digital Overconsumption and Waste: A Closer Look at the Impacts of Generative AI, https://arxiv.org/pdf/2505.18894, 2025-05-24
2025-11-12 01:41:09,160 - INFO - root - Page:4, Index:39, VISTA: Vision-Language Inference for Training-Free Stock Time-Series Analysis, https://arxiv.org/pdf/2505.18570, 2025-06-11
2025-11-12 01:41:09,161 - INFO - root - Page:4, Index:40, Syn3DTxt: Embedding 3D Cues for Scene Text Generation, https://arxiv.org/pdf/2505.18479, 2025-05-23
2025-11-12 01:41:09,165 - INFO - root - Page:4, Index:41, CTRL-GS: Cascaded Temporal Residue Learning for 4D Gaussian Splatting, https://arxiv.org/pdf/2505.18306, 2025-05-31
2025-11-12 01:41:09,165 - INFO - root - Page:4, Index:42, DualTalk: Dual-Speaker Interaction for 3D Talking Head Conversations, https://arxiv.org/pdf/2505.18096, 2025-05-26
2025-11-12 01:41:09,166 - INFO - root - Page:4, Index:43, SeaLion: Semantic Part-Aware Latent Point Diffusion Models for 3D Generation, https://arxiv.org/pdf/2505.17721, 2025-07-07
2025-11-12 01:41:09,168 - INFO - root - Page:4, Index:44, PoseBH: Prototypical Multi-Dataset Training Beyond Human Pose Estimation, https://arxiv.org/pdf/2505.17475, 2025-05-23
2025-11-12 01:41:09,168 - INFO - root - Page:4, Index:45, Pursuing Temporal-Consistent Video Virtual Try-On via Dynamic Pose Interaction, https://arxiv.org/pdf/2505.16980, 2025-05-22
2025-11-12 01:41:09,168 - INFO - root - Page:4, Index:46, UniPhy: Learning a Unified Constitutive Model for Inverse Physics Simulation, https://arxiv.org/pdf/2505.16971, 2025-05-22
2025-11-12 01:41:09,169 - INFO - root - Page:4, Index:47, Tracking the Flight: Exploring a Computational Framework for Analyzing Escape Responses in Plains Zebra (Equus quagga), https://arxiv.org/pdf/2505.16882, 2025-05-23
2025-11-12 01:41:09,169 - INFO - root - Page:4, Index:48, Semi-Supervised State-Space Model with Dynamic Stacking Filter for Real-World Video Deraining, https://arxiv.org/pdf/2505.16811, 2025-05-22
2025-11-12 01:41:09,171 - INFO - root - Page:4, Index:49, SOLVE: Synergy of Language-Vision and End-to-End Networks for Autonomous Driving, https://arxiv.org/pdf/2505.16805, 2025-05-22
2025-11-12 01:41:09,172 - INFO - root - Fetching page 6 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=250
2025-11-12 01:41:42,866 - INFO - root - get_all_titles_from_web 
2025-11-12 01:41:42,866 - INFO - root - Page:5, Index:0, Four Eyes Are Better Than Two: Harnessing the Collaborative Potential of Large Models via Differentiated Thinking and Complementary Ensembles, https://arxiv.org/pdf/2505.16784, 2025-06-07
2025-11-12 01:41:42,867 - INFO - root - Page:5, Index:1, Single Domain Generalization for Few-Shot Counting via Universal Representation Matching, https://arxiv.org/pdf/2505.16778, 2025-05-22
2025-11-12 01:41:42,867 - INFO - root - Page:5, Index:2, Seeing Far and Clearly: Mitigating Hallucinations in MLLMs with Attention Causal Decoding, https://arxiv.org/pdf/2505.16652, 2025-06-07
2025-11-12 01:41:42,867 - INFO - root - Page:5, Index:3, Sketchy Bounding-box Supervision for 3D Instance Segmentation, https://arxiv.org/pdf/2505.16399, 2025-05-22
2025-11-12 01:41:42,867 - INFO - root - Page:5, Index:4, DeCafNet: Delegate and Conquer for Efficient Temporal Grounding in Long Videos, https://arxiv.org/pdf/2505.16376, 2025-05-22
2025-11-12 01:41:42,868 - INFO - root - Page:5, Index:5, NTIRE 2025 challenge on Text to Image Generation Model Quality Assessment, https://arxiv.org/pdf/2505.16314, 2025-05-22
2025-11-12 01:41:42,868 - INFO - root - Page:5, Index:6, Analyzing Hierarchical Structure in Vision Models with Sparse Autoencoders, https://arxiv.org/pdf/2505.15970, 2025-05-21
2025-11-12 01:41:42,868 - INFO - root - Page:5, Index:7, Efficient Data Driven Mixture-of-Expert Extraction from Trained Networks, https://arxiv.org/pdf/2505.15414, 2025-05-21
2025-11-12 01:41:42,868 - INFO - root - Page:5, Index:8, Mouse Lockbox Dataset: Behavior Recognition for Mice Solving Lockboxes, https://arxiv.org/pdf/2505.15408, 2025-06-17
2025-11-12 01:41:42,868 - INFO - root - Page:5, Index:9, Zero-Shot Gaze-based Volumetric Medical Image Segmentation, https://arxiv.org/pdf/2505.15256, 2025-06-10
2025-11-12 01:41:42,870 - INFO - root - Page:5, Index:10, Dual Precision Quantization for Efficient and Accurate Deep Neural Networks Inference, https://arxiv.org/pdf/2505.14638, 2025-05-20
2025-11-12 01:41:42,870 - INFO - root - Page:5, Index:11, Neural Video Compression with Context Modulation, https://arxiv.org/pdf/2505.14541, 2025-05-20
2025-11-12 01:41:42,870 - INFO - root - Page:5, Index:12, Selective Structured State Space for Multispectral-fused Small Target Detection, https://arxiv.org/pdf/2505.14043, 2025-05-23
2025-11-12 01:41:42,870 - INFO - root - Page:5, Index:13, OmniStyle: Filtering High Quality Style Transfer Data at Scale, https://arxiv.org/pdf/2505.14028, 2025-05-20
2025-11-12 01:41:42,871 - INFO - root - Page:5, Index:14, Domain Adaptation of VLM for Soccer Video Understanding, https://arxiv.org/pdf/2505.13860, 2025-07-07
2025-11-12 01:41:42,871 - INFO - root - Page:5, Index:15, Ground-V: Teaching VLMs to Ground Complex Instructions in Pixels, https://arxiv.org/pdf/2505.13788, 2025-05-19
2025-11-12 01:41:42,871 - INFO - root - Page:5, Index:16, FinePhys: Fine-grained Human Action Generation by Explicitly Incorporating Physical Laws for Effective Skeletal Guidance, https://arxiv.org/pdf/2505.13437, 2025-05-19
2025-11-12 01:41:42,871 - INFO - root - Page:5, Index:17, The Way Up: A Dataset for Hold Usage Detection in Sport Climbing, https://arxiv.org/pdf/2505.12854, 2025-05-19
2025-11-12 01:41:42,872 - INFO - root - Page:5, Index:18, PEER pressure: Model-to-Model Regularization for Single Source Domain Generalization, https://arxiv.org/pdf/2505.12745, 2025-05-19
2025-11-12 01:41:42,872 - INFO - root - Page:5, Index:19, Mamba-Adaptor: State Space Model Adaptor for Visual Recognition, https://arxiv.org/pdf/2505.12685, 2025-05-19
2025-11-12 01:41:42,872 - INFO - root - Page:5, Index:20, Scalable Video-to-Dataset Generation for Cross-Platform Mobile Agents, https://arxiv.org/pdf/2505.12632, 2025-05-18
2025-11-12 01:41:42,873 - INFO - root - Page:5, Index:21, Degradation-Aware Feature Perturbation for All-in-One Image Restoration, https://arxiv.org/pdf/2505.12630, 2025-05-18
2025-11-12 01:41:42,873 - INFO - root - Page:5, Index:22, Guiding Diffusion with Deep Geometric Moments: Balancing Fidelity and Variation, https://arxiv.org/pdf/2505.12486, 2025-05-18
2025-11-12 01:41:42,873 - INFO - root - Page:5, Index:23, Learning to Highlight Audio by Watching Movies, https://arxiv.org/pdf/2505.12154, 2025-05-17
2025-11-12 01:41:42,874 - INFO - root - Page:5, Index:24, Understanding the Capabilities of Molecular Graph Neural Networks in Materials Science Through Multimodal Learning and Physical Context Encoding, https://arxiv.org/pdf/2505.12137, 2025-05-17
2025-11-12 01:41:42,874 - INFO - root - Page:5, Index:25, iSegMan: Interactive Segment-and-Manipulate 3D Gaussians, https://arxiv.org/pdf/2505.11934, 2025-05-17
2025-11-12 01:41:42,875 - INFO - root - Page:5, Index:26, Self-Learning Hyperspectral and Multispectral Image Fusion via Adaptive Residual Guided Subspace Diffusion Model, https://arxiv.org/pdf/2505.11800, 2025-05-16
2025-11-12 01:41:42,875 - INFO - root - Page:5, Index:27, X-Edit: Detecting and Localizing Edits in Images Altered by Text-Guided Diffusion Models, https://arxiv.org/pdf/2505.11753, 2025-05-16
2025-11-12 01:41:42,875 - INFO - root - Page:5, Index:28, MTevent: A Multi-Task Event Camera Dataset for 6D Pose Estimation and Moving Object Detection, https://arxiv.org/pdf/2505.11282, 2025-06-02
2025-11-12 01:41:42,878 - INFO - root - Page:5, Index:29, Imputation-free and Alignment-free: Incomplete Multi-view Clustering Driven by Consensus Semantic Learning, https://arxiv.org/pdf/2505.11182, 2025-05-16
2025-11-12 01:41:42,878 - INFO - root - Page:5, Index:30, MultiLink: Multi-class Structure Recovery via Agglomerative Clustering and Model Selection, https://arxiv.org/pdf/2505.10874, 2025-05-16
2025-11-12 01:41:42,880 - INFO - root - Page:5, Index:31, RefPose: Leveraging Reference Geometric Correspondences for Accurate 6D Pose Estimation of Unseen Objects, https://arxiv.org/pdf/2505.10841, 2025-05-16
2025-11-12 01:41:42,880 - INFO - root - Page:5, Index:32, PosterO: Structuring Layout Trees to Enable Language Models in Generalized Content-Aware Layout Generation, https://arxiv.org/pdf/2505.07843, 2025-05-26
2025-11-12 01:41:42,880 - INFO - root - Page:5, Index:33, Prototype Augmented Hypernetworks for Continual Learning, https://arxiv.org/pdf/2505.07450, 2025-05-16
2025-11-12 01:41:42,880 - INFO - root - Fetching page 7 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=300
2025-11-12 01:42:14,996 - INFO - root - get_all_titles_from_web 
2025-11-12 01:42:14,996 - INFO - root - Page:6, Index:0, Convex Relaxation for Robust Vanishing Point Estimation in Manhattan World, https://arxiv.org/pdf/2505.04788, 2025-06-05
2025-11-12 01:42:14,996 - INFO - root - Page:6, Index:1, S3D: Sketch-Driven 3D Model Generation, https://arxiv.org/pdf/2505.04185, 2025-06-03
2025-11-12 01:42:14,996 - INFO - root - Page:6, Index:2, Generating Synthetic Data via Augmentations for Improved Facial Resemblance in DreamBooth and InstantID, https://arxiv.org/pdf/2505.03557, 2025-07-17
2025-11-12 01:42:14,996 - INFO - root - Page:6, Index:3, CAV-MAE Sync: Improving Contrastive Audio-Visual Mask Autoencoders via Fine-Grained Alignment, https://arxiv.org/pdf/2505.01237, 2025-05-21
2025-11-12 01:42:14,996 - INFO - root - Fetching page 8 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=350
2025-11-12 01:42:51,619 - INFO - root - get_all_titles_from_web 
2025-11-12 01:42:51,620 - INFO - root - Page:7, Index:0, Where's the liability in the Generative Era? Recovery-based Black-Box Detection of AI-Generated Content, https://arxiv.org/pdf/2505.01008, 2025-08-25
2025-11-12 01:42:51,620 - INFO - root - Page:7, Index:1, SpatialLLM: A Compound 3D-Informed Design towards Spatially-Intelligent Large Multimodal Models, https://arxiv.org/pdf/2505.00788, 2025-06-10
2025-11-12 01:42:51,620 - INFO - root - Page:7, Index:2, Prisma: An Open Source Toolkit for Mechanistic Interpretability in Vision and Video, https://arxiv.org/pdf/2504.19475, 2025-06-03
2025-11-12 01:42:51,620 - INFO - root - Page:7, Index:3, SSL4Eco: A Global Seasonal Dataset for Geospatial Foundation Models in Ecology, https://arxiv.org/pdf/2504.18256, 2025-10-20
2025-11-12 01:42:51,621 - INFO - root - Page:7, Index:4, Vision-Language Models Are Not Pragmatically Competent in Referring Expression Generation, https://arxiv.org/pdf/2504.16060, 2025-07-30
2025-11-12 01:42:51,621 - INFO - root - Fetching page 9 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=400
2025-11-12 01:43:17,894 - INFO - root - get_all_titles_from_web 
2025-11-12 01:43:17,894 - INFO - root - Page:8, Index:0, Leveraging Automatic CAD Annotations for Supervised Learning in 3D Scene Understanding, https://arxiv.org/pdf/2504.13580, 2025-05-16
2025-11-12 01:43:17,895 - INFO - root - Page:8, Index:1, CAP-Net: A Unified Network for 6D Pose and Size Estimation of Categorical Articulated Parts from a Single RGB-D Image, https://arxiv.org/pdf/2504.11230, 2025-06-02
2025-11-12 01:43:17,895 - INFO - root - Page:8, Index:2, Video Summarization with Large Language Models, https://arxiv.org/pdf/2504.11199, 2025-06-05
2025-11-12 01:43:17,895 - INFO - root - Page:8, Index:3, R-TPT: Improving Adversarial Robustness of Vision-Language Models through Test-Time Prompt Tuning, https://arxiv.org/pdf/2504.11195, 2025-08-27
2025-11-12 01:43:17,896 - INFO - root - Page:8, Index:4, TerraMesh: A Planetary Mosaic of Multimodal Earth Observation Data, https://arxiv.org/pdf/2504.11172, 2025-08-01
2025-11-12 01:43:17,896 - INFO - root - Page:8, Index:5, Seeing like a Cephalopod: Colour Vision with a Monochrome Event Camera, https://arxiv.org/pdf/2504.10984, 2025-06-06
2025-11-12 01:43:17,896 - INFO - root - Page:8, Index:6, Hearing Anywhere in Any Environment, https://arxiv.org/pdf/2504.10746, 2025-06-04
2025-11-12 01:43:17,896 - INFO - root - Fetching page 10 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=450
2025-11-12 01:43:46,848 - INFO - root - get_all_titles_from_web 
2025-11-12 01:43:46,848 - INFO - root - Page:9, Index:0, Correlative and Discriminative Label Grouping for Multi-Label Visual Prompt Tuning, https://arxiv.org/pdf/2504.09990, 2025-07-09
2025-11-12 01:43:46,849 - INFO - root - Page:9, Index:1, SPICE: A Synergistic, Precise, Iterative, and Customizable Image Editing Workflow, https://arxiv.org/pdf/2504.09697, 2025-10-16
2025-11-12 01:43:46,849 - INFO - root - Page:9, Index:2, Mimic In-Context Learning for Multimodal Tasks, https://arxiv.org/pdf/2504.08851, 2025-05-17
2025-11-12 01:43:46,849 - INFO - root - Page:9, Index:3, Digital Twin Catalog: A Large-Scale Photorealistic 3D Object Digital Twin Dataset, https://arxiv.org/pdf/2504.08541, 2025-05-18
2025-11-12 01:43:46,849 - INFO - root - Page:9, Index:4, MMLA: Multi-Environment, Multi-Species, Low-Altitude Drone Dataset, https://arxiv.org/pdf/2504.07744, 2025-10-22
2025-11-12 01:43:46,850 - INFO - root - Fetching page 11 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=500
2025-11-12 01:44:34,077 - INFO - root - get_all_titles_from_web 
2025-11-12 01:44:34,077 - INFO - root - Page:10, Index:0, PromptHMR: Promptable Human Mesh Recovery, https://arxiv.org/pdf/2504.06397, 2025-05-23
2025-11-12 01:44:34,077 - INFO - root - Page:10, Index:1, SCAM: A Real-World Typographic Robustness Evaluation for Multimodal Foundation Models, https://arxiv.org/pdf/2504.04893, 2025-09-26
2025-11-12 01:44:34,077 - INFO - root - Fetching page 12 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=550
2025-11-12 01:45:19,497 - INFO - root - get_all_titles_from_web 
2025-11-12 01:45:19,497 - INFO - root - Page:11, Index:0, T*: Re-thinking Temporal Search for Long-Form Video Understanding, https://arxiv.org/pdf/2504.02259, 2025-08-24
2025-11-12 01:45:19,499 - INFO - root - Page:11, Index:1, CoMatcher: Multi-View Collaborative Feature Matching, https://arxiv.org/pdf/2504.01872, 2025-08-20
2025-11-12 01:45:19,499 - INFO - root - Page:11, Index:2, Think Small, Act Big: Primitive Prompt Learning for Lifelong Robot Manipulation, https://arxiv.org/pdf/2504.00420, 2025-06-01
2025-11-12 01:45:19,499 - INFO - root - Fetching page 13 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=600
2025-11-12 01:45:20,606 - INFO - root - ------------------------------------------------------------------------------------------------------------------------
2025-11-12 01:45:20,609 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\CVPR 2025\Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness.pdf
2025-11-12 01:45:20,622 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\CVPR 2025\OmniTrack++_ Omnidirectional Multi-Object Tracking by Learning Large-FoV Traject.pdf
2025-11-12 01:45:20,625 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\CVPR 2025\NeuCo-Bench_ A Novel Benchmark Framework for Neural Embeddings in Earth Observat.pdf
2025-11-12 01:45:20,631 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\CVPR 2025\NTIRE 2025 Challenge on Low Light Image Enhancement_ Methods and Results.pdf
2025-11-12 01:45:20,633 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\CVPR 2025\Class Prototypes based Contrastive Learning for Classifying Multi-Label and Fine.pdf
2025-11-12 01:45:20,636 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\CVPR 2025\MIMO_ A medical vision language model with visual referring multimodal input and.pdf
2025-11-12 01:45:20,637 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\CVPR 2025\Vision Language Models_ A Survey of 26K Papers.pdf
2025-11-12 01:45:20,640 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\CVPR 2025\DiT-VTON_ Diffusion Transformer Framework for Unified Multi-Category Virtual Try.pdf
2025-11-12 01:45:20,642 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\CVPR 2025\PatchVSR_ Breaking Video Diffusion Resolution Limits with Patch-wise Video Super.pdf
2025-11-12 01:45:20,643 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\CVPR 2025\FreqDebias_ Towards Generalizable Deepfake Detection via Consistency-Driven Freq.pdf
2025-11-12 01:45:20,650 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\CVPR 2025\A Mutual Learning Method for Salient Object Detection with intertwined Multi-Sup.pdf
2025-11-12 01:45:20,653 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\CVPR 2025\InstructVTON_ Optimal Auto-Masking and Natural-Language-Guided Interactive Style.pdf
2025-11-12 01:45:20,655 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\CVPR 2025\Efficient Encoder-Free Pose Conditioning and Pose Control for Virtual Try-On.pdf
2025-11-12 01:45:20,656 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\CVPR 2025\The Photographer Eye_ Teaching Multimodal Large Language Models to Understand Im.pdf
2025-11-12 01:45:20,657 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\CVPR 2025\ENSAM_ an efficient foundation model for interactive segmentation of 3D medical.pdf
2025-11-12 01:45:20,657 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\CVPR 2025\DEFT-VTON_ Efficient Virtual Try-On with Consistent Generalised H-Transform.pdf
2025-11-12 01:45:20,658 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\CVPR 2025\Weakly and Self-Supervised Class-Agnostic Motion Prediction for Autonomous Drivi.pdf
2025-11-12 01:45:20,658 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\CVPR 2025\Domain-Adaptive Pretraining Improves Primate Behavior Recognition.pdf
2025-11-12 01:45:20,658 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\CVPR 2025\The System Description of CPS Team for Track on Driving with Language of CVPR 20.pdf
2025-11-12 01:45:20,664 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\CVPR 2025\An HMM-based framework for identity-aware long-term multi-object tracking from s.pdf
2025-11-12 01:45:20,666 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\CVPR 2025\InterAct_ Advancing Large-Scale Versatile 3D Human-Object Interaction Generation.pdf
2025-11-12 01:45:20,667 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\CVPR 2025\Geospatial Foundational Embedder_ Top-1 Winning Solution on EarthVision Embed2Sc.pdf
2025-11-12 01:45:20,668 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\CVPR 2025\2nd Place Solution for CVPR2024 E2E Challenge_ End-to-End Autonomous Driving Usi.pdf
2025-11-12 01:45:20,669 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\CVPR 2025\Unsupervised Training of Vision Transformers with Synthetic Negatives.pdf
2025-11-12 01:45:20,672 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\CVPR 2025\MV-SSM_ Multi-View State Space Modeling for 3D Human Pose Estimation.pdf
2025-11-12 01:45:20,672 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\CVPR 2025\CryptoFace_ End-to-End Encrypted Face Recognition.pdf
2025-11-12 01:45:20,675 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\CVPR 2025\ControlEchoSynth_ Boosting Ejection Fraction Estimation Models via Controlled Vi.pdf
2025-11-12 01:45:20,675 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\CVPR 2025\Explain Before You Answer_ A Survey on Compositional Visual Reasoning.pdf
2025-11-12 01:45:20,677 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\CVPR 2025\Investigating Different Geo Priors for Image Classification.pdf
2025-11-12 01:45:20,681 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\CVPR 2025\Towards Source-Free Machine Unlearning.pdf
2025-11-12 01:45:20,685 - INFO - root - 跳过已处理论文 Learning to Seek Evidence: A Verifiable Reasoning Agent with Causal Faithfulness Analysis：d:\ChatPaper\academic Papers\CVPR 2025\Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness.pdf
2025-11-12 01:45:20,685 - INFO - root - 跳过已处理论文 OmniTrack++: Omnidirectional Multi-Object Tracking by Learning Large-FoV Trajectory Feedback：d:\ChatPaper\academic Papers\CVPR 2025\OmniTrack++_ Omnidirectional Multi-Object Tracking by Learning Large-FoV Traject.pdf
2025-11-12 01:45:20,686 - INFO - root - 跳过已处理论文 NeuCo-Bench: A Novel Benchmark Framework for Neural Embeddings in Earth Observation：d:\ChatPaper\academic Papers\CVPR 2025\NeuCo-Bench_ A Novel Benchmark Framework for Neural Embeddings in Earth Observat.pdf
2025-11-12 01:45:20,686 - INFO - root - 跳过已处理论文 NTIRE 2025 Challenge on Low Light Image Enhancement: Methods and Results：d:\ChatPaper\academic Papers\CVPR 2025\NTIRE 2025 Challenge on Low Light Image Enhancement_ Methods and Results.pdf
2025-11-12 01:45:20,687 - INFO - root - 跳过已处理论文 Class Prototypes based Contrastive Learning for Classifying Multi-Label and Fine-Grained Educational Videos：d:\ChatPaper\academic Papers\CVPR 2025\Class Prototypes based Contrastive Learning for Classifying Multi-Label and Fine.pdf
2025-11-12 01:45:20,689 - INFO - root - 跳过已处理论文 MIMO: A medical vision language model with visual referring multimodal input and pixel grounding multimodal output：d:\ChatPaper\academic Papers\CVPR 2025\MIMO_ A medical vision language model with visual referring multimodal input and.pdf
2025-11-12 01:45:20,689 - INFO - root - 跳过已处理论文 Vision Language Models: A Survey of 26K Papers：d:\ChatPaper\academic Papers\CVPR 2025\Vision Language Models_ A Survey of 26K Papers.pdf
2025-11-12 01:45:20,690 - INFO - root - 跳过已处理论文 DiT-VTON: Diffusion Transformer Framework for Unified Multi-Category Virtual Try-On and Virtual Try-All with Integrated Image Editing：d:\ChatPaper\academic Papers\CVPR 2025\DiT-VTON_ Diffusion Transformer Framework for Unified Multi-Category Virtual Try.pdf
2025-11-12 01:45:20,690 - INFO - root - 跳过已处理论文 PatchVSR: Breaking Video Diffusion Resolution Limits with Patch-wise Video Super-Resolution：d:\ChatPaper\academic Papers\CVPR 2025\PatchVSR_ Breaking Video Diffusion Resolution Limits with Patch-wise Video Super.pdf
2025-11-12 01:45:20,690 - INFO - root - 跳过已处理论文 FreqDebias: Towards Generalizable Deepfake Detection via Consistency-Driven Frequency Debiasing：d:\ChatPaper\academic Papers\CVPR 2025\FreqDebias_ Towards Generalizable Deepfake Detection via Consistency-Driven Freq.pdf
2025-11-12 01:45:20,691 - INFO - root - 跳过已处理论文 A Mutual Learning Method for Salient Object Detection with intertwined Multi-Supervision--Revised：d:\ChatPaper\academic Papers\CVPR 2025\A Mutual Learning Method for Salient Object Detection with intertwined Multi-Sup.pdf
2025-11-12 01:45:20,691 - INFO - root - 跳过已处理论文 InstructVTON: Optimal Auto-Masking and Natural-Language-Guided Interactive Style Control for Inpainting-Based Virtual Try-On：d:\ChatPaper\academic Papers\CVPR 2025\InstructVTON_ Optimal Auto-Masking and Natural-Language-Guided Interactive Style.pdf
2025-11-12 01:45:20,691 - INFO - root - 跳过已处理论文 Efficient Encoder-Free Pose Conditioning and Pose Control for Virtual Try-On：d:\ChatPaper\academic Papers\CVPR 2025\Efficient Encoder-Free Pose Conditioning and Pose Control for Virtual Try-On.pdf
2025-11-12 01:45:20,692 - INFO - root - 跳过已处理论文 The Photographer Eye: Teaching Multimodal Large Language Models to Understand Image Aesthetics like Photographers：d:\ChatPaper\academic Papers\CVPR 2025\The Photographer Eye_ Teaching Multimodal Large Language Models to Understand Im.pdf
2025-11-12 01:45:20,693 - INFO - root - 正在总结论文 15/30: ENSAM: an efficient foundation model for interactive segmentation of 3D medical images
2025-11-12 01:45:30,796 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 01:46:05,571 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 01:46:05,579 - INFO - root - LLMClient: rate limit reached, sleeping 15.1s
2025-11-12 01:46:46,344 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 01:46:46,346 - INFO - root - 正在提取论文图片到目录: ./export\CVPR 2026\images
2025-11-12 01:46:46,878 - INFO - root - 已保存图片 1/10：./export\CVPR 2026\images\figure_1_page4.png
2025-11-12 01:46:47,007 - INFO - root - 已保存图片 2/10：./export\CVPR 2026\images\figure_2_page4.png
2025-11-12 01:46:47,069 - INFO - root - 已保存图片 3/10：./export\CVPR 2026\images\figure_3_page16.png
2025-11-12 01:46:47,134 - INFO - root - 已保存图片 4/10：./export\CVPR 2026\images\figure_4_page15.png
2025-11-12 01:46:47,193 - INFO - root - 已保存图片 5/10：./export\CVPR 2026\images\figure_5_page15.png
2025-11-12 01:46:47,260 - INFO - root - 已保存图片 6/10：./export\CVPR 2026\images\figure_6_page16.png
2025-11-12 01:46:47,305 - INFO - root - 已保存图片 7/10：./export\CVPR 2026\images\figure_7_page14.png
2025-11-12 01:46:47,316 - INFO - root - 成功添加图片 1：./export\CVPR 2026\images\figure_1_page4.png
2025-11-12 01:46:47,318 - INFO - root - 成功添加图片 2：./export\CVPR 2026\images\figure_2_page4.png
2025-11-12 01:46:47,318 - INFO - root - 成功添加图片 3：./export\CVPR 2026\images\figure_3_page16.png
2025-11-12 01:46:47,318 - INFO - root - 成功添加图片 4：./export\CVPR 2026\images\figure_4_page15.png
2025-11-12 01:46:47,319 - INFO - root - 成功添加图片 5：./export\CVPR 2026\images\figure_5_page15.png
2025-11-12 01:46:47,320 - INFO - root - 成功添加图片 6：./export\CVPR 2026\images\figure_6_page16.png
2025-11-12 01:46:47,320 - INFO - root - 成功添加图片 7：./export\CVPR 2026\images\figure_7_page14.png
2025-11-12 01:46:47,324 - INFO - root - 已更新图片链接
2025-11-12 01:46:47,327 - INFO - root - 论文《ENSAM: an efficient foundation model for interactive segmentation of 3D medical images》的分析已保存到 ./export\CVPR 2026\ENSAM_ an efficient foundation model for interactive segmentation of 3D medical.md
2025-11-12 01:46:47,330 - INFO - root - 正在总结论文 16/30: DEFT-VTON: Efficient Virtual Try-On with Consistent Generalised H-Transform
2025-11-12 01:46:57,431 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 01:46:57,432 - INFO - root - LLMClient: rate limit reached, sleeping 23.3s
2025-11-12 01:48:10,238 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 01:48:53,295 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 01:48:53,295 - INFO - root - 正在提取论文图片到目录: ./export\CVPR 2026\images
2025-11-12 01:49:01,041 - INFO - root - 已保存图片 1/10：./export\CVPR 2026\images\figure_1_page13.png
2025-11-12 01:49:01,224 - INFO - root - 已保存图片 2/10：./export\CVPR 2026\images\figure_2_page4.png
2025-11-12 01:49:01,395 - INFO - root - 已保存图片 3/10：./export\CVPR 2026\images\figure_3_page3.png
2025-11-12 01:49:01,524 - INFO - root - 已保存图片 4/10：./export\CVPR 2026\images\figure_4_page2.jpeg
2025-11-12 01:49:01,601 - INFO - root - 已保存图片 5/10：./export\CVPR 2026\images\figure_5_page4.png
2025-11-12 01:49:01,734 - INFO - root - 已保存图片 6/10：./export\CVPR 2026\images\figure_6_page8.png
2025-11-12 01:49:01,852 - INFO - root - 已保存图片 7/10：./export\CVPR 2026\images\figure_7_page7.png
2025-11-12 01:49:01,871 - INFO - root - 成功添加图片 1：./export\CVPR 2026\images\figure_1_page13.png
2025-11-12 01:49:01,871 - INFO - root - 成功添加图片 2：./export\CVPR 2026\images\figure_2_page4.png
2025-11-12 01:49:01,871 - INFO - root - 成功添加图片 3：./export\CVPR 2026\images\figure_3_page3.png
2025-11-12 01:49:01,871 - INFO - root - 成功添加图片 4：./export\CVPR 2026\images\figure_4_page2.jpeg
2025-11-12 01:49:01,871 - INFO - root - 成功添加图片 5：./export\CVPR 2026\images\figure_5_page4.png
2025-11-12 01:49:01,871 - INFO - root - 成功添加图片 6：./export\CVPR 2026\images\figure_6_page8.png
2025-11-12 01:49:01,871 - INFO - root - 成功添加图片 7：./export\CVPR 2026\images\figure_7_page7.png
2025-11-12 01:49:01,871 - INFO - root - 已更新图片链接
2025-11-12 01:49:01,893 - INFO - root - 论文《DEFT-VTON: Efficient Virtual Try-On with Consistent Generalised H-Transform》的分析已保存到 ./export\CVPR 2026\DEFT-VTON_ Efficient Virtual Try-On with Consistent Generalised H-Transform.md
2025-11-12 01:49:01,895 - INFO - root - 正在总结论文 17/30: Weakly and Self-Supervised Class-Agnostic Motion Prediction for Autonomous Driving
2025-11-12 01:49:17,025 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 01:50:12,964 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 01:50:50,385 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 01:50:50,385 - INFO - root - 正在提取论文图片到目录: ./export\CVPR 2026\images
2025-11-12 01:50:52,698 - INFO - root - 已保存图片 1/10：./export\CVPR 2026\images\figure_1_page13.png
2025-11-12 01:50:52,795 - INFO - root - 已保存图片 2/10：./export\CVPR 2026\images\figure_2_page13.png
2025-11-12 01:50:52,881 - INFO - root - 已保存图片 3/10：./export\CVPR 2026\images\figure_3_page13.png
2025-11-12 01:50:52,959 - INFO - root - 已保存图片 4/10：./export\CVPR 2026\images\figure_4_page13.png
2025-11-12 01:50:53,065 - INFO - root - 已保存图片 5/10：./export\CVPR 2026\images\figure_5_page13.png
2025-11-12 01:50:53,243 - INFO - root - 已保存图片 6/10：./export\CVPR 2026\images\figure_6_page13.png
2025-11-12 01:50:53,398 - INFO - root - 已保存图片 7/10：./export\CVPR 2026\images\figure_7_page2.png
2025-11-12 01:50:53,589 - INFO - root - 已保存图片 8/10：./export\CVPR 2026\images\figure_8_page2.png
2025-11-12 01:50:53,692 - INFO - root - 已保存图片 9/10：./export\CVPR 2026\images\figure_9_page2.png
2025-11-12 01:50:53,766 - INFO - root - 已保存图片 10/10：./export\CVPR 2026\images\figure_10_page2.png
2025-11-12 01:50:53,773 - INFO - root - 成功添加图片 1：./export\CVPR 2026\images\figure_1_page13.png
2025-11-12 01:50:53,774 - INFO - root - 成功添加图片 2：./export\CVPR 2026\images\figure_2_page13.png
2025-11-12 01:50:53,774 - INFO - root - 成功添加图片 3：./export\CVPR 2026\images\figure_3_page13.png
2025-11-12 01:50:53,775 - INFO - root - 成功添加图片 4：./export\CVPR 2026\images\figure_4_page13.png
2025-11-12 01:50:53,775 - INFO - root - 成功添加图片 5：./export\CVPR 2026\images\figure_5_page13.png
2025-11-12 01:50:53,776 - INFO - root - 成功添加图片 6：./export\CVPR 2026\images\figure_6_page13.png
2025-11-12 01:50:53,776 - INFO - root - 成功添加图片 7：./export\CVPR 2026\images\figure_7_page2.png
2025-11-12 01:50:53,776 - INFO - root - 成功添加图片 8：./export\CVPR 2026\images\figure_8_page2.png
2025-11-12 01:50:53,776 - INFO - root - 成功添加图片 9：./export\CVPR 2026\images\figure_9_page2.png
2025-11-12 01:50:53,776 - INFO - root - 成功添加图片 10：./export\CVPR 2026\images\figure_10_page2.png
2025-11-12 01:50:53,783 - INFO - root - 已更新图片链接
2025-11-12 01:50:53,789 - INFO - root - 论文《Weakly and Self-Supervised Class-Agnostic Motion Prediction for Autonomous Driving》的分析已保存到 ./export\CVPR 2026\Weakly and Self-Supervised Class-Agnostic Motion Prediction for Autonomous Drivi.md
2025-11-12 01:50:53,792 - INFO - root - 正在总结论文 18/30: Domain-Adaptive Pretraining Improves Primate Behavior Recognition
2025-11-12 01:51:04,799 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 01:51:04,801 - INFO - root - LLMClient: rate limit reached, sleeping 8.2s
2025-11-12 01:51:50,570 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 01:51:50,575 - INFO - root - LLMClient: rate limit reached, sleeping 3.2s
2025-11-12 01:52:19,248 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 01:52:19,251 - INFO - root - 正在提取论文图片到目录: ./export\CVPR 2026\images
2025-11-12 01:52:19,545 - INFO - root - 已保存图片 1/10：./export\CVPR 2026\images\figure_1_page1.png
2025-11-12 01:52:19,683 - INFO - root - 已保存图片 2/10：./export\CVPR 2026\images\figure_2_page1.png
2025-11-12 01:52:19,893 - INFO - root - 已保存图片 3/10：./export\CVPR 2026\images\figure_3_page1.png
2025-11-12 01:52:19,894 - INFO - root - 成功添加图片 1：./export\CVPR 2026\images\figure_1_page1.png
2025-11-12 01:52:19,895 - INFO - root - 成功添加图片 2：./export\CVPR 2026\images\figure_2_page1.png
2025-11-12 01:52:19,895 - INFO - root - 成功添加图片 3：./export\CVPR 2026\images\figure_3_page1.png
2025-11-12 01:52:19,901 - INFO - root - 已更新图片链接
2025-11-12 01:52:19,904 - INFO - root - 论文《Domain-Adaptive Pretraining Improves Primate Behavior Recognition》的分析已保存到 ./export\CVPR 2026\Domain-Adaptive Pretraining Improves Primate Behavior Recognition.md
2025-11-12 01:52:19,905 - INFO - root - 正在总结论文 19/30: The System Description of CPS Team for Track on Driving with Language of CVPR 2024 Autonomous Grand Challenge
2025-11-12 01:52:29,314 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 01:52:29,317 - INFO - root - LLMClient: rate limit reached, sleeping 24.5s
2025-11-12 01:53:38,092 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 01:54:06,938 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 01:54:06,941 - INFO - root - 正在提取论文图片到目录: ./export\CVPR 2026\images
2025-11-12 01:54:07,285 - INFO - root - 已保存图片 1/10：./export\CVPR 2026\images\figure_1_page3.jpeg
2025-11-12 01:54:07,331 - INFO - root - 已保存图片 2/10：./export\CVPR 2026\images\figure_2_page3.jpeg
2025-11-12 01:54:07,377 - INFO - root - 已保存图片 3/10：./export\CVPR 2026\images\figure_3_page3.jpeg
2025-11-12 01:54:07,424 - INFO - root - 已保存图片 4/10：./export\CVPR 2026\images\figure_4_page3.jpeg
2025-11-12 01:54:07,467 - INFO - root - 已保存图片 5/10：./export\CVPR 2026\images\figure_5_page3.jpeg
2025-11-12 01:54:07,512 - INFO - root - 已保存图片 6/10：./export\CVPR 2026\images\figure_6_page3.jpeg
2025-11-12 01:54:07,589 - INFO - root - 已保存图片 7/10：./export\CVPR 2026\images\figure_7_page3.png
2025-11-12 01:54:07,634 - INFO - root - 已保存图片 8/10：./export\CVPR 2026\images\figure_8_page3.jpeg
2025-11-12 01:54:07,678 - INFO - root - 已保存图片 9/10：./export\CVPR 2026\images\figure_9_page3.jpeg
2025-11-12 01:54:07,727 - INFO - root - 已保存图片 10/10：./export\CVPR 2026\images\figure_10_page3.jpeg
2025-11-12 01:54:07,733 - INFO - root - 成功添加图片 1：./export\CVPR 2026\images\figure_1_page3.jpeg
2025-11-12 01:54:07,733 - INFO - root - 成功添加图片 2：./export\CVPR 2026\images\figure_2_page3.jpeg
2025-11-12 01:54:07,734 - INFO - root - 成功添加图片 3：./export\CVPR 2026\images\figure_3_page3.jpeg
2025-11-12 01:54:07,735 - INFO - root - 成功添加图片 4：./export\CVPR 2026\images\figure_4_page3.jpeg
2025-11-12 01:54:07,735 - INFO - root - 成功添加图片 5：./export\CVPR 2026\images\figure_5_page3.jpeg
2025-11-12 01:54:07,736 - INFO - root - 成功添加图片 6：./export\CVPR 2026\images\figure_6_page3.jpeg
2025-11-12 01:54:07,736 - INFO - root - 成功添加图片 7：./export\CVPR 2026\images\figure_7_page3.png
2025-11-12 01:54:07,737 - INFO - root - 成功添加图片 8：./export\CVPR 2026\images\figure_8_page3.jpeg
2025-11-12 01:54:07,738 - INFO - root - 成功添加图片 9：./export\CVPR 2026\images\figure_9_page3.jpeg
2025-11-12 01:54:07,738 - INFO - root - 成功添加图片 10：./export\CVPR 2026\images\figure_10_page3.jpeg
2025-11-12 01:54:07,749 - INFO - root - 已更新图片链接
2025-11-12 01:54:07,752 - INFO - root - 论文《The System Description of CPS Team for Track on Driving with Language of CVPR 2024 Autonomous Grand Challenge》的分析已保存到 ./export\CVPR 2026\The System Description of CPS Team for Track on Driving with Language of CVPR 20.md
2025-11-12 01:54:07,754 - INFO - root - 正在总结论文 20/30: An HMM-based framework for identity-aware long-term multi-object tracking from sparse and uncertain identification: use case on long-term tracking in livestock
2025-11-12 01:54:20,857 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 01:54:20,861 - INFO - root - LLMClient: rate limit reached, sleeping 17.2s
2025-11-12 01:55:42,259 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 01:56:11,431 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 01:56:11,432 - INFO - root - 正在提取论文图片到目录: ./export\CVPR 2026\images
2025-11-12 01:56:13,147 - INFO - root - 已保存图片 1/10：./export\CVPR 2026\images\figure_1_page6.png
2025-11-12 01:56:13,436 - INFO - root - 已保存图片 2/10：./export\CVPR 2026\images\figure_2_page3.png
2025-11-12 01:56:13,817 - INFO - root - 已保存图片 3/10：./export\CVPR 2026\images\figure_3_page9.png
2025-11-12 01:56:13,921 - INFO - root - 已保存图片 4/10：./export\CVPR 2026\images\figure_4_page5.png
2025-11-12 01:56:14,015 - INFO - root - 已保存图片 5/10：./export\CVPR 2026\images\figure_5_page8.png
2025-11-12 01:56:14,065 - INFO - root - 已保存图片 6/10：./export\CVPR 2026\images\figure_6_page9.png
2025-11-12 01:56:14,119 - INFO - root - 已保存图片 7/10：./export\CVPR 2026\images\figure_7_page12.png
2025-11-12 01:56:14,184 - INFO - root - 已保存图片 8/10：./export\CVPR 2026\images\figure_8_page12.png
2025-11-12 01:56:14,252 - INFO - root - 已保存图片 9/10：./export\CVPR 2026\images\figure_9_page12.png
2025-11-12 01:56:14,341 - INFO - root - 已保存图片 10/10：./export\CVPR 2026\images\figure_10_page12.png
2025-11-12 01:56:14,370 - INFO - root - 成功添加图片 1：./export\CVPR 2026\images\figure_1_page6.png
2025-11-12 01:56:14,375 - INFO - root - 成功添加图片 2：./export\CVPR 2026\images\figure_2_page3.png
2025-11-12 01:56:14,376 - INFO - root - 成功添加图片 3：./export\CVPR 2026\images\figure_3_page9.png
2025-11-12 01:56:14,377 - INFO - root - 成功添加图片 4：./export\CVPR 2026\images\figure_4_page5.png
2025-11-12 01:56:14,378 - INFO - root - 成功添加图片 5：./export\CVPR 2026\images\figure_5_page8.png
2025-11-12 01:56:14,378 - INFO - root - 成功添加图片 6：./export\CVPR 2026\images\figure_6_page9.png
2025-11-12 01:56:14,379 - INFO - root - 成功添加图片 7：./export\CVPR 2026\images\figure_7_page12.png
2025-11-12 01:56:14,379 - INFO - root - 成功添加图片 8：./export\CVPR 2026\images\figure_8_page12.png
2025-11-12 01:56:14,380 - INFO - root - 成功添加图片 9：./export\CVPR 2026\images\figure_9_page12.png
2025-11-12 01:56:14,381 - INFO - root - 成功添加图片 10：./export\CVPR 2026\images\figure_10_page12.png
2025-11-12 01:56:14,391 - INFO - root - 已更新图片链接
2025-11-12 01:56:14,394 - INFO - root - 论文《An HMM-based framework for identity-aware long-term multi-object tracking from sparse and uncertain identification: use case on long-term tracking in livestock》的分析已保存到 ./export\CVPR 2026\An HMM-based framework for identity-aware long-term multi-object tracking from s.md
2025-11-12 01:56:14,397 - INFO - root - 正在总结论文 21/30: InterAct: Advancing Large-Scale Versatile 3D Human-Object Interaction Generation
2025-11-12 01:56:26,700 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 01:56:26,701 - INFO - root - LLMClient: rate limit reached, sleeping 15.6s
2025-11-12 01:57:34,275 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 01:58:07,656 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 01:58:07,657 - INFO - root - 正在提取论文图片到目录: ./export\CVPR 2026\images
2025-11-12 01:58:10,854 - INFO - root - 已保存图片 1/10：./export\CVPR 2026\images\figure_1_page6.png
2025-11-12 01:58:10,934 - INFO - root - 已保存图片 2/10：./export\CVPR 2026\images\figure_2_page8.png
2025-11-12 01:58:11,005 - INFO - root - 已保存图片 3/10：./export\CVPR 2026\images\figure_3_page7.png
2025-11-12 01:58:11,119 - INFO - root - 已保存图片 4/10：./export\CVPR 2026\images\figure_4_page2.png
2025-11-12 01:58:11,236 - INFO - root - 已保存图片 5/10：./export\CVPR 2026\images\figure_5_page2.png
2025-11-12 01:58:11,295 - INFO - root - 已保存图片 6/10：./export\CVPR 2026\images\figure_6_page2.png
2025-11-12 01:58:11,349 - INFO - root - 已保存图片 7/10：./export\CVPR 2026\images\figure_7_page2.png
2025-11-12 01:58:11,419 - INFO - root - 已保存图片 8/10：./export\CVPR 2026\images\figure_8_page1.png
2025-11-12 01:58:11,494 - INFO - root - 已保存图片 9/10：./export\CVPR 2026\images\figure_9_page1.png
2025-11-12 01:58:11,568 - INFO - root - 已保存图片 10/10：./export\CVPR 2026\images\figure_10_page1.png
2025-11-12 01:58:11,575 - INFO - root - 成功添加图片 1：./export\CVPR 2026\images\figure_1_page6.png
2025-11-12 01:58:11,576 - INFO - root - 成功添加图片 2：./export\CVPR 2026\images\figure_2_page8.png
2025-11-12 01:58:11,576 - INFO - root - 成功添加图片 3：./export\CVPR 2026\images\figure_3_page7.png
2025-11-12 01:58:11,576 - INFO - root - 成功添加图片 4：./export\CVPR 2026\images\figure_4_page2.png
2025-11-12 01:58:11,577 - INFO - root - 成功添加图片 5：./export\CVPR 2026\images\figure_5_page2.png
2025-11-12 01:58:11,577 - INFO - root - 成功添加图片 6：./export\CVPR 2026\images\figure_6_page2.png
2025-11-12 01:58:11,578 - INFO - root - 成功添加图片 7：./export\CVPR 2026\images\figure_7_page2.png
2025-11-12 01:58:11,578 - INFO - root - 成功添加图片 8：./export\CVPR 2026\images\figure_8_page1.png
2025-11-12 01:58:11,579 - INFO - root - 成功添加图片 9：./export\CVPR 2026\images\figure_9_page1.png
2025-11-12 01:58:11,579 - INFO - root - 成功添加图片 10：./export\CVPR 2026\images\figure_10_page1.png
2025-11-12 01:58:11,586 - INFO - root - 已更新图片链接
2025-11-12 01:58:11,588 - INFO - root - 论文《InterAct: Advancing Large-Scale Versatile 3D Human-Object Interaction Generation》的分析已保存到 ./export\CVPR 2026\InterAct_ Advancing Large-Scale Versatile 3D Human-Object Interaction Generation.md
2025-11-12 01:58:11,590 - INFO - root - 正在总结论文 22/30: Geospatial Foundational Embedder: Top-1 Winning Solution on EarthVision Embed2Scale Challenge (CVPR 2025)
2025-11-12 01:58:27,636 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 01:58:27,637 - INFO - root - LLMClient: rate limit reached, sleeping 6.6s
2025-11-12 01:59:24,882 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 01:59:55,689 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 01:59:55,693 - INFO - root - 正在提取论文图片到目录: ./export\CVPR 2026\images
2025-11-12 01:59:56,602 - INFO - root - 已保存图片 1/10：./export\CVPR 2026\images\figure_1_page1.png
2025-11-12 01:59:56,665 - INFO - root - 已保存图片 2/10：./export\CVPR 2026\images\figure_2_page3.png
2025-11-12 01:59:56,669 - INFO - root - 成功添加图片 1：./export\CVPR 2026\images\figure_1_page1.png
2025-11-12 01:59:56,669 - INFO - root - 成功添加图片 2：./export\CVPR 2026\images\figure_2_page3.png
2025-11-12 01:59:56,672 - INFO - root - 已更新图片链接
2025-11-12 01:59:56,675 - INFO - root - 论文《Geospatial Foundational Embedder: Top-1 Winning Solution on EarthVision Embed2Scale Challenge (CVPR 2025)》的分析已保存到 ./export\CVPR 2026\Geospatial Foundational Embedder_ Top-1 Winning Solution on EarthVision Embed2Sc.md
2025-11-12 01:59:56,678 - INFO - root - 正在总结论文 23/30: 2nd Place Solution for CVPR2024 E2E Challenge: End-to-End Autonomous Driving Using Vision Language Model
2025-11-12 02:00:05,084 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 02:00:05,086 - INFO - root - LLMClient: rate limit reached, sleeping 19.8s
2025-11-12 02:01:11,815 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 02:01:41,225 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 02:01:41,227 - INFO - root - 正在提取论文图片到目录: ./export\CVPR 2026\images
2025-11-12 02:01:41,828 - INFO - root - 已保存图片 1/10：./export\CVPR 2026\images\figure_1_page3.png
2025-11-12 02:01:41,994 - INFO - root - 已保存图片 2/10：./export\CVPR 2026\images\figure_2_page3.png
2025-11-12 02:01:41,997 - INFO - root - 成功添加图片 1：./export\CVPR 2026\images\figure_1_page3.png
2025-11-12 02:01:41,998 - INFO - root - 成功添加图片 2：./export\CVPR 2026\images\figure_2_page3.png
2025-11-12 02:01:42,005 - INFO - root - 已更新图片链接
2025-11-12 02:01:42,010 - INFO - root - 论文《2nd Place Solution for CVPR2024 E2E Challenge: End-to-End Autonomous Driving Using Vision Language Model》的分析已保存到 ./export\CVPR 2026\2nd Place Solution for CVPR2024 E2E Challenge_ End-to-End Autonomous Driving Usi.md
2025-11-12 02:01:42,014 - INFO - root - 正在总结论文 24/30: Unsupervised Training of Vision Transformers with Synthetic Negatives
2025-11-12 02:01:54,901 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 02:01:54,904 - INFO - root - LLMClient: rate limit reached, sleeping 16.9s
2025-11-12 02:03:17,118 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 02:04:22,705 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 02:04:22,706 - INFO - root - 正在提取论文图片到目录: ./export\CVPR 2026\images
2025-11-12 02:04:23,017 - INFO - root - 已保存图片 1/10：./export\CVPR 2026\images\figure_1_page1.png
2025-11-12 02:04:23,353 - INFO - root - 已保存图片 2/10：./export\CVPR 2026\images\figure_2_page1.png
2025-11-12 02:04:23,653 - INFO - root - 已保存图片 3/10：./export\CVPR 2026\images\figure_3_page1.png
2025-11-12 02:04:23,756 - INFO - root - 已保存图片 4/10：./export\CVPR 2026\images\figure_4_page1.png
2025-11-12 02:04:23,959 - INFO - root - 已保存图片 5/10：./export\CVPR 2026\images\figure_5_page1.png
2025-11-12 02:04:24,016 - INFO - root - 已保存图片 6/10：./export\CVPR 2026\images\figure_6_page1.png
2025-11-12 02:04:24,082 - INFO - root - 已保存图片 7/10：./export\CVPR 2026\images\figure_7_page1.png
2025-11-12 02:04:24,329 - INFO - root - 已保存图片 8/10：./export\CVPR 2026\images\figure_8_page1.png
2025-11-12 02:04:24,387 - INFO - root - 已保存图片 9/10：./export\CVPR 2026\images\figure_9_page1.png
2025-11-12 02:04:24,443 - INFO - root - 已保存图片 10/10：./export\CVPR 2026\images\figure_10_page1.png
2025-11-12 02:04:24,443 - INFO - root - 成功添加图片 1：./export\CVPR 2026\images\figure_1_page1.png
2025-11-12 02:04:24,445 - INFO - root - 成功添加图片 2：./export\CVPR 2026\images\figure_2_page1.png
2025-11-12 02:04:24,446 - INFO - root - 成功添加图片 3：./export\CVPR 2026\images\figure_3_page1.png
2025-11-12 02:04:24,447 - INFO - root - 成功添加图片 4：./export\CVPR 2026\images\figure_4_page1.png
2025-11-12 02:04:24,447 - INFO - root - 成功添加图片 5：./export\CVPR 2026\images\figure_5_page1.png
2025-11-12 02:04:24,448 - INFO - root - 成功添加图片 6：./export\CVPR 2026\images\figure_6_page1.png
2025-11-12 02:04:24,448 - INFO - root - 成功添加图片 7：./export\CVPR 2026\images\figure_7_page1.png
2025-11-12 02:04:24,448 - INFO - root - 成功添加图片 8：./export\CVPR 2026\images\figure_8_page1.png
2025-11-12 02:04:24,449 - INFO - root - 成功添加图片 9：./export\CVPR 2026\images\figure_9_page1.png
2025-11-12 02:04:24,450 - INFO - root - 成功添加图片 10：./export\CVPR 2026\images\figure_10_page1.png
2025-11-12 02:04:24,454 - INFO - root - 已更新图片链接
2025-11-12 02:04:24,459 - INFO - root - 论文《Unsupervised Training of Vision Transformers with Synthetic Negatives》的分析已保存到 ./export\CVPR 2026\Unsupervised Training of Vision Transformers with Synthetic Negatives.md
2025-11-12 02:04:24,461 - INFO - root - 正在总结论文 25/30: MV-SSM: Multi-View State Space Modeling for 3D Human Pose Estimation
2025-11-12 02:04:35,215 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 02:05:27,461 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 02:05:58,049 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 02:05:58,050 - INFO - root - 正在提取论文图片到目录: ./export\CVPR 2026\images
2025-11-12 02:05:58,860 - INFO - root - 已保存图片 1/10：./export\CVPR 2026\images\figure_1_page8.jpeg
2025-11-12 02:05:59,069 - INFO - root - 已保存图片 2/10：./export\CVPR 2026\images\figure_2_page5.jpeg
2025-11-12 02:05:59,255 - INFO - root - 已保存图片 3/10：./export\CVPR 2026\images\figure_3_page1.jpeg
2025-11-12 02:05:59,384 - INFO - root - 已保存图片 4/10：./export\CVPR 2026\images\figure_4_page4.jpeg
2025-11-12 02:05:59,398 - INFO - root - 成功添加图片 1：./export\CVPR 2026\images\figure_1_page8.jpeg
2025-11-12 02:05:59,399 - INFO - root - 成功添加图片 2：./export\CVPR 2026\images\figure_2_page5.jpeg
2025-11-12 02:05:59,400 - INFO - root - 成功添加图片 3：./export\CVPR 2026\images\figure_3_page1.jpeg
2025-11-12 02:05:59,400 - INFO - root - 成功添加图片 4：./export\CVPR 2026\images\figure_4_page4.jpeg
2025-11-12 02:05:59,409 - INFO - root - 已更新图片链接
2025-11-12 02:05:59,411 - INFO - root - 论文《MV-SSM: Multi-View State Space Modeling for 3D Human Pose Estimation》的分析已保存到 ./export\CVPR 2026\MV-SSM_ Multi-View State Space Modeling for 3D Human Pose Estimation.md
2025-11-12 02:05:59,415 - INFO - root - 正在总结论文 26/30: CryptoFace: End-to-End Encrypted Face Recognition
2025-11-12 02:06:07,882 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 02:06:07,884 - INFO - root - LLMClient: rate limit reached, sleeping 19.6s
2025-11-12 02:07:04,938 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 02:07:36,653 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 02:07:36,656 - INFO - root - 正在提取论文图片到目录: ./export\CVPR 2026\images
2025-11-12 02:07:36,818 - INFO - root - 已保存图片 1/10：./export\CVPR 2026\images\figure_1_page4.png
2025-11-12 02:07:36,872 - INFO - root - 已保存图片 2/10：./export\CVPR 2026\images\figure_2_page4.png
2025-11-12 02:07:36,929 - INFO - root - 已保存图片 3/10：./export\CVPR 2026\images\figure_3_page4.png
2025-11-12 02:07:37,014 - INFO - root - 已保存图片 4/10：./export\CVPR 2026\images\figure_4_page5.png
2025-11-12 02:07:37,096 - INFO - root - 已保存图片 5/10：./export\CVPR 2026\images\figure_5_page5.png
2025-11-12 02:07:37,182 - INFO - root - 已保存图片 6/10：./export\CVPR 2026\images\figure_6_page5.png
2025-11-12 02:07:37,256 - INFO - root - 已保存图片 7/10：./export\CVPR 2026\images\figure_7_page5.png
2025-11-12 02:07:37,336 - INFO - root - 已保存图片 8/10：./export\CVPR 2026\images\figure_8_page5.png
2025-11-12 02:07:37,415 - INFO - root - 已保存图片 9/10：./export\CVPR 2026\images\figure_9_page5.png
2025-11-12 02:07:37,488 - INFO - root - 已保存图片 10/10：./export\CVPR 2026\images\figure_10_page5.png
2025-11-12 02:07:37,488 - INFO - root - 成功添加图片 1：./export\CVPR 2026\images\figure_1_page4.png
2025-11-12 02:07:37,490 - INFO - root - 成功添加图片 2：./export\CVPR 2026\images\figure_2_page4.png
2025-11-12 02:07:37,490 - INFO - root - 成功添加图片 3：./export\CVPR 2026\images\figure_3_page4.png
2025-11-12 02:07:37,490 - INFO - root - 成功添加图片 4：./export\CVPR 2026\images\figure_4_page5.png
2025-11-12 02:07:37,491 - INFO - root - 成功添加图片 5：./export\CVPR 2026\images\figure_5_page5.png
2025-11-12 02:07:37,491 - INFO - root - 成功添加图片 6：./export\CVPR 2026\images\figure_6_page5.png
2025-11-12 02:07:37,491 - INFO - root - 成功添加图片 7：./export\CVPR 2026\images\figure_7_page5.png
2025-11-12 02:07:37,492 - INFO - root - 成功添加图片 8：./export\CVPR 2026\images\figure_8_page5.png
2025-11-12 02:07:37,492 - INFO - root - 成功添加图片 9：./export\CVPR 2026\images\figure_9_page5.png
2025-11-12 02:07:37,492 - INFO - root - 成功添加图片 10：./export\CVPR 2026\images\figure_10_page5.png
2025-11-12 02:07:37,497 - INFO - root - 已更新图片链接
2025-11-12 02:07:37,501 - INFO - root - 论文《CryptoFace: End-to-End Encrypted Face Recognition》的分析已保存到 ./export\CVPR 2026\CryptoFace_ End-to-End Encrypted Face Recognition.md
2025-11-12 02:07:37,504 - INFO - root - 正在总结论文 27/30: ControlEchoSynth: Boosting Ejection Fraction Estimation Models via Controlled Video Diffusion
2025-11-12 02:07:45,804 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 02:07:45,805 - INFO - root - LLMClient: rate limit reached, sleeping 19.1s
2025-11-12 02:08:45,931 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 02:09:16,878 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 02:09:16,879 - INFO - root - 正在提取论文图片到目录: ./export\CVPR 2026\images
2025-11-12 02:09:17,401 - INFO - root - 已保存图片 1/10：./export\CVPR 2026\images\figure_1_page5.png
2025-11-12 02:09:17,455 - INFO - root - 已保存图片 2/10：./export\CVPR 2026\images\figure_2_page3.png
2025-11-12 02:09:17,507 - INFO - root - 已保存图片 3/10：./export\CVPR 2026\images\figure_3_page3.png
2025-11-12 02:09:17,558 - INFO - root - 已保存图片 4/10：./export\CVPR 2026\images\figure_4_page3.png
2025-11-12 02:09:17,571 - INFO - root - 已保存图片 5/10：./export\CVPR 2026\images\figure_5_page3.png
2025-11-12 02:09:17,585 - INFO - root - 已保存图片 6/10：./export\CVPR 2026\images\figure_6_page3.png
2025-11-12 02:09:17,587 - INFO - root - 成功添加图片 1：./export\CVPR 2026\images\figure_1_page5.png
2025-11-12 02:09:17,588 - INFO - root - 成功添加图片 2：./export\CVPR 2026\images\figure_2_page3.png
2025-11-12 02:09:17,588 - INFO - root - 成功添加图片 3：./export\CVPR 2026\images\figure_3_page3.png
2025-11-12 02:09:17,589 - INFO - root - 成功添加图片 4：./export\CVPR 2026\images\figure_4_page3.png
2025-11-12 02:09:17,589 - INFO - root - 成功添加图片 5：./export\CVPR 2026\images\figure_5_page3.png
2025-11-12 02:09:17,589 - INFO - root - 成功添加图片 6：./export\CVPR 2026\images\figure_6_page3.png
2025-11-12 02:09:17,595 - INFO - root - 已更新图片链接
2025-11-12 02:09:17,598 - INFO - root - 论文《ControlEchoSynth: Boosting Ejection Fraction Estimation Models via Controlled Video Diffusion》的分析已保存到 ./export\CVPR 2026\ControlEchoSynth_ Boosting Ejection Fraction Estimation Models via Controlled Vi.md
2025-11-12 02:09:17,601 - INFO - root - 正在总结论文 28/30: Explain Before You Answer: A Survey on Compositional Visual Reasoning
2025-11-12 02:09:24,873 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 02:09:24,877 - INFO - root - LLMClient: rate limit reached, sleeping 21.1s
2025-11-12 02:10:23,664 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 02:10:41,389 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 02:10:41,391 - INFO - root - 正在提取论文图片到目录: ./export\CVPR 2026\images
2025-11-12 02:10:47,729 - INFO - root - 已保存图片 1/10：./export\CVPR 2026\images\figure_1_page9.png
2025-11-12 02:10:48,202 - INFO - root - 已保存图片 2/10：./export\CVPR 2026\images\figure_2_page12.png
2025-11-12 02:10:48,782 - INFO - root - 已保存图片 3/10：./export\CVPR 2026\images\figure_3_page8.png
2025-11-12 02:10:48,994 - INFO - root - 已保存图片 4/10：./export\CVPR 2026\images\figure_4_page13.png
2025-11-12 02:10:49,338 - INFO - root - 已保存图片 5/10：./export\CVPR 2026\images\figure_5_page10.png
2025-11-12 02:10:49,534 - INFO - root - 已保存图片 6/10：./export\CVPR 2026\images\figure_6_page17.jpeg
2025-11-12 02:10:49,776 - INFO - root - 已保存图片 7/10：./export\CVPR 2026\images\figure_7_page15.png
2025-11-12 02:10:49,994 - INFO - root - 已保存图片 8/10：./export\CVPR 2026\images\figure_8_page17.jpeg
2025-11-12 02:10:50,127 - INFO - root - 已保存图片 9/10：./export\CVPR 2026\images\figure_9_page17.jpeg
2025-11-12 02:10:50,256 - INFO - root - 已保存图片 10/10：./export\CVPR 2026\images\figure_10_page17.jpeg
2025-11-12 02:10:50,315 - INFO - root - 成功添加图片 1：./export\CVPR 2026\images\figure_1_page9.png
2025-11-12 02:10:50,315 - INFO - root - 成功添加图片 2：./export\CVPR 2026\images\figure_2_page12.png
2025-11-12 02:10:50,315 - INFO - root - 成功添加图片 3：./export\CVPR 2026\images\figure_3_page8.png
2025-11-12 02:10:50,316 - INFO - root - 成功添加图片 4：./export\CVPR 2026\images\figure_4_page13.png
2025-11-12 02:10:50,316 - INFO - root - 成功添加图片 5：./export\CVPR 2026\images\figure_5_page10.png
2025-11-12 02:10:50,316 - INFO - root - 成功添加图片 6：./export\CVPR 2026\images\figure_6_page17.jpeg
2025-11-12 02:10:50,316 - INFO - root - 成功添加图片 7：./export\CVPR 2026\images\figure_7_page15.png
2025-11-12 02:10:50,316 - INFO - root - 成功添加图片 8：./export\CVPR 2026\images\figure_8_page17.jpeg
2025-11-12 02:10:50,317 - INFO - root - 成功添加图片 9：./export\CVPR 2026\images\figure_9_page17.jpeg
2025-11-12 02:10:50,317 - INFO - root - 成功添加图片 10：./export\CVPR 2026\images\figure_10_page17.jpeg
2025-11-12 02:10:50,324 - INFO - root - 已更新图片链接
2025-11-12 02:10:50,327 - INFO - root - 论文《Explain Before You Answer: A Survey on Compositional Visual Reasoning》的分析已保存到 ./export\CVPR 2026\Explain Before You Answer_ A Survey on Compositional Visual Reasoning.md
2025-11-12 02:10:50,330 - INFO - root - 正在总结论文 29/30: Investigating Different Geo Priors for Image Classification
2025-11-12 02:10:59,296 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 02:10:59,298 - INFO - root - LLMClient: rate limit reached, sleeping 24.4s
2025-11-12 02:11:56,175 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 02:12:17,833 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 02:12:17,838 - INFO - root - 正在提取论文图片到目录: ./export\CVPR 2026\images
2025-11-12 02:12:17,869 - INFO - root - 论文《Investigating Different Geo Priors for Image Classification》的分析已保存到 ./export\CVPR 2026\Investigating Different Geo Priors for Image Classification.md
2025-11-12 02:12:17,873 - INFO - root - 正在总结论文 30/30: Towards Source-Free Machine Unlearning
2025-11-12 02:12:17,875 - INFO - root - LLMClient: rate limit reached, sleeping 5.8s
2025-11-12 02:12:39,070 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 02:12:39,075 - INFO - root - LLMClient: rate limit reached, sleeping 17.1s
2025-11-12 02:13:34,706 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 02:13:58,958 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 02:13:58,960 - INFO - root - 正在提取论文图片到目录: ./export\CVPR 2026\images
2025-11-12 02:14:00,363 - INFO - root - 已保存图片 1/10：./export\CVPR 2026\images\figure_1_page7.png
2025-11-12 02:14:00,573 - INFO - root - 已保存图片 2/10：./export\CVPR 2026\images\figure_2_page7.png
2025-11-12 02:14:00,757 - INFO - root - 已保存图片 3/10：./export\CVPR 2026\images\figure_3_page7.png
2025-11-12 02:14:00,923 - INFO - root - 已保存图片 4/10：./export\CVPR 2026\images\figure_4_page7.png
2025-11-12 02:14:00,934 - INFO - root - 成功添加图片 1：./export\CVPR 2026\images\figure_1_page7.png
2025-11-12 02:14:00,935 - INFO - root - 成功添加图片 2：./export\CVPR 2026\images\figure_2_page7.png
2025-11-12 02:14:00,936 - INFO - root - 成功添加图片 3：./export\CVPR 2026\images\figure_3_page7.png
2025-11-12 02:14:00,936 - INFO - root - 成功添加图片 4：./export\CVPR 2026\images\figure_4_page7.png
2025-11-12 02:14:00,943 - INFO - root - 已更新图片链接
2025-11-12 02:14:00,945 - INFO - root - 论文《Towards Source-Free Machine Unlearning》的分析已保存到 ./export\CVPR 2026\Towards Source-Free Machine Unlearning.md
2025-11-12 02:14:01,291 - INFO - root - 已生成汇总Excel表格: export\CVPR 2026\论文汇总_CVPR 2026_20251112_021400.xlsx
2025-11-12 02:14:01,292 - INFO - root - 已生成汇总Excel表格: export\CVPR 2026\论文汇总_CVPR 2026_20251112_021400.xlsx
2025-11-12 02:14:01,292 - INFO - root - summary time: 2145.37 seconds
2025-11-12 19:18:55,623 - WARNING - root - 在 retrieval_strategy.py 中导入 Paper 类失败。
2025-11-12 19:18:55,629 - ERROR - root - 无法导入 retrievers.py: cannot import name 'Paper' from partially initialized module 'chat_paper' (most likely due to a circular import) (D:\ChatPaper\chat_paper.py)。请确保该文件存在。
2025-11-12 19:18:55,650 - WARNING - root - Google Scholar 检索器依赖未能加载: No module named 'matplotlib'。 'scholar' 策略将不可用。
2025-11-12 19:18:55,655 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-12 19:18:55,655 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-12 19:18:55,658 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-12 19:18:59,415 - INFO - root - LLMClientManager: 指定使用客户端: Deepseek
2025-11-12 19:18:59,416 - INFO - root - DeepSeekClient: API key found: 9f9e270e-b...
2025-11-12 19:18:59,416 - INFO - root - DeepSeekClient: 使用模式: 火山引擎
2025-11-12 19:18:59,416 - INFO - root - DeepSeekClient: 模型名称: deepseek-v3-1-terminus
2025-11-12 19:19:02,386 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 19:19:02,403 - INFO - root - DeepSeekClient: initialized successfully with model deepseek-v3-1-terminus
2025-11-12 19:19:02,403 - INFO - root - LLMClientManager: DeepSeek 客户端初始化成功
2025-11-12 19:19:02,403 - INFO - root - LLMClientManager: switched to DeepSeek client (case-insensitive match)
2025-11-12 19:19:02,403 - INFO - root - 已手动切换到 LLM 客户端: Deepseek
2025-11-12 19:19:02,404 - INFO - root - 使用 LLM 模型: deepseek-v3-1-terminus
2025-11-12 19:19:02,404 - INFO - root - 可用客户端: ['DeepSeek']
2025-11-12 19:19:02,408 - INFO - root - === 运行配置 ===
2025-11-12 19:19:02,411 - INFO - root - 处理模式: Semantic Scholar 高引用搜索 (API)
2025-11-12 19:19:02,411 - INFO - root - 查询 (关键词): hybrid attention
2025-11-12 19:19:02,411 - INFO - root - 关键词 (用于保存): hybrid attention
2025-11-12 19:19:02,411 - INFO - root - 排序: citationCount:desc
2025-11-12 19:19:02,411 - INFO - root - 最大处理数量: 2
2025-11-12 19:19:02,412 - INFO - root - 保存图片: 否
2025-11-12 19:19:02,412 - INFO - root - 输出语言: 中文
2025-11-12 19:19:02,413 - INFO - root - 强制重新处理: 否
2025-11-12 19:19:02,413 - INFO - root - LLM 客户端: Deepseek
2025-11-12 19:19:02,416 - INFO - root - ====================
2025-11-12 19:19:02,416 - INFO - root - 正在使用检索策略: semantic
2025-11-12 19:19:02,417 - INFO - root - 使用 Semantic Scholar 高引用搜索模式 (API)
2025-11-12 19:19:02,417 - INFO - root - Semantic API 查询: query=hybrid attention, limit=2, sort=citationCount:desc
2025-11-12 19:19:03,983 - WARNING - root - 【手动下载提示】(Semantic Scholar 未提供开放 PDF): An Instrument Indication Acquisition Algorithm Based on Lightweight Deep Convolutional Neural Network and Hybrid Attention Fine-Grained Features @ https://www.semanticscholar.org/paper/49f99d7a21e2ded7915676753a180983763b9a22
2025-11-12 19:19:03,983 - WARNING - root - 【手动下载提示】(Semantic Scholar 未提供开放 PDF): Enhancing ASD classification through hybrid attention-based learning of facial features @ https://www.semanticscholar.org/paper/22547aa4c72c7c2799932a0f451ab3f2db6d7d0f
2025-11-12 19:19:03,990 - INFO - root - 没有找到要处理的论文，程序退出
2025-11-12 19:19:03,995 - INFO - root - 总运行时间: 8.34 seconds
2025-11-12 19:22:49,617 - WARNING - root - 在 retrieval_strategy.py 中导入 Paper 类失败。
2025-11-12 19:22:49,619 - ERROR - root - 无法导入 retrievers.py: cannot import name 'Paper' from partially initialized module 'chat_paper' (most likely due to a circular import) (D:\ChatPaper\chat_paper.py)。请确保该文件存在。
2025-11-12 19:22:49,623 - WARNING - root - Google Scholar 检索器依赖未能加载: No module named 'matplotlib'。 'scholar' 策略将不可用。
2025-11-12 19:22:49,627 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-12 19:22:49,657 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-12 19:22:49,660 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-12 19:22:53,584 - INFO - root - LLMClientManager: 指定使用客户端: Deepseek
2025-11-12 19:22:53,585 - INFO - root - DeepSeekClient: API key found: 9f9e270e-b...
2025-11-12 19:22:53,585 - INFO - root - DeepSeekClient: 使用模式: 火山引擎
2025-11-12 19:22:53,586 - INFO - root - DeepSeekClient: 模型名称: deepseek-v3-1-terminus
2025-11-12 19:22:56,509 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 19:22:56,528 - INFO - root - DeepSeekClient: initialized successfully with model deepseek-v3-1-terminus
2025-11-12 19:22:56,530 - INFO - root - LLMClientManager: DeepSeek 客户端初始化成功
2025-11-12 19:22:56,530 - INFO - root - LLMClientManager: switched to DeepSeek client (case-insensitive match)
2025-11-12 19:22:56,531 - INFO - root - 已手动切换到 LLM 客户端: Deepseek
2025-11-12 19:22:56,531 - INFO - root - 使用 LLM 模型: deepseek-v3-1-terminus
2025-11-12 19:22:56,533 - INFO - root - 可用客户端: ['DeepSeek']
2025-11-12 19:22:56,533 - INFO - root - === 运行配置 ===
2025-11-12 19:22:56,534 - INFO - root - 处理模式: Semantic Scholar 高引用搜索 (API)
2025-11-12 19:22:56,534 - INFO - root - 查询 (关键词): hybrid attention
2025-11-12 19:22:56,534 - INFO - root - 关键词 (用于保存): hybrid attention
2025-11-12 19:22:56,534 - INFO - root - 排序: citationCount:desc
2025-11-12 19:22:56,535 - INFO - root - 最大处理数量: 2
2025-11-12 19:22:56,535 - INFO - root - 保存图片: 否
2025-11-12 19:22:56,535 - INFO - root - 输出语言: 中文
2025-11-12 19:22:56,536 - INFO - root - 强制重新处理: 否
2025-11-12 19:22:56,536 - INFO - root - LLM 客户端: Deepseek
2025-11-12 19:22:56,536 - INFO - root - ====================
2025-11-12 19:22:56,536 - INFO - root - 正在使用检索策略: semantic
2025-11-12 19:22:56,536 - INFO - root - 使用 Semantic Scholar 高引用搜索模式 (API)
2025-11-12 19:22:56,537 - INFO - root - Semantic API 查询: query=hybrid attention, limit=2, sort=citationCount:desc
2025-11-12 19:22:58,806 - WARNING - root - 【手动下载提示】(Semantic Scholar 未提供开放 PDF): An Instrument Indication Acquisition Algorithm Based on Lightweight Deep Convolutional Neural Network and Hybrid Attention Fine-Grained Features @ https://www.semanticscholar.org/paper/49f99d7a21e2ded7915676753a180983763b9a22
2025-11-12 19:22:58,807 - WARNING - root - 【手动下载提示】(Semantic Scholar 未提供开放 PDF): Enhancing ASD classification through hybrid attention-based learning of facial features @ https://www.semanticscholar.org/paper/22547aa4c72c7c2799932a0f451ab3f2db6d7d0f
2025-11-12 19:22:58,810 - INFO - root - 没有找到要处理的论文，程序退出
2025-11-12 19:22:58,810 - INFO - root - 总运行时间: 9.18 seconds
2025-11-12 19:24:22,276 - WARNING - root - 在 retrieval_strategy.py 中导入 Paper 类失败。
2025-11-12 19:24:22,277 - ERROR - root - 无法导入 retrievers.py: cannot import name 'Paper' from partially initialized module 'chat_paper' (most likely due to a circular import) (D:\ChatPaper\chat_paper.py)。请确保该文件存在。
2025-11-12 19:24:22,280 - WARNING - root - Google Scholar 检索器依赖未能加载: No module named 'matplotlib'。 'scholar' 策略将不可用。
2025-11-12 19:24:22,283 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-12 19:24:22,284 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-12 19:24:22,286 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-12 19:24:25,336 - INFO - root - LLMClientManager: 指定使用客户端: Deepseek
2025-11-12 19:24:25,338 - INFO - root - DeepSeekClient: API key found: 9f9e270e-b...
2025-11-12 19:24:25,338 - INFO - root - DeepSeekClient: 使用模式: 火山引擎
2025-11-12 19:24:25,338 - INFO - root - DeepSeekClient: 模型名称: deepseek-v3-1-terminus
2025-11-12 19:24:28,486 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 19:24:28,510 - INFO - root - DeepSeekClient: initialized successfully with model deepseek-v3-1-terminus
2025-11-12 19:24:28,510 - INFO - root - LLMClientManager: DeepSeek 客户端初始化成功
2025-11-12 19:24:28,512 - INFO - root - LLMClientManager: switched to DeepSeek client (case-insensitive match)
2025-11-12 19:24:28,513 - INFO - root - 已手动切换到 LLM 客户端: Deepseek
2025-11-12 19:24:28,514 - INFO - root - 使用 LLM 模型: deepseek-v3-1-terminus
2025-11-12 19:24:28,515 - INFO - root - 可用客户端: ['DeepSeek']
2025-11-12 19:24:28,519 - INFO - root - === 运行配置 ===
2025-11-12 19:24:28,521 - INFO - root - 处理模式: Semantic Scholar 高引用搜索 (API)
2025-11-12 19:24:28,521 - INFO - root - 查询 (关键词): hybrid attention
2025-11-12 19:24:28,522 - INFO - root - 关键词 (用于保存): hybrid attention
2025-11-12 19:24:28,522 - INFO - root - 排序: citationCount:desc
2025-11-12 19:24:28,522 - INFO - root - 最大处理数量: 2
2025-11-12 19:24:28,523 - INFO - root - 保存图片: 否
2025-11-12 19:24:28,523 - INFO - root - 输出语言: 中文
2025-11-12 19:24:28,524 - INFO - root - 强制重新处理: 否
2025-11-12 19:24:28,524 - INFO - root - LLM 客户端: Deepseek
2025-11-12 19:24:28,524 - INFO - root - ====================
2025-11-12 19:24:28,525 - INFO - root - 正在使用检索策略: semantic
2025-11-12 19:24:28,525 - INFO - root - 使用 Semantic Scholar 高引用搜索模式 (API)
2025-11-12 19:24:28,527 - INFO - root - Semantic API 查询: query=hybrid attention, limit=2, sort=citationCount:desc
2025-11-12 19:24:29,763 - ERROR - root - Semantic Scholar API 请求失败: 429 Client Error:  for url: https://api.semanticscholar.org/graph/v1/paper/search?query=hybrid+attention&limit=2&sort=citationCount%3Adesc&fields=title%2Curl%2Cabstract%2Cauthors%2CpublicationDate%2CcitationCount%2CopenAccessPdf
Traceback (most recent call last):
  File "D:\ChatPaper\retrievers.py", line 246, in retrieve
    response.raise_for_status() # 请求失败则抛出异常
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\requests\models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 429 Client Error:  for url: https://api.semanticscholar.org/graph/v1/paper/search?query=hybrid+attention&limit=2&sort=citationCount%3Adesc&fields=title%2Curl%2Cabstract%2Cauthors%2CpublicationDate%2CcitationCount%2CopenAccessPdf
2025-11-12 19:24:29,774 - INFO - root - 没有找到要处理的论文，程序退出
2025-11-12 19:24:29,775 - INFO - root - 总运行时间: 7.49 seconds
2025-11-12 19:25:21,733 - WARNING - root - 在 retrieval_strategy.py 中导入 Paper 类失败。
2025-11-12 19:25:21,735 - ERROR - root - 无法导入 retrievers.py: cannot import name 'Paper' from partially initialized module 'chat_paper' (most likely due to a circular import) (D:\ChatPaper\chat_paper.py)。请确保该文件存在。
2025-11-12 19:25:21,738 - WARNING - root - Google Scholar 检索器依赖未能加载: No module named 'matplotlib'。 'scholar' 策略将不可用。
2025-11-12 19:25:21,741 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-12 19:25:21,743 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-12 19:25:21,744 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-12 19:25:25,018 - INFO - root - LLMClientManager: 指定使用客户端: Deepseek
2025-11-12 19:25:25,019 - INFO - root - DeepSeekClient: API key found: 9f9e270e-b...
2025-11-12 19:25:25,019 - INFO - root - DeepSeekClient: 使用模式: 火山引擎
2025-11-12 19:25:25,019 - INFO - root - DeepSeekClient: 模型名称: deepseek-v3-1-terminus
2025-11-12 19:25:27,514 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 19:25:27,523 - INFO - root - DeepSeekClient: initialized successfully with model deepseek-v3-1-terminus
2025-11-12 19:25:27,523 - INFO - root - LLMClientManager: DeepSeek 客户端初始化成功
2025-11-12 19:25:27,525 - INFO - root - LLMClientManager: switched to DeepSeek client (case-insensitive match)
2025-11-12 19:25:27,526 - INFO - root - 已手动切换到 LLM 客户端: Deepseek
2025-11-12 19:25:27,526 - INFO - root - 使用 LLM 模型: deepseek-v3-1-terminus
2025-11-12 19:25:27,526 - INFO - root - 可用客户端: ['DeepSeek']
2025-11-12 19:25:27,528 - INFO - root - === 运行配置 ===
2025-11-12 19:25:27,528 - INFO - root - 处理模式: Semantic Scholar 高引用搜索 (API)
2025-11-12 19:25:27,529 - INFO - root - 查询 (关键词): hybrid attention
2025-11-12 19:25:27,529 - INFO - root - 关键词 (用于保存): hybrid attention
2025-11-12 19:25:27,529 - INFO - root - 排序: citationCount:desc
2025-11-12 19:25:27,529 - INFO - root - 最大处理数量: 2
2025-11-12 19:25:27,530 - INFO - root - 保存图片: 否
2025-11-12 19:25:27,531 - INFO - root - 输出语言: 中文
2025-11-12 19:25:27,531 - INFO - root - 强制重新处理: 否
2025-11-12 19:25:27,531 - INFO - root - LLM 客户端: Deepseek
2025-11-12 19:25:27,532 - INFO - root - ====================
2025-11-12 19:25:27,532 - INFO - root - 正在使用检索策略: semantic
2025-11-12 19:25:27,533 - INFO - root - 使用 Semantic Scholar 高引用搜索模式 (API)
2025-11-12 19:25:27,533 - INFO - root - Semantic API 查询: query=hybrid attention, limit=2, sort=citationCount:desc
2025-11-12 19:25:28,987 - WARNING - root - 【手动下载提示】(Semantic Scholar 未提供开放 PDF): An Instrument Indication Acquisition Algorithm Based on Lightweight Deep Convolutional Neural Network and Hybrid Attention Fine-Grained Features @ https://www.semanticscholar.org/paper/49f99d7a21e2ded7915676753a180983763b9a22
2025-11-12 19:25:28,988 - WARNING - root - 【手动下载提示】(Semantic Scholar 未提供开放 PDF): Dual-Hybrid Attention Network for Specular Highlight Removal @ https://www.semanticscholar.org/paper/d56ce689cc0f8b1cf0e5f58882503a5e59ec440b
2025-11-12 19:25:28,995 - INFO - root - 没有找到要处理的论文，程序退出
2025-11-12 19:25:29,002 - INFO - root - 总运行时间: 7.26 seconds
2025-11-12 19:33:14,445 - WARNING - root - 在 retrieval_strategy.py 中导入 Paper 类失败。
2025-11-12 19:33:14,451 - ERROR - root - 无法导入 retrievers.py: cannot import name 'Paper' from partially initialized module 'chat_paper' (most likely due to a circular import) (D:\ChatPaper\chat_paper.py)。请确保该文件存在。
2025-11-12 19:33:14,454 - WARNING - root - Google Scholar 检索器依赖未能加载: No module named 'matplotlib'。 'scholar' 策略将不可用。
2025-11-12 19:33:14,457 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-12 19:33:14,457 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-12 19:33:14,463 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-12 19:33:18,173 - INFO - root - LLMClientManager: 指定使用客户端: Deepseek
2025-11-12 19:33:18,173 - INFO - root - DeepSeekClient: API key found: 9f9e270e-b...
2025-11-12 19:33:18,173 - INFO - root - DeepSeekClient: 使用模式: 火山引擎
2025-11-12 19:33:18,173 - INFO - root - DeepSeekClient: 模型名称: deepseek-v3-1-terminus
2025-11-12 19:33:21,196 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 19:33:21,273 - INFO - root - DeepSeekClient: initialized successfully with model deepseek-v3-1-terminus
2025-11-12 19:33:21,280 - INFO - root - LLMClientManager: DeepSeek 客户端初始化成功
2025-11-12 19:33:21,288 - INFO - root - LLMClientManager: switched to DeepSeek client (case-insensitive match)
2025-11-12 19:33:21,293 - INFO - root - 已手动切换到 LLM 客户端: Deepseek
2025-11-12 19:33:21,305 - INFO - root - 使用 LLM 模型: deepseek-v3-1-terminus
2025-11-12 19:33:21,314 - INFO - root - 可用客户端: ['DeepSeek']
2025-11-12 19:33:21,323 - INFO - root - === 运行配置 ===
2025-11-12 19:33:21,329 - INFO - root - 处理模式: Semantic Scholar 高引用搜索 (API)
2025-11-12 19:33:21,341 - INFO - root - 查询 (关键词): hybrid attention
2025-11-12 19:33:21,356 - INFO - root - 关键词 (用于保存): hybrid attention
2025-11-12 19:33:21,361 - INFO - root - 排序: citationCount:desc
2025-11-12 19:33:21,372 - INFO - root - 最大处理数量: 2
2025-11-12 19:33:21,377 - INFO - root - 保存图片: 否
2025-11-12 19:33:21,380 - INFO - root - 输出语言: 中文
2025-11-12 19:33:21,388 - INFO - root - 强制重新处理: 否
2025-11-12 19:33:21,394 - INFO - root - LLM 客户端: Deepseek
2025-11-12 19:33:21,405 - INFO - root - ====================
2025-11-12 19:33:21,408 - INFO - root - 正在使用检索策略: semantic
2025-11-12 19:33:21,409 - INFO - root - 使用 Semantic Scholar 高引用搜索模式 (API)
2025-11-12 19:33:21,419 - INFO - root - Semantic API 查询: query=hybrid attention, limit=2, sort=citationCount:desc
2025-11-12 19:33:24,186 - WARNING - root - 【手动下载提示】(Semantic Scholar 未提供开放 PDF): An Instrument Indication Acquisition Algorithm Based on Lightweight Deep Convolutional Neural Network and Hybrid Attention Fine-Grained Features @ https://www.semanticscholar.org/paper/49f99d7a21e2ded7915676753a180983763b9a22
2025-11-12 19:33:24,186 - WARNING - root - 【手动下载提示】(Semantic Scholar 未提供开放 PDF): Dual-Hybrid Attention Network for Specular Highlight Removal @ https://www.semanticscholar.org/paper/d56ce689cc0f8b1cf0e5f58882503a5e59ec440b
2025-11-12 19:33:24,193 - INFO - root - 没有找到要处理的论文，程序退出
2025-11-12 19:33:24,193 - INFO - root - 总运行时间: 9.74 seconds
2025-11-12 19:34:37,727 - WARNING - root - 在 retrieval_strategy.py 中导入 Paper 类失败。
2025-11-12 19:34:37,729 - ERROR - root - 无法导入 retrievers.py: cannot import name 'Paper' from partially initialized module 'chat_paper' (most likely due to a circular import) (D:\ChatPaper\chat_paper.py)。请确保该文件存在。
2025-11-12 19:34:37,732 - WARNING - root - Google Scholar 检索器依赖未能加载: No module named 'matplotlib'。 'scholar' 策略将不可用。
2025-11-12 19:34:37,733 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-12 19:34:37,735 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-12 19:34:37,737 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-12 19:34:41,309 - INFO - root - LLMClientManager: 指定使用客户端: Deepseek
2025-11-12 19:34:41,342 - INFO - root - DeepSeekClient: API key found: 9f9e270e-b...
2025-11-12 19:34:41,352 - INFO - root - DeepSeekClient: 使用模式: 火山引擎
2025-11-12 19:34:41,357 - INFO - root - DeepSeekClient: 模型名称: deepseek-v3-1-terminus
2025-11-12 19:34:44,352 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 19:34:44,361 - INFO - root - DeepSeekClient: initialized successfully with model deepseek-v3-1-terminus
2025-11-12 19:34:44,361 - INFO - root - LLMClientManager: DeepSeek 客户端初始化成功
2025-11-12 19:34:44,362 - INFO - root - LLMClientManager: switched to DeepSeek client (case-insensitive match)
2025-11-12 19:34:44,362 - INFO - root - 已手动切换到 LLM 客户端: Deepseek
2025-11-12 19:34:44,362 - INFO - root - 使用 LLM 模型: deepseek-v3-1-terminus
2025-11-12 19:34:44,365 - INFO - root - 可用客户端: ['DeepSeek']
2025-11-12 19:34:44,366 - INFO - root - === 运行配置 ===
2025-11-12 19:34:44,369 - INFO - root - 处理模式: Semantic Scholar 高引用搜索 (API)
2025-11-12 19:34:44,370 - INFO - root - 查询 (关键词): hybrid attention
2025-11-12 19:34:44,371 - INFO - root - 关键词 (用于保存): hybrid attention
2025-11-12 19:34:44,372 - INFO - root - 排序: citationCount:desc
2025-11-12 19:34:44,372 - INFO - root - 最大处理数量: 10
2025-11-12 19:34:44,373 - INFO - root - 保存图片: 否
2025-11-12 19:34:44,373 - INFO - root - 输出语言: 中文
2025-11-12 19:34:44,373 - INFO - root - 强制重新处理: 否
2025-11-12 19:34:44,373 - INFO - root - LLM 客户端: Deepseek
2025-11-12 19:34:44,373 - INFO - root - ====================
2025-11-12 19:34:44,375 - INFO - root - 正在使用检索策略: semantic
2025-11-12 19:34:44,375 - INFO - root - 使用 Semantic Scholar 高引用搜索模式 (API)
2025-11-12 19:34:44,375 - INFO - root - Semantic API 查询: query=hybrid attention, limit=10, sort=citationCount:desc
2025-11-12 19:34:46,840 - WARNING - root - 【手动下载提示】(Semantic Scholar 未提供开放 PDF): An Instrument Indication Acquisition Algorithm Based on Lightweight Deep Convolutional Neural Network and Hybrid Attention Fine-Grained Features @ https://www.semanticscholar.org/paper/49f99d7a21e2ded7915676753a180983763b9a22
2025-11-12 19:34:46,840 - WARNING - root - 【手动下载提示】(Semantic Scholar 未提供开放 PDF): Dual-Hybrid Attention Network for Specular Highlight Removal @ https://www.semanticscholar.org/paper/d56ce689cc0f8b1cf0e5f58882503a5e59ec440b
2025-11-12 19:34:46,840 - WARNING - root - 【手动下载提示】(Semantic Scholar 未提供开放 PDF): Enhancing ASD classification through hybrid attention-based learning of facial features @ https://www.semanticscholar.org/paper/22547aa4c72c7c2799932a0f451ab3f2db6d7d0f
2025-11-12 19:34:46,840 - WARNING - root - 【手动下载提示】(Semantic Scholar 未提供开放 PDF): HyA-GAN: remote sensing image cloud removal based on hybrid attention generation adversarial network @ https://www.semanticscholar.org/paper/905b42f2f8d912d98fd7cbec4f7b244401176acc
2025-11-12 19:34:46,840 - WARNING - root - 【手动下载提示】(Semantic Scholar 未提供开放 PDF): Radar Signal Recognition Based on CNN With a Hybrid Attention Mechanism and Skip Feature Aggregation @ https://www.semanticscholar.org/paper/dacad703c49e9434321c91220219638f871fd9d2
2025-11-12 19:34:46,840 - WARNING - root - 【手动下载提示】(Semantic Scholar 未提供开放 PDF): Hybrid Attention-Aware Transformer Network Collaborative Multiscale Feature Alignment for Building Change Detection @ https://www.semanticscholar.org/paper/a0f8053046622628073ac6f051b5181a80cb7ad3
2025-11-12 19:34:46,843 - INFO - root - 正在下载: https://ieeexplore.ieee.org/ielx7/4609443/4609444/10416333.pdf
2025-11-12 19:34:59,395 - INFO - root - 已保存到: D:\ChatPaper\myPapers\hybrid attention\Hybrid Attention Fusion Embedded in Transformer for Remote Sensing Image Semantic Segmentation.pdf
2025-11-12 19:34:59,398 - INFO - root - 成功下载 (Semantic Scholar): Hybrid Attention Fusion Embedded in Transformer for Remote Sensing Image Semantic Segmentation
2025-11-12 19:34:59,400 - WARNING - root - 【手动下载提示】(Semantic Scholar 未提供开放 PDF): Probabilistic Multienergy Load Forecasting Based on Hybrid Attention-Enabled Transformer Network and Gaussian Process-Aided Residual Learning @ https://www.semanticscholar.org/paper/a2d81cc04f73e2898fb16e7e8c8f9cf69adadfd5
2025-11-12 19:34:59,400 - WARNING - root - 【手动下载提示】(Semantic Scholar 未提供开放 PDF): Enhancing Time Series Product Demand Forecasting With Hybrid Attention-Based Deep Learning Models @ https://www.semanticscholar.org/paper/4848b35cbe515f8909a67a82dcb83d7c5e48f74b
2025-11-12 19:34:59,400 - INFO - root - 正在下载: https://www.mdpi.com/2306-5354/11/3/240/pdf?version=1709132347
2025-11-12 19:35:04,011 - INFO - root - 正在下载: https://www.mdpi.com/2306-5354/11/3/240/pdf?version=1709132347
2025-11-12 19:35:08,615 - INFO - root - 正在下载: https://www.mdpi.com/2306-5354/11/3/240/pdf?version=1709132347
2025-11-12 19:35:13,326 - INFO - root - 正在下载: https://www.mdpi.com/2306-5354/11/3/240/pdf?version=1709132347
2025-11-12 19:35:21,925 - INFO - root - 正在下载: https://www.mdpi.com/2306-5354/11/3/240/pdf?version=1709132347
2025-11-12 19:35:22,718 - WARNING - root - 下载 Advancing Ocular Imaging: A Hybrid Attention Mechanism-Based U-Net Model for Precise Segmentation of Sub-Retinal Layers in OCT Images (https://www.mdpi.com/2306-5354/11/3/240/pdf?version=1709132347) 失败: 403 Client Error: Forbidden for url: https://www.mdpi.com/2306-5354/11/3/240/pdf?version=1709132347
2025-11-12 19:35:22,719 - INFO - root - 检索到 1 篇论文，开始总结...
2025-11-12 19:55:21,068 - INFO - matplotlib.font_manager - generated new fontManager
2025-11-12 19:55:21,909 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-12 19:55:21,910 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-12 19:55:21,911 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-12 19:55:27,465 - INFO - root - LLMClientManager: 指定使用客户端: Deepseek
2025-11-12 19:55:27,467 - INFO - root - DeepSeekClient: API key found: 9f9e270e-b...
2025-11-12 19:55:27,467 - INFO - root - DeepSeekClient: 使用模式: 火山引擎
2025-11-12 19:55:27,467 - INFO - root - DeepSeekClient: 模型名称: deepseek-v3-1-terminus
2025-11-12 19:55:32,681 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 19:55:32,752 - INFO - root - DeepSeekClient: initialized successfully with model deepseek-v3-1-terminus
2025-11-12 19:55:32,771 - INFO - root - LLMClientManager: DeepSeek 客户端初始化成功
2025-11-12 19:55:32,831 - INFO - root - LLMClientManager: switched to DeepSeek client (case-insensitive match)
2025-11-12 19:55:32,876 - INFO - root - 已手动切换到 LLM 客户端: Deepseek
2025-11-12 19:55:32,897 - INFO - root - 使用 LLM 模型: deepseek-v3-1-terminus
2025-11-12 19:55:32,931 - INFO - root - 可用客户端: ['DeepSeek']
2025-11-12 19:55:32,937 - INFO - root - === 运行配置 ===
2025-11-12 19:55:32,976 - INFO - root - 处理模式: Semantic Scholar 高引用搜索 (API)
2025-11-12 19:55:33,014 - INFO - root - 查询 (关键词): hybrid attention
2025-11-12 19:55:33,031 - INFO - root - 关键词 (用于保存): hybrid attention
2025-11-12 19:55:33,031 - INFO - root - 排序: citationCount:desc
2025-11-12 19:55:33,036 - INFO - root - 最大处理数量: 2
2025-11-12 19:55:33,041 - INFO - root - 保存图片: 否
2025-11-12 19:55:33,045 - INFO - root - 输出语言: 中文
2025-11-12 19:55:33,060 - INFO - root - 强制重新处理: 否
2025-11-12 19:55:33,065 - INFO - root - LLM 客户端: Deepseek
2025-11-12 19:55:33,065 - INFO - root - ====================
2025-11-12 19:55:33,067 - INFO - root - 正在使用检索策略: semantic
2025-11-12 19:55:33,083 - INFO - root - 使用 Semantic Scholar 高引用搜索模式 (API)
2025-11-12 19:55:33,092 - INFO - root - Semantic API 查询: query=hybrid attention, limit=2, sort=citationCount:desc
2025-11-12 19:55:34,713 - WARNING - root - 【手动下载提示】(Semantic Scholar 未提供开放 PDF): An Instrument Indication Acquisition Algorithm Based on Lightweight Deep Convolutional Neural Network and Hybrid Attention Fine-Grained Features @ https://www.semanticscholar.org/paper/49f99d7a21e2ded7915676753a180983763b9a22
2025-11-12 19:55:34,713 - WARNING - root - 【手动下载提示】(Semantic Scholar 未提供开放 PDF): Enhancing ASD classification through hybrid attention-based learning of facial features @ https://www.semanticscholar.org/paper/22547aa4c72c7c2799932a0f451ab3f2db6d7d0f
2025-11-12 19:55:34,718 - INFO - root - 没有找到要处理的论文，程序退出
2025-11-12 19:55:34,725 - INFO - root - 总运行时间: 12.82 seconds
2025-11-12 19:55:53,084 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-12 19:55:53,084 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-12 19:55:53,089 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-12 19:55:56,980 - INFO - root - LLMClientManager: 指定使用客户端: Deepseek
2025-11-12 19:55:56,980 - INFO - root - DeepSeekClient: API key found: 9f9e270e-b...
2025-11-12 19:55:56,980 - INFO - root - DeepSeekClient: 使用模式: 火山引擎
2025-11-12 19:55:56,980 - INFO - root - DeepSeekClient: 模型名称: deepseek-v3-1-terminus
2025-11-12 19:55:59,382 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 19:55:59,411 - INFO - root - DeepSeekClient: initialized successfully with model deepseek-v3-1-terminus
2025-11-12 19:55:59,412 - INFO - root - LLMClientManager: DeepSeek 客户端初始化成功
2025-11-12 19:55:59,413 - INFO - root - LLMClientManager: switched to DeepSeek client (case-insensitive match)
2025-11-12 19:55:59,413 - INFO - root - 已手动切换到 LLM 客户端: Deepseek
2025-11-12 19:55:59,413 - INFO - root - 使用 LLM 模型: deepseek-v3-1-terminus
2025-11-12 19:55:59,414 - INFO - root - 可用客户端: ['DeepSeek']
2025-11-12 19:55:59,414 - INFO - root - === 运行配置 ===
2025-11-12 19:55:59,414 - INFO - root - 处理模式: Semantic Scholar 高引用搜索 (API)
2025-11-12 19:55:59,416 - INFO - root - 查询 (关键词): hybrid attention
2025-11-12 19:55:59,416 - INFO - root - 关键词 (用于保存): hybrid attention
2025-11-12 19:55:59,416 - INFO - root - 排序: citationCount:desc
2025-11-12 19:55:59,417 - INFO - root - 最大处理数量: 10
2025-11-12 19:55:59,419 - INFO - root - 保存图片: 否
2025-11-12 19:55:59,420 - INFO - root - 输出语言: 中文
2025-11-12 19:55:59,422 - INFO - root - 强制重新处理: 否
2025-11-12 19:55:59,428 - INFO - root - LLM 客户端: Deepseek
2025-11-12 19:55:59,432 - INFO - root - ====================
2025-11-12 19:55:59,434 - INFO - root - 正在使用检索策略: semantic
2025-11-12 19:55:59,434 - INFO - root - 使用 Semantic Scholar 高引用搜索模式 (API)
2025-11-12 19:55:59,434 - INFO - root - Semantic API 查询: query=hybrid attention, limit=10, sort=citationCount:desc
2025-11-12 19:56:00,270 - ERROR - root - Semantic Scholar API 请求失败: 429 Client Error:  for url: https://api.semanticscholar.org/graph/v1/paper/search?query=hybrid+attention&limit=10&sort=citationCount%3Adesc&fields=title%2Curl%2Cabstract%2Cauthors%2CpublicationDate%2CcitationCount%2CopenAccessPdf
Traceback (most recent call last):
  File "D:\ChatPaper\retrievers.py", line 247, in retrieve
    response.raise_for_status() # 请求失败则抛出异常
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\requests\models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 429 Client Error:  for url: https://api.semanticscholar.org/graph/v1/paper/search?query=hybrid+attention&limit=10&sort=citationCount%3Adesc&fields=title%2Curl%2Cabstract%2Cauthors%2CpublicationDate%2CcitationCount%2CopenAccessPdf
2025-11-12 19:56:00,282 - INFO - root - 没有找到要处理的论文，程序退出
2025-11-12 19:56:00,283 - INFO - root - 总运行时间: 7.20 seconds
2025-11-12 19:58:52,138 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-12 19:58:52,140 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-12 19:58:52,140 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-12 19:58:55,375 - INFO - root - LLMClientManager: 指定使用客户端: Deepseek
2025-11-12 19:58:55,375 - INFO - root - DeepSeekClient: API key found: 9f9e270e-b...
2025-11-12 19:58:55,376 - INFO - root - DeepSeekClient: 使用模式: 火山引擎
2025-11-12 19:58:55,376 - INFO - root - DeepSeekClient: 模型名称: deepseek-v3-1-terminus
2025-11-12 19:58:58,886 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 19:58:58,910 - INFO - root - DeepSeekClient: initialized successfully with model deepseek-v3-1-terminus
2025-11-12 19:58:58,915 - INFO - root - LLMClientManager: DeepSeek 客户端初始化成功
2025-11-12 19:58:58,916 - INFO - root - LLMClientManager: switched to DeepSeek client (case-insensitive match)
2025-11-12 19:58:58,917 - INFO - root - 已手动切换到 LLM 客户端: Deepseek
2025-11-12 19:58:58,918 - INFO - root - 使用 LLM 模型: deepseek-v3-1-terminus
2025-11-12 19:58:58,919 - INFO - root - 可用客户端: ['DeepSeek']
2025-11-12 19:58:58,921 - INFO - root - === 运行配置 ===
2025-11-12 19:58:58,926 - INFO - root - 处理模式: Semantic Scholar 高引用搜索 (API)
2025-11-12 19:58:58,926 - INFO - root - 查询 (关键词): hybrid attention
2025-11-12 19:58:58,927 - INFO - root - 关键词 (用于保存): hybrid attention
2025-11-12 19:58:58,927 - INFO - root - 排序: citationCount:desc
2025-11-12 19:58:58,928 - INFO - root - 最大处理数量: 10
2025-11-12 19:58:58,930 - INFO - root - 保存图片: 否
2025-11-12 19:58:58,931 - INFO - root - 输出语言: 中文
2025-11-12 19:58:58,931 - INFO - root - 强制重新处理: 否
2025-11-12 19:58:58,931 - INFO - root - LLM 客户端: Deepseek
2025-11-12 19:58:58,931 - INFO - root - ====================
2025-11-12 19:58:58,931 - INFO - root - 正在使用检索策略: semantic
2025-11-12 19:58:58,932 - INFO - root - 使用 Semantic Scholar 高引用搜索模式 (API)
2025-11-12 19:58:58,932 - INFO - root - Semantic API 查询: query=hybrid attention, limit=10, sort=citationCount:desc
2025-11-12 19:58:58,932 - INFO - root - 正在调用 Semantic Scholar API...
2025-11-12 19:59:03,834 - INFO - root - 正在调用 Semantic Scholar API...
2025-11-12 19:59:05,829 - WARNING - root - 【手动下载提示】(Semantic Scholar 未提供开放 PDF): An Instrument Indication Acquisition Algorithm Based on Lightweight Deep Convolutional Neural Network and Hybrid Attention Fine-Grained Features @ https://www.semanticscholar.org/paper/49f99d7a21e2ded7915676753a180983763b9a22
2025-11-12 19:59:05,829 - WARNING - root - 【手动下载提示】(Semantic Scholar 未提供开放 PDF): Dual-Hybrid Attention Network for Specular Highlight Removal @ https://www.semanticscholar.org/paper/d56ce689cc0f8b1cf0e5f58882503a5e59ec440b
2025-11-12 19:59:05,830 - WARNING - root - 【手动下载提示】(Semantic Scholar 未提供开放 PDF): Enhancing ASD classification through hybrid attention-based learning of facial features @ https://www.semanticscholar.org/paper/22547aa4c72c7c2799932a0f451ab3f2db6d7d0f
2025-11-12 19:59:05,831 - WARNING - root - 【手动下载提示】(Semantic Scholar 未提供开放 PDF): HyA-GAN: remote sensing image cloud removal based on hybrid attention generation adversarial network @ https://www.semanticscholar.org/paper/905b42f2f8d912d98fd7cbec4f7b244401176acc
2025-11-12 19:59:05,834 - WARNING - root - 【手动下载提示】(Semantic Scholar 未提供开放 PDF): Radar Signal Recognition Based on CNN With a Hybrid Attention Mechanism and Skip Feature Aggregation @ https://www.semanticscholar.org/paper/dacad703c49e9434321c91220219638f871fd9d2
2025-11-12 19:59:05,834 - WARNING - root - 【手动下载提示】(Semantic Scholar 未提供开放 PDF): Hybrid Attention-Aware Transformer Network Collaborative Multiscale Feature Alignment for Building Change Detection @ https://www.semanticscholar.org/paper/a0f8053046622628073ac6f051b5181a80cb7ad3
2025-11-12 19:59:05,836 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\myPapers\hybrid attention\Hybrid Attention Fusion Embedded in Transformer for Remote Sensing Image Semantic Segmentation.pdf
2025-11-12 19:59:05,836 - INFO - root - 成功下载 (Semantic Scholar): Hybrid Attention Fusion Embedded in Transformer for Remote Sensing Image Semantic Segmentation
2025-11-12 19:59:05,836 - WARNING - root - 【手动下载提示】(Semantic Scholar 未提供开放 PDF): Probabilistic Multienergy Load Forecasting Based on Hybrid Attention-Enabled Transformer Network and Gaussian Process-Aided Residual Learning @ https://www.semanticscholar.org/paper/a2d81cc04f73e2898fb16e7e8c8f9cf69adadfd5
2025-11-12 19:59:05,837 - INFO - root - 正在下载: https://www.mdpi.com/2306-5354/11/3/240/pdf?version=1709132347
2025-11-12 19:59:10,745 - INFO - root - 正在下载: https://www.mdpi.com/2306-5354/11/3/240/pdf?version=1709132347
2025-11-12 19:59:15,943 - INFO - root - 正在下载: https://www.mdpi.com/2306-5354/11/3/240/pdf?version=1709132347
2025-11-12 19:59:20,706 - INFO - root - 正在下载: https://www.mdpi.com/2306-5354/11/3/240/pdf?version=1709132347
2025-11-12 19:59:29,902 - INFO - root - 正在下载: https://www.mdpi.com/2306-5354/11/3/240/pdf?version=1709132347
2025-11-12 19:59:30,507 - WARNING - root - 下载 Advancing Ocular Imaging: A Hybrid Attention Mechanism-Based U-Net Model for Precise Segmentation of Sub-Retinal Layers in OCT Images (https://www.mdpi.com/2306-5354/11/3/240/pdf?version=1709132347) 失败: 403 Client Error: Forbidden for url: https://www.mdpi.com/2306-5354/11/3/240/pdf?version=1709132347
2025-11-12 19:59:30,508 - WARNING - root - 【手动下载提示】(Semantic Scholar 未提供开放 PDF): Enhancing Time Series Product Demand Forecasting With Hybrid Attention-Based Deep Learning Models @ https://www.semanticscholar.org/paper/4848b35cbe515f8909a67a82dcb83d7c5e48f74b
2025-11-12 19:59:30,508 - INFO - root - 检索到 1 篇论文，开始总结...
2025-11-12 19:59:30,510 - INFO - root - 正在总结论文 1/1: Hybrid Attention Fusion Embedded in Transformer for Remote Sensing Image Semantic Segmentation
2025-11-12 19:59:42,656 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 20:00:30,557 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 20:01:07,036 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 20:01:07,042 - INFO - root - 论文《Hybrid Attention Fusion Embedded in Transformer for Remote Sensing Image Semantic Segmentation》的分析已保存到 ./export\hybrid attention\Hybrid Attention Fusion Embedded in Transformer for Remote Sensing Image Semantic Segmentation.md
2025-11-12 20:01:07,390 - INFO - root - 已生成汇总Excel表格: export\hybrid attention\论文汇总_hybrid attention_20251112_200107.xlsx
2025-11-12 20:01:07,391 - INFO - root - 已生成汇总Excel表格: export\hybrid attention\论文汇总_hybrid attention_20251112_200107.xlsx
2025-11-12 20:01:07,392 - INFO - root - 总运行时间: 135.25 seconds
2025-11-12 20:04:45,142 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-12 20:04:45,143 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-12 20:04:45,145 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-12 20:04:48,851 - INFO - root - LLMClientManager: 指定使用客户端: Deepseek
2025-11-12 20:04:48,856 - INFO - root - DeepSeekClient: API key found: 9f9e270e-b...
2025-11-12 20:04:48,856 - INFO - root - DeepSeekClient: 使用模式: 火山引擎
2025-11-12 20:04:48,856 - INFO - root - DeepSeekClient: 模型名称: deepseek-v3-1-terminus
2025-11-12 20:04:52,301 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 20:04:52,326 - INFO - root - DeepSeekClient: initialized successfully with model deepseek-v3-1-terminus
2025-11-12 20:04:52,326 - INFO - root - LLMClientManager: DeepSeek 客户端初始化成功
2025-11-12 20:04:52,327 - INFO - root - LLMClientManager: switched to DeepSeek client (case-insensitive match)
2025-11-12 20:04:52,328 - INFO - root - 已手动切换到 LLM 客户端: Deepseek
2025-11-12 20:04:52,332 - INFO - root - 使用 LLM 模型: deepseek-v3-1-terminus
2025-11-12 20:04:52,332 - INFO - root - 可用客户端: ['DeepSeek']
2025-11-12 20:04:52,334 - INFO - root - === 运行配置 ===
2025-11-12 20:04:52,334 - INFO - root - 处理模式: arXiv 最新搜索 (API)
2025-11-12 20:04:52,334 - INFO - root - 查询: all:hybrid attention
2025-11-12 20:04:52,334 - INFO - root - 关键词 (用于保存): hybrid attention_Recent
2025-11-12 20:04:52,334 - INFO - root - 排序: SubmittedDate
2025-11-12 20:04:52,334 - INFO - root - 最近天数: 7
2025-11-12 20:04:52,334 - INFO - root - 最大处理数量: 3
2025-11-12 20:04:52,334 - INFO - root - 保存图片: 否
2025-11-12 20:04:52,334 - INFO - root - 输出语言: 中文
2025-11-12 20:04:52,338 - INFO - root - 强制重新处理: 否
2025-11-12 20:04:52,338 - INFO - root - LLM 客户端: Deepseek
2025-11-12 20:04:52,338 - INFO - root - ====================
2025-11-12 20:04:52,338 - INFO - root - 正在使用检索策略: arxiv
2025-11-12 20:04:52,339 - INFO - root - 使用 arXiv 搜索模式 (API + 并发)
2025-11-12 20:04:52,339 - INFO - root - 正在使用 arXiv API 搜索: query='all:hybrid attention', sort_by=SubmittedDate
2025-11-12 20:04:52,339 - INFO - arxiv - Requesting page (first: True, try: 0): https://export.arxiv.org/api/query?search_query=all%3Ahybrid+attention&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=50
2025-11-12 20:04:54,003 - INFO - arxiv - Got first page: 50 of 135016 total results
2025-11-12 20:04:54,006 - INFO - root - API 返回了 50 篇论文
2025-11-12 20:04:54,014 - INFO - root - 论文 'Symmetries and periodic orbits in simple hybrid Routhian systems' (日期: 2020-01-24) 已超出 7 天范围，停止过滤。
2025-11-12 20:04:54,015 - INFO - root - 经过 'days=7' 过滤后，剩余 0 篇论文。
2025-11-12 20:04:54,016 - INFO - root - 没有找到符合条件的论文。
2025-11-12 20:04:54,017 - INFO - root - 没有找到要处理的论文，程序退出
2025-11-12 20:04:54,017 - INFO - root - 总运行时间: 8.88 seconds
2025-11-12 20:05:11,934 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-12 20:05:11,934 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-12 20:05:11,934 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-12 20:05:14,923 - INFO - root - LLMClientManager: 指定使用客户端: Deepseek
2025-11-12 20:05:14,924 - INFO - root - DeepSeekClient: API key found: 9f9e270e-b...
2025-11-12 20:05:14,924 - INFO - root - DeepSeekClient: 使用模式: 火山引擎
2025-11-12 20:05:14,924 - INFO - root - DeepSeekClient: 模型名称: deepseek-v3-1-terminus
2025-11-12 20:05:18,409 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 20:05:18,418 - INFO - root - DeepSeekClient: initialized successfully with model deepseek-v3-1-terminus
2025-11-12 20:05:18,419 - INFO - root - LLMClientManager: DeepSeek 客户端初始化成功
2025-11-12 20:05:18,422 - INFO - root - LLMClientManager: switched to DeepSeek client (case-insensitive match)
2025-11-12 20:05:18,424 - INFO - root - 已手动切换到 LLM 客户端: Deepseek
2025-11-12 20:05:18,424 - INFO - root - 使用 LLM 模型: deepseek-v3-1-terminus
2025-11-12 20:05:18,425 - INFO - root - 可用客户端: ['DeepSeek']
2025-11-12 20:05:18,426 - INFO - root - === 运行配置 ===
2025-11-12 20:05:18,426 - INFO - root - 处理模式: arXiv 最新搜索 (API)
2025-11-12 20:05:18,427 - INFO - root - 查询: all:hybrid attention
2025-11-12 20:05:18,427 - INFO - root - 关键词 (用于保存): hybrid attention_Recent
2025-11-12 20:05:18,427 - INFO - root - 排序: SubmittedDate
2025-11-12 20:05:18,428 - INFO - root - 最近天数: 365
2025-11-12 20:05:18,428 - INFO - root - 最大处理数量: 3
2025-11-12 20:05:18,429 - INFO - root - 保存图片: 否
2025-11-12 20:05:18,429 - INFO - root - 输出语言: 中文
2025-11-12 20:05:18,429 - INFO - root - 强制重新处理: 否
2025-11-12 20:05:18,434 - INFO - root - LLM 客户端: Deepseek
2025-11-12 20:05:18,435 - INFO - root - ====================
2025-11-12 20:05:18,435 - INFO - root - 正在使用检索策略: arxiv
2025-11-12 20:05:18,436 - INFO - root - 使用 arXiv 搜索模式 (API + 并发)
2025-11-12 20:05:18,436 - INFO - root - 正在使用 arXiv API 搜索: query='all:hybrid attention', sort_by=SubmittedDate
2025-11-12 20:05:18,440 - INFO - arxiv - Requesting page (first: True, try: 0): https://export.arxiv.org/api/query?search_query=all%3Ahybrid+attention&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=50
2025-11-12 20:05:19,546 - INFO - arxiv - Got first page: 50 of 135016 total results
2025-11-12 20:05:19,551 - INFO - root - API 返回了 50 篇论文
2025-11-12 20:05:19,554 - INFO - root - 论文 'Symmetries and periodic orbits in simple hybrid Routhian systems' (日期: 2020-01-24) 已超出 365 天范围，停止过滤。
2025-11-12 20:05:19,556 - INFO - root - 经过 'days=365' 过滤后，剩余 0 篇论文。
2025-11-12 20:05:19,557 - INFO - root - 没有找到符合条件的论文。
2025-11-12 20:05:19,557 - INFO - root - 没有找到要处理的论文，程序退出
2025-11-12 20:05:19,557 - INFO - root - 总运行时间: 7.62 seconds
2025-11-12 20:06:45,833 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-12 20:06:45,836 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-12 20:06:45,839 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-12 20:06:50,260 - INFO - root - LLMClientManager: 指定使用客户端: Deepseek
2025-11-12 20:06:50,261 - INFO - root - DeepSeekClient: API key found: 9f9e270e-b...
2025-11-12 20:06:50,261 - INFO - root - DeepSeekClient: 使用模式: 火山引擎
2025-11-12 20:06:50,261 - INFO - root - DeepSeekClient: 模型名称: deepseek-v3-1-terminus
2025-11-12 20:06:53,243 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 20:06:53,261 - INFO - root - DeepSeekClient: initialized successfully with model deepseek-v3-1-terminus
2025-11-12 20:06:53,287 - INFO - root - LLMClientManager: DeepSeek 客户端初始化成功
2025-11-12 20:06:53,293 - INFO - root - LLMClientManager: switched to DeepSeek client (case-insensitive match)
2025-11-12 20:06:53,330 - INFO - root - 已手动切换到 LLM 客户端: Deepseek
2025-11-12 20:06:53,356 - INFO - root - 使用 LLM 模型: deepseek-v3-1-terminus
2025-11-12 20:06:53,380 - INFO - root - 可用客户端: ['DeepSeek']
2025-11-12 20:06:53,408 - INFO - root - === 运行配置 ===
2025-11-12 20:06:53,424 - INFO - root - 处理模式: arXiv 最新搜索 (API)
2025-11-12 20:06:53,459 - INFO - root - 查询: all:CVPR 2025
2025-11-12 20:06:53,461 - INFO - root - 关键词 (用于保存): CVPR 202
2025-11-12 20:06:53,462 - INFO - root - 排序: SubmittedDate
2025-11-12 20:06:53,464 - INFO - root - 最近天数: 365
2025-11-12 20:06:53,469 - INFO - root - 最大处理数量: 3
2025-11-12 20:06:53,470 - INFO - root - 保存图片: 否
2025-11-12 20:06:53,471 - INFO - root - 输出语言: 中文
2025-11-12 20:06:53,471 - INFO - root - 强制重新处理: 否
2025-11-12 20:06:53,472 - INFO - root - LLM 客户端: Deepseek
2025-11-12 20:06:53,472 - INFO - root - ====================
2025-11-12 20:06:53,473 - INFO - root - 正在使用检索策略: arxiv
2025-11-12 20:06:53,477 - INFO - root - 使用 arXiv 搜索模式 (API + 并发)
2025-11-12 20:06:53,479 - INFO - root - 正在使用 arXiv API 搜索: query='all:CVPR 2025', sort_by=SubmittedDate
2025-11-12 20:06:53,480 - INFO - arxiv - Requesting page (first: True, try: 0): https://export.arxiv.org/api/query?search_query=all%3ACVPR+2025&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=50
2025-11-12 20:06:55,586 - INFO - arxiv - Got first page: 50 of 278845 total results
2025-11-12 20:06:55,589 - INFO - root - API 返回了 50 篇论文
2025-11-12 20:06:55,591 - INFO - root - 经过 'days=365' 过滤后，剩余 50 篇论文。
2025-11-12 20:06:55,591 - INFO - root - 将开始并发下载 3 篇论文...
2025-11-12 20:06:55,592 - WARNING - root - 处理论文 http://arxiv.org/abs/2509.06993v1 时失败: name 'chat_arxiv' is not defined
Traceback (most recent call last):
  File "D:\ChatPaper\chat_arxiv.py", line 149, in _download_and_create_paper
    filename = chat_arxiv.try_download_pdf(pdf_url, title, args.key_word)
               ^^^^^^^^^^
NameError: name 'chat_arxiv' is not defined
2025-11-12 20:06:55,594 - WARNING - root - 处理论文 http://arxiv.org/abs/2506.23351v2 时失败: name 'chat_arxiv' is not defined
Traceback (most recent call last):
  File "D:\ChatPaper\chat_arxiv.py", line 149, in _download_and_create_paper
    filename = chat_arxiv.try_download_pdf(pdf_url, title, args.key_word)
               ^^^^^^^^^^
NameError: name 'chat_arxiv' is not defined
2025-11-12 20:06:55,594 - WARNING - root - 处理论文 http://arxiv.org/abs/2506.05815v1 时失败: name 'chat_arxiv' is not defined
Traceback (most recent call last):
  File "D:\ChatPaper\chat_arxiv.py", line 149, in _download_and_create_paper
    filename = chat_arxiv.try_download_pdf(pdf_url, title, args.key_word)
               ^^^^^^^^^^
NameError: name 'chat_arxiv' is not defined
2025-11-12 20:06:55,610 - INFO - root - 下载进度: 1/3
2025-11-12 20:06:55,614 - INFO - root - 下载进度: 2/3
2025-11-12 20:06:55,614 - INFO - root - 下载进度: 3/3
2025-11-12 20:06:55,622 - INFO - root - 成功下载并处理了 0 篇论文，耗时 0.03 秒。
2025-11-12 20:06:55,623 - INFO - root - 没有找到要处理的论文，程序退出
2025-11-12 20:06:55,624 - INFO - root - 总运行时间: 9.79 seconds
2025-11-12 20:12:19,378 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-12 20:12:19,380 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-12 20:12:19,384 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-12 20:12:22,990 - INFO - root - LLMClientManager: 指定使用客户端: Deepseek
2025-11-12 20:12:22,990 - INFO - root - DeepSeekClient: API key found: 9f9e270e-b...
2025-11-12 20:12:22,990 - INFO - root - DeepSeekClient: 使用模式: 火山引擎
2025-11-12 20:12:22,990 - INFO - root - DeepSeekClient: 模型名称: deepseek-v3-1-terminus
2025-11-12 20:12:26,483 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 20:12:26,503 - INFO - root - DeepSeekClient: initialized successfully with model deepseek-v3-1-terminus
2025-11-12 20:12:26,507 - INFO - root - LLMClientManager: DeepSeek 客户端初始化成功
2025-11-12 20:12:26,507 - INFO - root - LLMClientManager: switched to DeepSeek client (case-insensitive match)
2025-11-12 20:12:26,508 - INFO - root - 已手动切换到 LLM 客户端: Deepseek
2025-11-12 20:12:26,508 - INFO - root - 使用 LLM 模型: deepseek-v3-1-terminus
2025-11-12 20:12:26,509 - INFO - root - 可用客户端: ['DeepSeek']
2025-11-12 20:12:26,509 - INFO - root - === 运行配置 ===
2025-11-12 20:12:26,509 - INFO - root - 处理模式: arXiv 最新搜索 (API)
2025-11-12 20:12:26,510 - INFO - root - 查询: all:CVPR 2025
2025-11-12 20:12:26,510 - INFO - root - 关键词 (用于保存): CVPR 202
2025-11-12 20:12:26,511 - INFO - root - 排序: SubmittedDate
2025-11-12 20:12:26,512 - INFO - root - 最近天数: 365
2025-11-12 20:12:26,512 - INFO - root - 最大处理数量: 3
2025-11-12 20:12:26,513 - INFO - root - 保存图片: 否
2025-11-12 20:12:26,513 - INFO - root - 输出语言: 中文
2025-11-12 20:12:26,514 - INFO - root - 强制重新处理: 否
2025-11-12 20:12:26,514 - INFO - root - LLM 客户端: Deepseek
2025-11-12 20:12:26,515 - INFO - root - ====================
2025-11-12 20:12:26,517 - INFO - root - 正在使用检索策略: arxiv
2025-11-12 20:12:26,517 - INFO - root - 使用 arXiv 搜索模式 (API + 并发)
2025-11-12 20:12:26,519 - INFO - root - 正在使用 arXiv API 搜索: query='all:CVPR 2025', sort_by=SubmittedDate
2025-11-12 20:12:26,520 - INFO - arxiv - Requesting page (first: True, try: 0): https://export.arxiv.org/api/query?search_query=all%3ACVPR+2025&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=50
2025-11-12 20:12:27,668 - INFO - arxiv - Got first page: 50 of 278845 total results
2025-11-12 20:12:27,671 - INFO - root - API 返回了 50 篇论文
2025-11-12 20:12:27,679 - INFO - root - 经过 'days=365' 过滤后，剩余 50 篇论文。
2025-11-12 20:12:27,679 - INFO - root - 将开始并发下载 3 篇论文...
2025-11-12 20:12:27,684 - INFO - root - 正在下载: None
2025-11-12 20:12:27,685 - INFO - root - 正在下载: None
2025-11-12 20:12:27,686 - INFO - root - 正在下载: None
2025-11-12 20:12:31,690 - INFO - root - 正在下载: None
2025-11-12 20:12:31,691 - INFO - root - 正在下载: None
2025-11-12 20:12:31,693 - INFO - root - 正在下载: None
2025-11-12 20:12:35,691 - INFO - root - 正在下载: None
2025-11-12 20:12:35,695 - INFO - root - 正在下载: None
2025-11-12 20:12:35,695 - INFO - root - 正在下载: None
2025-11-12 20:12:39,694 - INFO - root - 正在下载: None
2025-11-12 20:12:39,699 - INFO - root - 正在下载: None
2025-11-12 20:12:39,707 - INFO - root - 正在下载: None
2025-11-12 20:12:47,696 - INFO - root - 正在下载: None
2025-11-12 20:12:47,697 - WARNING - root - 处理论文 http://arxiv.org/abs/2509.06993v1 时失败: Invalid URL 'None': No scheme supplied. Perhaps you meant https://None?
Traceback (most recent call last):
  File "D:\ChatPaper\chat_arxiv.py", line 150, in _download_and_create_paper
    file_path = try_download_pdf(result.pdf_url, result.title, query)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\tenacity\__init__.py", line 338, in wrapped_f
    return copy(f, *args, **kw)
           ^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\tenacity\__init__.py", line 477, in __call__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\tenacity\__init__.py", line 378, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\tenacity\__init__.py", line 420, in exc_check
    raise retry_exc.reraise()
          ^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\tenacity\__init__.py", line 187, in reraise
    raise self.last_attempt.result()
          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "D:\ChatPaper\.venv\Lib\site-packages\tenacity\__init__.py", line 480, in __call__
    result = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\chat_arxiv.py", line 76, in try_download_pdf
    r = requests.get(pdf_url, headers=headers, timeout=30)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\requests\api.py", line 73, in get
    return request("get", url, params=params, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\requests\api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\requests\sessions.py", line 575, in request
    prep = self.prepare_request(req)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\requests\sessions.py", line 484, in prepare_request
    p.prepare(
  File "D:\ChatPaper\.venv\Lib\site-packages\requests\models.py", line 367, in prepare
    self.prepare_url(url, params)
  File "D:\ChatPaper\.venv\Lib\site-packages\requests\models.py", line 438, in prepare_url
    raise MissingSchema(
requests.exceptions.MissingSchema: Invalid URL 'None': No scheme supplied. Perhaps you meant https://None?
2025-11-12 20:12:47,715 - INFO - root - 正在下载: None
2025-11-12 20:12:47,717 - INFO - root - 正在下载: None
2025-11-12 20:12:47,737 - INFO - root - 下载进度: 1/3
2025-11-12 20:12:47,737 - WARNING - root - 处理论文 http://arxiv.org/abs/2506.05815v1 时失败: Invalid URL 'None': No scheme supplied. Perhaps you meant https://None?
Traceback (most recent call last):
  File "D:\ChatPaper\chat_arxiv.py", line 150, in _download_and_create_paper
    file_path = try_download_pdf(result.pdf_url, result.title, query)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\tenacity\__init__.py", line 338, in wrapped_f
    return copy(f, *args, **kw)
           ^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\tenacity\__init__.py", line 477, in __call__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\tenacity\__init__.py", line 378, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\tenacity\__init__.py", line 420, in exc_check
    raise retry_exc.reraise()
          ^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\tenacity\__init__.py", line 187, in reraise
    raise self.last_attempt.result()
          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "D:\ChatPaper\.venv\Lib\site-packages\tenacity\__init__.py", line 480, in __call__
    result = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\chat_arxiv.py", line 76, in try_download_pdf
    r = requests.get(pdf_url, headers=headers, timeout=30)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\requests\api.py", line 73, in get
    return request("get", url, params=params, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\requests\api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\requests\sessions.py", line 575, in request
    prep = self.prepare_request(req)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\requests\sessions.py", line 484, in prepare_request
    p.prepare(
  File "D:\ChatPaper\.venv\Lib\site-packages\requests\models.py", line 367, in prepare
    self.prepare_url(url, params)
  File "D:\ChatPaper\.venv\Lib\site-packages\requests\models.py", line 438, in prepare_url
    raise MissingSchema(
requests.exceptions.MissingSchema: Invalid URL 'None': No scheme supplied. Perhaps you meant https://None?
2025-11-12 20:12:47,742 - WARNING - root - 处理论文 http://arxiv.org/abs/2506.23351v2 时失败: Invalid URL 'None': No scheme supplied. Perhaps you meant https://None?
Traceback (most recent call last):
  File "D:\ChatPaper\chat_arxiv.py", line 150, in _download_and_create_paper
    file_path = try_download_pdf(result.pdf_url, result.title, query)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\tenacity\__init__.py", line 338, in wrapped_f
    return copy(f, *args, **kw)
           ^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\tenacity\__init__.py", line 477, in __call__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\tenacity\__init__.py", line 378, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\tenacity\__init__.py", line 420, in exc_check
    raise retry_exc.reraise()
          ^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\tenacity\__init__.py", line 187, in reraise
    raise self.last_attempt.result()
          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "D:\ChatPaper\.venv\Lib\site-packages\tenacity\__init__.py", line 480, in __call__
    result = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\chat_arxiv.py", line 76, in try_download_pdf
    r = requests.get(pdf_url, headers=headers, timeout=30)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\requests\api.py", line 73, in get
    return request("get", url, params=params, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\requests\api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\requests\sessions.py", line 575, in request
    prep = self.prepare_request(req)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\requests\sessions.py", line 484, in prepare_request
    p.prepare(
  File "D:\ChatPaper\.venv\Lib\site-packages\requests\models.py", line 367, in prepare
    self.prepare_url(url, params)
  File "D:\ChatPaper\.venv\Lib\site-packages\requests\models.py", line 438, in prepare_url
    raise MissingSchema(
requests.exceptions.MissingSchema: Invalid URL 'None': No scheme supplied. Perhaps you meant https://None?
2025-11-12 20:12:47,746 - INFO - root - 下载进度: 2/3
2025-11-12 20:12:47,748 - INFO - root - 下载进度: 3/3
2025-11-12 20:12:47,751 - INFO - root - 成功下载并处理了 0 篇论文，耗时 20.07 秒。
2025-11-12 20:12:47,752 - INFO - root - 没有找到要处理的论文，程序退出
2025-11-12 20:12:47,753 - INFO - root - 总运行时间: 28.38 seconds
2025-11-12 20:16:11,079 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-12 20:16:11,081 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-12 20:16:11,083 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-12 20:16:16,121 - INFO - root - LLMClientManager: 指定使用客户端: Deepseek
2025-11-12 20:16:16,124 - INFO - root - DeepSeekClient: API key found: 9f9e270e-b...
2025-11-12 20:16:16,126 - INFO - root - DeepSeekClient: 使用模式: 火山引擎
2025-11-12 20:16:16,127 - INFO - root - DeepSeekClient: 模型名称: deepseek-v3-1-terminus
2025-11-12 20:16:19,291 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 20:16:19,313 - INFO - root - DeepSeekClient: initialized successfully with model deepseek-v3-1-terminus
2025-11-12 20:16:19,313 - INFO - root - LLMClientManager: DeepSeek 客户端初始化成功
2025-11-12 20:16:19,317 - INFO - root - LLMClientManager: switched to DeepSeek client (case-insensitive match)
2025-11-12 20:16:19,319 - INFO - root - 已手动切换到 LLM 客户端: Deepseek
2025-11-12 20:16:19,319 - INFO - root - 使用 LLM 模型: deepseek-v3-1-terminus
2025-11-12 20:16:19,319 - INFO - root - 可用客户端: ['DeepSeek']
2025-11-12 20:16:19,321 - INFO - root - === 运行配置 ===
2025-11-12 20:16:19,322 - INFO - root - 处理模式: arXiv 最新搜索 (API)
2025-11-12 20:16:19,322 - INFO - root - 查询: all:CVPR 2025
2025-11-12 20:16:19,323 - INFO - root - 关键词 (用于保存): CVPR 202
2025-11-12 20:16:19,323 - INFO - root - 排序: SubmittedDate
2025-11-12 20:16:19,323 - INFO - root - 最近天数: 365
2025-11-12 20:16:19,324 - INFO - root - 最大处理数量: 3
2025-11-12 20:16:19,324 - INFO - root - 保存图片: 否
2025-11-12 20:16:19,324 - INFO - root - 输出语言: 中文
2025-11-12 20:16:19,324 - INFO - root - 强制重新处理: 否
2025-11-12 20:16:19,325 - INFO - root - LLM 客户端: Deepseek
2025-11-12 20:16:19,325 - INFO - root - ====================
2025-11-12 20:16:19,325 - INFO - root - 正在使用检索策略: arxiv
2025-11-12 20:16:19,325 - INFO - root - 使用 arXiv 搜索模式 (API + 并发)
2025-11-12 20:16:19,326 - INFO - root - 正在使用 arXiv API 搜索: query='all:CVPR 2025', sort_by=SubmittedDate
2025-11-12 20:16:19,326 - INFO - arxiv - Requesting page (first: True, try: 0): https://export.arxiv.org/api/query?search_query=all%3ACVPR+2025&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=50
2025-11-12 20:16:20,589 - INFO - arxiv - Got first page: 50 of 278845 total results
2025-11-12 20:16:20,593 - INFO - root - API 返回了 50 篇论文
2025-11-12 20:16:20,598 - INFO - root - 经过 'days=365' 过滤后，剩余 50 篇论文。
2025-11-12 20:16:20,598 - INFO - root - 将开始并发下载 3 篇论文...
2025-11-12 20:16:20,609 - INFO - root - 正在下载: http://arxiv.org/pdf/2509.06993v1.pdf
2025-11-12 20:16:20,615 - INFO - root - 正在下载: http://arxiv.org/pdf/2506.23351v2.pdf
2025-11-12 20:16:20,621 - INFO - root - 正在下载: http://arxiv.org/pdf/2506.05815v1.pdf
2025-11-12 20:16:26,332 - INFO - root - 已保存到: D:\ChatPaper\myPapers\CVPR 202\Benchmarking Generalizable Bimanual Manipulation_ RoboTwin Dual-Arm Collaboration Challenge at CVPR.pdf
2025-11-12 20:16:26,334 - INFO - root - 成功创建 Paper 对象: 2506.23351v2
2025-11-12 20:16:26,334 - INFO - root - 下载进度: 1/3
2025-11-12 20:16:29,050 - INFO - root - 已保存到: D:\ChatPaper\myPapers\CVPR 202\Geospatial Foundational Embedder_ Top-1 Winning Solution on EarthVision Embed2Scale Challenge (CVPR.pdf
2025-11-12 20:16:29,053 - INFO - root - 成功创建 Paper 对象: 2509.06993v1
2025-11-12 20:16:29,053 - INFO - root - 下载进度: 2/3
2025-11-12 20:16:36,367 - INFO - root - 已保存到: D:\ChatPaper\myPapers\CVPR 202\NTIRE 2025 Challenge on HR Depth from Images of Specular and Transparent Surfaces.pdf
2025-11-12 20:16:36,369 - INFO - root - 成功创建 Paper 对象: 2506.05815v1
2025-11-12 20:16:36,369 - INFO - root - 下载进度: 3/3
2025-11-12 20:16:36,371 - INFO - root - 成功下载并处理了 3 篇论文，耗时 15.76 秒。
2025-11-12 20:16:36,371 - INFO - root - 检索到 3 篇论文，开始总结...
2025-11-12 20:16:36,373 - INFO - root - 正在总结论文 1/3: Benchmarking Generalizable Bimanual Manipulation: RoboTwin Dual-Arm Collaboration Challenge at CVPR 2025 MEIS Workshop
2025-11-12 20:16:52,734 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 20:17:40,617 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 20:18:12,897 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 20:18:12,897 - INFO - root - 论文《Benchmarking Generalizable Bimanual Manipulation: RoboTwin Dual-Arm Collaboration Challenge at CVPR 2025 MEIS Workshop》的分析已保存到 ./export\CVPR 202\Benchmarking Generalizable Bimanual Manipulation_ RoboTwin Dual-Arm Collaboration Challenge at CVPR.md
2025-11-12 20:18:12,901 - INFO - root - 正在总结论文 2/3: Geospatial Foundational Embedder: Top-1 Winning Solution on EarthVision Embed2Scale Challenge (CVPR 2025)
2025-11-12 20:18:23,788 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 20:18:23,789 - INFO - root - LLMClient: rate limit reached, sleeping 16.8s
2025-11-12 20:19:34,751 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 20:20:08,684 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 20:20:08,697 - INFO - root - 论文《Geospatial Foundational Embedder: Top-1 Winning Solution on EarthVision Embed2Scale Challenge (CVPR 2025)》的分析已保存到 ./export\CVPR 202\Geospatial Foundational Embedder_ Top-1 Winning Solution on EarthVision Embed2Scale Challenge (CVPR.md
2025-11-12 20:20:08,713 - INFO - root - 正在总结论文 3/3: NTIRE 2025 Challenge on HR Depth from Images of Specular and Transparent Surfaces
2025-11-12 20:20:24,235 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 20:20:24,237 - INFO - root - LLMClient: rate limit reached, sleeping 10.5s
2025-11-12 20:21:46,523 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 20:22:21,453 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 20:22:21,463 - INFO - root - 论文《NTIRE 2025 Challenge on HR Depth from Images of Specular and Transparent Surfaces》的分析已保存到 ./export\CVPR 202\NTIRE 2025 Challenge on HR Depth from Images of Specular and Transparent Surfaces.md
2025-11-12 20:22:21,769 - INFO - root - 已生成汇总Excel表格: export\CVPR 202\论文汇总_CVPR 202_20251112_202221.xlsx
2025-11-12 20:22:21,769 - INFO - root - 已生成汇总Excel表格: export\CVPR 202\论文汇总_CVPR 202_20251112_202221.xlsx
2025-11-12 20:22:21,769 - INFO - root - 总运行时间: 370.69 seconds
2025-11-12 20:26:42,722 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-12 20:26:42,722 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-12 20:26:42,728 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-12 20:26:47,362 - INFO - root - LLMClientManager: 指定使用客户端: Deepseek
2025-11-12 20:26:47,363 - INFO - root - DeepSeekClient: API key found: 9f9e270e-b...
2025-11-12 20:26:47,367 - INFO - root - DeepSeekClient: 使用模式: 火山引擎
2025-11-12 20:26:47,367 - INFO - root - DeepSeekClient: 模型名称: deepseek-v3-1-terminus
2025-11-12 20:26:50,614 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 20:26:50,631 - INFO - root - DeepSeekClient: initialized successfully with model deepseek-v3-1-terminus
2025-11-12 20:26:50,632 - INFO - root - LLMClientManager: DeepSeek 客户端初始化成功
2025-11-12 20:26:50,633 - INFO - root - LLMClientManager: switched to DeepSeek client (case-insensitive match)
2025-11-12 20:26:50,634 - INFO - root - 已手动切换到 LLM 客户端: Deepseek
2025-11-12 20:26:50,635 - INFO - root - 使用 LLM 模型: deepseek-v3-1-terminus
2025-11-12 20:26:50,635 - INFO - root - 可用客户端: ['DeepSeek']
2025-11-12 20:26:50,636 - INFO - root - === 运行配置 ===
2025-11-12 20:26:50,637 - INFO - root - 处理模式: arXiv 最新搜索 (API)
2025-11-12 20:26:50,638 - INFO - root - 查询: all:CVPR 2025
2025-11-12 20:26:50,639 - INFO - root - 关键词 (用于保存): CVPR 202
2025-11-12 20:26:50,643 - INFO - root - 排序: SubmittedDate
2025-11-12 20:26:50,645 - INFO - root - 最近天数: 365
2025-11-12 20:26:50,646 - INFO - root - 最大处理数量: 5
2025-11-12 20:26:50,648 - INFO - root - 保存图片: 是
2025-11-12 20:26:50,649 - INFO - root - 输出语言: 中文
2025-11-12 20:26:50,650 - INFO - root - 强制重新处理: 否
2025-11-12 20:26:50,651 - INFO - root - LLM 客户端: Deepseek
2025-11-12 20:26:50,651 - INFO - root - ====================
2025-11-12 20:26:50,652 - INFO - root - 正在使用检索策略: arxiv
2025-11-12 20:26:50,653 - INFO - root - 使用 arXiv 搜索模式 (API + 并发)
2025-11-12 20:26:50,653 - INFO - root - 正在使用 arXiv API 搜索: query='all:CVPR 2025', sort_by=SubmittedDate
2025-11-12 20:26:50,655 - INFO - arxiv - Requesting page (first: True, try: 0): https://export.arxiv.org/api/query?search_query=all%3ACVPR+2025&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=50
2025-11-12 20:26:52,384 - INFO - arxiv - Got first page: 50 of 278845 total results
2025-11-12 20:26:52,387 - INFO - root - API 返回了 50 篇论文
2025-11-12 20:26:52,388 - INFO - root - 经过 'days=365' 过滤后，剩余 50 篇论文。
2025-11-12 20:26:52,388 - INFO - root - 将开始并发下载 5 篇论文...
2025-11-12 20:26:52,393 - INFO - root - 正在下载: http://arxiv.org/pdf/2509.06993v1.pdf
2025-11-12 20:26:52,393 - INFO - root - 正在下载: http://arxiv.org/pdf/2506.23351v2.pdf
2025-11-12 20:26:52,393 - INFO - root - 正在下载: http://arxiv.org/pdf/2506.05815v1.pdf
2025-11-12 20:26:52,398 - INFO - root - 正在下载: http://arxiv.org/pdf/2509.02969v1.pdf
2025-11-12 20:26:52,398 - INFO - root - 正在下载: http://arxiv.org/pdf/2506.02550v2.pdf
2025-11-12 20:26:58,445 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\CVPR 202\Technical Report for Ego4D Long-Term Action Anticipation Challenge 2025.pdf
2025-11-12 20:26:58,445 - INFO - root - 成功创建 Paper 对象: 2506.02550v2
2025-11-12 20:26:58,446 - INFO - root - 下载进度: 1/5
2025-11-12 20:26:59,438 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\CVPR 202\Benchmarking Generalizable Bimanual Manipulation_ RoboTwin Dual-Arm Collaboration Challenge at CVPR.pdf
2025-11-12 20:26:59,439 - INFO - root - 成功创建 Paper 对象: 2506.23351v2
2025-11-12 20:26:59,440 - INFO - root - 下载进度: 2/5
2025-11-12 20:27:00,409 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\CVPR 202\NTIRE 2025 Challenge on HR Depth from Images of Specular and Transparent Surfaces.pdf
2025-11-12 20:27:00,415 - INFO - root - 成功创建 Paper 对象: 2506.05815v1
2025-11-12 20:27:00,415 - INFO - root - 下载进度: 3/5
2025-11-12 20:27:00,861 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\CVPR 202\Geospatial Foundational Embedder_ Top-1 Winning Solution on EarthVision Embed2Scale Challenge (CVPR.pdf
2025-11-12 20:27:00,863 - INFO - root - 成功创建 Paper 对象: 2509.06993v1
2025-11-12 20:27:00,863 - INFO - root - 下载进度: 4/5
2025-11-12 20:27:07,947 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\CVPR 202\VQualA 2025 Challenge on Engagement Prediction for Short Videos_ Methods and Results.pdf
2025-11-12 20:27:07,949 - INFO - root - 成功创建 Paper 对象: 2509.02969v1
2025-11-12 20:27:07,949 - INFO - root - 下载进度: 5/5
2025-11-12 20:27:07,949 - INFO - root - 成功下载并处理了 5 篇论文，耗时 15.55 秒。
2025-11-12 20:27:07,950 - INFO - root - 检索到 5 篇论文，开始总结...
2025-11-12 20:27:07,952 - INFO - root - 正在总结论文 1/5: Technical Report for Ego4D Long-Term Action Anticipation Challenge 2025
2025-11-12 20:27:19,823 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 20:28:21,512 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 20:29:05,656 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 20:29:05,657 - INFO - root - 正在提取论文图片到目录: ./export\CVPR 202\images
2025-11-12 20:29:05,806 - INFO - root - 已保存图片 1/10：./export\CVPR 202\images\figure_1_page3.jpeg
2025-11-12 20:29:05,833 - INFO - root - 已保存图片 2/10：./export\CVPR 202\images\figure_2_page3.jpeg
2025-11-12 20:29:05,861 - INFO - root - 已保存图片 3/10：./export\CVPR 202\images\figure_3_page3.jpeg
2025-11-12 20:29:05,887 - INFO - root - 已保存图片 4/10：./export\CVPR 202\images\figure_4_page3.jpeg
2025-11-12 20:29:06,000 - INFO - root - 已保存图片 5/10：./export\CVPR 202\images\figure_5_page3.jpeg
2025-11-12 20:29:06,115 - INFO - root - 已保存图片 6/10：./export\CVPR 202\images\figure_6_page3.jpeg
2025-11-12 20:29:06,154 - INFO - root - 已保存图片 7/10：./export\CVPR 202\images\figure_7_page3.jpeg
2025-11-12 20:29:06,193 - INFO - root - 已保存图片 8/10：./export\CVPR 202\images\figure_8_page3.jpeg
2025-11-12 20:29:06,349 - INFO - root - 已保存图片 9/10：./export\CVPR 202\images\figure_9_page2.png
2025-11-12 20:29:06,487 - INFO - root - 已保存图片 10/10：./export\CVPR 202\images\figure_10_page2.png
2025-11-12 20:29:06,489 - INFO - root - 成功添加图片 1：./export\CVPR 202\images\figure_1_page3.jpeg
2025-11-12 20:29:06,489 - INFO - root - 成功添加图片 2：./export\CVPR 202\images\figure_2_page3.jpeg
2025-11-12 20:29:06,489 - INFO - root - 成功添加图片 3：./export\CVPR 202\images\figure_3_page3.jpeg
2025-11-12 20:29:06,491 - INFO - root - 成功添加图片 4：./export\CVPR 202\images\figure_4_page3.jpeg
2025-11-12 20:29:06,491 - INFO - root - 成功添加图片 5：./export\CVPR 202\images\figure_5_page3.jpeg
2025-11-12 20:29:06,491 - INFO - root - 成功添加图片 6：./export\CVPR 202\images\figure_6_page3.jpeg
2025-11-12 20:29:06,491 - INFO - root - 成功添加图片 7：./export\CVPR 202\images\figure_7_page3.jpeg
2025-11-12 20:29:06,491 - INFO - root - 成功添加图片 8：./export\CVPR 202\images\figure_8_page3.jpeg
2025-11-12 20:29:06,491 - INFO - root - 成功添加图片 9：./export\CVPR 202\images\figure_9_page2.png
2025-11-12 20:29:06,494 - INFO - root - 成功添加图片 10：./export\CVPR 202\images\figure_10_page2.png
2025-11-12 20:29:06,496 - INFO - root - 已更新图片链接
2025-11-12 20:29:06,499 - INFO - root - 论文《Technical Report for Ego4D Long-Term Action Anticipation Challenge 2025》的分析已保存到 ./export\CVPR 202\Technical Report for Ego4D Long-Term Action Anticipation Challenge 2025.md
2025-11-12 20:29:06,503 - INFO - root - 跳过已处理论文 Benchmarking Generalizable Bimanual Manipulation: RoboTwin Dual-Arm Collaboration Challenge at CVPR 2025 MEIS Workshop：D:\ChatPaper\api_downloads\CVPR 202\Benchmarking Generalizable Bimanual Manipulation_ RoboTwin Dual-Arm Collaboration Challenge at CVPR.pdf
2025-11-12 20:29:06,504 - INFO - root - 跳过已处理论文 NTIRE 2025 Challenge on HR Depth from Images of Specular and Transparent Surfaces：D:\ChatPaper\api_downloads\CVPR 202\NTIRE 2025 Challenge on HR Depth from Images of Specular and Transparent Surfaces.pdf
2025-11-12 20:29:06,504 - INFO - root - 跳过已处理论文 Geospatial Foundational Embedder: Top-1 Winning Solution on EarthVision Embed2Scale Challenge (CVPR 2025)：D:\ChatPaper\api_downloads\CVPR 202\Geospatial Foundational Embedder_ Top-1 Winning Solution on EarthVision Embed2Scale Challenge (CVPR.pdf
2025-11-12 20:29:06,507 - INFO - root - 正在总结论文 5/5: VQualA 2025 Challenge on Engagement Prediction for Short Videos: Methods and Results
2025-11-12 20:29:17,634 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 20:29:17,638 - INFO - root - LLMClient: rate limit reached, sleeping 3.9s
2025-11-12 20:30:15,619 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 20:30:46,774 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 20:30:46,778 - INFO - root - 正在提取论文图片到目录: ./export\CVPR 202\images
2025-11-12 20:30:51,318 - INFO - root - 已保存图片 1/10：./export\CVPR 202\images\figure_1_page2.png
2025-11-12 20:30:51,786 - INFO - root - 已保存图片 2/10：./export\CVPR 202\images\figure_2_page2.png
2025-11-12 20:30:52,049 - INFO - root - 已保存图片 3/10：./export\CVPR 202\images\figure_3_page2.png
2025-11-12 20:30:52,248 - INFO - root - 已保存图片 4/10：./export\CVPR 202\images\figure_4_page2.png
2025-11-12 20:30:52,287 - INFO - root - 已保存图片 5/10：./export\CVPR 202\images\figure_5_page8.jpeg
2025-11-12 20:30:52,327 - INFO - root - 已保存图片 6/10：./export\CVPR 202\images\figure_6_page6.jpeg
2025-11-12 20:30:52,362 - INFO - root - 已保存图片 7/10：./export\CVPR 202\images\figure_7_page6.jpeg
2025-11-12 20:30:52,410 - INFO - root - 已保存图片 8/10：./export\CVPR 202\images\figure_8_page6.jpeg
2025-11-12 20:30:52,426 - INFO - root - 已保存图片 9/10：./export\CVPR 202\images\figure_9_page3.jpeg
2025-11-12 20:30:52,445 - INFO - root - 已保存图片 10/10：./export\CVPR 202\images\figure_10_page5.jpeg
2025-11-12 20:30:52,453 - INFO - root - 成功添加图片 1：./export\CVPR 202\images\figure_1_page2.png
2025-11-12 20:30:52,453 - INFO - root - 成功添加图片 2：./export\CVPR 202\images\figure_2_page2.png
2025-11-12 20:30:52,456 - INFO - root - 成功添加图片 3：./export\CVPR 202\images\figure_3_page2.png
2025-11-12 20:30:52,459 - INFO - root - 成功添加图片 4：./export\CVPR 202\images\figure_4_page2.png
2025-11-12 20:30:52,460 - INFO - root - 成功添加图片 5：./export\CVPR 202\images\figure_5_page8.jpeg
2025-11-12 20:30:52,460 - INFO - root - 成功添加图片 6：./export\CVPR 202\images\figure_6_page6.jpeg
2025-11-12 20:30:52,460 - INFO - root - 成功添加图片 7：./export\CVPR 202\images\figure_7_page6.jpeg
2025-11-12 20:30:52,460 - INFO - root - 成功添加图片 8：./export\CVPR 202\images\figure_8_page6.jpeg
2025-11-12 20:30:52,462 - INFO - root - 成功添加图片 9：./export\CVPR 202\images\figure_9_page3.jpeg
2025-11-12 20:30:52,462 - INFO - root - 成功添加图片 10：./export\CVPR 202\images\figure_10_page5.jpeg
2025-11-12 20:30:52,463 - INFO - root - 已更新图片链接
2025-11-12 20:30:52,464 - INFO - root - 论文《VQualA 2025 Challenge on Engagement Prediction for Short Videos: Methods and Results》的分析已保存到 ./export\CVPR 202\VQualA 2025 Challenge on Engagement Prediction for Short Videos_ Methods and Results.md
2025-11-12 20:30:52,795 - INFO - root - 已生成汇总Excel表格: export\CVPR 202\论文汇总_CVPR 202_20251112_203052.xlsx
2025-11-12 20:30:52,797 - INFO - root - 已生成汇总Excel表格: export\CVPR 202\论文汇总_CVPR 202_20251112_203052.xlsx
2025-11-12 20:30:52,797 - INFO - root - 总运行时间: 250.08 seconds
2025-11-12 20:33:56,839 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-12 20:33:56,841 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-12 20:33:56,846 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-12 20:34:00,689 - INFO - root - GeminiClient: trying model models/gemini-2.5-flash
2025-11-12 20:34:07,800 - INFO - root - GeminiClient: initialized model gemini-2.5-flash
2025-11-12 20:34:07,801 - INFO - root - LLMClientManager: Gemini client initialized successfully
2025-11-12 20:34:07,801 - INFO - root - LLMClientManager: using Gemini as default client
2025-11-12 20:34:07,801 - INFO - root - DeepSeekClient: API key found: 9f9e270e-b...
2025-11-12 20:34:07,802 - INFO - root - DeepSeekClient: 使用模式: 火山引擎
2025-11-12 20:34:07,802 - INFO - root - DeepSeekClient: 模型名称: deepseek-v3-1-terminus
2025-11-12 20:34:10,914 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 20:34:10,931 - INFO - root - DeepSeekClient: initialized successfully with model deepseek-v3-1-terminus
2025-11-12 20:34:10,947 - INFO - root - LLMClientManager: DeepSeek client initialized successfully
2025-11-12 20:34:10,949 - WARNING - root - KimiClient: API key not provided. LLM disabled.
2025-11-12 20:34:10,949 - WARNING - root - LLMClientManager: Kimi client initialization failed
2025-11-12 20:34:10,949 - WARNING - root - QwenClient: API key not provided. LLM disabled.
2025-11-12 20:34:10,949 - WARNING - root - LLMClientManager: Qwen client initialization failed
2025-11-12 20:34:10,951 - INFO - root - DoubaoClient: API key found: 9f9e270e-b...
2025-11-12 20:34:14,700 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 20:34:14,701 - INFO - root - DoubaoClient: initialized successfully with model doubao-seed-1-6-lite-251015
2025-11-12 20:34:14,703 - INFO - root - LLMClientManager: Doubao client initialized successfully
2025-11-12 20:34:14,704 - INFO - root - 使用 LLM 模型: gemini-2.5-flash
2025-11-12 20:34:14,704 - INFO - root - 可用客户端: ['Gemini', 'DeepSeek', 'Doubao']
2025-11-12 20:34:14,705 - INFO - root - === 运行配置 ===
2025-11-12 20:34:14,705 - INFO - root - 处理模式: Google Scholar 高引用搜索 (爬虫)
2025-11-12 20:34:14,706 - INFO - root - 查询 (关键词): transformer attention
2025-11-12 20:34:14,707 - INFO - root - 关键词 (用于保存): Transformer_Legacy
2025-11-12 20:34:14,707 - INFO - root - 排序: Citations
2025-11-12 20:34:14,708 - INFO - root - 年份范围: 2017 - 2020
2025-11-12 20:34:14,709 - INFO - root - 最大处理数量: 2
2025-11-12 20:34:14,718 - INFO - root - 保存图片: 否
2025-11-12 20:34:14,719 - INFO - root - 输出语言: 中文
2025-11-12 20:34:14,720 - INFO - root - 强制重新处理: 否
2025-11-12 20:34:14,722 - INFO - root - LLM 客户端: None
2025-11-12 20:34:14,724 - INFO - root - ====================
2025-11-12 20:34:14,725 - INFO - root - 正在使用检索策略: scholar
2025-11-12 20:34:14,726 - INFO - root - 使用 Google Scholar 高引用搜索模式 (爬虫)
2025-11-12 20:34:14,726 - INFO - root - Scholar 配置: 关键词=transformer attention, 数量=2, 排序=Citations, 年份=2017-2020
2025-11-12 20:34:16,109 - WARNING - root - Robot checking detected, handling with selenium (if installed)
2025-11-12 20:34:16,116 - ERROR - root - selenium setup error: No module named 'selenium'
Traceback (most recent call last):
  File "D:\ChatPaper\others\google_scholar_spider.py", line 122, in setup_driver
    from selenium import webdriver
ModuleNotFoundError: No module named 'selenium'
2025-11-12 20:34:16,151 - ERROR - root - Please install Selenium and chrome webdriver for manual checking of captchas
2025-11-12 20:34:16,152 - ERROR - root - No success fetching with selenium: cannot access local variable 'Options' where it is not associated with a value
2025-11-12 20:34:16,673 - INFO - root - Google Scholar 未返回结果。
2025-11-12 20:34:16,675 - INFO - root - 没有找到要处理的论文，程序退出
2025-11-12 20:34:16,675 - INFO - root - 总运行时间: 19.84 seconds
2025-11-12 20:36:35,216 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-12 20:36:35,218 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-12 20:36:35,222 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-12 20:36:56,232 - INFO - root - GeminiClient: trying model models/gemini-2.5-flash
2025-11-12 20:37:11,666 - INFO - root - GeminiClient: initialized model gemini-2.5-flash
2025-11-12 20:37:11,667 - INFO - root - LLMClientManager: Gemini client initialized successfully
2025-11-12 20:37:11,667 - INFO - root - LLMClientManager: using Gemini as default client
2025-11-12 20:37:11,668 - INFO - root - DeepSeekClient: API key found: 9f9e270e-b...
2025-11-12 20:37:11,668 - INFO - root - DeepSeekClient: 使用模式: 火山引擎
2025-11-12 20:37:11,669 - INFO - root - DeepSeekClient: 模型名称: deepseek-v3-1-terminus
2025-11-12 20:37:15,062 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 20:37:15,083 - INFO - root - DeepSeekClient: initialized successfully with model deepseek-v3-1-terminus
2025-11-12 20:37:15,083 - INFO - root - LLMClientManager: DeepSeek client initialized successfully
2025-11-12 20:37:15,083 - WARNING - root - KimiClient: API key not provided. LLM disabled.
2025-11-12 20:37:15,084 - WARNING - root - LLMClientManager: Kimi client initialization failed
2025-11-12 20:37:15,084 - WARNING - root - QwenClient: API key not provided. LLM disabled.
2025-11-12 20:37:15,084 - WARNING - root - LLMClientManager: Qwen client initialization failed
2025-11-12 20:37:15,085 - INFO - root - DoubaoClient: API key found: 9f9e270e-b...
2025-11-12 20:37:19,549 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 20:37:19,549 - INFO - root - DoubaoClient: initialized successfully with model doubao-seed-1-6-lite-251015
2025-11-12 20:37:19,549 - INFO - root - LLMClientManager: Doubao client initialized successfully
2025-11-12 20:37:19,549 - INFO - root - 使用 LLM 模型: gemini-2.5-flash
2025-11-12 20:37:19,551 - INFO - root - 可用客户端: ['Gemini', 'DeepSeek', 'Doubao']
2025-11-12 20:37:19,553 - INFO - root - === 运行配置 ===
2025-11-12 20:37:19,553 - INFO - root - 处理模式: Google Scholar 高引用搜索 (爬虫)
2025-11-12 20:37:19,554 - INFO - root - 查询 (关键词): transformer attention
2025-11-12 20:37:19,554 - INFO - root - 关键词 (用于保存): Transformer_Legacy
2025-11-12 20:37:19,555 - INFO - root - 排序: Citations
2025-11-12 20:37:19,556 - INFO - root - 年份范围: 2017 - 2020
2025-11-12 20:37:19,556 - INFO - root - 最大处理数量: 2
2025-11-12 20:37:19,559 - INFO - root - 保存图片: 否
2025-11-12 20:37:19,562 - INFO - root - 输出语言: 中文
2025-11-12 20:37:19,562 - INFO - root - 强制重新处理: 否
2025-11-12 20:37:19,563 - INFO - root - LLM 客户端: None
2025-11-12 20:37:19,563 - INFO - root - ====================
2025-11-12 20:37:19,563 - INFO - root - 正在使用检索策略: scholar
2025-11-12 20:37:19,563 - INFO - root - 使用 Google Scholar 高引用搜索模式 (爬虫)
2025-11-12 20:37:19,563 - INFO - root - Scholar 配置: 关键词=transformer attention, 数量=2, 排序=Citations, 年份=2017-2020
2025-11-12 20:37:21,155 - WARNING - root - Robot checking detected, handling with selenium (if installed)
2025-11-12 20:37:21,307 - ERROR - root - No success fetching with selenium: WebDriver.__init__() got an unexpected keyword argument 'chrome_options'
2025-11-12 20:37:21,847 - INFO - root - Google Scholar 未返回结果。
2025-11-12 20:37:21,852 - INFO - root - 没有找到要处理的论文，程序退出
2025-11-12 20:37:21,852 - INFO - root - 总运行时间: 46.64 seconds
2025-11-12 20:41:42,053 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-12 20:41:42,053 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-12 20:41:42,053 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-12 20:41:46,999 - INFO - root - GeminiClient: trying model models/gemini-2.5-flash
2025-11-12 20:41:51,030 - INFO - root - GeminiClient: initialized model gemini-2.5-flash
2025-11-12 20:41:51,081 - INFO - root - LLMClientManager: Gemini client initialized successfully
2025-11-12 20:41:51,083 - INFO - root - LLMClientManager: using Gemini as default client
2025-11-12 20:41:51,083 - INFO - root - DeepSeekClient: API key found: 9f9e270e-b...
2025-11-12 20:41:51,084 - INFO - root - DeepSeekClient: 使用模式: 火山引擎
2025-11-12 20:41:51,085 - INFO - root - DeepSeekClient: 模型名称: deepseek-v3-1-terminus
2025-11-12 20:41:53,779 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 20:41:53,795 - INFO - root - DeepSeekClient: initialized successfully with model deepseek-v3-1-terminus
2025-11-12 20:41:53,797 - INFO - root - LLMClientManager: DeepSeek client initialized successfully
2025-11-12 20:41:53,798 - WARNING - root - KimiClient: API key not provided. LLM disabled.
2025-11-12 20:41:53,798 - WARNING - root - LLMClientManager: Kimi client initialization failed
2025-11-12 20:41:53,798 - WARNING - root - QwenClient: API key not provided. LLM disabled.
2025-11-12 20:41:53,799 - WARNING - root - LLMClientManager: Qwen client initialization failed
2025-11-12 20:41:53,799 - INFO - root - DoubaoClient: API key found: 9f9e270e-b...
2025-11-12 20:41:58,893 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 20:41:58,900 - INFO - root - DoubaoClient: initialized successfully with model doubao-seed-1-6-lite-251015
2025-11-12 20:41:58,902 - INFO - root - LLMClientManager: Doubao client initialized successfully
2025-11-12 20:41:58,903 - INFO - root - 使用 LLM 模型: gemini-2.5-flash
2025-11-12 20:41:58,905 - INFO - root - 可用客户端: ['Gemini', 'DeepSeek', 'Doubao']
2025-11-12 20:41:58,907 - INFO - root - === 运行配置 ===
2025-11-12 20:41:58,908 - INFO - root - 处理模式: Google Scholar 高引用搜索 (爬虫)
2025-11-12 20:41:58,908 - INFO - root - 查询 (关键词): transformer attention
2025-11-12 20:41:58,909 - INFO - root - 关键词 (用于保存): Transformer_Legacy
2025-11-12 20:41:58,910 - INFO - root - 排序: Citations
2025-11-12 20:41:58,911 - INFO - root - 年份范围: 2017 - 2020
2025-11-12 20:41:58,912 - INFO - root - 最大处理数量: 2
2025-11-12 20:41:58,915 - INFO - root - 保存图片: 否
2025-11-12 20:41:58,916 - INFO - root - 输出语言: 中文
2025-11-12 20:41:58,916 - INFO - root - 强制重新处理: 否
2025-11-12 20:41:58,917 - INFO - root - LLM 客户端: None
2025-11-12 20:41:58,918 - INFO - root - ====================
2025-11-12 20:41:58,918 - INFO - root - 正在使用检索策略: scholar
2025-11-12 20:41:58,919 - INFO - root - 使用 Google Scholar 高引用搜索模式 (爬虫)
2025-11-12 20:41:58,920 - INFO - root - Scholar 配置: 关键词=transformer attention, 数量=2, 排序=Citations, 年份=2017-2020
2025-11-12 20:42:01,031 - WARNING - root - Robot checking detected, handling with selenium (if installed)
2025-11-12 20:42:19,172 - WARNING - root - Element not found: /html/body
2025-11-12 20:42:19,172 - ERROR - root - No success fetching with selenium: 'NoneType' object has no attribute 'get_attribute'
2025-11-12 20:42:19,677 - INFO - root - Google Scholar 未返回结果。
2025-11-12 20:42:19,684 - INFO - root - 没有找到要处理的论文，程序退出
2025-11-12 20:42:19,684 - INFO - root - 总运行时间: 37.63 seconds
2025-11-12 20:46:48,862 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-12 20:46:48,863 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-12 20:46:48,865 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-12 20:46:53,114 - INFO - root - GeminiClient: trying model models/gemini-2.5-flash
2025-11-12 20:46:55,253 - INFO - root - GeminiClient: initialized model gemini-2.5-flash
2025-11-12 20:46:55,254 - INFO - root - LLMClientManager: Gemini client initialized successfully
2025-11-12 20:46:55,254 - INFO - root - LLMClientManager: using Gemini as default client
2025-11-12 20:46:55,255 - INFO - root - DeepSeekClient: API key found: 9f9e270e-b...
2025-11-12 20:46:55,256 - INFO - root - DeepSeekClient: 使用模式: 火山引擎
2025-11-12 20:46:55,257 - INFO - root - DeepSeekClient: 模型名称: deepseek-v3-1-terminus
2025-11-12 20:46:58,204 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 20:46:58,221 - INFO - root - DeepSeekClient: initialized successfully with model deepseek-v3-1-terminus
2025-11-12 20:46:58,223 - INFO - root - LLMClientManager: DeepSeek client initialized successfully
2025-11-12 20:46:58,224 - WARNING - root - KimiClient: API key not provided. LLM disabled.
2025-11-12 20:46:58,225 - WARNING - root - LLMClientManager: Kimi client initialization failed
2025-11-12 20:46:58,226 - WARNING - root - QwenClient: API key not provided. LLM disabled.
2025-11-12 20:46:58,226 - WARNING - root - LLMClientManager: Qwen client initialization failed
2025-11-12 20:46:58,227 - INFO - root - DoubaoClient: API key found: 9f9e270e-b...
2025-11-12 20:47:02,187 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 20:47:02,189 - INFO - root - DoubaoClient: initialized successfully with model doubao-seed-1-6-lite-251015
2025-11-12 20:47:02,190 - INFO - root - LLMClientManager: Doubao client initialized successfully
2025-11-12 20:47:02,190 - INFO - root - 使用 LLM 模型: gemini-2.5-flash
2025-11-12 20:47:02,191 - INFO - root - 可用客户端: ['Gemini', 'DeepSeek', 'Doubao']
2025-11-12 20:47:02,191 - INFO - root - === 运行配置 ===
2025-11-12 20:47:02,191 - INFO - root - 处理模式: Google Scholar 高引用搜索 (爬虫)
2025-11-12 20:47:02,191 - INFO - root - 查询 (关键词): transformer attention
2025-11-12 20:47:02,192 - INFO - root - 关键词 (用于保存): Transformer_Legacy
2025-11-12 20:47:02,192 - INFO - root - 排序: Citations
2025-11-12 20:47:02,193 - INFO - root - 年份范围: 2017 - 2020
2025-11-12 20:47:02,193 - INFO - root - 最大处理数量: 2
2025-11-12 20:47:02,194 - INFO - root - 保存图片: 否
2025-11-12 20:47:02,195 - INFO - root - 输出语言: 中文
2025-11-12 20:47:02,195 - INFO - root - 强制重新处理: 否
2025-11-12 20:47:02,195 - INFO - root - LLM 客户端: None
2025-11-12 20:47:02,196 - INFO - root - ====================
2025-11-12 20:47:02,196 - INFO - root - 正在使用检索策略: scholar
2025-11-12 20:47:02,196 - INFO - root - 使用 Google Scholar 高引用搜索模式 (爬虫)
2025-11-12 20:47:02,197 - INFO - root - Scholar 配置: 关键词=transformer attention, 数量=2, 排序=Citations, 年份=2017-2020
2025-11-12 20:47:03,739 - WARNING - root - Robot checking detected, handling with selenium (if installed)
2025-11-12 20:47:09,757 - INFO - root - 正在下载: https://arxiv.org/pdf/2004.05150.pdf
2025-11-12 20:47:12,679 - INFO - root - 已保存到: D:\ChatPaper\downloads\Transformer_Legacy\Longformer_ The long-document transformer.pdf
2025-11-12 20:47:12,684 - INFO - root - 成功下载 (Scholar-ArXiv): Longformer: The long-document transformer
2025-11-12 20:47:12,684 - WARNING - root - 【手动下载提示】(非ArXiv链接): Set transformer: A framework for attention-based permutation-invariant neural networks @ http://proceedings.mlr.press/v97/lee19d.html
2025-11-12 20:47:12,687 - INFO - root - 正在下载: https://arxiv.org/pdf/1906.05714.pdf
2025-11-12 20:47:15,716 - INFO - root - 已保存到: D:\ChatPaper\downloads\Transformer_Legacy\A multiscale visualization of attention in the transformer model.pdf
2025-11-12 20:47:15,723 - INFO - root - 成功下载 (Scholar-ArXiv): A multiscale visualization of attention in the transformer model
2025-11-12 20:47:15,738 - INFO - root - 检索到 2 篇论文，开始总结...
2025-11-12 20:47:15,754 - INFO - root - 正在总结论文 1/2: Longformer: The long-document transformer
2025-11-12 20:47:58,312 - INFO - root - LLMClient: rate limit reached, sleeping 17.5s
2025-11-12 20:48:58,633 - INFO - root - 论文《Longformer: The long-document transformer》的分析已保存到 ./export\Transformer_Legacy\Longformer_ The long-document transformer.md
2025-11-12 20:48:58,635 - INFO - root - 正在总结论文 2/2: A multiscale visualization of attention in the transformer model
2025-11-12 20:49:07,887 - INFO - root - LLMClient: rate limit reached, sleeping 7.9s
2025-11-12 20:49:47,159 - INFO - root - LLMClient: rate limit reached, sleeping 11.5s
2025-11-12 20:50:39,601 - INFO - root - 论文《A multiscale visualization of attention in the transformer model》的分析已保存到 ./export\Transformer_Legacy\A multiscale visualization of attention in the transformer model.md
2025-11-12 20:50:40,004 - INFO - root - 已生成汇总Excel表格: export\Transformer_Legacy\论文汇总_Transformer_Legacy_20251112_205039.xlsx
2025-11-12 20:50:40,005 - INFO - root - 已生成汇总Excel表格: export\Transformer_Legacy\论文汇总_Transformer_Legacy_20251112_205039.xlsx
2025-11-12 20:50:40,005 - INFO - root - 总运行时间: 231.14 seconds
2025-11-12 20:54:13,310 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-12 20:54:13,312 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-12 20:54:13,314 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-12 20:54:22,098 - INFO - root - LLMClientManager: 指定使用客户端: Deepseek
2025-11-12 20:54:22,099 - INFO - root - DeepSeekClient: API key found: 9f9e270e-b...
2025-11-12 20:54:22,099 - INFO - root - DeepSeekClient: 使用模式: 火山引擎
2025-11-12 20:54:22,099 - INFO - root - DeepSeekClient: 模型名称: deepseek-v3-1-terminus
2025-11-12 20:54:25,710 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 20:54:25,745 - INFO - root - DeepSeekClient: initialized successfully with model deepseek-v3-1-terminus
2025-11-12 20:54:25,754 - INFO - root - LLMClientManager: DeepSeek 客户端初始化成功
2025-11-12 20:54:25,762 - INFO - root - LLMClientManager: switched to DeepSeek client (case-insensitive match)
2025-11-12 20:54:25,769 - INFO - root - 已手动切换到 LLM 客户端: Deepseek
2025-11-12 20:54:25,774 - INFO - root - 使用 LLM 模型: deepseek-v3-1-terminus
2025-11-12 20:54:25,781 - INFO - root - 可用客户端: ['DeepSeek']
2025-11-12 20:54:25,788 - INFO - root - === 运行配置 ===
2025-11-12 20:54:25,791 - INFO - root - 处理模式: arXiv 最新搜索 (API)
2025-11-12 20:54:25,801 - INFO - root - 查询: all:hybrid attention
2025-11-12 20:54:25,805 - INFO - root - 关键词 (用于保存): hybrid attention
2025-11-12 20:54:25,813 - INFO - root - 排序: SubmittedDate
2025-11-12 20:54:25,817 - INFO - root - 最近天数: 1000
2025-11-12 20:54:25,820 - INFO - root - 最大处理数量: 40
2025-11-12 20:54:25,824 - INFO - root - 保存图片: 是
2025-11-12 20:54:25,835 - INFO - root - 输出语言: 中文
2025-11-12 20:54:25,839 - INFO - root - 强制重新处理: 否
2025-11-12 20:54:25,846 - INFO - root - LLM 客户端: Deepseek
2025-11-12 20:54:25,851 - INFO - root - ====================
2025-11-12 20:54:25,853 - INFO - root - 正在使用检索策略: arxiv
2025-11-12 20:54:25,861 - INFO - root - 使用 arXiv 搜索模式 (API + 并发)
2025-11-12 20:54:25,869 - INFO - root - 正在使用 arXiv API 搜索: query='all:hybrid attention', sort_by=SubmittedDate
2025-11-12 20:54:25,882 - INFO - arxiv - Requesting page (first: True, try: 0): https://export.arxiv.org/api/query?search_query=all%3Ahybrid+attention&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=50
2025-11-12 20:54:27,658 - INFO - arxiv - Got first page: 50 of 135016 total results
2025-11-12 20:54:27,664 - INFO - root - API 返回了 50 篇论文
2025-11-12 20:54:27,666 - INFO - root - 论文 'Symmetries and periodic orbits in simple hybrid Routhian systems' (日期: 2020-01-24) 已超出 1000 天范围，停止过滤。
2025-11-12 20:54:27,667 - INFO - root - 经过 'days=1000' 过滤后，剩余 0 篇论文。
2025-11-12 20:54:27,668 - INFO - root - 没有找到要处理的论文。
2025-11-12 20:54:27,668 - INFO - root - 没有找到要处理的论文，程序退出
2025-11-12 20:54:27,669 - INFO - root - 总运行时间: 14.36 seconds
2025-11-12 21:02:09,363 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-12 21:02:09,363 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-12 21:02:09,363 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-12 21:02:13,220 - INFO - root - LLMClientManager: 指定使用客户端: Deepseek
2025-11-12 21:02:13,221 - INFO - root - DeepSeekClient: API key found: 9f9e270e-b...
2025-11-12 21:02:13,221 - INFO - root - DeepSeekClient: 使用模式: 火山引擎
2025-11-12 21:02:13,222 - INFO - root - DeepSeekClient: 模型名称: deepseek-v3-1-terminus
2025-11-12 21:02:16,233 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 21:02:16,258 - INFO - root - DeepSeekClient: initialized successfully with model deepseek-v3-1-terminus
2025-11-12 21:02:16,258 - INFO - root - LLMClientManager: DeepSeek 客户端初始化成功
2025-11-12 21:02:16,261 - INFO - root - LLMClientManager: switched to DeepSeek client (case-insensitive match)
2025-11-12 21:02:16,261 - INFO - root - 已手动切换到 LLM 客户端: Deepseek
2025-11-12 21:02:16,261 - INFO - root - 使用 LLM 模型: deepseek-v3-1-terminus
2025-11-12 21:02:16,263 - INFO - root - 可用客户端: ['DeepSeek']
2025-11-12 21:02:16,263 - INFO - root - === 运行配置 ===
2025-11-12 21:02:16,264 - INFO - root - 处理模式: arXiv 最新搜索 (API)
2025-11-12 21:02:16,264 - INFO - root - 查询: hybrid attention
2025-11-12 21:02:16,264 - INFO - root - 关键词 (用于保存): hybrid attention
2025-11-12 21:02:16,264 - INFO - root - 排序: SubmittedDate
2025-11-12 21:02:16,265 - INFO - root - 最近天数: 1000
2025-11-12 21:02:16,265 - INFO - root - 最大处理数量: 40
2025-11-12 21:02:16,265 - INFO - root - 保存图片: 是
2025-11-12 21:02:16,266 - INFO - root - 输出语言: 中文
2025-11-12 21:02:16,266 - INFO - root - 强制重新处理: 否
2025-11-12 21:02:16,266 - INFO - root - LLM 客户端: Deepseek
2025-11-12 21:02:16,267 - INFO - root - ====================
2025-11-12 21:02:16,267 - INFO - root - 正在使用检索策略: arxiv
2025-11-12 21:02:16,267 - INFO - root - 使用 arXiv 搜索模式 (API + 并发)
2025-11-12 21:02:16,268 - INFO - root - 正在使用 arXiv API 搜索: query='hybrid attention', sort_by=SubmittedDate
2025-11-12 21:02:16,269 - INFO - arxiv - Requesting page (first: True, try: 0): https://export.arxiv.org/api/query?search_query=hybrid+attention&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=50
2025-11-12 21:02:17,999 - INFO - arxiv - Got first page: 50 of 135016 total results
2025-11-12 21:02:18,010 - INFO - root - API 返回了 50 篇论文
2025-11-12 21:02:18,013 - INFO - root - 论文 'Symmetries and periodic orbits in simple hybrid Routhian systems' (日期: 2020-01-24) 已超出 1000 天范围，停止过滤。
2025-11-12 21:02:18,013 - INFO - root - 经过 'days=1000' 过滤后，剩余 0 篇论文。
2025-11-12 21:02:18,014 - INFO - root - 没有找到要处理的论文。
2025-11-12 21:02:18,016 - INFO - root - 没有找到要处理的论文，程序退出
2025-11-12 21:02:18,016 - INFO - root - 总运行时间: 8.65 seconds
2025-11-12 21:09:15,834 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-12 21:09:15,838 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-12 21:09:15,840 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-12 21:09:24,479 - INFO - root - LLMClientManager: 指定使用客户端: Deepseek
2025-11-12 21:09:24,480 - INFO - root - DeepSeekClient: API key found: 9f9e270e-b...
2025-11-12 21:09:24,480 - INFO - root - DeepSeekClient: 使用模式: 火山引擎
2025-11-12 21:09:24,480 - INFO - root - DeepSeekClient: 模型名称: deepseek-v3-1-terminus
2025-11-12 21:09:28,979 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 21:09:29,002 - INFO - root - DeepSeekClient: initialized successfully with model deepseek-v3-1-terminus
2025-11-12 21:09:29,003 - INFO - root - LLMClientManager: DeepSeek 客户端初始化成功
2025-11-12 21:09:29,003 - INFO - root - LLMClientManager: switched to DeepSeek client (case-insensitive match)
2025-11-12 21:09:29,004 - INFO - root - 已手动切换到 LLM 客户端: Deepseek
2025-11-12 21:09:29,005 - INFO - root - 使用 LLM 模型: deepseek-v3-1-terminus
2025-11-12 21:09:29,006 - INFO - root - 可用客户端: ['DeepSeek']
2025-11-12 21:09:29,006 - INFO - root - === 运行配置 ===
2025-11-12 21:09:29,006 - INFO - root - 处理模式: arXiv 最新搜索 (API)
2025-11-12 21:09:29,007 - INFO - root - 查询: hybrid attention
2025-11-12 21:09:29,007 - INFO - root - 关键词 (用于保存): hybrid attention
2025-11-12 21:09:29,008 - INFO - root - 排序: SubmittedDate
2025-11-12 21:09:29,009 - INFO - root - 最近天数: 1000
2025-11-12 21:09:29,010 - INFO - root - 最大处理数量: 40
2025-11-12 21:09:29,010 - INFO - root - 保存图片: 是
2025-11-12 21:09:29,016 - INFO - root - 输出语言: 中文
2025-11-12 21:09:29,016 - INFO - root - 强制重新处理: 否
2025-11-12 21:09:29,017 - INFO - root - LLM 客户端: Deepseek
2025-11-12 21:09:29,017 - INFO - root - ====================
2025-11-12 21:09:29,018 - INFO - root - 正在使用检索策略: arxiv
2025-11-12 21:09:29,019 - INFO - root - 使用 arXiv 搜索模式 (API + 并发)
2025-11-12 21:09:29,020 - INFO - root - 正在使用 arXiv API 搜索: query='hybrid attention', sort_by=SubmittedDate
2025-11-12 21:09:29,022 - INFO - arxiv - Requesting page (first: True, try: 0): https://export.arxiv.org/api/query?search_query=hybrid+attention&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=50
2025-11-12 21:09:30,347 - INFO - arxiv - Got first page: 50 of 135016 total results
2025-11-12 21:09:30,347 - INFO - root - API 返回了 50 篇论文
2025-11-12 21:09:30,359 - INFO - root - 开始按 1000 天过滤 (检查 50 篇论文)...
2025-11-12 21:09:30,359 - INFO - root - 经过 'days=1000' 过滤后，剩余 18 篇论文。
2025-11-12 21:09:30,359 - INFO - root - 将开始并发下载 18 篇论文...
2025-11-12 21:09:30,366 - INFO - root - 正在下载: http://arxiv.org/pdf/2305.15599v1.pdf
2025-11-12 21:09:30,367 - INFO - root - 正在下载: http://arxiv.org/pdf/2306.05427v2.pdf
2025-11-12 21:09:30,372 - INFO - root - 正在下载: http://arxiv.org/pdf/2506.19852v1.pdf
2025-11-12 21:09:30,373 - INFO - root - 正在下载: http://arxiv.org/pdf/2411.09702v1.pdf
2025-11-12 21:09:30,385 - INFO - root - 正在下载: http://arxiv.org/pdf/2406.13770v2.pdf
2025-11-12 21:09:37,715 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\hybrid attention\Radial Attention_ $O(n_log n)$ Sparse Attention with Energy Decay for Long Video Generation.pdf
2025-11-12 21:09:37,721 - INFO - root - 成功创建 Paper 对象: 2506.19852v1
2025-11-12 21:09:37,721 - INFO - root - 下载进度: 1/18
2025-11-12 21:09:37,724 - INFO - root - 正在下载: http://arxiv.org/pdf/2307.13365v3.pdf
2025-11-12 21:09:38,080 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\hybrid attention\Elliptical Attention.pdf
2025-11-12 21:09:38,083 - INFO - root - 成功创建 Paper 对象: 2406.13770v2
2025-11-12 21:09:38,083 - INFO - root - 下载进度: 2/18
2025-11-12 21:09:38,084 - INFO - root - 正在下载: http://arxiv.org/pdf/2403.16990v1.pdf
2025-11-12 21:09:40,171 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\hybrid attention\Hybrid-MPET_ an open-source simulation software for hybrid electrode batteries.pdf
2025-11-12 21:09:40,177 - INFO - root - 成功创建 Paper 对象: 2305.15599v1
2025-11-12 21:09:40,178 - INFO - root - 下载进度: 3/18
2025-11-12 21:09:40,178 - INFO - root - 正在下载: http://arxiv.org/pdf/2303.17696v1.pdf
2025-11-12 21:09:41,296 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\hybrid attention\On the Surprising Effectiveness of Attention Transfer for Vision Transformers.pdf
2025-11-12 21:09:41,312 - INFO - root - 成功创建 Paper 对象: 2411.09702v1
2025-11-12 21:09:41,312 - INFO - root - 下载进度: 4/18
2025-11-12 21:09:41,312 - INFO - root - 正在下载: http://arxiv.org/pdf/2509.07963v1.pdf
2025-11-12 21:09:44,284 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\hybrid attention\Pay Attention to What You Need.pdf
2025-11-12 21:09:44,284 - INFO - root - 成功创建 Paper 对象: 2307.13365v3
2025-11-12 21:09:44,284 - INFO - root - 下载进度: 5/18
2025-11-12 21:09:44,284 - INFO - root - 正在下载: http://arxiv.org/pdf/2409.17625v3.pdf
2025-11-12 21:09:52,664 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\hybrid attention\Dual Cross-Attention for Medical Image Segmentation.pdf
2025-11-12 21:09:52,664 - INFO - root - 成功创建 Paper 对象: 2303.17696v1
2025-11-12 21:09:52,664 - INFO - root - 下载进度: 6/18
2025-11-12 21:09:52,664 - INFO - root - 正在下载: http://arxiv.org/pdf/2407.13885v1.pdf
2025-11-12 21:09:55,376 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\hybrid attention\Customizing the Inductive Biases of Softmax Attention using Structured Matrices.pdf
2025-11-12 21:09:55,378 - INFO - root - 成功创建 Paper 对象: 2509.07963v1
2025-11-12 21:09:55,380 - INFO - root - 下载进度: 7/18
2025-11-12 21:09:55,380 - INFO - root - 正在下载: http://arxiv.org/pdf/2406.05816v4.pdf
2025-11-12 21:09:55,413 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\hybrid attention\Benign Overfitting in Token Selection of Attention Mechanism.pdf
2025-11-12 21:09:55,414 - INFO - root - 成功创建 Paper 对象: 2409.17625v3
2025-11-12 21:09:55,415 - INFO - root - 下载进度: 8/18
2025-11-12 21:09:55,416 - INFO - root - 正在下载: http://arxiv.org/pdf/2507.06457v1.pdf
2025-11-12 21:09:56,641 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\hybrid attention\Attention in SRAM on Tenstorrent Grayskull.pdf
2025-11-12 21:09:56,645 - INFO - root - 成功创建 Paper 对象: 2407.13885v1
2025-11-12 21:09:56,646 - INFO - root - 下载进度: 9/18
2025-11-12 21:09:56,646 - INFO - root - 正在下载: http://arxiv.org/pdf/2411.00348v2.pdf
2025-11-12 21:10:00,532 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\hybrid attention\Grounded Text-to-Image Synthesis with Attention Refocusing.pdf
2025-11-12 21:10:00,539 - INFO - root - 成功创建 Paper 对象: 2306.05427v2
2025-11-12 21:10:00,540 - INFO - root - 下载进度: 10/18
2025-11-12 21:10:00,541 - INFO - root - 正在下载: http://arxiv.org/pdf/2503.02130v2.pdf
2025-11-12 21:10:01,644 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\hybrid attention\Attention Tracker_ Detecting Prompt Injection Attacks in LLMs.pdf
2025-11-12 21:10:01,688 - INFO - root - 成功创建 Paper 对象: 2411.00348v2
2025-11-12 21:10:01,748 - INFO - root - 下载进度: 11/18
2025-11-12 21:10:01,750 - INFO - root - 正在下载: http://arxiv.org/pdf/2403.18413v2.pdf
2025-11-12 21:10:02,018 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\hybrid attention\A Systematic Analysis of Hybrid Linear Attention.pdf
2025-11-12 21:10:02,020 - INFO - root - 成功创建 Paper 对象: 2507.06457v1
2025-11-12 21:10:02,021 - INFO - root - 下载进度: 12/18
2025-11-12 21:10:02,022 - INFO - root - 正在下载: http://arxiv.org/pdf/2303.15105v1.pdf
2025-11-12 21:10:02,596 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\hybrid attention\Attention as a Hypernetwork.pdf
2025-11-12 21:10:02,599 - INFO - root - 成功创建 Paper 对象: 2406.05816v4
2025-11-12 21:10:02,599 - INFO - root - 下载进度: 13/18
2025-11-12 21:10:02,599 - INFO - root - 正在下载: http://arxiv.org/pdf/2311.03335v1.pdf
2025-11-12 21:10:04,293 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\hybrid attention\HyRRT-Connect_ A Bidirectional Rapidly-Exploring Random Trees Motion Planning Algorithm for Hybrid S.pdf
2025-11-12 21:10:04,293 - INFO - root - 成功创建 Paper 对象: 2403.18413v2
2025-11-12 21:10:04,295 - INFO - root - 下载进度: 14/18
2025-11-12 21:10:09,577 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\hybrid attention\Vision Transformer with Quadrangle Attention.pdf
2025-11-12 21:10:09,580 - INFO - root - 成功创建 Paper 对象: 2303.15105v1
2025-11-12 21:10:09,580 - INFO - root - 下载进度: 15/18
2025-11-12 21:10:11,728 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\hybrid attention\Forgetting Transformer_ Softmax Attention with a Forget Gate.pdf
2025-11-12 21:10:11,734 - INFO - root - 成功创建 Paper 对象: 2503.02130v2
2025-11-12 21:10:11,739 - INFO - root - 下载进度: 16/18
2025-11-12 21:10:16,417 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\hybrid attention\Be Yourself_ Bounded Attention for Multi-Subject Text-to-Image Generation.pdf
2025-11-12 21:10:16,498 - INFO - root - 成功创建 Paper 对象: 2403.16990v1
2025-11-12 21:10:16,555 - INFO - root - 下载进度: 17/18
2025-11-12 21:11:11,497 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\hybrid attention\Cross-Image Attention for Zero-Shot Appearance Transfer.pdf
2025-11-12 21:11:11,501 - INFO - root - 成功创建 Paper 对象: 2311.03335v1
2025-11-12 21:11:11,502 - INFO - root - 下载进度: 18/18
2025-11-12 21:11:11,503 - INFO - root - 成功下载并处理了 18 篇论文，耗时 101.13 秒。
2025-11-12 21:11:11,504 - INFO - root - 检索到 18 篇论文，开始总结...
2025-11-12 21:11:11,509 - INFO - root - 正在总结论文 1/18: Radial Attention: $O(n\log n)$ Sparse Attention with Energy Decay for Long Video Generation
2025-11-12 21:11:22,812 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 21:12:13,397 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 21:12:48,279 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 21:12:48,285 - INFO - root - 正在提取论文图片到目录: ./export\hybrid attention\images
2025-11-12 21:12:48,995 - INFO - root - 已保存图片 1/10：./export\hybrid attention\images\figure_1_page16.jpeg
2025-11-12 21:12:49,082 - INFO - root - 已保存图片 2/10：./export\hybrid attention\images\figure_2_page16.jpeg
2025-11-12 21:12:49,169 - INFO - root - 已保存图片 3/10：./export\hybrid attention\images\figure_3_page16.jpeg
2025-11-12 21:12:49,251 - INFO - root - 已保存图片 4/10：./export\hybrid attention\images\figure_4_page16.jpeg
2025-11-12 21:12:49,336 - INFO - root - 已保存图片 5/10：./export\hybrid attention\images\figure_5_page16.jpeg
2025-11-12 21:12:49,421 - INFO - root - 已保存图片 6/10：./export\hybrid attention\images\figure_6_page16.jpeg
2025-11-12 21:12:49,515 - INFO - root - 已保存图片 7/10：./export\hybrid attention\images\figure_7_page16.jpeg
2025-11-12 21:12:49,600 - INFO - root - 已保存图片 8/10：./export\hybrid attention\images\figure_8_page16.jpeg
2025-11-12 21:12:49,690 - INFO - root - 已保存图片 9/10：./export\hybrid attention\images\figure_9_page16.jpeg
2025-11-12 21:12:49,781 - INFO - root - 已保存图片 10/10：./export\hybrid attention\images\figure_10_page16.jpeg
2025-11-12 21:12:49,798 - INFO - root - 成功添加图片 1：./export\hybrid attention\images\figure_1_page16.jpeg
2025-11-12 21:12:49,798 - INFO - root - 成功添加图片 2：./export\hybrid attention\images\figure_2_page16.jpeg
2025-11-12 21:12:49,798 - INFO - root - 成功添加图片 3：./export\hybrid attention\images\figure_3_page16.jpeg
2025-11-12 21:12:49,798 - INFO - root - 成功添加图片 4：./export\hybrid attention\images\figure_4_page16.jpeg
2025-11-12 21:12:49,798 - INFO - root - 成功添加图片 5：./export\hybrid attention\images\figure_5_page16.jpeg
2025-11-12 21:12:49,798 - INFO - root - 成功添加图片 6：./export\hybrid attention\images\figure_6_page16.jpeg
2025-11-12 21:12:49,798 - INFO - root - 成功添加图片 7：./export\hybrid attention\images\figure_7_page16.jpeg
2025-11-12 21:12:49,804 - INFO - root - 成功添加图片 8：./export\hybrid attention\images\figure_8_page16.jpeg
2025-11-12 21:12:49,805 - INFO - root - 成功添加图片 9：./export\hybrid attention\images\figure_9_page16.jpeg
2025-11-12 21:12:49,806 - INFO - root - 成功添加图片 10：./export\hybrid attention\images\figure_10_page16.jpeg
2025-11-12 21:12:49,811 - INFO - root - 已更新图片链接
2025-11-12 21:12:49,813 - INFO - root - 论文《Radial Attention: $O(n\log n)$ Sparse Attention with Energy Decay for Long Video Generation》的分析已保存到 ./export\hybrid attention\Radial Attention_ $O(n_log n)$ Sparse Attention with Energy Decay for Long Video Generation.md
2025-11-12 21:12:49,816 - INFO - root - 正在总结论文 2/18: Elliptical Attention
2025-11-12 21:13:03,238 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 21:13:03,238 - INFO - root - LLMClient: rate limit reached, sleeping 10.2s
2025-11-12 21:14:20,224 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 21:15:05,146 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 21:15:05,149 - INFO - root - 正在提取论文图片到目录: ./export\hybrid attention\images
2025-11-12 21:15:06,344 - INFO - root - 已保存图片 1/10：./export\hybrid attention\images\figure_1_page10.png
2025-11-12 21:15:06,461 - INFO - root - 已保存图片 2/10：./export\hybrid attention\images\figure_2_page4.png
2025-11-12 21:15:06,544 - INFO - root - 已保存图片 3/10：./export\hybrid attention\images\figure_3_page3.png
2025-11-12 21:15:06,602 - INFO - root - 已保存图片 4/10：./export\hybrid attention\images\figure_4_page2.png
2025-11-12 21:15:06,648 - INFO - root - 已保存图片 5/10：./export\hybrid attention\images\figure_5_page29.png
2025-11-12 21:15:06,689 - INFO - root - 已保存图片 6/10：./export\hybrid attention\images\figure_6_page29.png
2025-11-12 21:15:06,734 - INFO - root - 已保存图片 7/10：./export\hybrid attention\images\figure_7_page29.png
2025-11-12 21:15:06,780 - INFO - root - 已保存图片 8/10：./export\hybrid attention\images\figure_8_page24.png
2025-11-12 21:15:06,810 - INFO - root - 已保存图片 9/10：./export\hybrid attention\images\figure_9_page24.png
2025-11-12 21:15:06,816 - INFO - root - 成功添加图片 1：./export\hybrid attention\images\figure_1_page10.png
2025-11-12 21:15:06,817 - INFO - root - 成功添加图片 2：./export\hybrid attention\images\figure_2_page4.png
2025-11-12 21:15:06,817 - INFO - root - 成功添加图片 3：./export\hybrid attention\images\figure_3_page3.png
2025-11-12 21:15:06,817 - INFO - root - 成功添加图片 4：./export\hybrid attention\images\figure_4_page2.png
2025-11-12 21:15:06,818 - INFO - root - 成功添加图片 5：./export\hybrid attention\images\figure_5_page29.png
2025-11-12 21:15:06,818 - INFO - root - 成功添加图片 6：./export\hybrid attention\images\figure_6_page29.png
2025-11-12 21:15:06,818 - INFO - root - 成功添加图片 7：./export\hybrid attention\images\figure_7_page29.png
2025-11-12 21:15:06,820 - INFO - root - 成功添加图片 8：./export\hybrid attention\images\figure_8_page24.png
2025-11-12 21:15:06,820 - INFO - root - 成功添加图片 9：./export\hybrid attention\images\figure_9_page24.png
2025-11-12 21:15:06,824 - INFO - root - 已更新图片链接
2025-11-12 21:15:06,829 - INFO - root - 论文《Elliptical Attention》的分析已保存到 ./export\hybrid attention\Elliptical Attention.md
2025-11-12 21:15:06,832 - INFO - root - 正在总结论文 3/18: Hybrid-MPET: an open-source simulation software for hybrid electrode batteries
2025-11-12 21:15:18,155 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 21:15:18,158 - INFO - root - LLMClient: rate limit reached, sleeping 2.1s
2025-11-12 21:16:25,407 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 21:17:00,836 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 21:17:00,873 - INFO - root - 正在提取论文图片到目录: ./export\hybrid attention\images
2025-11-12 21:17:02,703 - INFO - root - 已保存图片 1/10：./export\hybrid attention\images\figure_1_page20.png
2025-11-12 21:17:02,793 - INFO - root - 已保存图片 2/10：./export\hybrid attention\images\figure_2_page20.png
2025-11-12 21:17:02,801 - INFO - root - 已保存图片 3/10：./export\hybrid attention\images\figure_3_page18.png
2025-11-12 21:17:02,813 - INFO - root - 已保存图片 4/10：./export\hybrid attention\images\figure_4_page18.png
2025-11-12 21:17:02,828 - INFO - root - 成功添加图片 1：./export\hybrid attention\images\figure_1_page20.png
2025-11-12 21:17:02,828 - INFO - root - 成功添加图片 2：./export\hybrid attention\images\figure_2_page20.png
2025-11-12 21:17:02,830 - INFO - root - 成功添加图片 3：./export\hybrid attention\images\figure_3_page18.png
2025-11-12 21:17:02,830 - INFO - root - 成功添加图片 4：./export\hybrid attention\images\figure_4_page18.png
2025-11-12 21:17:02,832 - INFO - root - 已更新图片链接
2025-11-12 21:17:02,838 - INFO - root - 论文《Hybrid-MPET: an open-source simulation software for hybrid electrode batteries》的分析已保存到 ./export\hybrid attention\Hybrid-MPET_ an open-source simulation software for hybrid electrode batteries.md
2025-11-12 21:17:02,843 - INFO - root - 正在总结论文 4/18: On the Surprising Effectiveness of Attention Transfer for Vision Transformers
2025-11-12 21:17:14,875 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 21:17:14,879 - INFO - root - LLMClient: rate limit reached, sleeping 10.5s
2025-11-12 21:18:28,897 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 21:19:07,129 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 21:19:07,129 - INFO - root - 正在提取论文图片到目录: ./export\hybrid attention\images
2025-11-12 21:19:08,034 - INFO - root - 已保存图片 1/10：./export\hybrid attention\images\figure_1_page3.png
2025-11-12 21:19:08,100 - INFO - root - 已保存图片 2/10：./export\hybrid attention\images\figure_2_page3.png
2025-11-12 21:19:08,276 - INFO - root - 已保存图片 3/10：./export\hybrid attention\images\figure_3_page17.png
2025-11-12 21:19:08,398 - INFO - root - 已保存图片 4/10：./export\hybrid attention\images\figure_4_page17.png
2025-11-12 21:19:08,532 - INFO - root - 已保存图片 5/10：./export\hybrid attention\images\figure_5_page17.png
2025-11-12 21:19:08,672 - INFO - root - 已保存图片 6/10：./export\hybrid attention\images\figure_6_page17.png
2025-11-12 21:19:08,827 - INFO - root - 已保存图片 7/10：./export\hybrid attention\images\figure_7_page17.png
2025-11-12 21:19:08,944 - INFO - root - 已保存图片 8/10：./export\hybrid attention\images\figure_8_page17.png
2025-11-12 21:19:09,074 - INFO - root - 已保存图片 9/10：./export\hybrid attention\images\figure_9_page17.png
2025-11-12 21:19:09,227 - INFO - root - 已保存图片 10/10：./export\hybrid attention\images\figure_10_page17.png
2025-11-12 21:19:09,227 - INFO - root - 成功添加图片 1：./export\hybrid attention\images\figure_1_page3.png
2025-11-12 21:19:09,227 - INFO - root - 成功添加图片 2：./export\hybrid attention\images\figure_2_page3.png
2025-11-12 21:19:09,227 - INFO - root - 成功添加图片 3：./export\hybrid attention\images\figure_3_page17.png
2025-11-12 21:19:09,237 - INFO - root - 成功添加图片 4：./export\hybrid attention\images\figure_4_page17.png
2025-11-12 21:19:09,237 - INFO - root - 成功添加图片 5：./export\hybrid attention\images\figure_5_page17.png
2025-11-12 21:19:09,237 - INFO - root - 成功添加图片 6：./export\hybrid attention\images\figure_6_page17.png
2025-11-12 21:19:09,242 - INFO - root - 成功添加图片 7：./export\hybrid attention\images\figure_7_page17.png
2025-11-12 21:19:09,243 - INFO - root - 成功添加图片 8：./export\hybrid attention\images\figure_8_page17.png
2025-11-12 21:19:09,243 - INFO - root - 成功添加图片 9：./export\hybrid attention\images\figure_9_page17.png
2025-11-12 21:19:09,243 - INFO - root - 成功添加图片 10：./export\hybrid attention\images\figure_10_page17.png
2025-11-12 21:19:09,244 - INFO - root - 已更新图片链接
2025-11-12 21:19:09,249 - INFO - root - 论文《On the Surprising Effectiveness of Attention Transfer for Vision Transformers》的分析已保存到 ./export\hybrid attention\On the Surprising Effectiveness of Attention Transfer for Vision Transformers.md
2025-11-12 21:19:09,252 - INFO - root - 正在总结论文 5/18: Pay Attention to What You Need
2025-11-12 21:19:21,934 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 21:19:21,935 - INFO - root - LLMClient: rate limit reached, sleeping 7.0s
2025-11-12 21:20:20,260 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 21:20:54,714 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 21:20:54,717 - INFO - root - 正在提取论文图片到目录: ./export\hybrid attention\images
2025-11-12 21:20:56,690 - INFO - root - 已保存图片 1/10：./export\hybrid attention\images\figure_1_page2.png
2025-11-12 21:20:58,548 - INFO - root - 已保存图片 2/10：./export\hybrid attention\images\figure_2_page3.png
2025-11-12 21:20:59,091 - INFO - root - 已保存图片 3/10：./export\hybrid attention\images\figure_3_page6.png
2025-11-12 21:20:59,863 - INFO - root - 已保存图片 4/10：./export\hybrid attention\images\figure_4_page4.png
2025-11-12 21:21:00,431 - INFO - root - 已保存图片 5/10：./export\hybrid attention\images\figure_5_page3.png
2025-11-12 21:21:00,649 - INFO - root - 已保存图片 6/10：./export\hybrid attention\images\figure_6_page2.png
2025-11-12 21:21:01,004 - INFO - root - 已保存图片 7/10：./export\hybrid attention\images\figure_7_page7.png
2025-11-12 21:21:01,017 - INFO - root - 成功添加图片 1：./export\hybrid attention\images\figure_1_page2.png
2025-11-12 21:21:01,020 - INFO - root - 成功添加图片 2：./export\hybrid attention\images\figure_2_page3.png
2025-11-12 21:21:01,027 - INFO - root - 成功添加图片 3：./export\hybrid attention\images\figure_3_page6.png
2025-11-12 21:21:01,030 - INFO - root - 成功添加图片 4：./export\hybrid attention\images\figure_4_page4.png
2025-11-12 21:21:01,031 - INFO - root - 成功添加图片 5：./export\hybrid attention\images\figure_5_page3.png
2025-11-12 21:21:01,031 - INFO - root - 成功添加图片 6：./export\hybrid attention\images\figure_6_page2.png
2025-11-12 21:21:01,032 - INFO - root - 成功添加图片 7：./export\hybrid attention\images\figure_7_page7.png
2025-11-12 21:21:01,036 - INFO - root - 已更新图片链接
2025-11-12 21:21:01,072 - INFO - root - 论文《Pay Attention to What You Need》的分析已保存到 ./export\hybrid attention\Pay Attention to What You Need.md
2025-11-12 21:21:01,073 - INFO - root - 正在总结论文 6/18: Dual Cross-Attention for Medical Image Segmentation
2025-11-12 21:21:15,086 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 21:21:15,087 - INFO - root - LLMClient: rate limit reached, sleeping 5.2s
2025-11-12 21:22:21,987 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 21:23:01,959 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 21:23:01,959 - INFO - root - 正在提取论文图片到目录: ./export\hybrid attention\images
2025-11-12 21:23:03,772 - INFO - root - 已保存图片 1/10：./export\hybrid attention\images\figure_1_page2.png
2025-11-12 21:23:03,996 - INFO - root - 已保存图片 2/10：./export\hybrid attention\images\figure_2_page4.png
2025-11-12 21:23:04,250 - INFO - root - 已保存图片 3/10：./export\hybrid attention\images\figure_3_page6.png
2025-11-12 21:23:04,260 - INFO - root - 成功添加图片 1：./export\hybrid attention\images\figure_1_page2.png
2025-11-12 21:23:04,261 - INFO - root - 成功添加图片 2：./export\hybrid attention\images\figure_2_page4.png
2025-11-12 21:23:04,261 - INFO - root - 成功添加图片 3：./export\hybrid attention\images\figure_3_page6.png
2025-11-12 21:23:04,265 - INFO - root - 已更新图片链接
2025-11-12 21:23:04,274 - INFO - root - 论文《Dual Cross-Attention for Medical Image Segmentation》的分析已保存到 ./export\hybrid attention\Dual Cross-Attention for Medical Image Segmentation.md
2025-11-12 21:23:04,276 - INFO - root - 正在总结论文 7/18: Customizing the Inductive Biases of Softmax Attention using Structured Matrices
2025-11-12 21:23:22,868 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 21:24:37,505 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 21:25:26,986 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 21:25:26,994 - INFO - root - 正在提取论文图片到目录: ./export\hybrid attention\images
2025-11-12 21:25:27,097 - INFO - root - 已保存图片 1/10：./export\hybrid attention\images\figure_1_page2.png
2025-11-12 21:25:27,140 - INFO - root - 已保存图片 2/10：./export\hybrid attention\images\figure_2_page2.png
2025-11-12 21:25:27,140 - INFO - root - 成功添加图片 1：./export\hybrid attention\images\figure_1_page2.png
2025-11-12 21:25:27,140 - INFO - root - 成功添加图片 2：./export\hybrid attention\images\figure_2_page2.png
2025-11-12 21:25:27,143 - INFO - root - 已更新图片链接
2025-11-12 21:25:27,147 - INFO - root - 论文《Customizing the Inductive Biases of Softmax Attention using Structured Matrices》的分析已保存到 ./export\hybrid attention\Customizing the Inductive Biases of Softmax Attention using Structured Matrices.md
2025-11-12 21:25:27,149 - INFO - root - 正在总结论文 8/18: Benign Overfitting in Token Selection of Attention Mechanism
2025-11-12 21:25:37,131 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 21:25:37,132 - INFO - root - LLMClient: rate limit reached, sleeping 0.4s
2025-11-12 21:26:31,653 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 21:27:08,960 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 21:27:08,961 - INFO - root - 正在提取论文图片到目录: ./export\hybrid attention\images
2025-11-12 21:27:09,664 - INFO - root - 已保存图片 1/10：./export\hybrid attention\images\figure_1_page18.png
2025-11-12 21:27:09,746 - INFO - root - 已保存图片 2/10：./export\hybrid attention\images\figure_2_page2.png
2025-11-12 21:27:09,808 - INFO - root - 已保存图片 3/10：./export\hybrid attention\images\figure_3_page7.png
2025-11-12 21:27:09,882 - INFO - root - 已保存图片 4/10：./export\hybrid attention\images\figure_4_page82.png
2025-11-12 21:27:09,950 - INFO - root - 已保存图片 5/10：./export\hybrid attention\images\figure_5_page80.png
2025-11-12 21:27:10,017 - INFO - root - 已保存图片 6/10：./export\hybrid attention\images\figure_6_page84.png
2025-11-12 21:27:10,098 - INFO - root - 已保存图片 7/10：./export\hybrid attention\images\figure_7_page9.png
2025-11-12 21:27:10,200 - INFO - root - 已保存图片 8/10：./export\hybrid attention\images\figure_8_page9.png
2025-11-12 21:27:10,284 - INFO - root - 已保存图片 9/10：./export\hybrid attention\images\figure_9_page9.png
2025-11-12 21:27:10,387 - INFO - root - 已保存图片 10/10：./export\hybrid attention\images\figure_10_page81.png
2025-11-12 21:27:10,391 - INFO - root - 成功添加图片 1：./export\hybrid attention\images\figure_1_page18.png
2025-11-12 21:27:10,394 - INFO - root - 成功添加图片 2：./export\hybrid attention\images\figure_2_page2.png
2025-11-12 21:27:10,395 - INFO - root - 成功添加图片 3：./export\hybrid attention\images\figure_3_page7.png
2025-11-12 21:27:10,395 - INFO - root - 成功添加图片 4：./export\hybrid attention\images\figure_4_page82.png
2025-11-12 21:27:10,396 - INFO - root - 成功添加图片 5：./export\hybrid attention\images\figure_5_page80.png
2025-11-12 21:27:10,398 - INFO - root - 成功添加图片 6：./export\hybrid attention\images\figure_6_page84.png
2025-11-12 21:27:10,399 - INFO - root - 成功添加图片 7：./export\hybrid attention\images\figure_7_page9.png
2025-11-12 21:27:10,399 - INFO - root - 成功添加图片 8：./export\hybrid attention\images\figure_8_page9.png
2025-11-12 21:27:10,401 - INFO - root - 成功添加图片 9：./export\hybrid attention\images\figure_9_page9.png
2025-11-12 21:27:10,403 - INFO - root - 成功添加图片 10：./export\hybrid attention\images\figure_10_page81.png
2025-11-12 21:27:10,412 - INFO - root - 已更新图片链接
2025-11-12 21:27:10,416 - INFO - root - 论文《Benign Overfitting in Token Selection of Attention Mechanism》的分析已保存到 ./export\hybrid attention\Benign Overfitting in Token Selection of Attention Mechanism.md
2025-11-12 21:27:10,423 - INFO - root - 正在总结论文 9/18: Attention in SRAM on Tenstorrent Grayskull
2025-11-12 21:27:25,670 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 21:27:25,681 - INFO - root - LLMClient: rate limit reached, sleeping 6.0s
2025-11-12 21:28:31,187 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 21:29:17,057 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 21:29:17,057 - INFO - root - 正在提取论文图片到目录: ./export\hybrid attention\images
2025-11-12 21:29:17,088 - INFO - root - 论文《Attention in SRAM on Tenstorrent Grayskull》的分析已保存到 ./export\hybrid attention\Attention in SRAM on Tenstorrent Grayskull.md
2025-11-12 21:29:17,111 - INFO - root - 正在总结论文 10/18: Grounded Text-to-Image Synthesis with Attention Refocusing
2025-11-12 21:29:26,115 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 21:29:26,115 - INFO - root - LLMClient: rate limit reached, sleeping 5.1s
2025-11-12 21:30:31,406 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 21:31:13,887 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 21:31:13,893 - INFO - root - 正在提取论文图片到目录: ./export\hybrid attention\images
2025-11-12 21:31:15,631 - INFO - root - 已保存图片 1/10：./export\hybrid attention\images\figure_1_page1.jpeg
2025-11-12 21:31:15,727 - INFO - root - 已保存图片 2/10：./export\hybrid attention\images\figure_2_page1.jpeg
2025-11-12 21:31:15,841 - INFO - root - 已保存图片 3/10：./export\hybrid attention\images\figure_3_page1.jpeg
2025-11-12 21:31:15,922 - INFO - root - 已保存图片 4/10：./export\hybrid attention\images\figure_4_page1.jpeg
2025-11-12 21:31:15,978 - INFO - root - 已保存图片 5/10：./export\hybrid attention\images\figure_5_page1.jpeg
2025-11-12 21:31:16,038 - INFO - root - 已保存图片 6/10：./export\hybrid attention\images\figure_6_page1.png
2025-11-12 21:31:16,078 - INFO - root - 已保存图片 7/10：./export\hybrid attention\images\figure_7_page1.jpeg
2025-11-12 21:31:16,130 - INFO - root - 已保存图片 8/10：./export\hybrid attention\images\figure_8_page1.jpeg
2025-11-12 21:31:16,204 - INFO - root - 已保存图片 9/10：./export\hybrid attention\images\figure_9_page1.png
2025-11-12 21:31:16,241 - INFO - root - 已保存图片 10/10：./export\hybrid attention\images\figure_10_page1.jpeg
2025-11-12 21:31:16,254 - INFO - root - 成功添加图片 1：./export\hybrid attention\images\figure_1_page1.jpeg
2025-11-12 21:31:16,254 - INFO - root - 成功添加图片 2：./export\hybrid attention\images\figure_2_page1.jpeg
2025-11-12 21:31:16,255 - INFO - root - 成功添加图片 3：./export\hybrid attention\images\figure_3_page1.jpeg
2025-11-12 21:31:16,255 - INFO - root - 成功添加图片 4：./export\hybrid attention\images\figure_4_page1.jpeg
2025-11-12 21:31:16,256 - INFO - root - 成功添加图片 5：./export\hybrid attention\images\figure_5_page1.jpeg
2025-11-12 21:31:16,256 - INFO - root - 成功添加图片 6：./export\hybrid attention\images\figure_6_page1.png
2025-11-12 21:31:16,257 - INFO - root - 成功添加图片 7：./export\hybrid attention\images\figure_7_page1.jpeg
2025-11-12 21:31:16,257 - INFO - root - 成功添加图片 8：./export\hybrid attention\images\figure_8_page1.jpeg
2025-11-12 21:31:16,258 - INFO - root - 成功添加图片 9：./export\hybrid attention\images\figure_9_page1.png
2025-11-12 21:31:16,258 - INFO - root - 成功添加图片 10：./export\hybrid attention\images\figure_10_page1.jpeg
2025-11-12 21:31:16,261 - INFO - root - 已更新图片链接
2025-11-12 21:31:16,265 - INFO - root - 论文《Grounded Text-to-Image Synthesis with Attention Refocusing》的分析已保存到 ./export\hybrid attention\Grounded Text-to-Image Synthesis with Attention Refocusing.md
2025-11-12 21:31:16,269 - INFO - root - 正在总结论文 11/18: Attention Tracker: Detecting Prompt Injection Attacks in LLMs
2025-11-12 21:31:27,441 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 21:31:27,443 - INFO - root - LLMClient: rate limit reached, sleeping 4.0s
2025-11-12 21:32:14,511 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 21:32:14,513 - INFO - root - LLMClient: rate limit reached, sleeping 1.8s
2025-11-12 21:32:51,715 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 21:32:51,719 - INFO - root - 正在提取论文图片到目录: ./export\hybrid attention\images
2025-11-12 21:32:52,256 - INFO - root - 已保存图片 1/10：./export\hybrid attention\images\figure_1_page2.png
2025-11-12 21:32:52,335 - INFO - root - 已保存图片 2/10：./export\hybrid attention\images\figure_2_page13.png
2025-11-12 21:32:52,396 - INFO - root - 已保存图片 3/10：./export\hybrid attention\images\figure_3_page8.png
2025-11-12 21:32:52,455 - INFO - root - 已保存图片 4/10：./export\hybrid attention\images\figure_4_page5.png
2025-11-12 21:32:52,516 - INFO - root - 已保存图片 5/10：./export\hybrid attention\images\figure_5_page14.png
2025-11-12 21:32:52,582 - INFO - root - 已保存图片 6/10：./export\hybrid attention\images\figure_6_page9.png
2025-11-12 21:32:52,691 - INFO - root - 已保存图片 7/10：./export\hybrid attention\images\figure_7_page7.png
2025-11-12 21:32:52,759 - INFO - root - 已保存图片 8/10：./export\hybrid attention\images\figure_8_page5.png
2025-11-12 21:32:52,766 - INFO - root - 成功添加图片 1：./export\hybrid attention\images\figure_1_page2.png
2025-11-12 21:32:52,768 - INFO - root - 成功添加图片 2：./export\hybrid attention\images\figure_2_page13.png
2025-11-12 21:32:52,769 - INFO - root - 成功添加图片 3：./export\hybrid attention\images\figure_3_page8.png
2025-11-12 21:32:52,769 - INFO - root - 成功添加图片 4：./export\hybrid attention\images\figure_4_page5.png
2025-11-12 21:32:52,770 - INFO - root - 成功添加图片 5：./export\hybrid attention\images\figure_5_page14.png
2025-11-12 21:32:52,770 - INFO - root - 成功添加图片 6：./export\hybrid attention\images\figure_6_page9.png
2025-11-12 21:32:52,770 - INFO - root - 成功添加图片 7：./export\hybrid attention\images\figure_7_page7.png
2025-11-12 21:32:52,770 - INFO - root - 成功添加图片 8：./export\hybrid attention\images\figure_8_page5.png
2025-11-12 21:32:52,773 - INFO - root - 已更新图片链接
2025-11-12 21:32:52,775 - INFO - root - 论文《Attention Tracker: Detecting Prompt Injection Attacks in LLMs》的分析已保存到 ./export\hybrid attention\Attention Tracker_ Detecting Prompt Injection Attacks in LLMs.md
2025-11-12 21:32:52,782 - INFO - root - 正在总结论文 12/18: A Systematic Analysis of Hybrid Linear Attention
2025-11-12 21:33:05,498 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 21:33:05,499 - INFO - root - LLMClient: rate limit reached, sleeping 10.8s
2025-11-12 21:33:58,762 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 21:34:33,163 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 21:34:33,163 - INFO - root - 正在提取论文图片到目录: ./export\hybrid attention\images
2025-11-12 21:34:34,084 - INFO - root - 已保存图片 1/10：./export\hybrid attention\images\figure_1_page9.png
2025-11-12 21:34:34,151 - INFO - root - 已保存图片 2/10：./export\hybrid attention\images\figure_2_page1.png
2025-11-12 21:34:34,253 - INFO - root - 已保存图片 3/10：./export\hybrid attention\images\figure_3_page8.png
2025-11-12 21:34:34,268 - INFO - root - 已保存图片 4/10：./export\hybrid attention\images\figure_4_page1.jpeg
2025-11-12 21:34:34,275 - INFO - root - 成功添加图片 1：./export\hybrid attention\images\figure_1_page9.png
2025-11-12 21:34:34,277 - INFO - root - 成功添加图片 2：./export\hybrid attention\images\figure_2_page1.png
2025-11-12 21:34:34,278 - INFO - root - 成功添加图片 3：./export\hybrid attention\images\figure_3_page8.png
2025-11-12 21:34:34,279 - INFO - root - 成功添加图片 4：./export\hybrid attention\images\figure_4_page1.jpeg
2025-11-12 21:34:34,281 - INFO - root - 已更新图片链接
2025-11-12 21:34:34,284 - INFO - root - 论文《A Systematic Analysis of Hybrid Linear Attention》的分析已保存到 ./export\hybrid attention\A Systematic Analysis of Hybrid Linear Attention.md
2025-11-12 21:34:34,287 - INFO - root - 正在总结论文 13/18: Attention as a Hypernetwork
2025-11-12 21:34:45,995 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 21:34:45,999 - INFO - root - LLMClient: rate limit reached, sleeping 12.8s
2025-11-12 21:35:48,075 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 21:36:16,820 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 21:36:16,822 - INFO - root - 正在提取论文图片到目录: ./export\hybrid attention\images
2025-11-12 21:36:16,919 - INFO - root - 论文《Attention as a Hypernetwork》的分析已保存到 ./export\hybrid attention\Attention as a Hypernetwork.md
2025-11-12 21:36:16,919 - INFO - root - 正在总结论文 14/18: HyRRT-Connect: A Bidirectional Rapidly-Exploring Random Trees Motion Planning Algorithm for Hybrid Systems
2025-11-12 21:36:33,420 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 21:36:33,421 - INFO - root - LLMClient: rate limit reached, sleeping 14.7s
2025-11-12 21:37:47,660 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 21:38:18,609 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 21:38:18,609 - INFO - root - 正在提取论文图片到目录: ./export\hybrid attention\images
2025-11-12 21:38:18,684 - INFO - root - 已保存图片 1/10：./export\hybrid attention\images\figure_1_page8.jpeg
2025-11-12 21:38:18,726 - INFO - root - 已保存图片 2/10：./export\hybrid attention\images\figure_2_page8.jpeg
2025-11-12 21:38:18,737 - INFO - root - 已保存图片 3/10：./export\hybrid attention\images\figure_3_page8.png
2025-11-12 21:38:18,743 - INFO - root - 已保存图片 4/10：./export\hybrid attention\images\figure_4_page8.png
2025-11-12 21:38:18,744 - INFO - root - 成功添加图片 1：./export\hybrid attention\images\figure_1_page8.jpeg
2025-11-12 21:38:18,746 - INFO - root - 成功添加图片 2：./export\hybrid attention\images\figure_2_page8.jpeg
2025-11-12 21:38:18,747 - INFO - root - 成功添加图片 3：./export\hybrid attention\images\figure_3_page8.png
2025-11-12 21:38:18,748 - INFO - root - 成功添加图片 4：./export\hybrid attention\images\figure_4_page8.png
2025-11-12 21:38:18,751 - INFO - root - 已更新图片链接
2025-11-12 21:38:18,755 - INFO - root - 论文《HyRRT-Connect: A Bidirectional Rapidly-Exploring Random Trees Motion Planning Algorithm for Hybrid Systems》的分析已保存到 ./export\hybrid attention\HyRRT-Connect_ A Bidirectional Rapidly-Exploring Random Trees Motion Planning Algorithm for Hybrid S.md
2025-11-12 21:38:18,759 - INFO - root - 正在总结论文 15/18: Vision Transformer with Quadrangle Attention
2025-11-12 21:38:28,766 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 21:38:28,769 - INFO - root - LLMClient: rate limit reached, sleeping 18.9s
2025-11-12 21:39:34,147 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 21:40:19,006 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 21:40:19,007 - INFO - root - 正在提取论文图片到目录: ./export\hybrid attention\images
2025-11-12 21:40:19,331 - INFO - root - 已保存图片 1/10：./export\hybrid attention\images\figure_1_page13.png
2025-11-12 21:40:19,409 - INFO - root - 已保存图片 2/10：./export\hybrid attention\images\figure_2_page13.png
2025-11-12 21:40:19,461 - INFO - root - 已保存图片 3/10：./export\hybrid attention\images\figure_3_page12.jpeg
2025-11-12 21:40:19,499 - INFO - root - 已保存图片 4/10：./export\hybrid attention\images\figure_4_page2.jpeg
2025-11-12 21:40:19,536 - INFO - root - 已保存图片 5/10：./export\hybrid attention\images\figure_5_page3.jpeg
2025-11-12 21:40:19,573 - INFO - root - 已保存图片 6/10：./export\hybrid attention\images\figure_6_page12.jpeg
2025-11-12 21:40:19,625 - INFO - root - 已保存图片 7/10：./export\hybrid attention\images\figure_7_page12.jpeg
2025-11-12 21:40:19,670 - INFO - root - 已保存图片 8/10：./export\hybrid attention\images\figure_8_page12.jpeg
2025-11-12 21:40:19,711 - INFO - root - 已保存图片 9/10：./export\hybrid attention\images\figure_9_page12.jpeg
2025-11-12 21:40:19,742 - INFO - root - 已保存图片 10/10：./export\hybrid attention\images\figure_10_page2.jpeg
2025-11-12 21:40:19,748 - INFO - root - 成功添加图片 1：./export\hybrid attention\images\figure_1_page13.png
2025-11-12 21:40:19,748 - INFO - root - 成功添加图片 2：./export\hybrid attention\images\figure_2_page13.png
2025-11-12 21:40:19,748 - INFO - root - 成功添加图片 3：./export\hybrid attention\images\figure_3_page12.jpeg
2025-11-12 21:40:19,749 - INFO - root - 成功添加图片 4：./export\hybrid attention\images\figure_4_page2.jpeg
2025-11-12 21:40:19,751 - INFO - root - 成功添加图片 5：./export\hybrid attention\images\figure_5_page3.jpeg
2025-11-12 21:40:19,752 - INFO - root - 成功添加图片 6：./export\hybrid attention\images\figure_6_page12.jpeg
2025-11-12 21:40:19,752 - INFO - root - 成功添加图片 7：./export\hybrid attention\images\figure_7_page12.jpeg
2025-11-12 21:40:19,753 - INFO - root - 成功添加图片 8：./export\hybrid attention\images\figure_8_page12.jpeg
2025-11-12 21:40:19,753 - INFO - root - 成功添加图片 9：./export\hybrid attention\images\figure_9_page12.jpeg
2025-11-12 21:40:19,753 - INFO - root - 成功添加图片 10：./export\hybrid attention\images\figure_10_page2.jpeg
2025-11-12 21:40:19,759 - INFO - root - 已更新图片链接
2025-11-12 21:40:19,762 - INFO - root - 论文《Vision Transformer with Quadrangle Attention》的分析已保存到 ./export\hybrid attention\Vision Transformer with Quadrangle Attention.md
2025-11-12 21:40:19,766 - INFO - root - 正在总结论文 16/18: Forgetting Transformer: Softmax Attention with a Forget Gate
2025-11-12 21:40:34,773 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 21:41:37,039 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 21:41:37,095 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-11-12 21:41:37,100 - INFO - openai._base_client - Retrying request to /chat/completions in 0.470528 seconds
2025-11-12 21:41:37,632 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-11-12 21:41:37,632 - INFO - openai._base_client - Retrying request to /chat/completions in 0.895162 seconds
2025-11-12 21:41:38,587 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-11-12 21:41:38,590 - ERROR - root - DeepSeekClient: generation error: Error code: 429 - {'error': {'code': 'SetLimitExceeded', 'message': 'Your account [2111747473] has reached the set inference limit for the [deepseek-v3-1] model, and the model service has been paused. To continue using this model, please visit the Model Activation page to adjust or close the "Safe Experience Mode". Request id: 02176295489854958495fca7b4b2c862697b101622074963b2cbc', 'param': '', 'type': 'TooManyRequests'}}
Traceback (most recent call last):
  File "D:\ChatPaper\llm_client_merged.py", line 296, in generate
    completion = self.client.chat.completions.create(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\openai\_utils\_utils.py", line 286, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\openai\resources\chat\completions\completions.py", line 1156, in create
    return self._post(
           ^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\openai\_base_client.py", line 1259, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\openai\_base_client.py", line 1047, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'code': 'SetLimitExceeded', 'message': 'Your account [2111747473] has reached the set inference limit for the [deepseek-v3-1] model, and the model service has been paused. To continue using this model, please visit the Model Activation page to adjust or close the "Safe Experience Mode". Request id: 02176295489854958495fca7b4b2c862697b101622074963b2cbc', 'param': '', 'type': 'TooManyRequests'}}
2025-11-12 21:41:38,603 - WARNING - root - DeepSeekClient: 频率限制 检测到，等待 60 秒后重试
2025-11-12 21:42:38,602 - INFO - root - DeepSeekClient: retry attempt 2 for generation
2025-11-12 21:42:38,903 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-11-12 21:42:38,905 - INFO - openai._base_client - Retrying request to /chat/completions in 0.432304 seconds
2025-11-12 21:42:39,391 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-11-12 21:42:39,392 - INFO - openai._base_client - Retrying request to /chat/completions in 0.929630 seconds
2025-11-12 21:42:40,377 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-11-12 21:42:40,378 - ERROR - root - DeepSeekClient: generation error: Error code: 429 - {'error': {'code': 'SetLimitExceeded', 'message': 'Your account [2111747473] has reached the set inference limit for the [deepseek-v3-1] model, and the model service has been paused. To continue using this model, please visit the Model Activation page to adjust or close the "Safe Experience Mode". Request id: 0217629549603495b129058f0bb51c438fa5c5aba5f4977218526', 'param': '', 'type': 'TooManyRequests'}}
Traceback (most recent call last):
  File "D:\ChatPaper\llm_client_merged.py", line 296, in generate
    completion = self.client.chat.completions.create(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\openai\_utils\_utils.py", line 286, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\openai\resources\chat\completions\completions.py", line 1156, in create
    return self._post(
           ^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\openai\_base_client.py", line 1259, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\openai\_base_client.py", line 1047, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'code': 'SetLimitExceeded', 'message': 'Your account [2111747473] has reached the set inference limit for the [deepseek-v3-1] model, and the model service has been paused. To continue using this model, please visit the Model Activation page to adjust or close the "Safe Experience Mode". Request id: 0217629549603495b129058f0bb51c438fa5c5aba5f4977218526', 'param': '', 'type': 'TooManyRequests'}}
2025-11-12 21:42:40,380 - WARNING - root - DeepSeekClient: 频率限制 检测到，等待 60 秒后重试
2025-11-12 21:43:41,503 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-12 21:43:41,506 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-12 21:43:41,508 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-12 21:43:45,809 - INFO - root - LLMClientManager: 指定使用客户端: Gemini
2025-11-12 21:43:47,144 - INFO - root - GeminiClient: trying model models/gemini-2.5-flash
2025-11-12 21:43:54,777 - INFO - root - GeminiClient: initialized model gemini-2.5-flash
2025-11-12 21:43:54,777 - INFO - root - LLMClientManager: Gemini 客户端初始化成功
2025-11-12 21:43:54,780 - INFO - root - LLMClientManager: switched to Gemini client
2025-11-12 21:43:54,781 - INFO - root - 已手动切换到 LLM 客户端: Gemini
2025-11-12 21:43:54,781 - INFO - root - 使用 LLM 模型: gemini-2.5-flash
2025-11-12 21:43:54,782 - INFO - root - 可用客户端: ['Gemini']
2025-11-12 21:43:54,782 - INFO - root - === 运行配置 ===
2025-11-12 21:43:54,783 - INFO - root - 处理模式: arXiv 最新搜索 (API)
2025-11-12 21:43:54,784 - INFO - root - 查询: hybrid attention
2025-11-12 21:43:54,784 - INFO - root - 关键词 (用于保存): hybrid attention
2025-11-12 21:43:54,785 - INFO - root - 排序: SubmittedDate
2025-11-12 21:43:54,786 - INFO - root - 最近天数: 1000
2025-11-12 21:43:54,787 - INFO - root - 最大处理数量: 40
2025-11-12 21:43:54,787 - INFO - root - 保存图片: 是
2025-11-12 21:43:54,788 - INFO - root - 输出语言: 中文
2025-11-12 21:43:54,788 - INFO - root - 强制重新处理: 否
2025-11-12 21:43:54,789 - INFO - root - LLM 客户端: Gemini
2025-11-12 21:43:54,789 - INFO - root - ====================
2025-11-12 21:43:54,789 - INFO - root - 正在使用检索策略: arxiv
2025-11-12 21:43:54,791 - INFO - root - 使用 arXiv 搜索模式 (API + 并发)
2025-11-12 21:43:54,791 - INFO - root - 正在使用 arXiv API 搜索: query='hybrid attention', sort_by=SubmittedDate
2025-11-12 21:43:54,792 - INFO - arxiv - Requesting page (first: True, try: 0): https://export.arxiv.org/api/query?search_query=hybrid+attention&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=50
2025-11-12 21:43:55,967 - INFO - arxiv - Got first page: 50 of 135016 total results
2025-11-12 21:43:55,969 - INFO - root - API 返回了 50 篇论文
2025-11-12 21:43:55,972 - INFO - root - 开始按 1000 天过滤 (检查 50 篇论文)...
2025-11-12 21:43:55,973 - INFO - root - 经过 'days=1000' 过滤后，剩余 18 篇论文。
2025-11-12 21:43:55,973 - INFO - root - 将开始并发下载 18 篇论文...
2025-11-12 21:43:55,975 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\hybrid attention\Hybrid-MPET_ an open-source simulation software for hybrid electrode batteries.pdf
2025-11-12 21:43:55,975 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\hybrid attention\Grounded Text-to-Image Synthesis with Attention Refocusing.pdf
2025-11-12 21:43:55,976 - INFO - root - 成功创建 Paper 对象: 2305.15599v1
2025-11-12 21:43:55,976 - INFO - root - 成功创建 Paper 对象: 2306.05427v2
2025-11-12 21:43:55,984 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\hybrid attention\On the Surprising Effectiveness of Attention Transfer for Vision Transformers.pdf
2025-11-12 21:43:55,985 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\hybrid attention\Radial Attention_ $O(n_log n)$ Sparse Attention with Energy Decay for Long Video Generation.pdf
2025-11-12 21:43:56,000 - INFO - root - 成功创建 Paper 对象: 2506.19852v1
2025-11-12 21:43:55,988 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\hybrid attention\Pay Attention to What You Need.pdf
2025-11-12 21:43:55,990 - INFO - root - 成功创建 Paper 对象: 2411.09702v1
2025-11-12 21:43:55,990 - INFO - root - 下载进度: 1/18
2025-11-12 21:43:55,999 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\hybrid attention\Be Yourself_ Bounded Attention for Multi-Subject Text-to-Image Generation.pdf
2025-11-12 21:43:56,145 - INFO - root - 成功创建 Paper 对象: 2403.16990v1
2025-11-12 21:43:56,037 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\hybrid attention\Dual Cross-Attention for Medical Image Segmentation.pdf
2025-11-12 21:43:56,147 - INFO - root - 成功创建 Paper 对象: 2303.17696v1
2025-11-12 21:43:56,129 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\hybrid attention\Customizing the Inductive Biases of Softmax Attention using Structured Matrices.pdf
2025-11-12 21:43:56,148 - INFO - root - 成功创建 Paper 对象: 2509.07963v1
2025-11-12 21:43:55,986 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\hybrid attention\Elliptical Attention.pdf
2025-11-12 21:43:56,084 - INFO - root - 成功创建 Paper 对象: 2307.13365v3
2025-11-12 21:43:56,148 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\hybrid attention\Benign Overfitting in Token Selection of Attention Mechanism.pdf
2025-11-12 21:43:56,143 - INFO - root - 下载进度: 2/18
2025-11-12 21:43:56,149 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\hybrid attention\Attention in SRAM on Tenstorrent Grayskull.pdf
2025-11-12 21:43:56,150 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\hybrid attention\Attention as a Hypernetwork.pdf
2025-11-12 21:43:56,151 - INFO - root - 成功创建 Paper 对象: 2406.13770v2
2025-11-12 21:43:56,151 - INFO - root - 成功创建 Paper 对象: 2409.17625v3
2025-11-12 21:43:56,152 - INFO - root - 下载进度: 3/18
2025-11-12 21:43:56,152 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\hybrid attention\A Systematic Analysis of Hybrid Linear Attention.pdf
2025-11-12 21:43:56,152 - INFO - root - 成功创建 Paper 对象: 2407.13885v1
2025-11-12 21:43:56,153 - INFO - root - 成功创建 Paper 对象: 2406.05816v4
2025-11-12 21:43:56,154 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\hybrid attention\Attention Tracker_ Detecting Prompt Injection Attacks in LLMs.pdf
2025-11-12 21:43:56,155 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\hybrid attention\Forgetting Transformer_ Softmax Attention with a Forget Gate.pdf
2025-11-12 21:43:56,155 - INFO - root - 下载进度: 4/18
2025-11-12 21:43:56,155 - INFO - root - 成功创建 Paper 对象: 2507.06457v1
2025-11-12 21:43:56,156 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\hybrid attention\HyRRT-Connect_ A Bidirectional Rapidly-Exploring Random Trees Motion Planning Algorithm for Hybrid S.pdf
2025-11-12 21:43:56,158 - INFO - root - 成功创建 Paper 对象: 2411.00348v2
2025-11-12 21:43:56,158 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\hybrid attention\Vision Transformer with Quadrangle Attention.pdf
2025-11-12 21:43:56,158 - INFO - root - 成功创建 Paper 对象: 2503.02130v2
2025-11-12 21:43:56,159 - INFO - root - 下载进度: 5/18
2025-11-12 21:43:56,160 - INFO - root - 成功创建 Paper 对象: 2403.18413v2
2025-11-12 21:43:56,160 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\hybrid attention\Cross-Image Attention for Zero-Shot Appearance Transfer.pdf
2025-11-12 21:43:56,162 - INFO - root - 成功创建 Paper 对象: 2303.15105v1
2025-11-12 21:43:56,162 - INFO - root - 下载进度: 6/18
2025-11-12 21:43:56,164 - INFO - root - 成功创建 Paper 对象: 2311.03335v1
2025-11-12 21:43:56,164 - INFO - root - 下载进度: 7/18
2025-11-12 21:43:56,166 - INFO - root - 下载进度: 8/18
2025-11-12 21:43:56,170 - INFO - root - 下载进度: 9/18
2025-11-12 21:43:56,170 - INFO - root - 下载进度: 10/18
2025-11-12 21:43:56,170 - INFO - root - 下载进度: 11/18
2025-11-12 21:43:56,172 - INFO - root - 下载进度: 12/18
2025-11-12 21:43:56,172 - INFO - root - 下载进度: 13/18
2025-11-12 21:43:56,190 - INFO - root - 下载进度: 14/18
2025-11-12 21:43:56,200 - INFO - root - 下载进度: 15/18
2025-11-12 21:43:56,200 - INFO - root - 下载进度: 16/18
2025-11-12 21:43:56,201 - INFO - root - 下载进度: 17/18
2025-11-12 21:43:56,201 - INFO - root - 下载进度: 18/18
2025-11-12 21:43:56,202 - INFO - root - 成功下载并处理了 18 篇论文，耗时 0.21 秒。
2025-11-12 21:43:56,205 - INFO - root - 检索到 18 篇论文，开始总结...
2025-11-12 21:43:56,207 - INFO - root - 跳过已处理论文 Grounded Text-to-Image Synthesis with Attention Refocusing：D:\ChatPaper\api_downloads\hybrid attention\Grounded Text-to-Image Synthesis with Attention Refocusing.pdf
2025-11-12 21:43:56,208 - INFO - root - 跳过已处理论文 Hybrid-MPET: an open-source simulation software for hybrid electrode batteries：D:\ChatPaper\api_downloads\hybrid attention\Hybrid-MPET_ an open-source simulation software for hybrid electrode batteries.pdf
2025-11-12 21:43:56,208 - INFO - root - 跳过已处理论文 Radial Attention: $O(n\log n)$ Sparse Attention with Energy Decay for Long Video Generation：D:\ChatPaper\api_downloads\hybrid attention\Radial Attention_ $O(n_log n)$ Sparse Attention with Energy Decay for Long Video Generation.pdf
2025-11-12 21:43:56,208 - INFO - root - 跳过已处理论文 On the Surprising Effectiveness of Attention Transfer for Vision Transformers：D:\ChatPaper\api_downloads\hybrid attention\On the Surprising Effectiveness of Attention Transfer for Vision Transformers.pdf
2025-11-12 21:43:56,208 - INFO - root - 正在总结论文 5/18: Be Yourself: Bounded Attention for Multi-Subject Text-to-Image Generation
2025-11-12 21:44:51,580 - INFO - root - LLMClient: rate limit reached, sleeping 4.6s
2025-11-12 21:49:54,530 - INFO - root - 正在提取论文图片到目录: ./export\hybrid attention\images
2025-11-12 21:49:56,045 - INFO - root - 已保存图片 1/10：./export\hybrid attention\images\figure_1_page1.jpeg
2025-11-12 21:49:56,239 - INFO - root - 已保存图片 2/10：./export\hybrid attention\images\figure_2_page1.jpeg
2025-11-12 21:49:56,336 - INFO - root - 已保存图片 3/10：./export\hybrid attention\images\figure_3_page1.jpeg
2025-11-12 21:49:56,404 - INFO - root - 已保存图片 4/10：./export\hybrid attention\images\figure_4_page1.jpeg
2025-11-12 21:49:56,479 - INFO - root - 已保存图片 5/10：./export\hybrid attention\images\figure_5_page7.jpeg
2025-11-12 21:49:56,547 - INFO - root - 已保存图片 6/10：./export\hybrid attention\images\figure_6_page8.jpeg
2025-11-12 21:49:56,611 - INFO - root - 已保存图片 7/10：./export\hybrid attention\images\figure_7_page8.jpeg
2025-11-12 21:49:56,681 - INFO - root - 已保存图片 8/10：./export\hybrid attention\images\figure_8_page8.jpeg
2025-11-12 21:49:56,743 - INFO - root - 已保存图片 9/10：./export\hybrid attention\images\figure_9_page8.jpeg
2025-11-12 21:49:56,801 - INFO - root - 已保存图片 10/10：./export\hybrid attention\images\figure_10_page8.jpeg
2025-11-12 21:49:56,812 - INFO - root - 成功添加图片 1：./export\hybrid attention\images\figure_1_page1.jpeg
2025-11-12 21:49:56,812 - INFO - root - 成功添加图片 2：./export\hybrid attention\images\figure_2_page1.jpeg
2025-11-12 21:49:56,815 - INFO - root - 成功添加图片 3：./export\hybrid attention\images\figure_3_page1.jpeg
2025-11-12 21:49:56,818 - INFO - root - 成功添加图片 4：./export\hybrid attention\images\figure_4_page1.jpeg
2025-11-12 21:49:56,824 - INFO - root - 成功添加图片 5：./export\hybrid attention\images\figure_5_page7.jpeg
2025-11-12 21:49:56,826 - INFO - root - 成功添加图片 6：./export\hybrid attention\images\figure_6_page8.jpeg
2025-11-12 21:49:56,828 - INFO - root - 成功添加图片 7：./export\hybrid attention\images\figure_7_page8.jpeg
2025-11-12 21:49:56,830 - INFO - root - 成功添加图片 8：./export\hybrid attention\images\figure_8_page8.jpeg
2025-11-12 21:49:56,837 - INFO - root - 成功添加图片 9：./export\hybrid attention\images\figure_9_page8.jpeg
2025-11-12 21:49:56,838 - INFO - root - 成功添加图片 10：./export\hybrid attention\images\figure_10_page8.jpeg
2025-11-12 21:49:56,840 - INFO - root - 已更新图片链接
2025-11-12 21:49:56,849 - INFO - root - 论文《Be Yourself: Bounded Attention for Multi-Subject Text-to-Image Generation》的分析已保存到 ./export\hybrid attention\Be Yourself_ Bounded Attention for Multi-Subject Text-to-Image Generation.md
2025-11-12 21:49:56,870 - INFO - root - 跳过已处理论文 Dual Cross-Attention for Medical Image Segmentation：D:\ChatPaper\api_downloads\hybrid attention\Dual Cross-Attention for Medical Image Segmentation.pdf
2025-11-12 21:49:56,877 - INFO - root - 跳过已处理论文 Customizing the Inductive Biases of Softmax Attention using Structured Matrices：D:\ChatPaper\api_downloads\hybrid attention\Customizing the Inductive Biases of Softmax Attention using Structured Matrices.pdf
2025-11-12 21:49:56,878 - INFO - root - 跳过已处理论文 Pay Attention to What You Need：D:\ChatPaper\api_downloads\hybrid attention\Pay Attention to What You Need.pdf
2025-11-12 21:49:56,878 - INFO - root - 跳过已处理论文 Elliptical Attention：D:\ChatPaper\api_downloads\hybrid attention\Elliptical Attention.pdf
2025-11-12 21:49:56,878 - INFO - root - 跳过已处理论文 Benign Overfitting in Token Selection of Attention Mechanism：D:\ChatPaper\api_downloads\hybrid attention\Benign Overfitting in Token Selection of Attention Mechanism.pdf
2025-11-12 21:49:56,880 - INFO - root - 跳过已处理论文 Attention in SRAM on Tenstorrent Grayskull：D:\ChatPaper\api_downloads\hybrid attention\Attention in SRAM on Tenstorrent Grayskull.pdf
2025-11-12 21:49:56,880 - INFO - root - 跳过已处理论文 Attention as a Hypernetwork：D:\ChatPaper\api_downloads\hybrid attention\Attention as a Hypernetwork.pdf
2025-11-12 21:49:56,881 - INFO - root - 跳过已处理论文 A Systematic Analysis of Hybrid Linear Attention：D:\ChatPaper\api_downloads\hybrid attention\A Systematic Analysis of Hybrid Linear Attention.pdf
2025-11-12 21:49:56,881 - INFO - root - 跳过已处理论文 Attention Tracker: Detecting Prompt Injection Attacks in LLMs：D:\ChatPaper\api_downloads\hybrid attention\Attention Tracker_ Detecting Prompt Injection Attacks in LLMs.pdf
2025-11-12 21:49:56,883 - INFO - root - 正在总结论文 15/18: Forgetting Transformer: Softmax Attention with a Forget Gate
2025-11-12 21:52:18,237 - INFO - root - 正在提取论文图片到目录: ./export\hybrid attention\images
2025-11-12 21:52:24,224 - INFO - root - 已保存图片 1/10：./export\hybrid attention\images\figure_1_page34.png
2025-11-12 21:52:24,337 - INFO - root - 已保存图片 2/10：./export\hybrid attention\images\figure_2_page34.png
2025-11-12 21:52:24,449 - INFO - root - 已保存图片 3/10：./export\hybrid attention\images\figure_3_page34.png
2025-11-12 21:52:24,543 - INFO - root - 已保存图片 4/10：./export\hybrid attention\images\figure_4_page34.png
2025-11-12 21:52:24,702 - INFO - root - 已保存图片 5/10：./export\hybrid attention\images\figure_5_page34.png
2025-11-12 21:52:25,005 - INFO - root - 已保存图片 6/10：./export\hybrid attention\images\figure_6_page34.png
2025-11-12 21:52:25,131 - INFO - root - 已保存图片 7/10：./export\hybrid attention\images\figure_7_page34.png
2025-11-12 21:52:25,267 - INFO - root - 已保存图片 8/10：./export\hybrid attention\images\figure_8_page34.png
2025-11-12 21:52:25,401 - INFO - root - 已保存图片 9/10：./export\hybrid attention\images\figure_9_page34.png
2025-11-12 21:52:25,549 - INFO - root - 已保存图片 10/10：./export\hybrid attention\images\figure_10_page34.png
2025-11-12 21:52:25,560 - INFO - root - 成功添加图片 1：./export\hybrid attention\images\figure_1_page34.png
2025-11-12 21:52:25,562 - INFO - root - 成功添加图片 2：./export\hybrid attention\images\figure_2_page34.png
2025-11-12 21:52:25,563 - INFO - root - 成功添加图片 3：./export\hybrid attention\images\figure_3_page34.png
2025-11-12 21:52:25,567 - INFO - root - 成功添加图片 4：./export\hybrid attention\images\figure_4_page34.png
2025-11-12 21:52:25,567 - INFO - root - 成功添加图片 5：./export\hybrid attention\images\figure_5_page34.png
2025-11-12 21:52:25,568 - INFO - root - 成功添加图片 6：./export\hybrid attention\images\figure_6_page34.png
2025-11-12 21:52:25,568 - INFO - root - 成功添加图片 7：./export\hybrid attention\images\figure_7_page34.png
2025-11-12 21:52:25,568 - INFO - root - 成功添加图片 8：./export\hybrid attention\images\figure_8_page34.png
2025-11-12 21:52:25,568 - INFO - root - 成功添加图片 9：./export\hybrid attention\images\figure_9_page34.png
2025-11-12 21:52:25,574 - INFO - root - 成功添加图片 10：./export\hybrid attention\images\figure_10_page34.png
2025-11-12 21:52:25,577 - INFO - root - 已更新图片链接
2025-11-12 21:52:25,583 - INFO - root - 论文《Forgetting Transformer: Softmax Attention with a Forget Gate》的分析已保存到 ./export\hybrid attention\Forgetting Transformer_ Softmax Attention with a Forget Gate.md
2025-11-12 21:52:25,593 - INFO - root - 跳过已处理论文 HyRRT-Connect: A Bidirectional Rapidly-Exploring Random Trees Motion Planning Algorithm for Hybrid Systems：D:\ChatPaper\api_downloads\hybrid attention\HyRRT-Connect_ A Bidirectional Rapidly-Exploring Random Trees Motion Planning Algorithm for Hybrid S.pdf
2025-11-12 21:52:25,594 - INFO - root - 跳过已处理论文 Vision Transformer with Quadrangle Attention：D:\ChatPaper\api_downloads\hybrid attention\Vision Transformer with Quadrangle Attention.pdf
2025-11-12 21:52:25,596 - INFO - root - 正在总结论文 18/18: Cross-Image Attention for Zero-Shot Appearance Transfer
2025-11-12 21:52:35,112 - INFO - root - LLMClient: rate limit reached, sleeping 10.5s
2025-11-12 21:53:15,709 - INFO - root - LLMClient: rate limit reached, sleeping 9.9s
2025-11-12 21:54:16,157 - INFO - root - 正在提取论文图片到目录: ./export\hybrid attention\images
2025-11-12 21:54:19,199 - INFO - root - 已保存图片 1/10：./export\hybrid attention\images\figure_1_page7.jpeg
2025-11-12 21:54:19,701 - INFO - root - 已保存图片 2/10：./export\hybrid attention\images\figure_2_page15.jpeg
2025-11-12 21:54:20,024 - INFO - root - 已保存图片 3/10：./export\hybrid attention\images\figure_3_page6.jpeg
2025-11-12 21:54:20,313 - INFO - root - 已保存图片 4/10：./export\hybrid attention\images\figure_4_page18.jpeg
2025-11-12 21:54:20,520 - INFO - root - 已保存图片 5/10：./export\hybrid attention\images\figure_5_page1.jpeg
2025-11-12 21:54:20,753 - INFO - root - 已保存图片 6/10：./export\hybrid attention\images\figure_6_page15.jpeg
2025-11-12 21:54:21,038 - INFO - root - 已保存图片 7/10：./export\hybrid attention\images\figure_7_page16.jpeg
2025-11-12 21:54:21,286 - INFO - root - 已保存图片 8/10：./export\hybrid attention\images\figure_8_page17.jpeg
2025-11-12 21:54:21,458 - INFO - root - 已保存图片 9/10：./export\hybrid attention\images\figure_9_page17.jpeg
2025-11-12 21:54:21,589 - INFO - root - 已保存图片 10/10：./export\hybrid attention\images\figure_10_page6.jpeg
2025-11-12 21:54:21,655 - INFO - root - 成功添加图片 1：./export\hybrid attention\images\figure_1_page7.jpeg
2025-11-12 21:54:21,656 - INFO - root - 成功添加图片 2：./export\hybrid attention\images\figure_2_page15.jpeg
2025-11-12 21:54:21,656 - INFO - root - 成功添加图片 3：./export\hybrid attention\images\figure_3_page6.jpeg
2025-11-12 21:54:21,656 - INFO - root - 成功添加图片 4：./export\hybrid attention\images\figure_4_page18.jpeg
2025-11-12 21:54:21,657 - INFO - root - 成功添加图片 5：./export\hybrid attention\images\figure_5_page1.jpeg
2025-11-12 21:54:21,657 - INFO - root - 成功添加图片 6：./export\hybrid attention\images\figure_6_page15.jpeg
2025-11-12 21:54:21,657 - INFO - root - 成功添加图片 7：./export\hybrid attention\images\figure_7_page16.jpeg
2025-11-12 21:54:21,659 - INFO - root - 成功添加图片 8：./export\hybrid attention\images\figure_8_page17.jpeg
2025-11-12 21:54:21,659 - INFO - root - 成功添加图片 9：./export\hybrid attention\images\figure_9_page17.jpeg
2025-11-12 21:54:21,659 - INFO - root - 成功添加图片 10：./export\hybrid attention\images\figure_10_page6.jpeg
2025-11-12 21:54:21,662 - INFO - root - 已更新图片链接
2025-11-12 21:54:21,666 - INFO - root - 论文《Cross-Image Attention for Zero-Shot Appearance Transfer》的分析已保存到 ./export\hybrid attention\Cross-Image Attention for Zero-Shot Appearance Transfer.md
2025-11-12 21:54:22,294 - INFO - root - 已生成汇总Excel表格: export\hybrid attention\论文汇总_hybrid attention_20251112_215421.xlsx
2025-11-12 21:54:22,300 - INFO - root - 已生成汇总Excel表格: export\hybrid attention\论文汇总_hybrid attention_20251112_215421.xlsx
2025-11-12 21:54:22,300 - INFO - root - 总运行时间: 640.80 seconds
2025-11-12 22:02:40,938 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-12 22:02:40,940 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-12 22:02:40,944 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-12 22:02:49,917 - INFO - root - GeminiClient: trying model models/gemini-2.5-flash
2025-11-12 22:02:56,097 - INFO - root - GeminiClient: initialized model gemini-2.5-flash
2025-11-12 22:02:56,097 - INFO - root - LLMClientManager: Gemini client initialized successfully
2025-11-12 22:02:56,098 - INFO - root - LLMClientManager: using Gemini as default client
2025-11-12 22:02:56,098 - INFO - root - DeepSeekClient: API key found: 9f9e270e-b...
2025-11-12 22:02:56,098 - INFO - root - DeepSeekClient: 使用模式: 火山引擎
2025-11-12 22:02:56,099 - INFO - root - DeepSeekClient: 模型名称: deepseek-v3-1-terminus
2025-11-12 22:02:59,317 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 22:02:59,349 - INFO - root - DeepSeekClient: initialized successfully with model deepseek-v3-1-terminus
2025-11-12 22:02:59,349 - INFO - root - LLMClientManager: DeepSeek client initialized successfully
2025-11-12 22:02:59,351 - WARNING - root - KimiClient: API key not provided. LLM disabled.
2025-11-12 22:02:59,351 - WARNING - root - LLMClientManager: Kimi client initialization failed
2025-11-12 22:02:59,351 - WARNING - root - QwenClient: API key not provided. LLM disabled.
2025-11-12 22:02:59,351 - WARNING - root - LLMClientManager: Qwen client initialization failed
2025-11-12 22:02:59,351 - INFO - root - DoubaoClient: API key found: 9f9e270e-b...
2025-11-12 22:03:03,127 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 22:03:03,131 - INFO - root - DoubaoClient: initialized successfully with model doubao-seed-1-6-lite-251015
2025-11-12 22:03:03,131 - INFO - root - LLMClientManager: Doubao client initialized successfully
2025-11-12 22:03:03,132 - INFO - root - 使用 LLM 模型: gemini-2.5-flash
2025-11-12 22:03:03,132 - INFO - root - 可用客户端: ['Gemini', 'DeepSeek', 'Doubao']
2025-11-12 22:03:03,133 - INFO - root - === 运行配置 ===
2025-11-12 22:03:03,133 - INFO - root - 处理模式: Google Scholar 高引用搜索 (爬虫)
2025-11-12 22:03:03,134 - INFO - root - 查询 (关键词): hybrid attention
2025-11-12 22:03:03,134 - INFO - root - 关键词 (用于保存): hybrid attention
2025-11-12 22:03:03,136 - INFO - root - 排序: Citations
2025-11-12 22:03:03,136 - INFO - root - 年份范围: 2017 - 2025
2025-11-12 22:03:03,136 - INFO - root - 最大处理数量: 50
2025-11-12 22:03:03,137 - INFO - root - 保存图片: 是
2025-11-12 22:03:03,138 - INFO - root - 输出语言: 中文
2025-11-12 22:03:03,139 - INFO - root - 强制重新处理: 否
2025-11-12 22:03:03,139 - INFO - root - LLM 客户端: None
2025-11-12 22:03:03,141 - INFO - root - ====================
2025-11-12 22:03:03,142 - INFO - root - 正在使用检索策略: scholar
2025-11-12 22:03:03,149 - INFO - root - 使用 Google Scholar 高引用搜索模式 (爬虫)
2025-11-12 22:03:03,150 - INFO - root - Scholar 配置: 关键词=hybrid attention, 数量=50, 排序=Citations, 年份=2017-2025
2025-11-12 22:03:04,759 - WARNING - root - Robot checking detected, handling with selenium (if installed)
2025-11-12 22:03:17,695 - WARNING - root - Robot checking detected, handling with selenium (if installed)
2025-11-12 22:04:02,172 - WARNING - root - Robot checking detected, handling with selenium (if installed)
2025-11-12 22:04:04,243 - WARNING - root - Robot checking detected, handling with selenium (if installed)
2025-11-12 22:04:06,943 - WARNING - root - Robot checking detected, handling with selenium (if installed)
2025-11-12 22:04:10,399 - WARNING - root - 【手动下载提示】(非ArXiv链接): Hybrid CTC/attention architecture for end-to-end speech recognition @ https://ieeexplore.ieee.org/abstract/document/8068205/
2025-11-12 22:04:10,401 - WARNING - root - 【手动下载提示】(非ArXiv链接): A hybrid deep learning model with attention-based conv-LSTM networks for short-term traffic flow prediction @ https://ieeexplore.ieee.org/abstract/document/9112272/
2025-11-12 22:04:10,401 - WARNING - root - 【手动下载提示】(非ArXiv链接): Bi-LSTM model to increase accuracy in text classification: Combining Word2vec CNN and attention mechanism @ https://www.mdpi.com/2076-3417/10/17/5841
2025-11-12 22:04:10,401 - WARNING - root - 【手动下载提示】(非ArXiv链接): RA-UNet: A hybrid deep attention-aware network to extract liver and tumor in CT scans @ https://www.frontiersin.org/articles/10.3389/fbioe.2020.605132/full
2025-11-12 22:04:10,401 - WARNING - root - 【手动下载提示】(非ArXiv链接): Hybrid attention-based prototypical networks for noisy few-shot relation classification @ https://aaai.org/ojs/index.php/AAAI/article/view/4604
2025-11-12 22:04:10,403 - WARNING - root - 【手动下载提示】(非ArXiv链接): A novel attention-based hybrid CNN-RNN architecture for sEMG-based gesture recognition @ https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0206049
2025-11-12 22:04:10,403 - WARNING - root - 【手动下载提示】(非ArXiv链接): Hybrid multiple attention network for semantic segmentation in aerial images @ https://ieeexplore.ieee.org/abstract/document/9385072/
2025-11-12 22:04:10,403 - WARNING - root - 【手动下载提示】(非ArXiv链接): CKD-TransBTS: clinical knowledge-driven hybrid transformer with modality-correlated cross-attention for brain tumor segmentation @ https://ieeexplore.ieee.org/abstract/document/10056308/
2025-11-12 22:04:10,404 - WARNING - root - 【手动下载提示】(非ArXiv链接): A hybrid attention-based deep learning approach for wind power prediction @ https://www.sciencedirect.com/science/article/pii/S0306261922009138
2025-11-12 22:04:10,404 - WARNING - root - 【手动下载提示】(非ArXiv链接): A study on water quality prediction by a hybrid CNN-LSTM model with attention mechanism @ https://link.springer.com/article/10.1007/s11356-021-14687-8
2025-11-12 22:04:10,406 - WARNING - root - 【手动下载提示】(非ArXiv链接): Hybrid dilation and attention residual U-Net for medical image segmentation @ https://www.sciencedirect.com/science/article/pii/S0010482521002432
2025-11-12 22:04:10,414 - WARNING - root - 【手动下载提示】(非ArXiv链接): A hybrid attention mechanism for weakly-supervised temporal action localization @ https://ojs.aaai.org/index.php/AAAI/article/view/16256
2025-11-12 22:04:10,414 - WARNING - root - 【手动下载提示】(非ArXiv链接): ALDONAr: A hybrid solution for sentence-level aspect-based sentiment analysis using a lexicalized domain ontology and a regularized neural attention model @ https://www.sciencedirect.com/science/article/pii/S0306457319310222
2025-11-12 22:04:10,416 - WARNING - root - 【手动下载提示】(非ArXiv链接): Attention-guided hybrid network for dementia diagnosis with structural MR images @ https://ieeexplore.ieee.org/abstract/document/9151307/
2025-11-12 22:04:10,427 - WARNING - root - 【手动下载提示】(非ArXiv链接): A hybrid deep learning architecture for wind power prediction based on bi-attention mechanism and crisscross optimization @ https://www.sciencedirect.com/science/article/pii/S0360544221020430
2025-11-12 22:04:10,444 - INFO - root - 正在下载: https://arxiv.org/pdf/2309.05239.pdf
2025-11-12 22:04:15,049 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\hybrid attention\Hat_ Hybrid attention transformer for image restoration.pdf
2025-11-12 22:04:15,056 - INFO - root - 成功下载 (Scholar-ArXiv): Hat: Hybrid attention transformer for image restoration
2025-11-12 22:04:15,056 - WARNING - root - 【手动下载提示】(非ArXiv链接): State of health estimation for lithium-ion batteries based on hybrid attention and deep learning @ https://www.sciencedirect.com/science/article/pii/S0951832022006810
2025-11-12 22:04:15,057 - WARNING - root - 【手动下载提示】(非ArXiv链接): Machine fault detection using a hybrid CNN-LSTM attention-based model @ https://www.mdpi.com/1424-8220/23/9/4512
2025-11-12 22:04:15,057 - WARNING - root - 【手动下载提示】(非ArXiv链接): Parallel deep learning algorithms with hybrid attention mechanism for image segmentation of lung tumors @ https://ieeexplore.ieee.org/abstract/document/9190051/
2025-11-12 22:04:15,057 - WARNING - root - 【手动下载提示】(非ArXiv链接): Hybrid network with attention mechanism for detection and location of myocardial infarction based on 12-lead electrocardiogram signals @ https://www.mdpi.com/1424-8220/20/4/1020
2025-11-12 22:04:15,059 - WARNING - root - 【手动下载提示】(非ArXiv链接): Sentiment and context-aware hybrid DNN with attention for text sentiment classification @ https://ieeexplore.ieee.org/abstract/document/10076431/
2025-11-12 22:04:15,060 - WARNING - root - 【手动下载提示】(非ArXiv链接): Twitter sentiment analysis using hybrid gated attention recurrent network @ https://link.springer.com/article/10.1186/s40537-023-00726-3
2025-11-12 22:04:15,061 - WARNING - root - 【手动下载提示】(非ArXiv链接): A hybrid deep learning-based fruit classification using attention model and convolution autoencoder @ https://link.springer.com/article/10.1007/s40747-020-00192-x
2025-11-12 22:04:15,061 - WARNING - root - 【手动下载提示】(非ArXiv链接): Abundance matrix correlation analysis network based on hierarchical multihead self-cross-hybrid attention for hyperspectral change detection @ https://ieeexplore.ieee.org/abstract/document/10017159/
2025-11-12 22:04:15,065 - WARNING - root - 【手动下载提示】(非ArXiv链接): Hybrid-attention based decoupled metric learning for zero-shot image retrieval @ http://openaccess.thecvf.com/content_CVPR_2019/html/Chen_Hybrid-Attention_Based_Decoupled_Metric_Learning_for_Zero-Shot_Image_Retrieval_CVPR_2019_paper.html
2025-11-12 22:04:15,070 - WARNING - root - 【手动下载提示】(非ArXiv链接): CRAN: a hybrid CNN-RNN attention-based model for text classification @ https://link.springer.com/chapter/10.1007/978-3-030-00847-5_42
2025-11-12 22:04:15,073 - WARNING - root - 【手动下载提示】(非ArXiv链接): Hybrid graph convolutional networks with multi-head attention for location recommendation @ https://link.springer.com/article/10.1007/s11280-020-00824-9
2025-11-12 22:04:15,075 - WARNING - root - 【手动下载提示】(非ArXiv链接): An attention-based hybrid architecture with explainability for depressive social media text detection in Bangla @ https://www.sciencedirect.com/science/article/pii/S0957417422020255
2025-11-12 22:04:15,077 - WARNING - root - 【手动下载提示】(非ArXiv链接): Depression detection based on hybrid deep learning SSCL framework using self-attention mechanism: An application to social networking data @ https://www.mdpi.com/1424-8220/22/24/9775
2025-11-12 22:04:15,078 - WARNING - root - 【手动下载提示】(非ArXiv链接): Attention-based hybrid CNN-LSTM and spectral data augmentation for COVID-19 diagnosis from cough sound @ https://link.springer.com/article/10.1007/s10844-022-00707-7
2025-11-12 22:04:15,078 - WARNING - root - 【手动下载提示】(非ArXiv链接): Stock movement prediction based on bi-typed hybrid-relational market knowledge graph via dual attention networks @ https://ieeexplore.ieee.org/abstract/document/9942340/
2025-11-12 22:04:15,078 - WARNING - root - 【手动下载提示】(非ArXiv链接): A two-step hybrid unsupervised model with attention mechanism for aspect extraction @ https://www.sciencedirect.com/science/article/pii/S0957417420304978
2025-11-12 22:04:15,084 - WARNING - root - 【手动下载提示】(非ArXiv链接): A hybrid attention-based multi-wavelet coefficient fusion method in RUL prognosis of rolling bearings @ https://www.sciencedirect.com/science/article/pii/S095183202300251X
2025-11-12 22:04:15,085 - WARNING - root - 【手动下载提示】(非ArXiv链接): Hac-net: A hybrid attention-based convolutional neural network for highly accurate protein–ligand binding affinity prediction @ https://pubs.acs.org/doi/abs/10.1021/acs.jcim.3c00251
2025-11-12 22:04:15,087 - WARNING - root - 【手动下载提示】(非ArXiv链接): Hybrid attention-based long short-term memory network for sarcasm identification @ https://www.sciencedirect.com/science/article/pii/S1568494621002714
2025-11-12 22:04:15,087 - WARNING - root - 【手动下载提示】(非ArXiv链接): A hybrid self-attention deep learning framework for multivariate sleep stage classification @ https://link.springer.com/article/10.1186/s12859-019-3075-z
2025-11-12 22:04:15,087 - WARNING - root - 【手动下载提示】(非ArXiv链接): Physics inspired hybrid attention for SAR target recognition @ https://www.sciencedirect.com/science/article/pii/S0924271623003374
2025-11-12 22:04:15,089 - WARNING - root - 【手动下载提示】(非ArXiv链接): Differential attention net: Multi-directed differential attention based hybrid deep learning model for solar power forecasting @ https://www.sciencedirect.com/science/article/pii/S0360544222026329
2025-11-12 22:04:15,089 - WARNING - root - 【手动下载提示】(非ArXiv链接): Look, investigate, and classify: a deep hybrid attention method for breast cancer classification @ https://ieeexplore.ieee.org/abstract/document/8759454/
2025-11-12 22:04:15,091 - INFO - root - 正在下载: https://arxiv.org/pdf/1904.11141.pdf
2025-11-12 22:04:17,111 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\hybrid attention\HAR-Net_ Joint learning of hybrid attention for single-stage object detection.pdf
2025-11-12 22:04:17,114 - INFO - root - 成功下载 (Scholar-ArXiv): HAR-Net: Joint learning of hybrid attention for single-stage object detection
2025-11-12 22:04:17,115 - WARNING - root - 【手动下载提示】(非ArXiv链接): Fake news detection and classification using hybrid BiLSTM and self-attention model @ https://link.springer.com/article/10.1007/s11042-022-12764-9
2025-11-12 22:04:17,116 - WARNING - root - 【手动下载提示】(非ArXiv链接): Defect detection method of aluminum profile surface using deep self-attention mechanism under hybrid noise conditions @ https://ieeexplore.ieee.org/abstract/document/9527218/
2025-11-12 22:04:17,116 - WARNING - root - 【手动下载提示】(非ArXiv链接): Hybrid-attention guided network with multiple resolution features for person re-identification @ https://www.sciencedirect.com/science/article/pii/S0020025521007489
2025-11-12 22:04:17,117 - INFO - root - 正在下载: https://arxiv.org/pdf/2505.19369.pdf
2025-11-12 22:04:18,606 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\hybrid attention\SETransformer_ A hybrid attention-based architecture for robust human activity recognition.pdf
2025-11-12 22:04:18,609 - INFO - root - 成功下载 (Scholar-ArXiv): SETransformer: A hybrid attention-based architecture for robust human activity recognition
2025-11-12 22:04:18,609 - WARNING - root - 【手动下载提示】(非ArXiv链接): Hybrid neural attention for agreement/disagreement inference in online debates @ https://aclanthology.org/D18-1069/
2025-11-12 22:04:18,611 - WARNING - root - 【手动下载提示】(非ArXiv链接): An attention-based hybrid deep learning approach for Bengali video captioning @ https://www.sciencedirect.com/science/article/pii/S1319157822004128
2025-11-12 22:04:18,612 - INFO - root - 正在下载: https://arxiv.org/pdf/1811.00253.pdf
2025-11-12 22:04:20,411 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\hybrid attention\Hybrid self-attention network for machine translation.pdf
2025-11-12 22:04:20,414 - INFO - root - 成功下载 (Scholar-ArXiv): Hybrid self-attention network for machine translation
2025-11-12 22:04:20,414 - WARNING - root - 【手动下载提示】(非ArXiv链接): A hybrid snn-ann network for event-based object detection with spatial and temporal attention @ https://juser.fz-juelich.de/record/1038039/files/A%20Hybrid%20SNN-ANN%20Network%20for%20Event-based%20Object%20Detection%20with%20Spatial%20and%20Temporal%20Attention.pdf
2025-11-12 22:04:20,416 - WARNING - root - 【手动下载提示】(非ArXiv链接): A hybrid Transformer architecture with a quantized self-attention mechanism applied to molecular generation @ https://pubs.acs.org/doi/abs/10.1021/acs.jctc.5c00331
2025-11-12 22:04:20,417 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\hybrid attention\A systematic analysis of hybrid linear attention.pdf
2025-11-12 22:04:20,425 - INFO - root - 成功下载 (Scholar-ArXiv): A systematic analysis of hybrid linear attention
2025-11-12 22:04:20,431 - INFO - root - 检索到 5 篇论文，开始总结...
2025-11-12 22:04:20,445 - INFO - root - 正在总结论文 1/5: Hat: Hybrid attention transformer for image restoration
2025-11-12 22:07:19,923 - INFO - root - 正在提取论文图片到目录: ./export\hybrid attention\images
2025-11-12 22:07:20,654 - INFO - root - 已保存图片 1/10：./export\hybrid attention\images\figure_1_page12.jpeg
2025-11-12 22:07:21,246 - INFO - root - 已保存图片 2/10：./export\hybrid attention\images\figure_2_page18.jpeg
2025-11-12 22:07:21,474 - INFO - root - 已保存图片 3/10：./export\hybrid attention\images\figure_3_page14.jpeg
2025-11-12 22:07:21,628 - INFO - root - 已保存图片 4/10：./export\hybrid attention\images\figure_4_page14.jpeg
2025-11-12 22:07:21,768 - INFO - root - 已保存图片 5/10：./export\hybrid attention\images\figure_5_page11.jpeg
2025-11-12 22:07:21,886 - INFO - root - 已保存图片 6/10：./export\hybrid attention\images\figure_6_page14.jpeg
2025-11-12 22:07:22,001 - INFO - root - 已保存图片 7/10：./export\hybrid attention\images\figure_7_page18.jpeg
2025-11-12 22:07:22,118 - INFO - root - 已保存图片 8/10：./export\hybrid attention\images\figure_8_page4.jpeg
2025-11-12 22:07:22,228 - INFO - root - 已保存图片 9/10：./export\hybrid attention\images\figure_9_page18.jpeg
2025-11-12 22:07:22,358 - INFO - root - 已保存图片 10/10：./export\hybrid attention\images\figure_10_page5.jpeg
2025-11-12 22:07:22,383 - INFO - root - 成功添加图片 1：./export\hybrid attention\images\figure_1_page12.jpeg
2025-11-12 22:07:22,384 - INFO - root - 成功添加图片 2：./export\hybrid attention\images\figure_2_page18.jpeg
2025-11-12 22:07:22,386 - INFO - root - 成功添加图片 3：./export\hybrid attention\images\figure_3_page14.jpeg
2025-11-12 22:07:22,386 - INFO - root - 成功添加图片 4：./export\hybrid attention\images\figure_4_page14.jpeg
2025-11-12 22:07:22,387 - INFO - root - 成功添加图片 5：./export\hybrid attention\images\figure_5_page11.jpeg
2025-11-12 22:07:22,388 - INFO - root - 成功添加图片 6：./export\hybrid attention\images\figure_6_page14.jpeg
2025-11-12 22:07:22,389 - INFO - root - 成功添加图片 7：./export\hybrid attention\images\figure_7_page18.jpeg
2025-11-12 22:07:22,390 - INFO - root - 成功添加图片 8：./export\hybrid attention\images\figure_8_page4.jpeg
2025-11-12 22:07:22,391 - INFO - root - 成功添加图片 9：./export\hybrid attention\images\figure_9_page18.jpeg
2025-11-12 22:07:22,391 - INFO - root - 成功添加图片 10：./export\hybrid attention\images\figure_10_page5.jpeg
2025-11-12 22:07:22,394 - INFO - root - 已更新图片链接
2025-11-12 22:07:22,397 - INFO - root - 论文《Hat: Hybrid attention transformer for image restoration》的分析已保存到 ./export\hybrid attention\Hat_ Hybrid attention transformer for image restoration.md
2025-11-12 22:07:22,406 - INFO - root - 正在总结论文 2/5: HAR-Net: Joint learning of hybrid attention for single-stage object detection
2025-11-12 22:08:09,029 - INFO - root - LLMClient: rate limit reached, sleeping 13.4s
2025-11-12 22:09:00,759 - INFO - root - 正在提取论文图片到目录: ./export\hybrid attention\images
2025-11-12 22:09:01,058 - INFO - root - 已保存图片 1/10：./export\hybrid attention\images\figure_1_page6.jpeg
2025-11-12 22:09:01,199 - INFO - root - 已保存图片 2/10：./export\hybrid attention\images\figure_2_page3.jpeg
2025-11-12 22:09:01,267 - INFO - root - 已保存图片 3/10：./export\hybrid attention\images\figure_3_page1.jpeg
2025-11-12 22:09:01,354 - INFO - root - 已保存图片 4/10：./export\hybrid attention\images\figure_4_page4.jpeg
2025-11-12 22:09:01,431 - INFO - root - 已保存图片 5/10：./export\hybrid attention\images\figure_5_page7.jpeg
2025-11-12 22:09:01,483 - INFO - root - 已保存图片 6/10：./export\hybrid attention\images\figure_6_page5.jpeg
2025-11-12 22:09:01,490 - INFO - root - 成功添加图片 1：./export\hybrid attention\images\figure_1_page6.jpeg
2025-11-12 22:09:01,490 - INFO - root - 成功添加图片 2：./export\hybrid attention\images\figure_2_page3.jpeg
2025-11-12 22:09:01,491 - INFO - root - 成功添加图片 3：./export\hybrid attention\images\figure_3_page1.jpeg
2025-11-12 22:09:01,494 - INFO - root - 成功添加图片 4：./export\hybrid attention\images\figure_4_page4.jpeg
2025-11-12 22:09:01,495 - INFO - root - 成功添加图片 5：./export\hybrid attention\images\figure_5_page7.jpeg
2025-11-12 22:09:01,495 - INFO - root - 成功添加图片 6：./export\hybrid attention\images\figure_6_page5.jpeg
2025-11-12 22:09:01,501 - INFO - root - 已更新图片链接
2025-11-12 22:09:01,506 - INFO - root - 论文《HAR-Net: Joint learning of hybrid attention for single-stage object detection》的分析已保存到 ./export\hybrid attention\HAR-Net_ Joint learning of hybrid attention for single-stage object detection.md
2025-11-12 22:09:01,518 - INFO - root - 正在总结论文 3/5: SETransformer: A hybrid attention-based architecture for robust human activity recognition
2025-11-12 22:09:13,326 - INFO - root - LLMClient: rate limit reached, sleeping 9.1s
2025-11-12 22:14:17,867 - INFO - root - 正在提取论文图片到目录: ./export\hybrid attention\images
2025-11-12 22:14:18,014 - INFO - root - 已保存图片 1/10：./export\hybrid attention\images\figure_1_page6.png
2025-11-12 22:14:18,234 - INFO - root - 已保存图片 2/10：./export\hybrid attention\images\figure_2_page5.png
2025-11-12 22:14:18,240 - INFO - root - 成功添加图片 1：./export\hybrid attention\images\figure_1_page6.png
2025-11-12 22:14:18,240 - INFO - root - 成功添加图片 2：./export\hybrid attention\images\figure_2_page5.png
2025-11-12 22:14:18,247 - INFO - root - 已更新图片链接
2025-11-12 22:14:18,251 - INFO - root - 论文《SETransformer: A hybrid attention-based architecture for robust human activity recognition》的分析已保存到 ./export\hybrid attention\SETransformer_ A hybrid attention-based architecture for robust human activity recognition.md
2025-11-12 22:14:18,265 - INFO - root - 正在总结论文 4/5: Hybrid self-attention network for machine translation
2025-11-12 22:14:56,836 - INFO - root - LLMClient: rate limit reached, sleeping 21.4s
2025-11-12 22:15:44,955 - INFO - root - 正在提取论文图片到目录: ./export\hybrid attention\images
2025-11-12 22:15:45,077 - INFO - root - 已保存图片 1/10：./export\hybrid attention\images\figure_1_page3.png
2025-11-12 22:15:45,138 - INFO - root - 已保存图片 2/10：./export\hybrid attention\images\figure_2_page7.png
2025-11-12 22:15:45,174 - INFO - root - 已保存图片 3/10：./export\hybrid attention\images\figure_3_page7.jpeg
2025-11-12 22:15:45,211 - INFO - root - 已保存图片 4/10：./export\hybrid attention\images\figure_4_page7.jpeg
2025-11-12 22:15:45,254 - INFO - root - 已保存图片 5/10：./export\hybrid attention\images\figure_5_page7.jpeg
2025-11-12 22:15:45,284 - INFO - root - 已保存图片 6/10：./export\hybrid attention\images\figure_6_page7.jpeg
2025-11-12 22:15:45,332 - INFO - root - 已保存图片 7/10：./export\hybrid attention\images\figure_7_page7.jpeg
2025-11-12 22:15:45,376 - INFO - root - 已保存图片 8/10：./export\hybrid attention\images\figure_8_page7.jpeg
2025-11-12 22:15:45,435 - INFO - root - 已保存图片 9/10：./export\hybrid attention\images\figure_9_page7.jpeg
2025-11-12 22:15:45,481 - INFO - root - 已保存图片 10/10：./export\hybrid attention\images\figure_10_page7.jpeg
2025-11-12 22:15:45,492 - INFO - root - 成功添加图片 1：./export\hybrid attention\images\figure_1_page3.png
2025-11-12 22:15:45,492 - INFO - root - 成功添加图片 2：./export\hybrid attention\images\figure_2_page7.png
2025-11-12 22:15:45,526 - INFO - root - 成功添加图片 3：./export\hybrid attention\images\figure_3_page7.jpeg
2025-11-12 22:15:45,568 - INFO - root - 成功添加图片 4：./export\hybrid attention\images\figure_4_page7.jpeg
2025-11-12 22:15:45,586 - INFO - root - 成功添加图片 5：./export\hybrid attention\images\figure_5_page7.jpeg
2025-11-12 22:15:45,625 - INFO - root - 成功添加图片 6：./export\hybrid attention\images\figure_6_page7.jpeg
2025-11-12 22:15:45,650 - INFO - root - 成功添加图片 7：./export\hybrid attention\images\figure_7_page7.jpeg
2025-11-12 22:15:45,669 - INFO - root - 成功添加图片 8：./export\hybrid attention\images\figure_8_page7.jpeg
2025-11-12 22:15:45,677 - INFO - root - 成功添加图片 9：./export\hybrid attention\images\figure_9_page7.jpeg
2025-11-12 22:15:45,690 - INFO - root - 成功添加图片 10：./export\hybrid attention\images\figure_10_page7.jpeg
2025-11-12 22:15:45,703 - INFO - root - 已更新图片链接
2025-11-12 22:15:45,709 - INFO - root - 论文《Hybrid self-attention network for machine translation》的分析已保存到 ./export\hybrid attention\Hybrid self-attention network for machine translation.md
2025-11-12 22:15:45,723 - INFO - root - 跳过已处理论文 A systematic analysis of hybrid linear attention：D:\ChatPaper\api_downloads\hybrid attention\A systematic analysis of hybrid linear attention.pdf
2025-11-12 22:15:46,726 - INFO - root - 已生成汇总Excel表格: export\hybrid attention\论文汇总_hybrid attention_20251112_221545.xlsx
2025-11-12 22:15:46,728 - INFO - root - 已生成汇总Excel表格: export\hybrid attention\论文汇总_hybrid attention_20251112_221545.xlsx
2025-11-12 22:15:46,732 - INFO - root - 总运行时间: 785.79 seconds
2025-11-12 22:16:30,000 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-12 22:16:30,002 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-12 22:16:30,003 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-12 22:16:35,907 - INFO - root - GeminiClient: trying model models/gemini-2.5-flash
2025-11-12 22:16:39,019 - INFO - root - GeminiClient: initialized model gemini-2.5-flash
2025-11-12 22:16:39,020 - INFO - root - LLMClientManager: Gemini client initialized successfully
2025-11-12 22:16:39,020 - INFO - root - LLMClientManager: using Gemini as default client
2025-11-12 22:16:39,020 - INFO - root - DeepSeekClient: API key found: 9f9e270e-b...
2025-11-12 22:16:39,021 - INFO - root - DeepSeekClient: 使用模式: 火山引擎
2025-11-12 22:16:39,021 - INFO - root - DeepSeekClient: 模型名称: deepseek-v3-1-terminus
2025-11-12 22:16:42,665 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 22:16:42,681 - INFO - root - DeepSeekClient: initialized successfully with model deepseek-v3-1-terminus
2025-11-12 22:16:42,681 - INFO - root - LLMClientManager: DeepSeek client initialized successfully
2025-11-12 22:16:42,681 - WARNING - root - KimiClient: API key not provided. LLM disabled.
2025-11-12 22:16:42,681 - WARNING - root - LLMClientManager: Kimi client initialization failed
2025-11-12 22:16:42,681 - WARNING - root - QwenClient: API key not provided. LLM disabled.
2025-11-12 22:16:42,681 - WARNING - root - LLMClientManager: Qwen client initialization failed
2025-11-12 22:16:42,683 - INFO - root - DoubaoClient: API key found: 9f9e270e-b...
2025-11-12 22:16:46,778 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 22:16:46,779 - INFO - root - DoubaoClient: initialized successfully with model doubao-seed-1-6-lite-251015
2025-11-12 22:16:46,779 - INFO - root - LLMClientManager: Doubao client initialized successfully
2025-11-12 22:16:46,779 - INFO - root - 使用 LLM 模型: gemini-2.5-flash
2025-11-12 22:16:46,780 - INFO - root - 可用客户端: ['Gemini', 'DeepSeek', 'Doubao']
2025-11-12 22:16:46,780 - INFO - root - === 运行配置 ===
2025-11-12 22:16:46,780 - INFO - root - 处理模式: Google Scholar 高引用搜索 (爬虫)
2025-11-12 22:16:46,780 - INFO - root - 查询 (关键词): hybrid attention
2025-11-12 22:16:46,781 - INFO - root - 关键词 (用于保存): hybrid attention
2025-11-12 22:16:46,782 - INFO - root - 排序: Citations
2025-11-12 22:16:46,782 - INFO - root - 年份范围: 2017 - 2025
2025-11-12 22:16:46,783 - INFO - root - 最大处理数量: 100
2025-11-12 22:16:46,783 - INFO - root - 保存图片: 是
2025-11-12 22:16:46,784 - INFO - root - 输出语言: 中文
2025-11-12 22:16:46,784 - INFO - root - 强制重新处理: 否
2025-11-12 22:16:46,784 - INFO - root - LLM 客户端: None
2025-11-12 22:16:46,785 - INFO - root - ====================
2025-11-12 22:16:46,786 - INFO - root - 正在使用检索策略: scholar
2025-11-12 22:16:46,786 - INFO - root - 使用 Google Scholar 高引用搜索模式 (爬虫)
2025-11-12 22:16:46,786 - INFO - root - Scholar 配置: 关键词=hybrid attention, 数量=100, 排序=Citations, 年份=2017-2025
2025-11-12 22:16:48,404 - WARNING - root - Robot checking detected, handling with selenium (if installed)
2025-11-12 22:16:56,921 - WARNING - root - Robot checking detected, handling with selenium (if installed)
2025-11-12 22:17:35,995 - WARNING - root - Robot checking detected, handling with selenium (if installed)
2025-11-12 22:17:38,757 - WARNING - root - Robot checking detected, handling with selenium (if installed)
2025-11-12 22:17:40,973 - WARNING - root - Robot checking detected, handling with selenium (if installed)
2025-11-12 22:17:44,553 - WARNING - root - Robot checking detected, handling with selenium (if installed)
2025-11-12 22:17:46,570 - WARNING - root - Robot checking detected, handling with selenium (if installed)
2025-11-12 22:17:48,813 - WARNING - root - Robot checking detected, handling with selenium (if installed)
2025-11-12 22:17:51,258 - WARNING - root - Robot checking detected, handling with selenium (if installed)
2025-11-12 22:17:54,275 - WARNING - root - Robot checking detected, handling with selenium (if installed)
2025-11-12 22:17:55,798 - INFO - root - 正在下载: https://arxiv.org/pdf/2208.01626.pdf
2025-11-12 22:18:13,965 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\hybrid attention\Prompt-to-prompt image editing with cross attention control.pdf
2025-11-12 22:18:13,970 - INFO - root - 成功下载 (Scholar-ArXiv): Prompt-to-prompt image editing with cross attention control
2025-11-12 22:18:13,971 - WARNING - root - 【手动下载提示】(非ArXiv链接): Activating more pixels in image super-resolution transformer
	  URL: http://openaccess.thecvf.com/content/CVPR2023/html/Chen_Activating_More_Pixels_in_Image_Super-Resolution_Transformer_CVPR_2023_paper.html
	  Citations: 1225
2025-11-12 22:18:13,974 - WARNING - root - 【手动下载提示】(非ArXiv链接): Hybrid CTC/attention architecture for end-to-end speech recognition
	  URL: https://ieeexplore.ieee.org/abstract/document/8068205/
	  Citations: 1073
2025-11-12 22:18:13,974 - WARNING - root - 【手动下载提示】(非ArXiv链接): Mixformer: End-to-end tracking with iterative mixed attention
	  URL: http://openaccess.thecvf.com/content/CVPR2022/html/Cui_MixFormer_End-to-End_Tracking_With_Iterative_Mixed_Attention_CVPR_2022_paper.html
	  Citations: 949
2025-11-12 22:18:13,975 - WARNING - root - 【手动下载提示】(非ArXiv链接): Pay attention to mlps
	  URL: https://proceedings.neurips.cc/paper/2021/hash/4cc05b35c2f937c5bd9e7d41d3686fff-Abstract.html
	  Citations: 874
2025-11-12 22:18:13,976 - WARNING - root - 【手动下载提示】(非ArXiv链接): UTNet: a hybrid transformer architecture for medical image segmentation
	  URL: https://link.springer.com/chapter/10.1007/978-3-030-87199-4_6
	  Citations: 739
2025-11-12 22:18:13,982 - WARNING - root - 【手动下载提示】(非ArXiv链接): Multi-attention recurrent network for human communication comprehension
	  URL: https://ojs.aaai.org/index.php/AAAI/article/view/12024
	  Citations: 661
2025-11-12 22:18:13,983 - WARNING - root - 【手动下载提示】(非ArXiv链接): Detrs with collaborative hybrid assignments training
	  URL: http://openaccess.thecvf.com/content/ICCV2023/html/Zong_DETRs_with_Collaborative_Hybrid_Assignments_Training_ICCV_2023_paper.html
	  Citations: 653
2025-11-12 22:18:13,983 - WARNING - root - 【手动下载提示】(非ArXiv链接): A review on recent sizing methodologies of hybrid renewable energy systems
	  URL: https://www.sciencedirect.com/science/article/pii/S0196890419310337
	  Citations: 635
2025-11-12 22:18:13,983 - WARNING - root - 【手动下载提示】(非ArXiv链接): Scaling local self-attention for parameter efficient visual backbones
	  URL: http://openaccess.thecvf.com/content/CVPR2021/html/Vaswani_Scaling_Local_Self-Attention_for_Parameter_Efficient_Visual_Backbones_CVPR_2021_paper.html
	  Citations: 585
2025-11-12 22:18:13,983 - WARNING - root - 【手动下载提示】(非ArXiv链接): A hybrid deep learning model with attention-based conv-LSTM networks for short-term traffic flow prediction
	  URL: https://ieeexplore.ieee.org/abstract/document/9112272/
	  Citations: 565
2025-11-12 22:18:13,983 - WARNING - root - 【手动下载提示】(非ArXiv链接): Bi-LSTM model to increase accuracy in text classification: Combining Word2vec CNN and attention mechanism
	  URL: https://www.mdpi.com/2076-3417/10/17/5841
	  Citations: 553
2025-11-12 22:18:13,985 - WARNING - root - 【手动下载提示】(非ArXiv链接): Towards hybrid nanofluids: preparation, thermophysical properties, applications, and challenges
	  URL: https://www.sciencedirect.com/science/article/pii/S0167732218366236
	  Citations: 524
2025-11-12 22:18:13,985 - WARNING - root - 【手动下载提示】(非ArXiv链接): RA-UNet: A hybrid deep attention-aware network to extract liver and tumor in CT scans
	  URL: https://www.frontiersin.org/articles/10.3389/fbioe.2020.605132/full
	  Citations: 513
2025-11-12 22:18:13,985 - WARNING - root - 【手动下载提示】(非ArXiv链接): Sequential recommender system based on hierarchical attention network
	  URL: https://opus.lib.uts.edu.au/handle/10453/126040
	  Citations: 487
2025-11-12 22:18:13,985 - WARNING - root - 【手动下载提示】(非ArXiv链接): Hybrid attention-based prototypical networks for noisy few-shot relation classification
	  URL: https://aaai.org/ojs/index.php/AAAI/article/view/4604
	  Citations: 472
2025-11-12 22:18:13,985 - WARNING - root - 【手动下载提示】(非ArXiv链接): A novel attention-based hybrid CNN-RNN architecture for sEMG-based gesture recognition
	  URL: https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0206049
	  Citations: 466
2025-11-12 22:18:13,985 - WARNING - root - 【手动下载提示】(非ArXiv链接): Listening to chaotic whispers: A deep learning framework for news-oriented stock trend prediction
	  URL: https://dl.acm.org/doi/abs/10.1145/3159652.3159690
	  Citations: 452
2025-11-12 22:18:13,985 - WARNING - root - 【手动下载提示】(非ArXiv链接): DSTP-RNN: A dual-stage two-phase attention-based recurrent neural network for long-term and multivariate time series prediction
	  URL: https://www.sciencedirect.com/science/article/pii/S0957417419307997
	  Citations: 434
2025-11-12 22:18:13,985 - WARNING - root - 【手动下载提示】(非ArXiv链接): Shunted self-attention via multi-scale token aggregation
	  URL: http://openaccess.thecvf.com/content/CVPR2022/html/Ren_Shunted_Self-Attention_via_Multi-Scale_Token_Aggregation_CVPR_2022_paper.html
	  Citations: 404
2025-11-12 22:18:13,990 - INFO - root - 正在下载: https://arxiv.org/pdf/2107.00782.pdf
2025-11-12 22:18:16,806 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\hybrid attention\Polarized self-attention_ Towards high-quality pixel-wise regression.pdf
2025-11-12 22:18:16,808 - INFO - root - 成功下载 (Scholar-ArXiv): Polarized self-attention: Towards high-quality pixel-wise regression
2025-11-12 22:18:16,810 - INFO - root - 正在下载: https://arxiv.org/pdf/1706.02737.pdf
2025-11-12 22:18:18,228 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\hybrid attention\Advances in joint CTC-attention based end-to-end speech recognition with a deep CNN encoder and RNN-.pdf
2025-11-12 22:18:18,233 - INFO - root - 成功下载 (Scholar-ArXiv): Advances in joint CTC-attention based end-to-end speech recognition with a deep CNN encoder and RNN-LM
2025-11-12 22:18:18,233 - WARNING - root - 【手动下载提示】(非ArXiv链接): Sentic LSTM: a hybrid network for targeted aspect-based sentiment analysis
	  URL: https://link.springer.com/article/10.1007/s12559-018-9549-x
	  Citations: 360
2025-11-12 22:18:18,233 - WARNING - root - 【手动下载提示】(非ArXiv链接): Fake news detection through multi-perspective speaker profiles
	  URL: https://aclanthology.org/I17-2043/
	  Citations: 336
2025-11-12 22:18:18,233 - WARNING - root - 【手动下载提示】(非ArXiv链接): Transformer-based acoustic modeling for hybrid speech recognition
	  URL: https://ieeexplore.ieee.org/abstract/document/9054345/
	  Citations: 305
2025-11-12 22:18:18,235 - WARNING - root - 【手动下载提示】(非ArXiv链接): Mambavision: A hybrid mamba-transformer vision backbone
	  URL: http://openaccess.thecvf.com/content/CVPR2025/html/Hatamizadeh_MambaVision_A_Hybrid_Mamba-Transformer_Vision_Backbone_CVPR_2025_paper.html
	  Citations: 258
2025-11-12 22:18:18,236 - WARNING - root - 【手动下载提示】(非ArXiv链接): Hybrid multiple attention network for semantic segmentation in aerial images
	  URL: https://ieeexplore.ieee.org/abstract/document/9385072/
	  Citations: 257
2025-11-12 22:18:18,236 - WARNING - root - 【手动下载提示】(非ArXiv链接): CKD-TransBTS: clinical knowledge-driven hybrid transformer with modality-correlated cross-attention for brain tumor segmentation
	  URL: https://ieeexplore.ieee.org/abstract/document/10056308/
	  Citations: 170
2025-11-12 22:18:18,237 - WARNING - root - 【手动下载提示】(非ArXiv链接): A hybrid attention-based deep learning approach for wind power prediction
	  URL: https://www.sciencedirect.com/science/article/pii/S0306261922009138
	  Citations: 163
2025-11-12 22:18:18,237 - WARNING - root - 【手动下载提示】(非ArXiv链接): A study on water quality prediction by a hybrid CNN-LSTM model with attention mechanism
	  URL: https://link.springer.com/article/10.1007/s11356-021-14687-8
	  Citations: 160
2025-11-12 22:18:18,237 - WARNING - root - 【手动下载提示】(非ArXiv链接): Hybrid dilation and attention residual U-Net for medical image segmentation
	  URL: https://www.sciencedirect.com/science/article/pii/S0010482521002432
	  Citations: 159
2025-11-12 22:18:18,239 - WARNING - root - 【手动下载提示】(非ArXiv链接): A hybrid attention mechanism for weakly-supervised temporal action localization
	  URL: https://ojs.aaai.org/index.php/AAAI/article/view/16256
	  Citations: 155
2025-11-12 22:18:18,240 - WARNING - root - 【手动下载提示】(非ArXiv链接): Point and interval forecasting of ultra-short-term wind power based on a data-driven method and hybrid deep learning model
	  URL: https://www.sciencedirect.com/science/article/pii/S0360544222012877
	  Citations: 153
2025-11-12 22:18:18,240 - WARNING - root - 【手动下载提示】(非ArXiv链接): A hybrid deep learning approach with GCN and LSTM for traffic flow prediction
	  URL: https://ieeexplore.ieee.org/abstract/document/8916778/
	  Citations: 147
2025-11-12 22:18:18,240 - WARNING - root - 【手动下载提示】(非ArXiv链接): Hybrid neural recommendation with joint deep representation learning of ratings and reviews
	  URL: https://www.sciencedirect.com/science/article/pii/S0925231219313207
	  Citations: 138
2025-11-12 22:18:18,241 - WARNING - root - 【手动下载提示】(非ArXiv链接): ALDONAr: A hybrid solution for sentence-level aspect-based sentiment analysis using a lexicalized domain ontology and a regularized neural attention model
	  URL: https://www.sciencedirect.com/science/article/pii/S0306457319310222
	  Citations: 135
2025-11-12 22:18:18,244 - WARNING - root - 【手动下载提示】(非ArXiv链接): Hybrid or mono nanofluids for convective heat transfer applications. A critical review of experimental research
	  URL: https://www.sciencedirect.com/science/article/pii/S135943112101348X
	  Citations: 131
2025-11-12 22:18:18,245 - WARNING - root - 【手动下载提示】(非ArXiv链接): Attention-guided hybrid network for dementia diagnosis with structural MR images
	  URL: https://ieeexplore.ieee.org/abstract/document/9151307/
	  Citations: 125
2025-11-12 22:18:18,245 - WARNING - root - 【手动下载提示】(非ArXiv链接): A hybrid deep learning architecture for wind power prediction based on bi-attention mechanism and crisscross optimization
	  URL: https://www.sciencedirect.com/science/article/pii/S0360544221020430
	  Citations: 123
2025-11-12 22:18:18,248 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\hybrid attention\Hat_ Hybrid attention transformer for image restoration.pdf
2025-11-12 22:18:18,250 - INFO - root - 成功下载 (Scholar-ArXiv): Hat: Hybrid attention transformer for image restoration
2025-11-12 22:18:18,250 - WARNING - root - 【手动下载提示】(非ArXiv链接): State of health estimation for lithium-ion batteries based on hybrid attention and deep learning
	  URL: https://www.sciencedirect.com/science/article/pii/S0951832022006810
	  Citations: 120
2025-11-12 22:18:18,251 - WARNING - root - 【手动下载提示】(非ArXiv链接): Forecasting stock prices using a hybrid deep learning model integrating attention mechanism, multi-layer perceptron, and bidirectional long-short term memory neural …
	  URL: https://ieeexplore.ieee.org/abstract/document/9122554/
	  Citations: 117
2025-11-12 22:18:18,253 - WARNING - root - 【手动下载提示】(非ArXiv链接): Machine fault detection using a hybrid CNN-LSTM attention-based model
	  URL: https://www.mdpi.com/1424-8220/23/9/4512
	  Citations: 116
2025-11-12 22:18:18,253 - WARNING - root - 【手动下载提示】(非ArXiv链接): Parallel deep learning algorithms with hybrid attention mechanism for image segmentation of lung tumors
	  URL: https://ieeexplore.ieee.org/abstract/document/9190051/
	  Citations: 114
2025-11-12 22:18:18,254 - WARNING - root - 【手动下载提示】(非ArXiv链接): Hybrid network with attention mechanism for detection and location of myocardial infarction based on 12-lead electrocardiogram signals
	  URL: https://www.mdpi.com/1424-8220/20/4/1020
	  Citations: 110
2025-11-12 22:18:18,255 - WARNING - root - 【手动下载提示】(非ArXiv链接): Hybrid routing transformer for zero-shot learning
	  URL: https://www.sciencedirect.com/science/article/pii/S003132032200749X
	  Citations: 101
2025-11-12 22:18:18,255 - WARNING - root - 【手动下载提示】(非ArXiv链接): Sentiment and context-aware hybrid DNN with attention for text sentiment classification
	  URL: https://ieeexplore.ieee.org/abstract/document/10076431/
	  Citations: 95
2025-11-12 22:18:18,256 - WARNING - root - 【手动下载提示】(非ArXiv链接): Twitter sentiment analysis using hybrid gated attention recurrent network
	  URL: https://link.springer.com/article/10.1186/s40537-023-00726-3
	  Citations: 93
2025-11-12 22:18:18,256 - WARNING - root - 【手动下载提示】(非ArXiv链接): FGANet: fNIRS-guided attention network for hybrid EEG-fNIRS brain-computer interfaces
	  URL: https://ieeexplore.ieee.org/abstract/document/9706459/
	  Citations: 91
2025-11-12 22:18:18,257 - WARNING - root - 【手动下载提示】(非ArXiv链接): A hybrid deep learning-based fruit classification using attention model and convolution autoencoder
	  URL: https://link.springer.com/article/10.1007/s40747-020-00192-x
	  Citations: 91
2025-11-12 22:18:18,258 - WARNING - root - 【手动下载提示】(非ArXiv链接): Abundance matrix correlation analysis network based on hierarchical multihead self-cross-hybrid attention for hyperspectral change detection
	  URL: https://ieeexplore.ieee.org/abstract/document/10017159/
	  Citations: 84
2025-11-12 22:18:18,258 - WARNING - root - 【手动下载提示】(非ArXiv链接): A hybrid photovoltaic/wind power prediction model based on Time2Vec, WDCNN and BiLSTM
	  URL: https://www.sciencedirect.com/science/article/pii/S019689042300688X
	  Citations: 81
2025-11-12 22:18:18,258 - WARNING - root - 【手动下载提示】(非ArXiv链接): Hybrid-attention based decoupled metric learning for zero-shot image retrieval
	  URL: http://openaccess.thecvf.com/content_CVPR_2019/html/Chen_Hybrid-Attention_Based_Decoupled_Metric_Learning_for_Zero-Shot_Image_Retrieval_CVPR_2019_paper.html
	  Citations: 80
2025-11-12 22:18:18,260 - WARNING - root - 【手动下载提示】(非ArXiv链接): CRAN: a hybrid CNN-RNN attention-based model for text classification
	  URL: https://link.springer.com/chapter/10.1007/978-3-030-00847-5_42
	  Citations: 78
2025-11-12 22:18:18,260 - WARNING - root - 【手动下载提示】(非ArXiv链接): Hybrid graph convolutional networks with multi-head attention for location recommendation
	  URL: https://link.springer.com/article/10.1007/s11280-020-00824-9
	  Citations: 73
2025-11-12 22:18:18,261 - WARNING - root - 【手动下载提示】(非ArXiv链接): Depression detection based on hybrid deep learning SSCL framework using self-attention mechanism: An application to social networking data
	  URL: https://www.mdpi.com/1424-8220/22/24/9775
	  Citations: 72
2025-11-12 22:18:18,261 - WARNING - root - 【手动下载提示】(非ArXiv链接): An attention-based hybrid architecture with explainability for depressive social media text detection in Bangla
	  URL: https://www.sciencedirect.com/science/article/pii/S0957417422020255
	  Citations: 72
2025-11-12 22:18:18,262 - WARNING - root - 【手动下载提示】(非ArXiv链接): Attention-based hybrid CNN-LSTM and spectral data augmentation for COVID-19 diagnosis from cough sound
	  URL: https://link.springer.com/article/10.1007/s10844-022-00707-7
	  Citations: 71
2025-11-12 22:18:18,262 - WARNING - root - 【手动下载提示】(非ArXiv链接): The mamba in the llama: Distilling and accelerating hybrid models
	  URL: https://proceedings.neurips.cc/paper_files/paper/2024/hash/723933067ad315269b620bc0d2c05cba-Abstract-Conference.html
	  Citations: 69
2025-11-12 22:18:18,264 - WARNING - root - 【手动下载提示】(非ArXiv链接): A short-term forecasting method for photovoltaic power generation based on the TCN-ECANet-GRU hybrid model
	  URL: https://www.nature.com/articles/s41598-024-56751-6
	  Citations: 68
2025-11-12 22:18:18,267 - WARNING - root - 【手动下载提示】(非ArXiv链接): Stock movement prediction based on bi-typed hybrid-relational market knowledge graph via dual attention networks
	  URL: https://ieeexplore.ieee.org/abstract/document/9942340/
	  Citations: 68
2025-11-12 22:18:18,268 - WARNING - root - 【手动下载提示】(非ArXiv链接): A hybrid approach for aspect-based sentiment analysis using deep contextual word embeddings and hierarchical attention
	  URL: https://link.springer.com/chapter/10.1007/978-3-030-50578-3_25
	  Citations: 68
2025-11-12 22:18:18,268 - WARNING - root - 【手动下载提示】(非ArXiv链接): Driver emotion recognition with a hybrid attentional multimodal fusion framework
	  URL: https://ieeexplore.ieee.org/abstract/document/10056293/
	  Citations: 67
2025-11-12 22:18:18,270 - WARNING - root - 【手动下载提示】(非ArXiv链接): A two-step hybrid unsupervised model with attention mechanism for aspect extraction
	  URL: https://www.sciencedirect.com/science/article/pii/S0957417420304978
	  Citations: 66
2025-11-12 22:18:18,271 - WARNING - root - 【手动下载提示】(非ArXiv链接): Multimodal hybrid deep learning approach to detect tomato leaf disease using attention based dilated convolution feature extractor with logistic regression …
	  URL: https://www.mdpi.com/1424-8220/22/16/6079
	  Citations: 65
2025-11-12 22:18:18,272 - WARNING - root - 【手动下载提示】(非ArXiv链接): Hierarchical attentional hybrid neural networks for document classification
	  URL: https://link.springer.com/chapter/10.1007/978-3-030-30493-5_39
	  Citations: 63
2025-11-12 22:18:18,273 - WARNING - root - 【手动下载提示】(非ArXiv链接): The internationalization of social hybrid firms
	  URL: https://www.sciencedirect.com/science/article/pii/S0148296319306058
	  Citations: 62
2025-11-12 22:18:18,274 - WARNING - root - 【手动下载提示】(非ArXiv链接): A hybrid attention-based multi-wavelet coefficient fusion method in RUL prognosis of rolling bearings
	  URL: https://www.sciencedirect.com/science/article/pii/S095183202300251X
	  Citations: 62
2025-11-12 22:18:18,274 - WARNING - root - 【手动下载提示】(非ArXiv链接): HAU-Net: Hybrid CNN-transformer for breast ultrasound image segmentation
	  URL: https://www.sciencedirect.com/science/article/pii/S1746809423008601
	  Citations: 62
2025-11-12 22:18:18,275 - WARNING - root - 【手动下载提示】(非ArXiv链接): Hac-net: A hybrid attention-based convolutional neural network for highly accurate protein–ligand binding affinity prediction
	  URL: https://pubs.acs.org/doi/abs/10.1021/acs.jcim.3c00251
	  Citations: 61
2025-11-12 22:18:18,276 - WARNING - root - 【手动下载提示】(非ArXiv链接): A novel hybrid deep learning model with ARIMA Conv-LSTM networks and shuffle attention layer for short-term traffic flow prediction
	  URL: https://www.tandfonline.com/doi/abs/10.1080/23249935.2023.2236724
	  Citations: 60
2025-11-12 22:18:18,277 - WARNING - root - 【手动下载提示】(非ArXiv链接): Hybrid data augmentation and deep attention-based dilated convolutional-recurrent neural networks for speech emotion recognition
	  URL: https://www.sciencedirect.com/science/article/pii/S0957417423011107
	  Citations: 60
2025-11-12 22:18:18,277 - WARNING - root - 【手动下载提示】(非ArXiv链接): Hybrid attention-based long short-term memory network for sarcasm identification
	  URL: https://www.sciencedirect.com/science/article/pii/S1568494621002714
	  Citations: 58
2025-11-12 22:18:18,278 - WARNING - root - 【手动下载提示】(非ArXiv链接): A hybrid self-attention deep learning framework for multivariate sleep stage classification
	  URL: https://link.springer.com/article/10.1186/s12859-019-3075-z
	  Citations: 55
2025-11-12 22:18:18,280 - WARNING - root - 【手动下载提示】(非ArXiv链接): Physics inspired hybrid attention for SAR target recognition
	  URL: https://www.sciencedirect.com/science/article/pii/S0924271623003374
	  Citations: 53
2025-11-12 22:18:18,281 - WARNING - root - 【手动下载提示】(非ArXiv链接): Look, investigate, and classify: a deep hybrid attention method for breast cancer classification
	  URL: https://ieeexplore.ieee.org/abstract/document/8759454/
	  Citations: 52
2025-11-12 22:18:18,282 - WARNING - root - 【手动下载提示】(非ArXiv链接): Differential attention net: Multi-directed differential attention based hybrid deep learning model for solar power forecasting
	  URL: https://www.sciencedirect.com/science/article/pii/S0360544222026329
	  Citations: 52
2025-11-12 22:18:18,284 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\hybrid attention\HAR-Net_ Joint learning of hybrid attention for single-stage object detection.pdf
2025-11-12 22:18:18,284 - INFO - root - 成功下载 (Scholar-ArXiv): HAR-Net: Joint learning of hybrid attention for single-stage object detection
2025-11-12 22:18:18,285 - WARNING - root - 【手动下载提示】(非ArXiv链接): Ash determination of coal flotation concentrate by analyzing froth image using a novel hybrid model based on deep learning algorithms and attention mechanism
	  URL: https://www.sciencedirect.com/science/article/pii/S0360544222019247
	  Citations: 50
2025-11-12 22:18:18,286 - WARNING - root - 【手动下载提示】(非ArXiv链接): Fake news detection and classification using hybrid BiLSTM and self-attention model
	  URL: https://link.springer.com/article/10.1007/s11042-022-12764-9
	  Citations: 49
2025-11-12 22:18:18,286 - WARNING - root - 【手动下载提示】(非ArXiv链接): Defect detection method of aluminum profile surface using deep self-attention mechanism under hybrid noise conditions
	  URL: https://ieeexplore.ieee.org/abstract/document/9527218/
	  Citations: 47
2025-11-12 22:18:18,287 - WARNING - root - 【手动下载提示】(非ArXiv链接): AFFU-Net: Attention feature fusion U-Net with hybrid loss for winter jujube crack detection
	  URL: https://www.sciencedirect.com/science/article/pii/S0168169922003660
	  Citations: 47
2025-11-12 22:18:18,287 - WARNING - root - 【手动下载提示】(非ArXiv链接): Hybrid-attention guided network with multiple resolution features for person re-identification
	  URL: https://www.sciencedirect.com/science/article/pii/S0020025521007489
	  Citations: 43
2025-11-12 22:18:18,289 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\hybrid attention\SETransformer_ A hybrid attention-based architecture for robust human activity recognition.pdf
2025-11-12 22:18:18,291 - INFO - root - 成功下载 (Scholar-ArXiv): SETransformer: A hybrid attention-based architecture for robust human activity recognition
2025-11-12 22:18:18,291 - WARNING - root - 【手动下载提示】(非ArXiv链接): Self-attention based deep direct recurrent reinforcement learning with hybrid loss for trading signal generation
	  URL: https://www.sciencedirect.com/science/article/pii/S0020025522015377
	  Citations: 25
2025-11-12 22:18:18,292 - WARNING - root - 【手动下载提示】(非ArXiv链接): Hybrid neural attention for agreement/disagreement inference in online debates
	  URL: https://aclanthology.org/D18-1069/
	  Citations: 20
2025-11-12 22:18:18,292 - WARNING - root - 【手动下载提示】(非ArXiv链接): An attention-based hybrid deep learning approach for Bengali video captioning
	  URL: https://www.sciencedirect.com/science/article/pii/S1319157822004128
	  Citations: 19
2025-11-12 22:18:18,293 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\hybrid attention\Hybrid self-attention network for machine translation.pdf
2025-11-12 22:18:18,294 - INFO - root - 成功下载 (Scholar-ArXiv): Hybrid self-attention network for machine translation
2025-11-12 22:18:18,296 - WARNING - root - 【手动下载提示】(非ArXiv链接): RockSeg: A novel semantic segmentation network based on a hybrid framework combining a convolutional neural network and transformer for deep space …
	  URL: https://www.mdpi.com/2072-4292/15/16/3935
	  Citations: 12
2025-11-12 22:18:18,301 - WARNING - root - 【手动下载提示】(非ArXiv链接): Hybrid network using dynamic graph convolution and temporal self-attention for EEG-based emotion recognition
	  URL: https://ui.adsabs.harvard.edu/abs/2024ITNNL..3518565C/abstract
	  Citations: 9
2025-11-12 22:18:18,302 - WARNING - root - 【手动下载提示】(非ArXiv链接): DM-GAN: CNN hybrid vits for training GANs under limited data
	  URL: https://www.sciencedirect.com/science/article/pii/S0031320324005612
	  Citations: 9
2025-11-12 22:18:18,302 - WARNING - root - 【手动下载提示】(非ArXiv链接): A hybrid snn-ann network for event-based object detection with spatial and temporal attention
	  URL: https://juser.fz-juelich.de/record/1038039/files/A%20Hybrid%20SNN-ANN%20Network%20for%20Event-based%20Object%20Detection%20with%20Spatial%20and%20Temporal%20Attention.pdf
	  Citations: 9
2025-11-12 22:18:18,303 - WARNING - root - 【手动下载提示】(非ArXiv链接): A hybrid Transformer architecture with a quantized self-attention mechanism applied to molecular generation
	  URL: https://pubs.acs.org/doi/abs/10.1021/acs.jctc.5c00331
	  Citations: 7
2025-11-12 22:18:18,306 - WARNING - root - 【手动下载提示】(非ArXiv链接): … ClassificatiCobiat: a sentiment classification model using hybrid convnet-dual-lstm with attention mechanismon model using hybrid ConvNet-dual-LSTM with attention …
	  URL: https://www.informatica.si/index.php/informatica/article/view/3911
	  Citations: 6
2025-11-12 22:18:18,307 - WARNING - root - 【手动下载提示】(非ArXiv链接): A hybrid short-term load forecasting model based on sparse attention mechanism
	  URL: https://ieeexplore.ieee.org/abstract/document/9233285/
	  Citations: 5
2025-11-12 22:18:18,308 - WARNING - root - 【手动下载提示】(非ArXiv链接): … DETECTION SYSTEM FOR INTERNET OF MEDICAL THINGS USING GRU WITH ATTENTION MECHANISM-BASED HYBRID DEEP LEARNING TECHNIQUE.
	  URL: https://search.ebscohost.com/login.aspx?direct=true&profile=ehost&scope=site&authtype=crawler&jrnl=24139351&AN=187049171&h=elTpIib7fKUdIk9WLkEBDQb%2BzWpDGhT%2FC5Tr%2B0NyO24e5C4h0J71wecUPqACDFAqCUj66C8AxdLIysLO635A3Q%3D%3D&crl=c
	  Citations: 5
2025-11-12 22:18:18,311 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\hybrid attention\A systematic analysis of hybrid linear attention.pdf
2025-11-12 22:18:18,313 - INFO - root - 成功下载 (Scholar-ArXiv): A systematic analysis of hybrid linear attention
2025-11-12 22:18:18,318 - WARNING - root - 【手动下载提示】(非ArXiv链接): Attention-based eda tool parameter explorer: From hybrid parameters to multi-qor metrics
	  URL: https://ieeexplore.ieee.org/abstract/document/11084888/
	  Citations: 4
2025-11-12 22:18:18,320 - WARNING - root - 【手动下载提示】(非ArXiv链接): A hybrid and regenerative model chat robot based on LSTM and attention model
	  URL: https://www.spiedigitallibrary.org/conference-proceedings-of-spie/11884/118840H/A-hybrid-and-regenerative-model-chat-robot-based-on-LSTM/10.1117/12.2603769.short
	  Citations: 4
2025-11-12 22:18:18,323 - WARNING - root - 【手动下载提示】(非ArXiv链接): Image caption based on bigru and attention hybrid model
	  URL: https://dl.acm.org/doi/abs/10.1145/3488933.3488978
	  Citations: 3
2025-11-12 22:18:18,337 - INFO - root - 检索到 8 篇论文，开始总结...
2025-11-12 22:18:18,339 - INFO - root - 正在总结论文 1/8: Prompt-to-prompt image editing with cross attention control
2025-11-12 22:22:59,345 - INFO - root - 正在提取论文图片到目录: ./export\hybrid attention\images
2025-11-12 22:23:07,008 - INFO - root - 已保存图片 1/10：./export\hybrid attention\images\figure_1_page8.jpeg
2025-11-12 22:23:07,109 - INFO - root - 已保存图片 2/10：./export\hybrid attention\images\figure_2_page8.jpeg
2025-11-12 22:23:07,218 - INFO - root - 已保存图片 3/10：./export\hybrid attention\images\figure_3_page8.jpeg
2025-11-12 22:23:07,329 - INFO - root - 已保存图片 4/10：./export\hybrid attention\images\figure_4_page8.jpeg
2025-11-12 22:23:07,379 - INFO - root - 已保存图片 5/10：./export\hybrid attention\images\figure_5_page18.jpeg
2025-11-12 22:23:07,428 - INFO - root - 已保存图片 6/10：./export\hybrid attention\images\figure_6_page18.jpeg
2025-11-12 22:23:07,478 - INFO - root - 已保存图片 7/10：./export\hybrid attention\images\figure_7_page18.jpeg
2025-11-12 22:23:07,528 - INFO - root - 已保存图片 8/10：./export\hybrid attention\images\figure_8_page18.jpeg
2025-11-12 22:23:07,580 - INFO - root - 已保存图片 9/10：./export\hybrid attention\images\figure_9_page18.jpeg
2025-11-12 22:23:07,631 - INFO - root - 已保存图片 10/10：./export\hybrid attention\images\figure_10_page18.jpeg
2025-11-12 22:23:07,644 - INFO - root - 成功添加图片 1：./export\hybrid attention\images\figure_1_page8.jpeg
2025-11-12 22:23:07,645 - INFO - root - 成功添加图片 2：./export\hybrid attention\images\figure_2_page8.jpeg
2025-11-12 22:23:07,646 - INFO - root - 成功添加图片 3：./export\hybrid attention\images\figure_3_page8.jpeg
2025-11-12 22:23:07,646 - INFO - root - 成功添加图片 4：./export\hybrid attention\images\figure_4_page8.jpeg
2025-11-12 22:23:07,648 - INFO - root - 成功添加图片 5：./export\hybrid attention\images\figure_5_page18.jpeg
2025-11-12 22:23:07,648 - INFO - root - 成功添加图片 6：./export\hybrid attention\images\figure_6_page18.jpeg
2025-11-12 22:23:07,649 - INFO - root - 成功添加图片 7：./export\hybrid attention\images\figure_7_page18.jpeg
2025-11-12 22:23:07,649 - INFO - root - 成功添加图片 8：./export\hybrid attention\images\figure_8_page18.jpeg
2025-11-12 22:23:07,650 - INFO - root - 成功添加图片 9：./export\hybrid attention\images\figure_9_page18.jpeg
2025-11-12 22:23:07,650 - INFO - root - 成功添加图片 10：./export\hybrid attention\images\figure_10_page18.jpeg
2025-11-12 22:23:07,654 - INFO - root - 已更新图片链接
2025-11-12 22:23:07,660 - INFO - root - 论文《Prompt-to-prompt image editing with cross attention control》的分析已保存到 ./export\hybrid attention\Prompt-to-prompt image editing with cross attention control.md
2025-11-12 22:23:07,665 - INFO - root - 正在总结论文 2/8: Polarized self-attention: Towards high-quality pixel-wise regression
2025-11-12 22:26:53,364 - INFO - root - 正在提取论文图片到目录: ./export\hybrid attention\images
2025-11-12 22:26:53,972 - INFO - root - 已保存图片 1/10：./export\hybrid attention\images\figure_1_page8.png
2025-11-12 22:26:54,108 - INFO - root - 已保存图片 2/10：./export\hybrid attention\images\figure_2_page8.png
2025-11-12 22:26:54,189 - INFO - root - 已保存图片 3/10：./export\hybrid attention\images\figure_3_page4.png
2025-11-12 22:26:54,327 - INFO - root - 已保存图片 4/10：./export\hybrid attention\images\figure_4_page1.png
2025-11-12 22:26:54,403 - INFO - root - 已保存图片 5/10：./export\hybrid attention\images\figure_5_page4.png
2025-11-12 22:26:54,407 - INFO - root - 成功添加图片 1：./export\hybrid attention\images\figure_1_page8.png
2025-11-12 22:26:54,407 - INFO - root - 成功添加图片 2：./export\hybrid attention\images\figure_2_page8.png
2025-11-12 22:26:54,408 - INFO - root - 成功添加图片 3：./export\hybrid attention\images\figure_3_page4.png
2025-11-12 22:26:54,409 - INFO - root - 成功添加图片 4：./export\hybrid attention\images\figure_4_page1.png
2025-11-12 22:26:54,411 - INFO - root - 成功添加图片 5：./export\hybrid attention\images\figure_5_page4.png
2025-11-12 22:26:54,413 - INFO - root - 已更新图片链接
2025-11-12 22:26:54,418 - INFO - root - 论文《Polarized self-attention: Towards high-quality pixel-wise regression》的分析已保存到 ./export\hybrid attention\Polarized self-attention_ Towards high-quality pixel-wise regression.md
2025-11-12 22:26:54,421 - INFO - root - 正在总结论文 3/8: Advances in joint CTC-attention based end-to-end speech recognition with a deep CNN encoder and RNN-LM
2025-11-12 22:29:12,478 - INFO - root - 正在提取论文图片到目录: ./export\hybrid attention\images
2025-11-12 22:29:12,534 - INFO - root - 已保存图片 1/10：./export\hybrid attention\images\figure_1_page3.png
2025-11-12 22:29:12,544 - INFO - root - 已保存图片 2/10：./export\hybrid attention\images\figure_2_page3.png
2025-11-12 22:29:12,566 - INFO - root - 已保存图片 3/10：./export\hybrid attention\images\figure_3_page3.png
2025-11-12 22:29:12,595 - INFO - root - 已保存图片 4/10：./export\hybrid attention\images\figure_4_page3.png
2025-11-12 22:29:12,627 - INFO - root - 已保存图片 5/10：./export\hybrid attention\images\figure_5_page3.png
2025-11-12 22:29:12,644 - INFO - root - 已保存图片 6/10：./export\hybrid attention\images\figure_6_page3.png
2025-11-12 22:29:12,650 - INFO - root - 成功添加图片 1：./export\hybrid attention\images\figure_1_page3.png
2025-11-12 22:29:12,650 - INFO - root - 成功添加图片 2：./export\hybrid attention\images\figure_2_page3.png
2025-11-12 22:29:12,652 - INFO - root - 成功添加图片 3：./export\hybrid attention\images\figure_3_page3.png
2025-11-12 22:29:12,652 - INFO - root - 成功添加图片 4：./export\hybrid attention\images\figure_4_page3.png
2025-11-12 22:29:12,653 - INFO - root - 成功添加图片 5：./export\hybrid attention\images\figure_5_page3.png
2025-11-12 22:29:12,653 - INFO - root - 成功添加图片 6：./export\hybrid attention\images\figure_6_page3.png
2025-11-12 22:29:12,654 - INFO - root - 已更新图片链接
2025-11-12 22:29:12,657 - INFO - root - 论文《Advances in joint CTC-attention based end-to-end speech recognition with a deep CNN encoder and RNN-LM》的分析已保存到 ./export\hybrid attention\Advances in joint CTC-attention based end-to-end speech recognition with a deep CNN encoder and RNN-.md
2025-11-12 22:29:12,661 - INFO - root - 跳过已处理论文 Hat: Hybrid attention transformer for image restoration：D:\ChatPaper\api_downloads\hybrid attention\Hat_ Hybrid attention transformer for image restoration.pdf
2025-11-12 22:29:12,661 - INFO - root - 跳过已处理论文 HAR-Net: Joint learning of hybrid attention for single-stage object detection：D:\ChatPaper\api_downloads\hybrid attention\HAR-Net_ Joint learning of hybrid attention for single-stage object detection.pdf
2025-11-12 22:29:12,664 - INFO - root - 跳过已处理论文 SETransformer: A hybrid attention-based architecture for robust human activity recognition：D:\ChatPaper\api_downloads\hybrid attention\SETransformer_ A hybrid attention-based architecture for robust human activity recognition.pdf
2025-11-12 22:29:12,665 - INFO - root - 跳过已处理论文 Hybrid self-attention network for machine translation：D:\ChatPaper\api_downloads\hybrid attention\Hybrid self-attention network for machine translation.pdf
2025-11-12 22:29:12,665 - INFO - root - 跳过已处理论文 A systematic analysis of hybrid linear attention：D:\ChatPaper\api_downloads\hybrid attention\A systematic analysis of hybrid linear attention.pdf
2025-11-12 22:29:12,971 - INFO - root - 已生成汇总Excel表格: export\hybrid attention\论文汇总_hybrid attention_20251112_222912.xlsx
2025-11-12 22:29:12,972 - INFO - root - 已生成汇总Excel表格: export\hybrid attention\论文汇总_hybrid attention_20251112_222912.xlsx
2025-11-12 22:29:12,972 - INFO - root - 总运行时间: 762.97 seconds
2025-11-12 22:32:51,039 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-12 22:32:51,041 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-12 22:32:51,043 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-12 22:32:54,484 - INFO - root - LLMClientManager: 指定使用客户端: Deepseek
2025-11-12 22:32:54,484 - INFO - root - DeepSeekClient: API key found: 9f9e270e-b...
2025-11-12 22:32:54,484 - INFO - root - DeepSeekClient: 使用模式: 火山引擎
2025-11-12 22:32:54,484 - INFO - root - DeepSeekClient: 模型名称: deepseek-v3-1-terminus
2025-11-12 22:32:57,955 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 22:32:57,963 - INFO - root - DeepSeekClient: initialized successfully with model deepseek-v3-1-terminus
2025-11-12 22:32:57,963 - INFO - root - LLMClientManager: DeepSeek 客户端初始化成功
2025-11-12 22:32:57,964 - INFO - root - LLMClientManager: switched to DeepSeek client (case-insensitive match)
2025-11-12 22:32:57,965 - INFO - root - 已手动切换到 LLM 客户端: Deepseek
2025-11-12 22:32:57,965 - INFO - root - 使用 LLM 模型: deepseek-v3-1-terminus
2025-11-12 22:32:57,966 - INFO - root - 可用客户端: ['DeepSeek']
2025-11-12 22:32:57,966 - INFO - root - === 运行配置 ===
2025-11-12 22:32:57,966 - INFO - root - 处理模式: Semantic Scholar 高引用搜索 (API)
2025-11-12 22:32:57,967 - INFO - root - 查询 (关键词): hybrid attention
2025-11-12 22:32:57,967 - INFO - root - 关键词 (用于保存): hybrid attention
2025-11-12 22:32:57,967 - INFO - root - 排序: citationCount:desc
2025-11-12 22:32:57,967 - INFO - root - 最大处理数量: 50
2025-11-12 22:32:57,968 - INFO - root - 保存图片: 是
2025-11-12 22:32:57,968 - INFO - root - 输出语言: 中文
2025-11-12 22:32:57,968 - INFO - root - 强制重新处理: 否
2025-11-12 22:32:57,969 - INFO - root - LLM 客户端: Deepseek
2025-11-12 22:32:57,972 - INFO - root - ====================
2025-11-12 22:32:57,973 - INFO - root - 正在使用检索策略: semantic
2025-11-12 22:32:57,973 - INFO - root - 使用 Semantic Scholar 高引用搜索模式 (API)
2025-11-12 22:32:57,974 - INFO - root - Semantic API 查询: query=hybrid attention, limit=50, sort=citationCount:desc
2025-11-12 22:32:57,974 - INFO - root - 正在调用 Semantic Scholar API...
2025-11-12 22:33:02,827 - INFO - root - 正在调用 Semantic Scholar API...
2025-11-12 22:33:07,650 - INFO - root - 正在调用 Semantic Scholar API...
2025-11-12 22:33:11,310 - WARNING - root - 【手动下载提示】(无PDF): An Instrument Indication Acquisition Algorithm Based on Lightweight Deep Convolutional Neural Network and Hybrid Attention Fine-Grained Features
	  URL: https://www.semanticscholar.org/paper/49f99d7a21e2ded7915676753a180983763b9a22
	  Citations: 66 | Authors: Jiaquan Shen, Ningzhong Liu, Han Sun, Deguang Li, Yongxin Zhang | Date: N/A
2025-11-12 22:33:11,310 - WARNING - root - 【手动下载提示】(无PDF): Enhancing ASD classification through hybrid attention-based learning of facial features
	  URL: https://www.semanticscholar.org/paper/22547aa4c72c7c2799932a0f451ab3f2db6d7d0f
	  Citations: 35 | Authors: Inzamam Shahzad, Saif Ur Rehman Khan, Waseem Abbas, Z. U. Abideen, Jin Liu | Date: 2024-04-21
2025-11-12 22:33:11,310 - WARNING - root - 【手动下载提示】(无PDF): Dual-Hybrid Attention Network for Specular Highlight Removal
	  URL: https://www.semanticscholar.org/paper/d56ce689cc0f8b1cf0e5f58882503a5e59ec440b
	  Citations: 33 | Authors: Xiaojiao Guo, Xuhang Chen, Shenghong Luo, Shuqiang Wang, Chi-Man Pun | Date: 2024-07-17
2025-11-12 22:33:11,314 - WARNING - root - 【手动下载提示】(无PDF): HyA-GAN: remote sensing image cloud removal based on hybrid attention generation adversarial network
	  URL: https://www.semanticscholar.org/paper/905b42f2f8d912d98fd7cbec4f7b244401176acc
	  Citations: 16 | Authors: Minghao Jin, Pengwei Wang, Yusong Li | Date: 2024-02-27
2025-11-12 22:33:11,315 - WARNING - root - 【手动下载提示】(无PDF): Hybrid Attention-Aware Transformer Network Collaborative Multiscale Feature Alignment for Building Change Detection
	  URL: https://www.semanticscholar.org/paper/a0f8053046622628073ac6f051b5181a80cb7ad3
	  Citations: 28 | Authors: Chuan Xu, Zhaoyi Ye, Liye Mei, Haonan Yu, Jianchen Liu, Yaxiaer Yalikun, Shuangtong Jin, Sheng Liu, Wei Yang, Cheng Lei | Date: N/A
2025-11-12 22:33:11,315 - WARNING - root - 【手动下载提示】(无PDF): Radar Signal Recognition Based on CNN With a Hybrid Attention Mechanism and Skip Feature Aggregation
	  URL: https://www.semanticscholar.org/paper/dacad703c49e9434321c91220219638f871fd9d2
	  Citations: 25 | Authors: Yuanpu Guo, Haixin Sun, Hui Liu, Zhen-miao Deng | Date: N/A
2025-11-12 22:33:11,317 - WARNING - root - 【手动下载提示】(无PDF): Probabilistic Multienergy Load Forecasting Based on Hybrid Attention-Enabled Transformer Network and Gaussian Process-Aided Residual Learning
	  URL: https://www.semanticscholar.org/paper/a2d81cc04f73e2898fb16e7e8c8f9cf69adadfd5
	  Citations: 16 | Authors: Pengfei Zhao, Weihao Hu, Di Cao, Zhenyuan Zhang, Yuehui Huang, Longcheng Dai, Zhe Chen | Date: 2024-06-01
2025-11-12 22:33:11,322 - INFO - root - 正在下载: https://ieeexplore.ieee.org/ielx7/4609443/4609444/10416333.pdf
2025-11-12 22:33:16,240 - INFO - root - 正在下载: https://ieeexplore.ieee.org/ielx7/4609443/4609444/10416333.pdf
2025-11-12 22:33:21,138 - INFO - root - 正在下载: https://ieeexplore.ieee.org/ielx7/4609443/4609444/10416333.pdf
2025-11-12 22:33:26,135 - INFO - root - 正在下载: https://ieeexplore.ieee.org/ielx7/4609443/4609444/10416333.pdf
2025-11-12 22:33:35,228 - INFO - root - 正在下载: https://ieeexplore.ieee.org/ielx7/4609443/4609444/10416333.pdf
2025-11-12 22:33:36,550 - WARNING - root - 下载 Hybrid Attention Fusion Embedded in Transformer for Remote Sensing Image Semantic Segmentation (https://ieeexplore.ieee.org/ielx7/4609443/4609444/10416333.pdf) 失败: 418 Client Error: Unknown Code for url: https://ieeexplore.ieee.org/ielx7/4609443/4609444/10416333.pdf
2025-11-12 22:33:36,550 - WARNING - root - 【手动下载提示】(无PDF): Enhancing Time Series Product Demand Forecasting With Hybrid Attention-Based Deep Learning Models
	  URL: https://www.semanticscholar.org/paper/4848b35cbe515f8909a67a82dcb83d7c5e48f74b
	  Citations: 14 | Authors: Xuguang Zhang, Pan Li, Xu Han, Yongbin Yang, Yiwen Cui | Date: N/A
2025-11-12 22:33:36,554 - INFO - root - 正在下载: https://www.mdpi.com/2306-5354/11/3/240/pdf?version=1709132347
2025-11-12 22:33:41,366 - INFO - root - 正在下载: https://www.mdpi.com/2306-5354/11/3/240/pdf?version=1709132347
2025-11-12 22:33:46,069 - INFO - root - 正在下载: https://www.mdpi.com/2306-5354/11/3/240/pdf?version=1709132347
2025-11-12 22:33:51,910 - INFO - root - 正在下载: https://www.mdpi.com/2306-5354/11/3/240/pdf?version=1709132347
2025-11-12 22:34:02,948 - INFO - root - 正在下载: https://www.mdpi.com/2306-5354/11/3/240/pdf?version=1709132347
2025-11-12 22:34:03,663 - WARNING - root - 下载 Advancing Ocular Imaging: A Hybrid Attention Mechanism-Based U-Net Model for Precise Segmentation of Sub-Retinal Layers in OCT Images (https://www.mdpi.com/2306-5354/11/3/240/pdf?version=1709132347) 失败: 403 Client Error: Forbidden for url: https://www.mdpi.com/2306-5354/11/3/240/pdf?version=1709132347
2025-11-12 22:34:03,663 - WARNING - root - 【手动下载提示】(无PDF): A novel approach for bearings multiclass fault diagnosis fusing multiscale deep convolution and hybrid attention networks
	  URL: https://www.semanticscholar.org/paper/bf72523fe518b2e4ce4d75d125dd5220177043f6
	  Citations: 13 | Authors: Fule Li, Xinlong Zhao | Date: 2024-01-08
2025-11-12 22:34:03,664 - INFO - root - 正在下载: https://arxiv.org/pdf/2401.01214
2025-11-12 22:34:05,741 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\hybrid attention\YOLO Algorithm With Hybrid Attention Feature Pyramid Network for Solder Joint Defect Detection.pdf
2025-11-12 22:34:05,746 - INFO - root - 成功下载 (Semantic Scholar): YOLO Algorithm With Hybrid Attention Feature Pyramid Network for Solder Joint Defect Detection
2025-11-12 22:34:05,746 - WARNING - root - 【手动下载提示】(无PDF): Drone-HAT: Hybrid Attention Transformer for Complex Action Recognition in Drone Surveillance Videos
	  URL: https://www.semanticscholar.org/paper/a76690fb96dc7d3dfd5f8fec62c3949cc7ec96f6
	  Citations: 12 | Authors: Mustaqeem Khan, Jamil Ahmad, Abdulmotaleb El-Saddik, W. Gueaieb, Giulia De Masi, Fakhri Karray | Date: 2024-06-17
2025-11-12 22:34:05,747 - WARNING - root - 【手动下载提示】(无PDF): Dense Hybrid Attention Network for Palmprint Image Super-Resolution
	  URL: https://www.semanticscholar.org/paper/75746d8d52509b24d9975d9b3b07ae91311dc7ed
	  Citations: 12 | Authors: Yao Wang, Lunke Fei, Shuping Zhao, Qi Zhu, Jie Wen, Wei Jia, Imad Rida | Date: 2024-04-01
2025-11-12 22:34:05,748 - INFO - root - 正在下载: https://arxiv.org/pdf/2304.09184
2025-11-12 22:34:11,883 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\hybrid attention\Frequency Enhanced Hybrid Attention Network for Sequential Recommendation.pdf
2025-11-12 22:34:11,891 - INFO - root - 成功下载 (Semantic Scholar): Frequency Enhanced Hybrid Attention Network for Sequential Recommendation
2025-11-12 22:34:11,891 - WARNING - root - 【手动下载提示】(无PDF): A Multiscale Hybrid Attention Networks Based on Multiview Images for the Diagnosis of Parkinson’s Disease
	  URL: https://www.semanticscholar.org/paper/b2af0577ee8ac56b527bd108ce57755a4a4b04e7
	  Citations: 11 | Authors: Xinchun Cui, Youshi Zhou, Chao Zhao, Jianlong Li, Xiangwei Zheng, Xiuli Li, Shixiao Shan, JinXing Liu, Xiaoli Liu | Date: N/A
2025-11-12 22:34:11,891 - WARNING - root - 【手动下载提示】(无PDF): Hybrid Attention Feature Refinement Network for Lightweight Image Super-Resolution in Metaverse Immersive Display
	  URL: https://www.semanticscholar.org/paper/c4d95a47eec1a23320d60dd95848d41e10820ee4
	  Citations: 10 | Authors: Kexin Wang, Xiaomin Yang, Gwanggil Jeon | Date: 2024-02-01
2025-11-12 22:34:11,893 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\hybrid attention\HAT_ Hybrid Attention Transformer for Image Restoration.pdf
2025-11-12 22:34:11,893 - INFO - root - 成功下载 (Semantic Scholar): HAT: Hybrid Attention Transformer for Image Restoration
2025-11-12 22:34:11,894 - INFO - root - 正在下载: https://www.mdpi.com/2076-3417/14/3/1293/pdf?version=1707037901
2025-11-12 22:34:16,607 - INFO - root - 正在下载: https://www.mdpi.com/2076-3417/14/3/1293/pdf?version=1707037901
2025-11-12 22:34:21,279 - INFO - root - 正在下载: https://www.mdpi.com/2076-3417/14/3/1293/pdf?version=1707037901
2025-11-12 22:34:26,058 - INFO - root - 正在下载: https://www.mdpi.com/2076-3417/14/3/1293/pdf?version=1707037901
2025-11-12 22:34:34,706 - INFO - root - 正在下载: https://www.mdpi.com/2076-3417/14/3/1293/pdf?version=1707037901
2025-11-12 22:34:36,394 - WARNING - root - 下载 Dual Hybrid Attention Mechanism-Based U-Net for Building Segmentation in Remote Sensing Images (https://www.mdpi.com/2076-3417/14/3/1293/pdf?version=1707037901) 失败: 403 Client Error: Forbidden for url: https://www.mdpi.com/2076-3417/14/3/1293/pdf?version=1707037901
2025-11-12 22:34:36,394 - WARNING - root - 【手动下载提示】(无PDF): Abundance Matrix Correlation Analysis Network Based on Hierarchical Multihead Self-Cross-Hybrid Attention for Hyperspectral Change Detection
	  URL: https://www.semanticscholar.org/paper/6aae02a41656cecba872b29bb3d71c414a58f57b
	  Citations: 66 | Authors: Wenqian Dong, Jing Zhao, Jiahui Qu, Song Xiao, Nan Li, Shaoxiong Hou, Yunsong Li | Date: N/A
2025-11-12 22:34:36,395 - WARNING - root - 【手动下载提示】(无PDF): Hybrid Attention Module and Transformer Based Fuze DRFM Jamming Signal Recognition
	  URL: https://www.semanticscholar.org/paper/0fb8059c6aaf0c86c9e9a623fa1ad73d0f737c37
	  Citations: 7 | Authors: Jikai Yang, Zhiquan Bai, Zhaoxia Xian, Hongwu Xiang, Jingxin Li, Huili Hu, Jian Dai, Xinhong Hao | Date: 2024-09-01
2025-11-12 22:34:36,396 - WARNING - root - 【手动下载提示】(无PDF): HA-Net: a SAR image ship detector based on hybrid attention
	  URL: https://www.semanticscholar.org/paper/4c40b6f75ab19e1402ae88e38013a64c504c3a80
	  Citations: 6 | Authors: Shouwen Cai, Hao Meng, Ming Yuan, Fei Gao | Date: 2024-06-10
2025-11-12 22:34:36,396 - WARNING - root - 【手动下载提示】(无PDF): Deep Hashing Network With Hybrid Attention and Adaptive Weighting for Image Retrieval
	  URL: https://www.semanticscholar.org/paper/1c688a4da1c546ea783f5743c371732ace568498
	  Citations: 7 | Authors: Yingjiao Pei, Zhongyuan Wang, Na Li, Heling Chen, Baojin Huang, Weiping Tu | Date: N/A
2025-11-12 22:34:36,398 - WARNING - root - 【手动下载提示】(无PDF): Towards Effective Author Name Disambiguation by Hybrid Attention
	  URL: https://www.semanticscholar.org/paper/fc2dcb9e544a0aaad3034a61eaf0563a79c65cbf
	  Citations: 6 | Authors: Qian Zhou, Wei Chen, Peng-Peng Zhao, An Liu, Jia-Jie Xu, Jian-Feng Qu, Lei Zhao | Date: 2024-07-01
2025-11-12 22:34:36,399 - WARNING - root - 【手动下载提示】(无PDF): Actor-Hybrid-Attention-Critic for Multi-Logistic Robots Path Planning
	  URL: https://www.semanticscholar.org/paper/5260da08f9f524b8fa77a37e2884b22804a47c6a
	  Citations: 6 | Authors: Chunjie Yang, Bodi Yuan, Pengzhao Zhai | Date: 2024-06-01
2025-11-12 22:34:36,402 - INFO - root - 正在下载: https://www.researchsquare.com/article/rs-2802750/latest.pdf
2025-11-12 22:34:53,171 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\hybrid attention\Multi-scale deep residual shrinkage networks with a hybrid attention mechanism for rolling bearing f.pdf
2025-11-12 22:34:53,173 - INFO - root - 成功下载 (Semantic Scholar): Multi-scale deep residual shrinkage networks with a hybrid attention mechanism for rolling bearing fault diagnosis
2025-11-12 22:34:53,173 - INFO - root - 正在下载: https://www.mdpi.com/2306-5354/10/6/714/pdf?version=1686635187
2025-11-12 22:34:58,275 - INFO - root - 正在下载: https://www.mdpi.com/2306-5354/10/6/714/pdf?version=1686635187
2025-11-12 22:35:02,895 - INFO - root - 正在下载: https://www.mdpi.com/2306-5354/10/6/714/pdf?version=1686635187
2025-11-12 22:35:07,572 - INFO - root - 正在下载: https://www.mdpi.com/2306-5354/10/6/714/pdf?version=1686635187
2025-11-12 22:35:16,544 - INFO - root - 正在下载: https://www.mdpi.com/2306-5354/10/6/714/pdf?version=1686635187
2025-11-12 22:35:18,172 - WARNING - root - 下载 AHANet: Adaptive Hybrid Attention Network for Alzheimer’s Disease Classification Using Brain Magnetic Resonance Imaging (https://www.mdpi.com/2306-5354/10/6/714/pdf?version=1686635187) 失败: 403 Client Error: Forbidden for url: https://www.mdpi.com/2306-5354/10/6/714/pdf?version=1686635187
2025-11-12 22:35:18,175 - INFO - root - 正在下载: https://arxiv.org/pdf/2309.15697
2025-11-12 22:35:24,303 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\hybrid attention\Physics Inspired Hybrid Attention for SAR Target Recognition.pdf
2025-11-12 22:35:24,308 - INFO - root - 成功下载 (Semantic Scholar): Physics Inspired Hybrid Attention for SAR Target Recognition
2025-11-12 22:35:24,308 - WARNING - root - 【手动下载提示】(无PDF): WHEN: A Wavelet-DTW Hybrid Attention Network for Heterogeneous Time Series Analysis
	  URL: https://www.semanticscholar.org/paper/c2e57a1926217f67a72c617d09fa12ec8e667d0e
	  Citations: 33 | Authors: Jingyuan Wang, Chen Yang, Xiaohan Jiang, Junjie Wu | Date: 2023-08-04
2025-11-12 22:35:24,308 - WARNING - root - 【手动下载提示】(无PDF): Hybrid Attention-Aware Learning Network for Facial Expression Recognition in the Wild
	  URL: https://www.semanticscholar.org/paper/a13c5a80a32c0e2dbf589d9fca9daa9b2300165d
	  Citations: 4 | Authors: Weijun Gong, Zhiyao La, Yurong Qian, Weihang Zhou | Date: 2024-01-05
2025-11-12 22:35:24,308 - INFO - root - 正在下载: https://www.frontiersin.org/articles/10.3389/fnbot.2024.1391791/pdf?isPublishedV2=False
2025-11-12 22:35:33,185 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\hybrid attention\Fine-grained image classification method based on hybrid attention module.pdf
2025-11-12 22:35:33,191 - INFO - root - 成功下载 (Semantic Scholar): Fine-grained image classification method based on hybrid attention module
2025-11-12 22:35:33,192 - INFO - root - 正在下载: https://ieeexplore.ieee.org/ielx7/36/10006360/10145829.pdf
2025-11-12 22:35:38,097 - INFO - root - 正在下载: https://ieeexplore.ieee.org/ielx7/36/10006360/10145829.pdf
2025-11-12 22:35:43,158 - INFO - root - 正在下载: https://ieeexplore.ieee.org/ielx7/36/10006360/10145829.pdf
2025-11-12 22:35:48,066 - INFO - root - 正在下载: https://ieeexplore.ieee.org/ielx7/36/10006360/10145829.pdf
2025-11-12 22:35:57,405 - INFO - root - 正在下载: https://ieeexplore.ieee.org/ielx7/36/10006360/10145829.pdf
2025-11-12 22:35:58,530 - WARNING - root - 下载 Hybrid Attention-Based U-Shaped Network for Remote Sensing Image Super-Resolution (https://ieeexplore.ieee.org/ielx7/36/10006360/10145829.pdf) 失败: 418 Client Error: Unknown Code for url: https://ieeexplore.ieee.org/ielx7/36/10006360/10145829.pdf
2025-11-12 22:35:58,530 - INFO - root - 正在下载: https://ieeexplore.ieee.org/ielx7/6287639/6514899/10373836.pdf
2025-11-12 22:36:53,728 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\hybrid attention\Text-Conditioned Outfit Recommendation With Hybrid Attention Layer.pdf
2025-11-12 22:36:53,733 - INFO - root - 成功下载 (Semantic Scholar): Text-Conditioned Outfit Recommendation With Hybrid Attention Layer
2025-11-12 22:36:53,733 - INFO - root - 正在下载: https://www.mdpi.com/2076-3417/13/2/770/pdf?version=1673518878
2025-11-12 22:36:58,431 - INFO - root - 正在下载: https://www.mdpi.com/2076-3417/13/2/770/pdf?version=1673518878
2025-11-12 22:37:03,100 - INFO - root - 正在下载: https://www.mdpi.com/2076-3417/13/2/770/pdf?version=1673518878
2025-11-12 22:37:07,758 - INFO - root - 正在下载: https://www.mdpi.com/2076-3417/13/2/770/pdf?version=1673518878
2025-11-12 22:37:17,070 - INFO - root - 正在下载: https://www.mdpi.com/2076-3417/13/2/770/pdf?version=1673518878
2025-11-12 22:37:17,656 - WARNING - root - 下载 Smart Contract Vulnerability Detection Based on Hybrid Attention Mechanism Model (https://www.mdpi.com/2076-3417/13/2/770/pdf?version=1673518878) 失败: 403 Client Error: Forbidden for url: https://www.mdpi.com/2076-3417/13/2/770/pdf?version=1673518878
2025-11-12 22:37:17,657 - WARNING - root - 【手动下载提示】(无PDF): Mutiscale Hybrid Attention Transformer for Remote Sensing Image Pansharpening
	  URL: https://www.semanticscholar.org/paper/3b8404c8b16dd7abb86aa5f13139fa9a9c5f5ca8
	  Citations: 21 | Authors: Wengang Zhu, Jinjiang Li, Zhi-Yonga An, Zhen Hua | Date: N/A
2025-11-12 22:37:17,658 - WARNING - root - 【手动下载提示】(无PDF): Multimodal emotion recognition based on audio and text by using hybrid attention networks
	  URL: https://www.semanticscholar.org/paper/5a35815f9d5f7ed5697b4638b1158f42837051c1
	  Citations: 42 | Authors: Shiqing Zhang, Yijiao Yang, Ruixin Liu, Chen Chen, Xin Tao, Wenping Guo, Yicheng Xu, Xiaoming Zhao | Date: N/A
2025-11-12 22:37:17,658 - WARNING - root - 【手动下载提示】(无PDF): A Novel Approach for Surface Integrity Monitoring in High-Energy Nanosecond-Pulse Laser Shock Peening: Acoustic Emission and Hybrid-Attention CNN
	  URL: https://www.semanticscholar.org/paper/9608f2b16d1d302f7507505b51a5be96fdf0b542
	  Citations: 19 | Authors: Zhifen Zhang, Rui Qin, Gengze Li, Z. Du, G. Wen, Weifeng He | Date: 2023-03-01
2025-11-12 22:37:17,659 - WARNING - root - 【手动下载提示】(无PDF): Intention-convolution and hybrid-attention network for vehicle trajectory prediction
	  URL: https://www.semanticscholar.org/paper/3bcb4d2994896053a5a8da42d09eb621d3b2b221
	  Citations: 33 | Authors: Chao Li, Zhanwen Liu, Shang Lin, Yang Wang, Xiangmo Zhao | Date: 2023-09-01
2025-11-12 22:37:17,659 - WARNING - root - 【手动下载提示】(无PDF): Hybrid Attention Network for Epileptic EEG Classification
	  URL: https://www.semanticscholar.org/paper/f282fa85469cc789c2f3b62e57e3446a49528afa
	  Citations: 17 | Authors: Yanna Zhao, Jiatong He, Fenglin Zhu, Tiantian Xiao, Yongfeng Zhang, Ziwei Wang, Fangzhou Xu, Yi Niu | Date: 2023-03-31
2025-11-12 22:37:17,663 - INFO - root - 正在下载: https://www.mdpi.com/1424-8220/23/13/6052/pdf?version=1688107163
2025-11-12 22:37:22,706 - INFO - root - 正在下载: https://www.mdpi.com/1424-8220/23/13/6052/pdf?version=1688107163
2025-11-12 22:37:29,213 - INFO - root - 正在下载: https://www.mdpi.com/1424-8220/23/13/6052/pdf?version=1688107163
2025-11-12 22:37:33,870 - INFO - root - 正在下载: https://www.mdpi.com/1424-8220/23/13/6052/pdf?version=1688107163
2025-11-12 22:37:42,489 - INFO - root - 正在下载: https://www.mdpi.com/1424-8220/23/13/6052/pdf?version=1688107163
2025-11-12 22:37:43,127 - WARNING - root - 下载 PHAM-YOLO: A Parallel Hybrid Attention Mechanism Network for Defect Detection of Meter in Substation (https://www.mdpi.com/1424-8220/23/13/6052/pdf?version=1688107163) 失败: 403 Client Error: Forbidden for url: https://www.mdpi.com/1424-8220/23/13/6052/pdf?version=1688107163
2025-11-12 22:37:43,128 - INFO - root - 正在下载: https://www.mdpi.com/1424-8220/23/15/6982/pdf?version=1691312141
2025-11-12 22:37:48,409 - INFO - root - 正在下载: https://www.mdpi.com/1424-8220/23/15/6982/pdf?version=1691312141
2025-11-12 22:37:53,140 - INFO - root - 正在下载: https://www.mdpi.com/1424-8220/23/15/6982/pdf?version=1691312141
2025-11-12 22:37:58,246 - INFO - root - 正在下载: https://www.mdpi.com/1424-8220/23/15/6982/pdf?version=1691312141
2025-11-12 22:38:07,183 - INFO - root - 正在下载: https://www.mdpi.com/1424-8220/23/15/6982/pdf?version=1691312141
2025-11-12 22:38:07,908 - WARNING - root - 下载 Defect Detection in Steel Using a Hybrid Attention Network (https://www.mdpi.com/1424-8220/23/15/6982/pdf?version=1691312141) 失败: 403 Client Error: Forbidden for url: https://www.mdpi.com/1424-8220/23/15/6982/pdf?version=1691312141
2025-11-12 22:38:07,909 - WARNING - root - 【手动下载提示】(无PDF): Hybrid Attention and Motion Constraint for Anomaly Detection in Crowded Scenes
	  URL: https://www.semanticscholar.org/paper/a5e107a1112c88294f44989f6622433fb402fb31
	  Citations: 30 | Authors: Xinfeng Zhang, Jinpeng Fang, Baoqing Yang, Shuhan Chen, Bin Li | Date: 2023-05-01
2025-11-12 22:38:07,909 - INFO - root - 正在下载: https://ojs.aaai.org/index.php/AAAI/article/download/4604/4482
2025-11-12 22:38:31,408 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\hybrid attention\Hybrid Attention-Based Prototypical Networks for Noisy Few-Shot Relation Classification.pdf
2025-11-12 22:38:31,411 - INFO - root - 成功下载 (Semantic Scholar): Hybrid Attention-Based Prototypical Networks for Noisy Few-Shot Relation Classification
2025-11-12 22:38:31,413 - INFO - root - 正在下载: https://www.mdpi.com/2072-4292/15/2/526/pdf?version=1673863751
2025-11-12 22:38:36,234 - INFO - root - 正在下载: https://www.mdpi.com/2072-4292/15/2/526/pdf?version=1673863751
2025-11-12 22:38:40,944 - INFO - root - 正在下载: https://www.mdpi.com/2072-4292/15/2/526/pdf?version=1673863751
2025-11-12 22:38:45,718 - INFO - root - 正在下载: https://www.mdpi.com/2072-4292/15/2/526/pdf?version=1673863751
2025-11-12 22:38:55,986 - INFO - root - 正在下载: https://www.mdpi.com/2072-4292/15/2/526/pdf?version=1673863751
2025-11-12 22:38:57,502 - WARNING - root - 下载 Hybrid Attention-Based Encoder-Decoder Fully Convolutional Network for PolSAR Image Classification (https://www.mdpi.com/2072-4292/15/2/526/pdf?version=1673863751) 失败: 403 Client Error: Forbidden for url: https://www.mdpi.com/2072-4292/15/2/526/pdf?version=1673863751
2025-11-12 22:38:57,502 - WARNING - root - 【手动下载提示】(无PDF): Hybrid Attention Compression Network With Light Graph Attention Module for Remote Sensing Images
	  URL: https://www.semanticscholar.org/paper/11ab89aa34dae52624533795ebbe1ce707a66fd4
	  Citations: 9 | Authors: Tianpeng Pan, Lili Zhang, Yingchao Song, Yuxuan Liu | Date: N/A
2025-11-12 22:38:57,502 - WARNING - root - 【手动下载提示】(无PDF): An Adaptive Hybrid Attention Based Convolutional Neural Net for Intelligent Transportation Object Recognition
	  URL: https://www.semanticscholar.org/paper/269fed3c9a541a4073cde6e205878c2618b2f973
	  Citations: 11 | Authors: Qili Chen, Guangyuan Pan, Lin Zhao, Junfang Fan, Wenbai Chen, A. Zhang | Date: 2023-07-01
2025-11-12 22:38:57,502 - WARNING - root - 【手动下载提示】(无PDF): HEU-Net: hybrid attention residual block-based network with external skip connections for metal corrosion semantic segmentation
	  URL: https://www.semanticscholar.org/paper/80e0948897bc53edf4eba2e31e443010d8a2e19a
	  Citations: 9 | Authors: Tianchen Zhu, Shiqiang Zhu, Tao Zheng, Hongliang Ding, Wei Song, Cunjun Li | Date: 2023-06-22
2025-11-12 22:38:57,502 - WARNING - root - 【手动下载提示】(无PDF): Face-Periocular Cross-Identification via Contrastive Hybrid Attention Vision Transformer
	  URL: https://www.semanticscholar.org/paper/5765cc795e642e1a8e834d6af93cda3ac65a753a
	  Citations: 6 | Authors: Leslie Ching Ow Tiong, D. Sigmund, A. Teoh | Date: N/A
2025-11-12 22:38:57,505 - INFO - root - 正在下载: http://arxiv.org/pdf/2306.10676
2025-11-12 22:39:03,062 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\hybrid attention\Dual-view Correlation Hybrid Attention Network for Robust Holistic Mammogram Classification.pdf
2025-11-12 22:39:03,069 - INFO - root - 成功下载 (Semantic Scholar): Dual-view Correlation Hybrid Attention Network for Robust Holistic Mammogram Classification
2025-11-12 22:39:03,072 - WARNING - root - 【手动下载提示】(无PDF): Multi-level wavelet network based on CNN-Transformer hybrid attention for single image deraining
	  URL: https://www.semanticscholar.org/paper/97c485dbb41b68c193decdec5a4618ce3f5b4ee2
	  Citations: 8 | Authors: B. Liu, Siyan Fang | Date: 2023-08-09
2025-11-12 22:39:03,074 - INFO - root - 检索到 9 篇论文，开始总结...
2025-11-12 22:39:03,074 - INFO - root - 正在总结论文 1/9: YOLO Algorithm With Hybrid Attention Feature Pyramid Network for Solder Joint Defect Detection
2025-11-12 22:39:18,305 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 22:40:19,981 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 22:40:53,492 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 22:40:53,493 - INFO - root - 正在提取论文图片到目录: ./export\hybrid attention\images
2025-11-12 22:40:54,147 - INFO - root - 已保存图片 1/10：./export\hybrid attention\images\figure_1_page4.png
2025-11-12 22:40:54,201 - INFO - root - 已保存图片 2/10：./export\hybrid attention\images\figure_2_page11.png
2025-11-12 22:40:54,265 - INFO - root - 已保存图片 3/10：./export\hybrid attention\images\figure_3_page9.png
2025-11-12 22:40:54,324 - INFO - root - 已保存图片 4/10：./export\hybrid attention\images\figure_4_page9.png
2025-11-12 22:40:54,451 - INFO - root - 已保存图片 5/10：./export\hybrid attention\images\figure_5_page10.png
2025-11-12 22:40:54,529 - INFO - root - 已保存图片 6/10：./export\hybrid attention\images\figure_6_page15.png
2025-11-12 22:40:54,595 - INFO - root - 已保存图片 7/10：./export\hybrid attention\images\figure_7_page15.png
2025-11-12 22:40:54,645 - INFO - root - 已保存图片 8/10：./export\hybrid attention\images\figure_8_page8.png
2025-11-12 22:40:54,696 - INFO - root - 已保存图片 9/10：./export\hybrid attention\images\figure_9_page8.png
2025-11-12 22:40:54,801 - INFO - root - 已保存图片 10/10：./export\hybrid attention\images\figure_10_page3.png
2025-11-12 22:40:54,806 - INFO - root - 成功添加图片 1：./export\hybrid attention\images\figure_1_page4.png
2025-11-12 22:40:54,806 - INFO - root - 成功添加图片 2：./export\hybrid attention\images\figure_2_page11.png
2025-11-12 22:40:54,807 - INFO - root - 成功添加图片 3：./export\hybrid attention\images\figure_3_page9.png
2025-11-12 22:40:54,807 - INFO - root - 成功添加图片 4：./export\hybrid attention\images\figure_4_page9.png
2025-11-12 22:40:54,808 - INFO - root - 成功添加图片 5：./export\hybrid attention\images\figure_5_page10.png
2025-11-12 22:40:54,808 - INFO - root - 成功添加图片 6：./export\hybrid attention\images\figure_6_page15.png
2025-11-12 22:40:54,808 - INFO - root - 成功添加图片 7：./export\hybrid attention\images\figure_7_page15.png
2025-11-12 22:40:54,808 - INFO - root - 成功添加图片 8：./export\hybrid attention\images\figure_8_page8.png
2025-11-12 22:40:54,811 - INFO - root - 成功添加图片 9：./export\hybrid attention\images\figure_9_page8.png
2025-11-12 22:40:54,812 - INFO - root - 成功添加图片 10：./export\hybrid attention\images\figure_10_page3.png
2025-11-12 22:40:54,814 - INFO - root - 已更新图片链接
2025-11-12 22:40:54,824 - INFO - root - 论文《YOLO Algorithm With Hybrid Attention Feature Pyramid Network for Solder Joint Defect Detection》的分析已保存到 ./export\hybrid attention\YOLO Algorithm With Hybrid Attention Feature Pyramid Network for Solder Joint Defect Detection.md
2025-11-12 22:40:54,834 - INFO - root - 正在总结论文 2/9: Frequency Enhanced Hybrid Attention Network for Sequential Recommendation
2025-11-12 22:41:02,512 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 22:41:02,514 - INFO - root - LLMClient: rate limit reached, sleeping 17.5s
2025-11-12 22:42:21,402 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 22:43:08,961 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 22:43:08,964 - INFO - root - 正在提取论文图片到目录: ./export\hybrid attention\images
2025-11-12 22:43:09,280 - INFO - root - 已保存图片 1/10：./export\hybrid attention\images\figure_1_page2.png
2025-11-12 22:43:09,345 - INFO - root - 已保存图片 2/10：./export\hybrid attention\images\figure_2_page2.png
2025-11-12 22:43:09,426 - INFO - root - 已保存图片 3/10：./export\hybrid attention\images\figure_3_page2.png
2025-11-12 22:43:09,497 - INFO - root - 已保存图片 4/10：./export\hybrid attention\images\figure_4_page2.png
2025-11-12 22:43:09,557 - INFO - root - 已保存图片 5/10：./export\hybrid attention\images\figure_5_page2.png
2025-11-12 22:43:09,630 - INFO - root - 已保存图片 6/10：./export\hybrid attention\images\figure_6_page2.png
2025-11-12 22:43:09,640 - INFO - root - 已保存图片 7/10：./export\hybrid attention\images\figure_7_page3.png
2025-11-12 22:43:09,669 - INFO - root - 已保存图片 8/10：./export\hybrid attention\images\figure_8_page3.jpeg
2025-11-12 22:43:09,696 - INFO - root - 已保存图片 9/10：./export\hybrid attention\images\figure_9_page3.png
2025-11-12 22:43:09,724 - INFO - root - 已保存图片 10/10：./export\hybrid attention\images\figure_10_page3.png
2025-11-12 22:43:09,725 - INFO - root - 成功添加图片 1：./export\hybrid attention\images\figure_1_page2.png
2025-11-12 22:43:09,725 - INFO - root - 成功添加图片 2：./export\hybrid attention\images\figure_2_page2.png
2025-11-12 22:43:09,726 - INFO - root - 成功添加图片 3：./export\hybrid attention\images\figure_3_page2.png
2025-11-12 22:43:09,726 - INFO - root - 成功添加图片 4：./export\hybrid attention\images\figure_4_page2.png
2025-11-12 22:43:09,727 - INFO - root - 成功添加图片 5：./export\hybrid attention\images\figure_5_page2.png
2025-11-12 22:43:09,730 - INFO - root - 成功添加图片 6：./export\hybrid attention\images\figure_6_page2.png
2025-11-12 22:43:09,731 - INFO - root - 成功添加图片 7：./export\hybrid attention\images\figure_7_page3.png
2025-11-12 22:43:09,734 - INFO - root - 成功添加图片 8：./export\hybrid attention\images\figure_8_page3.jpeg
2025-11-12 22:43:09,734 - INFO - root - 成功添加图片 9：./export\hybrid attention\images\figure_9_page3.png
2025-11-12 22:43:09,734 - INFO - root - 成功添加图片 10：./export\hybrid attention\images\figure_10_page3.png
2025-11-12 22:43:09,736 - INFO - root - 已更新图片链接
2025-11-12 22:43:09,740 - INFO - root - 论文《Frequency Enhanced Hybrid Attention Network for Sequential Recommendation》的分析已保存到 ./export\hybrid attention\Frequency Enhanced Hybrid Attention Network for Sequential Recommendation.md
2025-11-12 22:43:09,746 - INFO - root - 跳过已处理论文 HAT: Hybrid Attention Transformer for Image Restoration：D:\ChatPaper\api_downloads\hybrid attention\HAT_ Hybrid Attention Transformer for Image Restoration.pdf
2025-11-12 22:43:09,747 - INFO - root - 正在总结论文 4/9: Multi-scale deep residual shrinkage networks with a hybrid attention mechanism for rolling bearing fault diagnosis
2025-11-12 22:43:21,976 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 22:44:22,327 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 22:44:52,362 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 22:44:52,364 - INFO - root - 正在提取论文图片到目录: ./export\hybrid attention\images
2025-11-12 22:44:52,449 - INFO - root - 已保存图片 1/10：./export\hybrid attention\images\figure_1_page1.png
2025-11-12 22:44:52,469 - INFO - root - 已保存图片 2/10：./export\hybrid attention\images\figure_2_page15.jpeg
2025-11-12 22:44:52,498 - INFO - root - 已保存图片 3/10：./export\hybrid attention\images\figure_3_page15.png
2025-11-12 22:44:52,525 - INFO - root - 已保存图片 4/10：./export\hybrid attention\images\figure_4_page8.jpeg
2025-11-12 22:44:52,552 - INFO - root - 已保存图片 5/10：./export\hybrid attention\images\figure_5_page8.png
2025-11-12 22:44:52,575 - INFO - root - 已保存图片 6/10：./export\hybrid attention\images\figure_6_page10.jpeg
2025-11-12 22:44:52,602 - INFO - root - 已保存图片 7/10：./export\hybrid attention\images\figure_7_page10.jpeg
2025-11-12 22:44:52,637 - INFO - root - 已保存图片 8/10：./export\hybrid attention\images\figure_8_page19.jpeg
2025-11-12 22:44:52,670 - INFO - root - 已保存图片 9/10：./export\hybrid attention\images\figure_9_page14.jpeg
2025-11-12 22:44:52,694 - INFO - root - 已保存图片 10/10：./export\hybrid attention\images\figure_10_page18.jpeg
2025-11-12 22:44:52,696 - INFO - root - 成功添加图片 1：./export\hybrid attention\images\figure_1_page1.png
2025-11-12 22:44:52,699 - INFO - root - 成功添加图片 2：./export\hybrid attention\images\figure_2_page15.jpeg
2025-11-12 22:44:52,700 - INFO - root - 成功添加图片 3：./export\hybrid attention\images\figure_3_page15.png
2025-11-12 22:44:52,702 - INFO - root - 成功添加图片 4：./export\hybrid attention\images\figure_4_page8.jpeg
2025-11-12 22:44:52,705 - INFO - root - 成功添加图片 5：./export\hybrid attention\images\figure_5_page8.png
2025-11-12 22:44:52,705 - INFO - root - 成功添加图片 6：./export\hybrid attention\images\figure_6_page10.jpeg
2025-11-12 22:44:52,705 - INFO - root - 成功添加图片 7：./export\hybrid attention\images\figure_7_page10.jpeg
2025-11-12 22:44:52,706 - INFO - root - 成功添加图片 8：./export\hybrid attention\images\figure_8_page19.jpeg
2025-11-12 22:44:52,706 - INFO - root - 成功添加图片 9：./export\hybrid attention\images\figure_9_page14.jpeg
2025-11-12 22:44:52,707 - INFO - root - 成功添加图片 10：./export\hybrid attention\images\figure_10_page18.jpeg
2025-11-12 22:44:52,709 - INFO - root - 已更新图片链接
2025-11-12 22:44:52,710 - INFO - root - 论文《Multi-scale deep residual shrinkage networks with a hybrid attention mechanism for rolling bearing fault diagnosis》的分析已保存到 ./export\hybrid attention\Multi-scale deep residual shrinkage networks with a hybrid attention mechanism for rolling bearing f.md
2025-11-12 22:44:52,717 - INFO - root - 正在总结论文 5/9: Physics Inspired Hybrid Attention for SAR Target Recognition
2025-11-12 22:45:06,630 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 22:45:06,632 - INFO - root - LLMClient: rate limit reached, sleeping 15.7s
2025-11-12 22:46:41,981 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 22:47:21,013 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 22:47:21,014 - INFO - root - 正在提取论文图片到目录: ./export\hybrid attention\images
2025-11-12 22:47:22,043 - INFO - root - 已保存图片 1/10：./export\hybrid attention\images\figure_1_page3.png
2025-11-12 22:47:22,199 - INFO - root - 已保存图片 2/10：./export\hybrid attention\images\figure_2_page1.png
2025-11-12 22:47:22,288 - INFO - root - 已保存图片 3/10：./export\hybrid attention\images\figure_3_page6.jpeg
2025-11-12 22:47:22,355 - INFO - root - 已保存图片 4/10：./export\hybrid attention\images\figure_4_page4.png
2025-11-12 22:47:22,477 - INFO - root - 已保存图片 5/10：./export\hybrid attention\images\figure_5_page11.png
2025-11-12 22:47:22,580 - INFO - root - 已保存图片 6/10：./export\hybrid attention\images\figure_6_page10.png
2025-11-12 22:47:22,663 - INFO - root - 已保存图片 7/10：./export\hybrid attention\images\figure_7_page2.png
2025-11-12 22:47:22,748 - INFO - root - 已保存图片 8/10：./export\hybrid attention\images\figure_8_page11.png
2025-11-12 22:47:22,757 - INFO - root - 成功添加图片 1：./export\hybrid attention\images\figure_1_page3.png
2025-11-12 22:47:22,758 - INFO - root - 成功添加图片 2：./export\hybrid attention\images\figure_2_page1.png
2025-11-12 22:47:22,758 - INFO - root - 成功添加图片 3：./export\hybrid attention\images\figure_3_page6.jpeg
2025-11-12 22:47:22,759 - INFO - root - 成功添加图片 4：./export\hybrid attention\images\figure_4_page4.png
2025-11-12 22:47:22,760 - INFO - root - 成功添加图片 5：./export\hybrid attention\images\figure_5_page11.png
2025-11-12 22:47:22,760 - INFO - root - 成功添加图片 6：./export\hybrid attention\images\figure_6_page10.png
2025-11-12 22:47:22,762 - INFO - root - 成功添加图片 7：./export\hybrid attention\images\figure_7_page2.png
2025-11-12 22:47:22,766 - INFO - root - 成功添加图片 8：./export\hybrid attention\images\figure_8_page11.png
2025-11-12 22:47:22,769 - INFO - root - 已更新图片链接
2025-11-12 22:47:22,775 - INFO - root - 论文《Physics Inspired Hybrid Attention for SAR Target Recognition》的分析已保存到 ./export\hybrid attention\Physics Inspired Hybrid Attention for SAR Target Recognition.md
2025-11-12 22:47:22,782 - INFO - root - 正在总结论文 6/9: Fine-grained image classification method based on hybrid attention module
2025-11-12 22:47:36,954 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 22:47:36,955 - INFO - root - LLMClient: rate limit reached, sleeping 5.0s
2025-11-12 22:48:39,253 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 22:49:12,137 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 22:49:12,141 - INFO - root - 正在提取论文图片到目录: ./export\hybrid attention\images
2025-11-12 22:49:12,261 - INFO - root - 已保存图片 1/10：./export\hybrid attention\images\figure_1_page10.jpeg
2025-11-12 22:49:12,351 - INFO - root - 已保存图片 2/10：./export\hybrid attention\images\figure_2_page10.jpeg
2025-11-12 22:49:12,415 - INFO - root - 已保存图片 3/10：./export\hybrid attention\images\figure_3_page4.jpeg
2025-11-12 22:49:12,461 - INFO - root - 已保存图片 4/10：./export\hybrid attention\images\figure_4_page6.jpeg
2025-11-12 22:49:12,509 - INFO - root - 已保存图片 5/10：./export\hybrid attention\images\figure_5_page7.jpeg
2025-11-12 22:49:12,547 - INFO - root - 已保存图片 6/10：./export\hybrid attention\images\figure_6_page5.jpeg
2025-11-12 22:49:12,570 - INFO - root - 已保存图片 7/10：./export\hybrid attention\images\figure_7_page6.jpeg
2025-11-12 22:49:12,574 - INFO - root - 成功添加图片 1：./export\hybrid attention\images\figure_1_page10.jpeg
2025-11-12 22:49:12,574 - INFO - root - 成功添加图片 2：./export\hybrid attention\images\figure_2_page10.jpeg
2025-11-12 22:49:12,574 - INFO - root - 成功添加图片 3：./export\hybrid attention\images\figure_3_page4.jpeg
2025-11-12 22:49:12,574 - INFO - root - 成功添加图片 4：./export\hybrid attention\images\figure_4_page6.jpeg
2025-11-12 22:49:12,579 - INFO - root - 成功添加图片 5：./export\hybrid attention\images\figure_5_page7.jpeg
2025-11-12 22:49:12,579 - INFO - root - 成功添加图片 6：./export\hybrid attention\images\figure_6_page5.jpeg
2025-11-12 22:49:12,579 - INFO - root - 成功添加图片 7：./export\hybrid attention\images\figure_7_page6.jpeg
2025-11-12 22:49:12,580 - INFO - root - 已更新图片链接
2025-11-12 22:49:12,583 - INFO - root - 论文《Fine-grained image classification method based on hybrid attention module》的分析已保存到 ./export\hybrid attention\Fine-grained image classification method based on hybrid attention module.md
2025-11-12 22:49:12,586 - INFO - root - 正在总结论文 7/9: Text-Conditioned Outfit Recommendation With Hybrid Attention Layer
2025-11-12 22:49:29,803 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 22:49:29,813 - INFO - root - LLMClient: rate limit reached, sleeping 9.4s
2025-11-12 22:50:49,939 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 22:51:25,610 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 22:51:25,614 - INFO - root - 正在提取论文图片到目录: ./export\hybrid attention\images
2025-11-12 22:51:29,471 - INFO - root - 已保存图片 1/10：./export\hybrid attention\images\figure_1_page2.jpeg
2025-11-12 22:51:29,565 - INFO - root - 已保存图片 2/10：./export\hybrid attention\images\figure_2_page8.png
2025-11-12 22:51:29,663 - INFO - root - 已保存图片 3/10：./export\hybrid attention\images\figure_3_page8.png
2025-11-12 22:51:29,761 - INFO - root - 已保存图片 4/10：./export\hybrid attention\images\figure_4_page8.png
2025-11-12 22:51:29,800 - INFO - root - 已保存图片 5/10：./export\hybrid attention\images\figure_5_page4.jpeg
2025-11-12 22:51:29,855 - INFO - root - 已保存图片 6/10：./export\hybrid attention\images\figure_6_page4.jpeg
2025-11-12 22:51:29,902 - INFO - root - 已保存图片 7/10：./export\hybrid attention\images\figure_7_page4.jpeg
2025-11-12 22:51:29,956 - INFO - root - 已保存图片 8/10：./export\hybrid attention\images\figure_8_page4.jpeg
2025-11-12 22:51:30,066 - INFO - root - 已保存图片 9/10：./export\hybrid attention\images\figure_9_page4.jpeg
2025-11-12 22:51:30,118 - INFO - root - 已保存图片 10/10：./export\hybrid attention\images\figure_10_page4.jpeg
2025-11-12 22:51:30,155 - INFO - root - 成功添加图片 1：./export\hybrid attention\images\figure_1_page2.jpeg
2025-11-12 22:51:30,156 - INFO - root - 成功添加图片 2：./export\hybrid attention\images\figure_2_page8.png
2025-11-12 22:51:30,156 - INFO - root - 成功添加图片 3：./export\hybrid attention\images\figure_3_page8.png
2025-11-12 22:51:30,156 - INFO - root - 成功添加图片 4：./export\hybrid attention\images\figure_4_page8.png
2025-11-12 22:51:30,157 - INFO - root - 成功添加图片 5：./export\hybrid attention\images\figure_5_page4.jpeg
2025-11-12 22:51:30,157 - INFO - root - 成功添加图片 6：./export\hybrid attention\images\figure_6_page4.jpeg
2025-11-12 22:51:30,157 - INFO - root - 成功添加图片 7：./export\hybrid attention\images\figure_7_page4.jpeg
2025-11-12 22:51:30,157 - INFO - root - 成功添加图片 8：./export\hybrid attention\images\figure_8_page4.jpeg
2025-11-12 22:51:30,160 - INFO - root - 成功添加图片 9：./export\hybrid attention\images\figure_9_page4.jpeg
2025-11-12 22:51:30,162 - INFO - root - 成功添加图片 10：./export\hybrid attention\images\figure_10_page4.jpeg
2025-11-12 22:51:30,164 - INFO - root - 已更新图片链接
2025-11-12 22:51:30,173 - INFO - root - 论文《Text-Conditioned Outfit Recommendation With Hybrid Attention Layer》的分析已保存到 ./export\hybrid attention\Text-Conditioned Outfit Recommendation With Hybrid Attention Layer.md
2025-11-12 22:51:30,177 - INFO - root - 正在总结论文 8/9: Hybrid Attention-Based Prototypical Networks for Noisy Few-Shot Relation Classification
2025-11-12 22:51:44,182 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 22:51:44,183 - INFO - root - LLMClient: rate limit reached, sleeping 5.8s
2025-11-12 22:52:47,217 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 22:53:19,192 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 22:53:19,193 - INFO - root - 正在提取论文图片到目录: ./export\hybrid attention\images
2025-11-12 22:53:19,223 - INFO - root - 论文《Hybrid Attention-Based Prototypical Networks for Noisy Few-Shot Relation Classification》的分析已保存到 ./export\hybrid attention\Hybrid Attention-Based Prototypical Networks for Noisy Few-Shot Relation Classification.md
2025-11-12 22:53:19,232 - INFO - root - 正在总结论文 9/9: Dual-view Correlation Hybrid Attention Network for Robust Holistic Mammogram Classification
2025-11-12 22:53:29,675 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 22:53:29,676 - INFO - root - LLMClient: rate limit reached, sleeping 17.5s
2025-11-12 22:54:52,482 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 22:55:41,999 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 22:55:42,000 - INFO - root - 正在提取论文图片到目录: ./export\hybrid attention\images
2025-11-12 22:55:43,529 - INFO - root - 已保存图片 1/10：./export\hybrid attention\images\figure_1_page4.jpeg
2025-11-12 22:55:43,623 - INFO - root - 已保存图片 2/10：./export\hybrid attention\images\figure_2_page5.jpeg
2025-11-12 22:55:43,753 - INFO - root - 已保存图片 3/10：./export\hybrid attention\images\figure_3_page3.jpeg
2025-11-12 22:55:43,854 - INFO - root - 已保存图片 4/10：./export\hybrid attention\images\figure_4_page3.jpeg
2025-11-12 22:55:43,977 - INFO - root - 已保存图片 5/10：./export\hybrid attention\images\figure_5_page7.jpeg
2025-11-12 22:55:44,082 - INFO - root - 已保存图片 6/10：./export\hybrid attention\images\figure_6_page7.jpeg
2025-11-12 22:55:44,191 - INFO - root - 已保存图片 7/10：./export\hybrid attention\images\figure_7_page7.jpeg
2025-11-12 22:55:44,292 - INFO - root - 已保存图片 8/10：./export\hybrid attention\images\figure_8_page7.jpeg
2025-11-12 22:55:44,399 - INFO - root - 已保存图片 9/10：./export\hybrid attention\images\figure_9_page7.jpeg
2025-11-12 22:55:44,493 - INFO - root - 已保存图片 10/10：./export\hybrid attention\images\figure_10_page7.jpeg
2025-11-12 22:55:44,498 - INFO - root - 成功添加图片 1：./export\hybrid attention\images\figure_1_page4.jpeg
2025-11-12 22:55:44,499 - INFO - root - 成功添加图片 2：./export\hybrid attention\images\figure_2_page5.jpeg
2025-11-12 22:55:44,499 - INFO - root - 成功添加图片 3：./export\hybrid attention\images\figure_3_page3.jpeg
2025-11-12 22:55:44,499 - INFO - root - 成功添加图片 4：./export\hybrid attention\images\figure_4_page3.jpeg
2025-11-12 22:55:44,499 - INFO - root - 成功添加图片 5：./export\hybrid attention\images\figure_5_page7.jpeg
2025-11-12 22:55:44,500 - INFO - root - 成功添加图片 6：./export\hybrid attention\images\figure_6_page7.jpeg
2025-11-12 22:55:44,500 - INFO - root - 成功添加图片 7：./export\hybrid attention\images\figure_7_page7.jpeg
2025-11-12 22:55:44,501 - INFO - root - 成功添加图片 8：./export\hybrid attention\images\figure_8_page7.jpeg
2025-11-12 22:55:44,501 - INFO - root - 成功添加图片 9：./export\hybrid attention\images\figure_9_page7.jpeg
2025-11-12 22:55:44,501 - INFO - root - 成功添加图片 10：./export\hybrid attention\images\figure_10_page7.jpeg
2025-11-12 22:55:44,520 - INFO - root - 已更新图片链接
2025-11-12 22:55:44,526 - INFO - root - 论文《Dual-view Correlation Hybrid Attention Network for Robust Holistic Mammogram Classification》的分析已保存到 ./export\hybrid attention\Dual-view Correlation Hybrid Attention Network for Robust Holistic Mammogram Classification.md
2025-11-12 22:55:49,077 - INFO - root - 已生成汇总Excel表格: export\hybrid attention\论文汇总_hybrid attention_20251112_225546.xlsx
2025-11-12 22:55:49,079 - INFO - root - 已生成汇总Excel表格: export\hybrid attention\论文汇总_hybrid attention_20251112_225546.xlsx
2025-11-12 22:55:49,080 - INFO - root - 总运行时间: 1378.04 seconds
2025-11-12 23:00:45,462 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-12 23:00:45,464 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-12 23:00:45,467 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-12 23:00:49,871 - INFO - root - LLMClientManager: 指定使用客户端: Deepseek
2025-11-12 23:00:49,872 - INFO - root - DeepSeekClient: API key found: 9f9e270e-b...
2025-11-12 23:00:49,872 - INFO - root - DeepSeekClient: 使用模式: 火山引擎
2025-11-12 23:00:49,874 - INFO - root - DeepSeekClient: 模型名称: deepseek-v3-1-terminus
2025-11-12 23:00:53,907 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 23:00:53,934 - INFO - root - DeepSeekClient: initialized successfully with model deepseek-v3-1-terminus
2025-11-12 23:00:53,935 - INFO - root - LLMClientManager: DeepSeek 客户端初始化成功
2025-11-12 23:00:53,939 - INFO - root - LLMClientManager: switched to DeepSeek client (case-insensitive match)
2025-11-12 23:00:53,940 - INFO - root - 已手动切换到 LLM 客户端: Deepseek
2025-11-12 23:00:53,941 - INFO - root - 使用 LLM 模型: deepseek-v3-1-terminus
2025-11-12 23:00:53,941 - INFO - root - 可用客户端: ['DeepSeek']
2025-11-12 23:00:53,942 - INFO - root - === 运行配置 ===
2025-11-12 23:00:53,944 - INFO - root - 处理模式: Semantic Scholar 高引用搜索 (API)
2025-11-12 23:00:53,944 - INFO - root - 查询 (关键词): hybrid attention
2025-11-12 23:00:53,945 - INFO - root - 关键词 (用于保存): hybrid attention
2025-11-12 23:00:53,945 - INFO - root - 排序: citationCount:desc
2025-11-12 23:00:53,945 - INFO - root - 最大处理数量: 80
2025-11-12 23:00:53,946 - INFO - root - 保存图片: 是
2025-11-12 23:00:53,946 - INFO - root - 输出语言: 中文
2025-11-12 23:00:53,947 - INFO - root - 强制重新处理: 否
2025-11-12 23:00:53,947 - INFO - root - LLM 客户端: Deepseek
2025-11-12 23:00:53,948 - INFO - root - ====================
2025-11-12 23:00:53,949 - INFO - root - 正在使用检索策略: semantic
2025-11-12 23:00:53,949 - INFO - root - 使用 Semantic Scholar 高引用搜索模式 (API)
2025-11-12 23:00:53,949 - INFO - root - Semantic API 查询: query=hybrid attention, limit=80, sort=citationCount:desc
2025-11-12 23:00:53,950 - INFO - root - 正在调用 Semantic Scholar API...
2025-11-12 23:00:56,969 - WARNING - root - 【手动下载提示】(无PDF): An Instrument Indication Acquisition Algorithm Based on Lightweight Deep Convolutional Neural Network and Hybrid Attention Fine-Grained Features
	  URL: https://www.semanticscholar.org/paper/49f99d7a21e2ded7915676753a180983763b9a22
	  Citations: 66 | Authors: Jiaquan Shen, Ningzhong Liu, Han Sun, Deguang Li, Yongxin Zhang | Date: N/A
2025-11-12 23:00:56,975 - WARNING - root - 【手动下载提示】(无PDF): Enhancing ASD classification through hybrid attention-based learning of facial features
	  URL: https://www.semanticscholar.org/paper/22547aa4c72c7c2799932a0f451ab3f2db6d7d0f
	  Citations: 35 | Authors: Inzamam Shahzad, Saif Ur Rehman Khan, Waseem Abbas, Z. U. Abideen, Jin Liu | Date: 2024-04-21
2025-11-12 23:00:56,975 - WARNING - root - 【手动下载提示】(无PDF): Dual-Hybrid Attention Network for Specular Highlight Removal
	  URL: https://www.semanticscholar.org/paper/d56ce689cc0f8b1cf0e5f58882503a5e59ec440b
	  Citations: 33 | Authors: Xiaojiao Guo, Xuhang Chen, Shenghong Luo, Shuqiang Wang, Chi-Man Pun | Date: 2024-07-17
2025-11-12 23:00:56,976 - WARNING - root - 【手动下载提示】(无PDF): HyA-GAN: remote sensing image cloud removal based on hybrid attention generation adversarial network
	  URL: https://www.semanticscholar.org/paper/905b42f2f8d912d98fd7cbec4f7b244401176acc
	  Citations: 16 | Authors: Minghao Jin, Pengwei Wang, Yusong Li | Date: 2024-02-27
2025-11-12 23:00:56,976 - WARNING - root - 【手动下载提示】(无PDF): Radar Signal Recognition Based on CNN With a Hybrid Attention Mechanism and Skip Feature Aggregation
	  URL: https://www.semanticscholar.org/paper/dacad703c49e9434321c91220219638f871fd9d2
	  Citations: 25 | Authors: Yuanpu Guo, Haixin Sun, Hui Liu, Zhen-miao Deng | Date: N/A
2025-11-12 23:00:56,976 - WARNING - root - 【手动下载提示】(无PDF): Hybrid Attention-Aware Transformer Network Collaborative Multiscale Feature Alignment for Building Change Detection
	  URL: https://www.semanticscholar.org/paper/a0f8053046622628073ac6f051b5181a80cb7ad3
	  Citations: 28 | Authors: Chuan Xu, Zhaoyi Ye, Liye Mei, Haonan Yu, Jianchen Liu, Yaxiaer Yalikun, Shuangtong Jin, Sheng Liu, Wei Yang, Cheng Lei | Date: N/A
2025-11-12 23:00:56,976 - WARNING - root - 【手动下载提示】(无PDF): Probabilistic Multienergy Load Forecasting Based on Hybrid Attention-Enabled Transformer Network and Gaussian Process-Aided Residual Learning
	  URL: https://www.semanticscholar.org/paper/a2d81cc04f73e2898fb16e7e8c8f9cf69adadfd5
	  Citations: 16 | Authors: Pengfei Zhao, Weihao Hu, Di Cao, Zhenyuan Zhang, Yuehui Huang, Longcheng Dai, Zhe Chen | Date: 2024-06-01
2025-11-12 23:00:56,977 - INFO - root - 正在下载: https://ieeexplore.ieee.org/ielx7/4609443/4609444/10416333.pdf
2025-11-12 23:01:01,814 - INFO - root - 正在下载: https://ieeexplore.ieee.org/ielx7/4609443/4609444/10416333.pdf
2025-11-12 23:01:06,657 - INFO - root - 正在下载: https://ieeexplore.ieee.org/ielx7/4609443/4609444/10416333.pdf
2025-11-12 23:01:11,857 - INFO - root - 正在下载: https://ieeexplore.ieee.org/ielx7/4609443/4609444/10416333.pdf
2025-11-12 23:01:24,908 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\hybrid attention\Hybrid Attention Fusion Embedded in Transformer for Remote Sensing Image Semantic Segmentation.pdf
2025-11-12 23:01:24,911 - INFO - root - 成功下载 (Semantic Scholar): Hybrid Attention Fusion Embedded in Transformer for Remote Sensing Image Semantic Segmentation
2025-11-12 23:01:24,911 - WARNING - root - 【手动下载提示】(无PDF): Enhancing Time Series Product Demand Forecasting With Hybrid Attention-Based Deep Learning Models
	  URL: https://www.semanticscholar.org/paper/4848b35cbe515f8909a67a82dcb83d7c5e48f74b
	  Citations: 14 | Authors: Xuguang Zhang, Pan Li, Xu Han, Yongbin Yang, Yiwen Cui | Date: N/A
2025-11-12 23:01:24,912 - INFO - root - 正在下载: https://www.mdpi.com/2306-5354/11/3/240/pdf?version=1709132347
2025-11-12 23:01:29,622 - INFO - root - 正在下载: https://www.mdpi.com/2306-5354/11/3/240/pdf?version=1709132347
2025-11-12 23:01:34,349 - INFO - root - 正在下载: https://www.mdpi.com/2306-5354/11/3/240/pdf?version=1709132347
2025-11-12 23:01:39,098 - INFO - root - 正在下载: https://www.mdpi.com/2306-5354/11/3/240/pdf?version=1709132347
2025-11-12 23:01:47,813 - INFO - root - 正在下载: https://www.mdpi.com/2306-5354/11/3/240/pdf?version=1709132347
2025-11-12 23:01:48,845 - WARNING - root - 下载 Advancing Ocular Imaging: A Hybrid Attention Mechanism-Based U-Net Model for Precise Segmentation of Sub-Retinal Layers in OCT Images (https://www.mdpi.com/2306-5354/11/3/240/pdf?version=1709132347) 失败: 403 Client Error: Forbidden for url: https://www.mdpi.com/2306-5354/11/3/240/pdf?version=1709132347
2025-11-12 23:01:48,848 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\hybrid attention\YOLO Algorithm With Hybrid Attention Feature Pyramid Network for Solder Joint Defect Detection.pdf
2025-11-12 23:01:48,848 - INFO - root - 成功下载 (Semantic Scholar): YOLO Algorithm With Hybrid Attention Feature Pyramid Network for Solder Joint Defect Detection
2025-11-12 23:01:48,848 - WARNING - root - 【手动下载提示】(无PDF): A novel approach for bearings multiclass fault diagnosis fusing multiscale deep convolution and hybrid attention networks
	  URL: https://www.semanticscholar.org/paper/bf72523fe518b2e4ce4d75d125dd5220177043f6
	  Citations: 13 | Authors: Fule Li, Xinlong Zhao | Date: 2024-01-08
2025-11-12 23:01:48,849 - WARNING - root - 【手动下载提示】(无PDF): Drone-HAT: Hybrid Attention Transformer for Complex Action Recognition in Drone Surveillance Videos
	  URL: https://www.semanticscholar.org/paper/a76690fb96dc7d3dfd5f8fec62c3949cc7ec96f6
	  Citations: 12 | Authors: Mustaqeem Khan, Jamil Ahmad, Abdulmotaleb El-Saddik, W. Gueaieb, Giulia De Masi, Fakhri Karray | Date: 2024-06-17
2025-11-12 23:01:48,849 - WARNING - root - 【手动下载提示】(无PDF): Dense Hybrid Attention Network for Palmprint Image Super-Resolution
	  URL: https://www.semanticscholar.org/paper/75746d8d52509b24d9975d9b3b07ae91311dc7ed
	  Citations: 12 | Authors: Yao Wang, Lunke Fei, Shuping Zhao, Qi Zhu, Jie Wen, Wei Jia, Imad Rida | Date: 2024-04-01
2025-11-12 23:01:48,850 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\hybrid attention\Frequency Enhanced Hybrid Attention Network for Sequential Recommendation.pdf
2025-11-12 23:01:48,851 - INFO - root - 成功下载 (Semantic Scholar): Frequency Enhanced Hybrid Attention Network for Sequential Recommendation
2025-11-12 23:01:48,851 - WARNING - root - 【手动下载提示】(无PDF): Hybrid Attention Feature Refinement Network for Lightweight Image Super-Resolution in Metaverse Immersive Display
	  URL: https://www.semanticscholar.org/paper/c4d95a47eec1a23320d60dd95848d41e10820ee4
	  Citations: 10 | Authors: Kexin Wang, Xiaomin Yang, Gwanggil Jeon | Date: 2024-02-01
2025-11-12 23:01:48,854 - WARNING - root - 【手动下载提示】(无PDF): A Multiscale Hybrid Attention Networks Based on Multiview Images for the Diagnosis of Parkinson’s Disease
	  URL: https://www.semanticscholar.org/paper/b2af0577ee8ac56b527bd108ce57755a4a4b04e7
	  Citations: 11 | Authors: Xinchun Cui, Youshi Zhou, Chao Zhao, Jianlong Li, Xiangwei Zheng, Xiuli Li, Shixiao Shan, JinXing Liu, Xiaoli Liu | Date: N/A
2025-11-12 23:01:48,856 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\hybrid attention\HAT_ Hybrid Attention Transformer for Image Restoration.pdf
2025-11-12 23:01:48,858 - INFO - root - 成功下载 (Semantic Scholar): HAT: Hybrid Attention Transformer for Image Restoration
2025-11-12 23:01:48,860 - INFO - root - 正在下载: https://www.mdpi.com/2076-3417/14/3/1293/pdf?version=1707037901
2025-11-12 23:01:53,802 - INFO - root - 正在下载: https://www.mdpi.com/2076-3417/14/3/1293/pdf?version=1707037901
2025-11-12 23:01:58,853 - INFO - root - 正在下载: https://www.mdpi.com/2076-3417/14/3/1293/pdf?version=1707037901
2025-11-12 23:02:03,678 - INFO - root - 正在下载: https://www.mdpi.com/2076-3417/14/3/1293/pdf?version=1707037901
2025-11-12 23:02:12,461 - INFO - root - 正在下载: https://www.mdpi.com/2076-3417/14/3/1293/pdf?version=1707037901
2025-11-12 23:02:13,192 - WARNING - root - 下载 Dual Hybrid Attention Mechanism-Based U-Net for Building Segmentation in Remote Sensing Images (https://www.mdpi.com/2076-3417/14/3/1293/pdf?version=1707037901) 失败: 403 Client Error: Forbidden for url: https://www.mdpi.com/2076-3417/14/3/1293/pdf?version=1707037901
2025-11-12 23:02:13,192 - WARNING - root - 【手动下载提示】(无PDF): Abundance Matrix Correlation Analysis Network Based on Hierarchical Multihead Self-Cross-Hybrid Attention for Hyperspectral Change Detection
	  URL: https://www.semanticscholar.org/paper/6aae02a41656cecba872b29bb3d71c414a58f57b
	  Citations: 66 | Authors: Wenqian Dong, Jing Zhao, Jiahui Qu, Song Xiao, Nan Li, Shaoxiong Hou, Yunsong Li | Date: N/A
2025-11-12 23:02:13,193 - WARNING - root - 【手动下载提示】(无PDF): HA-Net: a SAR image ship detector based on hybrid attention
	  URL: https://www.semanticscholar.org/paper/4c40b6f75ab19e1402ae88e38013a64c504c3a80
	  Citations: 6 | Authors: Shouwen Cai, Hao Meng, Ming Yuan, Fei Gao | Date: 2024-06-10
2025-11-12 23:02:13,194 - WARNING - root - 【手动下载提示】(无PDF): Hybrid Attention Module and Transformer Based Fuze DRFM Jamming Signal Recognition
	  URL: https://www.semanticscholar.org/paper/0fb8059c6aaf0c86c9e9a623fa1ad73d0f737c37
	  Citations: 7 | Authors: Jikai Yang, Zhiquan Bai, Zhaoxia Xian, Hongwu Xiang, Jingxin Li, Huili Hu, Jian Dai, Xinhong Hao | Date: 2024-09-01
2025-11-12 23:02:13,194 - WARNING - root - 【手动下载提示】(无PDF): Actor-Hybrid-Attention-Critic for Multi-Logistic Robots Path Planning
	  URL: https://www.semanticscholar.org/paper/5260da08f9f524b8fa77a37e2884b22804a47c6a
	  Citations: 6 | Authors: Chunjie Yang, Bodi Yuan, Pengzhao Zhai | Date: 2024-06-01
2025-11-12 23:02:13,195 - WARNING - root - 【手动下载提示】(无PDF): Deep Hashing Network With Hybrid Attention and Adaptive Weighting for Image Retrieval
	  URL: https://www.semanticscholar.org/paper/1c688a4da1c546ea783f5743c371732ace568498
	  Citations: 7 | Authors: Yingjiao Pei, Zhongyuan Wang, Na Li, Heling Chen, Baojin Huang, Weiping Tu | Date: N/A
2025-11-12 23:02:13,197 - WARNING - root - 【手动下载提示】(无PDF): Towards Effective Author Name Disambiguation by Hybrid Attention
	  URL: https://www.semanticscholar.org/paper/fc2dcb9e544a0aaad3034a61eaf0563a79c65cbf
	  Citations: 6 | Authors: Qian Zhou, Wei Chen, Peng-Peng Zhao, An Liu, Jia-Jie Xu, Jian-Feng Qu, Lei Zhao | Date: 2024-07-01
2025-11-12 23:02:13,200 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\hybrid attention\Multi-scale deep residual shrinkage networks with a hybrid attention mechanism for rolling bearing f.pdf
2025-11-12 23:02:13,203 - INFO - root - 成功下载 (Semantic Scholar): Multi-scale deep residual shrinkage networks with a hybrid attention mechanism for rolling bearing fault diagnosis
2025-11-12 23:02:13,208 - INFO - root - 正在下载: https://www.mdpi.com/2306-5354/10/6/714/pdf?version=1686635187
2025-11-12 23:02:17,885 - INFO - root - 正在下载: https://www.mdpi.com/2306-5354/10/6/714/pdf?version=1686635187
2025-11-12 23:02:22,825 - INFO - root - 正在下载: https://www.mdpi.com/2306-5354/10/6/714/pdf?version=1686635187
2025-11-12 23:02:28,146 - INFO - root - 正在下载: https://www.mdpi.com/2306-5354/10/6/714/pdf?version=1686635187
2025-11-12 23:02:38,071 - INFO - root - 正在下载: https://www.mdpi.com/2306-5354/10/6/714/pdf?version=1686635187
2025-11-12 23:02:39,126 - WARNING - root - 下载 AHANet: Adaptive Hybrid Attention Network for Alzheimer’s Disease Classification Using Brain Magnetic Resonance Imaging (https://www.mdpi.com/2306-5354/10/6/714/pdf?version=1686635187) 失败: 403 Client Error: Forbidden for url: https://www.mdpi.com/2306-5354/10/6/714/pdf?version=1686635187
2025-11-12 23:02:39,127 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\hybrid attention\Physics Inspired Hybrid Attention for SAR Target Recognition.pdf
2025-11-12 23:02:39,135 - INFO - root - 成功下载 (Semantic Scholar): Physics Inspired Hybrid Attention for SAR Target Recognition
2025-11-12 23:02:39,135 - WARNING - root - 【手动下载提示】(无PDF): WHEN: A Wavelet-DTW Hybrid Attention Network for Heterogeneous Time Series Analysis
	  URL: https://www.semanticscholar.org/paper/c2e57a1926217f67a72c617d09fa12ec8e667d0e
	  Citations: 33 | Authors: Jingyuan Wang, Chen Yang, Xiaohan Jiang, Junjie Wu | Date: 2023-08-04
2025-11-12 23:02:39,138 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\hybrid attention\Fine-grained image classification method based on hybrid attention module.pdf
2025-11-12 23:02:39,139 - INFO - root - 成功下载 (Semantic Scholar): Fine-grained image classification method based on hybrid attention module
2025-11-12 23:02:39,145 - WARNING - root - 【手动下载提示】(无PDF): Hybrid Attention-Aware Learning Network for Facial Expression Recognition in the Wild
	  URL: https://www.semanticscholar.org/paper/a13c5a80a32c0e2dbf589d9fca9daa9b2300165d
	  Citations: 4 | Authors: Weijun Gong, Zhiyao La, Yurong Qian, Weihang Zhou | Date: 2024-01-05
2025-11-12 23:02:39,148 - INFO - root - 正在下载: https://ieeexplore.ieee.org/ielx7/36/10006360/10145829.pdf
2025-11-12 23:02:45,199 - INFO - root - 正在下载: https://ieeexplore.ieee.org/ielx7/36/10006360/10145829.pdf
2025-11-12 23:02:51,631 - INFO - root - 正在下载: https://ieeexplore.ieee.org/ielx7/36/10006360/10145829.pdf
2025-11-12 23:02:57,290 - INFO - root - 正在下载: https://ieeexplore.ieee.org/ielx7/36/10006360/10145829.pdf
2025-11-12 23:03:06,960 - INFO - root - 正在下载: https://ieeexplore.ieee.org/ielx7/36/10006360/10145829.pdf
2025-11-12 23:03:09,343 - WARNING - root - 下载 Hybrid Attention-Based U-Shaped Network for Remote Sensing Image Super-Resolution (https://ieeexplore.ieee.org/ielx7/36/10006360/10145829.pdf) 失败: 418 Client Error: Unknown Code for url: https://ieeexplore.ieee.org/ielx7/36/10006360/10145829.pdf
2025-11-12 23:03:09,344 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\hybrid attention\Text-Conditioned Outfit Recommendation With Hybrid Attention Layer.pdf
2025-11-12 23:03:09,344 - INFO - root - 成功下载 (Semantic Scholar): Text-Conditioned Outfit Recommendation With Hybrid Attention Layer
2025-11-12 23:03:09,345 - INFO - root - 正在下载: https://www.mdpi.com/2076-3417/13/2/770/pdf?version=1673518878
2025-11-12 23:03:15,022 - INFO - root - 正在下载: https://www.mdpi.com/2076-3417/13/2/770/pdf?version=1673518878
2025-11-12 23:03:20,768 - INFO - root - 正在下载: https://www.mdpi.com/2076-3417/13/2/770/pdf?version=1673518878
2025-11-12 23:03:26,844 - INFO - root - 正在下载: https://www.mdpi.com/2076-3417/13/2/770/pdf?version=1673518878
2025-11-12 23:03:36,295 - INFO - root - 正在下载: https://www.mdpi.com/2076-3417/13/2/770/pdf?version=1673518878
2025-11-12 23:03:37,856 - WARNING - root - 下载 Smart Contract Vulnerability Detection Based on Hybrid Attention Mechanism Model (https://www.mdpi.com/2076-3417/13/2/770/pdf?version=1673518878) 失败: 403 Client Error: Forbidden for url: https://www.mdpi.com/2076-3417/13/2/770/pdf?version=1673518878
2025-11-12 23:03:37,872 - WARNING - root - 【手动下载提示】(无PDF): Mutiscale Hybrid Attention Transformer for Remote Sensing Image Pansharpening
	  URL: https://www.semanticscholar.org/paper/3b8404c8b16dd7abb86aa5f13139fa9a9c5f5ca8
	  Citations: 21 | Authors: Wengang Zhu, Jinjiang Li, Zhi-Yonga An, Zhen Hua | Date: N/A
2025-11-12 23:03:37,895 - WARNING - root - 【手动下载提示】(无PDF): Multimodal emotion recognition based on audio and text by using hybrid attention networks
	  URL: https://www.semanticscholar.org/paper/5a35815f9d5f7ed5697b4638b1158f42837051c1
	  Citations: 42 | Authors: Shiqing Zhang, Yijiao Yang, Ruixin Liu, Chen Chen, Xin Tao, Wenping Guo, Yicheng Xu, Xiaoming Zhao | Date: N/A
2025-11-12 23:03:37,896 - WARNING - root - 【手动下载提示】(无PDF): A Novel Approach for Surface Integrity Monitoring in High-Energy Nanosecond-Pulse Laser Shock Peening: Acoustic Emission and Hybrid-Attention CNN
	  URL: https://www.semanticscholar.org/paper/9608f2b16d1d302f7507505b51a5be96fdf0b542
	  Citations: 19 | Authors: Zhifen Zhang, Rui Qin, Gengze Li, Z. Du, G. Wen, Weifeng He | Date: 2023-03-01
2025-11-12 23:03:37,901 - WARNING - root - 【手动下载提示】(无PDF): Intention-convolution and hybrid-attention network for vehicle trajectory prediction
	  URL: https://www.semanticscholar.org/paper/3bcb4d2994896053a5a8da42d09eb621d3b2b221
	  Citations: 33 | Authors: Chao Li, Zhanwen Liu, Shang Lin, Yang Wang, Xiangmo Zhao | Date: 2023-09-01
2025-11-12 23:03:37,923 - WARNING - root - 【手动下载提示】(无PDF): Hybrid Attention Network for Epileptic EEG Classification
	  URL: https://www.semanticscholar.org/paper/f282fa85469cc789c2f3b62e57e3446a49528afa
	  Citations: 17 | Authors: Yanna Zhao, Jiatong He, Fenglin Zhu, Tiantian Xiao, Yongfeng Zhang, Ziwei Wang, Fangzhou Xu, Yi Niu | Date: 2023-03-31
2025-11-12 23:03:37,955 - INFO - root - 正在下载: https://www.mdpi.com/1424-8220/23/13/6052/pdf?version=1688107163
2025-11-12 23:03:43,580 - INFO - root - 正在下载: https://www.mdpi.com/1424-8220/23/13/6052/pdf?version=1688107163
2025-11-12 23:03:48,964 - INFO - root - 正在下载: https://www.mdpi.com/1424-8220/23/13/6052/pdf?version=1688107163
2025-11-12 23:03:54,461 - INFO - root - 正在下载: https://www.mdpi.com/1424-8220/23/13/6052/pdf?version=1688107163
2025-11-12 23:04:03,419 - INFO - root - 正在下载: https://www.mdpi.com/1424-8220/23/13/6052/pdf?version=1688107163
2025-11-12 23:04:04,569 - WARNING - root - 下载 PHAM-YOLO: A Parallel Hybrid Attention Mechanism Network for Defect Detection of Meter in Substation (https://www.mdpi.com/1424-8220/23/13/6052/pdf?version=1688107163) 失败: 403 Client Error: Forbidden for url: https://www.mdpi.com/1424-8220/23/13/6052/pdf?version=1688107163
2025-11-12 23:04:04,572 - INFO - root - 正在下载: https://www.mdpi.com/1424-8220/23/15/6982/pdf?version=1691312141
2025-11-12 23:04:10,726 - INFO - root - 正在下载: https://www.mdpi.com/1424-8220/23/15/6982/pdf?version=1691312141
2025-11-12 23:04:17,830 - INFO - root - 正在下载: https://www.mdpi.com/1424-8220/23/15/6982/pdf?version=1691312141
2025-11-12 23:04:23,168 - INFO - root - 正在下载: https://www.mdpi.com/1424-8220/23/15/6982/pdf?version=1691312141
2025-11-12 23:04:32,059 - INFO - root - 正在下载: https://www.mdpi.com/1424-8220/23/15/6982/pdf?version=1691312141
2025-11-12 23:04:32,727 - WARNING - root - 下载 Defect Detection in Steel Using a Hybrid Attention Network (https://www.mdpi.com/1424-8220/23/15/6982/pdf?version=1691312141) 失败: 403 Client Error: Forbidden for url: https://www.mdpi.com/1424-8220/23/15/6982/pdf?version=1691312141
2025-11-12 23:04:32,728 - WARNING - root - 【手动下载提示】(无PDF): Hybrid Attention and Motion Constraint for Anomaly Detection in Crowded Scenes
	  URL: https://www.semanticscholar.org/paper/a5e107a1112c88294f44989f6622433fb402fb31
	  Citations: 30 | Authors: Xinfeng Zhang, Jinpeng Fang, Baoqing Yang, Shuhan Chen, Bin Li | Date: 2023-05-01
2025-11-12 23:04:32,728 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\hybrid attention\Hybrid Attention-Based Prototypical Networks for Noisy Few-Shot Relation Classification.pdf
2025-11-12 23:04:32,729 - INFO - root - 成功下载 (Semantic Scholar): Hybrid Attention-Based Prototypical Networks for Noisy Few-Shot Relation Classification
2025-11-12 23:04:32,730 - INFO - root - 正在下载: https://www.mdpi.com/2072-4292/15/2/526/pdf?version=1673863751
2025-11-12 23:04:37,739 - INFO - root - 正在下载: https://www.mdpi.com/2072-4292/15/2/526/pdf?version=1673863751
2025-11-12 23:04:44,349 - INFO - root - 正在下载: https://www.mdpi.com/2072-4292/15/2/526/pdf?version=1673863751
2025-11-12 23:04:48,983 - INFO - root - 正在下载: https://www.mdpi.com/2072-4292/15/2/526/pdf?version=1673863751
2025-11-12 23:04:57,648 - INFO - root - 正在下载: https://www.mdpi.com/2072-4292/15/2/526/pdf?version=1673863751
2025-11-12 23:04:59,327 - WARNING - root - 下载 Hybrid Attention-Based Encoder-Decoder Fully Convolutional Network for PolSAR Image Classification (https://www.mdpi.com/2072-4292/15/2/526/pdf?version=1673863751) 失败: 403 Client Error: Forbidden for url: https://www.mdpi.com/2072-4292/15/2/526/pdf?version=1673863751
2025-11-12 23:04:59,328 - WARNING - root - 【手动下载提示】(无PDF): Hybrid Attention Compression Network With Light Graph Attention Module for Remote Sensing Images
	  URL: https://www.semanticscholar.org/paper/11ab89aa34dae52624533795ebbe1ce707a66fd4
	  Citations: 9 | Authors: Tianpeng Pan, Lili Zhang, Yingchao Song, Yuxuan Liu | Date: N/A
2025-11-12 23:04:59,328 - WARNING - root - 【手动下载提示】(无PDF): An Adaptive Hybrid Attention Based Convolutional Neural Net for Intelligent Transportation Object Recognition
	  URL: https://www.semanticscholar.org/paper/269fed3c9a541a4073cde6e205878c2618b2f973
	  Citations: 11 | Authors: Qili Chen, Guangyuan Pan, Lin Zhao, Junfang Fan, Wenbai Chen, A. Zhang | Date: 2023-07-01
2025-11-12 23:04:59,328 - WARNING - root - 【手动下载提示】(无PDF): HEU-Net: hybrid attention residual block-based network with external skip connections for metal corrosion semantic segmentation
	  URL: https://www.semanticscholar.org/paper/80e0948897bc53edf4eba2e31e443010d8a2e19a
	  Citations: 9 | Authors: Tianchen Zhu, Shiqiang Zhu, Tao Zheng, Hongliang Ding, Wei Song, Cunjun Li | Date: 2023-06-22
2025-11-12 23:04:59,328 - WARNING - root - 【手动下载提示】(无PDF): Face-Periocular Cross-Identification via Contrastive Hybrid Attention Vision Transformer
	  URL: https://www.semanticscholar.org/paper/5765cc795e642e1a8e834d6af93cda3ac65a753a
	  Citations: 6 | Authors: Leslie Ching Ow Tiong, D. Sigmund, A. Teoh | Date: N/A
2025-11-12 23:04:59,328 - WARNING - root - 【手动下载提示】(无PDF): Multi-level wavelet network based on CNN-Transformer hybrid attention for single image deraining
	  URL: https://www.semanticscholar.org/paper/97c485dbb41b68c193decdec5a4618ce3f5b4ee2
	  Citations: 8 | Authors: B. Liu, Siyan Fang | Date: 2023-08-09
2025-11-12 23:04:59,331 - INFO - root - 正在下载: https://www.mdpi.com/1424-8220/23/19/8285/pdf?version=1696663695
2025-11-12 23:05:04,037 - INFO - root - 正在下载: https://www.mdpi.com/1424-8220/23/19/8285/pdf?version=1696663695
2025-11-12 23:05:08,661 - INFO - root - 正在下载: https://www.mdpi.com/1424-8220/23/19/8285/pdf?version=1696663695
2025-11-12 23:05:13,345 - INFO - root - 正在下载: https://www.mdpi.com/1424-8220/23/19/8285/pdf?version=1696663695
2025-11-12 23:05:22,023 - INFO - root - 正在下载: https://www.mdpi.com/1424-8220/23/19/8285/pdf?version=1696663695
2025-11-12 23:05:22,682 - WARNING - root - 下载 A Fast and Robust Lane Detection via Online Re-Parameterization and Hybrid Attention (https://www.mdpi.com/1424-8220/23/19/8285/pdf?version=1696663695) 失败: 403 Client Error: Forbidden for url: https://www.mdpi.com/1424-8220/23/19/8285/pdf?version=1696663695
2025-11-12 23:05:22,683 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\hybrid attention\Dual-view Correlation Hybrid Attention Network for Robust Holistic Mammogram Classification.pdf
2025-11-12 23:05:22,683 - INFO - root - 成功下载 (Semantic Scholar): Dual-view Correlation Hybrid Attention Network for Robust Holistic Mammogram Classification
2025-11-12 23:05:22,684 - INFO - root - 正在下载: https://arxiv.org/pdf/2203.09811
2025-11-12 23:05:23,872 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\hybrid attention\Stacked Hybrid-Attention and Group Collaborative Learning for Unbiased Scene Graph Generation.pdf
2025-11-12 23:05:23,875 - INFO - root - 成功下载 (Semantic Scholar): Stacked Hybrid-Attention and Group Collaborative Learning for Unbiased Scene Graph Generation
2025-11-12 23:05:23,876 - INFO - root - 正在下载: https://onlinelibrary.wiley.com/doi/pdfdirect/10.1049/ipr2.12934
2025-11-12 23:05:33,398 - INFO - root - 正在下载: https://onlinelibrary.wiley.com/doi/pdfdirect/10.1049/ipr2.12934
2025-11-12 23:05:42,903 - INFO - root - 正在下载: https://onlinelibrary.wiley.com/doi/pdfdirect/10.1049/ipr2.12934
2025-11-12 23:05:52,433 - INFO - root - 正在下载: https://onlinelibrary.wiley.com/doi/pdfdirect/10.1049/ipr2.12934
2025-11-12 23:06:05,849 - INFO - root - 正在下载: https://onlinelibrary.wiley.com/doi/pdfdirect/10.1049/ipr2.12934
2025-11-12 23:06:11,466 - WARNING - root - 下载 Hybrid attention mechanism of feature fusion for medical image segmentation (https://onlinelibrary.wiley.com/doi/pdfdirect/10.1049/ipr2.12934) 失败: 403 Client Error: Forbidden for url: https://onlinelibrary.wiley.com/doi/pdfdirect/10.1049/ipr2.12934
2025-11-12 23:06:11,469 - INFO - root - 正在下载: https://www.mdpi.com/2073-8994/15/10/1947/pdf?version=1697811500
2025-11-12 23:06:16,175 - INFO - root - 正在下载: https://www.mdpi.com/2073-8994/15/10/1947/pdf?version=1697811500
2025-11-12 23:06:20,824 - INFO - root - 正在下载: https://www.mdpi.com/2073-8994/15/10/1947/pdf?version=1697811500
2025-11-12 23:06:25,815 - INFO - root - 正在下载: https://www.mdpi.com/2073-8994/15/10/1947/pdf?version=1697811500
2025-11-12 23:06:34,706 - INFO - root - 正在下载: https://www.mdpi.com/2073-8994/15/10/1947/pdf?version=1697811500
2025-11-12 23:06:35,621 - WARNING - root - 下载 Transformer with Hybrid Attention Mechanism for Stereo Endoscopic Video Super Resolution (https://www.mdpi.com/2073-8994/15/10/1947/pdf?version=1697811500) 失败: 403 Client Error: Forbidden for url: https://www.mdpi.com/2073-8994/15/10/1947/pdf?version=1697811500
2025-11-12 23:06:35,659 - WARNING - root - 【手动下载提示】(无PDF): HHTrack: Hyperspectral Object Tracking Based on Hybrid Attention
	  URL: https://www.semanticscholar.org/paper/c1c5c93f3bd9b99ec5fe55b4c2b5bc29abf4b12a
	  Citations: 1 | Authors: Yuedong Tan, Wenfang Sun, Jieran Yuan, Wenwang Du, Zhe Wang, Nan Mao, Beibei Song | Date: 2023-08-14
2025-11-12 23:06:35,662 - INFO - root - 正在下载: https://arxiv.org/pdf/2303.08636
2025-11-12 23:06:40,054 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\hybrid attention\Hybridformer_ Improving Squeezeformer with Hybrid Attention and NSR Mechanism.pdf
2025-11-12 23:06:40,058 - INFO - root - 成功下载 (Semantic Scholar): Hybridformer: Improving Squeezeformer with Hybrid Attention and NSR Mechanism
2025-11-12 23:06:40,058 - INFO - root - 正在下载: https://arxiv.org/pdf/2212.12440
2025-11-12 23:06:46,117 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\hybrid attention\HAC-Net_ A Hybrid Attention-Based Convolutional Neural Network for Highly Accurate Protein-Ligand Bi.pdf
2025-11-12 23:06:46,120 - INFO - root - 成功下载 (Semantic Scholar): HAC-Net: A Hybrid Attention-Based Convolutional Neural Network for Highly Accurate Protein-Ligand Binding Affinity Prediction
2025-11-12 23:06:46,122 - WARNING - root - 【手动下载提示】(无PDF): A hybrid-attention semantic segmentation network for remote sensing interpretation in land-use surveillance
	  URL: https://www.semanticscholar.org/paper/4905315ab99ea19871a65e52be8c8c51624748aa
	  Citations: 49 | Authors: Ning Lv, Zenghui Zhang, Cong Li, Jiaxuan Deng, Tao Su, Chen Chen, Yang Zhou | Date: 2022-02-07
2025-11-12 23:06:46,124 - INFO - root - 正在下载: https://ojs.aaai.org/index.php/AAAI/article/download/16256/16063
2025-11-12 23:07:18,624 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\hybrid attention\A Hybrid Attention Mechanism for Weakly-Supervised Temporal Action Localization.pdf
2025-11-12 23:07:18,626 - INFO - root - 成功下载 (Semantic Scholar): A Hybrid Attention Mechanism for Weakly-Supervised Temporal Action Localization
2025-11-12 23:07:18,627 - WARNING - root - 【手动下载提示】(无PDF): A hybrid attention-based deep learning approach for wind power prediction
	  URL: https://www.semanticscholar.org/paper/9d591544b9f179d93ad85720e8382e8e1c04c916
	  Citations: 128 | Authors: Zhengjing Ma, Gang Mei | Date: 2022-10-01
2025-11-12 23:07:18,627 - WARNING - root - 【手动下载提示】(无PDF): ColorFormer: Image Colorization via Color Memory Assisted Hybrid-Attention Transformer
	  URL: https://www.semanticscholar.org/paper/33618e85644d6705fd74086c13ee3b7e2a2a466a
	  Citations: 27 | Authors: Xiaozhong Ji, Boyuan Jiang, Donghao Luo, Guangpin Tao, Wenqing Chu, Zhifeng Xie, Chengjie Wang, Ying Tai | Date: N/A
2025-11-12 23:07:18,627 - WARNING - root - 【手动下载提示】(无PDF): HAM: Hybrid attention module in deep convolutional neural networks for image classification
	  URL: https://www.semanticscholar.org/paper/2cfa77f582ee36f2d1fe8869505aa5a71a5f99f3
	  Citations: 92 | Authors: Guoqiang Li, Qianhao Fang, Li Zha, Xin Gao, Nenggan Zheng | Date: 2022-05-01
2025-11-12 23:07:18,628 - INFO - root - 正在下载: https://downloads.hindawi.com/journals/cin/2022/4189500.pdf
2025-11-12 23:07:29,468 - INFO - root - 正在下载: https://downloads.hindawi.com/journals/cin/2022/4189500.pdf
2025-11-12 23:07:39,210 - INFO - root - 正在下载: https://downloads.hindawi.com/journals/cin/2022/4189500.pdf
2025-11-12 23:08:03,701 - INFO - root - 正在下载: https://downloads.hindawi.com/journals/cin/2022/4189500.pdf
2025-11-12 23:08:17,615 - INFO - root - 正在下载: https://downloads.hindawi.com/journals/cin/2022/4189500.pdf
2025-11-12 23:08:23,908 - WARNING - root - 下载 Aircraft Image Recognition Network Based on Hybrid Attention Mechanism (https://downloads.hindawi.com/journals/cin/2022/4189500.pdf) 失败: 403 Client Error: Forbidden for url: https://downloads.hindawi.com/journals/cin/2022/4189500.pdf
2025-11-12 23:08:23,910 - WARNING - root - 【手动下载提示】(无PDF): Hybrid attention based vehicle trajectory prediction
	  URL: https://www.semanticscholar.org/paper/a2778f12363b79e0a604ddd21a878f3abb0acced
	  Citations: 6 | Authors: Lingyang Wang, Wenping Jiang | Date: 2023-04-06
2025-11-12 23:08:23,910 - WARNING - root - 【手动下载提示】(无PDF): A Hybrid Attention-Based Paralleled Deep Learning model for tool wear prediction
	  URL: https://www.semanticscholar.org/paper/27da7ffd2319f8a2f47eec128894be31f88fc35c
	  Citations: 87 | Authors: Jian Duan, Xi Zhang, Tielin Shi | Date: 2022-08-01
2025-11-12 23:08:23,910 - WARNING - root - 【手动下载提示】(无PDF): State of health estimation for lithium-ion batteries based on hybrid attention and deep learning
	  URL: https://www.semanticscholar.org/paper/f91dcfd8df66da9bf3649c176869f980b9205115
	  Citations: 89 | Authors: Hongqian Zhao, Zheng Chen, Xing Shu, Jiangwei Shen, Zhenzhen Lei, Yuanjian Zhang | Date: 2022-12-01
2025-11-12 23:08:23,913 - INFO - root - 正在下载: https://ieeexplore.ieee.org/ielx7/6287639/9668973/09693977.pdf
2025-11-12 23:08:28,816 - INFO - root - 正在下载: https://ieeexplore.ieee.org/ielx7/6287639/9668973/09693977.pdf
2025-11-12 23:08:34,101 - INFO - root - 正在下载: https://ieeexplore.ieee.org/ielx7/6287639/9668973/09693977.pdf
2025-11-12 23:08:39,037 - INFO - root - 正在下载: https://ieeexplore.ieee.org/ielx7/6287639/9668973/09693977.pdf
2025-11-12 23:08:49,104 - INFO - root - 正在下载: https://ieeexplore.ieee.org/ielx7/6287639/9668973/09693977.pdf
2025-11-12 23:08:50,263 - WARNING - root - 下载 HANN: Hybrid Attention Neural Network for Detecting Covid-19 Related Rumors (https://ieeexplore.ieee.org/ielx7/6287639/9668973/09693977.pdf) 失败: 418 Client Error: Unknown Code for url: https://ieeexplore.ieee.org/ielx7/6287639/9668973/09693977.pdf
2025-11-12 23:08:50,264 - WARNING - root - 【手动下载提示】(无PDF): Hybrid Attention-Based Prototypical Networks for Few-Shot Sound Classification
	  URL: https://www.semanticscholar.org/paper/e0ddd13d74fe020c8e63eb2ef5a2daa687565953
	  Citations: 15 | Authors: You Wang, D.V. Anderson | Date: 2022-05-23
2025-11-12 23:08:50,264 - INFO - root - 正在下载: https://www.mdpi.com/1424-8220/22/10/3701/pdf?version=1652360619
2025-11-12 23:08:55,474 - INFO - root - 正在下载: https://www.mdpi.com/1424-8220/22/10/3701/pdf?version=1652360619
2025-11-12 23:09:00,545 - INFO - root - 正在下载: https://www.mdpi.com/1424-8220/22/10/3701/pdf?version=1652360619
2025-11-12 23:09:05,548 - INFO - root - 正在下载: https://www.mdpi.com/1424-8220/22/10/3701/pdf?version=1652360619
2025-11-12 23:09:15,503 - INFO - root - 正在下载: https://www.mdpi.com/1424-8220/22/10/3701/pdf?version=1652360619
2025-11-12 23:09:16,739 - WARNING - root - 下载 An Anti-UAV Long-Term Tracking Method with Hybrid Attention Mechanism and Hierarchical Discriminator (https://www.mdpi.com/1424-8220/22/10/3701/pdf?version=1652360619) 失败: 403 Client Error: Forbidden for url: https://www.mdpi.com/1424-8220/22/10/3701/pdf?version=1652360619
2025-11-12 23:09:16,740 - WARNING - root - 【手动下载提示】(无PDF): A Hybrid Attention-Based Deep Neural Network for Simultaneous Multi-Sensor Pruning and Human Activity Recognition
	  URL: https://www.semanticscholar.org/paper/06f82dcfa03d18408410b03b4203fff9bbeceeac
	  Citations: 21 | Authors: Yu Zhou, Zhuo Yang, Xiao Zhang, Yufan Wang | Date: 2022-12-15
2025-11-12 23:09:16,740 - WARNING - root - 【手动下载提示】(无PDF): End-to-End Multilevel Hybrid Attention Framework for Hyperspectral Image Classification
	  URL: https://www.semanticscholar.org/paper/6cbd2101b7faff37d402cc8574c95477af70f3aa
	  Citations: 19 | Authors: Jianhong Xiang, Chen Wei, Minhui Wang, Long Teng | Date: N/A
2025-11-12 23:09:16,741 - WARNING - root - 【手动下载提示】(无PDF): Parallel Deep Learning Algorithms With Hybrid Attention Mechanism for Image Segmentation of Lung Tumors
	  URL: https://www.semanticscholar.org/paper/05c67b073bde463686697eb553576958c8403a60
	  Citations: 87 | Authors: Hexuan Hu, Qingqiu Li, Yun-feng Zhao, Ye Zhang | Date: 2021-04-01
2025-11-12 23:09:16,741 - WARNING - root - 【手动下载提示】(无PDF): Hybrid attention network for semantic segmentation
	  URL: https://www.semanticscholar.org/paper/ee93962e142d4e7fa0b84f5d59970cb30a0b8960
	  Citations: 0 | Authors: Yin Yang, Juan Yang, Ronggui Wang | Date: 2023-10-19
2025-11-12 23:09:16,742 - WARNING - root - 【手动下载提示】(无PDF): A hybrid attention semantic segmentation network for unstructured terrain on Mars
	  URL: https://www.semanticscholar.org/paper/7b71919c1e0adafaa102cf03849b6c21841c8e54
	  Citations: 53 | Authors: Haiqiang Liu, Meibao Yao, Xueming Xiao, Hutao Cui | Date: 2022-08-01
2025-11-12 23:09:16,748 - INFO - root - 正在下载: https://downloads.hindawi.com/journals/wcmc/2022/5441366.pdf
2025-11-12 23:09:26,368 - INFO - root - 正在下载: https://downloads.hindawi.com/journals/wcmc/2022/5441366.pdf
2025-11-12 23:09:35,796 - INFO - root - 正在下载: https://downloads.hindawi.com/journals/wcmc/2022/5441366.pdf
2025-11-12 23:09:45,391 - INFO - root - 正在下载: https://downloads.hindawi.com/journals/wcmc/2022/5441366.pdf
2025-11-12 23:10:00,169 - INFO - root - 正在下载: https://downloads.hindawi.com/journals/wcmc/2022/5441366.pdf
2025-11-12 23:10:05,645 - WARNING - root - 下载 Classification of Diabetic Retinopathy Based on Multiscale Hybrid Attention Mechanism and Residual Algorithm (https://downloads.hindawi.com/journals/wcmc/2022/5441366.pdf) 失败: 403 Client Error: Forbidden for url: https://downloads.hindawi.com/journals/wcmc/2022/5441366.pdf
2025-11-12 23:10:05,647 - INFO - root - 正在下载: http://arxiv.org/pdf/2207.14166
2025-11-12 23:10:13,245 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\hybrid attention\RHA-Net_ An Encoder-Decoder Network with Residual Blocks and Hybrid Attention Mechanisms for Pavemen.pdf
2025-11-12 23:10:13,252 - INFO - root - 成功下载 (Semantic Scholar): RHA-Net: An Encoder-Decoder Network with Residual Blocks and Hybrid Attention Mechanisms for Pavement Crack Segmentation
2025-11-12 23:10:13,255 - INFO - root - 正在下载: https://arxiv.org/pdf/2308.07016
2025-11-12 23:10:14,633 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\hybrid attention\HHTrack_ Hyperspectral Object Tracking Using Hybrid Attention.pdf
2025-11-12 23:10:14,637 - INFO - root - 成功下载 (Semantic Scholar): HHTrack: Hyperspectral Object Tracking Using Hybrid Attention
2025-11-12 23:10:14,637 - WARNING - root - 【手动下载提示】(无PDF): Hybrid attention network for image captioning
	  URL: https://www.semanticscholar.org/paper/45acf57fd885b60d858dc6c49da4ff536a901d67
	  Citations: 22 | Authors: Wenhui Jiang, Qin Li, K. Zhan, Yuming Fang, Fei Shen | Date: 2022-05-01
2025-11-12 23:10:14,638 - INFO - root - 正在下载: https://downloads.hindawi.com/journals/wcmc/2022/3301718.pdf
2025-11-12 23:10:24,093 - INFO - root - 正在下载: https://downloads.hindawi.com/journals/wcmc/2022/3301718.pdf
2025-11-12 23:10:33,538 - INFO - root - 正在下载: https://downloads.hindawi.com/journals/wcmc/2022/3301718.pdf
2025-11-12 23:10:43,346 - INFO - root - 正在下载: https://downloads.hindawi.com/journals/wcmc/2022/3301718.pdf
2025-11-12 23:10:57,173 - INFO - root - 正在下载: https://downloads.hindawi.com/journals/wcmc/2022/3301718.pdf
2025-11-12 23:11:03,051 - WARNING - root - 下载 Malicious Code Classification Method Based on Deep Residual Network and Hybrid Attention Mechanism for Edge Security (https://downloads.hindawi.com/journals/wcmc/2022/3301718.pdf) 失败: 403 Client Error: Forbidden for url: https://downloads.hindawi.com/journals/wcmc/2022/3301718.pdf
2025-11-12 23:11:03,052 - INFO - root - 正在下载: https://www.mdpi.com/2079-9292/11/17/2709/pdf?version=1661780513
2025-11-12 23:11:07,983 - INFO - root - 正在下载: https://www.mdpi.com/2079-9292/11/17/2709/pdf?version=1661780513
2025-11-12 23:11:12,628 - INFO - root - 正在下载: https://www.mdpi.com/2079-9292/11/17/2709/pdf?version=1661780513
2025-11-12 23:11:17,346 - INFO - root - 正在下载: https://www.mdpi.com/2079-9292/11/17/2709/pdf?version=1661780513
2025-11-12 23:11:26,249 - INFO - root - 正在下载: https://www.mdpi.com/2079-9292/11/17/2709/pdf?version=1661780513
2025-11-12 23:11:26,985 - WARNING - root - 下载 Occluded Vehicle Detection via Multi-Scale Hybrid Attention Mechanism in the Road Scene (https://www.mdpi.com/2079-9292/11/17/2709/pdf?version=1661780513) 失败: 403 Client Error: Forbidden for url: https://www.mdpi.com/2079-9292/11/17/2709/pdf?version=1661780513
2025-11-12 23:11:26,987 - INFO - root - 检索到 16 篇论文，开始总结...
2025-11-12 23:11:26,991 - INFO - root - 正在总结论文 1/16: Hybrid Attention Fusion Embedded in Transformer for Remote Sensing Image Semantic Segmentation
2025-11-12 23:11:44,465 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 23:12:39,591 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 23:13:21,011 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 23:13:21,021 - INFO - root - 正在提取论文图片到目录: ./export\hybrid attention\images
2025-11-12 23:13:21,968 - INFO - root - 已保存图片 1/10：./export\hybrid attention\images\figure_1_page12.png
2025-11-12 23:13:22,037 - INFO - root - 已保存图片 2/10：./export\hybrid attention\images\figure_2_page4.png
2025-11-12 23:13:22,108 - INFO - root - 已保存图片 3/10：./export\hybrid attention\images\figure_3_page8.png
2025-11-12 23:13:22,158 - INFO - root - 已保存图片 4/10：./export\hybrid attention\images\figure_4_page12.png
2025-11-12 23:13:22,241 - INFO - root - 已保存图片 5/10：./export\hybrid attention\images\figure_5_page13.png
2025-11-12 23:13:22,284 - INFO - root - 已保存图片 6/10：./export\hybrid attention\images\figure_6_page10.jpeg
2025-11-12 23:13:22,366 - INFO - root - 已保存图片 7/10：./export\hybrid attention\images\figure_7_page13.png
2025-11-12 23:13:22,427 - INFO - root - 已保存图片 8/10：./export\hybrid attention\images\figure_8_page6.png
2025-11-12 23:13:22,468 - INFO - root - 已保存图片 9/10：./export\hybrid attention\images\figure_9_page5.png
2025-11-12 23:13:22,555 - INFO - root - 已保存图片 10/10：./export\hybrid attention\images\figure_10_page2.png
2025-11-12 23:13:22,557 - INFO - root - 成功添加图片 1：./export\hybrid attention\images\figure_1_page12.png
2025-11-12 23:13:22,558 - INFO - root - 成功添加图片 2：./export\hybrid attention\images\figure_2_page4.png
2025-11-12 23:13:22,558 - INFO - root - 成功添加图片 3：./export\hybrid attention\images\figure_3_page8.png
2025-11-12 23:13:22,558 - INFO - root - 成功添加图片 4：./export\hybrid attention\images\figure_4_page12.png
2025-11-12 23:13:22,558 - INFO - root - 成功添加图片 5：./export\hybrid attention\images\figure_5_page13.png
2025-11-12 23:13:22,558 - INFO - root - 成功添加图片 6：./export\hybrid attention\images\figure_6_page10.jpeg
2025-11-12 23:13:22,558 - INFO - root - 成功添加图片 7：./export\hybrid attention\images\figure_7_page13.png
2025-11-12 23:13:22,559 - INFO - root - 成功添加图片 8：./export\hybrid attention\images\figure_8_page6.png
2025-11-12 23:13:22,559 - INFO - root - 成功添加图片 9：./export\hybrid attention\images\figure_9_page5.png
2025-11-12 23:13:22,559 - INFO - root - 成功添加图片 10：./export\hybrid attention\images\figure_10_page2.png
2025-11-12 23:13:22,560 - INFO - root - 已更新图片链接
2025-11-12 23:13:22,570 - INFO - root - 论文《Hybrid Attention Fusion Embedded in Transformer for Remote Sensing Image Semantic Segmentation》的分析已保存到 ./export\hybrid attention\Hybrid Attention Fusion Embedded in Transformer for Remote Sensing Image Semantic Segmentation.md
2025-11-12 23:13:22,572 - INFO - root - 跳过已处理论文 YOLO Algorithm With Hybrid Attention Feature Pyramid Network for Solder Joint Defect Detection：D:\ChatPaper\api_downloads\hybrid attention\YOLO Algorithm With Hybrid Attention Feature Pyramid Network for Solder Joint Defect Detection.pdf
2025-11-12 23:13:22,572 - INFO - root - 跳过已处理论文 Frequency Enhanced Hybrid Attention Network for Sequential Recommendation：D:\ChatPaper\api_downloads\hybrid attention\Frequency Enhanced Hybrid Attention Network for Sequential Recommendation.pdf
2025-11-12 23:13:22,572 - INFO - root - 跳过已处理论文 HAT: Hybrid Attention Transformer for Image Restoration：D:\ChatPaper\api_downloads\hybrid attention\HAT_ Hybrid Attention Transformer for Image Restoration.pdf
2025-11-12 23:13:22,572 - INFO - root - 跳过已处理论文 Multi-scale deep residual shrinkage networks with a hybrid attention mechanism for rolling bearing fault diagnosis：D:\ChatPaper\api_downloads\hybrid attention\Multi-scale deep residual shrinkage networks with a hybrid attention mechanism for rolling bearing f.pdf
2025-11-12 23:13:22,580 - INFO - root - 跳过已处理论文 Physics Inspired Hybrid Attention for SAR Target Recognition：D:\ChatPaper\api_downloads\hybrid attention\Physics Inspired Hybrid Attention for SAR Target Recognition.pdf
2025-11-12 23:13:22,583 - INFO - root - 跳过已处理论文 Fine-grained image classification method based on hybrid attention module：D:\ChatPaper\api_downloads\hybrid attention\Fine-grained image classification method based on hybrid attention module.pdf
2025-11-12 23:13:22,586 - INFO - root - 跳过已处理论文 Text-Conditioned Outfit Recommendation With Hybrid Attention Layer：D:\ChatPaper\api_downloads\hybrid attention\Text-Conditioned Outfit Recommendation With Hybrid Attention Layer.pdf
2025-11-12 23:13:22,588 - INFO - root - 跳过已处理论文 Hybrid Attention-Based Prototypical Networks for Noisy Few-Shot Relation Classification：D:\ChatPaper\api_downloads\hybrid attention\Hybrid Attention-Based Prototypical Networks for Noisy Few-Shot Relation Classification.pdf
2025-11-12 23:13:22,589 - INFO - root - 跳过已处理论文 Dual-view Correlation Hybrid Attention Network for Robust Holistic Mammogram Classification：D:\ChatPaper\api_downloads\hybrid attention\Dual-view Correlation Hybrid Attention Network for Robust Holistic Mammogram Classification.pdf
2025-11-12 23:13:22,590 - INFO - root - 正在总结论文 11/16: Stacked Hybrid-Attention and Group Collaborative Learning for Unbiased Scene Graph Generation
2025-11-12 23:13:33,625 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 23:13:33,629 - INFO - root - LLMClient: rate limit reached, sleeping 6.0s
2025-11-12 23:14:48,704 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 23:15:24,512 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 23:15:24,515 - INFO - root - 正在提取论文图片到目录: ./export\hybrid attention\images
2025-11-12 23:15:25,410 - INFO - root - 已保存图片 1/10：./export\hybrid attention\images\figure_1_page1.png
2025-11-12 23:15:25,484 - INFO - root - 已保存图片 2/10：./export\hybrid attention\images\figure_2_page1.png
2025-11-12 23:15:25,549 - INFO - root - 已保存图片 3/10：./export\hybrid attention\images\figure_3_page3.jpeg
2025-11-12 23:15:25,608 - INFO - root - 已保存图片 4/10：./export\hybrid attention\images\figure_4_page13.jpeg
2025-11-12 23:15:25,666 - INFO - root - 已保存图片 5/10：./export\hybrid attention\images\figure_5_page1.png
2025-11-12 23:15:25,729 - INFO - root - 已保存图片 6/10：./export\hybrid attention\images\figure_6_page13.jpeg
2025-11-12 23:15:25,821 - INFO - root - 已保存图片 7/10：./export\hybrid attention\images\figure_7_page13.jpeg
2025-11-12 23:15:25,892 - INFO - root - 已保存图片 8/10：./export\hybrid attention\images\figure_8_page1.png
2025-11-12 23:15:25,958 - INFO - root - 已保存图片 9/10：./export\hybrid attention\images\figure_9_page5.png
2025-11-12 23:15:26,012 - INFO - root - 已保存图片 10/10：./export\hybrid attention\images\figure_10_page5.png
2025-11-12 23:15:26,110 - INFO - root - 成功添加图片 1：./export\hybrid attention\images\figure_1_page1.png
2025-11-12 23:15:26,122 - INFO - root - 成功添加图片 2：./export\hybrid attention\images\figure_2_page1.png
2025-11-12 23:15:26,162 - INFO - root - 成功添加图片 3：./export\hybrid attention\images\figure_3_page3.jpeg
2025-11-12 23:15:26,178 - INFO - root - 成功添加图片 4：./export\hybrid attention\images\figure_4_page13.jpeg
2025-11-12 23:15:26,181 - INFO - root - 成功添加图片 5：./export\hybrid attention\images\figure_5_page1.png
2025-11-12 23:15:26,182 - INFO - root - 成功添加图片 6：./export\hybrid attention\images\figure_6_page13.jpeg
2025-11-12 23:15:26,183 - INFO - root - 成功添加图片 7：./export\hybrid attention\images\figure_7_page13.jpeg
2025-11-12 23:15:26,184 - INFO - root - 成功添加图片 8：./export\hybrid attention\images\figure_8_page1.png
2025-11-12 23:15:26,184 - INFO - root - 成功添加图片 9：./export\hybrid attention\images\figure_9_page5.png
2025-11-12 23:15:26,185 - INFO - root - 成功添加图片 10：./export\hybrid attention\images\figure_10_page5.png
2025-11-12 23:15:26,186 - INFO - root - 已更新图片链接
2025-11-12 23:15:26,196 - INFO - root - 论文《Stacked Hybrid-Attention and Group Collaborative Learning for Unbiased Scene Graph Generation》的分析已保存到 ./export\hybrid attention\Stacked Hybrid-Attention and Group Collaborative Learning for Unbiased Scene Graph Generation.md
2025-11-12 23:15:26,230 - INFO - root - 正在总结论文 12/16: Hybridformer: Improving Squeezeformer with Hybrid Attention and NSR Mechanism
2025-11-12 23:15:42,426 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 23:15:42,427 - INFO - root - LLMClient: rate limit reached, sleeping 6.3s
2025-11-12 23:16:52,345 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 23:17:27,010 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 23:17:27,013 - INFO - root - 正在提取论文图片到目录: ./export\hybrid attention\images
2025-11-12 23:17:27,245 - INFO - root - 已保存图片 1/10：./export\hybrid attention\images\figure_1_page2.png
2025-11-12 23:17:27,310 - INFO - root - 已保存图片 2/10：./export\hybrid attention\images\figure_2_page3.png
2025-11-12 23:17:27,372 - INFO - root - 已保存图片 3/10：./export\hybrid attention\images\figure_3_page4.png
2025-11-12 23:17:27,450 - INFO - root - 已保存图片 4/10：./export\hybrid attention\images\figure_4_page3.png
2025-11-12 23:17:27,451 - INFO - root - 成功添加图片 1：./export\hybrid attention\images\figure_1_page2.png
2025-11-12 23:17:27,452 - INFO - root - 成功添加图片 2：./export\hybrid attention\images\figure_2_page3.png
2025-11-12 23:17:27,452 - INFO - root - 成功添加图片 3：./export\hybrid attention\images\figure_3_page4.png
2025-11-12 23:17:27,452 - INFO - root - 成功添加图片 4：./export\hybrid attention\images\figure_4_page3.png
2025-11-12 23:17:27,452 - INFO - root - 已更新图片链接
2025-11-12 23:17:27,456 - INFO - root - 论文《Hybridformer: Improving Squeezeformer with Hybrid Attention and NSR Mechanism》的分析已保存到 ./export\hybrid attention\Hybridformer_ Improving Squeezeformer with Hybrid Attention and NSR Mechanism.md
2025-11-12 23:17:27,465 - INFO - root - 正在总结论文 13/16: HAC-Net: A Hybrid Attention-Based Convolutional Neural Network for Highly Accurate Protein-Ligand Binding Affinity Prediction
2025-11-12 23:17:42,288 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 23:17:42,293 - INFO - root - LLMClient: rate limit reached, sleeping 10.1s
2025-11-12 23:18:48,911 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 23:19:28,210 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 23:19:28,213 - INFO - root - 正在提取论文图片到目录: ./export\hybrid attention\images
2025-11-12 23:19:28,387 - INFO - root - 已保存图片 1/10：./export\hybrid attention\images\figure_1_page22.jpeg
2025-11-12 23:19:28,439 - INFO - root - 已保存图片 2/10：./export\hybrid attention\images\figure_2_page9.jpeg
2025-11-12 23:19:28,483 - INFO - root - 已保存图片 3/10：./export\hybrid attention\images\figure_3_page5.jpeg
2025-11-12 23:19:28,530 - INFO - root - 已保存图片 4/10：./export\hybrid attention\images\figure_4_page3.jpeg
2025-11-12 23:19:28,591 - INFO - root - 已保存图片 5/10：./export\hybrid attention\images\figure_5_page21.png
2025-11-12 23:19:28,640 - INFO - root - 已保存图片 6/10：./export\hybrid attention\images\figure_6_page27.jpeg
2025-11-12 23:19:28,691 - INFO - root - 已保存图片 7/10：./export\hybrid attention\images\figure_7_page6.jpeg
2025-11-12 23:19:28,727 - INFO - root - 已保存图片 8/10：./export\hybrid attention\images\figure_8_page24.jpeg
2025-11-12 23:19:28,757 - INFO - root - 已保存图片 9/10：./export\hybrid attention\images\figure_9_page25.jpeg
2025-11-12 23:19:28,833 - INFO - root - 已保存图片 10/10：./export\hybrid attention\images\figure_10_page26.jpeg
2025-11-12 23:19:28,839 - INFO - root - 成功添加图片 1：./export\hybrid attention\images\figure_1_page22.jpeg
2025-11-12 23:19:28,840 - INFO - root - 成功添加图片 2：./export\hybrid attention\images\figure_2_page9.jpeg
2025-11-12 23:19:28,840 - INFO - root - 成功添加图片 3：./export\hybrid attention\images\figure_3_page5.jpeg
2025-11-12 23:19:28,841 - INFO - root - 成功添加图片 4：./export\hybrid attention\images\figure_4_page3.jpeg
2025-11-12 23:19:28,842 - INFO - root - 成功添加图片 5：./export\hybrid attention\images\figure_5_page21.png
2025-11-12 23:19:28,842 - INFO - root - 成功添加图片 6：./export\hybrid attention\images\figure_6_page27.jpeg
2025-11-12 23:19:28,843 - INFO - root - 成功添加图片 7：./export\hybrid attention\images\figure_7_page6.jpeg
2025-11-12 23:19:28,843 - INFO - root - 成功添加图片 8：./export\hybrid attention\images\figure_8_page24.jpeg
2025-11-12 23:19:28,844 - INFO - root - 成功添加图片 9：./export\hybrid attention\images\figure_9_page25.jpeg
2025-11-12 23:19:28,844 - INFO - root - 成功添加图片 10：./export\hybrid attention\images\figure_10_page26.jpeg
2025-11-12 23:19:28,844 - INFO - root - 已更新图片链接
2025-11-12 23:19:28,856 - INFO - root - 论文《HAC-Net: A Hybrid Attention-Based Convolutional Neural Network for Highly Accurate Protein-Ligand Binding Affinity Prediction》的分析已保存到 ./export\hybrid attention\HAC-Net_ A Hybrid Attention-Based Convolutional Neural Network for Highly Accurate Protein-Ligand Bi.md
2025-11-12 23:19:28,858 - INFO - root - 正在总结论文 14/16: A Hybrid Attention Mechanism for Weakly-Supervised Temporal Action Localization
2025-11-12 23:19:42,588 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 23:19:42,591 - INFO - root - LLMClient: rate limit reached, sleeping 6.3s
2025-11-12 23:21:15,561 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 23:22:02,460 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 23:22:02,461 - INFO - root - 正在提取论文图片到目录: ./export\hybrid attention\images
2025-11-12 23:22:02,906 - INFO - root - 已保存图片 1/10：./export\hybrid attention\images\figure_1_page3.png
2025-11-12 23:22:02,952 - INFO - root - 已保存图片 2/10：./export\hybrid attention\images\figure_2_page3.png
2025-11-12 23:22:02,994 - INFO - root - 已保存图片 3/10：./export\hybrid attention\images\figure_3_page3.png
2025-11-12 23:22:03,046 - INFO - root - 已保存图片 4/10：./export\hybrid attention\images\figure_4_page3.png
2025-11-12 23:22:03,095 - INFO - root - 已保存图片 5/10：./export\hybrid attention\images\figure_5_page3.png
2025-11-12 23:22:03,165 - INFO - root - 已保存图片 6/10：./export\hybrid attention\images\figure_6_page3.png
2025-11-12 23:22:03,220 - INFO - root - 已保存图片 7/10：./export\hybrid attention\images\figure_7_page6.png
2025-11-12 23:22:03,258 - INFO - root - 已保存图片 8/10：./export\hybrid attention\images\figure_8_page7.png
2025-11-12 23:22:03,305 - INFO - root - 已保存图片 9/10：./export\hybrid attention\images\figure_9_page7.png
2025-11-12 23:22:03,411 - INFO - root - 已保存图片 10/10：./export\hybrid attention\images\figure_10_page1.png
2025-11-12 23:22:03,411 - INFO - root - 成功添加图片 1：./export\hybrid attention\images\figure_1_page3.png
2025-11-12 23:22:03,411 - INFO - root - 成功添加图片 2：./export\hybrid attention\images\figure_2_page3.png
2025-11-12 23:22:03,411 - INFO - root - 成功添加图片 3：./export\hybrid attention\images\figure_3_page3.png
2025-11-12 23:22:03,411 - INFO - root - 成功添加图片 4：./export\hybrid attention\images\figure_4_page3.png
2025-11-12 23:22:03,411 - INFO - root - 成功添加图片 5：./export\hybrid attention\images\figure_5_page3.png
2025-11-12 23:22:03,411 - INFO - root - 成功添加图片 6：./export\hybrid attention\images\figure_6_page3.png
2025-11-12 23:22:03,411 - INFO - root - 成功添加图片 7：./export\hybrid attention\images\figure_7_page6.png
2025-11-12 23:22:03,419 - INFO - root - 成功添加图片 8：./export\hybrid attention\images\figure_8_page7.png
2025-11-12 23:22:03,419 - INFO - root - 成功添加图片 9：./export\hybrid attention\images\figure_9_page7.png
2025-11-12 23:22:03,420 - INFO - root - 成功添加图片 10：./export\hybrid attention\images\figure_10_page1.png
2025-11-12 23:22:03,420 - INFO - root - 已更新图片链接
2025-11-12 23:22:03,428 - INFO - root - 论文《A Hybrid Attention Mechanism for Weakly-Supervised Temporal Action Localization》的分析已保存到 ./export\hybrid attention\A Hybrid Attention Mechanism for Weakly-Supervised Temporal Action Localization.md
2025-11-12 23:22:03,431 - INFO - root - 正在总结论文 15/16: RHA-Net: An Encoder-Decoder Network with Residual Blocks and Hybrid Attention Mechanisms for Pavement Crack Segmentation
2025-11-12 23:22:16,878 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 23:23:15,354 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 23:23:54,441 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 23:23:54,441 - INFO - root - 正在提取论文图片到目录: ./export\hybrid attention\images
2025-11-12 23:23:58,193 - INFO - root - 已保存图片 1/10：./export\hybrid attention\images\figure_1_page8.jpeg
2025-11-12 23:23:58,269 - INFO - root - 已保存图片 2/10：./export\hybrid attention\images\figure_2_page8.jpeg
2025-11-12 23:23:58,344 - INFO - root - 已保存图片 3/10：./export\hybrid attention\images\figure_3_page8.jpeg
2025-11-12 23:23:58,412 - INFO - root - 已保存图片 4/10：./export\hybrid attention\images\figure_4_page8.jpeg
2025-11-12 23:23:58,449 - INFO - root - 已保存图片 5/10：./export\hybrid attention\images\figure_5_page7.png
2025-11-12 23:23:58,511 - INFO - root - 已保存图片 6/10：./export\hybrid attention\images\figure_6_page11.png
2025-11-12 23:23:58,543 - INFO - root - 已保存图片 7/10：./export\hybrid attention\images\figure_7_page7.png
2025-11-12 23:23:58,576 - INFO - root - 已保存图片 8/10：./export\hybrid attention\images\figure_8_page7.png
2025-11-12 23:23:58,611 - INFO - root - 已保存图片 9/10：./export\hybrid attention\images\figure_9_page7.png
2025-11-12 23:23:58,642 - INFO - root - 已保存图片 10/10：./export\hybrid attention\images\figure_10_page7.png
2025-11-12 23:23:58,646 - INFO - root - 成功添加图片 1：./export\hybrid attention\images\figure_1_page8.jpeg
2025-11-12 23:23:58,649 - INFO - root - 成功添加图片 2：./export\hybrid attention\images\figure_2_page8.jpeg
2025-11-12 23:23:58,651 - INFO - root - 成功添加图片 3：./export\hybrid attention\images\figure_3_page8.jpeg
2025-11-12 23:23:58,652 - INFO - root - 成功添加图片 4：./export\hybrid attention\images\figure_4_page8.jpeg
2025-11-12 23:23:58,653 - INFO - root - 成功添加图片 5：./export\hybrid attention\images\figure_5_page7.png
2025-11-12 23:23:58,655 - INFO - root - 成功添加图片 6：./export\hybrid attention\images\figure_6_page11.png
2025-11-12 23:23:58,655 - INFO - root - 成功添加图片 7：./export\hybrid attention\images\figure_7_page7.png
2025-11-12 23:23:58,656 - INFO - root - 成功添加图片 8：./export\hybrid attention\images\figure_8_page7.png
2025-11-12 23:23:58,656 - INFO - root - 成功添加图片 9：./export\hybrid attention\images\figure_9_page7.png
2025-11-12 23:23:58,657 - INFO - root - 成功添加图片 10：./export\hybrid attention\images\figure_10_page7.png
2025-11-12 23:23:58,658 - INFO - root - 已更新图片链接
2025-11-12 23:23:58,662 - INFO - root - 论文《RHA-Net: An Encoder-Decoder Network with Residual Blocks and Hybrid Attention Mechanisms for Pavement Crack Segmentation》的分析已保存到 ./export\hybrid attention\RHA-Net_ An Encoder-Decoder Network with Residual Blocks and Hybrid Attention Mechanisms for Pavemen.md
2025-11-12 23:23:58,674 - INFO - root - 正在总结论文 16/16: HHTrack: Hyperspectral Object Tracking Using Hybrid Attention
2025-11-12 23:24:13,992 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 23:24:13,992 - INFO - root - LLMClient: rate limit reached, sleeping 1.4s
2025-11-12 23:25:09,738 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 23:25:50,992 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 23:25:50,994 - INFO - root - 正在提取论文图片到目录: ./export\hybrid attention\images
2025-11-12 23:25:51,135 - INFO - root - 已保存图片 1/10：./export\hybrid attention\images\figure_1_page2.png
2025-11-12 23:25:51,169 - INFO - root - 已保存图片 2/10：./export\hybrid attention\images\figure_2_page2.jpeg
2025-11-12 23:25:51,204 - INFO - root - 已保存图片 3/10：./export\hybrid attention\images\figure_3_page4.jpeg
2025-11-12 23:25:51,205 - INFO - root - 成功添加图片 1：./export\hybrid attention\images\figure_1_page2.png
2025-11-12 23:25:51,207 - INFO - root - 成功添加图片 2：./export\hybrid attention\images\figure_2_page2.jpeg
2025-11-12 23:25:51,207 - INFO - root - 成功添加图片 3：./export\hybrid attention\images\figure_3_page4.jpeg
2025-11-12 23:25:51,208 - INFO - root - 已更新图片链接
2025-11-12 23:25:51,214 - INFO - root - 论文《HHTrack: Hyperspectral Object Tracking Using Hybrid Attention》的分析已保存到 ./export\hybrid attention\HHTrack_ Hyperspectral Object Tracking Using Hybrid Attention.md
2025-11-12 23:25:51,251 - INFO - root - 未找到旧 Excel 文件。正在创建新文件: export\hybrid_attention_summary.xlsx
2025-11-12 23:25:51,308 - INFO - root - 成功保存 Excel: export\hybrid_attention_summary.xlsx
2025-11-12 23:25:51,313 - INFO - root - 已生成汇总Excel表格: export\hybrid_attention_summary.xlsx
2025-11-12 23:25:51,313 - INFO - root - 总运行时间: 1505.85 seconds
2025-11-12 23:47:59,401 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-12 23:47:59,401 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-12 23:47:59,403 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-12 23:48:03,548 - INFO - root - LLMClientManager: 指定使用客户端: Deepseek
2025-11-12 23:48:03,550 - INFO - root - DeepSeekClient: API key found: 9f9e270e-b...
2025-11-12 23:48:03,550 - INFO - root - DeepSeekClient: 使用模式: 火山引擎
2025-11-12 23:48:03,550 - INFO - root - DeepSeekClient: 模型名称: deepseek-v3-1-terminus
2025-11-12 23:48:07,857 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 23:48:07,897 - INFO - root - DeepSeekClient: initialized successfully with model deepseek-v3-1-terminus
2025-11-12 23:48:07,897 - INFO - root - LLMClientManager: DeepSeek 客户端初始化成功
2025-11-12 23:48:07,897 - INFO - root - LLMClientManager: switched to DeepSeek client (case-insensitive match)
2025-11-12 23:48:07,906 - INFO - root - 已手动切换到 LLM 客户端: Deepseek
2025-11-12 23:48:07,907 - INFO - root - 使用 LLM 模型: deepseek-v3-1-terminus
2025-11-12 23:48:07,908 - INFO - root - 可用客户端: ['DeepSeek']
2025-11-12 23:48:07,908 - INFO - root - === 运行配置 ===
2025-11-12 23:48:07,908 - INFO - root - 处理模式: Semantic Scholar 高引用搜索 (API)
2025-11-12 23:48:07,909 - INFO - root - 查询 (关键词): hybrid attention
2025-11-12 23:48:07,911 - INFO - root - 关键词 (用于保存): hybrid attention
2025-11-12 23:48:07,911 - INFO - root - 排序: citationCount:desc
2025-11-12 23:48:07,911 - INFO - root - 最大处理数量: 90
2025-11-12 23:48:07,914 - INFO - root - 保存图片: 是
2025-11-12 23:48:08,118 - INFO - root - 输出语言: 中文
2025-11-12 23:48:08,191 - INFO - root - 强制重新处理: 否
2025-11-12 23:48:08,197 - INFO - root - LLM 客户端: Deepseek
2025-11-12 23:48:08,225 - INFO - root - ====================
2025-11-12 23:48:08,243 - INFO - root - 正在使用检索策略: semantic
2025-11-12 23:48:08,259 - INFO - root - 使用 Semantic Scholar 高引用搜索模式 (API)
2025-11-12 23:48:08,281 - INFO - root - Semantic API 查询: query=hybrid attention, limit=90, sort=citationCount:desc
2025-11-12 23:48:08,297 - INFO - root - 正在调用 Semantic Scholar API...
2025-11-12 23:48:15,828 - WARNING - root - 【手动下载提示】(无PDF): An Instrument Indication Acquisition Algorithm Based on Lightweight Deep Convolutional Neural Network and Hybrid Attention Fine-Grained Features
	  URL: https://www.semanticscholar.org/paper/49f99d7a21e2ded7915676753a180983763b9a22
	  Citations: 66 | Authors: Jiaquan Shen, Ningzhong Liu, Han Sun, Deguang Li, Yongxin Zhang | Date: N/A
2025-11-12 23:48:15,837 - WARNING - root - 【手动下载提示】(无PDF): Dual-Hybrid Attention Network for Specular Highlight Removal
	  URL: https://www.semanticscholar.org/paper/d56ce689cc0f8b1cf0e5f58882503a5e59ec440b
	  Citations: 33 | Authors: Xiaojiao Guo, Xuhang Chen, Shenghong Luo, Shuqiang Wang, Chi-Man Pun | Date: 2024-07-17
2025-11-12 23:48:15,843 - WARNING - root - 【手动下载提示】(无PDF): Enhancing ASD classification through hybrid attention-based learning of facial features
	  URL: https://www.semanticscholar.org/paper/22547aa4c72c7c2799932a0f451ab3f2db6d7d0f
	  Citations: 35 | Authors: Inzamam Shahzad, Saif Ur Rehman Khan, Waseem Abbas, Z. U. Abideen, Jin Liu | Date: 2024-04-21
2025-11-12 23:48:15,851 - WARNING - root - 【手动下载提示】(无PDF): HyA-GAN: remote sensing image cloud removal based on hybrid attention generation adversarial network
	  URL: https://www.semanticscholar.org/paper/905b42f2f8d912d98fd7cbec4f7b244401176acc
	  Citations: 16 | Authors: Minghao Jin, Pengwei Wang, Yusong Li | Date: 2024-02-27
2025-11-12 23:48:15,860 - WARNING - root - 【手动下载提示】(无PDF): Hybrid Attention-Aware Transformer Network Collaborative Multiscale Feature Alignment for Building Change Detection
	  URL: https://www.semanticscholar.org/paper/a0f8053046622628073ac6f051b5181a80cb7ad3
	  Citations: 28 | Authors: Chuan Xu, Zhaoyi Ye, Liye Mei, Haonan Yu, Jianchen Liu, Yaxiaer Yalikun, Shuangtong Jin, Sheng Liu, Wei Yang, Cheng Lei | Date: N/A
2025-11-12 23:48:15,872 - WARNING - root - 【手动下载提示】(无PDF): Radar Signal Recognition Based on CNN With a Hybrid Attention Mechanism and Skip Feature Aggregation
	  URL: https://www.semanticscholar.org/paper/dacad703c49e9434321c91220219638f871fd9d2
	  Citations: 25 | Authors: Yuanpu Guo, Haixin Sun, Hui Liu, Zhen-miao Deng | Date: N/A
2025-11-12 23:48:15,887 - WARNING - root - 【手动下载提示】(无PDF): Probabilistic Multienergy Load Forecasting Based on Hybrid Attention-Enabled Transformer Network and Gaussian Process-Aided Residual Learning
	  URL: https://www.semanticscholar.org/paper/a2d81cc04f73e2898fb16e7e8c8f9cf69adadfd5
	  Citations: 16 | Authors: Pengfei Zhao, Weihao Hu, Di Cao, Zhenyuan Zhang, Yuehui Huang, Longcheng Dai, Zhe Chen | Date: 2024-06-01
2025-11-12 23:48:15,915 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\hybrid attention\Hybrid Attention Fusion Embedded in Transformer for Remote Sensing Image Semantic Segmentation.pdf
2025-11-12 23:48:15,931 - INFO - root - 成功下载 (Semantic Scholar): Hybrid Attention Fusion Embedded in Transformer for Remote Sensing Image Semantic Segmentation
2025-11-12 23:48:15,967 - INFO - root - 正在下载: https://www.mdpi.com/2306-5354/11/3/240/pdf?version=1709132347
2025-11-12 23:48:25,539 - INFO - root - 正在下载: https://www.mdpi.com/2306-5354/11/3/240/pdf?version=1709132347
2025-11-12 23:48:34,994 - INFO - root - 正在下载: https://www.mdpi.com/2306-5354/11/3/240/pdf?version=1709132347
2025-11-12 23:48:44,704 - INFO - root - 正在下载: https://www.mdpi.com/2306-5354/11/3/240/pdf?version=1709132347
2025-11-12 23:48:59,503 - INFO - root - 正在下载: https://www.mdpi.com/2306-5354/11/3/240/pdf?version=1709132347
2025-11-12 23:49:04,892 - WARNING - root - 下载 Advancing Ocular Imaging: A Hybrid Attention Mechanism-Based U-Net Model for Precise Segmentation of Sub-Retinal Layers in OCT Images (https://www.mdpi.com/2306-5354/11/3/240/pdf?version=1709132347) 失败: 403 Client Error: Forbidden for url: https://www.mdpi.com/2306-5354/11/3/240/pdf?version=1709132347
2025-11-12 23:49:04,892 - WARNING - root - 【手动下载提示】(无PDF): Enhancing Time Series Product Demand Forecasting With Hybrid Attention-Based Deep Learning Models
	  URL: https://www.semanticscholar.org/paper/4848b35cbe515f8909a67a82dcb83d7c5e48f74b
	  Citations: 14 | Authors: Xuguang Zhang, Pan Li, Xu Han, Yongbin Yang, Yiwen Cui | Date: N/A
2025-11-12 23:49:04,892 - WARNING - root - 【手动下载提示】(无PDF): A novel approach for bearings multiclass fault diagnosis fusing multiscale deep convolution and hybrid attention networks
	  URL: https://www.semanticscholar.org/paper/bf72523fe518b2e4ce4d75d125dd5220177043f6
	  Citations: 13 | Authors: Fule Li, Xinlong Zhao | Date: 2024-01-08
2025-11-12 23:49:04,893 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\hybrid attention\YOLO Algorithm With Hybrid Attention Feature Pyramid Network for Solder Joint Defect Detection.pdf
2025-11-12 23:49:04,893 - INFO - root - 成功下载 (Semantic Scholar): YOLO Algorithm With Hybrid Attention Feature Pyramid Network for Solder Joint Defect Detection
2025-11-12 23:49:04,894 - WARNING - root - 【手动下载提示】(无PDF): Drone-HAT: Hybrid Attention Transformer for Complex Action Recognition in Drone Surveillance Videos
	  URL: https://www.semanticscholar.org/paper/a76690fb96dc7d3dfd5f8fec62c3949cc7ec96f6
	  Citations: 12 | Authors: Mustaqeem Khan, Jamil Ahmad, Abdulmotaleb El-Saddik, W. Gueaieb, Giulia De Masi, Fakhri Karray | Date: 2024-06-17
2025-11-12 23:49:04,894 - WARNING - root - 【手动下载提示】(无PDF): Dense Hybrid Attention Network for Palmprint Image Super-Resolution
	  URL: https://www.semanticscholar.org/paper/75746d8d52509b24d9975d9b3b07ae91311dc7ed
	  Citations: 12 | Authors: Yao Wang, Lunke Fei, Shuping Zhao, Qi Zhu, Jie Wen, Wei Jia, Imad Rida | Date: 2024-04-01
2025-11-12 23:49:04,896 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\hybrid attention\Frequency Enhanced Hybrid Attention Network for Sequential Recommendation.pdf
2025-11-12 23:49:04,896 - INFO - root - 成功下载 (Semantic Scholar): Frequency Enhanced Hybrid Attention Network for Sequential Recommendation
2025-11-12 23:49:04,897 - WARNING - root - 【手动下载提示】(无PDF): Hybrid Attention Feature Refinement Network for Lightweight Image Super-Resolution in Metaverse Immersive Display
	  URL: https://www.semanticscholar.org/paper/c4d95a47eec1a23320d60dd95848d41e10820ee4
	  Citations: 10 | Authors: Kexin Wang, Xiaomin Yang, Gwanggil Jeon | Date: 2024-02-01
2025-11-12 23:49:04,897 - WARNING - root - 【手动下载提示】(无PDF): A Multiscale Hybrid Attention Networks Based on Multiview Images for the Diagnosis of Parkinson’s Disease
	  URL: https://www.semanticscholar.org/paper/b2af0577ee8ac56b527bd108ce57755a4a4b04e7
	  Citations: 11 | Authors: Xinchun Cui, Youshi Zhou, Chao Zhao, Jianlong Li, Xiangwei Zheng, Xiuli Li, Shixiao Shan, JinXing Liu, Xiaoli Liu | Date: N/A
2025-11-12 23:49:04,899 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\hybrid attention\HAT_ Hybrid Attention Transformer for Image Restoration.pdf
2025-11-12 23:49:04,900 - INFO - root - 成功下载 (Semantic Scholar): HAT: Hybrid Attention Transformer for Image Restoration
2025-11-12 23:49:04,901 - INFO - root - 正在下载: https://www.mdpi.com/2076-3417/14/3/1293/pdf?version=1707037901
2025-11-12 23:49:14,323 - INFO - root - 正在下载: https://www.mdpi.com/2076-3417/14/3/1293/pdf?version=1707037901
2025-11-12 23:49:24,400 - INFO - root - 正在下载: https://www.mdpi.com/2076-3417/14/3/1293/pdf?version=1707037901
2025-11-12 23:49:34,108 - INFO - root - 正在下载: https://www.mdpi.com/2076-3417/14/3/1293/pdf?version=1707037901
2025-11-12 23:49:49,038 - INFO - root - 正在下载: https://www.mdpi.com/2076-3417/14/3/1293/pdf?version=1707037901
2025-11-12 23:49:54,732 - WARNING - root - 下载 Dual Hybrid Attention Mechanism-Based U-Net for Building Segmentation in Remote Sensing Images (https://www.mdpi.com/2076-3417/14/3/1293/pdf?version=1707037901) 失败: 403 Client Error: Forbidden for url: https://www.mdpi.com/2076-3417/14/3/1293/pdf?version=1707037901
2025-11-12 23:49:54,733 - WARNING - root - 【手动下载提示】(无PDF): Abundance Matrix Correlation Analysis Network Based on Hierarchical Multihead Self-Cross-Hybrid Attention for Hyperspectral Change Detection
	  URL: https://www.semanticscholar.org/paper/6aae02a41656cecba872b29bb3d71c414a58f57b
	  Citations: 66 | Authors: Wenqian Dong, Jing Zhao, Jiahui Qu, Song Xiao, Nan Li, Shaoxiong Hou, Yunsong Li | Date: N/A
2025-11-12 23:49:54,733 - WARNING - root - 【手动下载提示】(无PDF): Hybrid Attention Module and Transformer Based Fuze DRFM Jamming Signal Recognition
	  URL: https://www.semanticscholar.org/paper/0fb8059c6aaf0c86c9e9a623fa1ad73d0f737c37
	  Citations: 7 | Authors: Jikai Yang, Zhiquan Bai, Zhaoxia Xian, Hongwu Xiang, Jingxin Li, Huili Hu, Jian Dai, Xinhong Hao | Date: 2024-09-01
2025-11-12 23:49:54,733 - WARNING - root - 【手动下载提示】(无PDF): HA-Net: a SAR image ship detector based on hybrid attention
	  URL: https://www.semanticscholar.org/paper/4c40b6f75ab19e1402ae88e38013a64c504c3a80
	  Citations: 6 | Authors: Shouwen Cai, Hao Meng, Ming Yuan, Fei Gao | Date: 2024-06-10
2025-11-12 23:49:54,734 - WARNING - root - 【手动下载提示】(无PDF): Deep Hashing Network With Hybrid Attention and Adaptive Weighting for Image Retrieval
	  URL: https://www.semanticscholar.org/paper/1c688a4da1c546ea783f5743c371732ace568498
	  Citations: 7 | Authors: Yingjiao Pei, Zhongyuan Wang, Na Li, Heling Chen, Baojin Huang, Weiping Tu | Date: N/A
2025-11-12 23:49:54,734 - WARNING - root - 【手动下载提示】(无PDF): Towards Effective Author Name Disambiguation by Hybrid Attention
	  URL: https://www.semanticscholar.org/paper/fc2dcb9e544a0aaad3034a61eaf0563a79c65cbf
	  Citations: 6 | Authors: Qian Zhou, Wei Chen, Peng-Peng Zhao, An Liu, Jia-Jie Xu, Jian-Feng Qu, Lei Zhao | Date: 2024-07-01
2025-11-12 23:49:54,734 - WARNING - root - 【手动下载提示】(无PDF): Multi-modal bilinear fusion with hybrid attention mechanism for multi-label skin lesion classification
	  URL: https://www.semanticscholar.org/paper/2a89c443cf8b93abc7413ee32257f66fad5af684
	  Citations: 7 | Authors: Yun Wei, Lin Ji | Date: 2024-01-15
2025-11-12 23:49:54,735 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\hybrid attention\Multi-scale deep residual shrinkage networks with a hybrid attention mechanism for rolling bearing f.pdf
2025-11-12 23:49:54,736 - INFO - root - 成功下载 (Semantic Scholar): Multi-scale deep residual shrinkage networks with a hybrid attention mechanism for rolling bearing fault diagnosis
2025-11-12 23:49:54,736 - WARNING - root - 【手动下载提示】(无PDF): Actor-Hybrid-Attention-Critic for Multi-Logistic Robots Path Planning
	  URL: https://www.semanticscholar.org/paper/5260da08f9f524b8fa77a37e2884b22804a47c6a
	  Citations: 6 | Authors: Chunjie Yang, Bodi Yuan, Pengzhao Zhai | Date: 2024-06-01
2025-11-12 23:49:54,737 - INFO - root - 正在下载: https://www.mdpi.com/2306-5354/10/6/714/pdf?version=1686635187
2025-11-12 23:50:04,418 - INFO - root - 正在下载: https://www.mdpi.com/2306-5354/10/6/714/pdf?version=1686635187
2025-11-12 23:50:14,088 - INFO - root - 正在下载: https://www.mdpi.com/2306-5354/10/6/714/pdf?version=1686635187
2025-11-12 23:50:23,682 - INFO - root - 正在下载: https://www.mdpi.com/2306-5354/10/6/714/pdf?version=1686635187
2025-11-12 23:50:37,108 - INFO - root - 正在下载: https://www.mdpi.com/2306-5354/10/6/714/pdf?version=1686635187
2025-11-12 23:50:42,557 - WARNING - root - 下载 AHANet: Adaptive Hybrid Attention Network for Alzheimer’s Disease Classification Using Brain Magnetic Resonance Imaging (https://www.mdpi.com/2306-5354/10/6/714/pdf?version=1686635187) 失败: 403 Client Error: Forbidden for url: https://www.mdpi.com/2306-5354/10/6/714/pdf?version=1686635187
2025-11-12 23:50:42,559 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\hybrid attention\Physics Inspired Hybrid Attention for SAR Target Recognition.pdf
2025-11-12 23:50:42,559 - INFO - root - 成功下载 (Semantic Scholar): Physics Inspired Hybrid Attention for SAR Target Recognition
2025-11-12 23:50:42,561 - WARNING - root - 【手动下载提示】(无PDF): WHEN: A Wavelet-DTW Hybrid Attention Network for Heterogeneous Time Series Analysis
	  URL: https://www.semanticscholar.org/paper/c2e57a1926217f67a72c617d09fa12ec8e667d0e
	  Citations: 33 | Authors: Jingyuan Wang, Chen Yang, Xiaohan Jiang, Junjie Wu | Date: 2023-08-04
2025-11-12 23:50:42,561 - WARNING - root - 【手动下载提示】(无PDF): Hybrid Attention-Aware Learning Network for Facial Expression Recognition in the Wild
	  URL: https://www.semanticscholar.org/paper/a13c5a80a32c0e2dbf589d9fca9daa9b2300165d
	  Citations: 4 | Authors: Weijun Gong, Zhiyao La, Yurong Qian, Weihang Zhou | Date: 2024-01-05
2025-11-12 23:50:42,565 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\hybrid attention\Fine-grained image classification method based on hybrid attention module.pdf
2025-11-12 23:50:42,565 - INFO - root - 成功下载 (Semantic Scholar): Fine-grained image classification method based on hybrid attention module
2025-11-12 23:50:42,567 - INFO - root - 正在下载: https://ieeexplore.ieee.org/ielx7/36/10006360/10145829.pdf
2025-11-12 23:50:52,271 - INFO - root - 正在下载: https://ieeexplore.ieee.org/ielx7/36/10006360/10145829.pdf
2025-11-12 23:52:33,945 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-12 23:52:33,946 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-12 23:52:33,948 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-12 23:52:37,559 - INFO - root - LLMClientManager: 指定使用客户端: Deepseek
2025-11-12 23:52:37,559 - INFO - root - DeepSeekClient: API key found: 9f9e270e-b...
2025-11-12 23:52:37,560 - INFO - root - DeepSeekClient: 使用模式: 火山引擎
2025-11-12 23:52:37,560 - INFO - root - DeepSeekClient: 模型名称: deepseek-v3-1-terminus
2025-11-12 23:52:41,000 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-12 23:52:41,012 - INFO - root - DeepSeekClient: initialized successfully with model deepseek-v3-1-terminus
2025-11-12 23:52:41,012 - INFO - root - LLMClientManager: DeepSeek 客户端初始化成功
2025-11-12 23:52:41,013 - INFO - root - LLMClientManager: switched to DeepSeek client (case-insensitive match)
2025-11-12 23:52:41,013 - INFO - root - 已手动切换到 LLM 客户端: Deepseek
2025-11-12 23:52:41,013 - INFO - root - 使用 LLM 模型: deepseek-v3-1-terminus
2025-11-12 23:52:41,013 - INFO - root - 可用客户端: ['DeepSeek']
2025-11-12 23:52:41,014 - INFO - root - === 运行配置 ===
2025-11-12 23:52:41,014 - INFO - root - 处理模式: Semantic Scholar 高引用搜索 (API)
2025-11-12 23:52:41,014 - INFO - root - 查询 (关键词): hybrid attention
2025-11-12 23:52:41,015 - INFO - root - 关键词 (用于保存): hybrid attention
2025-11-12 23:52:41,015 - INFO - root - 排序: citationCount:desc
2025-11-12 23:52:41,015 - INFO - root - 最大处理数量: 90
2025-11-12 23:52:41,015 - INFO - root - 保存图片: 是
2025-11-12 23:52:41,016 - INFO - root - 输出语言: 中文
2025-11-12 23:52:41,016 - INFO - root - 强制重新处理: 否
2025-11-12 23:52:41,016 - INFO - root - LLM 客户端: Deepseek
2025-11-12 23:52:41,018 - INFO - root - ====================
2025-11-12 23:52:41,018 - INFO - root - 正在使用检索策略: semantic
2025-11-12 23:52:41,021 - INFO - root - 使用 Semantic Scholar 高引用搜索模式 (API)
2025-11-12 23:52:41,023 - INFO - root - Semantic API 查询: query=hybrid attention, limit=90, sort=citationCount:desc
2025-11-12 23:52:41,024 - INFO - root - 正在调用 Semantic Scholar API...
2025-11-12 23:52:48,950 - WARNING - root - 【手动下载提示】(无PDF): An Instrument Indication Acquisition Algorithm Based on Lightweight Deep Convolutional Neural Network and Hybrid Attention Fine-Grained Features
	  URL: https://www.semanticscholar.org/paper/49f99d7a21e2ded7915676753a180983763b9a22
	  Citations: 66 | Authors: Jiaquan Shen, Ningzhong Liu, Han Sun, Deguang Li, Yongxin Zhang | Date: N/A
2025-11-12 23:52:48,950 - WARNING - root - 【手动下载提示】(无PDF): Enhancing ASD classification through hybrid attention-based learning of facial features
	  URL: https://www.semanticscholar.org/paper/22547aa4c72c7c2799932a0f451ab3f2db6d7d0f
	  Citations: 35 | Authors: Inzamam Shahzad, Saif Ur Rehman Khan, Waseem Abbas, Z. U. Abideen, Jin Liu | Date: 2024-04-21
2025-11-12 23:52:48,951 - WARNING - root - 【手动下载提示】(无PDF): Dual-Hybrid Attention Network for Specular Highlight Removal
	  URL: https://www.semanticscholar.org/paper/d56ce689cc0f8b1cf0e5f58882503a5e59ec440b
	  Citations: 33 | Authors: Xiaojiao Guo, Xuhang Chen, Shenghong Luo, Shuqiang Wang, Chi-Man Pun | Date: 2024-07-17
2025-11-12 23:52:48,951 - WARNING - root - 【手动下载提示】(无PDF): HyA-GAN: remote sensing image cloud removal based on hybrid attention generation adversarial network
	  URL: https://www.semanticscholar.org/paper/905b42f2f8d912d98fd7cbec4f7b244401176acc
	  Citations: 16 | Authors: Minghao Jin, Pengwei Wang, Yusong Li | Date: 2024-02-27
2025-11-12 23:52:48,951 - WARNING - root - 【手动下载提示】(无PDF): Hybrid Attention-Aware Transformer Network Collaborative Multiscale Feature Alignment for Building Change Detection
	  URL: https://www.semanticscholar.org/paper/a0f8053046622628073ac6f051b5181a80cb7ad3
	  Citations: 28 | Authors: Chuan Xu, Zhaoyi Ye, Liye Mei, Haonan Yu, Jianchen Liu, Yaxiaer Yalikun, Shuangtong Jin, Sheng Liu, Wei Yang, Cheng Lei | Date: N/A
2025-11-12 23:52:48,952 - WARNING - root - 【手动下载提示】(无PDF): Radar Signal Recognition Based on CNN With a Hybrid Attention Mechanism and Skip Feature Aggregation
	  URL: https://www.semanticscholar.org/paper/dacad703c49e9434321c91220219638f871fd9d2
	  Citations: 25 | Authors: Yuanpu Guo, Haixin Sun, Hui Liu, Zhen-miao Deng | Date: N/A
2025-11-12 23:52:48,952 - WARNING - root - 【手动下载提示】(无PDF): Probabilistic Multienergy Load Forecasting Based on Hybrid Attention-Enabled Transformer Network and Gaussian Process-Aided Residual Learning
	  URL: https://www.semanticscholar.org/paper/a2d81cc04f73e2898fb16e7e8c8f9cf69adadfd5
	  Citations: 16 | Authors: Pengfei Zhao, Weihao Hu, Di Cao, Zhenyuan Zhang, Yuehui Huang, Longcheng Dai, Zhe Chen | Date: 2024-06-01
2025-11-12 23:52:48,953 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\hybrid attention\Hybrid Attention Fusion Embedded in Transformer for Remote Sensing Image Semantic Segmentation.pdf
2025-11-12 23:52:48,954 - INFO - root - 成功下载 (Semantic Scholar): Hybrid Attention Fusion Embedded in Transformer for Remote Sensing Image Semantic Segmentation
2025-11-12 23:52:48,954 - WARNING - root - 【手动下载提示】(无PDF): Enhancing Time Series Product Demand Forecasting With Hybrid Attention-Based Deep Learning Models
	  URL: https://www.semanticscholar.org/paper/4848b35cbe515f8909a67a82dcb83d7c5e48f74b
	  Citations: 14 | Authors: Xuguang Zhang, Pan Li, Xu Han, Yongbin Yang, Yiwen Cui | Date: N/A
2025-11-12 23:52:48,955 - INFO - root - 正在下载: https://www.mdpi.com/2306-5354/11/3/240/pdf?version=1709132347
2025-11-12 23:52:58,616 - INFO - root - 正在下载: https://www.mdpi.com/2306-5354/11/3/240/pdf?version=1709132347
2025-11-12 23:53:08,639 - INFO - root - 正在下载: https://www.mdpi.com/2306-5354/11/3/240/pdf?version=1709132347
2025-11-12 23:53:18,543 - INFO - root - 正在下载: https://www.mdpi.com/2306-5354/11/3/240/pdf?version=1709132347
2025-11-12 23:53:39,444 - INFO - root - 正在下载: https://www.mdpi.com/2306-5354/11/3/240/pdf?version=1709132347
2025-11-12 23:53:45,337 - WARNING - root - 下载 Advancing Ocular Imaging: A Hybrid Attention Mechanism-Based U-Net Model for Precise Segmentation of Sub-Retinal Layers in OCT Images (https://www.mdpi.com/2306-5354/11/3/240/pdf?version=1709132347) 失败: 403 Client Error: Forbidden for url: https://www.mdpi.com/2306-5354/11/3/240/pdf?version=1709132347
2025-11-12 23:53:45,339 - WARNING - root - 【手动下载提示】(无PDF): A novel approach for bearings multiclass fault diagnosis fusing multiscale deep convolution and hybrid attention networks
	  URL: https://www.semanticscholar.org/paper/bf72523fe518b2e4ce4d75d125dd5220177043f6
	  Citations: 13 | Authors: Fule Li, Xinlong Zhao | Date: 2024-01-08
2025-11-12 23:53:45,340 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\hybrid attention\YOLO Algorithm With Hybrid Attention Feature Pyramid Network for Solder Joint Defect Detection.pdf
2025-11-12 23:53:45,340 - INFO - root - 成功下载 (Semantic Scholar): YOLO Algorithm With Hybrid Attention Feature Pyramid Network for Solder Joint Defect Detection
2025-11-12 23:53:45,341 - WARNING - root - 【手动下载提示】(无PDF): Drone-HAT: Hybrid Attention Transformer for Complex Action Recognition in Drone Surveillance Videos
	  URL: https://www.semanticscholar.org/paper/a76690fb96dc7d3dfd5f8fec62c3949cc7ec96f6
	  Citations: 12 | Authors: Mustaqeem Khan, Jamil Ahmad, Abdulmotaleb El-Saddik, W. Gueaieb, Giulia De Masi, Fakhri Karray | Date: 2024-06-17
2025-11-12 23:53:45,341 - WARNING - root - 【手动下载提示】(无PDF): Dense Hybrid Attention Network for Palmprint Image Super-Resolution
	  URL: https://www.semanticscholar.org/paper/75746d8d52509b24d9975d9b3b07ae91311dc7ed
	  Citations: 12 | Authors: Yao Wang, Lunke Fei, Shuping Zhao, Qi Zhu, Jie Wen, Wei Jia, Imad Rida | Date: 2024-04-01
2025-11-12 23:53:45,343 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\hybrid attention\Frequency Enhanced Hybrid Attention Network for Sequential Recommendation.pdf
2025-11-12 23:53:45,343 - INFO - root - 成功下载 (Semantic Scholar): Frequency Enhanced Hybrid Attention Network for Sequential Recommendation
2025-11-12 23:53:45,343 - WARNING - root - 【手动下载提示】(无PDF): A Multiscale Hybrid Attention Networks Based on Multiview Images for the Diagnosis of Parkinson’s Disease
	  URL: https://www.semanticscholar.org/paper/b2af0577ee8ac56b527bd108ce57755a4a4b04e7
	  Citations: 11 | Authors: Xinchun Cui, Youshi Zhou, Chao Zhao, Jianlong Li, Xiangwei Zheng, Xiuli Li, Shixiao Shan, JinXing Liu, Xiaoli Liu | Date: N/A
2025-11-12 23:53:45,344 - WARNING - root - 【手动下载提示】(无PDF): Hybrid Attention Feature Refinement Network for Lightweight Image Super-Resolution in Metaverse Immersive Display
	  URL: https://www.semanticscholar.org/paper/c4d95a47eec1a23320d60dd95848d41e10820ee4
	  Citations: 10 | Authors: Kexin Wang, Xiaomin Yang, Gwanggil Jeon | Date: 2024-02-01
2025-11-12 23:53:45,345 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\hybrid attention\HAT_ Hybrid Attention Transformer for Image Restoration.pdf
2025-11-12 23:53:45,345 - INFO - root - 成功下载 (Semantic Scholar): HAT: Hybrid Attention Transformer for Image Restoration
2025-11-12 23:53:45,347 - INFO - root - 正在下载: https://www.mdpi.com/2076-3417/14/3/1293/pdf?version=1707037901
2025-11-12 23:53:54,920 - INFO - root - 正在下载: https://www.mdpi.com/2076-3417/14/3/1293/pdf?version=1707037901
2025-11-12 23:54:04,422 - INFO - root - 正在下载: https://www.mdpi.com/2076-3417/14/3/1293/pdf?version=1707037901
2025-11-12 23:54:13,945 - INFO - root - 正在下载: https://www.mdpi.com/2076-3417/14/3/1293/pdf?version=1707037901
2025-11-12 23:54:27,427 - INFO - root - 正在下载: https://www.mdpi.com/2076-3417/14/3/1293/pdf?version=1707037901
2025-11-12 23:54:32,924 - WARNING - root - 下载 Dual Hybrid Attention Mechanism-Based U-Net for Building Segmentation in Remote Sensing Images (https://www.mdpi.com/2076-3417/14/3/1293/pdf?version=1707037901) 失败: 403 Client Error: Forbidden for url: https://www.mdpi.com/2076-3417/14/3/1293/pdf?version=1707037901
2025-11-12 23:54:32,925 - WARNING - root - 【手动下载提示】(无PDF): Abundance Matrix Correlation Analysis Network Based on Hierarchical Multihead Self-Cross-Hybrid Attention for Hyperspectral Change Detection
	  URL: https://www.semanticscholar.org/paper/6aae02a41656cecba872b29bb3d71c414a58f57b
	  Citations: 66 | Authors: Wenqian Dong, Jing Zhao, Jiahui Qu, Song Xiao, Nan Li, Shaoxiong Hou, Yunsong Li | Date: N/A
2025-11-12 23:54:32,925 - WARNING - root - 【手动下载提示】(无PDF): HA-Net: a SAR image ship detector based on hybrid attention
	  URL: https://www.semanticscholar.org/paper/4c40b6f75ab19e1402ae88e38013a64c504c3a80
	  Citations: 6 | Authors: Shouwen Cai, Hao Meng, Ming Yuan, Fei Gao | Date: 2024-06-10
2025-11-12 23:54:32,925 - WARNING - root - 【手动下载提示】(无PDF): Hybrid Attention Module and Transformer Based Fuze DRFM Jamming Signal Recognition
	  URL: https://www.semanticscholar.org/paper/0fb8059c6aaf0c86c9e9a623fa1ad73d0f737c37
	  Citations: 7 | Authors: Jikai Yang, Zhiquan Bai, Zhaoxia Xian, Hongwu Xiang, Jingxin Li, Huili Hu, Jian Dai, Xinhong Hao | Date: 2024-09-01
2025-11-12 23:54:32,926 - WARNING - root - 【手动下载提示】(无PDF): Towards Effective Author Name Disambiguation by Hybrid Attention
	  URL: https://www.semanticscholar.org/paper/fc2dcb9e544a0aaad3034a61eaf0563a79c65cbf
	  Citations: 6 | Authors: Qian Zhou, Wei Chen, Peng-Peng Zhao, An Liu, Jia-Jie Xu, Jian-Feng Qu, Lei Zhao | Date: 2024-07-01
2025-11-12 23:54:32,927 - WARNING - root - 【手动下载提示】(无PDF): Deep Hashing Network With Hybrid Attention and Adaptive Weighting for Image Retrieval
	  URL: https://www.semanticscholar.org/paper/1c688a4da1c546ea783f5743c371732ace568498
	  Citations: 7 | Authors: Yingjiao Pei, Zhongyuan Wang, Na Li, Heling Chen, Baojin Huang, Weiping Tu | Date: N/A
2025-11-12 23:54:32,927 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\hybrid attention\Multi-scale deep residual shrinkage networks with a hybrid attention mechanism for rolling bearing f.pdf
2025-11-12 23:54:32,929 - INFO - root - 成功下载 (Semantic Scholar): Multi-scale deep residual shrinkage networks with a hybrid attention mechanism for rolling bearing fault diagnosis
2025-11-12 23:54:32,929 - WARNING - root - 【手动下载提示】(无PDF): Actor-Hybrid-Attention-Critic for Multi-Logistic Robots Path Planning
	  URL: https://www.semanticscholar.org/paper/5260da08f9f524b8fa77a37e2884b22804a47c6a
	  Citations: 6 | Authors: Chunjie Yang, Bodi Yuan, Pengzhao Zhai | Date: 2024-06-01
2025-11-12 23:54:32,931 - INFO - root - 正在下载: https://www.mdpi.com/2306-5354/10/6/714/pdf?version=1686635187
2025-11-12 23:54:42,712 - INFO - root - 正在下载: https://www.mdpi.com/2306-5354/10/6/714/pdf?version=1686635187
2025-11-12 23:54:53,339 - INFO - root - 正在下载: https://www.mdpi.com/2306-5354/10/6/714/pdf?version=1686635187
2025-11-12 23:55:02,815 - INFO - root - 正在下载: https://www.mdpi.com/2306-5354/10/6/714/pdf?version=1686635187
2025-11-12 23:55:16,374 - INFO - root - 正在下载: https://www.mdpi.com/2306-5354/10/6/714/pdf?version=1686635187
2025-11-12 23:55:21,791 - WARNING - root - 下载 AHANet: Adaptive Hybrid Attention Network for Alzheimer’s Disease Classification Using Brain Magnetic Resonance Imaging (https://www.mdpi.com/2306-5354/10/6/714/pdf?version=1686635187) 失败: 403 Client Error: Forbidden for url: https://www.mdpi.com/2306-5354/10/6/714/pdf?version=1686635187
2025-11-12 23:55:21,794 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\hybrid attention\Physics Inspired Hybrid Attention for SAR Target Recognition.pdf
2025-11-12 23:55:21,795 - INFO - root - 成功下载 (Semantic Scholar): Physics Inspired Hybrid Attention for SAR Target Recognition
2025-11-12 23:55:21,795 - WARNING - root - 【手动下载提示】(无PDF): WHEN: A Wavelet-DTW Hybrid Attention Network for Heterogeneous Time Series Analysis
	  URL: https://www.semanticscholar.org/paper/c2e57a1926217f67a72c617d09fa12ec8e667d0e
	  Citations: 33 | Authors: Jingyuan Wang, Chen Yang, Xiaohan Jiang, Junjie Wu | Date: 2023-08-04
2025-11-12 23:55:21,809 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\hybrid attention\Fine-grained image classification method based on hybrid attention module.pdf
2025-11-12 23:55:21,810 - INFO - root - 成功下载 (Semantic Scholar): Fine-grained image classification method based on hybrid attention module
2025-11-12 23:55:21,810 - WARNING - root - 【手动下载提示】(无PDF): Hybrid Attention-Aware Learning Network for Facial Expression Recognition in the Wild
	  URL: https://www.semanticscholar.org/paper/a13c5a80a32c0e2dbf589d9fca9daa9b2300165d
	  Citations: 4 | Authors: Weijun Gong, Zhiyao La, Yurong Qian, Weihang Zhou | Date: 2024-01-05
2025-11-12 23:55:21,812 - INFO - root - 正在下载: https://ieeexplore.ieee.org/ielx7/36/10006360/10145829.pdf
2025-11-12 23:55:32,092 - INFO - root - 正在下载: https://ieeexplore.ieee.org/ielx7/36/10006360/10145829.pdf
2025-11-12 23:55:42,162 - INFO - root - 正在下载: https://ieeexplore.ieee.org/ielx7/36/10006360/10145829.pdf
2025-11-12 23:55:51,819 - INFO - root - 正在下载: https://ieeexplore.ieee.org/ielx7/36/10006360/10145829.pdf
2025-11-12 23:56:05,494 - INFO - root - 正在下载: https://ieeexplore.ieee.org/ielx7/36/10006360/10145829.pdf
2025-11-12 23:56:11,217 - WARNING - root - 下载 Hybrid Attention-Based U-Shaped Network for Remote Sensing Image Super-Resolution (https://ieeexplore.ieee.org/ielx7/36/10006360/10145829.pdf) 失败: 418 Client Error: Unknown Code for url: https://ieeexplore.ieee.org/ielx7/36/10006360/10145829.pdf
2025-11-12 23:56:11,218 - INFO - root - 正在下载: https://www.mdpi.com/2076-3417/13/2/770/pdf?version=1673518878
2025-11-12 23:56:20,618 - INFO - root - 正在下载: https://www.mdpi.com/2076-3417/13/2/770/pdf?version=1673518878
2025-11-12 23:56:31,039 - INFO - root - 正在下载: https://www.mdpi.com/2076-3417/13/2/770/pdf?version=1673518878
2025-11-12 23:56:40,722 - INFO - root - 正在下载: https://www.mdpi.com/2076-3417/13/2/770/pdf?version=1673518878
2025-11-12 23:56:55,631 - INFO - root - 正在下载: https://www.mdpi.com/2076-3417/13/2/770/pdf?version=1673518878
2025-11-12 23:57:01,295 - WARNING - root - 下载 Smart Contract Vulnerability Detection Based on Hybrid Attention Mechanism Model (https://www.mdpi.com/2076-3417/13/2/770/pdf?version=1673518878) 失败: 403 Client Error: Forbidden for url: https://www.mdpi.com/2076-3417/13/2/770/pdf?version=1673518878
2025-11-12 23:57:01,295 - WARNING - root - 【手动下载提示】(无PDF): Mutiscale Hybrid Attention Transformer for Remote Sensing Image Pansharpening
	  URL: https://www.semanticscholar.org/paper/3b8404c8b16dd7abb86aa5f13139fa9a9c5f5ca8
	  Citations: 21 | Authors: Wengang Zhu, Jinjiang Li, Zhi-Yonga An, Zhen Hua | Date: N/A
2025-11-12 23:57:01,296 - WARNING - root - 【手动下载提示】(无PDF): Multimodal emotion recognition based on audio and text by using hybrid attention networks
	  URL: https://www.semanticscholar.org/paper/5a35815f9d5f7ed5697b4638b1158f42837051c1
	  Citations: 42 | Authors: Shiqing Zhang, Yijiao Yang, Ruixin Liu, Chen Chen, Xin Tao, Wenping Guo, Yicheng Xu, Xiaoming Zhao | Date: N/A
2025-11-12 23:57:01,296 - WARNING - root - 【手动下载提示】(无PDF): A Novel Approach for Surface Integrity Monitoring in High-Energy Nanosecond-Pulse Laser Shock Peening: Acoustic Emission and Hybrid-Attention CNN
	  URL: https://www.semanticscholar.org/paper/9608f2b16d1d302f7507505b51a5be96fdf0b542
	  Citations: 19 | Authors: Zhifen Zhang, Rui Qin, Gengze Li, Z. Du, G. Wen, Weifeng He | Date: 2023-03-01
2025-11-12 23:57:01,297 - WARNING - root - 【手动下载提示】(无PDF): Intention-convolution and hybrid-attention network for vehicle trajectory prediction
	  URL: https://www.semanticscholar.org/paper/3bcb4d2994896053a5a8da42d09eb621d3b2b221
	  Citations: 33 | Authors: Chao Li, Zhanwen Liu, Shang Lin, Yang Wang, Xiangmo Zhao | Date: 2023-09-01
2025-11-12 23:57:01,298 - WARNING - root - 【手动下载提示】(无PDF): Hybrid Attention Network for Epileptic EEG Classification
	  URL: https://www.semanticscholar.org/paper/f282fa85469cc789c2f3b62e57e3446a49528afa
	  Citations: 17 | Authors: Yanna Zhao, Jiatong He, Fenglin Zhu, Tiantian Xiao, Yongfeng Zhang, Ziwei Wang, Fangzhou Xu, Yi Niu | Date: 2023-03-31
2025-11-12 23:57:01,299 - INFO - root - 正在下载: https://www.mdpi.com/1424-8220/23/13/6052/pdf?version=1688107163
2025-11-12 23:57:10,927 - INFO - root - 正在下载: https://www.mdpi.com/1424-8220/23/13/6052/pdf?version=1688107163
2025-11-12 23:57:20,347 - INFO - root - 正在下载: https://www.mdpi.com/1424-8220/23/13/6052/pdf?version=1688107163
2025-11-12 23:57:30,013 - INFO - root - 正在下载: https://www.mdpi.com/1424-8220/23/13/6052/pdf?version=1688107163
2025-11-12 23:57:45,992 - INFO - root - 正在下载: https://www.mdpi.com/1424-8220/23/13/6052/pdf?version=1688107163
2025-11-12 23:57:51,810 - WARNING - root - 下载 PHAM-YOLO: A Parallel Hybrid Attention Mechanism Network for Defect Detection of Meter in Substation (https://www.mdpi.com/1424-8220/23/13/6052/pdf?version=1688107163) 失败: 403 Client Error: Forbidden for url: https://www.mdpi.com/1424-8220/23/13/6052/pdf?version=1688107163
2025-11-12 23:57:51,810 - INFO - root - 正在下载: https://www.mdpi.com/1424-8220/23/15/6982/pdf?version=1691312141
2025-11-12 23:58:01,956 - INFO - root - 正在下载: https://www.mdpi.com/1424-8220/23/15/6982/pdf?version=1691312141
2025-11-12 23:58:12,070 - INFO - root - 正在下载: https://www.mdpi.com/1424-8220/23/15/6982/pdf?version=1691312141
2025-11-12 23:58:22,312 - INFO - root - 正在下载: https://www.mdpi.com/1424-8220/23/15/6982/pdf?version=1691312141
2025-11-12 23:58:35,960 - INFO - root - 正在下载: https://www.mdpi.com/1424-8220/23/15/6982/pdf?version=1691312141
2025-11-12 23:58:41,372 - WARNING - root - 下载 Defect Detection in Steel Using a Hybrid Attention Network (https://www.mdpi.com/1424-8220/23/15/6982/pdf?version=1691312141) 失败: 403 Client Error: Forbidden for url: https://www.mdpi.com/1424-8220/23/15/6982/pdf?version=1691312141
2025-11-12 23:58:41,373 - WARNING - root - 【手动下载提示】(无PDF): Hybrid Attention and Motion Constraint for Anomaly Detection in Crowded Scenes
	  URL: https://www.semanticscholar.org/paper/a5e107a1112c88294f44989f6622433fb402fb31
	  Citations: 30 | Authors: Xinfeng Zhang, Jinpeng Fang, Baoqing Yang, Shuhan Chen, Bin Li | Date: 2023-05-01
2025-11-12 23:58:41,375 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\hybrid attention\Hybrid Attention-Based Prototypical Networks for Noisy Few-Shot Relation Classification.pdf
2025-11-12 23:58:41,375 - INFO - root - 成功下载 (Semantic Scholar): Hybrid Attention-Based Prototypical Networks for Noisy Few-Shot Relation Classification
2025-11-12 23:58:41,376 - INFO - root - 正在下载: https://www.mdpi.com/2072-4292/15/2/526/pdf?version=1673863751
2025-11-12 23:58:50,778 - INFO - root - 正在下载: https://www.mdpi.com/2072-4292/15/2/526/pdf?version=1673863751
2025-11-12 23:59:01,158 - INFO - root - 正在下载: https://www.mdpi.com/2072-4292/15/2/526/pdf?version=1673863751
2025-11-12 23:59:10,891 - INFO - root - 正在下载: https://www.mdpi.com/2072-4292/15/2/526/pdf?version=1673863751
2025-11-12 23:59:24,919 - INFO - root - 正在下载: https://www.mdpi.com/2072-4292/15/2/526/pdf?version=1673863751
2025-11-12 23:59:30,838 - WARNING - root - 下载 Hybrid Attention-Based Encoder-Decoder Fully Convolutional Network for PolSAR Image Classification (https://www.mdpi.com/2072-4292/15/2/526/pdf?version=1673863751) 失败: 403 Client Error: Forbidden for url: https://www.mdpi.com/2072-4292/15/2/526/pdf?version=1673863751
2025-11-12 23:59:30,862 - WARNING - root - 【手动下载提示】(无PDF): Hybrid Attention Compression Network With Light Graph Attention Module for Remote Sensing Images
	  URL: https://www.semanticscholar.org/paper/11ab89aa34dae52624533795ebbe1ce707a66fd4
	  Citations: 9 | Authors: Tianpeng Pan, Lili Zhang, Yingchao Song, Yuxuan Liu | Date: N/A
2025-11-12 23:59:30,865 - WARNING - root - 【手动下载提示】(无PDF): An Adaptive Hybrid Attention Based Convolutional Neural Net for Intelligent Transportation Object Recognition
	  URL: https://www.semanticscholar.org/paper/269fed3c9a541a4073cde6e205878c2618b2f973
	  Citations: 11 | Authors: Qili Chen, Guangyuan Pan, Lin Zhao, Junfang Fan, Wenbai Chen, A. Zhang | Date: 2023-07-01
2025-11-12 23:59:30,866 - WARNING - root - 【手动下载提示】(无PDF): HEU-Net: hybrid attention residual block-based network with external skip connections for metal corrosion semantic segmentation
	  URL: https://www.semanticscholar.org/paper/80e0948897bc53edf4eba2e31e443010d8a2e19a
	  Citations: 9 | Authors: Tianchen Zhu, Shiqiang Zhu, Tao Zheng, Hongliang Ding, Wei Song, Cunjun Li | Date: 2023-06-22
2025-11-12 23:59:30,866 - WARNING - root - 【手动下载提示】(无PDF): Face-Periocular Cross-Identification via Contrastive Hybrid Attention Vision Transformer
	  URL: https://www.semanticscholar.org/paper/5765cc795e642e1a8e834d6af93cda3ac65a753a
	  Citations: 6 | Authors: Leslie Ching Ow Tiong, D. Sigmund, A. Teoh | Date: N/A
2025-11-12 23:59:30,923 - WARNING - root - 【手动下载提示】(无PDF): Image Super-Resolution with Multi-scale Hybrid Attention
	  URL: https://www.semanticscholar.org/paper/09691760c37f27ddf4d4b7908a348b20b110db6d
	  Citations: 0 | Authors: Ningzhi Wang, Hanyi Shi, Wenna Ruan, Lingbin Zeng | Date: N/A
2025-11-12 23:59:30,935 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\hybrid attention\Dual-view Correlation Hybrid Attention Network for Robust Holistic Mammogram Classification.pdf
2025-11-12 23:59:30,990 - INFO - root - 成功下载 (Semantic Scholar): Dual-view Correlation Hybrid Attention Network for Robust Holistic Mammogram Classification
2025-11-12 23:59:30,993 - INFO - root - 正在下载: https://www.mdpi.com/1424-8220/23/19/8285/pdf?version=1696663695
2025-11-12 23:59:40,523 - INFO - root - 正在下载: https://www.mdpi.com/1424-8220/23/19/8285/pdf?version=1696663695
2025-11-12 23:59:50,188 - INFO - root - 正在下载: https://www.mdpi.com/1424-8220/23/19/8285/pdf?version=1696663695
2025-11-12 23:59:59,685 - INFO - root - 正在下载: https://www.mdpi.com/1424-8220/23/19/8285/pdf?version=1696663695
2025-11-13 00:00:13,113 - INFO - root - 正在下载: https://www.mdpi.com/1424-8220/23/19/8285/pdf?version=1696663695
2025-11-13 00:00:18,509 - WARNING - root - 下载 A Fast and Robust Lane Detection via Online Re-Parameterization and Hybrid Attention (https://www.mdpi.com/1424-8220/23/19/8285/pdf?version=1696663695) 失败: 403 Client Error: Forbidden for url: https://www.mdpi.com/1424-8220/23/19/8285/pdf?version=1696663695
2025-11-13 00:00:18,509 - WARNING - root - 【手动下载提示】(无PDF): Multi-level wavelet network based on CNN-Transformer hybrid attention for single image deraining
	  URL: https://www.semanticscholar.org/paper/97c485dbb41b68c193decdec5a4618ce3f5b4ee2
	  Citations: 8 | Authors: B. Liu, Siyan Fang | Date: 2023-08-09
2025-11-13 00:00:18,511 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\hybrid attention\Stacked Hybrid-Attention and Group Collaborative Learning for Unbiased Scene Graph Generation.pdf
2025-11-13 00:00:18,512 - INFO - root - 成功下载 (Semantic Scholar): Stacked Hybrid-Attention and Group Collaborative Learning for Unbiased Scene Graph Generation
2025-11-13 00:00:18,514 - INFO - root - 正在下载: https://onlinelibrary.wiley.com/doi/pdfdirect/10.1049/ipr2.12934
2025-11-13 00:00:28,000 - INFO - root - 正在下载: https://onlinelibrary.wiley.com/doi/pdfdirect/10.1049/ipr2.12934
2025-11-13 00:00:37,688 - INFO - root - 正在下载: https://onlinelibrary.wiley.com/doi/pdfdirect/10.1049/ipr2.12934
2025-11-13 00:00:47,184 - INFO - root - 正在下载: https://onlinelibrary.wiley.com/doi/pdfdirect/10.1049/ipr2.12934
2025-11-13 00:01:00,720 - INFO - root - 正在下载: https://onlinelibrary.wiley.com/doi/pdfdirect/10.1049/ipr2.12934
2025-11-13 00:01:06,480 - WARNING - root - 下载 Hybrid attention mechanism of feature fusion for medical image segmentation (https://onlinelibrary.wiley.com/doi/pdfdirect/10.1049/ipr2.12934) 失败: 403 Client Error: Forbidden for url: https://onlinelibrary.wiley.com/doi/pdfdirect/10.1049/ipr2.12934
2025-11-13 00:01:06,482 - INFO - root - 正在下载: https://www.mdpi.com/2073-8994/15/10/1947/pdf?version=1697811500
2025-11-13 00:01:15,980 - INFO - root - 正在下载: https://www.mdpi.com/2073-8994/15/10/1947/pdf?version=1697811500
2025-11-13 00:01:25,380 - INFO - root - 正在下载: https://www.mdpi.com/2073-8994/15/10/1947/pdf?version=1697811500
2025-11-13 00:01:34,985 - INFO - root - 正在下载: https://www.mdpi.com/2073-8994/15/10/1947/pdf?version=1697811500
2025-11-13 00:01:48,900 - INFO - root - 正在下载: https://www.mdpi.com/2073-8994/15/10/1947/pdf?version=1697811500
2025-11-13 00:01:54,876 - WARNING - root - 下载 Transformer with Hybrid Attention Mechanism for Stereo Endoscopic Video Super Resolution (https://www.mdpi.com/2073-8994/15/10/1947/pdf?version=1697811500) 失败: 403 Client Error: Forbidden for url: https://www.mdpi.com/2073-8994/15/10/1947/pdf?version=1697811500
2025-11-13 00:01:54,876 - WARNING - root - 【手动下载提示】(无PDF): HHTrack: Hyperspectral Object Tracking Based on Hybrid Attention
	  URL: https://www.semanticscholar.org/paper/c1c5c93f3bd9b99ec5fe55b4c2b5bc29abf4b12a
	  Citations: 1 | Authors: Yuedong Tan, Wenfang Sun, Jieran Yuan, Wenwang Du, Zhe Wang, Nan Mao, Beibei Song | Date: 2023-08-14
2025-11-13 00:01:54,877 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\hybrid attention\Hybridformer_ Improving Squeezeformer with Hybrid Attention and NSR Mechanism.pdf
2025-11-13 00:01:54,877 - INFO - root - 成功下载 (Semantic Scholar): Hybridformer: Improving Squeezeformer with Hybrid Attention and NSR Mechanism
2025-11-13 00:01:54,879 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\hybrid attention\HAC-Net_ A Hybrid Attention-Based Convolutional Neural Network for Highly Accurate Protein-Ligand Bi.pdf
2025-11-13 00:01:54,879 - INFO - root - 成功下载 (Semantic Scholar): HAC-Net: A Hybrid Attention-Based Convolutional Neural Network for Highly Accurate Protein-Ligand Binding Affinity Prediction
2025-11-13 00:01:54,879 - WARNING - root - 【手动下载提示】(无PDF): A hybrid-attention semantic segmentation network for remote sensing interpretation in land-use surveillance
	  URL: https://www.semanticscholar.org/paper/4905315ab99ea19871a65e52be8c8c51624748aa
	  Citations: 49 | Authors: Ning Lv, Zenghui Zhang, Cong Li, Jiaxuan Deng, Tao Su, Chen Chen, Yang Zhou | Date: 2022-02-07
2025-11-13 00:01:54,880 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\hybrid attention\A Hybrid Attention Mechanism for Weakly-Supervised Temporal Action Localization.pdf
2025-11-13 00:01:54,881 - INFO - root - 成功下载 (Semantic Scholar): A Hybrid Attention Mechanism for Weakly-Supervised Temporal Action Localization
2025-11-13 00:01:54,881 - WARNING - root - 【手动下载提示】(无PDF): A hybrid attention-based deep learning approach for wind power prediction
	  URL: https://www.semanticscholar.org/paper/9d591544b9f179d93ad85720e8382e8e1c04c916
	  Citations: 128 | Authors: Zhengjing Ma, Gang Mei | Date: 2022-10-01
2025-11-13 00:01:54,881 - WARNING - root - 【手动下载提示】(无PDF): ColorFormer: Image Colorization via Color Memory Assisted Hybrid-Attention Transformer
	  URL: https://www.semanticscholar.org/paper/33618e85644d6705fd74086c13ee3b7e2a2a466a
	  Citations: 27 | Authors: Xiaozhong Ji, Boyuan Jiang, Donghao Luo, Guangpin Tao, Wenqing Chu, Zhifeng Xie, Chengjie Wang, Ying Tai | Date: N/A
2025-11-13 00:01:54,882 - WARNING - root - 【手动下载提示】(无PDF): HAM: Hybrid attention module in deep convolutional neural networks for image classification
	  URL: https://www.semanticscholar.org/paper/2cfa77f582ee36f2d1fe8869505aa5a71a5f99f3
	  Citations: 92 | Authors: Guoqiang Li, Qianhao Fang, Li Zha, Xin Gao, Nenggan Zheng | Date: 2022-05-01
2025-11-13 00:01:54,882 - INFO - root - 正在下载: https://downloads.hindawi.com/journals/cin/2022/4189500.pdf
2025-11-13 00:02:05,705 - INFO - root - 正在下载: https://downloads.hindawi.com/journals/cin/2022/4189500.pdf
2025-11-13 00:02:15,230 - INFO - root - 正在下载: https://downloads.hindawi.com/journals/cin/2022/4189500.pdf
2025-11-13 00:02:24,831 - INFO - root - 正在下载: https://downloads.hindawi.com/journals/cin/2022/4189500.pdf
2025-11-13 00:02:38,470 - INFO - root - 正在下载: https://downloads.hindawi.com/journals/cin/2022/4189500.pdf
2025-11-13 00:02:44,031 - WARNING - root - 下载 Aircraft Image Recognition Network Based on Hybrid Attention Mechanism (https://downloads.hindawi.com/journals/cin/2022/4189500.pdf) 失败: 403 Client Error: Forbidden for url: https://downloads.hindawi.com/journals/cin/2022/4189500.pdf
2025-11-13 00:02:44,032 - WARNING - root - 【手动下载提示】(无PDF): Hybrid attention based vehicle trajectory prediction
	  URL: https://www.semanticscholar.org/paper/a2778f12363b79e0a604ddd21a878f3abb0acced
	  Citations: 6 | Authors: Lingyang Wang, Wenping Jiang | Date: 2023-04-06
2025-11-13 00:02:44,032 - WARNING - root - 【手动下载提示】(无PDF): A Hybrid Attention-Based Paralleled Deep Learning model for tool wear prediction
	  URL: https://www.semanticscholar.org/paper/27da7ffd2319f8a2f47eec128894be31f88fc35c
	  Citations: 87 | Authors: Jian Duan, Xi Zhang, Tielin Shi | Date: 2022-08-01
2025-11-13 00:02:44,033 - WARNING - root - 【手动下载提示】(无PDF): State of health estimation for lithium-ion batteries based on hybrid attention and deep learning
	  URL: https://www.semanticscholar.org/paper/f91dcfd8df66da9bf3649c176869f980b9205115
	  Citations: 89 | Authors: Hongqian Zhao, Zheng Chen, Xing Shu, Jiangwei Shen, Zhenzhen Lei, Yuanjian Zhang | Date: 2022-12-01
2025-11-13 00:02:44,034 - INFO - root - 正在下载: https://ieeexplore.ieee.org/ielx7/6287639/9668973/09693977.pdf
2025-11-13 00:02:53,984 - INFO - root - 正在下载: https://ieeexplore.ieee.org/ielx7/6287639/9668973/09693977.pdf
2025-11-13 00:03:05,417 - INFO - root - 正在下载: https://ieeexplore.ieee.org/ielx7/6287639/9668973/09693977.pdf
2025-11-13 00:03:15,771 - INFO - root - 正在下载: https://ieeexplore.ieee.org/ielx7/6287639/9668973/09693977.pdf
2025-11-13 00:03:29,637 - INFO - root - 正在下载: https://ieeexplore.ieee.org/ielx7/6287639/9668973/09693977.pdf
2025-11-13 00:03:35,294 - WARNING - root - 下载 HANN: Hybrid Attention Neural Network for Detecting Covid-19 Related Rumors (https://ieeexplore.ieee.org/ielx7/6287639/9668973/09693977.pdf) 失败: 418 Client Error: Unknown Code for url: https://ieeexplore.ieee.org/ielx7/6287639/9668973/09693977.pdf
2025-11-13 00:03:35,295 - INFO - root - 正在下载: https://www.mdpi.com/1424-8220/22/10/3701/pdf?version=1652360619
2025-11-13 00:03:44,767 - INFO - root - 正在下载: https://www.mdpi.com/1424-8220/22/10/3701/pdf?version=1652360619
2025-11-13 00:03:54,195 - INFO - root - 正在下载: https://www.mdpi.com/1424-8220/22/10/3701/pdf?version=1652360619
2025-11-13 00:04:03,670 - INFO - root - 正在下载: https://www.mdpi.com/1424-8220/22/10/3701/pdf?version=1652360619
2025-11-13 00:04:17,460 - INFO - root - 正在下载: https://www.mdpi.com/1424-8220/22/10/3701/pdf?version=1652360619
2025-11-13 00:04:22,931 - WARNING - root - 下载 An Anti-UAV Long-Term Tracking Method with Hybrid Attention Mechanism and Hierarchical Discriminator (https://www.mdpi.com/1424-8220/22/10/3701/pdf?version=1652360619) 失败: 403 Client Error: Forbidden for url: https://www.mdpi.com/1424-8220/22/10/3701/pdf?version=1652360619
2025-11-13 00:04:22,933 - WARNING - root - 【手动下载提示】(无PDF): Hybrid Attention-Based Prototypical Networks for Few-Shot Sound Classification
	  URL: https://www.semanticscholar.org/paper/e0ddd13d74fe020c8e63eb2ef5a2daa687565953
	  Citations: 15 | Authors: You Wang, D.V. Anderson | Date: 2022-05-23
2025-11-13 00:04:22,934 - WARNING - root - 【手动下载提示】(无PDF): A Hybrid Attention-Based Deep Neural Network for Simultaneous Multi-Sensor Pruning and Human Activity Recognition
	  URL: https://www.semanticscholar.org/paper/06f82dcfa03d18408410b03b4203fff9bbeceeac
	  Citations: 21 | Authors: Yu Zhou, Zhuo Yang, Xiao Zhang, Yufan Wang | Date: 2022-12-15
2025-11-13 00:04:22,934 - WARNING - root - 【手动下载提示】(无PDF): End-to-End Multilevel Hybrid Attention Framework for Hyperspectral Image Classification
	  URL: https://www.semanticscholar.org/paper/6cbd2101b7faff37d402cc8574c95477af70f3aa
	  Citations: 19 | Authors: Jianhong Xiang, Chen Wei, Minhui Wang, Long Teng | Date: N/A
2025-11-13 00:04:22,935 - WARNING - root - 【手动下载提示】(无PDF): Parallel Deep Learning Algorithms With Hybrid Attention Mechanism for Image Segmentation of Lung Tumors
	  URL: https://www.semanticscholar.org/paper/05c67b073bde463686697eb553576958c8403a60
	  Citations: 87 | Authors: Hexuan Hu, Qingqiu Li, Yun-feng Zhao, Ye Zhang | Date: 2021-04-01
2025-11-13 00:04:22,935 - WARNING - root - 【手动下载提示】(无PDF): Hybrid attention network for semantic segmentation
	  URL: https://www.semanticscholar.org/paper/ee93962e142d4e7fa0b84f5d59970cb30a0b8960
	  Citations: 0 | Authors: Yin Yang, Juan Yang, Ronggui Wang | Date: 2023-10-19
2025-11-13 00:04:22,937 - WARNING - root - 【手动下载提示】(无PDF): A hybrid attention semantic segmentation network for unstructured terrain on Mars
	  URL: https://www.semanticscholar.org/paper/7b71919c1e0adafaa102cf03849b6c21841c8e54
	  Citations: 53 | Authors: Haiqiang Liu, Meibao Yao, Xueming Xiao, Hutao Cui | Date: 2022-08-01
2025-11-13 00:04:22,942 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\hybrid attention\RHA-Net_ An Encoder-Decoder Network with Residual Blocks and Hybrid Attention Mechanisms for Pavemen.pdf
2025-11-13 00:04:22,945 - INFO - root - 成功下载 (Semantic Scholar): RHA-Net: An Encoder-Decoder Network with Residual Blocks and Hybrid Attention Mechanisms for Pavement Crack Segmentation
2025-11-13 00:04:22,948 - INFO - root - 正在下载: https://downloads.hindawi.com/journals/wcmc/2022/5441366.pdf
2025-11-13 00:04:32,539 - INFO - root - 正在下载: https://downloads.hindawi.com/journals/wcmc/2022/5441366.pdf
2025-11-13 00:04:42,315 - INFO - root - 正在下载: https://downloads.hindawi.com/journals/wcmc/2022/5441366.pdf
2025-11-13 00:04:51,800 - INFO - root - 正在下载: https://downloads.hindawi.com/journals/wcmc/2022/5441366.pdf
2025-11-13 00:05:06,325 - INFO - root - 正在下载: https://downloads.hindawi.com/journals/wcmc/2022/5441366.pdf
2025-11-13 00:05:11,906 - WARNING - root - 下载 Classification of Diabetic Retinopathy Based on Multiscale Hybrid Attention Mechanism and Residual Algorithm (https://downloads.hindawi.com/journals/wcmc/2022/5441366.pdf) 失败: 403 Client Error: Forbidden for url: https://downloads.hindawi.com/journals/wcmc/2022/5441366.pdf
2025-11-13 00:05:11,907 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\hybrid attention\HHTrack_ Hyperspectral Object Tracking Using Hybrid Attention.pdf
2025-11-13 00:05:11,908 - INFO - root - 成功下载 (Semantic Scholar): HHTrack: Hyperspectral Object Tracking Using Hybrid Attention
2025-11-13 00:05:11,908 - WARNING - root - 【手动下载提示】(无PDF): Hybrid attention network for image captioning
	  URL: https://www.semanticscholar.org/paper/45acf57fd885b60d858dc6c49da4ff536a901d67
	  Citations: 22 | Authors: Wenhui Jiang, Qin Li, K. Zhan, Yuming Fang, Fei Shen | Date: 2022-05-01
2025-11-13 00:05:11,909 - INFO - root - 正在下载: https://downloads.hindawi.com/journals/wcmc/2022/3301718.pdf
2025-11-13 00:05:21,401 - INFO - root - 正在下载: https://downloads.hindawi.com/journals/wcmc/2022/3301718.pdf
2025-11-13 00:05:30,892 - INFO - root - 正在下载: https://downloads.hindawi.com/journals/wcmc/2022/3301718.pdf
2025-11-13 00:05:40,586 - INFO - root - 正在下载: https://downloads.hindawi.com/journals/wcmc/2022/3301718.pdf
2025-11-13 00:05:55,842 - INFO - root - 正在下载: https://downloads.hindawi.com/journals/wcmc/2022/3301718.pdf
2025-11-13 00:06:01,785 - WARNING - root - 下载 Malicious Code Classification Method Based on Deep Residual Network and Hybrid Attention Mechanism for Edge Security (https://downloads.hindawi.com/journals/wcmc/2022/3301718.pdf) 失败: 403 Client Error: Forbidden for url: https://downloads.hindawi.com/journals/wcmc/2022/3301718.pdf
2025-11-13 00:06:01,786 - INFO - root - 正在下载: https://www.mdpi.com/2079-9292/11/22/3787/pdf?version=1669096288
2025-11-13 00:06:11,565 - INFO - root - 正在下载: https://www.mdpi.com/2079-9292/11/22/3787/pdf?version=1669096288
2025-11-13 00:06:21,691 - INFO - root - 正在下载: https://www.mdpi.com/2079-9292/11/22/3787/pdf?version=1669096288
2025-11-13 00:06:31,160 - INFO - root - 正在下载: https://www.mdpi.com/2079-9292/11/22/3787/pdf?version=1669096288
2025-11-13 00:06:46,220 - INFO - root - 正在下载: https://www.mdpi.com/2079-9292/11/22/3787/pdf?version=1669096288
2025-11-13 00:06:51,657 - WARNING - root - 下载 HA-Unet: A Modified Unet Based on Hybrid Attention for Urban Water Extraction in SAR Images (https://www.mdpi.com/2079-9292/11/22/3787/pdf?version=1669096288) 失败: 403 Client Error: Forbidden for url: https://www.mdpi.com/2079-9292/11/22/3787/pdf?version=1669096288
2025-11-13 00:06:51,660 - INFO - root - 正在下载: https://www.mdpi.com/2227-7390/10/11/1915/pdf?version=1654510435
2025-11-13 00:07:01,099 - INFO - root - 正在下载: https://www.mdpi.com/2227-7390/10/11/1915/pdf?version=1654510435
2025-11-13 00:07:10,557 - INFO - root - 正在下载: https://www.mdpi.com/2227-7390/10/11/1915/pdf?version=1654510435
2025-11-13 00:07:20,079 - INFO - root - 正在下载: https://www.mdpi.com/2227-7390/10/11/1915/pdf?version=1654510435
2025-11-13 00:07:33,528 - INFO - root - 正在下载: https://www.mdpi.com/2227-7390/10/11/1915/pdf?version=1654510435
2025-11-13 00:07:38,948 - WARNING - root - 下载 HA-RoadFormer: Hybrid Attention Transformer with Multi-Branch for Large-Scale High-Resolution Dense Road Segmentation (https://www.mdpi.com/2227-7390/10/11/1915/pdf?version=1654510435) 失败: 403 Client Error: Forbidden for url: https://www.mdpi.com/2227-7390/10/11/1915/pdf?version=1654510435
2025-11-13 00:07:38,949 - WARNING - root - 【手动下载提示】(无PDF): Generative adversarial network with hybrid attention and compromised normalization for multi-scene image conversion
	  URL: https://www.semanticscholar.org/paper/1defd0b952f393b189dc61bc421c8ae7dd4df3c2
	  Citations: 11 | Authors: Jinsheng Xiao, Shuhao Zhang, Yuntao Yao, Zhongyuan Wang, Yongqin Zhang, Yuan-fang Wang | Date: 2022-01-29
2025-11-13 00:07:38,952 - INFO - root - 正在下载: https://www.mdpi.com/2079-9292/11/17/2709/pdf?version=1661780513
2025-11-13 00:07:48,394 - INFO - root - 正在下载: https://www.mdpi.com/2079-9292/11/17/2709/pdf?version=1661780513
2025-11-13 00:07:57,851 - INFO - root - 正在下载: https://www.mdpi.com/2079-9292/11/17/2709/pdf?version=1661780513
2025-11-13 00:08:07,770 - INFO - root - 正在下载: https://www.mdpi.com/2079-9292/11/17/2709/pdf?version=1661780513
2025-11-13 00:08:21,477 - INFO - root - 正在下载: https://www.mdpi.com/2079-9292/11/17/2709/pdf?version=1661780513
2025-11-13 00:08:28,371 - WARNING - root - 下载 Occluded Vehicle Detection via Multi-Scale Hybrid Attention Mechanism in the Road Scene (https://www.mdpi.com/2079-9292/11/17/2709/pdf?version=1661780513) 失败: 403 Client Error: Forbidden for url: https://www.mdpi.com/2079-9292/11/17/2709/pdf?version=1661780513
2025-11-13 00:08:28,372 - WARNING - root - 【手动下载提示】(无PDF): A hybrid attention improved ResNet based fault diagnosis method of wind turbines gearbox
	  URL: https://www.semanticscholar.org/paper/c71d11b59d8a85d413af1dab9337e39e52910774
	  Citations: 161 | Authors: Kai Zhang, B. Tang, Lei Deng, Xiaoli Liu | Date: 2021-05-03
2025-11-13 00:08:28,374 - INFO - root - 正在下载: https://arxiv.org/pdf/2108.01316
2025-11-13 00:08:38,425 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\hybrid attention\RAIN_ Reinforced Hybrid Attention Inference Network for Motion Forecasting.pdf
2025-11-13 00:08:38,431 - INFO - root - 成功下载 (Semantic Scholar): RAIN: Reinforced Hybrid Attention Inference Network for Motion Forecasting
2025-11-13 00:08:38,431 - WARNING - root - 【手动下载提示】(无PDF): A hybrid attention mechanism for blind automatic modulation classification
	  URL: https://www.semanticscholar.org/paper/f226e86f57129dfa31db5c69c14163b9d3904988
	  Citations: 8 | Authors: Fan Jia, Yueyi Yang, Junyi Zhang, Yong Yang | Date: 2022-04-05
2025-11-13 00:08:38,433 - INFO - root - 正在下载: https://www.frontiersin.org/articles/10.3389/fmolb.2021.614174/pdf
2025-11-13 00:08:46,807 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\hybrid attention\A Hybrid-Attention Nested UNet for Nuclear Segmentation in Histopathological Images.pdf
2025-11-13 00:08:46,811 - INFO - root - 成功下载 (Semantic Scholar): A Hybrid-Attention Nested UNet for Nuclear Segmentation in Histopathological Images
2025-11-13 00:08:46,812 - INFO - root - 正在下载: https://ieeexplore.ieee.org/ielx7/4609443/9314330/09444168.pdf
2025-11-13 00:08:56,468 - INFO - root - 正在下载: https://ieeexplore.ieee.org/ielx7/4609443/9314330/09444168.pdf
2025-11-13 00:09:06,162 - INFO - root - 正在下载: https://ieeexplore.ieee.org/ielx7/4609443/9314330/09444168.pdf
2025-11-13 00:09:15,810 - INFO - root - 正在下载: https://ieeexplore.ieee.org/ielx7/4609443/9314330/09444168.pdf
2025-11-13 00:09:29,562 - INFO - root - 正在下载: https://ieeexplore.ieee.org/ielx7/4609443/9314330/09444168.pdf
2025-11-13 00:09:35,699 - WARNING - root - 下载 MHA-Net: Multipath Hybrid Attention Network for Building Footprint Extraction From High-Resolution Remote Sensing Imagery (https://ieeexplore.ieee.org/ielx7/4609443/9314330/09444168.pdf) 失败: 418 Client Error: Unknown Code for url: https://ieeexplore.ieee.org/ielx7/4609443/9314330/09444168.pdf
2025-11-13 00:09:35,711 - INFO - root - 正在下载: https://ieeexplore.ieee.org/ielx7/6287639/6514899/09837031.pdf
2025-11-13 00:09:45,469 - INFO - root - 正在下载: https://ieeexplore.ieee.org/ielx7/6287639/6514899/09837031.pdf
2025-11-13 00:09:55,386 - INFO - root - 正在下载: https://ieeexplore.ieee.org/ielx7/6287639/6514899/09837031.pdf
2025-11-13 00:10:05,104 - INFO - root - 正在下载: https://ieeexplore.ieee.org/ielx7/6287639/6514899/09837031.pdf
2025-11-13 00:10:19,801 - INFO - root - 正在下载: https://ieeexplore.ieee.org/ielx7/6287639/6514899/09837031.pdf
2025-11-13 00:10:25,487 - WARNING - root - 下载 Dual-Path Hybrid Attention Network for Monaural Speech Separation (https://ieeexplore.ieee.org/ielx7/6287639/6514899/09837031.pdf) 失败: 418 Client Error: Unknown Code for url: https://ieeexplore.ieee.org/ielx7/6287639/6514899/09837031.pdf
2025-11-13 00:10:25,490 - WARNING - root - 【手动下载提示】(无PDF): Neural machine translation for Indian language pair using hybrid attention mechanism
	  URL: https://www.semanticscholar.org/paper/3479ff37a0bb3858b1761a871b81f4ca3dd26454
	  Citations: 7 | Authors: Basab Nath, Sunita Sarkar, Surajeet Das, Somnath Mukhopadhyay | Date: 2022-02-01
2025-11-13 00:10:25,501 - INFO - root - 检索到 17 篇论文（包括待手动下载的），开始总结...
2025-11-13 00:10:25,507 - INFO - root - --- 开始论文总结阶段 ---
2025-11-13 00:10:25,515 - INFO - root - 跳过已处理论文 Hybrid Attention Fusion Embedded in Transformer for Remote Sensing Image Semantic Segmentation：D:\ChatPaper\api_downloads\hybrid attention\Hybrid Attention Fusion Embedded in Transformer for Remote Sensing Image Semantic Segmentation.pdf
2025-11-13 00:10:25,531 - INFO - root - 跳过已处理论文 YOLO Algorithm With Hybrid Attention Feature Pyramid Network for Solder Joint Defect Detection：D:\ChatPaper\api_downloads\hybrid attention\YOLO Algorithm With Hybrid Attention Feature Pyramid Network for Solder Joint Defect Detection.pdf
2025-11-13 00:10:25,538 - INFO - root - 跳过已处理论文 Frequency Enhanced Hybrid Attention Network for Sequential Recommendation：D:\ChatPaper\api_downloads\hybrid attention\Frequency Enhanced Hybrid Attention Network for Sequential Recommendation.pdf
2025-11-13 00:10:25,540 - INFO - root - 跳过已处理论文 HAT: Hybrid Attention Transformer for Image Restoration：D:\ChatPaper\api_downloads\hybrid attention\HAT_ Hybrid Attention Transformer for Image Restoration.pdf
2025-11-13 00:10:25,562 - INFO - root - 跳过已处理论文 Multi-scale deep residual shrinkage networks with a hybrid attention mechanism for rolling bearing fault diagnosis：D:\ChatPaper\api_downloads\hybrid attention\Multi-scale deep residual shrinkage networks with a hybrid attention mechanism for rolling bearing f.pdf
2025-11-13 00:10:25,582 - INFO - root - 跳过已处理论文 Physics Inspired Hybrid Attention for SAR Target Recognition：D:\ChatPaper\api_downloads\hybrid attention\Physics Inspired Hybrid Attention for SAR Target Recognition.pdf
2025-11-13 00:10:25,593 - INFO - root - 跳过已处理论文 Fine-grained image classification method based on hybrid attention module：D:\ChatPaper\api_downloads\hybrid attention\Fine-grained image classification method based on hybrid attention module.pdf
2025-11-13 00:10:25,594 - INFO - root - 跳过已处理论文 Hybrid Attention-Based Prototypical Networks for Noisy Few-Shot Relation Classification：D:\ChatPaper\api_downloads\hybrid attention\Hybrid Attention-Based Prototypical Networks for Noisy Few-Shot Relation Classification.pdf
2025-11-13 00:10:25,594 - INFO - root - 跳过已处理论文 Dual-view Correlation Hybrid Attention Network for Robust Holistic Mammogram Classification：D:\ChatPaper\api_downloads\hybrid attention\Dual-view Correlation Hybrid Attention Network for Robust Holistic Mammogram Classification.pdf
2025-11-13 00:10:25,595 - INFO - root - 跳过已处理论文 Stacked Hybrid-Attention and Group Collaborative Learning for Unbiased Scene Graph Generation：D:\ChatPaper\api_downloads\hybrid attention\Stacked Hybrid-Attention and Group Collaborative Learning for Unbiased Scene Graph Generation.pdf
2025-11-13 00:10:25,606 - INFO - root - 跳过已处理论文 Hybridformer: Improving Squeezeformer with Hybrid Attention and NSR Mechanism：D:\ChatPaper\api_downloads\hybrid attention\Hybridformer_ Improving Squeezeformer with Hybrid Attention and NSR Mechanism.pdf
2025-11-13 00:10:25,636 - INFO - root - 跳过已处理论文 HAC-Net: A Hybrid Attention-Based Convolutional Neural Network for Highly Accurate Protein-Ligand Binding Affinity Prediction：D:\ChatPaper\api_downloads\hybrid attention\HAC-Net_ A Hybrid Attention-Based Convolutional Neural Network for Highly Accurate Protein-Ligand Bi.pdf
2025-11-13 00:10:25,663 - INFO - root - 跳过已处理论文 A Hybrid Attention Mechanism for Weakly-Supervised Temporal Action Localization：D:\ChatPaper\api_downloads\hybrid attention\A Hybrid Attention Mechanism for Weakly-Supervised Temporal Action Localization.pdf
2025-11-13 00:10:25,690 - INFO - root - 跳过已处理论文 RHA-Net: An Encoder-Decoder Network with Residual Blocks and Hybrid Attention Mechanisms for Pavement Crack Segmentation：D:\ChatPaper\api_downloads\hybrid attention\RHA-Net_ An Encoder-Decoder Network with Residual Blocks and Hybrid Attention Mechanisms for Pavemen.pdf
2025-11-13 00:10:25,708 - INFO - root - 跳过已处理论文 HHTrack: Hyperspectral Object Tracking Using Hybrid Attention：D:\ChatPaper\api_downloads\hybrid attention\HHTrack_ Hyperspectral Object Tracking Using Hybrid Attention.pdf
2025-11-13 00:10:25,739 - INFO - root - 正在总结论文 16/17: RAIN: Reinforced Hybrid Attention Inference Network for Motion Forecasting
2025-11-13 00:10:35,807 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-13 00:11:33,030 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-13 00:12:05,014 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-13 00:12:05,021 - INFO - root - 正在提取论文图片到目录: ./export\hybrid attention\images\RAIN_ Reinforced Hybrid Attention Inference Network for Motion Forecasting
2025-11-13 00:12:05,893 - INFO - root - 已保存图片 1/10：./export\hybrid attention\images\RAIN_ Reinforced Hybrid Attention Inference Network for Motion Forecasting\figure_1_page8.png
2025-11-13 00:12:06,055 - INFO - root - 已保存图片 2/10：./export\hybrid attention\images\RAIN_ Reinforced Hybrid Attention Inference Network for Motion Forecasting\figure_2_page8.png
2025-11-13 00:12:06,182 - INFO - root - 已保存图片 3/10：./export\hybrid attention\images\RAIN_ Reinforced Hybrid Attention Inference Network for Motion Forecasting\figure_3_page8.png
2025-11-13 00:12:06,456 - INFO - root - 已保存图片 4/10：./export\hybrid attention\images\RAIN_ Reinforced Hybrid Attention Inference Network for Motion Forecasting\figure_4_page8.png
2025-11-13 00:12:06,653 - INFO - root - 已保存图片 5/10：./export\hybrid attention\images\RAIN_ Reinforced Hybrid Attention Inference Network for Motion Forecasting\figure_5_page7.png
2025-11-13 00:12:06,845 - INFO - root - 已保存图片 6/10：./export\hybrid attention\images\RAIN_ Reinforced Hybrid Attention Inference Network for Motion Forecasting\figure_6_page7.png
2025-11-13 00:12:06,958 - INFO - root - 已保存图片 7/10：./export\hybrid attention\images\RAIN_ Reinforced Hybrid Attention Inference Network for Motion Forecasting\figure_7_page7.png
2025-11-13 00:12:07,062 - INFO - root - 已保存图片 8/10：./export\hybrid attention\images\RAIN_ Reinforced Hybrid Attention Inference Network for Motion Forecasting\figure_8_page7.png
2025-11-13 00:12:07,152 - INFO - root - 已保存图片 9/10：./export\hybrid attention\images\RAIN_ Reinforced Hybrid Attention Inference Network for Motion Forecasting\figure_9_page7.png
2025-11-13 00:12:07,238 - INFO - root - 已保存图片 10/10：./export\hybrid attention\images\RAIN_ Reinforced Hybrid Attention Inference Network for Motion Forecasting\figure_10_page7.png
2025-11-13 00:12:07,246 - INFO - root - 成功添加图片 1：./export\hybrid attention\images\RAIN_ Reinforced Hybrid Attention Inference Network for Motion Forecasting\figure_1_page8.png
2025-11-13 00:12:07,247 - INFO - root - 成功添加图片 2：./export\hybrid attention\images\RAIN_ Reinforced Hybrid Attention Inference Network for Motion Forecasting\figure_2_page8.png
2025-11-13 00:12:07,248 - INFO - root - 成功添加图片 3：./export\hybrid attention\images\RAIN_ Reinforced Hybrid Attention Inference Network for Motion Forecasting\figure_3_page8.png
2025-11-13 00:12:07,249 - INFO - root - 成功添加图片 4：./export\hybrid attention\images\RAIN_ Reinforced Hybrid Attention Inference Network for Motion Forecasting\figure_4_page8.png
2025-11-13 00:12:07,249 - INFO - root - 成功添加图片 5：./export\hybrid attention\images\RAIN_ Reinforced Hybrid Attention Inference Network for Motion Forecasting\figure_5_page7.png
2025-11-13 00:12:07,249 - INFO - root - 成功添加图片 6：./export\hybrid attention\images\RAIN_ Reinforced Hybrid Attention Inference Network for Motion Forecasting\figure_6_page7.png
2025-11-13 00:12:07,250 - INFO - root - 成功添加图片 7：./export\hybrid attention\images\RAIN_ Reinforced Hybrid Attention Inference Network for Motion Forecasting\figure_7_page7.png
2025-11-13 00:12:07,250 - INFO - root - 成功添加图片 8：./export\hybrid attention\images\RAIN_ Reinforced Hybrid Attention Inference Network for Motion Forecasting\figure_8_page7.png
2025-11-13 00:12:07,251 - INFO - root - 成功添加图片 9：./export\hybrid attention\images\RAIN_ Reinforced Hybrid Attention Inference Network for Motion Forecasting\figure_9_page7.png
2025-11-13 00:12:07,251 - INFO - root - 成功添加图片 10：./export\hybrid attention\images\RAIN_ Reinforced Hybrid Attention Inference Network for Motion Forecasting\figure_10_page7.png
2025-11-13 00:12:07,256 - INFO - root - 论文《RAIN: Reinforced Hybrid Attention Inference Network for Motion Forecasting》的分析已保存到 ./export\hybrid attention\RAIN_ Reinforced Hybrid Attention Inference Network for Motion Forecasting.md
2025-11-13 00:12:07,277 - INFO - root - 正在总结论文 17/17: A Hybrid-Attention Nested UNet for Nuclear Segmentation in Histopathological Images
2025-11-13 00:12:15,254 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-13 00:12:15,256 - INFO - root - LLMClient: rate limit reached, sleeping 17.8s
2025-11-13 00:13:18,730 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-13 00:13:49,923 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-13 00:13:49,941 - INFO - root - 正在提取论文图片到目录: ./export\hybrid attention\images\A Hybrid-Attention Nested UNet for Nuclear Segmentation in Histopathological Images
2025-11-13 00:13:50,264 - INFO - root - 已保存图片 1/10：./export\hybrid attention\images\A Hybrid-Attention Nested UNet for Nuclear Segmentation in Histopathological Images\figure_1_page5.jpeg
2025-11-13 00:13:50,394 - INFO - root - 已保存图片 2/10：./export\hybrid attention\images\A Hybrid-Attention Nested UNet for Nuclear Segmentation in Histopathological Images\figure_2_page4.jpeg
2025-11-13 00:13:50,501 - INFO - root - 已保存图片 3/10：./export\hybrid attention\images\A Hybrid-Attention Nested UNet for Nuclear Segmentation in Histopathological Images\figure_3_page2.jpeg
2025-11-13 00:13:50,611 - INFO - root - 已保存图片 4/10：./export\hybrid attention\images\A Hybrid-Attention Nested UNet for Nuclear Segmentation in Histopathological Images\figure_4_page3.jpeg
2025-11-13 00:13:50,614 - INFO - root - 成功添加图片 1：./export\hybrid attention\images\A Hybrid-Attention Nested UNet for Nuclear Segmentation in Histopathological Images\figure_1_page5.jpeg
2025-11-13 00:13:50,614 - INFO - root - 成功添加图片 2：./export\hybrid attention\images\A Hybrid-Attention Nested UNet for Nuclear Segmentation in Histopathological Images\figure_2_page4.jpeg
2025-11-13 00:13:50,614 - INFO - root - 成功添加图片 3：./export\hybrid attention\images\A Hybrid-Attention Nested UNet for Nuclear Segmentation in Histopathological Images\figure_3_page2.jpeg
2025-11-13 00:13:50,620 - INFO - root - 成功添加图片 4：./export\hybrid attention\images\A Hybrid-Attention Nested UNet for Nuclear Segmentation in Histopathological Images\figure_4_page3.jpeg
2025-11-13 00:13:50,624 - INFO - root - 论文《A Hybrid-Attention Nested UNet for Nuclear Segmentation in Histopathological Images》的分析已保存到 ./export\hybrid attention\A Hybrid-Attention Nested UNet for Nuclear Segmentation in Histopathological Images.md
2025-11-13 00:13:50,630 - INFO - root - --- 论文总结阶段结束 ---
2025-11-13 00:13:50,630 - INFO - root - --- 开始生成 Excel 报告 (包含 17 篇论文) ---
2025-11-13 00:13:50,727 - INFO - root - 检测到已存在的 Excel 文件: export\hybrid_attention_summary.xlsx。正在追加...
2025-11-13 00:13:50,864 - INFO - root - 合并后: 18 条记录 (新增 2 条)
2025-11-13 00:13:51,149 - INFO - root - 成功保存 Excel: export\hybrid_attention_summary.xlsx
2025-11-13 00:13:51,156 - INFO - root - 已生成或更新汇总 Excel 表格: export\hybrid_attention_summary.xlsx
2025-11-13 00:13:51,157 - INFO - root - 总运行时间: 1277.21 seconds
2025-11-14 21:46:28,096 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-14 21:46:28,103 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-14 21:46:28,106 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-14 21:46:34,241 - INFO - root - LLMClientManager: 指定使用客户端: Gemini
2025-11-14 21:46:35,030 - INFO - root - GeminiClient: trying model models/gemini-2.5-flash
2025-11-14 21:46:43,616 - INFO - root - GeminiClient: initialized model gemini-2.5-flash
2025-11-14 21:46:43,617 - INFO - root - LLMClientManager: Gemini 客户端初始化成功
2025-11-14 21:46:43,618 - INFO - root - LLMClientManager: switched to Gemini client
2025-11-14 21:46:43,618 - INFO - root - 已手动切换到 LLM 客户端: Gemini
2025-11-14 21:46:43,619 - INFO - root - 使用 LLM 模型: gemini-2.5-flash
2025-11-14 21:46:43,619 - INFO - root - 可用客户端: ['Gemini']
2025-11-14 21:46:43,620 - INFO - root - === 运行配置 ===
2025-11-14 21:46:43,621 - INFO - root - 处理模式: Semantic Scholar 高引用搜索 (API)
2025-11-14 21:46:43,622 - INFO - root - 查询 (关键词): hybrid attention
2025-11-14 21:46:43,622 - INFO - root - 关键词 (用于保存): hybrid attention
2025-11-14 21:46:43,622 - INFO - root - 排序: citationCount:desc
2025-11-14 21:46:43,623 - INFO - root - 最大处理数量: 150
2025-11-14 21:46:43,624 - INFO - root - 保存图片: 是
2025-11-14 21:46:43,624 - INFO - root - 输出语言: 中文
2025-11-14 21:46:43,625 - INFO - root - 强制重新处理: 否
2025-11-14 21:46:43,626 - INFO - root - LLM 客户端: Gemini
2025-11-14 21:46:43,626 - INFO - root - ====================
2025-11-14 21:46:43,627 - INFO - root - 正在使用检索策略: semantic
2025-11-14 21:46:43,627 - INFO - root - 使用 Semantic Scholar 高引用搜索模式 (API)
2025-11-14 21:46:43,628 - INFO - root - Semantic API 查询: query=hybrid attention, limit=150, sort=citationCount:desc
2025-11-14 21:46:43,628 - INFO - root - 正在调用 Semantic Scholar API...
2025-11-14 21:46:49,753 - INFO - root - 正在调用 Semantic Scholar API...
2025-11-14 21:46:54,680 - INFO - root - 正在调用 Semantic Scholar API...
2025-11-14 21:46:59,952 - INFO - root - 正在调用 Semantic Scholar API...
2025-11-14 21:47:09,456 - INFO - root - 正在调用 Semantic Scholar API...
2025-11-14 21:47:10,406 - ERROR - root - Semantic Scholar API 请求失败: 500 Server Error: Internal Server Error for url: https://api.semanticscholar.org/graph/v1/paper/search?query=hybrid+attention&limit=150&sort=citationCount%3Adesc&fields=title%2Curl%2Cabstract%2Cauthors%2CpublicationDate%2CcitationCount%2CopenAccessPdf
Traceback (most recent call last):
  File "D:\ChatPaper\retrievers.py", line 269, in retrieve
    response = self._call_api(params)
               ^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\tenacity\__init__.py", line 338, in wrapped_f
    return copy(f, *args, **kw)
           ^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\tenacity\__init__.py", line 477, in __call__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\tenacity\__init__.py", line 378, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\tenacity\__init__.py", line 420, in exc_check
    raise retry_exc.reraise()
          ^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\tenacity\__init__.py", line 187, in reraise
    raise self.last_attempt.result()
          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "D:\ChatPaper\.venv\Lib\site-packages\tenacity\__init__.py", line 480, in __call__
    result = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\retrievers.py", line 250, in _call_api
    response.raise_for_status() # 请求失败(如 429)则抛出异常，触发重试
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\requests\models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 500 Server Error: Internal Server Error for url: https://api.semanticscholar.org/graph/v1/paper/search?query=hybrid+attention&limit=150&sort=citationCount%3Adesc&fields=title%2Curl%2Cabstract%2Cauthors%2CpublicationDate%2CcitationCount%2CopenAccessPdf
2025-11-14 21:47:10,498 - INFO - root - 没有找到要处理的论文，程序退出
2025-11-14 21:47:10,586 - INFO - root - 总运行时间: 42.49 seconds
2025-11-14 22:02:02,008 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-14 22:02:02,010 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-14 22:02:02,011 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-14 22:02:05,896 - INFO - root - LLMClientManager: 指定使用客户端: Gemini
2025-11-14 22:03:01,898 - ERROR - root - GeminiClient: error during initialization: Timeout of 60.0s exceeded, last exception: 503 failed to connect to all addresses; last error: UNKNOWN: ipv4:142.251.34.202:443: socket is null
2025-11-14 22:03:01,899 - ERROR - root - LLMClientManager: 指定的客户端 Gemini 初始化失败
2025-11-14 22:03:01,900 - WARNING - root - LLMClientManager: 指定的客户端 Gemini 不可用，将尝试其他客户端
2025-11-14 22:03:01,901 - INFO - root - DeepSeekClient: API key found: 9f9e270e-b...
2025-11-14 22:03:01,901 - INFO - root - DeepSeekClient: 使用模式: 火山引擎
2025-11-14 22:03:01,902 - INFO - root - DeepSeekClient: 模型名称: deepseek-v3-1-terminus
2025-11-14 22:03:05,815 - INFO - openai._base_client - Retrying request to /chat/completions in 0.439505 seconds
2025-11-14 22:03:08,280 - INFO - openai._base_client - Retrying request to /chat/completions in 0.953643 seconds
2025-11-14 22:03:11,261 - ERROR - root - DeepSeekClient: error during initialization: Connection error.
2025-11-14 22:03:11,263 - WARNING - root - LLMClientManager: DeepSeek client initialization failed
2025-11-14 22:03:11,263 - WARNING - root - KimiClient: API key not provided. LLM disabled.
2025-11-14 22:03:11,264 - WARNING - root - LLMClientManager: Kimi client initialization failed
2025-11-14 22:03:11,265 - WARNING - root - QwenClient: API key not provided. LLM disabled.
2025-11-14 22:03:11,266 - WARNING - root - LLMClientManager: Qwen client initialization failed
2025-11-14 22:03:11,267 - INFO - root - DoubaoClient: API key found: 9f9e270e-b...
2025-11-14 22:03:14,343 - INFO - openai._base_client - Retrying request to /chat/completions in 0.415300 seconds
2025-11-14 22:03:16,789 - INFO - openai._base_client - Retrying request to /chat/completions in 0.826033 seconds
2025-11-14 22:03:19,637 - ERROR - root - DoubaoClient: error during initialization: Connection error.
2025-11-14 22:03:19,638 - WARNING - root - LLMClientManager: Doubao client initialization failed
2025-11-14 22:03:19,640 - WARNING - root - LLMClientManager: no LLM client available
2025-11-14 22:03:19,641 - WARNING - root - LLMClientManager: client Gemini not available. Available clients: []
2025-11-14 22:03:19,642 - WARNING - root - 无法切换到指定的客户端 Gemini，将使用默认客户端
2025-11-14 22:03:19,643 - INFO - root - 可用客户端: []
2025-11-14 22:03:19,643 - INFO - root - LLM 未初始化或不可用，后续生成将返回备用消息
2025-11-14 22:03:19,644 - INFO - root - === 运行配置 ===
2025-11-14 22:03:19,645 - INFO - root - 处理模式: Semantic Scholar 高引用搜索 (API)
2025-11-14 22:03:19,646 - INFO - root - 查询 (关键词): hybrid attention
2025-11-14 22:03:19,646 - INFO - root - 关键词 (用于保存): hybrid attention
2025-11-14 22:03:19,648 - INFO - root - 排序: citationCount:desc
2025-11-14 22:03:19,649 - INFO - root - 最大处理数量: 100
2025-11-14 22:03:19,651 - INFO - root - 保存图片: 是
2025-11-14 22:03:19,651 - INFO - root - 输出语言: 中文
2025-11-14 22:03:19,653 - INFO - root - 强制重新处理: 否
2025-11-14 22:03:19,656 - INFO - root - LLM 客户端: Gemini
2025-11-14 22:03:19,656 - INFO - root - ====================
2025-11-14 22:03:19,657 - INFO - root - 正在使用检索策略: semantic
2025-11-14 22:03:19,658 - INFO - root - 使用 Semantic Scholar 高引用搜索模式 (API)
2025-11-14 22:03:19,659 - INFO - root - Semantic API 查询: query=hybrid attention, limit=100, sort=citationCount:desc
2025-11-14 22:03:19,665 - INFO - root - 正在调用 Semantic Scholar API...
2025-11-14 22:03:21,701 - ERROR - root - 处理 Semantic Scholar 结果时出错: HTTPSConnectionPool(host='api.semanticscholar.org', port=443): Max retries exceeded with url: /graph/v1/paper/search?query=hybrid+attention&limit=100&sort=citationCount%3Adesc&fields=title%2Curl%2Cabstract%2Cauthors%2CpublicationDate%2CcitationCount%2CopenAccessPdf (Caused by ProxyError('Unable to connect to proxy', NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x000001EEB4BAAC30>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。')))
Traceback (most recent call last):
  File "D:\ChatPaper\.venv\Lib\site-packages\urllib3\connection.py", line 198, in _new_conn
    sock = connection.create_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    raise err
  File "D:\ChatPaper\.venv\Lib\site-packages\urllib3\util\connection.py", line 73, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "D:\ChatPaper\.venv\Lib\site-packages\urllib3\connectionpool.py", line 773, in urlopen
    self._prepare_proxy(conn)
  File "D:\ChatPaper\.venv\Lib\site-packages\urllib3\connectionpool.py", line 1042, in _prepare_proxy
    conn.connect()
  File "D:\ChatPaper\.venv\Lib\site-packages\urllib3\connection.py", line 753, in connect
    self.sock = sock = self._new_conn()
                       ^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\urllib3\connection.py", line 213, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPSConnection object at 0x000001EEB4BAAC30>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

The above exception was the direct cause of the following exception:

urllib3.exceptions.ProxyError: ('Unable to connect to proxy', NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x000001EEB4BAAC30>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "D:\ChatPaper\.venv\Lib\site-packages\requests\adapters.py", line 644, in send
    resp = conn.urlopen(
           ^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\urllib3\connectionpool.py", line 841, in urlopen
    retries = retries.increment(
              ^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\urllib3\util\retry.py", line 519, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='api.semanticscholar.org', port=443): Max retries exceeded with url: /graph/v1/paper/search?query=hybrid+attention&limit=100&sort=citationCount%3Adesc&fields=title%2Curl%2Cabstract%2Cauthors%2CpublicationDate%2CcitationCount%2CopenAccessPdf (Caused by ProxyError('Unable to connect to proxy', NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x000001EEB4BAAC30>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。')))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\ChatPaper\retrievers.py", line 269, in retrieve
    response = self._call_api(params)
               ^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\tenacity\__init__.py", line 338, in wrapped_f
    return copy(f, *args, **kw)
           ^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\tenacity\__init__.py", line 477, in __call__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\tenacity\__init__.py", line 378, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\tenacity\__init__.py", line 400, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "D:\ChatPaper\.venv\Lib\site-packages\tenacity\__init__.py", line 480, in __call__
    result = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\retrievers.py", line 249, in _call_api
    response = requests.get(self.API_URL, params=params, timeout=30)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\requests\api.py", line 73, in get
    return request("get", url, params=params, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\requests\api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\requests\sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\requests\sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\requests\adapters.py", line 671, in send
    raise ProxyError(e, request=request)
requests.exceptions.ProxyError: HTTPSConnectionPool(host='api.semanticscholar.org', port=443): Max retries exceeded with url: /graph/v1/paper/search?query=hybrid+attention&limit=100&sort=citationCount%3Adesc&fields=title%2Curl%2Cabstract%2Cauthors%2CpublicationDate%2CcitationCount%2CopenAccessPdf (Caused by ProxyError('Unable to connect to proxy', NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x000001EEB4BAAC30>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。')))
2025-11-14 22:03:21,742 - INFO - root - 没有找到要处理的论文，程序退出
2025-11-14 22:03:21,743 - INFO - root - 总运行时间: 79.73 seconds
2025-11-14 22:03:52,104 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-14 22:03:52,105 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-14 22:03:52,107 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-14 22:03:55,675 - INFO - root - LLMClientManager: 指定使用客户端: Gemini
2025-11-14 22:03:56,603 - INFO - root - GeminiClient: trying model models/gemini-2.5-flash
2025-11-14 22:04:48,018 - INFO - root - GeminiClient: trying model models/gemini-2.5-pro
2025-11-14 22:05:07,349 - INFO - root - GeminiClient: initialized model gemini-2.5-pro
2025-11-14 22:05:07,351 - INFO - root - LLMClientManager: Gemini 客户端初始化成功
2025-11-14 22:05:07,352 - INFO - root - LLMClientManager: switched to Gemini client
2025-11-14 22:05:07,354 - INFO - root - 已手动切换到 LLM 客户端: Gemini
2025-11-14 22:05:07,354 - INFO - root - 使用 LLM 模型: gemini-2.5-pro
2025-11-14 22:05:07,358 - INFO - root - 可用客户端: ['Gemini']
2025-11-14 22:05:07,361 - INFO - root - === 运行配置 ===
2025-11-14 22:05:07,363 - INFO - root - 处理模式: Semantic Scholar 高引用搜索 (API)
2025-11-14 22:05:07,365 - INFO - root - 查询 (关键词): hybrid attention
2025-11-14 22:05:07,365 - INFO - root - 关键词 (用于保存): hybrid attention
2025-11-14 22:05:07,368 - INFO - root - 排序: citationCount:desc
2025-11-14 22:05:07,370 - INFO - root - 最大处理数量: 100
2025-11-14 22:05:07,371 - INFO - root - 保存图片: 是
2025-11-14 22:05:07,372 - INFO - root - 输出语言: 中文
2025-11-14 22:05:07,372 - INFO - root - 强制重新处理: 否
2025-11-14 22:05:07,374 - INFO - root - LLM 客户端: Gemini
2025-11-14 22:05:07,382 - INFO - root - ====================
2025-11-14 22:05:07,387 - INFO - root - 正在使用检索策略: semantic
2025-11-14 22:05:07,441 - INFO - root - 使用 Semantic Scholar 高引用搜索模式 (API)
2025-11-14 22:05:07,444 - INFO - root - Semantic API 查询: query=hybrid attention, limit=100, sort=citationCount:desc
2025-11-14 22:05:07,446 - INFO - root - 正在调用 Semantic Scholar API...
2025-11-14 22:05:15,592 - WARNING - root - 【手动下载提示】(无PDF): An Instrument Indication Acquisition Algorithm Based on Lightweight Deep Convolutional Neural Network and Hybrid Attention Fine-Grained Features
	  URL: https://www.semanticscholar.org/paper/49f99d7a21e2ded7915676753a180983763b9a22
	  Citations: 66 | Authors: Jiaquan Shen, Ningzhong Liu, Han Sun, Deguang Li, Yongxin Zhang | Date: N/A
2025-11-14 22:05:15,594 - WARNING - root - 【手动下载提示】(无PDF): Enhancing ASD classification through hybrid attention-based learning of facial features
	  URL: https://www.semanticscholar.org/paper/22547aa4c72c7c2799932a0f451ab3f2db6d7d0f
	  Citations: 35 | Authors: Inzamam Shahzad, Saif Ur Rehman Khan, Waseem Abbas, Z. U. Abideen, Jin Liu | Date: 2024-04-21
2025-11-14 22:05:15,595 - WARNING - root - 【手动下载提示】(无PDF): Dual-Hybrid Attention Network for Specular Highlight Removal
	  URL: https://www.semanticscholar.org/paper/d56ce689cc0f8b1cf0e5f58882503a5e59ec440b
	  Citations: 33 | Authors: Xiaojiao Guo, Xuhang Chen, Shenghong Luo, Shuqiang Wang, Chi-Man Pun | Date: 2024-07-17
2025-11-14 22:05:15,595 - WARNING - root - 【手动下载提示】(无PDF): HyA-GAN: remote sensing image cloud removal based on hybrid attention generation adversarial network
	  URL: https://www.semanticscholar.org/paper/905b42f2f8d912d98fd7cbec4f7b244401176acc
	  Citations: 16 | Authors: Minghao Jin, Pengwei Wang, Yusong Li | Date: 2024-02-27
2025-11-14 22:05:15,595 - WARNING - root - 【手动下载提示】(无PDF): Hybrid Attention-Aware Transformer Network Collaborative Multiscale Feature Alignment for Building Change Detection
	  URL: https://www.semanticscholar.org/paper/a0f8053046622628073ac6f051b5181a80cb7ad3
	  Citations: 28 | Authors: Chuan Xu, Zhaoyi Ye, Liye Mei, Haonan Yu, Jianchen Liu, Yaxiaer Yalikun, Shuangtong Jin, Sheng Liu, Wei Yang, Cheng Lei | Date: N/A
2025-11-14 22:05:15,596 - WARNING - root - 【手动下载提示】(无PDF): Radar Signal Recognition Based on CNN With a Hybrid Attention Mechanism and Skip Feature Aggregation
	  URL: https://www.semanticscholar.org/paper/dacad703c49e9434321c91220219638f871fd9d2
	  Citations: 26 | Authors: Yuanpu Guo, Haixin Sun, Hui Liu, Zhen-miao Deng | Date: N/A
2025-11-14 22:05:15,598 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\hybrid attention\Hybrid Attention Fusion Embedded in Transformer for Remote Sensing Image Semantic Segmentation.pdf
2025-11-14 22:05:15,598 - INFO - root - 成功下载 (Semantic Scholar): Hybrid Attention Fusion Embedded in Transformer for Remote Sensing Image Semantic Segmentation
2025-11-14 22:05:15,599 - WARNING - root - 【手动下载提示】(无PDF): Probabilistic Multienergy Load Forecasting Based on Hybrid Attention-Enabled Transformer Network and Gaussian Process-Aided Residual Learning
	  URL: https://www.semanticscholar.org/paper/a2d81cc04f73e2898fb16e7e8c8f9cf69adadfd5
	  Citations: 16 | Authors: Pengfei Zhao, Weihao Hu, Di Cao, Zhenyuan Zhang, Yuehui Huang, Longcheng Dai, Zhe Chen | Date: 2024-06-01
2025-11-14 22:05:15,599 - WARNING - root - 【手动下载提示】(无PDF): Enhancing Time Series Product Demand Forecasting With Hybrid Attention-Based Deep Learning Models
	  URL: https://www.semanticscholar.org/paper/4848b35cbe515f8909a67a82dcb83d7c5e48f74b
	  Citations: 14 | Authors: Xuguang Zhang, Pan Li, Xu Han, Yongbin Yang, Yiwen Cui | Date: N/A
2025-11-14 22:05:15,600 - INFO - root - 正在下载: https://www.mdpi.com/2306-5354/11/3/240/pdf?version=1709132347
2025-11-14 22:05:25,258 - INFO - root - 正在下载: https://www.mdpi.com/2306-5354/11/3/240/pdf?version=1709132347
2025-11-14 22:05:34,822 - INFO - root - 正在下载: https://www.mdpi.com/2306-5354/11/3/240/pdf?version=1709132347
2025-11-14 22:05:44,499 - INFO - root - 正在下载: https://www.mdpi.com/2306-5354/11/3/240/pdf?version=1709132347
2025-11-14 22:05:58,427 - INFO - root - 正在下载: https://www.mdpi.com/2306-5354/11/3/240/pdf?version=1709132347
2025-11-14 22:06:03,926 - WARNING - root - 下载 Advancing Ocular Imaging: A Hybrid Attention Mechanism-Based U-Net Model for Precise Segmentation of Sub-Retinal Layers in OCT Images (https://www.mdpi.com/2306-5354/11/3/240/pdf?version=1709132347) 失败: 403 Client Error: Forbidden for url: https://www.mdpi.com/2306-5354/11/3/240/pdf?version=1709132347
2025-11-14 22:06:03,928 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\hybrid attention\YOLO Algorithm With Hybrid Attention Feature Pyramid Network for Solder Joint Defect Detection.pdf
2025-11-14 22:06:03,929 - INFO - root - 成功下载 (Semantic Scholar): YOLO Algorithm With Hybrid Attention Feature Pyramid Network for Solder Joint Defect Detection
2025-11-14 22:06:03,930 - WARNING - root - 【手动下载提示】(无PDF): A novel approach for bearings multiclass fault diagnosis fusing multiscale deep convolution and hybrid attention networks
	  URL: https://www.semanticscholar.org/paper/bf72523fe518b2e4ce4d75d125dd5220177043f6
	  Citations: 13 | Authors: Fule Li, Xinlong Zhao | Date: 2024-01-08
2025-11-14 22:06:03,932 - WARNING - root - 【手动下载提示】(无PDF): Drone-HAT: Hybrid Attention Transformer for Complex Action Recognition in Drone Surveillance Videos
	  URL: https://www.semanticscholar.org/paper/a76690fb96dc7d3dfd5f8fec62c3949cc7ec96f6
	  Citations: 12 | Authors: Mustaqeem Khan, Jamil Ahmad, Abdulmotaleb El-Saddik, W. Gueaieb, Giulia De Masi, Fakhri Karray | Date: 2024-06-17
2025-11-14 22:06:03,933 - WARNING - root - 【手动下载提示】(无PDF): Dense Hybrid Attention Network for Palmprint Image Super-Resolution
	  URL: https://www.semanticscholar.org/paper/75746d8d52509b24d9975d9b3b07ae91311dc7ed
	  Citations: 12 | Authors: Yao Wang, Lunke Fei, Shuping Zhao, Qi Zhu, Jie Wen, Wei Jia, Imad Rida | Date: 2024-04-01
2025-11-14 22:06:03,938 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\hybrid attention\Frequency Enhanced Hybrid Attention Network for Sequential Recommendation.pdf
2025-11-14 22:06:03,944 - INFO - root - 成功下载 (Semantic Scholar): Frequency Enhanced Hybrid Attention Network for Sequential Recommendation
2025-11-14 22:06:03,948 - WARNING - root - 【手动下载提示】(无PDF): A Multiscale Hybrid Attention Networks Based on Multiview Images for the Diagnosis of Parkinson’s Disease
	  URL: https://www.semanticscholar.org/paper/b2af0577ee8ac56b527bd108ce57755a4a4b04e7
	  Citations: 11 | Authors: Xinchun Cui, Youshi Zhou, Chao Zhao, Jianlong Li, Xiangwei Zheng, Xiuli Li, Shixiao Shan, JinXing Liu, Xiaoli Liu | Date: N/A
2025-11-14 22:06:03,957 - WARNING - root - 【手动下载提示】(无PDF): Hybrid Attention Feature Refinement Network for Lightweight Image Super-Resolution in Metaverse Immersive Display
	  URL: https://www.semanticscholar.org/paper/c4d95a47eec1a23320d60dd95848d41e10820ee4
	  Citations: 10 | Authors: Kexin Wang, Xiaomin Yang, Gwanggil Jeon | Date: 2024-02-01
2025-11-14 22:06:03,958 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\hybrid attention\HAT_ Hybrid Attention Transformer for Image Restoration.pdf
2025-11-14 22:06:03,959 - INFO - root - 成功下载 (Semantic Scholar): HAT: Hybrid Attention Transformer for Image Restoration
2025-11-14 22:06:03,961 - INFO - root - 正在下载: https://www.mdpi.com/2076-3417/14/3/1293/pdf?version=1707037901
2025-11-14 22:06:13,389 - INFO - root - 正在下载: https://www.mdpi.com/2076-3417/14/3/1293/pdf?version=1707037901
2025-11-14 22:06:22,826 - INFO - root - 正在下载: https://www.mdpi.com/2076-3417/14/3/1293/pdf?version=1707037901
2025-11-14 22:06:32,268 - INFO - root - 正在下载: https://www.mdpi.com/2076-3417/14/3/1293/pdf?version=1707037901
2025-11-14 22:06:45,711 - INFO - root - 正在下载: https://www.mdpi.com/2076-3417/14/3/1293/pdf?version=1707037901
2025-11-14 22:06:51,249 - WARNING - root - 下载 Dual Hybrid Attention Mechanism-Based U-Net for Building Segmentation in Remote Sensing Images (https://www.mdpi.com/2076-3417/14/3/1293/pdf?version=1707037901) 失败: 403 Client Error: Forbidden for url: https://www.mdpi.com/2076-3417/14/3/1293/pdf?version=1707037901
2025-11-14 22:06:51,250 - WARNING - root - 【手动下载提示】(无PDF): Abundance Matrix Correlation Analysis Network Based on Hierarchical Multihead Self-Cross-Hybrid Attention for Hyperspectral Change Detection
	  URL: https://www.semanticscholar.org/paper/6aae02a41656cecba872b29bb3d71c414a58f57b
	  Citations: 66 | Authors: Wenqian Dong, Jing Zhao, Jiahui Qu, Song Xiao, Nan Li, Shaoxiong Hou, Yunsong Li | Date: N/A
2025-11-14 22:06:51,251 - WARNING - root - 【手动下载提示】(无PDF): DenseNet model incorporating hybrid attention mechanisms and clinical features for pancreatic cystic tumor classification
	  URL: https://www.semanticscholar.org/paper/7c520ed397a3d9e6863a840325b3b0643eb15fa7
	  Citations: 7 | Authors: Hui Tian, Bo Zhang, Zhiwei Zhang, Zhenshun Xu, Liang Jin, Yun Bian, Jie Wu | Date: 2024-05-07
2025-11-14 22:06:51,253 - WARNING - root - 【手动下载提示】(无PDF): HA-Net: a SAR image ship detector based on hybrid attention
	  URL: https://www.semanticscholar.org/paper/4c40b6f75ab19e1402ae88e38013a64c504c3a80
	  Citations: 6 | Authors: Shouwen Cai, Hao Meng, Ming Yuan, Fei Gao | Date: 2024-06-10
2025-11-14 22:06:51,254 - WARNING - root - 【手动下载提示】(无PDF): Hybrid Attention Module and Transformer Based Fuze DRFM Jamming Signal Recognition
	  URL: https://www.semanticscholar.org/paper/0fb8059c6aaf0c86c9e9a623fa1ad73d0f737c37
	  Citations: 7 | Authors: Jikai Yang, Zhiquan Bai, Zhaoxia Xian, Hongwu Xiang, Jingxin Li, Huili Hu, Jian Dai, Xinhong Hao | Date: 2024-09-01
2025-11-14 22:06:51,258 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\hybrid attention\Multi-scale deep residual shrinkage networks with a hybrid attention mechanism for rolling bearing f.pdf
2025-11-14 22:06:51,259 - INFO - root - 成功下载 (Semantic Scholar): Multi-scale deep residual shrinkage networks with a hybrid attention mechanism for rolling bearing fault diagnosis
2025-11-14 22:06:51,261 - WARNING - root - 【手动下载提示】(无PDF): Actor-Hybrid-Attention-Critic for Multi-Logistic Robots Path Planning
	  URL: https://www.semanticscholar.org/paper/5260da08f9f524b8fa77a37e2884b22804a47c6a
	  Citations: 6 | Authors: Chunjie Yang, Bodi Yuan, Pengzhao Zhai | Date: 2024-06-01
2025-11-14 22:06:51,273 - WARNING - root - 【手动下载提示】(无PDF): Multi-modal bilinear fusion with hybrid attention mechanism for multi-label skin lesion classification
	  URL: https://www.semanticscholar.org/paper/2a89c443cf8b93abc7413ee32257f66fad5af684
	  Citations: 7 | Authors: Yun Wei, Lin Ji | Date: 2024-01-15
2025-11-14 22:06:51,274 - WARNING - root - 【手动下载提示】(无PDF): Deep Hashing Network With Hybrid Attention and Adaptive Weighting for Image Retrieval
	  URL: https://www.semanticscholar.org/paper/1c688a4da1c546ea783f5743c371732ace568498
	  Citations: 7 | Authors: Yingjiao Pei, Zhongyuan Wang, Na Li, Heling Chen, Baojin Huang, Weiping Tu | Date: N/A
2025-11-14 22:06:51,277 - WARNING - root - 【手动下载提示】(无PDF): Towards Effective Author Name Disambiguation by Hybrid Attention
	  URL: https://www.semanticscholar.org/paper/fc2dcb9e544a0aaad3034a61eaf0563a79c65cbf
	  Citations: 6 | Authors: Qian Zhou, Wei Chen, Peng-Peng Zhao, An Liu, Jia-Jie Xu, Jianfeng Qu, Lei Zhao | Date: 2024-07-01
2025-11-14 22:06:51,281 - INFO - root - 正在下载: https://www.mdpi.com/2306-5354/10/6/714/pdf?version=1686635187
2025-11-14 22:07:00,861 - INFO - root - 正在下载: https://www.mdpi.com/2306-5354/10/6/714/pdf?version=1686635187
2025-11-14 22:07:10,360 - INFO - root - 正在下载: https://www.mdpi.com/2306-5354/10/6/714/pdf?version=1686635187
2025-11-14 22:07:19,795 - INFO - root - 正在下载: https://www.mdpi.com/2306-5354/10/6/714/pdf?version=1686635187
2025-11-14 22:07:33,273 - INFO - root - 正在下载: https://www.mdpi.com/2306-5354/10/6/714/pdf?version=1686635187
2025-11-14 22:07:38,836 - WARNING - root - 下载 AHANet: Adaptive Hybrid Attention Network for Alzheimer’s Disease Classification Using Brain Magnetic Resonance Imaging (https://www.mdpi.com/2306-5354/10/6/714/pdf?version=1686635187) 失败: 403 Client Error: Forbidden for url: https://www.mdpi.com/2306-5354/10/6/714/pdf?version=1686635187
2025-11-14 22:07:38,838 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\hybrid attention\Physics Inspired Hybrid Attention for SAR Target Recognition.pdf
2025-11-14 22:07:38,839 - INFO - root - 成功下载 (Semantic Scholar): Physics Inspired Hybrid Attention for SAR Target Recognition
2025-11-14 22:07:38,839 - WARNING - root - 【手动下载提示】(无PDF): WHEN: A Wavelet-DTW Hybrid Attention Network for Heterogeneous Time Series Analysis
	  URL: https://www.semanticscholar.org/paper/c2e57a1926217f67a72c617d09fa12ec8e667d0e
	  Citations: 33 | Authors: Jingyuan Wang, Chen Yang, Xiaohan Jiang, Junjie Wu | Date: 2023-08-04
2025-11-14 22:07:38,842 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\hybrid attention\Fine-grained image classification method based on hybrid attention module.pdf
2025-11-14 22:07:38,843 - INFO - root - 成功下载 (Semantic Scholar): Fine-grained image classification method based on hybrid attention module
2025-11-14 22:07:38,844 - WARNING - root - 【手动下载提示】(无PDF): Hybrid Attention-Aware Learning Network for Facial Expression Recognition in the Wild
	  URL: https://www.semanticscholar.org/paper/a13c5a80a32c0e2dbf589d9fca9daa9b2300165d
	  Citations: 4 | Authors: Weijun Gong, Zhiyao La, Yurong Qian, Weihang Zhou | Date: 2024-01-05
2025-11-14 22:07:38,846 - INFO - root - 正在下载: https://ieeexplore.ieee.org/ielx7/36/10006360/10145829.pdf
2025-11-14 22:07:48,668 - INFO - root - 正在下载: https://ieeexplore.ieee.org/ielx7/36/10006360/10145829.pdf
2025-11-14 22:09:57,141 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\hybrid attention\Hybrid Attention-Based U-Shaped Network for Remote Sensing Image Super-Resolution.pdf
2025-11-14 22:09:57,150 - INFO - root - 成功下载 (Semantic Scholar): Hybrid Attention-Based U-Shaped Network for Remote Sensing Image Super-Resolution
2025-11-14 22:09:57,152 - INFO - root - 正在下载: https://www.mdpi.com/2076-3417/13/2/770/pdf?version=1673518878
2025-11-14 22:10:08,385 - INFO - root - 正在下载: https://www.mdpi.com/2076-3417/13/2/770/pdf?version=1673518878
2025-11-14 22:10:19,213 - INFO - root - 正在下载: https://www.mdpi.com/2076-3417/13/2/770/pdf?version=1673518878
2025-11-14 22:10:29,532 - INFO - root - 正在下载: https://www.mdpi.com/2076-3417/13/2/770/pdf?version=1673518878
2025-11-14 22:10:43,040 - INFO - root - 正在下载: https://www.mdpi.com/2076-3417/13/2/770/pdf?version=1673518878
2025-11-14 22:10:48,531 - WARNING - root - 下载 Smart Contract Vulnerability Detection Based on Hybrid Attention Mechanism Model (https://www.mdpi.com/2076-3417/13/2/770/pdf?version=1673518878) 失败: 403 Client Error: Forbidden for url: https://www.mdpi.com/2076-3417/13/2/770/pdf?version=1673518878
2025-11-14 22:10:48,532 - WARNING - root - 【手动下载提示】(无PDF): Mutiscale Hybrid Attention Transformer for Remote Sensing Image Pansharpening
	  URL: https://www.semanticscholar.org/paper/3b8404c8b16dd7abb86aa5f13139fa9a9c5f5ca8
	  Citations: 22 | Authors: Wengang Zhu, Jinjiang Li, Zhi-Yonga An, Zhen Hua | Date: N/A
2025-11-14 22:10:48,537 - WARNING - root - 【手动下载提示】(无PDF): Multimodal emotion recognition based on audio and text by using hybrid attention networks
	  URL: https://www.semanticscholar.org/paper/5a35815f9d5f7ed5697b4638b1158f42837051c1
	  Citations: 42 | Authors: Shiqing Zhang, Yijiao Yang, Ruixin Liu, Chen Chen, Xin Tao, Wenping Guo, Yicheng Xu, Xiaoming Zhao | Date: N/A
2025-11-14 22:10:48,538 - WARNING - root - 【手动下载提示】(无PDF): A Novel Approach for Surface Integrity Monitoring in High-Energy Nanosecond-Pulse Laser Shock Peening: Acoustic Emission and Hybrid-Attention CNN
	  URL: https://www.semanticscholar.org/paper/9608f2b16d1d302f7507505b51a5be96fdf0b542
	  Citations: 19 | Authors: Zhifen Zhang, Rui Qin, Gengze Li, Z. Du, G. Wen, Weifeng He | Date: 2023-03-01
2025-11-14 22:10:48,539 - WARNING - root - 【手动下载提示】(无PDF): Intention-convolution and hybrid-attention network for vehicle trajectory prediction
	  URL: https://www.semanticscholar.org/paper/3bcb4d2994896053a5a8da42d09eb621d3b2b221
	  Citations: 34 | Authors: Chao Li, Zhanwen Liu, Shang Lin, Yang Wang, Xiangmo Zhao | Date: 2023-09-01
2025-11-14 22:10:48,541 - WARNING - root - 【手动下载提示】(无PDF): Hybrid Attention Network for Epileptic EEG Classification
	  URL: https://www.semanticscholar.org/paper/f282fa85469cc789c2f3b62e57e3446a49528afa
	  Citations: 17 | Authors: Yanna Zhao, Jiatong He, Fenglin Zhu, Tiantian Xiao, Yongfeng Zhang, Ziwei Wang, Fangzhou Xu, Yi Niu | Date: 2023-03-31
2025-11-14 22:10:48,545 - INFO - root - 正在下载: https://www.mdpi.com/1424-8220/23/13/6052/pdf?version=1688107163
2025-11-14 22:10:54,860 - INFO - root - 正在下载: https://www.mdpi.com/1424-8220/23/13/6052/pdf?version=1688107163
2025-11-14 22:10:59,485 - INFO - root - 正在下载: https://www.mdpi.com/1424-8220/23/13/6052/pdf?version=1688107163
2025-11-14 22:11:04,677 - INFO - root - 正在下载: https://www.mdpi.com/1424-8220/23/13/6052/pdf?version=1688107163
2025-11-14 22:11:13,318 - INFO - root - 正在下载: https://www.mdpi.com/1424-8220/23/13/6052/pdf?version=1688107163
2025-11-14 22:11:14,043 - WARNING - root - 下载 PHAM-YOLO: A Parallel Hybrid Attention Mechanism Network for Defect Detection of Meter in Substation (https://www.mdpi.com/1424-8220/23/13/6052/pdf?version=1688107163) 失败: 403 Client Error: Forbidden for url: https://www.mdpi.com/1424-8220/23/13/6052/pdf?version=1688107163
2025-11-14 22:11:14,044 - INFO - root - 正在下载: https://www.mdpi.com/1424-8220/23/15/6982/pdf?version=1691312141
2025-11-14 22:11:18,705 - INFO - root - 正在下载: https://www.mdpi.com/1424-8220/23/15/6982/pdf?version=1691312141
2025-11-14 22:11:23,547 - INFO - root - 正在下载: https://www.mdpi.com/1424-8220/23/15/6982/pdf?version=1691312141
2025-11-14 22:11:28,153 - INFO - root - 正在下载: https://www.mdpi.com/1424-8220/23/15/6982/pdf?version=1691312141
2025-11-14 22:11:39,445 - INFO - root - 正在下载: https://www.mdpi.com/1424-8220/23/15/6982/pdf?version=1691312141
2025-11-14 22:11:40,228 - WARNING - root - 下载 Defect Detection in Steel Using a Hybrid Attention Network (https://www.mdpi.com/1424-8220/23/15/6982/pdf?version=1691312141) 失败: 403 Client Error: Forbidden for url: https://www.mdpi.com/1424-8220/23/15/6982/pdf?version=1691312141
2025-11-14 22:11:40,229 - WARNING - root - 【手动下载提示】(无PDF): Hybrid Attention and Motion Constraint for Anomaly Detection in Crowded Scenes
	  URL: https://www.semanticscholar.org/paper/a5e107a1112c88294f44989f6622433fb402fb31
	  Citations: 30 | Authors: Xinfeng Zhang, Jinpeng Fang, Baoqing Yang, Shuhan Chen, Bin Li | Date: 2023-05-01
2025-11-14 22:11:40,232 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\hybrid attention\Hybrid Attention-Based Prototypical Networks for Noisy Few-Shot Relation Classification.pdf
2025-11-14 22:11:40,234 - INFO - root - 成功下载 (Semantic Scholar): Hybrid Attention-Based Prototypical Networks for Noisy Few-Shot Relation Classification
2025-11-14 22:11:40,245 - INFO - root - 正在下载: https://www.mdpi.com/2072-4292/15/2/526/pdf?version=1673863751
2025-11-14 22:11:44,919 - INFO - root - 正在下载: https://www.mdpi.com/2072-4292/15/2/526/pdf?version=1673863751
2025-11-14 22:11:49,854 - INFO - root - 正在下载: https://www.mdpi.com/2072-4292/15/2/526/pdf?version=1673863751
2025-11-14 22:11:54,887 - INFO - root - 正在下载: https://www.mdpi.com/2072-4292/15/2/526/pdf?version=1673863751
2025-11-14 22:12:04,514 - INFO - root - 正在下载: https://www.mdpi.com/2072-4292/15/2/526/pdf?version=1673863751
2025-11-14 22:12:05,149 - WARNING - root - 下载 Hybrid Attention-Based Encoder-Decoder Fully Convolutional Network for PolSAR Image Classification (https://www.mdpi.com/2072-4292/15/2/526/pdf?version=1673863751) 失败: 403 Client Error: Forbidden for url: https://www.mdpi.com/2072-4292/15/2/526/pdf?version=1673863751
2025-11-14 22:12:05,149 - WARNING - root - 【手动下载提示】(无PDF): Hybrid Attention Compression Network With Light Graph Attention Module for Remote Sensing Images
	  URL: https://www.semanticscholar.org/paper/11ab89aa34dae52624533795ebbe1ce707a66fd4
	  Citations: 9 | Authors: Tianpeng Pan, Lili Zhang, Yingchao Song, Yuxuan Liu | Date: N/A
2025-11-14 22:12:05,149 - WARNING - root - 【手动下载提示】(无PDF): An Adaptive Hybrid Attention Based Convolutional Neural Net for Intelligent Transportation Object Recognition
	  URL: https://www.semanticscholar.org/paper/269fed3c9a541a4073cde6e205878c2618b2f973
	  Citations: 11 | Authors: Qili Chen, Guangyuan Pan, Lin Zhao, Junfang Fan, Wenbai Chen, A. Zhang | Date: 2023-07-01
2025-11-14 22:12:05,150 - WARNING - root - 【手动下载提示】(无PDF): HEU-Net: hybrid attention residual block-based network with external skip connections for metal corrosion semantic segmentation
	  URL: https://www.semanticscholar.org/paper/80e0948897bc53edf4eba2e31e443010d8a2e19a
	  Citations: 9 | Authors: Tianchen Zhu, Shiqiang Zhu, Tao Zheng, Hongliang Ding, Wei Song, Cunjun Li | Date: 2023-06-22
2025-11-14 22:12:05,150 - WARNING - root - 【手动下载提示】(无PDF): Face-Periocular Cross-Identification via Contrastive Hybrid Attention Vision Transformer
	  URL: https://www.semanticscholar.org/paper/5765cc795e642e1a8e834d6af93cda3ac65a753a
	  Citations: 6 | Authors: Leslie Ching Ow Tiong, D. Sigmund, A. Teoh | Date: N/A
2025-11-14 22:12:05,150 - WARNING - root - 【手动下载提示】(无PDF): Image Super-Resolution with Multi-scale Hybrid Attention
	  URL: https://www.semanticscholar.org/paper/09691760c37f27ddf4d4b7908a348b20b110db6d
	  Citations: 0 | Authors: Ningzhi Wang, Hanyi Shi, Wenna Ruan, Lingbin Zeng | Date: N/A
2025-11-14 22:12:05,151 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\hybrid attention\Dual-view Correlation Hybrid Attention Network for Robust Holistic Mammogram Classification.pdf
2025-11-14 22:12:05,153 - INFO - root - 成功下载 (Semantic Scholar): Dual-view Correlation Hybrid Attention Network for Robust Holistic Mammogram Classification
2025-11-14 22:12:05,154 - INFO - root - 正在下载: https://www.mdpi.com/1424-8220/23/19/8285/pdf?version=1696663695
2025-11-14 22:12:09,799 - INFO - root - 正在下载: https://www.mdpi.com/1424-8220/23/19/8285/pdf?version=1696663695
2025-11-14 22:12:14,407 - INFO - root - 正在下载: https://www.mdpi.com/1424-8220/23/19/8285/pdf?version=1696663695
2025-11-14 22:12:19,968 - INFO - root - 正在下载: https://www.mdpi.com/1424-8220/23/19/8285/pdf?version=1696663695
2025-11-14 22:12:28,641 - INFO - root - 正在下载: https://www.mdpi.com/1424-8220/23/19/8285/pdf?version=1696663695
2025-11-14 22:12:29,383 - WARNING - root - 下载 A Fast and Robust Lane Detection via Online Re-Parameterization and Hybrid Attention (https://www.mdpi.com/1424-8220/23/19/8285/pdf?version=1696663695) 失败: 403 Client Error: Forbidden for url: https://www.mdpi.com/1424-8220/23/19/8285/pdf?version=1696663695
2025-11-14 22:12:29,384 - WARNING - root - 【手动下载提示】(无PDF): Multi-level wavelet network based on CNN-Transformer hybrid attention for single image deraining
	  URL: https://www.semanticscholar.org/paper/97c485dbb41b68c193decdec5a4618ce3f5b4ee2
	  Citations: 8 | Authors: B. Liu, Siyan Fang | Date: 2023-08-09
2025-11-14 22:12:29,384 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\hybrid attention\Stacked Hybrid-Attention and Group Collaborative Learning for Unbiased Scene Graph Generation.pdf
2025-11-14 22:12:29,385 - INFO - root - 成功下载 (Semantic Scholar): Stacked Hybrid-Attention and Group Collaborative Learning for Unbiased Scene Graph Generation
2025-11-14 22:12:29,385 - INFO - root - 正在下载: https://onlinelibrary.wiley.com/doi/pdfdirect/10.1049/ipr2.12934
2025-11-14 22:12:38,866 - INFO - root - 正在下载: https://onlinelibrary.wiley.com/doi/pdfdirect/10.1049/ipr2.12934
2025-11-14 22:12:48,381 - INFO - root - 正在下载: https://onlinelibrary.wiley.com/doi/pdfdirect/10.1049/ipr2.12934
2025-11-14 22:12:57,901 - INFO - root - 正在下载: https://onlinelibrary.wiley.com/doi/pdfdirect/10.1049/ipr2.12934
2025-11-14 22:13:11,453 - INFO - root - 正在下载: https://onlinelibrary.wiley.com/doi/pdfdirect/10.1049/ipr2.12934
2025-11-14 22:13:17,007 - WARNING - root - 下载 Hybrid attention mechanism of feature fusion for medical image segmentation (https://onlinelibrary.wiley.com/doi/pdfdirect/10.1049/ipr2.12934) 失败: 403 Client Error: Forbidden for url: https://onlinelibrary.wiley.com/doi/pdfdirect/10.1049/ipr2.12934
2025-11-14 22:13:17,008 - INFO - root - 正在下载: https://www.mdpi.com/2073-8994/15/10/1947/pdf?version=1697811500
2025-11-14 22:13:22,799 - INFO - root - 正在下载: https://www.mdpi.com/2073-8994/15/10/1947/pdf?version=1697811500
2025-11-14 22:13:27,417 - INFO - root - 正在下载: https://www.mdpi.com/2073-8994/15/10/1947/pdf?version=1697811500
2025-11-14 22:13:32,050 - INFO - root - 正在下载: https://www.mdpi.com/2073-8994/15/10/1947/pdf?version=1697811500
2025-11-14 22:13:40,700 - INFO - root - 正在下载: https://www.mdpi.com/2073-8994/15/10/1947/pdf?version=1697811500
2025-11-14 22:13:41,297 - WARNING - root - 下载 Transformer with Hybrid Attention Mechanism for Stereo Endoscopic Video Super Resolution (https://www.mdpi.com/2073-8994/15/10/1947/pdf?version=1697811500) 失败: 403 Client Error: Forbidden for url: https://www.mdpi.com/2073-8994/15/10/1947/pdf?version=1697811500
2025-11-14 22:13:41,297 - WARNING - root - 【手动下载提示】(无PDF): HHTrack: Hyperspectral Object Tracking Based on Hybrid Attention
	  URL: https://www.semanticscholar.org/paper/c1c5c93f3bd9b99ec5fe55b4c2b5bc29abf4b12a
	  Citations: 1 | Authors: Yuedong Tan, Wenfang Sun, Jieran Yuan, Wenwang Du, Zhe Wang, Nan Mao, Beibei Song | Date: 2023-08-14
2025-11-14 22:13:41,297 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\hybrid attention\Hybridformer_ Improving Squeezeformer with Hybrid Attention and NSR Mechanism.pdf
2025-11-14 22:13:41,299 - INFO - root - 成功下载 (Semantic Scholar): Hybridformer: Improving Squeezeformer with Hybrid Attention and NSR Mechanism
2025-11-14 22:13:41,300 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\hybrid attention\HAC-Net_ A Hybrid Attention-Based Convolutional Neural Network for Highly Accurate Protein-Ligand Bi.pdf
2025-11-14 22:13:41,301 - INFO - root - 成功下载 (Semantic Scholar): HAC-Net: A Hybrid Attention-Based Convolutional Neural Network for Highly Accurate Protein-Ligand Binding Affinity Prediction
2025-11-14 22:13:41,301 - WARNING - root - 【手动下载提示】(无PDF): A hybrid-attention semantic segmentation network for remote sensing interpretation in land-use surveillance
	  URL: https://www.semanticscholar.org/paper/4905315ab99ea19871a65e52be8c8c51624748aa
	  Citations: 49 | Authors: Ning Lv, Zenghui Zhang, Cong Li, Jiaxuan Deng, Tao Su, Chen Chen, Yang Zhou | Date: 2022-02-07
2025-11-14 22:13:41,302 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\hybrid attention\A Hybrid Attention Mechanism for Weakly-Supervised Temporal Action Localization.pdf
2025-11-14 22:13:41,303 - INFO - root - 成功下载 (Semantic Scholar): A Hybrid Attention Mechanism for Weakly-Supervised Temporal Action Localization
2025-11-14 22:13:41,303 - WARNING - root - 【手动下载提示】(无PDF): A hybrid attention-based deep learning approach for wind power prediction
	  URL: https://www.semanticscholar.org/paper/9d591544b9f179d93ad85720e8382e8e1c04c916
	  Citations: 128 | Authors: Zhengjing Ma, Gang Mei | Date: 2022-10-01
2025-11-14 22:13:41,305 - WARNING - root - 【手动下载提示】(无PDF): ColorFormer: Image Colorization via Color Memory Assisted Hybrid-Attention Transformer
	  URL: https://www.semanticscholar.org/paper/33618e85644d6705fd74086c13ee3b7e2a2a466a
	  Citations: 28 | Authors: Xiaozhong Ji, Boyuan Jiang, Donghao Luo, Guangpin Tao, Wenqing Chu, Zhifeng Xie, Chengjie Wang, Ying Tai | Date: N/A
2025-11-14 22:13:41,305 - WARNING - root - 【手动下载提示】(无PDF): HAM: Hybrid attention module in deep convolutional neural networks for image classification
	  URL: https://www.semanticscholar.org/paper/2cfa77f582ee36f2d1fe8869505aa5a71a5f99f3
	  Citations: 92 | Authors: Guoqiang Li, Qianhao Fang, Li Zha, Xin Gao, Nenggan Zheng | Date: 2022-05-01
2025-11-14 22:13:41,306 - WARNING - root - 【手动下载提示】(无PDF): State of health estimation for lithium-ion batteries based on hybrid attention and deep learning
	  URL: https://www.semanticscholar.org/paper/f91dcfd8df66da9bf3649c176869f980b9205115
	  Citations: 91 | Authors: Hongqian Zhao, Zheng Chen, Xing Shu, Jiangwei Shen, Zhenzhen Lei, Yuanjian Zhang | Date: 2022-12-01
2025-11-14 22:13:41,307 - INFO - root - 正在下载: https://downloads.hindawi.com/journals/cin/2022/4189500.pdf
2025-11-14 22:14:00,321 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-14 22:14:00,322 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-14 22:14:00,325 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-14 22:14:02,729 - INFO - root - LLMClientManager: 指定使用客户端: Gemini
2025-11-14 22:14:03,640 - INFO - root - GeminiClient: trying model models/gemini-2.5-flash
2025-11-14 22:14:17,458 - INFO - root - GeminiClient: initialized model gemini-2.5-flash
2025-11-14 22:14:17,459 - INFO - root - LLMClientManager: Gemini 客户端初始化成功
2025-11-14 22:14:17,460 - INFO - root - LLMClientManager: switched to Gemini client
2025-11-14 22:14:17,460 - INFO - root - 已手动切换到 LLM 客户端: Gemini
2025-11-14 22:14:17,461 - INFO - root - 使用 LLM 模型: gemini-2.5-flash
2025-11-14 22:14:17,461 - INFO - root - 可用客户端: ['Gemini']
2025-11-14 22:14:17,462 - INFO - root - === 运行配置 ===
2025-11-14 22:14:17,462 - INFO - root - 处理模式: Semantic Scholar 高引用搜索 (API)
2025-11-14 22:14:17,463 - INFO - root - 查询 (关键词): hybrid attention
2025-11-14 22:14:17,463 - INFO - root - 关键词 (用于保存): hybrid attention
2025-11-14 22:14:17,464 - INFO - root - 排序: citationCount:desc
2025-11-14 22:14:17,465 - INFO - root - 最大处理数量: 100
2025-11-14 22:14:17,467 - INFO - root - 保存图片: 是
2025-11-14 22:14:17,468 - INFO - root - 输出语言: 中文
2025-11-14 22:14:17,469 - INFO - root - 强制重新处理: 否
2025-11-14 22:14:17,469 - INFO - root - LLM 客户端: Gemini
2025-11-14 22:14:17,469 - INFO - root - ====================
2025-11-14 22:14:17,469 - INFO - root - 正在使用检索策略: semantic
2025-11-14 22:14:17,471 - INFO - root - 使用 Semantic Scholar 高引用搜索模式 (API)
2025-11-14 22:14:17,472 - INFO - root - Semantic API 查询: query=hybrid attention, limit=100, sort=citationCount:desc
2025-11-14 22:14:17,472 - INFO - root - 正在调用 Semantic Scholar API...
2025-11-14 22:14:26,861 - WARNING - root - 【手动下载提示】(无PDF): An Instrument Indication Acquisition Algorithm Based on Lightweight Deep Convolutional Neural Network and Hybrid Attention Fine-Grained Features
	  URL: https://www.semanticscholar.org/paper/49f99d7a21e2ded7915676753a180983763b9a22
	  Citations: 66 | Authors: Jiaquan Shen, Ningzhong Liu, Han Sun, Deguang Li, Yongxin Zhang | Date: N/A
2025-11-14 22:14:26,861 - WARNING - root - 【手动下载提示】(无PDF): Enhancing ASD classification through hybrid attention-based learning of facial features
	  URL: https://www.semanticscholar.org/paper/22547aa4c72c7c2799932a0f451ab3f2db6d7d0f
	  Citations: 35 | Authors: Inzamam Shahzad, Saif Ur Rehman Khan, Waseem Abbas, Z. U. Abideen, Jin Liu | Date: 2024-04-21
2025-11-14 22:14:26,861 - WARNING - root - 【手动下载提示】(无PDF): Dual-Hybrid Attention Network for Specular Highlight Removal
	  URL: https://www.semanticscholar.org/paper/d56ce689cc0f8b1cf0e5f58882503a5e59ec440b
	  Citations: 33 | Authors: Xiaojiao Guo, Xuhang Chen, Shenghong Luo, Shuqiang Wang, Chi-Man Pun | Date: 2024-07-17
2025-11-14 22:14:26,862 - WARNING - root - 【手动下载提示】(无PDF): HyA-GAN: remote sensing image cloud removal based on hybrid attention generation adversarial network
	  URL: https://www.semanticscholar.org/paper/905b42f2f8d912d98fd7cbec4f7b244401176acc
	  Citations: 16 | Authors: Minghao Jin, Pengwei Wang, Yusong Li | Date: 2024-02-27
2025-11-14 22:14:26,862 - WARNING - root - 【手动下载提示】(无PDF): Radar Signal Recognition Based on CNN With a Hybrid Attention Mechanism and Skip Feature Aggregation
	  URL: https://www.semanticscholar.org/paper/dacad703c49e9434321c91220219638f871fd9d2
	  Citations: 26 | Authors: Yuanpu Guo, Haixin Sun, Hui Liu, Zhen-miao Deng | Date: N/A
2025-11-14 22:14:26,863 - WARNING - root - 【手动下载提示】(无PDF): Hybrid Attention-Aware Transformer Network Collaborative Multiscale Feature Alignment for Building Change Detection
	  URL: https://www.semanticscholar.org/paper/a0f8053046622628073ac6f051b5181a80cb7ad3
	  Citations: 28 | Authors: Chuan Xu, Zhaoyi Ye, Liye Mei, Haonan Yu, Jianchen Liu, Yaxiaer Yalikun, Shuangtong Jin, Sheng Liu, Wei Yang, Cheng Lei | Date: N/A
2025-11-14 22:14:26,863 - WARNING - root - 【手动下载提示】(无PDF): Probabilistic Multienergy Load Forecasting Based on Hybrid Attention-Enabled Transformer Network and Gaussian Process-Aided Residual Learning
	  URL: https://www.semanticscholar.org/paper/a2d81cc04f73e2898fb16e7e8c8f9cf69adadfd5
	  Citations: 16 | Authors: Pengfei Zhao, Weihao Hu, Di Cao, Zhenyuan Zhang, Yuehui Huang, Longcheng Dai, Zhe Chen | Date: 2024-06-01
2025-11-14 22:14:26,865 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\hybrid attention\Hybrid Attention Fusion Embedded in Transformer for Remote Sensing Image Semantic Segmentation.pdf
2025-11-14 22:14:26,865 - INFO - root - 成功下载 (Semantic Scholar): Hybrid Attention Fusion Embedded in Transformer for Remote Sensing Image Semantic Segmentation
2025-11-14 22:14:26,866 - INFO - root - 正在下载: https://www.mdpi.com/2306-5354/11/3/240/pdf?version=1709132347
2025-11-14 22:14:31,783 - INFO - root - 正在下载: https://www.mdpi.com/2306-5354/11/3/240/pdf?version=1709132347
2025-11-14 22:14:36,607 - INFO - root - 正在下载: https://www.mdpi.com/2306-5354/11/3/240/pdf?version=1709132347
2025-11-14 22:14:41,602 - INFO - root - 正在下载: https://www.mdpi.com/2306-5354/11/3/240/pdf?version=1709132347
2025-11-14 22:14:50,535 - INFO - root - 正在下载: https://www.mdpi.com/2306-5354/11/3/240/pdf?version=1709132347
2025-11-14 22:14:51,313 - WARNING - root - 下载 Advancing Ocular Imaging: A Hybrid Attention Mechanism-Based U-Net Model for Precise Segmentation of Sub-Retinal Layers in OCT Images (https://www.mdpi.com/2306-5354/11/3/240/pdf?version=1709132347) 失败: 403 Client Error: Forbidden for url: https://www.mdpi.com/2306-5354/11/3/240/pdf?version=1709132347
2025-11-14 22:14:51,314 - WARNING - root - 【手动下载提示】(无PDF): Enhancing Time Series Product Demand Forecasting With Hybrid Attention-Based Deep Learning Models
	  URL: https://www.semanticscholar.org/paper/4848b35cbe515f8909a67a82dcb83d7c5e48f74b
	  Citations: 14 | Authors: Xuguang Zhang, Pan Li, Xu Han, Yongbin Yang, Yiwen Cui | Date: N/A
2025-11-14 22:14:51,314 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\hybrid attention\YOLO Algorithm With Hybrid Attention Feature Pyramid Network for Solder Joint Defect Detection.pdf
2025-11-14 22:14:51,315 - INFO - root - 成功下载 (Semantic Scholar): YOLO Algorithm With Hybrid Attention Feature Pyramid Network for Solder Joint Defect Detection
2025-11-14 22:14:51,315 - WARNING - root - 【手动下载提示】(无PDF): A novel approach for bearings multiclass fault diagnosis fusing multiscale deep convolution and hybrid attention networks
	  URL: https://www.semanticscholar.org/paper/bf72523fe518b2e4ce4d75d125dd5220177043f6
	  Citations: 13 | Authors: Fule Li, Xinlong Zhao | Date: 2024-01-08
2025-11-14 22:14:51,315 - WARNING - root - 【手动下载提示】(无PDF): Drone-HAT: Hybrid Attention Transformer for Complex Action Recognition in Drone Surveillance Videos
	  URL: https://www.semanticscholar.org/paper/a76690fb96dc7d3dfd5f8fec62c3949cc7ec96f6
	  Citations: 12 | Authors: Mustaqeem Khan, Jamil Ahmad, Abdulmotaleb El-Saddik, W. Gueaieb, Giulia De Masi, Fakhri Karray | Date: 2024-06-17
2025-11-14 22:14:51,316 - WARNING - root - 【手动下载提示】(无PDF): Dense Hybrid Attention Network for Palmprint Image Super-Resolution
	  URL: https://www.semanticscholar.org/paper/75746d8d52509b24d9975d9b3b07ae91311dc7ed
	  Citations: 12 | Authors: Yao Wang, Lunke Fei, Shuping Zhao, Qi Zhu, Jie Wen, Wei Jia, Imad Rida | Date: 2024-04-01
2025-11-14 22:14:51,317 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\hybrid attention\Frequency Enhanced Hybrid Attention Network for Sequential Recommendation.pdf
2025-11-14 22:14:51,317 - INFO - root - 成功下载 (Semantic Scholar): Frequency Enhanced Hybrid Attention Network for Sequential Recommendation
2025-11-14 22:14:51,317 - WARNING - root - 【手动下载提示】(无PDF): Hybrid Attention Feature Refinement Network for Lightweight Image Super-Resolution in Metaverse Immersive Display
	  URL: https://www.semanticscholar.org/paper/c4d95a47eec1a23320d60dd95848d41e10820ee4
	  Citations: 10 | Authors: Kexin Wang, Xiaomin Yang, Gwanggil Jeon | Date: 2024-02-01
2025-11-14 22:14:51,317 - WARNING - root - 【手动下载提示】(无PDF): A Multiscale Hybrid Attention Networks Based on Multiview Images for the Diagnosis of Parkinson’s Disease
	  URL: https://www.semanticscholar.org/paper/b2af0577ee8ac56b527bd108ce57755a4a4b04e7
	  Citations: 11 | Authors: Xinchun Cui, Youshi Zhou, Chao Zhao, Jianlong Li, Xiangwei Zheng, Xiuli Li, Shixiao Shan, JinXing Liu, Xiaoli Liu | Date: N/A
2025-11-14 22:14:51,318 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\hybrid attention\HAT_ Hybrid Attention Transformer for Image Restoration.pdf
2025-11-14 22:14:51,319 - INFO - root - 成功下载 (Semantic Scholar): HAT: Hybrid Attention Transformer for Image Restoration
2025-11-14 22:14:51,320 - INFO - root - 正在下载: https://www.mdpi.com/2076-3417/14/3/1293/pdf?version=1707037901
2025-11-14 22:14:56,932 - INFO - root - 正在下载: https://www.mdpi.com/2076-3417/14/3/1293/pdf?version=1707037901
2025-11-14 22:15:03,301 - INFO - root - 正在下载: https://www.mdpi.com/2076-3417/14/3/1293/pdf?version=1707037901
2025-11-14 22:15:08,428 - INFO - root - 正在下载: https://www.mdpi.com/2076-3417/14/3/1293/pdf?version=1707037901
2025-11-14 22:15:17,105 - INFO - root - 正在下载: https://www.mdpi.com/2076-3417/14/3/1293/pdf?version=1707037901
2025-11-14 22:15:18,259 - WARNING - root - 下载 Dual Hybrid Attention Mechanism-Based U-Net for Building Segmentation in Remote Sensing Images (https://www.mdpi.com/2076-3417/14/3/1293/pdf?version=1707037901) 失败: 403 Client Error: Forbidden for url: https://www.mdpi.com/2076-3417/14/3/1293/pdf?version=1707037901
2025-11-14 22:15:18,260 - WARNING - root - 【手动下载提示】(无PDF): Abundance Matrix Correlation Analysis Network Based on Hierarchical Multihead Self-Cross-Hybrid Attention for Hyperspectral Change Detection
	  URL: https://www.semanticscholar.org/paper/6aae02a41656cecba872b29bb3d71c414a58f57b
	  Citations: 66 | Authors: Wenqian Dong, Jing Zhao, Jiahui Qu, Song Xiao, Nan Li, Shaoxiong Hou, Yunsong Li | Date: N/A
2025-11-14 22:15:18,260 - WARNING - root - 【手动下载提示】(无PDF): HA-Net: a SAR image ship detector based on hybrid attention
	  URL: https://www.semanticscholar.org/paper/4c40b6f75ab19e1402ae88e38013a64c504c3a80
	  Citations: 6 | Authors: Shouwen Cai, Hao Meng, Ming Yuan, Fei Gao | Date: 2024-06-10
2025-11-14 22:15:18,261 - WARNING - root - 【手动下载提示】(无PDF): DenseNet model incorporating hybrid attention mechanisms and clinical features for pancreatic cystic tumor classification
	  URL: https://www.semanticscholar.org/paper/7c520ed397a3d9e6863a840325b3b0643eb15fa7
	  Citations: 7 | Authors: Hui Tian, Bo Zhang, Zhiwei Zhang, Zhenshun Xu, Liang Jin, Yun Bian, Jie Wu | Date: 2024-05-07
2025-11-14 22:15:18,261 - WARNING - root - 【手动下载提示】(无PDF): Hybrid Attention Module and Transformer Based Fuze DRFM Jamming Signal Recognition
	  URL: https://www.semanticscholar.org/paper/0fb8059c6aaf0c86c9e9a623fa1ad73d0f737c37
	  Citations: 7 | Authors: Jikai Yang, Zhiquan Bai, Zhaoxia Xian, Hongwu Xiang, Jingxin Li, Huili Hu, Jian Dai, Xinhong Hao | Date: 2024-09-01
2025-11-14 22:15:18,262 - WARNING - root - 【手动下载提示】(无PDF): Towards Effective Author Name Disambiguation by Hybrid Attention
	  URL: https://www.semanticscholar.org/paper/fc2dcb9e544a0aaad3034a61eaf0563a79c65cbf
	  Citations: 6 | Authors: Qian Zhou, Wei Chen, Peng-Peng Zhao, An Liu, Jia-Jie Xu, Jianfeng Qu, Lei Zhao | Date: 2024-07-01
2025-11-14 22:15:18,264 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\hybrid attention\Multi-scale deep residual shrinkage networks with a hybrid attention mechanism for rolling bearing f.pdf
2025-11-14 22:15:18,265 - INFO - root - 成功下载 (Semantic Scholar): Multi-scale deep residual shrinkage networks with a hybrid attention mechanism for rolling bearing fault diagnosis
2025-11-14 22:15:18,271 - WARNING - root - 【手动下载提示】(无PDF): Deep Hashing Network With Hybrid Attention and Adaptive Weighting for Image Retrieval
	  URL: https://www.semanticscholar.org/paper/1c688a4da1c546ea783f5743c371732ace568498
	  Citations: 7 | Authors: Yingjiao Pei, Zhongyuan Wang, Na Li, Heling Chen, Baojin Huang, Weiping Tu | Date: N/A
2025-11-14 22:15:18,275 - WARNING - root - 【手动下载提示】(无PDF): Actor-Hybrid-Attention-Critic for Multi-Logistic Robots Path Planning
	  URL: https://www.semanticscholar.org/paper/5260da08f9f524b8fa77a37e2884b22804a47c6a
	  Citations: 6 | Authors: Chunjie Yang, Bodi Yuan, Pengzhao Zhai | Date: 2024-06-01
2025-11-14 22:15:18,276 - INFO - root - 正在下载: https://www.mdpi.com/2306-5354/10/6/714/pdf?version=1686635187
2025-11-14 22:15:24,058 - INFO - root - 正在下载: https://www.mdpi.com/2306-5354/10/6/714/pdf?version=1686635187
2025-11-14 22:15:29,248 - INFO - root - 正在下载: https://www.mdpi.com/2306-5354/10/6/714/pdf?version=1686635187
2025-11-14 22:15:34,901 - INFO - root - 正在下载: https://www.mdpi.com/2306-5354/10/6/714/pdf?version=1686635187
2025-11-14 22:15:44,242 - INFO - root - 正在下载: https://www.mdpi.com/2306-5354/10/6/714/pdf?version=1686635187
2025-11-14 22:15:44,887 - WARNING - root - 下载 AHANet: Adaptive Hybrid Attention Network for Alzheimer’s Disease Classification Using Brain Magnetic Resonance Imaging (https://www.mdpi.com/2306-5354/10/6/714/pdf?version=1686635187) 失败: 403 Client Error: Forbidden for url: https://www.mdpi.com/2306-5354/10/6/714/pdf?version=1686635187
2025-11-14 22:15:44,890 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\hybrid attention\Physics Inspired Hybrid Attention for SAR Target Recognition.pdf
2025-11-14 22:15:44,892 - INFO - root - 成功下载 (Semantic Scholar): Physics Inspired Hybrid Attention for SAR Target Recognition
2025-11-14 22:15:44,892 - WARNING - root - 【手动下载提示】(无PDF): WHEN: A Wavelet-DTW Hybrid Attention Network for Heterogeneous Time Series Analysis
	  URL: https://www.semanticscholar.org/paper/c2e57a1926217f67a72c617d09fa12ec8e667d0e
	  Citations: 33 | Authors: Jingyuan Wang, Chen Yang, Xiaohan Jiang, Junjie Wu | Date: 2023-08-04
2025-11-14 22:15:44,896 - WARNING - root - 【手动下载提示】(无PDF): Hybrid Attention-Aware Learning Network for Facial Expression Recognition in the Wild
	  URL: https://www.semanticscholar.org/paper/a13c5a80a32c0e2dbf589d9fca9daa9b2300165d
	  Citations: 4 | Authors: Weijun Gong, Zhiyao La, Yurong Qian, Weihang Zhou | Date: 2024-01-05
2025-11-14 22:15:44,901 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\hybrid attention\Fine-grained image classification method based on hybrid attention module.pdf
2025-11-14 22:15:44,902 - INFO - root - 成功下载 (Semantic Scholar): Fine-grained image classification method based on hybrid attention module
2025-11-14 22:15:44,906 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\hybrid attention\Hybrid Attention-Based U-Shaped Network for Remote Sensing Image Super-Resolution.pdf
2025-11-14 22:15:44,907 - INFO - root - 成功下载 (Semantic Scholar): Hybrid Attention-Based U-Shaped Network for Remote Sensing Image Super-Resolution
2025-11-14 22:15:44,913 - INFO - root - 正在下载: https://www.mdpi.com/2076-3417/13/2/770/pdf?version=1673518878
2025-11-14 22:15:50,549 - INFO - root - 正在下载: https://www.mdpi.com/2076-3417/13/2/770/pdf?version=1673518878
2025-11-14 22:15:55,495 - INFO - root - 正在下载: https://www.mdpi.com/2076-3417/13/2/770/pdf?version=1673518878
2025-11-14 22:16:00,256 - INFO - root - 正在下载: https://www.mdpi.com/2076-3417/13/2/770/pdf?version=1673518878
2025-11-14 22:16:09,966 - INFO - root - 正在下载: https://www.mdpi.com/2076-3417/13/2/770/pdf?version=1673518878
2025-11-14 22:16:10,623 - WARNING - root - 下载 Smart Contract Vulnerability Detection Based on Hybrid Attention Mechanism Model (https://www.mdpi.com/2076-3417/13/2/770/pdf?version=1673518878) 失败: 403 Client Error: Forbidden for url: https://www.mdpi.com/2076-3417/13/2/770/pdf?version=1673518878
2025-11-14 22:16:10,624 - WARNING - root - 【手动下载提示】(无PDF): Mutiscale Hybrid Attention Transformer for Remote Sensing Image Pansharpening
	  URL: https://www.semanticscholar.org/paper/3b8404c8b16dd7abb86aa5f13139fa9a9c5f5ca8
	  Citations: 22 | Authors: Wengang Zhu, Jinjiang Li, Zhi-Yonga An, Zhen Hua | Date: N/A
2025-11-14 22:16:10,625 - WARNING - root - 【手动下载提示】(无PDF): Multimodal emotion recognition based on audio and text by using hybrid attention networks
	  URL: https://www.semanticscholar.org/paper/5a35815f9d5f7ed5697b4638b1158f42837051c1
	  Citations: 42 | Authors: Shiqing Zhang, Yijiao Yang, Ruixin Liu, Chen Chen, Xin Tao, Wenping Guo, Yicheng Xu, Xiaoming Zhao | Date: N/A
2025-11-14 22:16:10,627 - WARNING - root - 【手动下载提示】(无PDF): A Novel Approach for Surface Integrity Monitoring in High-Energy Nanosecond-Pulse Laser Shock Peening: Acoustic Emission and Hybrid-Attention CNN
	  URL: https://www.semanticscholar.org/paper/9608f2b16d1d302f7507505b51a5be96fdf0b542
	  Citations: 19 | Authors: Zhifen Zhang, Rui Qin, Gengze Li, Z. Du, G. Wen, Weifeng He | Date: 2023-03-01
2025-11-14 22:16:10,628 - WARNING - root - 【手动下载提示】(无PDF): Intention-convolution and hybrid-attention network for vehicle trajectory prediction
	  URL: https://www.semanticscholar.org/paper/3bcb4d2994896053a5a8da42d09eb621d3b2b221
	  Citations: 34 | Authors: Chao Li, Zhanwen Liu, Shang Lin, Yang Wang, Xiangmo Zhao | Date: 2023-09-01
2025-11-14 22:16:10,629 - WARNING - root - 【手动下载提示】(无PDF): Hybrid Attention Network for Epileptic EEG Classification
	  URL: https://www.semanticscholar.org/paper/f282fa85469cc789c2f3b62e57e3446a49528afa
	  Citations: 17 | Authors: Yanna Zhao, Jiatong He, Fenglin Zhu, Tiantian Xiao, Yongfeng Zhang, Ziwei Wang, Fangzhou Xu, Yi Niu | Date: 2023-03-31
2025-11-14 22:16:10,630 - INFO - root - 正在下载: https://www.mdpi.com/1424-8220/23/13/6052/pdf?version=1688107163
2025-11-14 22:16:15,278 - INFO - root - 正在下载: https://www.mdpi.com/1424-8220/23/13/6052/pdf?version=1688107163
2025-11-14 22:16:20,973 - INFO - root - 正在下载: https://www.mdpi.com/1424-8220/23/13/6052/pdf?version=1688107163
2025-11-14 22:16:26,481 - INFO - root - 正在下载: https://www.mdpi.com/1424-8220/23/13/6052/pdf?version=1688107163
2025-11-14 22:16:36,713 - INFO - root - 正在下载: https://www.mdpi.com/1424-8220/23/13/6052/pdf?version=1688107163
2025-11-14 22:16:37,394 - WARNING - root - 下载 PHAM-YOLO: A Parallel Hybrid Attention Mechanism Network for Defect Detection of Meter in Substation (https://www.mdpi.com/1424-8220/23/13/6052/pdf?version=1688107163) 失败: 403 Client Error: Forbidden for url: https://www.mdpi.com/1424-8220/23/13/6052/pdf?version=1688107163
2025-11-14 22:16:37,394 - INFO - root - 正在下载: https://www.mdpi.com/1424-8220/23/15/6982/pdf?version=1691312141
2025-11-14 22:16:42,080 - INFO - root - 正在下载: https://www.mdpi.com/1424-8220/23/15/6982/pdf?version=1691312141
2025-11-14 22:16:47,059 - INFO - root - 正在下载: https://www.mdpi.com/1424-8220/23/15/6982/pdf?version=1691312141
2025-11-14 22:16:51,921 - INFO - root - 正在下载: https://www.mdpi.com/1424-8220/23/15/6982/pdf?version=1691312141
2025-11-14 22:17:01,018 - INFO - root - 正在下载: https://www.mdpi.com/1424-8220/23/15/6982/pdf?version=1691312141
2025-11-14 22:17:01,847 - WARNING - root - 下载 Defect Detection in Steel Using a Hybrid Attention Network (https://www.mdpi.com/1424-8220/23/15/6982/pdf?version=1691312141) 失败: 403 Client Error: Forbidden for url: https://www.mdpi.com/1424-8220/23/15/6982/pdf?version=1691312141
2025-11-14 22:17:01,850 - WARNING - root - 【手动下载提示】(无PDF): Hybrid Attention and Motion Constraint for Anomaly Detection in Crowded Scenes
	  URL: https://www.semanticscholar.org/paper/a5e107a1112c88294f44989f6622433fb402fb31
	  Citations: 30 | Authors: Xinfeng Zhang, Jinpeng Fang, Baoqing Yang, Shuhan Chen, Bin Li | Date: 2023-05-01
2025-11-14 22:17:01,851 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\hybrid attention\Hybrid Attention-Based Prototypical Networks for Noisy Few-Shot Relation Classification.pdf
2025-11-14 22:17:01,852 - INFO - root - 成功下载 (Semantic Scholar): Hybrid Attention-Based Prototypical Networks for Noisy Few-Shot Relation Classification
2025-11-14 22:17:01,860 - INFO - root - 正在下载: https://www.mdpi.com/2072-4292/15/2/526/pdf?version=1673863751
2025-11-14 22:17:06,684 - INFO - root - 正在下载: https://www.mdpi.com/2072-4292/15/2/526/pdf?version=1673863751
2025-11-14 22:17:11,303 - INFO - root - 正在下载: https://www.mdpi.com/2072-4292/15/2/526/pdf?version=1673863751
2025-11-14 22:17:16,213 - INFO - root - 正在下载: https://www.mdpi.com/2072-4292/15/2/526/pdf?version=1673863751
2025-11-14 22:17:24,926 - INFO - root - 正在下载: https://www.mdpi.com/2072-4292/15/2/526/pdf?version=1673863751
2025-11-14 22:17:25,728 - WARNING - root - 下载 Hybrid Attention-Based Encoder-Decoder Fully Convolutional Network for PolSAR Image Classification (https://www.mdpi.com/2072-4292/15/2/526/pdf?version=1673863751) 失败: 403 Client Error: Forbidden for url: https://www.mdpi.com/2072-4292/15/2/526/pdf?version=1673863751
2025-11-14 22:17:25,730 - WARNING - root - 【手动下载提示】(无PDF): Hybrid Attention Compression Network With Light Graph Attention Module for Remote Sensing Images
	  URL: https://www.semanticscholar.org/paper/11ab89aa34dae52624533795ebbe1ce707a66fd4
	  Citations: 9 | Authors: Tianpeng Pan, Lili Zhang, Yingchao Song, Yuxuan Liu | Date: N/A
2025-11-14 22:17:25,732 - WARNING - root - 【手动下载提示】(无PDF): An Adaptive Hybrid Attention Based Convolutional Neural Net for Intelligent Transportation Object Recognition
	  URL: https://www.semanticscholar.org/paper/269fed3c9a541a4073cde6e205878c2618b2f973
	  Citations: 11 | Authors: Qili Chen, Guangyuan Pan, Lin Zhao, Junfang Fan, Wenbai Chen, A. Zhang | Date: 2023-07-01
2025-11-14 22:17:25,734 - WARNING - root - 【手动下载提示】(无PDF): HEU-Net: hybrid attention residual block-based network with external skip connections for metal corrosion semantic segmentation
	  URL: https://www.semanticscholar.org/paper/80e0948897bc53edf4eba2e31e443010d8a2e19a
	  Citations: 9 | Authors: Tianchen Zhu, Shiqiang Zhu, Tao Zheng, Hongliang Ding, Wei Song, Cunjun Li | Date: 2023-06-22
2025-11-14 22:17:25,735 - WARNING - root - 【手动下载提示】(无PDF): Face-Periocular Cross-Identification via Contrastive Hybrid Attention Vision Transformer
	  URL: https://www.semanticscholar.org/paper/5765cc795e642e1a8e834d6af93cda3ac65a753a
	  Citations: 6 | Authors: Leslie Ching Ow Tiong, D. Sigmund, A. Teoh | Date: N/A
2025-11-14 22:17:25,737 - WARNING - root - 【手动下载提示】(无PDF): Image Super-Resolution with Multi-scale Hybrid Attention
	  URL: https://www.semanticscholar.org/paper/09691760c37f27ddf4d4b7908a348b20b110db6d
	  Citations: 0 | Authors: Ningzhi Wang, Hanyi Shi, Wenna Ruan, Lingbin Zeng | Date: N/A
2025-11-14 22:17:25,741 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\hybrid attention\Dual-view Correlation Hybrid Attention Network for Robust Holistic Mammogram Classification.pdf
2025-11-14 22:17:25,743 - INFO - root - 成功下载 (Semantic Scholar): Dual-view Correlation Hybrid Attention Network for Robust Holistic Mammogram Classification
2025-11-14 22:17:25,752 - WARNING - root - 【手动下载提示】(无PDF): Multi-level wavelet network based on CNN-Transformer hybrid attention for single image deraining
	  URL: https://www.semanticscholar.org/paper/97c485dbb41b68c193decdec5a4618ce3f5b4ee2
	  Citations: 8 | Authors: B. Liu, Siyan Fang | Date: 2023-08-09
2025-11-14 22:17:25,756 - INFO - root - 正在下载: https://www.mdpi.com/1424-8220/23/19/8285/pdf?version=1696663695
2025-11-14 22:17:30,690 - INFO - root - 正在下载: https://www.mdpi.com/1424-8220/23/19/8285/pdf?version=1696663695
2025-11-14 22:17:35,609 - INFO - root - 正在下载: https://www.mdpi.com/1424-8220/23/19/8285/pdf?version=1696663695
2025-11-14 22:17:40,435 - INFO - root - 正在下载: https://www.mdpi.com/1424-8220/23/19/8285/pdf?version=1696663695
2025-11-14 22:17:49,346 - INFO - root - 正在下载: https://www.mdpi.com/1424-8220/23/19/8285/pdf?version=1696663695
2025-11-14 22:17:50,047 - WARNING - root - 下载 A Fast and Robust Lane Detection via Online Re-Parameterization and Hybrid Attention (https://www.mdpi.com/1424-8220/23/19/8285/pdf?version=1696663695) 失败: 403 Client Error: Forbidden for url: https://www.mdpi.com/1424-8220/23/19/8285/pdf?version=1696663695
2025-11-14 22:17:50,049 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\hybrid attention\Stacked Hybrid-Attention and Group Collaborative Learning for Unbiased Scene Graph Generation.pdf
2025-11-14 22:17:50,050 - INFO - root - 成功下载 (Semantic Scholar): Stacked Hybrid-Attention and Group Collaborative Learning for Unbiased Scene Graph Generation
2025-11-14 22:17:50,054 - INFO - root - 正在下载: https://onlinelibrary.wiley.com/doi/pdfdirect/10.1049/ipr2.12934
2025-11-14 22:18:00,084 - INFO - root - 正在下载: https://onlinelibrary.wiley.com/doi/pdfdirect/10.1049/ipr2.12934
2025-11-14 22:18:09,652 - INFO - root - 正在下载: https://onlinelibrary.wiley.com/doi/pdfdirect/10.1049/ipr2.12934
2025-11-14 22:18:19,160 - INFO - root - 正在下载: https://onlinelibrary.wiley.com/doi/pdfdirect/10.1049/ipr2.12934
2025-11-14 22:18:33,043 - INFO - root - 正在下载: https://onlinelibrary.wiley.com/doi/pdfdirect/10.1049/ipr2.12934
2025-11-14 22:18:38,885 - WARNING - root - 下载 Hybrid attention mechanism of feature fusion for medical image segmentation (https://onlinelibrary.wiley.com/doi/pdfdirect/10.1049/ipr2.12934) 失败: 403 Client Error: Forbidden for url: https://onlinelibrary.wiley.com/doi/pdfdirect/10.1049/ipr2.12934
2025-11-14 22:18:38,887 - INFO - root - 正在下载: https://www.mdpi.com/2073-8994/15/10/1947/pdf?version=1697811500
2025-11-14 22:18:43,785 - INFO - root - 正在下载: https://www.mdpi.com/2073-8994/15/10/1947/pdf?version=1697811500
2025-11-14 22:18:49,196 - INFO - root - 正在下载: https://www.mdpi.com/2073-8994/15/10/1947/pdf?version=1697811500
2025-11-14 22:18:53,876 - INFO - root - 正在下载: https://www.mdpi.com/2073-8994/15/10/1947/pdf?version=1697811500
2025-11-14 22:19:02,707 - INFO - root - 正在下载: https://www.mdpi.com/2073-8994/15/10/1947/pdf?version=1697811500
2025-11-14 22:19:03,854 - WARNING - root - 下载 Transformer with Hybrid Attention Mechanism for Stereo Endoscopic Video Super Resolution (https://www.mdpi.com/2073-8994/15/10/1947/pdf?version=1697811500) 失败: 403 Client Error: Forbidden for url: https://www.mdpi.com/2073-8994/15/10/1947/pdf?version=1697811500
2025-11-14 22:19:03,855 - WARNING - root - 【手动下载提示】(无PDF): HHTrack: Hyperspectral Object Tracking Based on Hybrid Attention
	  URL: https://www.semanticscholar.org/paper/c1c5c93f3bd9b99ec5fe55b4c2b5bc29abf4b12a
	  Citations: 1 | Authors: Yuedong Tan, Wenfang Sun, Jieran Yuan, Wenwang Du, Zhe Wang, Nan Mao, Beibei Song | Date: 2023-08-14
2025-11-14 22:19:03,856 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\hybrid attention\Hybridformer_ Improving Squeezeformer with Hybrid Attention and NSR Mechanism.pdf
2025-11-14 22:19:03,856 - INFO - root - 成功下载 (Semantic Scholar): Hybridformer: Improving Squeezeformer with Hybrid Attention and NSR Mechanism
2025-11-14 22:19:03,857 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\hybrid attention\HAC-Net_ A Hybrid Attention-Based Convolutional Neural Network for Highly Accurate Protein-Ligand Bi.pdf
2025-11-14 22:19:03,859 - INFO - root - 成功下载 (Semantic Scholar): HAC-Net: A Hybrid Attention-Based Convolutional Neural Network for Highly Accurate Protein-Ligand Binding Affinity Prediction
2025-11-14 22:19:03,863 - WARNING - root - 【手动下载提示】(无PDF): A hybrid-attention semantic segmentation network for remote sensing interpretation in land-use surveillance
	  URL: https://www.semanticscholar.org/paper/4905315ab99ea19871a65e52be8c8c51624748aa
	  Citations: 49 | Authors: Ning Lv, Zenghui Zhang, Cong Li, Jiaxuan Deng, Tao Su, Chen Chen, Yang Zhou | Date: 2022-02-07
2025-11-14 22:19:03,878 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\hybrid attention\A Hybrid Attention Mechanism for Weakly-Supervised Temporal Action Localization.pdf
2025-11-14 22:19:03,879 - INFO - root - 成功下载 (Semantic Scholar): A Hybrid Attention Mechanism for Weakly-Supervised Temporal Action Localization
2025-11-14 22:19:03,880 - WARNING - root - 【手动下载提示】(无PDF): A hybrid attention-based deep learning approach for wind power prediction
	  URL: https://www.semanticscholar.org/paper/9d591544b9f179d93ad85720e8382e8e1c04c916
	  Citations: 128 | Authors: Zhengjing Ma, Gang Mei | Date: 2022-10-01
2025-11-14 22:19:03,880 - WARNING - root - 【手动下载提示】(无PDF): ColorFormer: Image Colorization via Color Memory Assisted Hybrid-Attention Transformer
	  URL: https://www.semanticscholar.org/paper/33618e85644d6705fd74086c13ee3b7e2a2a466a
	  Citations: 28 | Authors: Xiaozhong Ji, Boyuan Jiang, Donghao Luo, Guangpin Tao, Wenqing Chu, Zhifeng Xie, Chengjie Wang, Ying Tai | Date: N/A
2025-11-14 22:19:03,881 - WARNING - root - 【手动下载提示】(无PDF): HAM: Hybrid attention module in deep convolutional neural networks for image classification
	  URL: https://www.semanticscholar.org/paper/2cfa77f582ee36f2d1fe8869505aa5a71a5f99f3
	  Citations: 92 | Authors: Guoqiang Li, Qianhao Fang, Li Zha, Xin Gao, Nenggan Zheng | Date: 2022-05-01
2025-11-14 22:19:03,881 - WARNING - root - 【手动下载提示】(无PDF): State of health estimation for lithium-ion batteries based on hybrid attention and deep learning
	  URL: https://www.semanticscholar.org/paper/f91dcfd8df66da9bf3649c176869f980b9205115
	  Citations: 91 | Authors: Hongqian Zhao, Zheng Chen, Xing Shu, Jiangwei Shen, Zhenzhen Lei, Yuanjian Zhang | Date: 2022-12-01
2025-11-14 22:19:03,883 - INFO - root - 正在下载: https://downloads.hindawi.com/journals/cin/2022/4189500.pdf
2025-11-14 22:19:14,153 - INFO - root - 正在下载: https://downloads.hindawi.com/journals/cin/2022/4189500.pdf
2025-11-14 22:19:24,128 - INFO - root - 正在下载: https://downloads.hindawi.com/journals/cin/2022/4189500.pdf
2025-11-14 22:19:33,913 - INFO - root - 正在下载: https://downloads.hindawi.com/journals/cin/2022/4189500.pdf
2025-11-14 22:19:47,469 - INFO - root - 正在下载: https://downloads.hindawi.com/journals/cin/2022/4189500.pdf
2025-11-14 22:19:54,165 - WARNING - root - 下载 Aircraft Image Recognition Network Based on Hybrid Attention Mechanism (https://downloads.hindawi.com/journals/cin/2022/4189500.pdf) 失败: 403 Client Error: Forbidden for url: https://downloads.hindawi.com/journals/cin/2022/4189500.pdf
2025-11-14 22:19:54,166 - WARNING - root - 【手动下载提示】(无PDF): Hybrid attention based vehicle trajectory prediction
	  URL: https://www.semanticscholar.org/paper/a2778f12363b79e0a604ddd21a878f3abb0acced
	  Citations: 6 | Authors: Lingyang Wang, Wenping Jiang | Date: 2023-04-06
2025-11-14 22:19:54,166 - WARNING - root - 【手动下载提示】(无PDF): A Hybrid Attention-Based Paralleled Deep Learning model for tool wear prediction
	  URL: https://www.semanticscholar.org/paper/27da7ffd2319f8a2f47eec128894be31f88fc35c
	  Citations: 87 | Authors: Jian Duan, Xi Zhang, Tielin Shi | Date: 2022-08-01
2025-11-14 22:19:54,167 - INFO - root - 正在下载: https://ieeexplore.ieee.org/ielx7/6287639/9668973/09693977.pdf
2025-11-14 22:20:04,089 - INFO - root - 正在下载: https://ieeexplore.ieee.org/ielx7/6287639/9668973/09693977.pdf
2025-11-14 22:20:14,594 - INFO - root - 正在下载: https://ieeexplore.ieee.org/ielx7/6287639/9668973/09693977.pdf
2025-11-14 22:20:24,674 - INFO - root - 正在下载: https://ieeexplore.ieee.org/ielx7/6287639/9668973/09693977.pdf
2025-11-14 22:20:38,684 - INFO - root - 正在下载: https://ieeexplore.ieee.org/ielx7/6287639/9668973/09693977.pdf
2025-11-14 22:20:44,623 - WARNING - root - 下载 HANN: Hybrid Attention Neural Network for Detecting Covid-19 Related Rumors (https://ieeexplore.ieee.org/ielx7/6287639/9668973/09693977.pdf) 失败: 418 Client Error: Unknown Code for url: https://ieeexplore.ieee.org/ielx7/6287639/9668973/09693977.pdf
2025-11-14 22:20:44,625 - WARNING - root - 【手动下载提示】(无PDF): Hybrid Attention-Based Prototypical Networks for Few-Shot Sound Classification
	  URL: https://www.semanticscholar.org/paper/e0ddd13d74fe020c8e63eb2ef5a2daa687565953
	  Citations: 15 | Authors: You Wang, D.V. Anderson | Date: 2022-05-23
2025-11-14 22:20:44,628 - INFO - root - 正在下载: https://www.mdpi.com/1424-8220/22/10/3701/pdf?version=1652360619
2025-11-14 22:20:50,122 - INFO - root - 正在下载: https://www.mdpi.com/1424-8220/22/10/3701/pdf?version=1652360619
2025-11-14 22:20:54,995 - INFO - root - 正在下载: https://www.mdpi.com/1424-8220/22/10/3701/pdf?version=1652360619
2025-11-14 22:20:59,660 - INFO - root - 正在下载: https://www.mdpi.com/1424-8220/22/10/3701/pdf?version=1652360619
2025-11-14 22:21:08,665 - INFO - root - 正在下载: https://www.mdpi.com/1424-8220/22/10/3701/pdf?version=1652360619
2025-11-14 22:21:09,312 - WARNING - root - 下载 An Anti-UAV Long-Term Tracking Method with Hybrid Attention Mechanism and Hierarchical Discriminator (https://www.mdpi.com/1424-8220/22/10/3701/pdf?version=1652360619) 失败: 403 Client Error: Forbidden for url: https://www.mdpi.com/1424-8220/22/10/3701/pdf?version=1652360619
2025-11-14 22:21:09,313 - WARNING - root - 【手动下载提示】(无PDF): A Hybrid Attention-Based Deep Neural Network for Simultaneous Multi-Sensor Pruning and Human Activity Recognition
	  URL: https://www.semanticscholar.org/paper/06f82dcfa03d18408410b03b4203fff9bbeceeac
	  Citations: 21 | Authors: Yu Zhou, Zhuo Yang, Xiao Zhang, Yufan Wang | Date: 2022-12-15
2025-11-14 22:21:09,313 - WARNING - root - 【手动下载提示】(无PDF): End-to-End Multilevel Hybrid Attention Framework for Hyperspectral Image Classification
	  URL: https://www.semanticscholar.org/paper/6cbd2101b7faff37d402cc8574c95477af70f3aa
	  Citations: 19 | Authors: Jianhong Xiang, Chen Wei, Minhui Wang, Long Teng | Date: N/A
2025-11-14 22:21:09,314 - WARNING - root - 【手动下载提示】(无PDF): Parallel Deep Learning Algorithms With Hybrid Attention Mechanism for Image Segmentation of Lung Tumors
	  URL: https://www.semanticscholar.org/paper/05c67b073bde463686697eb553576958c8403a60
	  Citations: 88 | Authors: Hexuan Hu, Qingqiu Li, Yun-feng Zhao, Ye Zhang | Date: 2021-04-01
2025-11-14 22:21:09,314 - WARNING - root - 【手动下载提示】(无PDF): Hybrid attention network for semantic segmentation
	  URL: https://www.semanticscholar.org/paper/ee93962e142d4e7fa0b84f5d59970cb30a0b8960
	  Citations: 0 | Authors: Yin Yang, Juan Yang, Ronggui Wang | Date: 2023-10-19
2025-11-14 22:21:09,315 - WARNING - root - 【手动下载提示】(无PDF): A hybrid attention semantic segmentation network for unstructured terrain on Mars
	  URL: https://www.semanticscholar.org/paper/7b71919c1e0adafaa102cf03849b6c21841c8e54
	  Citations: 53 | Authors: Haiqiang Liu, Meibao Yao, Xueming Xiao, Hutao Cui | Date: 2022-08-01
2025-11-14 22:21:09,317 - INFO - root - 正在下载: https://downloads.hindawi.com/journals/wcmc/2022/5441366.pdf
2025-11-14 22:21:19,127 - INFO - root - 正在下载: https://downloads.hindawi.com/journals/wcmc/2022/5441366.pdf
2025-11-14 22:21:29,437 - INFO - root - 正在下载: https://downloads.hindawi.com/journals/wcmc/2022/5441366.pdf
2025-11-14 22:21:40,002 - INFO - root - 正在下载: https://downloads.hindawi.com/journals/wcmc/2022/5441366.pdf
2025-11-14 22:21:54,127 - INFO - root - 正在下载: https://downloads.hindawi.com/journals/wcmc/2022/5441366.pdf
2025-11-14 22:21:59,568 - WARNING - root - 下载 Classification of Diabetic Retinopathy Based on Multiscale Hybrid Attention Mechanism and Residual Algorithm (https://downloads.hindawi.com/journals/wcmc/2022/5441366.pdf) 失败: 403 Client Error: Forbidden for url: https://downloads.hindawi.com/journals/wcmc/2022/5441366.pdf
2025-11-14 22:21:59,568 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\hybrid attention\RHA-Net_ An Encoder-Decoder Network with Residual Blocks and Hybrid Attention Mechanisms for Pavemen.pdf
2025-11-14 22:21:59,569 - INFO - root - 成功下载 (Semantic Scholar): RHA-Net: An Encoder-Decoder Network with Residual Blocks and Hybrid Attention Mechanisms for Pavement Crack Segmentation
2025-11-14 22:21:59,570 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\hybrid attention\HHTrack_ Hyperspectral Object Tracking Using Hybrid Attention.pdf
2025-11-14 22:21:59,575 - INFO - root - 成功下载 (Semantic Scholar): HHTrack: Hyperspectral Object Tracking Using Hybrid Attention
2025-11-14 22:21:59,576 - WARNING - root - 【手动下载提示】(无PDF): Hybrid attention network for image captioning
	  URL: https://www.semanticscholar.org/paper/45acf57fd885b60d858dc6c49da4ff536a901d67
	  Citations: 22 | Authors: Wenhui Jiang, Qin Li, K. Zhan, Yuming Fang, Fei Shen | Date: 2022-05-01
2025-11-14 22:21:59,578 - INFO - root - 正在下载: https://downloads.hindawi.com/journals/wcmc/2022/3301718.pdf
2025-11-14 22:22:09,316 - INFO - root - 正在下载: https://downloads.hindawi.com/journals/wcmc/2022/3301718.pdf
2025-11-14 22:22:19,134 - INFO - root - 正在下载: https://downloads.hindawi.com/journals/wcmc/2022/3301718.pdf
2025-11-14 22:22:30,086 - INFO - root - 正在下载: https://downloads.hindawi.com/journals/wcmc/2022/3301718.pdf
2025-11-14 22:22:43,921 - INFO - root - 正在下载: https://downloads.hindawi.com/journals/wcmc/2022/3301718.pdf
2025-11-14 22:22:50,437 - WARNING - root - 下载 Malicious Code Classification Method Based on Deep Residual Network and Hybrid Attention Mechanism for Edge Security (https://downloads.hindawi.com/journals/wcmc/2022/3301718.pdf) 失败: 403 Client Error: Forbidden for url: https://downloads.hindawi.com/journals/wcmc/2022/3301718.pdf
2025-11-14 22:22:50,438 - INFO - root - 正在下载: https://www.mdpi.com/2079-9292/11/17/2709/pdf?version=1661780513
2025-11-14 22:22:55,055 - INFO - root - 正在下载: https://www.mdpi.com/2079-9292/11/17/2709/pdf?version=1661780513
2025-11-14 22:22:59,670 - INFO - root - 正在下载: https://www.mdpi.com/2079-9292/11/17/2709/pdf?version=1661780513
2025-11-14 22:23:04,409 - INFO - root - 正在下载: https://www.mdpi.com/2079-9292/11/17/2709/pdf?version=1661780513
2025-11-14 22:23:13,078 - INFO - root - 正在下载: https://www.mdpi.com/2079-9292/11/17/2709/pdf?version=1661780513
2025-11-14 22:23:13,836 - WARNING - root - 下载 Occluded Vehicle Detection via Multi-Scale Hybrid Attention Mechanism in the Road Scene (https://www.mdpi.com/2079-9292/11/17/2709/pdf?version=1661780513) 失败: 403 Client Error: Forbidden for url: https://www.mdpi.com/2079-9292/11/17/2709/pdf?version=1661780513
2025-11-14 22:23:13,837 - INFO - root - 正在下载: https://www.mdpi.com/2079-9292/11/22/3787/pdf?version=1669096288
2025-11-14 22:23:19,005 - INFO - root - 正在下载: https://www.mdpi.com/2079-9292/11/22/3787/pdf?version=1669096288
2025-11-14 22:23:23,909 - INFO - root - 正在下载: https://www.mdpi.com/2079-9292/11/22/3787/pdf?version=1669096288
2025-11-14 22:23:28,530 - INFO - root - 正在下载: https://www.mdpi.com/2079-9292/11/22/3787/pdf?version=1669096288
2025-11-14 22:23:37,169 - INFO - root - 正在下载: https://www.mdpi.com/2079-9292/11/22/3787/pdf?version=1669096288
2025-11-14 22:23:37,791 - WARNING - root - 下载 HA-Unet: A Modified Unet Based on Hybrid Attention for Urban Water Extraction in SAR Images (https://www.mdpi.com/2079-9292/11/22/3787/pdf?version=1669096288) 失败: 403 Client Error: Forbidden for url: https://www.mdpi.com/2079-9292/11/22/3787/pdf?version=1669096288
2025-11-14 22:23:37,793 - INFO - root - 正在下载: https://www.mdpi.com/2227-7390/10/11/1915/pdf?version=1654510435
2025-11-14 22:23:42,474 - INFO - root - 正在下载: https://www.mdpi.com/2227-7390/10/11/1915/pdf?version=1654510435
2025-11-14 22:23:47,221 - INFO - root - 正在下载: https://www.mdpi.com/2227-7390/10/11/1915/pdf?version=1654510435
2025-11-14 22:23:52,048 - INFO - root - 正在下载: https://www.mdpi.com/2227-7390/10/11/1915/pdf?version=1654510435
2025-11-14 22:24:00,685 - INFO - root - 正在下载: https://www.mdpi.com/2227-7390/10/11/1915/pdf?version=1654510435
2025-11-14 22:24:01,359 - WARNING - root - 下载 HA-RoadFormer: Hybrid Attention Transformer with Multi-Branch for Large-Scale High-Resolution Dense Road Segmentation (https://www.mdpi.com/2227-7390/10/11/1915/pdf?version=1654510435) 失败: 403 Client Error: Forbidden for url: https://www.mdpi.com/2227-7390/10/11/1915/pdf?version=1654510435
2025-11-14 22:24:01,360 - WARNING - root - 【手动下载提示】(无PDF): Generative adversarial network with hybrid attention and compromised normalization for multi-scene image conversion
	  URL: https://www.semanticscholar.org/paper/1defd0b952f393b189dc61bc421c8ae7dd4df3c2
	  Citations: 11 | Authors: Jinsheng Xiao, Shuhao Zhang, Yuntao Yao, Zhongyuan Wang, Yongqin Zhang, Yuan-fang Wang | Date: 2022-01-29
2025-11-14 22:24:01,361 - WARNING - root - 【手动下载提示】(无PDF): A hybrid attention improved ResNet based fault diagnosis method of wind turbines gearbox
	  URL: https://www.semanticscholar.org/paper/c71d11b59d8a85d413af1dab9337e39e52910774
	  Citations: 161 | Authors: Kai Zhang, B. Tang, Lei Deng, Xiaoli Liu | Date: 2021-05-03
2025-11-14 22:24:01,364 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\hybrid attention\RAIN_ Reinforced Hybrid Attention Inference Network for Motion Forecasting.pdf
2025-11-14 22:24:01,365 - INFO - root - 成功下载 (Semantic Scholar): RAIN: Reinforced Hybrid Attention Inference Network for Motion Forecasting
2025-11-14 22:24:01,368 - WARNING - root - 【手动下载提示】(无PDF): A hybrid attention mechanism for blind automatic modulation classification
	  URL: https://www.semanticscholar.org/paper/f226e86f57129dfa31db5c69c14163b9d3904988
	  Citations: 8 | Authors: Fan Jia, Yueyi Yang, Junyi Zhang, Yong Yang | Date: 2022-04-05
2025-11-14 22:24:01,372 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\hybrid attention\A Hybrid-Attention Nested UNet for Nuclear Segmentation in Histopathological Images.pdf
2025-11-14 22:24:01,375 - INFO - root - 成功下载 (Semantic Scholar): A Hybrid-Attention Nested UNet for Nuclear Segmentation in Histopathological Images
2025-11-14 22:24:01,377 - INFO - root - 正在下载: https://ieeexplore.ieee.org/ielx7/4609443/9314330/09444168.pdf
2025-11-14 22:24:20,986 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\hybrid attention\MHA-Net_ Multipath Hybrid Attention Network for Building Footprint Extraction From High-Resolution R.pdf
2025-11-14 22:24:20,991 - INFO - root - 成功下载 (Semantic Scholar): MHA-Net: Multipath Hybrid Attention Network for Building Footprint Extraction From High-Resolution Remote Sensing Imagery
2025-11-14 22:24:20,993 - INFO - root - 正在下载: https://ieeexplore.ieee.org/ielx7/6287639/6514899/09837031.pdf
2025-11-14 22:24:31,173 - INFO - root - 正在下载: https://ieeexplore.ieee.org/ielx7/6287639/6514899/09837031.pdf
2025-11-14 22:24:41,837 - INFO - root - 正在下载: https://ieeexplore.ieee.org/ielx7/6287639/6514899/09837031.pdf
2025-11-14 22:24:51,991 - INFO - root - 正在下载: https://ieeexplore.ieee.org/ielx7/6287639/6514899/09837031.pdf
2025-11-14 22:25:06,076 - INFO - root - 正在下载: https://ieeexplore.ieee.org/ielx7/6287639/6514899/09837031.pdf
2025-11-14 22:25:12,620 - WARNING - root - 下载 Dual-Path Hybrid Attention Network for Monaural Speech Separation (https://ieeexplore.ieee.org/ielx7/6287639/6514899/09837031.pdf) 失败: 404 Client Error: Not Found for url: https://ieeexplore.ieee.org/ielx7/6287639/6514899/09837031.pdf
2025-11-14 22:25:12,621 - WARNING - root - 【手动下载提示】(无PDF): Neural machine translation for Indian language pair using hybrid attention mechanism
	  URL: https://www.semanticscholar.org/paper/3479ff37a0bb3858b1761a871b81f4ca3dd26454
	  Citations: 7 | Authors: Basab Nath, Sunita Sarkar, Surajeet Das, Somnath Mukhopadhyay | Date: 2022-02-01
2025-11-14 22:25:12,622 - WARNING - root - 【手动下载提示】(无PDF): Hybrid Attention Fusion Segmentation Network for Diffuse Large B-cell Lymphoma in PET-CT
	  URL: https://www.semanticscholar.org/paper/80c16017651e0fc33b4bb10e2686a582ae119459
	  Citations: 6 | Authors: Shun Chen, Ang Li, Jianxin Chen, Xuguang Zhang, Chong Jiang, Jingyan Xu | Date: 2022-11-01
2025-11-14 22:25:12,622 - WARNING - root - 【手动下载提示】(无PDF): Hybrid attention mechanism for liver tumor segmentation in CT images
	  URL: https://www.semanticscholar.org/paper/9410e41c65c34be9a745cda06f430de0d53084d9
	  Citations: 6 | Authors: Ming Gong, Baixiang Zhao, J. Soraghan, G. D. Caterina, D. Grose | Date: 2022-09-11
2025-11-14 22:25:12,624 - WARNING - root - 【手动下载提示】(无PDF): Two-stream LSTM Network with Hybrid Attention for Vehicle Trajectory Prediction
	  URL: https://www.semanticscholar.org/paper/9d3d3290e715e5027b5cce97e10071ca0a6a06eb
	  Citations: 6 | Authors: Chao Li, Zhanwen Liu, Jiaying Zhang, Yang Wang, Fan Ding, Xiangmo Zhao | Date: 2022-10-08
2025-11-14 22:25:12,626 - INFO - root - 正在下载: https://www.mdpi.com/2072-4292/12/22/3764/pdf?version=1605536539
2025-11-14 22:25:17,347 - INFO - root - 正在下载: https://www.mdpi.com/2072-4292/12/22/3764/pdf?version=1605536539
2025-11-14 22:25:22,069 - INFO - root - 正在下载: https://www.mdpi.com/2072-4292/12/22/3764/pdf?version=1605536539
2025-11-14 22:25:31,180 - INFO - root - 正在下载: https://www.mdpi.com/2072-4292/12/22/3764/pdf?version=1605536539
2025-11-14 22:25:40,107 - INFO - root - 正在下载: https://www.mdpi.com/2072-4292/12/22/3764/pdf?version=1605536539
2025-11-14 22:25:41,116 - WARNING - root - 下载 A Hybrid Attention-Aware Fusion Network (HAFNet) for Building Extraction from High-Resolution Imagery and LiDAR Data (https://www.mdpi.com/2072-4292/12/22/3764/pdf?version=1605536539) 失败: 403 Client Error: Forbidden for url: https://www.mdpi.com/2072-4292/12/22/3764/pdf?version=1605536539
2025-11-14 22:25:41,117 - WARNING - root - 【手动下载提示】(无PDF): DA-DETR: Domain Adaptive Detection Transformer by Hybrid Attention
	  URL: https://www.semanticscholar.org/paper/c0f715596b2f557806c2de2404cf9a0ad5781cef
	  Citations: 33 | Authors: Jingyi Zhang, Jiaxing Huang, Zhipeng Luo, Gongjie Zhang, Shijian Lu | Date: N/A
2025-11-14 22:25:41,117 - INFO - root - 正在下载: https://www.mdpi.com/1424-8220/21/6/2003/pdf?version=1615879962
2025-11-14 22:25:45,749 - INFO - root - 正在下载: https://www.mdpi.com/1424-8220/21/6/2003/pdf?version=1615879962
2025-11-14 22:25:50,684 - INFO - root - 正在下载: https://www.mdpi.com/1424-8220/21/6/2003/pdf?version=1615879962
2025-11-14 22:25:55,395 - INFO - root - 正在下载: https://www.mdpi.com/1424-8220/21/6/2003/pdf?version=1615879962
2025-11-14 22:26:04,131 - INFO - root - 正在下载: https://www.mdpi.com/1424-8220/21/6/2003/pdf?version=1615879962
2025-11-14 22:26:04,792 - WARNING - root - 下载 Hybrid Attention Cascade Network for Facial Expression Recognition (https://www.mdpi.com/1424-8220/21/6/2003/pdf?version=1615879962) 失败: 403 Client Error: Forbidden for url: https://www.mdpi.com/1424-8220/21/6/2003/pdf?version=1615879962
2025-11-14 22:26:04,798 - INFO - root - 正在下载: https://www.frontiersin.org/articles/10.3389/fphys.2021.683025/pdf
2025-11-14 22:26:20,557 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\hybrid attention\HADLN_ Hybrid Attention-Based Deep Learning Network for Automated Arrhythmia Classification.pdf
2025-11-14 22:26:20,564 - INFO - root - 成功下载 (Semantic Scholar): HADLN: Hybrid Attention-Based Deep Learning Network for Automated Arrhythmia Classification
2025-11-14 22:26:20,566 - INFO - root - 正在下载: https://www.mdpi.com/2072-4292/13/10/1962/pdf?version=1621496001
2025-11-14 22:26:25,936 - INFO - root - 正在下载: https://www.mdpi.com/2072-4292/13/10/1962/pdf?version=1621496001
2025-11-14 22:26:30,561 - INFO - root - 正在下载: https://www.mdpi.com/2072-4292/13/10/1962/pdf?version=1621496001
2025-11-14 22:26:35,929 - INFO - root - 正在下载: https://www.mdpi.com/2072-4292/13/10/1962/pdf?version=1621496001
2025-11-14 22:26:44,572 - INFO - root - 正在下载: https://www.mdpi.com/2072-4292/13/10/1962/pdf?version=1621496001
2025-11-14 22:26:45,233 - WARNING - root - 下载 Hybrid Attention Based Residual Network for Pansharpening (https://www.mdpi.com/2072-4292/13/10/1962/pdf?version=1621496001) 失败: 403 Client Error: Forbidden for url: https://www.mdpi.com/2072-4292/13/10/1962/pdf?version=1621496001
2025-11-14 22:26:45,240 - INFO - root - 正在下载: https://journals.plos.org/plosone/article/file?id=10.1371/journal.pone.0261285&type=printable
2025-11-14 22:26:59,597 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\hybrid attention\MHANet_ A hybrid attention mechanism for retinal diseases classification.pdf
2025-11-14 22:26:59,603 - INFO - root - 成功下载 (Semantic Scholar): MHANet: A hybrid attention mechanism for retinal diseases classification
2025-11-14 22:26:59,603 - INFO - root - 检索到 21 篇论文（包括待手动下载的），开始总结...
2025-11-14 22:26:59,610 - INFO - root - --- 开始论文总结阶段 ---
2025-11-14 22:26:59,611 - INFO - root - 跳过已处理论文 Hybrid Attention Fusion Embedded in Transformer for Remote Sensing Image Semantic Segmentation：D:\ChatPaper\api_downloads\hybrid attention\Hybrid Attention Fusion Embedded in Transformer for Remote Sensing Image Semantic Segmentation.pdf
2025-11-14 22:26:59,613 - INFO - root - 跳过已处理论文 YOLO Algorithm With Hybrid Attention Feature Pyramid Network for Solder Joint Defect Detection：D:\ChatPaper\api_downloads\hybrid attention\YOLO Algorithm With Hybrid Attention Feature Pyramid Network for Solder Joint Defect Detection.pdf
2025-11-14 22:26:59,620 - INFO - root - 跳过已处理论文 Frequency Enhanced Hybrid Attention Network for Sequential Recommendation：D:\ChatPaper\api_downloads\hybrid attention\Frequency Enhanced Hybrid Attention Network for Sequential Recommendation.pdf
2025-11-14 22:26:59,620 - INFO - root - 跳过已处理论文 HAT: Hybrid Attention Transformer for Image Restoration：D:\ChatPaper\api_downloads\hybrid attention\HAT_ Hybrid Attention Transformer for Image Restoration.pdf
2025-11-14 22:26:59,622 - INFO - root - 跳过已处理论文 Multi-scale deep residual shrinkage networks with a hybrid attention mechanism for rolling bearing fault diagnosis：D:\ChatPaper\api_downloads\hybrid attention\Multi-scale deep residual shrinkage networks with a hybrid attention mechanism for rolling bearing f.pdf
2025-11-14 22:26:59,624 - INFO - root - 跳过已处理论文 Physics Inspired Hybrid Attention for SAR Target Recognition：D:\ChatPaper\api_downloads\hybrid attention\Physics Inspired Hybrid Attention for SAR Target Recognition.pdf
2025-11-14 22:26:59,625 - INFO - root - 跳过已处理论文 Fine-grained image classification method based on hybrid attention module：D:\ChatPaper\api_downloads\hybrid attention\Fine-grained image classification method based on hybrid attention module.pdf
2025-11-14 22:26:59,626 - INFO - root - 正在总结论文 8/21: Hybrid Attention-Based U-Shaped Network for Remote Sensing Image Super-Resolution
2025-11-14 22:33:06,678 - INFO - root - 正在提取论文图片到目录: ./export\hybrid attention\images\Hybrid Attention-Based U-Shaped Network for Remote Sensing Image Super-Resolution
2025-11-14 22:33:10,346 - INFO - root - 已保存图片 1/10：./export\hybrid attention\images\Hybrid Attention-Based U-Shaped Network for Remote Sensing Image Super-Resolution\figure_1_page9.png
2025-11-14 22:33:10,542 - INFO - root - 已保存图片 2/10：./export\hybrid attention\images\Hybrid Attention-Based U-Shaped Network for Remote Sensing Image Super-Resolution\figure_2_page9.png
2025-11-14 22:33:10,655 - INFO - root - 已保存图片 3/10：./export\hybrid attention\images\Hybrid Attention-Based U-Shaped Network for Remote Sensing Image Super-Resolution\figure_3_page9.png
2025-11-14 22:33:10,777 - INFO - root - 已保存图片 4/10：./export\hybrid attention\images\Hybrid Attention-Based U-Shaped Network for Remote Sensing Image Super-Resolution\figure_4_page9.png
2025-11-14 22:33:10,974 - INFO - root - 已保存图片 5/10：./export\hybrid attention\images\Hybrid Attention-Based U-Shaped Network for Remote Sensing Image Super-Resolution\figure_5_page13.png
2025-11-14 22:33:11,318 - INFO - root - 已保存图片 6/10：./export\hybrid attention\images\Hybrid Attention-Based U-Shaped Network for Remote Sensing Image Super-Resolution\figure_6_page13.png
2025-11-14 22:33:11,636 - INFO - root - 已保存图片 7/10：./export\hybrid attention\images\Hybrid Attention-Based U-Shaped Network for Remote Sensing Image Super-Resolution\figure_7_page15.png
2025-11-14 22:33:11,816 - INFO - root - 已保存图片 8/10：./export\hybrid attention\images\Hybrid Attention-Based U-Shaped Network for Remote Sensing Image Super-Resolution\figure_8_page15.png
2025-11-14 22:33:11,915 - INFO - root - 已保存图片 9/10：./export\hybrid attention\images\Hybrid Attention-Based U-Shaped Network for Remote Sensing Image Super-Resolution\figure_9_page15.png
2025-11-14 22:33:12,054 - INFO - root - 已保存图片 10/10：./export\hybrid attention\images\Hybrid Attention-Based U-Shaped Network for Remote Sensing Image Super-Resolution\figure_10_page15.png
2025-11-14 22:33:12,061 - INFO - root - 成功添加图片 1：./export\hybrid attention\images\Hybrid Attention-Based U-Shaped Network for Remote Sensing Image Super-Resolution\figure_1_page9.png
2025-11-14 22:33:12,062 - INFO - root - 成功添加图片 2：./export\hybrid attention\images\Hybrid Attention-Based U-Shaped Network for Remote Sensing Image Super-Resolution\figure_2_page9.png
2025-11-14 22:33:12,062 - INFO - root - 成功添加图片 3：./export\hybrid attention\images\Hybrid Attention-Based U-Shaped Network for Remote Sensing Image Super-Resolution\figure_3_page9.png
2025-11-14 22:33:12,062 - INFO - root - 成功添加图片 4：./export\hybrid attention\images\Hybrid Attention-Based U-Shaped Network for Remote Sensing Image Super-Resolution\figure_4_page9.png
2025-11-14 22:33:12,063 - INFO - root - 成功添加图片 5：./export\hybrid attention\images\Hybrid Attention-Based U-Shaped Network for Remote Sensing Image Super-Resolution\figure_5_page13.png
2025-11-14 22:33:12,063 - INFO - root - 成功添加图片 6：./export\hybrid attention\images\Hybrid Attention-Based U-Shaped Network for Remote Sensing Image Super-Resolution\figure_6_page13.png
2025-11-14 22:33:12,064 - INFO - root - 成功添加图片 7：./export\hybrid attention\images\Hybrid Attention-Based U-Shaped Network for Remote Sensing Image Super-Resolution\figure_7_page15.png
2025-11-14 22:33:12,064 - INFO - root - 成功添加图片 8：./export\hybrid attention\images\Hybrid Attention-Based U-Shaped Network for Remote Sensing Image Super-Resolution\figure_8_page15.png
2025-11-14 22:33:12,064 - INFO - root - 成功添加图片 9：./export\hybrid attention\images\Hybrid Attention-Based U-Shaped Network for Remote Sensing Image Super-Resolution\figure_9_page15.png
2025-11-14 22:33:12,064 - INFO - root - 成功添加图片 10：./export\hybrid attention\images\Hybrid Attention-Based U-Shaped Network for Remote Sensing Image Super-Resolution\figure_10_page15.png
2025-11-14 22:33:12,067 - INFO - root - 论文《Hybrid Attention-Based U-Shaped Network for Remote Sensing Image Super-Resolution》的分析已保存到 ./export\hybrid attention\Hybrid Attention-Based U-Shaped Network for Remote Sensing Image Super-Resolution.md
2025-11-14 22:33:12,076 - INFO - root - 跳过已处理论文 Hybrid Attention-Based Prototypical Networks for Noisy Few-Shot Relation Classification：D:\ChatPaper\api_downloads\hybrid attention\Hybrid Attention-Based Prototypical Networks for Noisy Few-Shot Relation Classification.pdf
2025-11-14 22:33:12,077 - INFO - root - 跳过已处理论文 Dual-view Correlation Hybrid Attention Network for Robust Holistic Mammogram Classification：D:\ChatPaper\api_downloads\hybrid attention\Dual-view Correlation Hybrid Attention Network for Robust Holistic Mammogram Classification.pdf
2025-11-14 22:33:12,077 - INFO - root - 跳过已处理论文 Stacked Hybrid-Attention and Group Collaborative Learning for Unbiased Scene Graph Generation：D:\ChatPaper\api_downloads\hybrid attention\Stacked Hybrid-Attention and Group Collaborative Learning for Unbiased Scene Graph Generation.pdf
2025-11-14 22:33:12,077 - INFO - root - 跳过已处理论文 Hybridformer: Improving Squeezeformer with Hybrid Attention and NSR Mechanism：D:\ChatPaper\api_downloads\hybrid attention\Hybridformer_ Improving Squeezeformer with Hybrid Attention and NSR Mechanism.pdf
2025-11-14 22:33:12,078 - INFO - root - 跳过已处理论文 HAC-Net: A Hybrid Attention-Based Convolutional Neural Network for Highly Accurate Protein-Ligand Binding Affinity Prediction：D:\ChatPaper\api_downloads\hybrid attention\HAC-Net_ A Hybrid Attention-Based Convolutional Neural Network for Highly Accurate Protein-Ligand Bi.pdf
2025-11-14 22:33:12,078 - INFO - root - 跳过已处理论文 A Hybrid Attention Mechanism for Weakly-Supervised Temporal Action Localization：D:\ChatPaper\api_downloads\hybrid attention\A Hybrid Attention Mechanism for Weakly-Supervised Temporal Action Localization.pdf
2025-11-14 22:33:12,079 - INFO - root - 跳过已处理论文 RHA-Net: An Encoder-Decoder Network with Residual Blocks and Hybrid Attention Mechanisms for Pavement Crack Segmentation：D:\ChatPaper\api_downloads\hybrid attention\RHA-Net_ An Encoder-Decoder Network with Residual Blocks and Hybrid Attention Mechanisms for Pavemen.pdf
2025-11-14 22:33:12,079 - INFO - root - 跳过已处理论文 HHTrack: Hyperspectral Object Tracking Using Hybrid Attention：D:\ChatPaper\api_downloads\hybrid attention\HHTrack_ Hyperspectral Object Tracking Using Hybrid Attention.pdf
2025-11-14 22:33:12,080 - INFO - root - 跳过已处理论文 RAIN: Reinforced Hybrid Attention Inference Network for Motion Forecasting：D:\ChatPaper\api_downloads\hybrid attention\RAIN_ Reinforced Hybrid Attention Inference Network for Motion Forecasting.pdf
2025-11-14 22:33:12,081 - INFO - root - 跳过已处理论文 A Hybrid-Attention Nested UNet for Nuclear Segmentation in Histopathological Images：D:\ChatPaper\api_downloads\hybrid attention\A Hybrid-Attention Nested UNet for Nuclear Segmentation in Histopathological Images.pdf
2025-11-14 22:33:12,081 - INFO - root - 正在总结论文 19/21: MHA-Net: Multipath Hybrid Attention Network for Building Footprint Extraction From High-Resolution Remote Sensing Imagery
2025-11-14 22:39:56,147 - INFO - root - 正在提取论文图片到目录: ./export\hybrid attention\images\MHA-Net_ Multipath Hybrid Attention Network for Building Footprint Extraction From High-Resolution R
2025-11-14 22:39:56,458 - INFO - root - 已保存图片 1/10：./export\hybrid attention\images\MHA-Net_ Multipath Hybrid Attention Network for Building Footprint Extraction From High-Resolution R\figure_1_page8.jpeg
2025-11-14 22:39:56,663 - INFO - root - 已保存图片 2/10：./export\hybrid attention\images\MHA-Net_ Multipath Hybrid Attention Network for Building Footprint Extraction From High-Resolution R\figure_2_page9.jpeg
2025-11-14 22:39:56,850 - INFO - root - 已保存图片 3/10：./export\hybrid attention\images\MHA-Net_ Multipath Hybrid Attention Network for Building Footprint Extraction From High-Resolution R\figure_3_page4.jpeg
2025-11-14 22:39:56,977 - INFO - root - 已保存图片 4/10：./export\hybrid attention\images\MHA-Net_ Multipath Hybrid Attention Network for Building Footprint Extraction From High-Resolution R\figure_4_page3.jpeg
2025-11-14 22:39:57,086 - INFO - root - 已保存图片 5/10：./export\hybrid attention\images\MHA-Net_ Multipath Hybrid Attention Network for Building Footprint Extraction From High-Resolution R\figure_5_page6.jpeg
2025-11-14 22:39:57,152 - INFO - root - 已保存图片 6/10：./export\hybrid attention\images\MHA-Net_ Multipath Hybrid Attention Network for Building Footprint Extraction From High-Resolution R\figure_6_page3.jpeg
2025-11-14 22:39:57,237 - INFO - root - 已保存图片 7/10：./export\hybrid attention\images\MHA-Net_ Multipath Hybrid Attention Network for Building Footprint Extraction From High-Resolution R\figure_7_page5.jpeg
2025-11-14 22:39:57,303 - INFO - root - 已保存图片 8/10：./export\hybrid attention\images\MHA-Net_ Multipath Hybrid Attention Network for Building Footprint Extraction From High-Resolution R\figure_8_page6.jpeg
2025-11-14 22:39:57,341 - INFO - root - 已保存图片 9/10：./export\hybrid attention\images\MHA-Net_ Multipath Hybrid Attention Network for Building Footprint Extraction From High-Resolution R\figure_9_page11.jpeg
2025-11-14 22:39:57,374 - INFO - root - 已保存图片 10/10：./export\hybrid attention\images\MHA-Net_ Multipath Hybrid Attention Network for Building Footprint Extraction From High-Resolution R\figure_10_page11.jpeg
2025-11-14 22:39:57,392 - INFO - root - 成功添加图片 1：./export\hybrid attention\images\MHA-Net_ Multipath Hybrid Attention Network for Building Footprint Extraction From High-Resolution R\figure_1_page8.jpeg
2025-11-14 22:39:57,393 - INFO - root - 成功添加图片 2：./export\hybrid attention\images\MHA-Net_ Multipath Hybrid Attention Network for Building Footprint Extraction From High-Resolution R\figure_2_page9.jpeg
2025-11-14 22:39:57,393 - INFO - root - 成功添加图片 3：./export\hybrid attention\images\MHA-Net_ Multipath Hybrid Attention Network for Building Footprint Extraction From High-Resolution R\figure_3_page4.jpeg
2025-11-14 22:39:57,393 - INFO - root - 成功添加图片 4：./export\hybrid attention\images\MHA-Net_ Multipath Hybrid Attention Network for Building Footprint Extraction From High-Resolution R\figure_4_page3.jpeg
2025-11-14 22:39:57,394 - INFO - root - 成功添加图片 5：./export\hybrid attention\images\MHA-Net_ Multipath Hybrid Attention Network for Building Footprint Extraction From High-Resolution R\figure_5_page6.jpeg
2025-11-14 22:39:57,394 - INFO - root - 成功添加图片 6：./export\hybrid attention\images\MHA-Net_ Multipath Hybrid Attention Network for Building Footprint Extraction From High-Resolution R\figure_6_page3.jpeg
2025-11-14 22:39:57,395 - INFO - root - 成功添加图片 7：./export\hybrid attention\images\MHA-Net_ Multipath Hybrid Attention Network for Building Footprint Extraction From High-Resolution R\figure_7_page5.jpeg
2025-11-14 22:39:57,395 - INFO - root - 成功添加图片 8：./export\hybrid attention\images\MHA-Net_ Multipath Hybrid Attention Network for Building Footprint Extraction From High-Resolution R\figure_8_page6.jpeg
2025-11-14 22:39:57,395 - INFO - root - 成功添加图片 9：./export\hybrid attention\images\MHA-Net_ Multipath Hybrid Attention Network for Building Footprint Extraction From High-Resolution R\figure_9_page11.jpeg
2025-11-14 22:39:57,396 - INFO - root - 成功添加图片 10：./export\hybrid attention\images\MHA-Net_ Multipath Hybrid Attention Network for Building Footprint Extraction From High-Resolution R\figure_10_page11.jpeg
2025-11-14 22:39:57,398 - INFO - root - 论文《MHA-Net: Multipath Hybrid Attention Network for Building Footprint Extraction From High-Resolution Remote Sensing Imagery》的分析已保存到 ./export\hybrid attention\MHA-Net_ Multipath Hybrid Attention Network for Building Footprint Extraction From High-Resolution R.md
2025-11-14 22:39:57,401 - INFO - root - 正在总结论文 20/21: HADLN: Hybrid Attention-Based Deep Learning Network for Automated Arrhythmia Classification
2025-11-14 22:40:50,907 - INFO - root - LLMClient: rate limit reached, sleeping 6.5s
2025-11-14 22:46:35,591 - INFO - root - 正在提取论文图片到目录: ./export\hybrid attention\images\HADLN_ Hybrid Attention-Based Deep Learning Network for Automated Arrhythmia Classification
2025-11-14 22:46:36,439 - INFO - root - 已保存图片 1/10：./export\hybrid attention\images\HADLN_ Hybrid Attention-Based Deep Learning Network for Automated Arrhythmia Classification\figure_1_page8.jpeg
2025-11-14 22:46:36,678 - INFO - root - 已保存图片 2/10：./export\hybrid attention\images\HADLN_ Hybrid Attention-Based Deep Learning Network for Automated Arrhythmia Classification\figure_2_page4.jpeg
2025-11-14 22:46:36,751 - INFO - root - 已保存图片 3/10：./export\hybrid attention\images\HADLN_ Hybrid Attention-Based Deep Learning Network for Automated Arrhythmia Classification\figure_3_page6.jpeg
2025-11-14 22:46:36,813 - INFO - root - 已保存图片 4/10：./export\hybrid attention\images\HADLN_ Hybrid Attention-Based Deep Learning Network for Automated Arrhythmia Classification\figure_4_page7.png
2025-11-14 22:46:36,885 - INFO - root - 已保存图片 5/10：./export\hybrid attention\images\HADLN_ Hybrid Attention-Based Deep Learning Network for Automated Arrhythmia Classification\figure_5_page7.png
2025-11-14 22:46:36,974 - INFO - root - 已保存图片 6/10：./export\hybrid attention\images\HADLN_ Hybrid Attention-Based Deep Learning Network for Automated Arrhythmia Classification\figure_6_page7.png
2025-11-14 22:46:37,040 - INFO - root - 已保存图片 7/10：./export\hybrid attention\images\HADLN_ Hybrid Attention-Based Deep Learning Network for Automated Arrhythmia Classification\figure_7_page7.png
2025-11-14 22:46:37,114 - INFO - root - 已保存图片 8/10：./export\hybrid attention\images\HADLN_ Hybrid Attention-Based Deep Learning Network for Automated Arrhythmia Classification\figure_8_page7.png
2025-11-14 22:46:37,186 - INFO - root - 已保存图片 9/10：./export\hybrid attention\images\HADLN_ Hybrid Attention-Based Deep Learning Network for Automated Arrhythmia Classification\figure_9_page7.png
2025-11-14 22:46:37,200 - INFO - root - 成功添加图片 1：./export\hybrid attention\images\HADLN_ Hybrid Attention-Based Deep Learning Network for Automated Arrhythmia Classification\figure_1_page8.jpeg
2025-11-14 22:46:37,200 - INFO - root - 成功添加图片 2：./export\hybrid attention\images\HADLN_ Hybrid Attention-Based Deep Learning Network for Automated Arrhythmia Classification\figure_2_page4.jpeg
2025-11-14 22:46:37,202 - INFO - root - 成功添加图片 3：./export\hybrid attention\images\HADLN_ Hybrid Attention-Based Deep Learning Network for Automated Arrhythmia Classification\figure_3_page6.jpeg
2025-11-14 22:46:37,203 - INFO - root - 成功添加图片 4：./export\hybrid attention\images\HADLN_ Hybrid Attention-Based Deep Learning Network for Automated Arrhythmia Classification\figure_4_page7.png
2025-11-14 22:46:37,209 - INFO - root - 成功添加图片 5：./export\hybrid attention\images\HADLN_ Hybrid Attention-Based Deep Learning Network for Automated Arrhythmia Classification\figure_5_page7.png
2025-11-14 22:46:37,213 - INFO - root - 成功添加图片 6：./export\hybrid attention\images\HADLN_ Hybrid Attention-Based Deep Learning Network for Automated Arrhythmia Classification\figure_6_page7.png
2025-11-14 22:46:37,215 - INFO - root - 成功添加图片 7：./export\hybrid attention\images\HADLN_ Hybrid Attention-Based Deep Learning Network for Automated Arrhythmia Classification\figure_7_page7.png
2025-11-14 22:46:37,215 - INFO - root - 成功添加图片 8：./export\hybrid attention\images\HADLN_ Hybrid Attention-Based Deep Learning Network for Automated Arrhythmia Classification\figure_8_page7.png
2025-11-14 22:46:37,216 - INFO - root - 成功添加图片 9：./export\hybrid attention\images\HADLN_ Hybrid Attention-Based Deep Learning Network for Automated Arrhythmia Classification\figure_9_page7.png
2025-11-14 22:46:37,219 - INFO - root - 论文《HADLN: Hybrid Attention-Based Deep Learning Network for Automated Arrhythmia Classification》的分析已保存到 ./export\hybrid attention\HADLN_ Hybrid Attention-Based Deep Learning Network for Automated Arrhythmia Classification.md
2025-11-14 22:46:37,226 - INFO - root - 正在总结论文 21/21: MHANet: A hybrid attention mechanism for retinal diseases classification
2025-11-14 22:55:52,805 - INFO - root - 正在提取论文图片到目录: ./export\hybrid attention\images\MHANet_ A hybrid attention mechanism for retinal diseases classification
2025-11-14 22:55:52,990 - INFO - root - 已保存图片 1/10：./export\hybrid attention\images\MHANet_ A hybrid attention mechanism for retinal diseases classification\figure_1_page11.jpeg
2025-11-14 22:55:53,099 - INFO - root - 已保存图片 2/10：./export\hybrid attention\images\MHANet_ A hybrid attention mechanism for retinal diseases classification\figure_2_page12.jpeg
2025-11-14 22:55:53,217 - INFO - root - 已保存图片 3/10：./export\hybrid attention\images\MHANet_ A hybrid attention mechanism for retinal diseases classification\figure_3_page16.jpeg
2025-11-14 22:55:53,336 - INFO - root - 已保存图片 4/10：./export\hybrid attention\images\MHANet_ A hybrid attention mechanism for retinal diseases classification\figure_4_page15.jpeg
2025-11-14 22:55:53,460 - INFO - root - 已保存图片 5/10：./export\hybrid attention\images\MHANet_ A hybrid attention mechanism for retinal diseases classification\figure_5_page18.jpeg
2025-11-14 22:55:53,558 - INFO - root - 已保存图片 6/10：./export\hybrid attention\images\MHANet_ A hybrid attention mechanism for retinal diseases classification\figure_6_page5.jpeg
2025-11-14 22:55:53,659 - INFO - root - 已保存图片 7/10：./export\hybrid attention\images\MHANet_ A hybrid attention mechanism for retinal diseases classification\figure_7_page17.jpeg
2025-11-14 22:55:53,733 - INFO - root - 已保存图片 8/10：./export\hybrid attention\images\MHANet_ A hybrid attention mechanism for retinal diseases classification\figure_8_page14.jpeg
2025-11-14 22:55:53,795 - INFO - root - 已保存图片 9/10：./export\hybrid attention\images\MHANet_ A hybrid attention mechanism for retinal diseases classification\figure_9_page14.jpeg
2025-11-14 22:55:53,883 - INFO - root - 已保存图片 10/10：./export\hybrid attention\images\MHANet_ A hybrid attention mechanism for retinal diseases classification\figure_10_page13.jpeg
2025-11-14 22:55:53,900 - INFO - root - 成功添加图片 1：./export\hybrid attention\images\MHANet_ A hybrid attention mechanism for retinal diseases classification\figure_1_page11.jpeg
2025-11-14 22:55:53,902 - INFO - root - 成功添加图片 2：./export\hybrid attention\images\MHANet_ A hybrid attention mechanism for retinal diseases classification\figure_2_page12.jpeg
2025-11-14 22:55:53,902 - INFO - root - 成功添加图片 3：./export\hybrid attention\images\MHANet_ A hybrid attention mechanism for retinal diseases classification\figure_3_page16.jpeg
2025-11-14 22:55:53,903 - INFO - root - 成功添加图片 4：./export\hybrid attention\images\MHANet_ A hybrid attention mechanism for retinal diseases classification\figure_4_page15.jpeg
2025-11-14 22:55:53,903 - INFO - root - 成功添加图片 5：./export\hybrid attention\images\MHANet_ A hybrid attention mechanism for retinal diseases classification\figure_5_page18.jpeg
2025-11-14 22:55:53,904 - INFO - root - 成功添加图片 6：./export\hybrid attention\images\MHANet_ A hybrid attention mechanism for retinal diseases classification\figure_6_page5.jpeg
2025-11-14 22:55:53,905 - INFO - root - 成功添加图片 7：./export\hybrid attention\images\MHANet_ A hybrid attention mechanism for retinal diseases classification\figure_7_page17.jpeg
2025-11-14 22:55:53,905 - INFO - root - 成功添加图片 8：./export\hybrid attention\images\MHANet_ A hybrid attention mechanism for retinal diseases classification\figure_8_page14.jpeg
2025-11-14 22:55:53,905 - INFO - root - 成功添加图片 9：./export\hybrid attention\images\MHANet_ A hybrid attention mechanism for retinal diseases classification\figure_9_page14.jpeg
2025-11-14 22:55:53,906 - INFO - root - 成功添加图片 10：./export\hybrid attention\images\MHANet_ A hybrid attention mechanism for retinal diseases classification\figure_10_page13.jpeg
2025-11-14 22:55:53,911 - INFO - root - 论文《MHANet: A hybrid attention mechanism for retinal diseases classification》的分析已保存到 ./export\hybrid attention\MHANet_ A hybrid attention mechanism for retinal diseases classification.md
2025-11-14 22:55:53,914 - INFO - root - --- 论文总结阶段结束 ---
2025-11-14 22:55:53,915 - INFO - root - --- 开始生成 Excel 报告 (包含 21 篇论文) ---
2025-11-14 22:55:54,132 - INFO - root - 检测到已存在的 Excel 文件: export\hybrid_attention_summary.xlsx。正在追加...
2025-11-14 22:55:54,288 - INFO - root - 合并后: 22 条记录 (新增 4 条)
2025-11-14 22:55:54,461 - INFO - root - 成功保存 Excel: export\hybrid_attention_summary.xlsx
2025-11-14 22:55:54,462 - INFO - root - 已生成或更新汇总 Excel 表格: export\hybrid_attention_summary.xlsx
2025-11-14 22:55:54,465 - INFO - root - 总运行时间: 2514.14 seconds
2025-11-15 00:30:11,709 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-15 00:30:11,712 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-15 00:30:11,714 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-15 00:30:17,148 - INFO - root - LLMClientManager: 指定使用客户端: Gemini
2025-11-15 00:30:18,184 - INFO - root - GeminiClient: trying model models/gemini-2.5-flash
2025-11-15 00:30:20,494 - INFO - root - GeminiClient: initialized model gemini-2.5-flash
2025-11-15 00:30:20,495 - INFO - root - LLMClientManager: Gemini 客户端初始化成功
2025-11-15 00:30:20,495 - INFO - root - LLMClientManager: switched to Gemini client
2025-11-15 00:30:20,496 - INFO - root - 已手动切换到 LLM 客户端: Gemini
2025-11-15 00:30:20,496 - INFO - root - 使用 LLM 模型: gemini-2.5-flash
2025-11-15 00:30:20,496 - INFO - root - 可用客户端: ['Gemini']
2025-11-15 00:30:20,498 - INFO - root - === 运行配置 ===
2025-11-15 00:30:20,498 - INFO - root - 处理模式: Semantic Scholar 高引用搜索 (API)
2025-11-15 00:30:20,499 - INFO - root - 查询 (关键词): hybrid attention
2025-11-15 00:30:20,499 - INFO - root - 关键词 (用于保存): hybrid attention
2025-11-15 00:30:20,499 - INFO - root - 排序: citationCount:desc
2025-11-15 00:30:20,500 - INFO - root - 最大处理数量: 100
2025-11-15 00:30:20,501 - INFO - root - 保存图片: 是
2025-11-15 00:30:20,501 - INFO - root - 输出语言: 中文
2025-11-15 00:30:20,501 - INFO - root - 强制重新处理: 否
2025-11-15 00:30:20,502 - INFO - root - LLM 客户端: Gemini
2025-11-15 00:30:20,502 - INFO - root - ====================
2025-11-15 00:30:20,502 - INFO - root - 正在使用检索策略: semantic
2025-11-15 00:30:20,502 - INFO - root - 使用 Semantic Scholar 高引用搜索模式 (API)
2025-11-15 00:30:20,503 - INFO - root - Semantic API 查询: query=hybrid attention, limit=100, sort=citationCount:desc
2025-11-15 00:30:20,503 - INFO - root - 正在调用 Semantic Scholar API...
2025-11-15 00:30:26,776 - INFO - root - 正在调用 Semantic Scholar API...
2025-11-15 00:30:30,305 - WARNING - root - 【手动下载提示】(无PDF): An Instrument Indication Acquisition Algorithm Based on Lightweight Deep Convolutional Neural Network and Hybrid Attention Fine-Grained Features
	  URL: https://www.semanticscholar.org/paper/49f99d7a21e2ded7915676753a180983763b9a22
	  Citations: 66 | Authors: Jiaquan Shen, Ningzhong Liu, Han Sun, Deguang Li, Yongxin Zhang | Date: N/A
2025-11-15 00:30:30,309 - WARNING - root - 【手动下载提示】(无PDF): Enhancing ASD classification through hybrid attention-based learning of facial features
	  URL: https://www.semanticscholar.org/paper/22547aa4c72c7c2799932a0f451ab3f2db6d7d0f
	  Citations: 35 | Authors: Inzamam Shahzad, Saif Ur Rehman Khan, Waseem Abbas, Z. U. Abideen, Jin Liu | Date: 2024-04-21
2025-11-15 00:30:30,309 - WARNING - root - 【手动下载提示】(无PDF): Dual-Hybrid Attention Network for Specular Highlight Removal
	  URL: https://www.semanticscholar.org/paper/d56ce689cc0f8b1cf0e5f58882503a5e59ec440b
	  Citations: 33 | Authors: Xiaojiao Guo, Xuhang Chen, Shenghong Luo, Shuqiang Wang, Chi-Man Pun | Date: 2024-07-17
2025-11-15 00:30:30,311 - WARNING - root - 【手动下载提示】(无PDF): HyA-GAN: remote sensing image cloud removal based on hybrid attention generation adversarial network
	  URL: https://www.semanticscholar.org/paper/905b42f2f8d912d98fd7cbec4f7b244401176acc
	  Citations: 16 | Authors: Minghao Jin, Pengwei Wang, Yusong Li | Date: 2024-02-27
2025-11-15 00:30:30,311 - WARNING - root - 【手动下载提示】(无PDF): Radar Signal Recognition Based on CNN With a Hybrid Attention Mechanism and Skip Feature Aggregation
	  URL: https://www.semanticscholar.org/paper/dacad703c49e9434321c91220219638f871fd9d2
	  Citations: 26 | Authors: Yuanpu Guo, Haixin Sun, Hui Liu, Zhen-miao Deng | Date: N/A
2025-11-15 00:30:30,311 - WARNING - root - 【手动下载提示】(无PDF): Hybrid Attention-Aware Transformer Network Collaborative Multiscale Feature Alignment for Building Change Detection
	  URL: https://www.semanticscholar.org/paper/a0f8053046622628073ac6f051b5181a80cb7ad3
	  Citations: 28 | Authors: Chuan Xu, Zhaoyi Ye, Liye Mei, Haonan Yu, Jianchen Liu, Yaxiaer Yalikun, Shuangtong Jin, Sheng Liu, Wei Yang, Cheng Lei | Date: N/A
2025-11-15 00:30:30,312 - WARNING - root - 【手动下载提示】(无PDF): Probabilistic Multienergy Load Forecasting Based on Hybrid Attention-Enabled Transformer Network and Gaussian Process-Aided Residual Learning
	  URL: https://www.semanticscholar.org/paper/a2d81cc04f73e2898fb16e7e8c8f9cf69adadfd5
	  Citations: 16 | Authors: Pengfei Zhao, Weihao Hu, Di Cao, Zhenyuan Zhang, Yuehui Huang, Longcheng Dai, Zhe Chen | Date: 2024-06-01
2025-11-15 00:30:30,313 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\hybrid attention\Hybrid Attention Fusion Embedded in Transformer for Remote Sensing Image Semantic Segmentation.pdf
2025-11-15 00:30:30,313 - INFO - root - 成功下载 (Semantic Scholar): Hybrid Attention Fusion Embedded in Transformer for Remote Sensing Image Semantic Segmentation
2025-11-15 00:30:30,313 - WARNING - root - 【手动下载提示】(无PDF): Enhancing Time Series Product Demand Forecasting With Hybrid Attention-Based Deep Learning Models
	  URL: https://www.semanticscholar.org/paper/4848b35cbe515f8909a67a82dcb83d7c5e48f74b
	  Citations: 14 | Authors: Xuguang Zhang, Pan Li, Xu Han, Yongbin Yang, Yiwen Cui | Date: N/A
2025-11-15 00:30:30,314 - INFO - root - 正在下载: https://www.mdpi.com/2306-5354/11/3/240/pdf?version=1709132347
2025-11-15 00:30:34,996 - INFO - root - 正在下载: https://www.mdpi.com/2306-5354/11/3/240/pdf?version=1709132347
2025-11-15 00:30:39,818 - INFO - root - 正在下载: https://www.mdpi.com/2306-5354/11/3/240/pdf?version=1709132347
2025-11-15 00:30:44,490 - INFO - root - 正在下载: https://www.mdpi.com/2306-5354/11/3/240/pdf?version=1709132347
2025-11-15 00:30:53,698 - INFO - root - 正在下载: https://www.mdpi.com/2306-5354/11/3/240/pdf?version=1709132347
2025-11-15 00:30:54,705 - WARNING - root - 下载 Advancing Ocular Imaging: A Hybrid Attention Mechanism-Based U-Net Model for Precise Segmentation of Sub-Retinal Layers in OCT Images (https://www.mdpi.com/2306-5354/11/3/240/pdf?version=1709132347) 失败: 403 Client Error: Forbidden for url: https://www.mdpi.com/2306-5354/11/3/240/pdf?version=1709132347
2025-11-15 00:30:54,705 - WARNING - root - 【手动下载提示】(无PDF): A novel approach for bearings multiclass fault diagnosis fusing multiscale deep convolution and hybrid attention networks
	  URL: https://www.semanticscholar.org/paper/bf72523fe518b2e4ce4d75d125dd5220177043f6
	  Citations: 13 | Authors: Fule Li, Xinlong Zhao | Date: 2024-01-08
2025-11-15 00:30:54,705 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\hybrid attention\YOLO Algorithm With Hybrid Attention Feature Pyramid Network for Solder Joint Defect Detection.pdf
2025-11-15 00:30:54,707 - INFO - root - 成功下载 (Semantic Scholar): YOLO Algorithm With Hybrid Attention Feature Pyramid Network for Solder Joint Defect Detection
2025-11-15 00:30:54,707 - WARNING - root - 【手动下载提示】(无PDF): Drone-HAT: Hybrid Attention Transformer for Complex Action Recognition in Drone Surveillance Videos
	  URL: https://www.semanticscholar.org/paper/a76690fb96dc7d3dfd5f8fec62c3949cc7ec96f6
	  Citations: 12 | Authors: Mustaqeem Khan, Jamil Ahmad, Abdulmotaleb El-Saddik, W. Gueaieb, Giulia De Masi, Fakhri Karray | Date: 2024-06-17
2025-11-15 00:30:54,707 - WARNING - root - 【手动下载提示】(无PDF): Dense Hybrid Attention Network for Palmprint Image Super-Resolution
	  URL: https://www.semanticscholar.org/paper/75746d8d52509b24d9975d9b3b07ae91311dc7ed
	  Citations: 12 | Authors: Yao Wang, Lunke Fei, Shuping Zhao, Qi Zhu, Jie Wen, Wei Jia, Imad Rida | Date: 2024-04-01
2025-11-15 00:30:54,708 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\hybrid attention\Frequency Enhanced Hybrid Attention Network for Sequential Recommendation.pdf
2025-11-15 00:30:54,709 - INFO - root - 成功下载 (Semantic Scholar): Frequency Enhanced Hybrid Attention Network for Sequential Recommendation
2025-11-15 00:30:54,709 - WARNING - root - 【手动下载提示】(无PDF): Hybrid Attention Feature Refinement Network for Lightweight Image Super-Resolution in Metaverse Immersive Display
	  URL: https://www.semanticscholar.org/paper/c4d95a47eec1a23320d60dd95848d41e10820ee4
	  Citations: 10 | Authors: Kexin Wang, Xiaomin Yang, Gwanggil Jeon | Date: 2024-02-01
2025-11-15 00:30:54,709 - WARNING - root - 【手动下载提示】(无PDF): A Multiscale Hybrid Attention Networks Based on Multiview Images for the Diagnosis of Parkinson’s Disease
	  URL: https://www.semanticscholar.org/paper/b2af0577ee8ac56b527bd108ce57755a4a4b04e7
	  Citations: 11 | Authors: Xinchun Cui, Youshi Zhou, Chao Zhao, Jianlong Li, Xiangwei Zheng, Xiuli Li, Shixiao Shan, JinXing Liu, Xiaoli Liu | Date: N/A
2025-11-15 00:30:54,710 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\hybrid attention\HAT_ Hybrid Attention Transformer for Image Restoration.pdf
2025-11-15 00:30:54,710 - INFO - root - 成功下载 (Semantic Scholar): HAT: Hybrid Attention Transformer for Image Restoration
2025-11-15 00:30:54,711 - INFO - root - 正在下载: https://www.mdpi.com/2076-3417/14/3/1293/pdf?version=1707037901
2025-11-15 00:30:59,347 - INFO - root - 正在下载: https://www.mdpi.com/2076-3417/14/3/1293/pdf?version=1707037901
2025-11-15 00:31:05,661 - INFO - root - 正在下载: https://www.mdpi.com/2076-3417/14/3/1293/pdf?version=1707037901
2025-11-15 00:31:10,983 - INFO - root - 正在下载: https://www.mdpi.com/2076-3417/14/3/1293/pdf?version=1707037901
2025-11-15 00:31:20,029 - INFO - root - 正在下载: https://www.mdpi.com/2076-3417/14/3/1293/pdf?version=1707037901
2025-11-15 00:31:20,944 - WARNING - root - 下载 Dual Hybrid Attention Mechanism-Based U-Net for Building Segmentation in Remote Sensing Images (https://www.mdpi.com/2076-3417/14/3/1293/pdf?version=1707037901) 失败: 403 Client Error: Forbidden for url: https://www.mdpi.com/2076-3417/14/3/1293/pdf?version=1707037901
2025-11-15 00:31:20,944 - WARNING - root - 【手动下载提示】(无PDF): Abundance Matrix Correlation Analysis Network Based on Hierarchical Multihead Self-Cross-Hybrid Attention for Hyperspectral Change Detection
	  URL: https://www.semanticscholar.org/paper/6aae02a41656cecba872b29bb3d71c414a58f57b
	  Citations: 66 | Authors: Wenqian Dong, Jing Zhao, Jiahui Qu, Song Xiao, Nan Li, Shaoxiong Hou, Yunsong Li | Date: N/A
2025-11-15 00:31:20,944 - WARNING - root - 【手动下载提示】(无PDF): DenseNet model incorporating hybrid attention mechanisms and clinical features for pancreatic cystic tumor classification
	  URL: https://www.semanticscholar.org/paper/7c520ed397a3d9e6863a840325b3b0643eb15fa7
	  Citations: 7 | Authors: Hui Tian, Bo Zhang, Zhiwei Zhang, Zhenshun Xu, Liang Jin, Yun Bian, Jie Wu | Date: 2024-05-07
2025-11-15 00:31:20,944 - WARNING - root - 【手动下载提示】(无PDF): Hybrid Attention Module and Transformer Based Fuze DRFM Jamming Signal Recognition
	  URL: https://www.semanticscholar.org/paper/0fb8059c6aaf0c86c9e9a623fa1ad73d0f737c37
	  Citations: 7 | Authors: Jikai Yang, Zhiquan Bai, Zhaoxia Xian, Hongwu Xiang, Jingxin Li, Huili Hu, Jian Dai, Xinhong Hao | Date: 2024-09-01
2025-11-15 00:31:20,944 - WARNING - root - 【手动下载提示】(无PDF): HA-Net: a SAR image ship detector based on hybrid attention
	  URL: https://www.semanticscholar.org/paper/4c40b6f75ab19e1402ae88e38013a64c504c3a80
	  Citations: 6 | Authors: Shouwen Cai, Hao Meng, Ming Yuan, Fei Gao | Date: 2024-06-10
2025-11-15 00:31:20,945 - WARNING - root - 【手动下载提示】(无PDF): Towards Effective Author Name Disambiguation by Hybrid Attention
	  URL: https://www.semanticscholar.org/paper/fc2dcb9e544a0aaad3034a61eaf0563a79c65cbf
	  Citations: 6 | Authors: Qian Zhou, Wei Chen, Peng-Peng Zhao, An Liu, Jia-Jie Xu, Jianfeng Qu, Lei Zhao | Date: 2024-07-01
2025-11-15 00:31:20,945 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\hybrid attention\Multi-scale deep residual shrinkage networks with a hybrid attention mechanism for rolling bearing f.pdf
2025-11-15 00:31:20,947 - INFO - root - 成功下载 (Semantic Scholar): Multi-scale deep residual shrinkage networks with a hybrid attention mechanism for rolling bearing fault diagnosis
2025-11-15 00:31:20,947 - WARNING - root - 【手动下载提示】(无PDF): Deep Hashing Network With Hybrid Attention and Adaptive Weighting for Image Retrieval
	  URL: https://www.semanticscholar.org/paper/1c688a4da1c546ea783f5743c371732ace568498
	  Citations: 7 | Authors: Yingjiao Pei, Zhongyuan Wang, Na Li, Heling Chen, Baojin Huang, Weiping Tu | Date: N/A
2025-11-15 00:31:20,947 - WARNING - root - 【手动下载提示】(无PDF): Multi-modal bilinear fusion with hybrid attention mechanism for multi-label skin lesion classification
	  URL: https://www.semanticscholar.org/paper/2a89c443cf8b93abc7413ee32257f66fad5af684
	  Citations: 7 | Authors: Yun Wei, Lin Ji | Date: 2024-01-15
2025-11-15 00:31:20,948 - WARNING - root - 【手动下载提示】(无PDF): Actor-Hybrid-Attention-Critic for Multi-Logistic Robots Path Planning
	  URL: https://www.semanticscholar.org/paper/5260da08f9f524b8fa77a37e2884b22804a47c6a
	  Citations: 6 | Authors: Chunjie Yang, Bodi Yuan, Pengzhao Zhai | Date: 2024-06-01
2025-11-15 00:31:20,949 - INFO - root - 正在下载: https://www.mdpi.com/2306-5354/10/6/714/pdf?version=1686635187
2025-11-15 00:31:25,705 - INFO - root - 正在下载: https://www.mdpi.com/2306-5354/10/6/714/pdf?version=1686635187
2025-11-15 00:31:30,635 - INFO - root - 正在下载: https://www.mdpi.com/2306-5354/10/6/714/pdf?version=1686635187
2025-11-15 00:31:35,311 - INFO - root - 正在下载: https://www.mdpi.com/2306-5354/10/6/714/pdf?version=1686635187
2025-11-15 00:31:44,189 - INFO - root - 正在下载: https://www.mdpi.com/2306-5354/10/6/714/pdf?version=1686635187
2025-11-15 00:31:45,223 - WARNING - root - 下载 AHANet: Adaptive Hybrid Attention Network for Alzheimer’s Disease Classification Using Brain Magnetic Resonance Imaging (https://www.mdpi.com/2306-5354/10/6/714/pdf?version=1686635187) 失败: 403 Client Error: Forbidden for url: https://www.mdpi.com/2306-5354/10/6/714/pdf?version=1686635187
2025-11-15 00:31:45,224 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\hybrid attention\Physics Inspired Hybrid Attention for SAR Target Recognition.pdf
2025-11-15 00:31:45,224 - INFO - root - 成功下载 (Semantic Scholar): Physics Inspired Hybrid Attention for SAR Target Recognition
2025-11-15 00:31:45,225 - WARNING - root - 【手动下载提示】(无PDF): WHEN: A Wavelet-DTW Hybrid Attention Network for Heterogeneous Time Series Analysis
	  URL: https://www.semanticscholar.org/paper/c2e57a1926217f67a72c617d09fa12ec8e667d0e
	  Citations: 33 | Authors: Jingyuan Wang, Chen Yang, Xiaohan Jiang, Junjie Wu | Date: 2023-08-04
2025-11-15 00:31:45,225 - WARNING - root - 【手动下载提示】(无PDF): Hybrid Attention-Aware Learning Network for Facial Expression Recognition in the Wild
	  URL: https://www.semanticscholar.org/paper/a13c5a80a32c0e2dbf589d9fca9daa9b2300165d
	  Citations: 4 | Authors: Weijun Gong, Zhiyao La, Yurong Qian, Weihang Zhou | Date: 2024-01-05
2025-11-15 00:31:45,226 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\hybrid attention\Fine-grained image classification method based on hybrid attention module.pdf
2025-11-15 00:31:45,226 - INFO - root - 成功下载 (Semantic Scholar): Fine-grained image classification method based on hybrid attention module
2025-11-15 00:31:45,227 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\hybrid attention\Hybrid Attention-Based U-Shaped Network for Remote Sensing Image Super-Resolution.pdf
2025-11-15 00:31:45,227 - INFO - root - 成功下载 (Semantic Scholar): Hybrid Attention-Based U-Shaped Network for Remote Sensing Image Super-Resolution
2025-11-15 00:31:45,229 - INFO - root - 正在下载: https://www.mdpi.com/2076-3417/13/2/770/pdf?version=1673518878
2025-11-15 00:31:50,689 - INFO - root - 正在下载: https://www.mdpi.com/2076-3417/13/2/770/pdf?version=1673518878
2025-11-15 00:31:55,411 - INFO - root - 正在下载: https://www.mdpi.com/2076-3417/13/2/770/pdf?version=1673518878
2025-11-15 00:32:00,715 - INFO - root - 正在下载: https://www.mdpi.com/2076-3417/13/2/770/pdf?version=1673518878
2025-11-15 00:32:09,428 - INFO - root - 正在下载: https://www.mdpi.com/2076-3417/13/2/770/pdf?version=1673518878
2025-11-15 00:32:10,730 - WARNING - root - 下载 Smart Contract Vulnerability Detection Based on Hybrid Attention Mechanism Model (https://www.mdpi.com/2076-3417/13/2/770/pdf?version=1673518878) 失败: 403 Client Error: Forbidden for url: https://www.mdpi.com/2076-3417/13/2/770/pdf?version=1673518878
2025-11-15 00:32:10,731 - WARNING - root - 【手动下载提示】(无PDF): Mutiscale Hybrid Attention Transformer for Remote Sensing Image Pansharpening
	  URL: https://www.semanticscholar.org/paper/3b8404c8b16dd7abb86aa5f13139fa9a9c5f5ca8
	  Citations: 22 | Authors: Wengang Zhu, Jinjiang Li, Zhi-Yonga An, Zhen Hua | Date: N/A
2025-11-15 00:32:10,732 - WARNING - root - 【手动下载提示】(无PDF): Multimodal emotion recognition based on audio and text by using hybrid attention networks
	  URL: https://www.semanticscholar.org/paper/5a35815f9d5f7ed5697b4638b1158f42837051c1
	  Citations: 42 | Authors: Shiqing Zhang, Yijiao Yang, Ruixin Liu, Chen Chen, Xin Tao, Wenping Guo, Yicheng Xu, Xiaoming Zhao | Date: N/A
2025-11-15 00:32:10,733 - WARNING - root - 【手动下载提示】(无PDF): A Novel Approach for Surface Integrity Monitoring in High-Energy Nanosecond-Pulse Laser Shock Peening: Acoustic Emission and Hybrid-Attention CNN
	  URL: https://www.semanticscholar.org/paper/9608f2b16d1d302f7507505b51a5be96fdf0b542
	  Citations: 19 | Authors: Zhifen Zhang, Rui Qin, Gengze Li, Z. Du, G. Wen, Weifeng He | Date: 2023-03-01
2025-11-15 00:32:10,733 - WARNING - root - 【手动下载提示】(无PDF): Intention-convolution and hybrid-attention network for vehicle trajectory prediction
	  URL: https://www.semanticscholar.org/paper/3bcb4d2994896053a5a8da42d09eb621d3b2b221
	  Citations: 34 | Authors: Chao Li, Zhanwen Liu, Shang Lin, Yang Wang, Xiangmo Zhao | Date: 2023-09-01
2025-11-15 00:32:10,734 - WARNING - root - 【手动下载提示】(无PDF): Hybrid Attention Network for Epileptic EEG Classification
	  URL: https://www.semanticscholar.org/paper/f282fa85469cc789c2f3b62e57e3446a49528afa
	  Citations: 17 | Authors: Yanna Zhao, Jiatong He, Fenglin Zhu, Tiantian Xiao, Yongfeng Zhang, Ziwei Wang, Fangzhou Xu, Yi Niu | Date: 2023-03-31
2025-11-15 00:32:10,734 - INFO - root - 正在下载: https://www.mdpi.com/1424-8220/23/13/6052/pdf?version=1688107163
2025-11-15 00:32:15,573 - INFO - root - 正在下载: https://www.mdpi.com/1424-8220/23/13/6052/pdf?version=1688107163
2025-11-15 00:32:20,618 - INFO - root - 正在下载: https://www.mdpi.com/1424-8220/23/13/6052/pdf?version=1688107163
2025-11-15 00:32:25,392 - INFO - root - 正在下载: https://www.mdpi.com/1424-8220/23/13/6052/pdf?version=1688107163
2025-11-15 00:32:34,471 - INFO - root - 正在下载: https://www.mdpi.com/1424-8220/23/13/6052/pdf?version=1688107163
2025-11-15 00:32:35,270 - WARNING - root - 下载 PHAM-YOLO: A Parallel Hybrid Attention Mechanism Network for Defect Detection of Meter in Substation (https://www.mdpi.com/1424-8220/23/13/6052/pdf?version=1688107163) 失败: 403 Client Error: Forbidden for url: https://www.mdpi.com/1424-8220/23/13/6052/pdf?version=1688107163
2025-11-15 00:32:35,272 - INFO - root - 正在下载: https://www.mdpi.com/1424-8220/23/15/6982/pdf?version=1691312141
2025-11-15 00:32:40,093 - INFO - root - 正在下载: https://www.mdpi.com/1424-8220/23/15/6982/pdf?version=1691312141
2025-11-15 00:32:44,869 - INFO - root - 正在下载: https://www.mdpi.com/1424-8220/23/15/6982/pdf?version=1691312141
2025-11-15 00:32:49,585 - INFO - root - 正在下载: https://www.mdpi.com/1424-8220/23/15/6982/pdf?version=1691312141
2025-11-15 00:32:58,656 - INFO - root - 正在下载: https://www.mdpi.com/1424-8220/23/15/6982/pdf?version=1691312141
2025-11-15 00:32:59,435 - WARNING - root - 下载 Defect Detection in Steel Using a Hybrid Attention Network (https://www.mdpi.com/1424-8220/23/15/6982/pdf?version=1691312141) 失败: 403 Client Error: Forbidden for url: https://www.mdpi.com/1424-8220/23/15/6982/pdf?version=1691312141
2025-11-15 00:32:59,435 - WARNING - root - 【手动下载提示】(无PDF): Hybrid Attention and Motion Constraint for Anomaly Detection in Crowded Scenes
	  URL: https://www.semanticscholar.org/paper/a5e107a1112c88294f44989f6622433fb402fb31
	  Citations: 30 | Authors: Xinfeng Zhang, Jinpeng Fang, Baoqing Yang, Shuhan Chen, Bin Li | Date: 2023-05-01
2025-11-15 00:32:59,436 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\hybrid attention\Hybrid Attention-Based Prototypical Networks for Noisy Few-Shot Relation Classification.pdf
2025-11-15 00:32:59,437 - INFO - root - 成功下载 (Semantic Scholar): Hybrid Attention-Based Prototypical Networks for Noisy Few-Shot Relation Classification
2025-11-15 00:32:59,441 - INFO - root - 正在下载: https://www.mdpi.com/2072-4292/15/2/526/pdf?version=1673863751
2025-11-15 00:33:06,044 - INFO - root - 正在下载: https://www.mdpi.com/2072-4292/15/2/526/pdf?version=1673863751
2025-11-15 00:33:10,819 - INFO - root - 正在下载: https://www.mdpi.com/2072-4292/15/2/526/pdf?version=1673863751
2025-11-15 00:33:15,648 - INFO - root - 正在下载: https://www.mdpi.com/2072-4292/15/2/526/pdf?version=1673863751
2025-11-15 00:33:24,425 - INFO - root - 正在下载: https://www.mdpi.com/2072-4292/15/2/526/pdf?version=1673863751
2025-11-15 00:33:25,243 - WARNING - root - 下载 Hybrid Attention-Based Encoder-Decoder Fully Convolutional Network for PolSAR Image Classification (https://www.mdpi.com/2072-4292/15/2/526/pdf?version=1673863751) 失败: 403 Client Error: Forbidden for url: https://www.mdpi.com/2072-4292/15/2/526/pdf?version=1673863751
2025-11-15 00:33:25,243 - WARNING - root - 【手动下载提示】(无PDF): Hybrid Attention Compression Network With Light Graph Attention Module for Remote Sensing Images
	  URL: https://www.semanticscholar.org/paper/11ab89aa34dae52624533795ebbe1ce707a66fd4
	  Citations: 9 | Authors: Tianpeng Pan, Lili Zhang, Yingchao Song, Yuxuan Liu | Date: N/A
2025-11-15 00:33:25,244 - WARNING - root - 【手动下载提示】(无PDF): An Adaptive Hybrid Attention Based Convolutional Neural Net for Intelligent Transportation Object Recognition
	  URL: https://www.semanticscholar.org/paper/269fed3c9a541a4073cde6e205878c2618b2f973
	  Citations: 11 | Authors: Qili Chen, Guangyuan Pan, Lin Zhao, Junfang Fan, Wenbai Chen, A. Zhang | Date: 2023-07-01
2025-11-15 00:33:25,244 - WARNING - root - 【手动下载提示】(无PDF): HEU-Net: hybrid attention residual block-based network with external skip connections for metal corrosion semantic segmentation
	  URL: https://www.semanticscholar.org/paper/80e0948897bc53edf4eba2e31e443010d8a2e19a
	  Citations: 9 | Authors: Tianchen Zhu, Shiqiang Zhu, Tao Zheng, Hongliang Ding, Wei Song, Cunjun Li | Date: 2023-06-22
2025-11-15 00:33:25,245 - WARNING - root - 【手动下载提示】(无PDF): Face-Periocular Cross-Identification via Contrastive Hybrid Attention Vision Transformer
	  URL: https://www.semanticscholar.org/paper/5765cc795e642e1a8e834d6af93cda3ac65a753a
	  Citations: 6 | Authors: Leslie Ching Ow Tiong, D. Sigmund, A. Teoh | Date: N/A
2025-11-15 00:33:25,245 - WARNING - root - 【手动下载提示】(无PDF): Image Super-Resolution with Multi-scale Hybrid Attention
	  URL: https://www.semanticscholar.org/paper/09691760c37f27ddf4d4b7908a348b20b110db6d
	  Citations: 0 | Authors: Ningzhi Wang, Hanyi Shi, Wenna Ruan, Lingbin Zeng | Date: N/A
2025-11-15 00:33:25,246 - INFO - root - 正在下载: https://www.mdpi.com/1424-8220/23/19/8285/pdf?version=1696663695
2025-11-15 00:33:30,071 - INFO - root - 正在下载: https://www.mdpi.com/1424-8220/23/19/8285/pdf?version=1696663695
2025-11-15 00:33:34,835 - INFO - root - 正在下载: https://www.mdpi.com/1424-8220/23/19/8285/pdf?version=1696663695
2025-11-15 00:33:39,737 - INFO - root - 正在下载: https://www.mdpi.com/1424-8220/23/19/8285/pdf?version=1696663695
2025-11-15 00:33:48,696 - INFO - root - 正在下载: https://www.mdpi.com/1424-8220/23/19/8285/pdf?version=1696663695
2025-11-15 00:33:49,766 - WARNING - root - 下载 A Fast and Robust Lane Detection via Online Re-Parameterization and Hybrid Attention (https://www.mdpi.com/1424-8220/23/19/8285/pdf?version=1696663695) 失败: 403 Client Error: Forbidden for url: https://www.mdpi.com/1424-8220/23/19/8285/pdf?version=1696663695
2025-11-15 00:33:49,767 - WARNING - root - 【手动下载提示】(无PDF): Multi-level wavelet network based on CNN-Transformer hybrid attention for single image deraining
	  URL: https://www.semanticscholar.org/paper/97c485dbb41b68c193decdec5a4618ce3f5b4ee2
	  Citations: 8 | Authors: B. Liu, Siyan Fang | Date: 2023-08-09
2025-11-15 00:33:49,768 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\hybrid attention\Dual-view Correlation Hybrid Attention Network for Robust Holistic Mammogram Classification.pdf
2025-11-15 00:33:49,768 - INFO - root - 成功下载 (Semantic Scholar): Dual-view Correlation Hybrid Attention Network for Robust Holistic Mammogram Classification
2025-11-15 00:33:49,769 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\hybrid attention\Stacked Hybrid-Attention and Group Collaborative Learning for Unbiased Scene Graph Generation.pdf
2025-11-15 00:33:49,770 - INFO - root - 成功下载 (Semantic Scholar): Stacked Hybrid-Attention and Group Collaborative Learning for Unbiased Scene Graph Generation
2025-11-15 00:33:49,770 - INFO - root - 正在下载: https://onlinelibrary.wiley.com/doi/pdfdirect/10.1049/ipr2.12934
2025-11-15 00:33:54,509 - INFO - root - 正在下载: https://onlinelibrary.wiley.com/doi/pdfdirect/10.1049/ipr2.12934
2025-11-15 00:33:59,490 - INFO - root - 正在下载: https://onlinelibrary.wiley.com/doi/pdfdirect/10.1049/ipr2.12934
2025-11-15 00:34:04,307 - INFO - root - 正在下载: https://onlinelibrary.wiley.com/doi/pdfdirect/10.1049/ipr2.12934
2025-11-15 00:34:13,966 - INFO - root - 正在下载: https://onlinelibrary.wiley.com/doi/pdfdirect/10.1049/ipr2.12934
2025-11-15 00:34:15,483 - WARNING - root - 下载 Hybrid attention mechanism of feature fusion for medical image segmentation (https://onlinelibrary.wiley.com/doi/pdfdirect/10.1049/ipr2.12934) 失败: 403 Client Error: Forbidden for url: https://onlinelibrary.wiley.com/doi/pdfdirect/10.1049/ipr2.12934
2025-11-15 00:34:15,484 - INFO - root - 正在下载: https://www.mdpi.com/2073-8994/15/10/1947/pdf?version=1697811500
2025-11-15 00:34:20,781 - INFO - root - 正在下载: https://www.mdpi.com/2073-8994/15/10/1947/pdf?version=1697811500
2025-11-15 00:34:25,566 - INFO - root - 正在下载: https://www.mdpi.com/2073-8994/15/10/1947/pdf?version=1697811500
2025-11-15 00:34:31,317 - INFO - root - 正在下载: https://www.mdpi.com/2073-8994/15/10/1947/pdf?version=1697811500
2025-11-15 00:34:42,004 - INFO - root - 正在下载: https://www.mdpi.com/2073-8994/15/10/1947/pdf?version=1697811500
2025-11-15 00:34:43,125 - WARNING - root - 下载 Transformer with Hybrid Attention Mechanism for Stereo Endoscopic Video Super Resolution (https://www.mdpi.com/2073-8994/15/10/1947/pdf?version=1697811500) 失败: 403 Client Error: Forbidden for url: https://www.mdpi.com/2073-8994/15/10/1947/pdf?version=1697811500
2025-11-15 00:34:43,127 - WARNING - root - 【手动下载提示】(无PDF): HHTrack: Hyperspectral Object Tracking Based on Hybrid Attention
	  URL: https://www.semanticscholar.org/paper/c1c5c93f3bd9b99ec5fe55b4c2b5bc29abf4b12a
	  Citations: 1 | Authors: Yuedong Tan, Wenfang Sun, Jieran Yuan, Wenwang Du, Zhe Wang, Nan Mao, Beibei Song | Date: 2023-08-14
2025-11-15 00:34:43,129 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\hybrid attention\Hybridformer_ Improving Squeezeformer with Hybrid Attention and NSR Mechanism.pdf
2025-11-15 00:34:43,129 - INFO - root - 成功下载 (Semantic Scholar): Hybridformer: Improving Squeezeformer with Hybrid Attention and NSR Mechanism
2025-11-15 00:34:43,130 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\hybrid attention\HAC-Net_ A Hybrid Attention-Based Convolutional Neural Network for Highly Accurate Protein-Ligand Bi.pdf
2025-11-15 00:34:43,131 - INFO - root - 成功下载 (Semantic Scholar): HAC-Net: A Hybrid Attention-Based Convolutional Neural Network for Highly Accurate Protein-Ligand Binding Affinity Prediction
2025-11-15 00:34:43,131 - WARNING - root - 【手动下载提示】(无PDF): A hybrid-attention semantic segmentation network for remote sensing interpretation in land-use surveillance
	  URL: https://www.semanticscholar.org/paper/4905315ab99ea19871a65e52be8c8c51624748aa
	  Citations: 49 | Authors: Ning Lv, Zenghui Zhang, Cong Li, Jiaxuan Deng, Tao Su, Chen Chen, Yang Zhou | Date: 2022-02-07
2025-11-15 00:34:43,156 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\hybrid attention\A Hybrid Attention Mechanism for Weakly-Supervised Temporal Action Localization.pdf
2025-11-15 00:34:43,156 - INFO - root - 成功下载 (Semantic Scholar): A Hybrid Attention Mechanism for Weakly-Supervised Temporal Action Localization
2025-11-15 00:34:43,163 - WARNING - root - 【手动下载提示】(无PDF): A hybrid attention-based deep learning approach for wind power prediction
	  URL: https://www.semanticscholar.org/paper/9d591544b9f179d93ad85720e8382e8e1c04c916
	  Citations: 128 | Authors: Zhengjing Ma, Gang Mei | Date: 2022-10-01
2025-11-15 00:34:43,169 - WARNING - root - 【手动下载提示】(无PDF): ColorFormer: Image Colorization via Color Memory Assisted Hybrid-Attention Transformer
	  URL: https://www.semanticscholar.org/paper/33618e85644d6705fd74086c13ee3b7e2a2a466a
	  Citations: 28 | Authors: Xiaozhong Ji, Boyuan Jiang, Donghao Luo, Guangpin Tao, Wenqing Chu, Zhifeng Xie, Chengjie Wang, Ying Tai | Date: N/A
2025-11-15 00:34:43,169 - WARNING - root - 【手动下载提示】(无PDF): HAM: Hybrid attention module in deep convolutional neural networks for image classification
	  URL: https://www.semanticscholar.org/paper/2cfa77f582ee36f2d1fe8869505aa5a71a5f99f3
	  Citations: 92 | Authors: Guoqiang Li, Qianhao Fang, Li Zha, Xin Gao, Nenggan Zheng | Date: 2022-05-01
2025-11-15 00:34:43,170 - WARNING - root - 【手动下载提示】(无PDF): State of health estimation for lithium-ion batteries based on hybrid attention and deep learning
	  URL: https://www.semanticscholar.org/paper/f91dcfd8df66da9bf3649c176869f980b9205115
	  Citations: 91 | Authors: Hongqian Zhao, Zheng Chen, Xing Shu, Jiangwei Shen, Zhenzhen Lei, Yuanjian Zhang | Date: 2022-12-01
2025-11-15 00:34:43,171 - INFO - root - 正在下载: https://downloads.hindawi.com/journals/cin/2022/4189500.pdf
2025-11-15 00:34:47,955 - INFO - root - 正在下载: https://downloads.hindawi.com/journals/cin/2022/4189500.pdf
2025-11-15 00:34:52,690 - INFO - root - 正在下载: https://downloads.hindawi.com/journals/cin/2022/4189500.pdf
2025-11-15 00:34:57,494 - INFO - root - 正在下载: https://downloads.hindawi.com/journals/cin/2022/4189500.pdf
2025-11-15 00:35:06,228 - INFO - root - 正在下载: https://downloads.hindawi.com/journals/cin/2022/4189500.pdf
2025-11-15 00:35:08,461 - WARNING - root - 下载 Aircraft Image Recognition Network Based on Hybrid Attention Mechanism (https://downloads.hindawi.com/journals/cin/2022/4189500.pdf) 失败: 403 Client Error: Forbidden for url: https://downloads.hindawi.com/journals/cin/2022/4189500.pdf
2025-11-15 00:35:08,462 - WARNING - root - 【手动下载提示】(无PDF): Hybrid attention based vehicle trajectory prediction
	  URL: https://www.semanticscholar.org/paper/a2778f12363b79e0a604ddd21a878f3abb0acced
	  Citations: 6 | Authors: Lingyang Wang, Wenping Jiang | Date: 2023-04-06
2025-11-15 00:35:08,462 - WARNING - root - 【手动下载提示】(无PDF): A Hybrid Attention-Based Paralleled Deep Learning model for tool wear prediction
	  URL: https://www.semanticscholar.org/paper/27da7ffd2319f8a2f47eec128894be31f88fc35c
	  Citations: 87 | Authors: Jian Duan, Xi Zhang, Tielin Shi | Date: 2022-08-01
2025-11-15 00:35:08,465 - INFO - root - 正在下载: https://ieeexplore.ieee.org/ielx7/6287639/9668973/09693977.pdf
2025-11-15 00:35:13,444 - INFO - root - 正在下载: https://ieeexplore.ieee.org/ielx7/6287639/9668973/09693977.pdf
2025-11-15 00:35:18,628 - INFO - root - 正在下载: https://ieeexplore.ieee.org/ielx7/6287639/9668973/09693977.pdf
2025-11-15 00:35:23,911 - INFO - root - 正在下载: https://ieeexplore.ieee.org/ielx7/6287639/9668973/09693977.pdf
2025-11-15 00:35:32,901 - INFO - root - 正在下载: https://ieeexplore.ieee.org/ielx7/6287639/9668973/09693977.pdf
2025-11-15 00:35:34,450 - WARNING - root - 下载 HANN: Hybrid Attention Neural Network for Detecting Covid-19 Related Rumors (https://ieeexplore.ieee.org/ielx7/6287639/9668973/09693977.pdf) 失败: 418 Client Error: Unknown Code for url: https://ieeexplore.ieee.org/ielx7/6287639/9668973/09693977.pdf
2025-11-15 00:35:34,451 - INFO - root - 正在下载: https://www.mdpi.com/1424-8220/22/10/3701/pdf?version=1652360619
2025-11-15 00:35:39,355 - INFO - root - 正在下载: https://www.mdpi.com/1424-8220/22/10/3701/pdf?version=1652360619
2025-11-15 00:35:44,047 - INFO - root - 正在下载: https://www.mdpi.com/1424-8220/22/10/3701/pdf?version=1652360619
2025-11-15 00:35:48,760 - INFO - root - 正在下载: https://www.mdpi.com/1424-8220/22/10/3701/pdf?version=1652360619
2025-11-15 00:35:57,731 - INFO - root - 正在下载: https://www.mdpi.com/1424-8220/22/10/3701/pdf?version=1652360619
2025-11-15 00:35:58,533 - WARNING - root - 下载 An Anti-UAV Long-Term Tracking Method with Hybrid Attention Mechanism and Hierarchical Discriminator (https://www.mdpi.com/1424-8220/22/10/3701/pdf?version=1652360619) 失败: 403 Client Error: Forbidden for url: https://www.mdpi.com/1424-8220/22/10/3701/pdf?version=1652360619
2025-11-15 00:35:58,534 - WARNING - root - 【手动下载提示】(无PDF): Hybrid Attention-Based Prototypical Networks for Few-Shot Sound Classification
	  URL: https://www.semanticscholar.org/paper/e0ddd13d74fe020c8e63eb2ef5a2daa687565953
	  Citations: 15 | Authors: You Wang, D.V. Anderson | Date: 2022-05-23
2025-11-15 00:35:58,535 - WARNING - root - 【手动下载提示】(无PDF): A Hybrid Attention-Based Deep Neural Network for Simultaneous Multi-Sensor Pruning and Human Activity Recognition
	  URL: https://www.semanticscholar.org/paper/06f82dcfa03d18408410b03b4203fff9bbeceeac
	  Citations: 21 | Authors: Yu Zhou, Zhuo Yang, Xiao Zhang, Yufan Wang | Date: 2022-12-15
2025-11-15 00:35:58,535 - WARNING - root - 【手动下载提示】(无PDF): End-to-End Multilevel Hybrid Attention Framework for Hyperspectral Image Classification
	  URL: https://www.semanticscholar.org/paper/6cbd2101b7faff37d402cc8574c95477af70f3aa
	  Citations: 19 | Authors: Jianhong Xiang, Chen Wei, Minhui Wang, Long Teng | Date: N/A
2025-11-15 00:35:58,536 - WARNING - root - 【手动下载提示】(无PDF): Parallel Deep Learning Algorithms With Hybrid Attention Mechanism for Image Segmentation of Lung Tumors
	  URL: https://www.semanticscholar.org/paper/05c67b073bde463686697eb553576958c8403a60
	  Citations: 88 | Authors: Hexuan Hu, Qingqiu Li, Yun-feng Zhao, Ye Zhang | Date: 2021-04-01
2025-11-15 00:35:58,536 - WARNING - root - 【手动下载提示】(无PDF): Hybrid attention network for semantic segmentation
	  URL: https://www.semanticscholar.org/paper/ee93962e142d4e7fa0b84f5d59970cb30a0b8960
	  Citations: 0 | Authors: Yin Yang, Juan Yang, Ronggui Wang | Date: 2023-10-19
2025-11-15 00:35:58,536 - WARNING - root - 【手动下载提示】(无PDF): A hybrid attention semantic segmentation network for unstructured terrain on Mars
	  URL: https://www.semanticscholar.org/paper/7b71919c1e0adafaa102cf03849b6c21841c8e54
	  Citations: 53 | Authors: Haiqiang Liu, Meibao Yao, Xueming Xiao, Hutao Cui | Date: 2022-08-01
2025-11-15 00:35:58,537 - INFO - root - 正在下载: https://downloads.hindawi.com/journals/wcmc/2022/5441366.pdf
2025-11-15 00:36:03,280 - INFO - root - 正在下载: https://downloads.hindawi.com/journals/wcmc/2022/5441366.pdf
2025-11-15 00:36:08,070 - INFO - root - 正在下载: https://downloads.hindawi.com/journals/wcmc/2022/5441366.pdf
2025-11-15 00:36:16,809 - INFO - root - 正在下载: https://downloads.hindawi.com/journals/wcmc/2022/5441366.pdf
2025-11-15 00:36:25,632 - INFO - root - 正在下载: https://downloads.hindawi.com/journals/wcmc/2022/5441366.pdf
2025-11-15 00:36:26,301 - WARNING - root - 下载 Classification of Diabetic Retinopathy Based on Multiscale Hybrid Attention Mechanism and Residual Algorithm (https://downloads.hindawi.com/journals/wcmc/2022/5441366.pdf) 失败: 403 Client Error: Forbidden for url: https://downloads.hindawi.com/journals/wcmc/2022/5441366.pdf
2025-11-15 00:36:26,302 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\hybrid attention\RHA-Net_ An Encoder-Decoder Network with Residual Blocks and Hybrid Attention Mechanisms for Pavemen.pdf
2025-11-15 00:36:26,303 - INFO - root - 成功下载 (Semantic Scholar): RHA-Net: An Encoder-Decoder Network with Residual Blocks and Hybrid Attention Mechanisms for Pavement Crack Segmentation
2025-11-15 00:36:26,304 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\hybrid attention\HHTrack_ Hyperspectral Object Tracking Using Hybrid Attention.pdf
2025-11-15 00:36:26,304 - INFO - root - 成功下载 (Semantic Scholar): HHTrack: Hyperspectral Object Tracking Using Hybrid Attention
2025-11-15 00:36:26,305 - WARNING - root - 【手动下载提示】(无PDF): Hybrid attention network for image captioning
	  URL: https://www.semanticscholar.org/paper/45acf57fd885b60d858dc6c49da4ff536a901d67
	  Citations: 22 | Authors: Wenhui Jiang, Qin Li, K. Zhan, Yuming Fang, Fei Shen | Date: 2022-05-01
2025-11-15 00:36:26,306 - INFO - root - 正在下载: https://downloads.hindawi.com/journals/wcmc/2022/3301718.pdf
2025-11-15 00:36:31,874 - INFO - root - 正在下载: https://downloads.hindawi.com/journals/wcmc/2022/3301718.pdf
2025-11-15 00:36:36,778 - INFO - root - 正在下载: https://downloads.hindawi.com/journals/wcmc/2022/3301718.pdf
2025-11-15 00:36:41,533 - INFO - root - 正在下载: https://downloads.hindawi.com/journals/wcmc/2022/3301718.pdf
2025-11-15 00:36:50,456 - INFO - root - 正在下载: https://downloads.hindawi.com/journals/wcmc/2022/3301718.pdf
2025-11-15 00:36:51,247 - WARNING - root - 下载 Malicious Code Classification Method Based on Deep Residual Network and Hybrid Attention Mechanism for Edge Security (https://downloads.hindawi.com/journals/wcmc/2022/3301718.pdf) 失败: 403 Client Error: Forbidden for url: https://downloads.hindawi.com/journals/wcmc/2022/3301718.pdf
2025-11-15 00:36:51,248 - WARNING - root - 【手动下载提示】(无PDF): Generative adversarial network with hybrid attention and compromised normalization for multi-scene image conversion
	  URL: https://www.semanticscholar.org/paper/1defd0b952f393b189dc61bc421c8ae7dd4df3c2
	  Citations: 11 | Authors: Jinsheng Xiao, Shuhao Zhang, Yuntao Yao, Zhongyuan Wang, Yongqin Zhang, Yuan-fang Wang | Date: 2022-01-29
2025-11-15 00:36:51,250 - INFO - root - 正在下载: https://www.mdpi.com/2079-9292/11/17/2709/pdf?version=1661780513
2025-11-15 00:36:56,117 - INFO - root - 正在下载: https://www.mdpi.com/2079-9292/11/17/2709/pdf?version=1661780513
2025-11-15 00:37:01,049 - INFO - root - 正在下载: https://www.mdpi.com/2079-9292/11/17/2709/pdf?version=1661780513
2025-11-15 00:37:05,858 - INFO - root - 正在下载: https://www.mdpi.com/2079-9292/11/17/2709/pdf?version=1661780513
2025-11-15 00:37:14,732 - INFO - root - 正在下载: https://www.mdpi.com/2079-9292/11/17/2709/pdf?version=1661780513
2025-11-15 00:37:15,494 - WARNING - root - 下载 Occluded Vehicle Detection via Multi-Scale Hybrid Attention Mechanism in the Road Scene (https://www.mdpi.com/2079-9292/11/17/2709/pdf?version=1661780513) 失败: 403 Client Error: Forbidden for url: https://www.mdpi.com/2079-9292/11/17/2709/pdf?version=1661780513
2025-11-15 00:37:15,496 - INFO - root - 正在下载: https://www.mdpi.com/2079-9292/11/22/3787/pdf?version=1669096288
2025-11-15 00:37:20,319 - INFO - root - 正在下载: https://www.mdpi.com/2079-9292/11/22/3787/pdf?version=1669096288
2025-11-15 00:37:25,168 - INFO - root - 正在下载: https://www.mdpi.com/2079-9292/11/22/3787/pdf?version=1669096288
2025-11-15 00:37:29,967 - INFO - root - 正在下载: https://www.mdpi.com/2079-9292/11/22/3787/pdf?version=1669096288
2025-11-15 00:37:39,168 - INFO - root - 正在下载: https://www.mdpi.com/2079-9292/11/22/3787/pdf?version=1669096288
2025-11-15 00:37:40,105 - WARNING - root - 下载 HA-Unet: A Modified Unet Based on Hybrid Attention for Urban Water Extraction in SAR Images (https://www.mdpi.com/2079-9292/11/22/3787/pdf?version=1669096288) 失败: 403 Client Error: Forbidden for url: https://www.mdpi.com/2079-9292/11/22/3787/pdf?version=1669096288
2025-11-15 00:37:40,107 - INFO - root - 正在下载: https://www.mdpi.com/2227-7390/10/11/1915/pdf?version=1654510435
2025-11-15 00:37:45,060 - INFO - root - 正在下载: https://www.mdpi.com/2227-7390/10/11/1915/pdf?version=1654510435
2025-11-15 00:37:49,838 - INFO - root - 正在下载: https://www.mdpi.com/2227-7390/10/11/1915/pdf?version=1654510435
2025-11-15 00:37:54,587 - INFO - root - 正在下载: https://www.mdpi.com/2227-7390/10/11/1915/pdf?version=1654510435
2025-11-15 00:38:03,297 - INFO - root - 正在下载: https://www.mdpi.com/2227-7390/10/11/1915/pdf?version=1654510435
2025-11-15 00:38:04,046 - WARNING - root - 下载 HA-RoadFormer: Hybrid Attention Transformer with Multi-Branch for Large-Scale High-Resolution Dense Road Segmentation (https://www.mdpi.com/2227-7390/10/11/1915/pdf?version=1654510435) 失败: 403 Client Error: Forbidden for url: https://www.mdpi.com/2227-7390/10/11/1915/pdf?version=1654510435
2025-11-15 00:38:04,047 - WARNING - root - 【手动下载提示】(无PDF): A hybrid attention improved ResNet based fault diagnosis method of wind turbines gearbox
	  URL: https://www.semanticscholar.org/paper/c71d11b59d8a85d413af1dab9337e39e52910774
	  Citations: 161 | Authors: Kai Zhang, B. Tang, Lei Deng, Xiaoli Liu | Date: 2021-05-03
2025-11-15 00:38:04,048 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\hybrid attention\RAIN_ Reinforced Hybrid Attention Inference Network for Motion Forecasting.pdf
2025-11-15 00:38:04,048 - INFO - root - 成功下载 (Semantic Scholar): RAIN: Reinforced Hybrid Attention Inference Network for Motion Forecasting
2025-11-15 00:38:04,049 - WARNING - root - 【手动下载提示】(无PDF): A hybrid attention mechanism for blind automatic modulation classification
	  URL: https://www.semanticscholar.org/paper/f226e86f57129dfa31db5c69c14163b9d3904988
	  Citations: 8 | Authors: Fan Jia, Yueyi Yang, Junyi Zhang, Yong Yang | Date: 2022-04-05
2025-11-15 00:38:04,049 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\hybrid attention\MHA-Net_ Multipath Hybrid Attention Network for Building Footprint Extraction From High-Resolution R.pdf
2025-11-15 00:38:04,050 - INFO - root - 成功下载 (Semantic Scholar): MHA-Net: Multipath Hybrid Attention Network for Building Footprint Extraction From High-Resolution Remote Sensing Imagery
2025-11-15 00:38:04,050 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\hybrid attention\A Hybrid-Attention Nested UNet for Nuclear Segmentation in Histopathological Images.pdf
2025-11-15 00:38:04,052 - INFO - root - 成功下载 (Semantic Scholar): A Hybrid-Attention Nested UNet for Nuclear Segmentation in Histopathological Images
2025-11-15 00:38:04,053 - INFO - root - 正在下载: https://ieeexplore.ieee.org/ielx7/6287639/6514899/09837031.pdf
2025-11-15 00:38:09,142 - INFO - root - 正在下载: https://ieeexplore.ieee.org/ielx7/6287639/6514899/09837031.pdf
2025-11-15 00:38:14,164 - INFO - root - 正在下载: https://ieeexplore.ieee.org/ielx7/6287639/6514899/09837031.pdf
2025-11-15 00:38:20,220 - INFO - root - 正在下载: https://ieeexplore.ieee.org/ielx7/6287639/6514899/09837031.pdf
2025-11-15 00:38:29,122 - INFO - root - 正在下载: https://ieeexplore.ieee.org/ielx7/6287639/6514899/09837031.pdf
2025-11-15 00:38:30,072 - WARNING - root - 下载 Dual-Path Hybrid Attention Network for Monaural Speech Separation (https://ieeexplore.ieee.org/ielx7/6287639/6514899/09837031.pdf) 失败: 418 Client Error: Unknown Code for url: https://ieeexplore.ieee.org/ielx7/6287639/6514899/09837031.pdf
2025-11-15 00:38:30,072 - WARNING - root - 【手动下载提示】(无PDF): Neural machine translation for Indian language pair using hybrid attention mechanism
	  URL: https://www.semanticscholar.org/paper/3479ff37a0bb3858b1761a871b81f4ca3dd26454
	  Citations: 7 | Authors: Basab Nath, Sunita Sarkar, Surajeet Das, Somnath Mukhopadhyay | Date: 2022-02-01
2025-11-15 00:38:30,072 - WARNING - root - 【手动下载提示】(无PDF): Hybrid attention mechanism for liver tumor segmentation in CT images
	  URL: https://www.semanticscholar.org/paper/9410e41c65c34be9a745cda06f430de0d53084d9
	  Citations: 6 | Authors: Ming Gong, Baixiang Zhao, J. Soraghan, G. D. Caterina, D. Grose | Date: 2022-09-11
2025-11-15 00:38:30,074 - WARNING - root - 【手动下载提示】(无PDF): Hybrid Attention Fusion Segmentation Network for Diffuse Large B-cell Lymphoma in PET-CT
	  URL: https://www.semanticscholar.org/paper/80c16017651e0fc33b4bb10e2686a582ae119459
	  Citations: 6 | Authors: Shun Chen, Ang Li, Jianxin Chen, Xuguang Zhang, Chong Jiang, Jingyan Xu | Date: 2022-11-01
2025-11-15 00:38:30,074 - WARNING - root - 【手动下载提示】(无PDF): Two-stream LSTM Network with Hybrid Attention for Vehicle Trajectory Prediction
	  URL: https://www.semanticscholar.org/paper/9d3d3290e715e5027b5cce97e10071ca0a6a06eb
	  Citations: 6 | Authors: Chao Li, Zhanwen Liu, Jiaying Zhang, Yang Wang, Fan Ding, Xiangmo Zhao | Date: 2022-10-08
2025-11-15 00:38:30,075 - INFO - root - 正在下载: https://www.mdpi.com/2072-4292/12/22/3764/pdf?version=1605536539
2025-11-15 00:38:35,017 - INFO - root - 正在下载: https://www.mdpi.com/2072-4292/12/22/3764/pdf?version=1605536539
2025-11-15 00:38:39,679 - INFO - root - 正在下载: https://www.mdpi.com/2072-4292/12/22/3764/pdf?version=1605536539
2025-11-15 00:38:44,417 - INFO - root - 正在下载: https://www.mdpi.com/2072-4292/12/22/3764/pdf?version=1605536539
2025-11-15 00:38:53,429 - INFO - root - 正在下载: https://www.mdpi.com/2072-4292/12/22/3764/pdf?version=1605536539
2025-11-15 00:38:54,227 - WARNING - root - 下载 A Hybrid Attention-Aware Fusion Network (HAFNet) for Building Extraction from High-Resolution Imagery and LiDAR Data (https://www.mdpi.com/2072-4292/12/22/3764/pdf?version=1605536539) 失败: 403 Client Error: Forbidden for url: https://www.mdpi.com/2072-4292/12/22/3764/pdf?version=1605536539
2025-11-15 00:38:54,228 - WARNING - root - 【手动下载提示】(无PDF): DA-DETR: Domain Adaptive Detection Transformer by Hybrid Attention
	  URL: https://www.semanticscholar.org/paper/c0f715596b2f557806c2de2404cf9a0ad5781cef
	  Citations: 33 | Authors: Jingyi Zhang, Jiaxing Huang, Zhipeng Luo, Gongjie Zhang, Shijian Lu | Date: N/A
2025-11-15 00:38:54,228 - INFO - root - 正在下载: https://www.mdpi.com/1424-8220/21/6/2003/pdf?version=1615879962
2025-11-15 00:38:58,943 - INFO - root - 正在下载: https://www.mdpi.com/1424-8220/21/6/2003/pdf?version=1615879962
2025-11-15 00:39:03,717 - INFO - root - 正在下载: https://www.mdpi.com/1424-8220/21/6/2003/pdf?version=1615879962
2025-11-15 00:39:08,427 - INFO - root - 正在下载: https://www.mdpi.com/1424-8220/21/6/2003/pdf?version=1615879962
2025-11-15 00:39:18,066 - INFO - root - 正在下载: https://www.mdpi.com/1424-8220/21/6/2003/pdf?version=1615879962
2025-11-15 00:39:19,251 - WARNING - root - 下载 Hybrid Attention Cascade Network for Facial Expression Recognition (https://www.mdpi.com/1424-8220/21/6/2003/pdf?version=1615879962) 失败: 403 Client Error: Forbidden for url: https://www.mdpi.com/1424-8220/21/6/2003/pdf?version=1615879962
2025-11-15 00:39:19,255 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\hybrid attention\HADLN_ Hybrid Attention-Based Deep Learning Network for Automated Arrhythmia Classification.pdf
2025-11-15 00:39:19,256 - INFO - root - 成功下载 (Semantic Scholar): HADLN: Hybrid Attention-Based Deep Learning Network for Automated Arrhythmia Classification
2025-11-15 00:39:19,257 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\hybrid attention\MHANet_ A hybrid attention mechanism for retinal diseases classification.pdf
2025-11-15 00:39:19,257 - INFO - root - 成功下载 (Semantic Scholar): MHANet: A hybrid attention mechanism for retinal diseases classification
2025-11-15 00:39:19,260 - INFO - root - 检索到 21 篇论文（包括待手动下载的），开始总结...
2025-11-15 00:39:19,286 - INFO - root - --- 开始论文总结阶段 ---
2025-11-15 00:39:19,306 - INFO - root - 跳过已处理论文 Hybrid Attention Fusion Embedded in Transformer for Remote Sensing Image Semantic Segmentation：D:\ChatPaper\api_downloads\hybrid attention\Hybrid Attention Fusion Embedded in Transformer for Remote Sensing Image Semantic Segmentation.pdf
2025-11-15 00:39:19,309 - INFO - root - 跳过已处理论文 YOLO Algorithm With Hybrid Attention Feature Pyramid Network for Solder Joint Defect Detection：D:\ChatPaper\api_downloads\hybrid attention\YOLO Algorithm With Hybrid Attention Feature Pyramid Network for Solder Joint Defect Detection.pdf
2025-11-15 00:39:19,312 - INFO - root - 跳过已处理论文 Frequency Enhanced Hybrid Attention Network for Sequential Recommendation：D:\ChatPaper\api_downloads\hybrid attention\Frequency Enhanced Hybrid Attention Network for Sequential Recommendation.pdf
2025-11-15 00:39:19,356 - INFO - root - 跳过已处理论文 HAT: Hybrid Attention Transformer for Image Restoration：D:\ChatPaper\api_downloads\hybrid attention\HAT_ Hybrid Attention Transformer for Image Restoration.pdf
2025-11-15 00:39:19,359 - INFO - root - 跳过已处理论文 Multi-scale deep residual shrinkage networks with a hybrid attention mechanism for rolling bearing fault diagnosis：D:\ChatPaper\api_downloads\hybrid attention\Multi-scale deep residual shrinkage networks with a hybrid attention mechanism for rolling bearing f.pdf
2025-11-15 00:39:19,363 - INFO - root - 跳过已处理论文 Physics Inspired Hybrid Attention for SAR Target Recognition：D:\ChatPaper\api_downloads\hybrid attention\Physics Inspired Hybrid Attention for SAR Target Recognition.pdf
2025-11-15 00:39:19,379 - INFO - root - 跳过已处理论文 Fine-grained image classification method based on hybrid attention module：D:\ChatPaper\api_downloads\hybrid attention\Fine-grained image classification method based on hybrid attention module.pdf
2025-11-15 00:39:19,415 - INFO - root - 跳过已处理论文 Hybrid Attention-Based U-Shaped Network for Remote Sensing Image Super-Resolution：D:\ChatPaper\api_downloads\hybrid attention\Hybrid Attention-Based U-Shaped Network for Remote Sensing Image Super-Resolution.pdf
2025-11-15 00:39:19,427 - INFO - root - 跳过已处理论文 Hybrid Attention-Based Prototypical Networks for Noisy Few-Shot Relation Classification：D:\ChatPaper\api_downloads\hybrid attention\Hybrid Attention-Based Prototypical Networks for Noisy Few-Shot Relation Classification.pdf
2025-11-15 00:39:19,459 - INFO - root - 跳过已处理论文 Dual-view Correlation Hybrid Attention Network for Robust Holistic Mammogram Classification：D:\ChatPaper\api_downloads\hybrid attention\Dual-view Correlation Hybrid Attention Network for Robust Holistic Mammogram Classification.pdf
2025-11-15 00:39:19,464 - INFO - root - 跳过已处理论文 Stacked Hybrid-Attention and Group Collaborative Learning for Unbiased Scene Graph Generation：D:\ChatPaper\api_downloads\hybrid attention\Stacked Hybrid-Attention and Group Collaborative Learning for Unbiased Scene Graph Generation.pdf
2025-11-15 00:39:19,471 - INFO - root - 跳过已处理论文 Hybridformer: Improving Squeezeformer with Hybrid Attention and NSR Mechanism：D:\ChatPaper\api_downloads\hybrid attention\Hybridformer_ Improving Squeezeformer with Hybrid Attention and NSR Mechanism.pdf
2025-11-15 00:39:19,477 - INFO - root - 跳过已处理论文 HAC-Net: A Hybrid Attention-Based Convolutional Neural Network for Highly Accurate Protein-Ligand Binding Affinity Prediction：D:\ChatPaper\api_downloads\hybrid attention\HAC-Net_ A Hybrid Attention-Based Convolutional Neural Network for Highly Accurate Protein-Ligand Bi.pdf
2025-11-15 00:39:19,480 - INFO - root - 跳过已处理论文 A Hybrid Attention Mechanism for Weakly-Supervised Temporal Action Localization：D:\ChatPaper\api_downloads\hybrid attention\A Hybrid Attention Mechanism for Weakly-Supervised Temporal Action Localization.pdf
2025-11-15 00:39:19,483 - INFO - root - 跳过已处理论文 RHA-Net: An Encoder-Decoder Network with Residual Blocks and Hybrid Attention Mechanisms for Pavement Crack Segmentation：D:\ChatPaper\api_downloads\hybrid attention\RHA-Net_ An Encoder-Decoder Network with Residual Blocks and Hybrid Attention Mechanisms for Pavemen.pdf
2025-11-15 00:39:19,492 - INFO - root - 跳过已处理论文 HHTrack: Hyperspectral Object Tracking Using Hybrid Attention：D:\ChatPaper\api_downloads\hybrid attention\HHTrack_ Hyperspectral Object Tracking Using Hybrid Attention.pdf
2025-11-15 00:39:19,494 - INFO - root - 跳过已处理论文 RAIN: Reinforced Hybrid Attention Inference Network for Motion Forecasting：D:\ChatPaper\api_downloads\hybrid attention\RAIN_ Reinforced Hybrid Attention Inference Network for Motion Forecasting.pdf
2025-11-15 00:39:19,497 - INFO - root - 跳过已处理论文 MHA-Net: Multipath Hybrid Attention Network for Building Footprint Extraction From High-Resolution Remote Sensing Imagery：D:\ChatPaper\api_downloads\hybrid attention\MHA-Net_ Multipath Hybrid Attention Network for Building Footprint Extraction From High-Resolution R.pdf
2025-11-15 00:39:19,504 - INFO - root - 跳过已处理论文 A Hybrid-Attention Nested UNet for Nuclear Segmentation in Histopathological Images：D:\ChatPaper\api_downloads\hybrid attention\A Hybrid-Attention Nested UNet for Nuclear Segmentation in Histopathological Images.pdf
2025-11-15 00:39:19,507 - INFO - root - 跳过已处理论文 HADLN: Hybrid Attention-Based Deep Learning Network for Automated Arrhythmia Classification：D:\ChatPaper\api_downloads\hybrid attention\HADLN_ Hybrid Attention-Based Deep Learning Network for Automated Arrhythmia Classification.pdf
2025-11-15 00:39:19,513 - INFO - root - 跳过已处理论文 MHANet: A hybrid attention mechanism for retinal diseases classification：D:\ChatPaper\api_downloads\hybrid attention\MHANet_ A hybrid attention mechanism for retinal diseases classification.pdf
2025-11-15 00:39:19,519 - INFO - root - --- 论文总结阶段结束 ---
2025-11-15 00:39:19,525 - INFO - root - --- 开始生成 Excel 报告 (包含 21 篇论文) ---
2025-11-15 00:39:19,574 - INFO - root - 检测到已存在的 Excel 文件: export\hybrid_attention_summary.xlsx。正在追加...
2025-11-15 00:39:19,727 - INFO - root - 合并后: 22 条记录 (新增 0 条, 更新 21 条)
2025-11-15 00:39:19,799 - ERROR - root - 保存 Excel 失败: [Errno 13] Permission denied: 'export\\hybrid_attention_summary.xlsx'
Traceback (most recent call last):
  File "D:\ChatPaper\paper_enhancer.py", line 132, in generate_summary_excel
    with pd.ExcelWriter(excel_path, engine='openpyxl') as writer:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\pandas\io\excel\_openpyxl.py", line 61, in __init__
    super().__init__(
  File "D:\ChatPaper\.venv\Lib\site-packages\pandas\io\excel\_base.py", line 1246, in __init__
    self._handles = get_handle(
                    ^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\pandas\io\common.py", line 882, in get_handle
    handle = open(handle, ioargs.mode)
             ^^^^^^^^^^^^^^^^^^^^^^^^^
PermissionError: [Errno 13] Permission denied: 'export\\hybrid_attention_summary.xlsx'
2025-11-15 00:39:19,815 - WARNING - root - Excel 保存失败，已保存为 CSV: export\hybrid_attention_summary_backup.csv
2025-11-15 00:39:19,815 - INFO - root - 已生成或更新汇总 Excel 表格: export\hybrid_attention_summary_backup.csv
2025-11-15 00:39:19,816 - INFO - root - 总运行时间: 548.11 seconds
2025-11-15 00:46:18,519 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-15 00:46:18,521 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-15 00:46:18,524 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-15 00:46:22,095 - INFO - root - LLMClientManager: 指定使用客户端: Gemini
2025-11-15 00:46:23,508 - INFO - root - GeminiClient: trying model models/gemini-2.5-flash
2025-11-15 00:46:25,915 - INFO - root - GeminiClient: initialized model gemini-2.5-flash
2025-11-15 00:46:25,915 - INFO - root - LLMClientManager: Gemini 客户端初始化成功
2025-11-15 00:46:25,916 - INFO - root - LLMClientManager: switched to Gemini client
2025-11-15 00:46:25,916 - INFO - root - 已手动切换到 LLM 客户端: Gemini
2025-11-15 00:46:25,917 - INFO - root - 使用 LLM 模型: gemini-2.5-flash
2025-11-15 00:46:25,917 - INFO - root - 可用客户端: ['Gemini']
2025-11-15 00:46:25,917 - INFO - root - === 运行配置 ===
2025-11-15 00:46:25,918 - INFO - root - 处理模式: Semantic Scholar 高引用搜索 (API)
2025-11-15 00:46:25,919 - INFO - root - 查询 (关键词): hybrid attention
2025-11-15 00:46:25,919 - INFO - root - 关键词 (用于保存): hybrid attention
2025-11-15 00:46:25,919 - INFO - root - 排序: citationCount:desc
2025-11-15 00:46:25,920 - INFO - root - 最大处理数量: 100
2025-11-15 00:46:25,920 - INFO - root - 保存图片: 是
2025-11-15 00:46:25,920 - INFO - root - 输出语言: 中文
2025-11-15 00:46:25,921 - INFO - root - 强制重新处理: 否
2025-11-15 00:46:25,921 - INFO - root - LLM 客户端: Gemini
2025-11-15 00:46:25,922 - INFO - root - ====================
2025-11-15 00:46:25,923 - INFO - root - 正在使用检索策略: semantic
2025-11-15 00:46:25,924 - INFO - root - 使用 Semantic Scholar 高引用搜索模式 (API)
2025-11-15 00:46:25,927 - INFO - root - Semantic API 查询: query=hybrid attention, limit=100, sort=citationCount:desc
2025-11-15 00:46:25,928 - INFO - root - 正在调用 Semantic Scholar API...
2025-11-15 00:46:28,054 - WARNING - root - 【手动下载提示】(无PDF): An Instrument Indication Acquisition Algorithm Based on Lightweight Deep Convolutional Neural Network and Hybrid Attention Fine-Grained Features
	  URL: https://www.semanticscholar.org/paper/49f99d7a21e2ded7915676753a180983763b9a22
	  Citations: 66 | Authors: Jiaquan Shen, Ningzhong Liu, Han Sun, Deguang Li, Yongxin Zhang | Date: N/A
2025-11-15 00:46:28,054 - WARNING - root - 【手动下载提示】(无PDF): Enhancing ASD classification through hybrid attention-based learning of facial features
	  URL: https://www.semanticscholar.org/paper/22547aa4c72c7c2799932a0f451ab3f2db6d7d0f
	  Citations: 35 | Authors: Inzamam Shahzad, Saif Ur Rehman Khan, Waseem Abbas, Z. U. Abideen, Jin Liu | Date: 2024-04-21
2025-11-15 00:46:28,055 - WARNING - root - 【手动下载提示】(无PDF): Dual-Hybrid Attention Network for Specular Highlight Removal
	  URL: https://www.semanticscholar.org/paper/d56ce689cc0f8b1cf0e5f58882503a5e59ec440b
	  Citations: 33 | Authors: Xiaojiao Guo, Xuhang Chen, Shenghong Luo, Shuqiang Wang, Chi-Man Pun | Date: 2024-07-17
2025-11-15 00:46:28,055 - WARNING - root - 【手动下载提示】(无PDF): HyA-GAN: remote sensing image cloud removal based on hybrid attention generation adversarial network
	  URL: https://www.semanticscholar.org/paper/905b42f2f8d912d98fd7cbec4f7b244401176acc
	  Citations: 16 | Authors: Minghao Jin, Pengwei Wang, Yusong Li | Date: 2024-02-27
2025-11-15 00:46:28,055 - WARNING - root - 【手动下载提示】(无PDF): Hybrid Attention-Aware Transformer Network Collaborative Multiscale Feature Alignment for Building Change Detection
	  URL: https://www.semanticscholar.org/paper/a0f8053046622628073ac6f051b5181a80cb7ad3
	  Citations: 28 | Authors: Chuan Xu, Zhaoyi Ye, Liye Mei, Haonan Yu, Jianchen Liu, Yaxiaer Yalikun, Shuangtong Jin, Sheng Liu, Wei Yang, Cheng Lei | Date: N/A
2025-11-15 00:46:28,056 - WARNING - root - 【手动下载提示】(无PDF): Radar Signal Recognition Based on CNN With a Hybrid Attention Mechanism and Skip Feature Aggregation
	  URL: https://www.semanticscholar.org/paper/dacad703c49e9434321c91220219638f871fd9d2
	  Citations: 26 | Authors: Yuanpu Guo, Haixin Sun, Hui Liu, Zhen-miao Deng | Date: N/A
2025-11-15 00:46:28,056 - WARNING - root - 【手动下载提示】(无PDF): Probabilistic Multienergy Load Forecasting Based on Hybrid Attention-Enabled Transformer Network and Gaussian Process-Aided Residual Learning
	  URL: https://www.semanticscholar.org/paper/a2d81cc04f73e2898fb16e7e8c8f9cf69adadfd5
	  Citations: 16 | Authors: Pengfei Zhao, Weihao Hu, Di Cao, Zhenyuan Zhang, Yuehui Huang, Longcheng Dai, Zhe Chen | Date: 2024-06-01
2025-11-15 00:46:28,058 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\hybrid attention\Hybrid Attention Fusion Embedded in Transformer for Remote Sensing Image Semantic Segmentation.pdf
2025-11-15 00:46:28,058 - INFO - root - 成功下载 (Semantic Scholar): Hybrid Attention Fusion Embedded in Transformer for Remote Sensing Image Semantic Segmentation
2025-11-15 00:46:28,059 - WARNING - root - 【手动下载提示】(无PDF): Enhancing Time Series Product Demand Forecasting With Hybrid Attention-Based Deep Learning Models
	  URL: https://www.semanticscholar.org/paper/4848b35cbe515f8909a67a82dcb83d7c5e48f74b
	  Citations: 14 | Authors: Xuguang Zhang, Pan Li, Xu Han, Yongbin Yang, Yiwen Cui | Date: N/A
2025-11-15 00:46:28,061 - INFO - root - 正在下载: https://www.mdpi.com/2306-5354/11/3/240/pdf?version=1709132347
2025-11-15 00:46:32,834 - INFO - root - 正在下载: https://www.mdpi.com/2306-5354/11/3/240/pdf?version=1709132347
2025-11-15 00:46:37,609 - INFO - root - 正在下载: https://www.mdpi.com/2306-5354/11/3/240/pdf?version=1709132347
2025-11-15 00:46:42,252 - INFO - root - 正在下载: https://www.mdpi.com/2306-5354/11/3/240/pdf?version=1709132347
2025-11-15 00:46:50,974 - INFO - root - 正在下载: https://www.mdpi.com/2306-5354/11/3/240/pdf?version=1709132347
2025-11-15 00:46:51,698 - WARNING - root - 下载 Advancing Ocular Imaging: A Hybrid Attention Mechanism-Based U-Net Model for Precise Segmentation of Sub-Retinal Layers in OCT Images (https://www.mdpi.com/2306-5354/11/3/240/pdf?version=1709132347) 失败: 403 Client Error: Forbidden for url: https://www.mdpi.com/2306-5354/11/3/240/pdf?version=1709132347
2025-11-15 00:46:51,698 - WARNING - root - 【手动下载提示】(无PDF): A novel approach for bearings multiclass fault diagnosis fusing multiscale deep convolution and hybrid attention networks
	  URL: https://www.semanticscholar.org/paper/bf72523fe518b2e4ce4d75d125dd5220177043f6
	  Citations: 13 | Authors: Fule Li, Xinlong Zhao | Date: 2024-01-08
2025-11-15 00:46:51,699 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\hybrid attention\YOLO Algorithm With Hybrid Attention Feature Pyramid Network for Solder Joint Defect Detection.pdf
2025-11-15 00:46:51,702 - INFO - root - 成功下载 (Semantic Scholar): YOLO Algorithm With Hybrid Attention Feature Pyramid Network for Solder Joint Defect Detection
2025-11-15 00:46:51,702 - WARNING - root - 【手动下载提示】(无PDF): Drone-HAT: Hybrid Attention Transformer for Complex Action Recognition in Drone Surveillance Videos
	  URL: https://www.semanticscholar.org/paper/a76690fb96dc7d3dfd5f8fec62c3949cc7ec96f6
	  Citations: 12 | Authors: Mustaqeem Khan, Jamil Ahmad, Abdulmotaleb El-Saddik, W. Gueaieb, Giulia De Masi, Fakhri Karray | Date: 2024-06-17
2025-11-15 00:46:51,703 - WARNING - root - 【手动下载提示】(无PDF): Dense Hybrid Attention Network for Palmprint Image Super-Resolution
	  URL: https://www.semanticscholar.org/paper/75746d8d52509b24d9975d9b3b07ae91311dc7ed
	  Citations: 12 | Authors: Yao Wang, Lunke Fei, Shuping Zhao, Qi Zhu, Jie Wen, Wei Jia, Imad Rida | Date: 2024-04-01
2025-11-15 00:46:51,704 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\hybrid attention\Frequency Enhanced Hybrid Attention Network for Sequential Recommendation.pdf
2025-11-15 00:46:51,705 - INFO - root - 成功下载 (Semantic Scholar): Frequency Enhanced Hybrid Attention Network for Sequential Recommendation
2025-11-15 00:46:51,705 - WARNING - root - 【手动下载提示】(无PDF): Hybrid Attention Feature Refinement Network for Lightweight Image Super-Resolution in Metaverse Immersive Display
	  URL: https://www.semanticscholar.org/paper/c4d95a47eec1a23320d60dd95848d41e10820ee4
	  Citations: 10 | Authors: Kexin Wang, Xiaomin Yang, Gwanggil Jeon | Date: 2024-02-01
2025-11-15 00:46:51,705 - WARNING - root - 【手动下载提示】(无PDF): A Multiscale Hybrid Attention Networks Based on Multiview Images for the Diagnosis of Parkinson’s Disease
	  URL: https://www.semanticscholar.org/paper/b2af0577ee8ac56b527bd108ce57755a4a4b04e7
	  Citations: 11 | Authors: Xinchun Cui, Youshi Zhou, Chao Zhao, Jianlong Li, Xiangwei Zheng, Xiuli Li, Shixiao Shan, JinXing Liu, Xiaoli Liu | Date: N/A
2025-11-15 00:46:51,706 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\hybrid attention\HAT_ Hybrid Attention Transformer for Image Restoration.pdf
2025-11-15 00:46:51,706 - INFO - root - 成功下载 (Semantic Scholar): HAT: Hybrid Attention Transformer for Image Restoration
2025-11-15 00:46:51,708 - INFO - root - 正在下载: https://www.mdpi.com/2076-3417/14/3/1293/pdf?version=1707037901
2025-11-15 00:46:56,483 - INFO - root - 正在下载: https://www.mdpi.com/2076-3417/14/3/1293/pdf?version=1707037901
2025-11-15 00:47:01,316 - INFO - root - 正在下载: https://www.mdpi.com/2076-3417/14/3/1293/pdf?version=1707037901
2025-11-15 00:47:06,629 - INFO - root - 正在下载: https://www.mdpi.com/2076-3417/14/3/1293/pdf?version=1707037901
2025-11-15 00:47:15,403 - INFO - root - 正在下载: https://www.mdpi.com/2076-3417/14/3/1293/pdf?version=1707037901
2025-11-15 00:47:16,042 - WARNING - root - 下载 Dual Hybrid Attention Mechanism-Based U-Net for Building Segmentation in Remote Sensing Images (https://www.mdpi.com/2076-3417/14/3/1293/pdf?version=1707037901) 失败: 403 Client Error: Forbidden for url: https://www.mdpi.com/2076-3417/14/3/1293/pdf?version=1707037901
2025-11-15 00:47:16,044 - WARNING - root - 【手动下载提示】(无PDF): Abundance Matrix Correlation Analysis Network Based on Hierarchical Multihead Self-Cross-Hybrid Attention for Hyperspectral Change Detection
	  URL: https://www.semanticscholar.org/paper/6aae02a41656cecba872b29bb3d71c414a58f57b
	  Citations: 66 | Authors: Wenqian Dong, Jing Zhao, Jiahui Qu, Song Xiao, Nan Li, Shaoxiong Hou, Yunsong Li | Date: N/A
2025-11-15 00:47:16,045 - WARNING - root - 【手动下载提示】(无PDF): Hybrid Attention Module and Transformer Based Fuze DRFM Jamming Signal Recognition
	  URL: https://www.semanticscholar.org/paper/0fb8059c6aaf0c86c9e9a623fa1ad73d0f737c37
	  Citations: 7 | Authors: Jikai Yang, Zhiquan Bai, Zhaoxia Xian, Hongwu Xiang, Jingxin Li, Huili Hu, Jian Dai, Xinhong Hao | Date: 2024-09-01
2025-11-15 00:47:16,045 - WARNING - root - 【手动下载提示】(无PDF): DenseNet model incorporating hybrid attention mechanisms and clinical features for pancreatic cystic tumor classification
	  URL: https://www.semanticscholar.org/paper/7c520ed397a3d9e6863a840325b3b0643eb15fa7
	  Citations: 7 | Authors: Hui Tian, Bo Zhang, Zhiwei Zhang, Zhenshun Xu, Liang Jin, Yun Bian, Jie Wu | Date: 2024-05-07
2025-11-15 00:47:16,045 - WARNING - root - 【手动下载提示】(无PDF): HA-Net: a SAR image ship detector based on hybrid attention
	  URL: https://www.semanticscholar.org/paper/4c40b6f75ab19e1402ae88e38013a64c504c3a80
	  Citations: 6 | Authors: Shouwen Cai, Hao Meng, Ming Yuan, Fei Gao | Date: 2024-06-10
2025-11-15 00:47:16,046 - WARNING - root - 【手动下载提示】(无PDF): Deep Hashing Network With Hybrid Attention and Adaptive Weighting for Image Retrieval
	  URL: https://www.semanticscholar.org/paper/1c688a4da1c546ea783f5743c371732ace568498
	  Citations: 8 | Authors: Yingjiao Pei, Zhongyuan Wang, Na Li, Heling Chen, Baojin Huang, Weiping Tu | Date: N/A
2025-11-15 00:47:16,046 - WARNING - root - 【手动下载提示】(无PDF): Actor-Hybrid-Attention-Critic for Multi-Logistic Robots Path Planning
	  URL: https://www.semanticscholar.org/paper/5260da08f9f524b8fa77a37e2884b22804a47c6a
	  Citations: 6 | Authors: Chunjie Yang, Bodi Yuan, Pengzhao Zhai | Date: 2024-06-01
2025-11-15 00:47:16,048 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\hybrid attention\Multi-scale deep residual shrinkage networks with a hybrid attention mechanism for rolling bearing f.pdf
2025-11-15 00:47:16,048 - INFO - root - 成功下载 (Semantic Scholar): Multi-scale deep residual shrinkage networks with a hybrid attention mechanism for rolling bearing fault diagnosis
2025-11-15 00:47:16,049 - WARNING - root - 【手动下载提示】(无PDF): Towards Effective Author Name Disambiguation by Hybrid Attention
	  URL: https://www.semanticscholar.org/paper/fc2dcb9e544a0aaad3034a61eaf0563a79c65cbf
	  Citations: 6 | Authors: Qian Zhou, Wei Chen, Peng-Peng Zhao, An Liu, Jia-Jie Xu, Jianfeng Qu, Lei Zhao | Date: 2024-07-01
2025-11-15 00:47:16,051 - INFO - root - 正在下载: https://www.mdpi.com/2306-5354/10/6/714/pdf?version=1686635187
2025-11-15 00:47:21,024 - INFO - root - 正在下载: https://www.mdpi.com/2306-5354/10/6/714/pdf?version=1686635187
2025-11-15 00:47:25,643 - INFO - root - 正在下载: https://www.mdpi.com/2306-5354/10/6/714/pdf?version=1686635187
2025-11-15 00:47:30,397 - INFO - root - 正在下载: https://www.mdpi.com/2306-5354/10/6/714/pdf?version=1686635187
2025-11-15 00:47:39,411 - INFO - root - 正在下载: https://www.mdpi.com/2306-5354/10/6/714/pdf?version=1686635187
2025-11-15 00:47:40,105 - WARNING - root - 下载 AHANet: Adaptive Hybrid Attention Network for Alzheimer’s Disease Classification Using Brain Magnetic Resonance Imaging (https://www.mdpi.com/2306-5354/10/6/714/pdf?version=1686635187) 失败: 403 Client Error: Forbidden for url: https://www.mdpi.com/2306-5354/10/6/714/pdf?version=1686635187
2025-11-15 00:47:40,107 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\hybrid attention\Physics Inspired Hybrid Attention for SAR Target Recognition.pdf
2025-11-15 00:47:40,108 - INFO - root - 成功下载 (Semantic Scholar): Physics Inspired Hybrid Attention for SAR Target Recognition
2025-11-15 00:47:40,109 - WARNING - root - 【手动下载提示】(无PDF): WHEN: A Wavelet-DTW Hybrid Attention Network for Heterogeneous Time Series Analysis
	  URL: https://www.semanticscholar.org/paper/c2e57a1926217f67a72c617d09fa12ec8e667d0e
	  Citations: 33 | Authors: Jingyuan Wang, Chen Yang, Xiaohan Jiang, Junjie Wu | Date: 2023-08-04
2025-11-15 00:47:40,111 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\hybrid attention\Fine-grained image classification method based on hybrid attention module.pdf
2025-11-15 00:47:40,113 - INFO - root - 成功下载 (Semantic Scholar): Fine-grained image classification method based on hybrid attention module
2025-11-15 00:47:40,114 - WARNING - root - 【手动下载提示】(无PDF): Hybrid Attention-Aware Learning Network for Facial Expression Recognition in the Wild
	  URL: https://www.semanticscholar.org/paper/a13c5a80a32c0e2dbf589d9fca9daa9b2300165d
	  Citations: 4 | Authors: Weijun Gong, Zhiyao La, Yurong Qian, Weihang Zhou | Date: 2024-01-05
2025-11-15 00:47:40,121 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\hybrid attention\Hybrid Attention-Based U-Shaped Network for Remote Sensing Image Super-Resolution.pdf
2025-11-15 00:47:40,123 - INFO - root - 成功下载 (Semantic Scholar): Hybrid Attention-Based U-Shaped Network for Remote Sensing Image Super-Resolution
2025-11-15 00:47:40,126 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\hybrid attention\Text-Conditioned Outfit Recommendation With Hybrid Attention Layer.pdf
2025-11-15 00:47:40,127 - INFO - root - 成功下载 (Semantic Scholar): Text-Conditioned Outfit Recommendation With Hybrid Attention Layer
2025-11-15 00:47:40,137 - INFO - root - 正在下载: https://www.mdpi.com/2076-3417/13/2/770/pdf?version=1673518878
2025-11-15 00:47:44,997 - INFO - root - 正在下载: https://www.mdpi.com/2076-3417/13/2/770/pdf?version=1673518878
2025-11-15 00:47:49,628 - INFO - root - 正在下载: https://www.mdpi.com/2076-3417/13/2/770/pdf?version=1673518878
2025-11-15 00:47:54,267 - INFO - root - 正在下载: https://www.mdpi.com/2076-3417/13/2/770/pdf?version=1673518878
2025-11-15 00:48:03,011 - INFO - root - 正在下载: https://www.mdpi.com/2076-3417/13/2/770/pdf?version=1673518878
2025-11-15 00:48:04,735 - WARNING - root - 下载 Smart Contract Vulnerability Detection Based on Hybrid Attention Mechanism Model (https://www.mdpi.com/2076-3417/13/2/770/pdf?version=1673518878) 失败: 403 Client Error: Forbidden for url: https://www.mdpi.com/2076-3417/13/2/770/pdf?version=1673518878
2025-11-15 00:48:04,736 - WARNING - root - 【手动下载提示】(无PDF): Mutiscale Hybrid Attention Transformer for Remote Sensing Image Pansharpening
	  URL: https://www.semanticscholar.org/paper/3b8404c8b16dd7abb86aa5f13139fa9a9c5f5ca8
	  Citations: 22 | Authors: Wengang Zhu, Jinjiang Li, Zhi-Yonga An, Zhen Hua | Date: N/A
2025-11-15 00:48:04,737 - WARNING - root - 【手动下载提示】(无PDF): Multimodal emotion recognition based on audio and text by using hybrid attention networks
	  URL: https://www.semanticscholar.org/paper/5a35815f9d5f7ed5697b4638b1158f42837051c1
	  Citations: 42 | Authors: Shiqing Zhang, Yijiao Yang, Ruixin Liu, Chen Chen, Xin Tao, Wenping Guo, Yicheng Xu, Xiaoming Zhao | Date: N/A
2025-11-15 00:48:04,737 - WARNING - root - 【手动下载提示】(无PDF): A Novel Approach for Surface Integrity Monitoring in High-Energy Nanosecond-Pulse Laser Shock Peening: Acoustic Emission and Hybrid-Attention CNN
	  URL: https://www.semanticscholar.org/paper/9608f2b16d1d302f7507505b51a5be96fdf0b542
	  Citations: 19 | Authors: Zhifen Zhang, Rui Qin, Gengze Li, Z. Du, G. Wen, Weifeng He | Date: 2023-03-01
2025-11-15 00:48:04,738 - WARNING - root - 【手动下载提示】(无PDF): Intention-convolution and hybrid-attention network for vehicle trajectory prediction
	  URL: https://www.semanticscholar.org/paper/3bcb4d2994896053a5a8da42d09eb621d3b2b221
	  Citations: 34 | Authors: Chao Li, Zhanwen Liu, Shang Lin, Yang Wang, Xiangmo Zhao | Date: 2023-09-01
2025-11-15 00:48:04,741 - WARNING - root - 【手动下载提示】(无PDF): Hybrid Attention Network for Epileptic EEG Classification
	  URL: https://www.semanticscholar.org/paper/f282fa85469cc789c2f3b62e57e3446a49528afa
	  Citations: 17 | Authors: Yanna Zhao, Jiatong He, Fenglin Zhu, Tiantian Xiao, Yongfeng Zhang, Ziwei Wang, Fangzhou Xu, Yi Niu | Date: 2023-03-31
2025-11-15 00:48:04,744 - INFO - root - 正在下载: https://www.mdpi.com/1424-8220/23/13/6052/pdf?version=1688107163
2025-11-15 00:48:09,680 - INFO - root - 正在下载: https://www.mdpi.com/1424-8220/23/13/6052/pdf?version=1688107163
2025-11-15 00:48:14,323 - INFO - root - 正在下载: https://www.mdpi.com/1424-8220/23/13/6052/pdf?version=1688107163
2025-11-15 00:48:19,035 - INFO - root - 正在下载: https://www.mdpi.com/1424-8220/23/13/6052/pdf?version=1688107163
2025-11-15 00:48:27,664 - INFO - root - 正在下载: https://www.mdpi.com/1424-8220/23/13/6052/pdf?version=1688107163
2025-11-15 00:48:28,502 - WARNING - root - 下载 PHAM-YOLO: A Parallel Hybrid Attention Mechanism Network for Defect Detection of Meter in Substation (https://www.mdpi.com/1424-8220/23/13/6052/pdf?version=1688107163) 失败: 403 Client Error: Forbidden for url: https://www.mdpi.com/1424-8220/23/13/6052/pdf?version=1688107163
2025-11-15 00:48:28,507 - INFO - root - 正在下载: https://www.mdpi.com/1424-8220/23/15/6982/pdf?version=1691312141
2025-11-15 00:48:33,154 - INFO - root - 正在下载: https://www.mdpi.com/1424-8220/23/15/6982/pdf?version=1691312141
2025-11-15 00:48:37,764 - INFO - root - 正在下载: https://www.mdpi.com/1424-8220/23/15/6982/pdf?version=1691312141
2025-11-15 00:48:42,538 - INFO - root - 正在下载: https://www.mdpi.com/1424-8220/23/15/6982/pdf?version=1691312141
2025-11-15 00:48:51,192 - INFO - root - 正在下载: https://www.mdpi.com/1424-8220/23/15/6982/pdf?version=1691312141
2025-11-15 00:48:51,856 - WARNING - root - 下载 Defect Detection in Steel Using a Hybrid Attention Network (https://www.mdpi.com/1424-8220/23/15/6982/pdf?version=1691312141) 失败: 403 Client Error: Forbidden for url: https://www.mdpi.com/1424-8220/23/15/6982/pdf?version=1691312141
2025-11-15 00:48:51,859 - WARNING - root - 【手动下载提示】(无PDF): Hybrid Attention and Motion Constraint for Anomaly Detection in Crowded Scenes
	  URL: https://www.semanticscholar.org/paper/a5e107a1112c88294f44989f6622433fb402fb31
	  Citations: 30 | Authors: Xinfeng Zhang, Jinpeng Fang, Baoqing Yang, Shuhan Chen, Bin Li | Date: 2023-05-01
2025-11-15 00:48:51,876 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\hybrid attention\Hybrid Attention-Based Prototypical Networks for Noisy Few-Shot Relation Classification.pdf
2025-11-15 00:48:51,877 - INFO - root - 成功下载 (Semantic Scholar): Hybrid Attention-Based Prototypical Networks for Noisy Few-Shot Relation Classification
2025-11-15 00:48:51,880 - INFO - root - 正在下载: https://www.mdpi.com/2072-4292/15/2/526/pdf?version=1673863751
2025-11-15 00:48:56,527 - INFO - root - 正在下载: https://www.mdpi.com/2072-4292/15/2/526/pdf?version=1673863751
2025-11-15 00:49:01,231 - INFO - root - 正在下载: https://www.mdpi.com/2072-4292/15/2/526/pdf?version=1673863751
2025-11-15 00:49:05,954 - INFO - root - 正在下载: https://www.mdpi.com/2072-4292/15/2/526/pdf?version=1673863751
2025-11-15 00:49:14,681 - INFO - root - 正在下载: https://www.mdpi.com/2072-4292/15/2/526/pdf?version=1673863751
2025-11-15 00:49:15,396 - WARNING - root - 下载 Hybrid Attention-Based Encoder-Decoder Fully Convolutional Network for PolSAR Image Classification (https://www.mdpi.com/2072-4292/15/2/526/pdf?version=1673863751) 失败: 403 Client Error: Forbidden for url: https://www.mdpi.com/2072-4292/15/2/526/pdf?version=1673863751
2025-11-15 00:49:15,397 - WARNING - root - 【手动下载提示】(无PDF): Hybrid Attention Compression Network With Light Graph Attention Module for Remote Sensing Images
	  URL: https://www.semanticscholar.org/paper/11ab89aa34dae52624533795ebbe1ce707a66fd4
	  Citations: 9 | Authors: Tianpeng Pan, Lili Zhang, Yingchao Song, Yuxuan Liu | Date: N/A
2025-11-15 00:49:15,397 - WARNING - root - 【手动下载提示】(无PDF): An Adaptive Hybrid Attention Based Convolutional Neural Net for Intelligent Transportation Object Recognition
	  URL: https://www.semanticscholar.org/paper/269fed3c9a541a4073cde6e205878c2618b2f973
	  Citations: 11 | Authors: Qili Chen, Guangyuan Pan, Lin Zhao, Junfang Fan, Wenbai Chen, A. Zhang | Date: 2023-07-01
2025-11-15 00:49:15,398 - WARNING - root - 【手动下载提示】(无PDF): HEU-Net: hybrid attention residual block-based network with external skip connections for metal corrosion semantic segmentation
	  URL: https://www.semanticscholar.org/paper/80e0948897bc53edf4eba2e31e443010d8a2e19a
	  Citations: 9 | Authors: Tianchen Zhu, Shiqiang Zhu, Tao Zheng, Hongliang Ding, Wei Song, Cunjun Li | Date: 2023-06-22
2025-11-15 00:49:15,398 - WARNING - root - 【手动下载提示】(无PDF): Face-Periocular Cross-Identification via Contrastive Hybrid Attention Vision Transformer
	  URL: https://www.semanticscholar.org/paper/5765cc795e642e1a8e834d6af93cda3ac65a753a
	  Citations: 6 | Authors: Leslie Ching Ow Tiong, D. Sigmund, A. Teoh | Date: N/A
2025-11-15 00:49:15,398 - WARNING - root - 【手动下载提示】(无PDF): Image Super-Resolution with Multi-scale Hybrid Attention
	  URL: https://www.semanticscholar.org/paper/09691760c37f27ddf4d4b7908a348b20b110db6d
	  Citations: 0 | Authors: Ningzhi Wang, Hanyi Shi, Wenna Ruan, Lingbin Zeng | Date: N/A
2025-11-15 00:49:15,399 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\hybrid attention\Dual-view Correlation Hybrid Attention Network for Robust Holistic Mammogram Classification.pdf
2025-11-15 00:49:15,399 - INFO - root - 成功下载 (Semantic Scholar): Dual-view Correlation Hybrid Attention Network for Robust Holistic Mammogram Classification
2025-11-15 00:49:15,400 - INFO - root - 正在下载: https://www.mdpi.com/1424-8220/23/19/8285/pdf?version=1696663695
2025-11-15 00:49:20,273 - INFO - root - 正在下载: https://www.mdpi.com/1424-8220/23/19/8285/pdf?version=1696663695
2025-11-15 00:49:24,859 - INFO - root - 正在下载: https://www.mdpi.com/1424-8220/23/19/8285/pdf?version=1696663695
2025-11-15 00:49:29,745 - INFO - root - 正在下载: https://www.mdpi.com/1424-8220/23/19/8285/pdf?version=1696663695
2025-11-15 00:49:38,851 - INFO - root - 正在下载: https://www.mdpi.com/1424-8220/23/19/8285/pdf?version=1696663695
2025-11-15 00:49:39,506 - WARNING - root - 下载 A Fast and Robust Lane Detection via Online Re-Parameterization and Hybrid Attention (https://www.mdpi.com/1424-8220/23/19/8285/pdf?version=1696663695) 失败: 403 Client Error: Forbidden for url: https://www.mdpi.com/1424-8220/23/19/8285/pdf?version=1696663695
2025-11-15 00:49:39,508 - WARNING - root - 【手动下载提示】(无PDF): Multi-level wavelet network based on CNN-Transformer hybrid attention for single image deraining
	  URL: https://www.semanticscholar.org/paper/97c485dbb41b68c193decdec5a4618ce3f5b4ee2
	  Citations: 8 | Authors: B. Liu, Siyan Fang | Date: 2023-08-09
2025-11-15 00:49:39,509 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\hybrid attention\Stacked Hybrid-Attention and Group Collaborative Learning for Unbiased Scene Graph Generation.pdf
2025-11-15 00:49:39,510 - INFO - root - 成功下载 (Semantic Scholar): Stacked Hybrid-Attention and Group Collaborative Learning for Unbiased Scene Graph Generation
2025-11-15 00:49:39,512 - INFO - root - 正在下载: https://onlinelibrary.wiley.com/doi/pdfdirect/10.1049/ipr2.12934
2025-11-15 00:49:44,241 - INFO - root - 正在下载: https://onlinelibrary.wiley.com/doi/pdfdirect/10.1049/ipr2.12934
2025-11-15 00:49:48,937 - INFO - root - 正在下载: https://onlinelibrary.wiley.com/doi/pdfdirect/10.1049/ipr2.12934
2025-11-15 00:49:53,688 - INFO - root - 正在下载: https://onlinelibrary.wiley.com/doi/pdfdirect/10.1049/ipr2.12934
2025-11-15 00:50:02,710 - INFO - root - 正在下载: https://onlinelibrary.wiley.com/doi/pdfdirect/10.1049/ipr2.12934
2025-11-15 00:50:03,641 - WARNING - root - 下载 Hybrid attention mechanism of feature fusion for medical image segmentation (https://onlinelibrary.wiley.com/doi/pdfdirect/10.1049/ipr2.12934) 失败: 403 Client Error: Forbidden for url: https://onlinelibrary.wiley.com/doi/pdfdirect/10.1049/ipr2.12934
2025-11-15 00:50:03,647 - INFO - root - 正在下载: https://www.mdpi.com/2073-8994/15/10/1947/pdf?version=1697811500
2025-11-15 00:50:08,266 - INFO - root - 正在下载: https://www.mdpi.com/2073-8994/15/10/1947/pdf?version=1697811500
2025-11-15 00:50:12,921 - INFO - root - 正在下载: https://www.mdpi.com/2073-8994/15/10/1947/pdf?version=1697811500
2025-11-15 00:50:17,509 - INFO - root - 正在下载: https://www.mdpi.com/2073-8994/15/10/1947/pdf?version=1697811500
2025-11-15 00:50:26,139 - INFO - root - 正在下载: https://www.mdpi.com/2073-8994/15/10/1947/pdf?version=1697811500
2025-11-15 00:50:26,764 - WARNING - root - 下载 Transformer with Hybrid Attention Mechanism for Stereo Endoscopic Video Super Resolution (https://www.mdpi.com/2073-8994/15/10/1947/pdf?version=1697811500) 失败: 403 Client Error: Forbidden for url: https://www.mdpi.com/2073-8994/15/10/1947/pdf?version=1697811500
2025-11-15 00:50:26,788 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\hybrid attention\Hybridformer_ Improving Squeezeformer with Hybrid Attention and NSR Mechanism.pdf
2025-11-15 00:50:26,790 - INFO - root - 成功下载 (Semantic Scholar): Hybridformer: Improving Squeezeformer with Hybrid Attention and NSR Mechanism
2025-11-15 00:50:26,793 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\hybrid attention\HAC-Net_ A Hybrid Attention-Based Convolutional Neural Network for Highly Accurate Protein-Ligand Bi.pdf
2025-11-15 00:50:26,793 - INFO - root - 成功下载 (Semantic Scholar): HAC-Net: A Hybrid Attention-Based Convolutional Neural Network for Highly Accurate Protein-Ligand Binding Affinity Prediction
2025-11-15 00:50:26,794 - WARNING - root - 【手动下载提示】(无PDF): A hybrid-attention semantic segmentation network for remote sensing interpretation in land-use surveillance
	  URL: https://www.semanticscholar.org/paper/4905315ab99ea19871a65e52be8c8c51624748aa
	  Citations: 49 | Authors: Ning Lv, Zenghui Zhang, Cong Li, Jiaxuan Deng, Tao Su, Chen Chen, Yang Zhou | Date: 2022-02-07
2025-11-15 00:50:26,794 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\hybrid attention\A Hybrid Attention Mechanism for Weakly-Supervised Temporal Action Localization.pdf
2025-11-15 00:50:26,795 - INFO - root - 成功下载 (Semantic Scholar): A Hybrid Attention Mechanism for Weakly-Supervised Temporal Action Localization
2025-11-15 00:50:26,795 - WARNING - root - 【手动下载提示】(无PDF): A hybrid attention-based deep learning approach for wind power prediction
	  URL: https://www.semanticscholar.org/paper/9d591544b9f179d93ad85720e8382e8e1c04c916
	  Citations: 128 | Authors: Zhengjing Ma, Gang Mei | Date: 2022-10-01
2025-11-15 00:50:26,796 - WARNING - root - 【手动下载提示】(无PDF): ColorFormer: Image Colorization via Color Memory Assisted Hybrid-Attention Transformer
	  URL: https://www.semanticscholar.org/paper/33618e85644d6705fd74086c13ee3b7e2a2a466a
	  Citations: 28 | Authors: Xiaozhong Ji, Boyuan Jiang, Donghao Luo, Guangpin Tao, Wenqing Chu, Zhifeng Xie, Chengjie Wang, Ying Tai | Date: N/A
2025-11-15 00:50:26,796 - WARNING - root - 【手动下载提示】(无PDF): HAM: Hybrid attention module in deep convolutional neural networks for image classification
	  URL: https://www.semanticscholar.org/paper/2cfa77f582ee36f2d1fe8869505aa5a71a5f99f3
	  Citations: 92 | Authors: Guoqiang Li, Qianhao Fang, Li Zha, Xin Gao, Nenggan Zheng | Date: 2022-05-01
2025-11-15 00:50:26,796 - WARNING - root - 【手动下载提示】(无PDF): State of health estimation for lithium-ion batteries based on hybrid attention and deep learning
	  URL: https://www.semanticscholar.org/paper/f91dcfd8df66da9bf3649c176869f980b9205115
	  Citations: 91 | Authors: Hongqian Zhao, Zheng Chen, Xing Shu, Jiangwei Shen, Zhenzhen Lei, Yuanjian Zhang | Date: 2022-12-01
2025-11-15 00:50:26,798 - INFO - root - 正在下载: https://downloads.hindawi.com/journals/cin/2022/4189500.pdf
2025-11-15 00:50:31,581 - INFO - root - 正在下载: https://downloads.hindawi.com/journals/cin/2022/4189500.pdf
2025-11-15 00:50:36,850 - INFO - root - 正在下载: https://downloads.hindawi.com/journals/cin/2022/4189500.pdf
2025-11-15 00:50:41,785 - INFO - root - 正在下载: https://downloads.hindawi.com/journals/cin/2022/4189500.pdf
2025-11-15 00:50:50,576 - INFO - root - 正在下载: https://downloads.hindawi.com/journals/cin/2022/4189500.pdf
2025-11-15 00:50:51,210 - WARNING - root - 下载 Aircraft Image Recognition Network Based on Hybrid Attention Mechanism (https://downloads.hindawi.com/journals/cin/2022/4189500.pdf) 失败: 403 Client Error: Forbidden for url: https://downloads.hindawi.com/journals/cin/2022/4189500.pdf
2025-11-15 00:50:51,211 - WARNING - root - 【手动下载提示】(无PDF): Hybrid attention based vehicle trajectory prediction
	  URL: https://www.semanticscholar.org/paper/a2778f12363b79e0a604ddd21a878f3abb0acced
	  Citations: 6 | Authors: Lingyang Wang, Wenping Jiang | Date: 2023-04-06
2025-11-15 00:50:51,212 - WARNING - root - 【手动下载提示】(无PDF): A Hybrid Attention-Based Paralleled Deep Learning model for tool wear prediction
	  URL: https://www.semanticscholar.org/paper/27da7ffd2319f8a2f47eec128894be31f88fc35c
	  Citations: 87 | Authors: Jian Duan, Xi Zhang, Tielin Shi | Date: 2022-08-01
2025-11-15 00:50:51,214 - INFO - root - 正在下载: https://ieeexplore.ieee.org/ielx7/6287639/9668973/09693977.pdf
2025-11-15 00:50:56,592 - INFO - root - 正在下载: https://ieeexplore.ieee.org/ielx7/6287639/9668973/09693977.pdf
2025-11-15 00:51:01,440 - INFO - root - 正在下载: https://ieeexplore.ieee.org/ielx7/6287639/9668973/09693977.pdf
2025-11-15 00:51:06,271 - INFO - root - 正在下载: https://ieeexplore.ieee.org/ielx7/6287639/9668973/09693977.pdf
2025-11-15 00:51:15,145 - INFO - root - 正在下载: https://ieeexplore.ieee.org/ielx7/6287639/9668973/09693977.pdf
2025-11-15 00:51:16,117 - WARNING - root - 下载 HANN: Hybrid Attention Neural Network for Detecting Covid-19 Related Rumors (https://ieeexplore.ieee.org/ielx7/6287639/9668973/09693977.pdf) 失败: 418 Client Error: Unknown Code for url: https://ieeexplore.ieee.org/ielx7/6287639/9668973/09693977.pdf
2025-11-15 00:51:16,118 - INFO - root - 正在下载: https://www.mdpi.com/1424-8220/22/10/3701/pdf?version=1652360619
2025-11-15 00:51:20,919 - INFO - root - 正在下载: https://www.mdpi.com/1424-8220/22/10/3701/pdf?version=1652360619
2025-11-15 00:51:25,842 - INFO - root - 正在下载: https://www.mdpi.com/1424-8220/22/10/3701/pdf?version=1652360619
2025-11-15 00:51:30,820 - INFO - root - 正在下载: https://www.mdpi.com/1424-8220/22/10/3701/pdf?version=1652360619
2025-11-15 00:51:39,450 - INFO - root - 正在下载: https://www.mdpi.com/1424-8220/22/10/3701/pdf?version=1652360619
2025-11-15 00:51:40,374 - WARNING - root - 下载 An Anti-UAV Long-Term Tracking Method with Hybrid Attention Mechanism and Hierarchical Discriminator (https://www.mdpi.com/1424-8220/22/10/3701/pdf?version=1652360619) 失败: 403 Client Error: Forbidden for url: https://www.mdpi.com/1424-8220/22/10/3701/pdf?version=1652360619
2025-11-15 00:51:40,379 - WARNING - root - 【手动下载提示】(无PDF): Hybrid Attention-Based Prototypical Networks for Few-Shot Sound Classification
	  URL: https://www.semanticscholar.org/paper/e0ddd13d74fe020c8e63eb2ef5a2daa687565953
	  Citations: 15 | Authors: You Wang, D.V. Anderson | Date: 2022-05-23
2025-11-15 00:51:40,380 - WARNING - root - 【手动下载提示】(无PDF): A Hybrid Attention-Based Deep Neural Network for Simultaneous Multi-Sensor Pruning and Human Activity Recognition
	  URL: https://www.semanticscholar.org/paper/06f82dcfa03d18408410b03b4203fff9bbeceeac
	  Citations: 21 | Authors: Yu Zhou, Zhuo Yang, Xiao Zhang, Yufan Wang | Date: 2022-12-15
2025-11-15 00:51:40,380 - WARNING - root - 【手动下载提示】(无PDF): End-to-End Multilevel Hybrid Attention Framework for Hyperspectral Image Classification
	  URL: https://www.semanticscholar.org/paper/6cbd2101b7faff37d402cc8574c95477af70f3aa
	  Citations: 19 | Authors: Jianhong Xiang, Chen Wei, Minhui Wang, Long Teng | Date: N/A
2025-11-15 00:51:40,380 - WARNING - root - 【手动下载提示】(无PDF): Parallel Deep Learning Algorithms With Hybrid Attention Mechanism for Image Segmentation of Lung Tumors
	  URL: https://www.semanticscholar.org/paper/05c67b073bde463686697eb553576958c8403a60
	  Citations: 88 | Authors: Hexuan Hu, Qingqiu Li, Yun-feng Zhao, Ye Zhang | Date: 2021-04-01
2025-11-15 00:51:40,380 - WARNING - root - 【手动下载提示】(无PDF): Hybrid attention network for semantic segmentation
	  URL: https://www.semanticscholar.org/paper/ee93962e142d4e7fa0b84f5d59970cb30a0b8960
	  Citations: 0 | Authors: Yin Yang, Juan Yang, Ronggui Wang | Date: 2023-10-19
2025-11-15 00:51:40,384 - WARNING - root - 【手动下载提示】(无PDF): A hybrid attention semantic segmentation network for unstructured terrain on Mars
	  URL: https://www.semanticscholar.org/paper/7b71919c1e0adafaa102cf03849b6c21841c8e54
	  Citations: 53 | Authors: Haiqiang Liu, Meibao Yao, Xueming Xiao, Hutao Cui | Date: 2022-08-01
2025-11-15 00:51:40,385 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\hybrid attention\RHA-Net_ An Encoder-Decoder Network with Residual Blocks and Hybrid Attention Mechanisms for Pavemen.pdf
2025-11-15 00:51:40,386 - INFO - root - 成功下载 (Semantic Scholar): RHA-Net: An Encoder-Decoder Network with Residual Blocks and Hybrid Attention Mechanisms for Pavement Crack Segmentation
2025-11-15 00:51:40,389 - INFO - root - 正在下载: https://downloads.hindawi.com/journals/wcmc/2022/5441366.pdf
2025-11-15 00:51:45,162 - INFO - root - 正在下载: https://downloads.hindawi.com/journals/wcmc/2022/5441366.pdf
2025-11-15 00:51:51,554 - INFO - root - 正在下载: https://downloads.hindawi.com/journals/wcmc/2022/5441366.pdf
2025-11-15 00:51:56,264 - INFO - root - 正在下载: https://downloads.hindawi.com/journals/wcmc/2022/5441366.pdf
2025-11-15 00:52:05,015 - INFO - root - 正在下载: https://downloads.hindawi.com/journals/wcmc/2022/5441366.pdf
2025-11-15 00:52:05,989 - WARNING - root - 下载 Classification of Diabetic Retinopathy Based on Multiscale Hybrid Attention Mechanism and Residual Algorithm (https://downloads.hindawi.com/journals/wcmc/2022/5441366.pdf) 失败: 403 Client Error: Forbidden for url: https://downloads.hindawi.com/journals/wcmc/2022/5441366.pdf
2025-11-15 00:52:05,991 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\hybrid attention\HHTrack_ Hyperspectral Object Tracking Using Hybrid Attention.pdf
2025-11-15 00:52:05,991 - INFO - root - 成功下载 (Semantic Scholar): HHTrack: Hyperspectral Object Tracking Using Hybrid Attention
2025-11-15 00:52:05,992 - WARNING - root - 【手动下载提示】(无PDF): Hybrid attention network for image captioning
	  URL: https://www.semanticscholar.org/paper/45acf57fd885b60d858dc6c49da4ff536a901d67
	  Citations: 22 | Authors: Wenhui Jiang, Qin Li, K. Zhan, Yuming Fang, Fei Shen | Date: 2022-05-01
2025-11-15 00:52:05,992 - INFO - root - 正在下载: https://downloads.hindawi.com/journals/wcmc/2022/3301718.pdf
2025-11-15 00:52:11,123 - INFO - root - 正在下载: https://downloads.hindawi.com/journals/wcmc/2022/3301718.pdf
2025-11-15 00:52:15,774 - INFO - root - 正在下载: https://downloads.hindawi.com/journals/wcmc/2022/3301718.pdf
2025-11-15 00:52:20,628 - INFO - root - 正在下载: https://downloads.hindawi.com/journals/wcmc/2022/3301718.pdf
2025-11-15 00:52:29,464 - INFO - root - 正在下载: https://downloads.hindawi.com/journals/wcmc/2022/3301718.pdf
2025-11-15 00:52:30,079 - WARNING - root - 下载 Malicious Code Classification Method Based on Deep Residual Network and Hybrid Attention Mechanism for Edge Security (https://downloads.hindawi.com/journals/wcmc/2022/3301718.pdf) 失败: 403 Client Error: Forbidden for url: https://downloads.hindawi.com/journals/wcmc/2022/3301718.pdf
2025-11-15 00:52:30,080 - INFO - root - 正在下载: https://www.mdpi.com/2079-9292/11/22/3787/pdf?version=1669096288
2025-11-15 00:52:35,063 - INFO - root - 正在下载: https://www.mdpi.com/2079-9292/11/22/3787/pdf?version=1669096288
2025-11-15 00:52:39,696 - INFO - root - 正在下载: https://www.mdpi.com/2079-9292/11/22/3787/pdf?version=1669096288
2025-11-15 00:52:44,382 - INFO - root - 正在下载: https://www.mdpi.com/2079-9292/11/22/3787/pdf?version=1669096288
2025-11-15 00:52:53,194 - INFO - root - 正在下载: https://www.mdpi.com/2079-9292/11/22/3787/pdf?version=1669096288
2025-11-15 00:52:54,019 - WARNING - root - 下载 HA-Unet: A Modified Unet Based on Hybrid Attention for Urban Water Extraction in SAR Images (https://www.mdpi.com/2079-9292/11/22/3787/pdf?version=1669096288) 失败: 403 Client Error: Forbidden for url: https://www.mdpi.com/2079-9292/11/22/3787/pdf?version=1669096288
2025-11-15 00:52:54,020 - WARNING - root - 【手动下载提示】(无PDF): Generative adversarial network with hybrid attention and compromised normalization for multi-scene image conversion
	  URL: https://www.semanticscholar.org/paper/1defd0b952f393b189dc61bc421c8ae7dd4df3c2
	  Citations: 11 | Authors: Jinsheng Xiao, Shuhao Zhang, Yuntao Yao, Zhongyuan Wang, Yongqin Zhang, Yuan-fang Wang | Date: 2022-01-29
2025-11-15 00:52:54,022 - INFO - root - 正在下载: https://www.mdpi.com/2079-9292/11/17/2709/pdf?version=1661780513
2025-11-15 00:52:59,090 - INFO - root - 正在下载: https://www.mdpi.com/2079-9292/11/17/2709/pdf?version=1661780513
2025-11-15 00:53:03,832 - INFO - root - 正在下载: https://www.mdpi.com/2079-9292/11/17/2709/pdf?version=1661780513
2025-11-15 00:53:08,513 - INFO - root - 正在下载: https://www.mdpi.com/2079-9292/11/17/2709/pdf?version=1661780513
2025-11-15 00:53:17,380 - INFO - root - 正在下载: https://www.mdpi.com/2079-9292/11/17/2709/pdf?version=1661780513
2025-11-15 00:53:18,067 - WARNING - root - 下载 Occluded Vehicle Detection via Multi-Scale Hybrid Attention Mechanism in the Road Scene (https://www.mdpi.com/2079-9292/11/17/2709/pdf?version=1661780513) 失败: 403 Client Error: Forbidden for url: https://www.mdpi.com/2079-9292/11/17/2709/pdf?version=1661780513
2025-11-15 00:53:18,069 - INFO - root - 正在下载: https://www.mdpi.com/2227-7390/10/11/1915/pdf?version=1654510435
2025-11-15 00:53:22,708 - INFO - root - 正在下载: https://www.mdpi.com/2227-7390/10/11/1915/pdf?version=1654510435
2025-11-15 00:53:27,622 - INFO - root - 正在下载: https://www.mdpi.com/2227-7390/10/11/1915/pdf?version=1654510435
2025-11-15 00:53:32,292 - INFO - root - 正在下载: https://www.mdpi.com/2227-7390/10/11/1915/pdf?version=1654510435
2025-11-15 00:53:40,939 - INFO - root - 正在下载: https://www.mdpi.com/2227-7390/10/11/1915/pdf?version=1654510435
2025-11-15 00:53:41,551 - WARNING - root - 下载 HA-RoadFormer: Hybrid Attention Transformer with Multi-Branch for Large-Scale High-Resolution Dense Road Segmentation (https://www.mdpi.com/2227-7390/10/11/1915/pdf?version=1654510435) 失败: 403 Client Error: Forbidden for url: https://www.mdpi.com/2227-7390/10/11/1915/pdf?version=1654510435
2025-11-15 00:53:41,551 - WARNING - root - 【手动下载提示】(无PDF): A hybrid attention improved ResNet based fault diagnosis method of wind turbines gearbox
	  URL: https://www.semanticscholar.org/paper/c71d11b59d8a85d413af1dab9337e39e52910774
	  Citations: 161 | Authors: Kai Zhang, B. Tang, Lei Deng, Xiaoli Liu | Date: 2021-05-03
2025-11-15 00:53:41,552 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\hybrid attention\RAIN_ Reinforced Hybrid Attention Inference Network for Motion Forecasting.pdf
2025-11-15 00:53:41,552 - INFO - root - 成功下载 (Semantic Scholar): RAIN: Reinforced Hybrid Attention Inference Network for Motion Forecasting
2025-11-15 00:53:41,553 - WARNING - root - 【手动下载提示】(无PDF): A hybrid attention mechanism for blind automatic modulation classification
	  URL: https://www.semanticscholar.org/paper/f226e86f57129dfa31db5c69c14163b9d3904988
	  Citations: 8 | Authors: Fan Jia, Yueyi Yang, Junyi Zhang, Yong Yang | Date: 2022-04-05
2025-11-15 00:53:41,555 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\hybrid attention\A Hybrid-Attention Nested UNet for Nuclear Segmentation in Histopathological Images.pdf
2025-11-15 00:53:41,555 - INFO - root - 成功下载 (Semantic Scholar): A Hybrid-Attention Nested UNet for Nuclear Segmentation in Histopathological Images
2025-11-15 00:53:41,556 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\hybrid attention\MHA-Net_ Multipath Hybrid Attention Network for Building Footprint Extraction From High-Resolution R.pdf
2025-11-15 00:53:41,556 - INFO - root - 成功下载 (Semantic Scholar): MHA-Net: Multipath Hybrid Attention Network for Building Footprint Extraction From High-Resolution Remote Sensing Imagery
2025-11-15 00:53:41,559 - INFO - root - 正在下载: https://ieeexplore.ieee.org/ielx7/6287639/6514899/09837031.pdf
2025-11-15 00:53:47,287 - INFO - root - 正在下载: https://ieeexplore.ieee.org/ielx7/6287639/6514899/09837031.pdf
2025-11-15 00:53:52,164 - INFO - root - 正在下载: https://ieeexplore.ieee.org/ielx7/6287639/6514899/09837031.pdf
2025-11-15 00:53:57,628 - INFO - root - 正在下载: https://ieeexplore.ieee.org/ielx7/6287639/6514899/09837031.pdf
2025-11-15 00:54:08,304 - INFO - root - 正在下载: https://ieeexplore.ieee.org/ielx7/6287639/6514899/09837031.pdf
2025-11-15 00:54:09,957 - WARNING - root - 下载 Dual-Path Hybrid Attention Network for Monaural Speech Separation (https://ieeexplore.ieee.org/ielx7/6287639/6514899/09837031.pdf) 失败: 418 Client Error: Unknown Code for url: https://ieeexplore.ieee.org/ielx7/6287639/6514899/09837031.pdf
2025-11-15 00:54:09,957 - WARNING - root - 【手动下载提示】(无PDF): Neural machine translation for Indian language pair using hybrid attention mechanism
	  URL: https://www.semanticscholar.org/paper/3479ff37a0bb3858b1761a871b81f4ca3dd26454
	  Citations: 7 | Authors: Basab Nath, Sunita Sarkar, Surajeet Das, Somnath Mukhopadhyay | Date: 2022-02-01
2025-11-15 00:54:09,957 - WARNING - root - 【手动下载提示】(无PDF): Two-stream LSTM Network with Hybrid Attention for Vehicle Trajectory Prediction
	  URL: https://www.semanticscholar.org/paper/9d3d3290e715e5027b5cce97e10071ca0a6a06eb
	  Citations: 6 | Authors: Chao Li, Zhanwen Liu, Jiaying Zhang, Yang Wang, Fan Ding, Xiangmo Zhao | Date: 2022-10-08
2025-11-15 00:54:09,958 - WARNING - root - 【手动下载提示】(无PDF): Hybrid Attention Fusion Segmentation Network for Diffuse Large B-cell Lymphoma in PET-CT
	  URL: https://www.semanticscholar.org/paper/80c16017651e0fc33b4bb10e2686a582ae119459
	  Citations: 6 | Authors: Shun Chen, Ang Li, Jianxin Chen, Xuguang Zhang, Chong Jiang, Jingyan Xu | Date: 2022-11-01
2025-11-15 00:54:09,958 - WARNING - root - 【手动下载提示】(无PDF): Hybrid attention mechanism for liver tumor segmentation in CT images
	  URL: https://www.semanticscholar.org/paper/9410e41c65c34be9a745cda06f430de0d53084d9
	  Citations: 6 | Authors: Ming Gong, Baixiang Zhao, J. Soraghan, G. D. Caterina, D. Grose | Date: 2022-09-11
2025-11-15 00:54:09,959 - INFO - root - 正在下载: https://www.mdpi.com/2072-4292/12/22/3764/pdf?version=1605536539
2025-11-15 00:54:14,563 - INFO - root - 正在下载: https://www.mdpi.com/2072-4292/12/22/3764/pdf?version=1605536539
2025-11-15 00:54:19,203 - INFO - root - 正在下载: https://www.mdpi.com/2072-4292/12/22/3764/pdf?version=1605536539
2025-11-15 00:54:23,846 - INFO - root - 正在下载: https://www.mdpi.com/2072-4292/12/22/3764/pdf?version=1605536539
2025-11-15 00:54:32,722 - INFO - root - 正在下载: https://www.mdpi.com/2072-4292/12/22/3764/pdf?version=1605536539
2025-11-15 00:54:33,339 - WARNING - root - 下载 A Hybrid Attention-Aware Fusion Network (HAFNet) for Building Extraction from High-Resolution Imagery and LiDAR Data (https://www.mdpi.com/2072-4292/12/22/3764/pdf?version=1605536539) 失败: 403 Client Error: Forbidden for url: https://www.mdpi.com/2072-4292/12/22/3764/pdf?version=1605536539
2025-11-15 00:54:33,339 - WARNING - root - 【手动下载提示】(无PDF): DA-DETR: Domain Adaptive Detection Transformer by Hybrid Attention
	  URL: https://www.semanticscholar.org/paper/c0f715596b2f557806c2de2404cf9a0ad5781cef
	  Citations: 33 | Authors: Jingyi Zhang, Jiaxing Huang, Zhipeng Luo, Gongjie Zhang, Shijian Lu | Date: N/A
2025-11-15 00:54:33,341 - INFO - root - 正在下载: https://www.mdpi.com/1424-8220/21/6/2003/pdf?version=1615879962
2025-11-15 00:54:37,942 - INFO - root - 正在下载: https://www.mdpi.com/1424-8220/21/6/2003/pdf?version=1615879962
2025-11-15 00:54:42,591 - INFO - root - 正在下载: https://www.mdpi.com/1424-8220/21/6/2003/pdf?version=1615879962
2025-11-15 00:54:47,195 - INFO - root - 正在下载: https://www.mdpi.com/1424-8220/21/6/2003/pdf?version=1615879962
2025-11-15 00:54:55,863 - INFO - root - 正在下载: https://www.mdpi.com/1424-8220/21/6/2003/pdf?version=1615879962
2025-11-15 00:54:56,485 - WARNING - root - 下载 Hybrid Attention Cascade Network for Facial Expression Recognition (https://www.mdpi.com/1424-8220/21/6/2003/pdf?version=1615879962) 失败: 403 Client Error: Forbidden for url: https://www.mdpi.com/1424-8220/21/6/2003/pdf?version=1615879962
2025-11-15 00:54:56,487 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\hybrid attention\HADLN_ Hybrid Attention-Based Deep Learning Network for Automated Arrhythmia Classification.pdf
2025-11-15 00:54:56,487 - INFO - root - 成功下载 (Semantic Scholar): HADLN: Hybrid Attention-Based Deep Learning Network for Automated Arrhythmia Classification
2025-11-15 00:54:56,489 - INFO - root - 正在下载: https://www.mdpi.com/2072-4292/13/10/1962/pdf?version=1621496001
2025-11-15 00:55:01,154 - INFO - root - 正在下载: https://www.mdpi.com/2072-4292/13/10/1962/pdf?version=1621496001
2025-11-15 00:55:05,766 - INFO - root - 正在下载: https://www.mdpi.com/2072-4292/13/10/1962/pdf?version=1621496001
2025-11-15 00:55:10,949 - INFO - root - 正在下载: https://www.mdpi.com/2072-4292/13/10/1962/pdf?version=1621496001
2025-11-15 00:55:19,543 - INFO - root - 正在下载: https://www.mdpi.com/2072-4292/13/10/1962/pdf?version=1621496001
2025-11-15 00:55:20,178 - WARNING - root - 下载 Hybrid Attention Based Residual Network for Pansharpening (https://www.mdpi.com/2072-4292/13/10/1962/pdf?version=1621496001) 失败: 403 Client Error: Forbidden for url: https://www.mdpi.com/2072-4292/13/10/1962/pdf?version=1621496001
2025-11-15 00:55:20,180 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\hybrid attention\MHANet_ A hybrid attention mechanism for retinal diseases classification.pdf
2025-11-15 00:55:20,181 - INFO - root - 成功下载 (Semantic Scholar): MHANet: A hybrid attention mechanism for retinal diseases classification
2025-11-15 00:55:20,181 - INFO - root - 检索到 22 篇论文（包括待手动下载的），开始总结...
2025-11-15 00:55:20,184 - INFO - root - --- 开始论文总结阶段 ---
2025-11-15 00:55:20,185 - INFO - root - 跳过已处理论文 Hybrid Attention Fusion Embedded in Transformer for Remote Sensing Image Semantic Segmentation：D:\ChatPaper\api_downloads\hybrid attention\Hybrid Attention Fusion Embedded in Transformer for Remote Sensing Image Semantic Segmentation.pdf
2025-11-15 00:55:20,186 - INFO - root - 跳过已处理论文 YOLO Algorithm With Hybrid Attention Feature Pyramid Network for Solder Joint Defect Detection：D:\ChatPaper\api_downloads\hybrid attention\YOLO Algorithm With Hybrid Attention Feature Pyramid Network for Solder Joint Defect Detection.pdf
2025-11-15 00:55:20,187 - INFO - root - 跳过已处理论文 Frequency Enhanced Hybrid Attention Network for Sequential Recommendation：D:\ChatPaper\api_downloads\hybrid attention\Frequency Enhanced Hybrid Attention Network for Sequential Recommendation.pdf
2025-11-15 00:55:20,187 - INFO - root - 跳过已处理论文 HAT: Hybrid Attention Transformer for Image Restoration：D:\ChatPaper\api_downloads\hybrid attention\HAT_ Hybrid Attention Transformer for Image Restoration.pdf
2025-11-15 00:55:20,188 - INFO - root - 跳过已处理论文 Multi-scale deep residual shrinkage networks with a hybrid attention mechanism for rolling bearing fault diagnosis：D:\ChatPaper\api_downloads\hybrid attention\Multi-scale deep residual shrinkage networks with a hybrid attention mechanism for rolling bearing f.pdf
2025-11-15 00:55:20,189 - INFO - root - 跳过已处理论文 Physics Inspired Hybrid Attention for SAR Target Recognition：D:\ChatPaper\api_downloads\hybrid attention\Physics Inspired Hybrid Attention for SAR Target Recognition.pdf
2025-11-15 00:55:20,191 - INFO - root - 跳过已处理论文 Fine-grained image classification method based on hybrid attention module：D:\ChatPaper\api_downloads\hybrid attention\Fine-grained image classification method based on hybrid attention module.pdf
2025-11-15 00:55:20,192 - INFO - root - 跳过已处理论文 Hybrid Attention-Based U-Shaped Network for Remote Sensing Image Super-Resolution：D:\ChatPaper\api_downloads\hybrid attention\Hybrid Attention-Based U-Shaped Network for Remote Sensing Image Super-Resolution.pdf
2025-11-15 00:55:20,193 - INFO - root - 跳过已处理论文 Text-Conditioned Outfit Recommendation With Hybrid Attention Layer：D:\ChatPaper\api_downloads\hybrid attention\Text-Conditioned Outfit Recommendation With Hybrid Attention Layer.pdf
2025-11-15 00:55:20,197 - INFO - root - 跳过已处理论文 Hybrid Attention-Based Prototypical Networks for Noisy Few-Shot Relation Classification：D:\ChatPaper\api_downloads\hybrid attention\Hybrid Attention-Based Prototypical Networks for Noisy Few-Shot Relation Classification.pdf
2025-11-15 00:55:20,198 - INFO - root - 跳过已处理论文 Dual-view Correlation Hybrid Attention Network for Robust Holistic Mammogram Classification：D:\ChatPaper\api_downloads\hybrid attention\Dual-view Correlation Hybrid Attention Network for Robust Holistic Mammogram Classification.pdf
2025-11-15 00:55:20,198 - INFO - root - 跳过已处理论文 Stacked Hybrid-Attention and Group Collaborative Learning for Unbiased Scene Graph Generation：D:\ChatPaper\api_downloads\hybrid attention\Stacked Hybrid-Attention and Group Collaborative Learning for Unbiased Scene Graph Generation.pdf
2025-11-15 00:55:20,199 - INFO - root - 跳过已处理论文 Hybridformer: Improving Squeezeformer with Hybrid Attention and NSR Mechanism：D:\ChatPaper\api_downloads\hybrid attention\Hybridformer_ Improving Squeezeformer with Hybrid Attention and NSR Mechanism.pdf
2025-11-15 00:55:20,199 - INFO - root - 跳过已处理论文 HAC-Net: A Hybrid Attention-Based Convolutional Neural Network for Highly Accurate Protein-Ligand Binding Affinity Prediction：D:\ChatPaper\api_downloads\hybrid attention\HAC-Net_ A Hybrid Attention-Based Convolutional Neural Network for Highly Accurate Protein-Ligand Bi.pdf
2025-11-15 00:55:20,199 - INFO - root - 跳过已处理论文 A Hybrid Attention Mechanism for Weakly-Supervised Temporal Action Localization：D:\ChatPaper\api_downloads\hybrid attention\A Hybrid Attention Mechanism for Weakly-Supervised Temporal Action Localization.pdf
2025-11-15 00:55:20,200 - INFO - root - 跳过已处理论文 RHA-Net: An Encoder-Decoder Network with Residual Blocks and Hybrid Attention Mechanisms for Pavement Crack Segmentation：D:\ChatPaper\api_downloads\hybrid attention\RHA-Net_ An Encoder-Decoder Network with Residual Blocks and Hybrid Attention Mechanisms for Pavemen.pdf
2025-11-15 00:55:20,201 - INFO - root - 跳过已处理论文 HHTrack: Hyperspectral Object Tracking Using Hybrid Attention：D:\ChatPaper\api_downloads\hybrid attention\HHTrack_ Hyperspectral Object Tracking Using Hybrid Attention.pdf
2025-11-15 00:55:20,202 - INFO - root - 跳过已处理论文 RAIN: Reinforced Hybrid Attention Inference Network for Motion Forecasting：D:\ChatPaper\api_downloads\hybrid attention\RAIN_ Reinforced Hybrid Attention Inference Network for Motion Forecasting.pdf
2025-11-15 00:55:20,202 - INFO - root - 跳过已处理论文 A Hybrid-Attention Nested UNet for Nuclear Segmentation in Histopathological Images：D:\ChatPaper\api_downloads\hybrid attention\A Hybrid-Attention Nested UNet for Nuclear Segmentation in Histopathological Images.pdf
2025-11-15 00:55:20,203 - INFO - root - 跳过已处理论文 MHA-Net: Multipath Hybrid Attention Network for Building Footprint Extraction From High-Resolution Remote Sensing Imagery：D:\ChatPaper\api_downloads\hybrid attention\MHA-Net_ Multipath Hybrid Attention Network for Building Footprint Extraction From High-Resolution R.pdf
2025-11-15 00:55:20,203 - INFO - root - 跳过已处理论文 HADLN: Hybrid Attention-Based Deep Learning Network for Automated Arrhythmia Classification：D:\ChatPaper\api_downloads\hybrid attention\HADLN_ Hybrid Attention-Based Deep Learning Network for Automated Arrhythmia Classification.pdf
2025-11-15 00:55:20,205 - INFO - root - 跳过已处理论文 MHANet: A hybrid attention mechanism for retinal diseases classification：D:\ChatPaper\api_downloads\hybrid attention\MHANet_ A hybrid attention mechanism for retinal diseases classification.pdf
2025-11-15 00:55:20,205 - INFO - root - --- 论文总结阶段结束 ---
2025-11-15 00:55:20,208 - INFO - root - --- 开始生成 Excel 报告 (包含 22 篇论文) ---
2025-11-15 00:55:20,225 - INFO - root - 检测到已存在的 Excel 文件: export\hybrid_attention_summary.xlsx。正在追加...
2025-11-15 00:55:20,252 - INFO - root - 合并后: 22 条记录 (新增 0 条, 更新 22 条)
2025-11-15 00:55:20,309 - INFO - root - 成功保存 Excel: export\hybrid_attention_summary.xlsx
2025-11-15 00:55:20,309 - INFO - root - 已生成或更新汇总 Excel 表格: export\hybrid_attention_summary.xlsx
2025-11-15 00:55:20,310 - INFO - root - 总运行时间: 541.79 seconds
2025-11-15 01:08:32,335 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-15 01:08:32,338 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-15 01:08:32,341 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-15 01:08:35,991 - INFO - root - LLMClientManager: 指定使用客户端: Gemini
2025-11-15 01:08:36,972 - INFO - root - GeminiClient: trying model models/gemini-2.5-flash
2025-11-15 01:08:45,310 - INFO - root - GeminiClient: initialized model gemini-2.5-flash
2025-11-15 01:08:45,310 - INFO - root - LLMClientManager: Gemini 客户端初始化成功
2025-11-15 01:08:45,311 - INFO - root - LLMClientManager: switched to Gemini client
2025-11-15 01:08:45,311 - INFO - root - 已手动切换到 LLM 客户端: Gemini
2025-11-15 01:08:45,312 - INFO - root - 使用 LLM 模型: gemini-2.5-flash
2025-11-15 01:08:45,313 - INFO - root - 可用客户端: ['Gemini']
2025-11-15 01:08:45,313 - INFO - root - === 运行配置 ===
2025-11-15 01:08:45,314 - INFO - root - 处理模式: Semantic Scholar 高引用搜索 (API)
2025-11-15 01:08:45,314 - INFO - root - 查询 (关键词): hybrid attention
2025-11-15 01:08:45,315 - INFO - root - 关键词 (用于保存): hybrid attention
2025-11-15 01:08:45,315 - INFO - root - 排序: citationCount:desc
2025-11-15 01:08:45,316 - INFO - root - 最大处理数量: 100
2025-11-15 01:08:45,317 - INFO - root - 保存图片: 是
2025-11-15 01:08:45,318 - INFO - root - 输出语言: 中文
2025-11-15 01:08:45,318 - INFO - root - 强制重新处理: 否
2025-11-15 01:08:45,319 - INFO - root - LLM 客户端: Gemini
2025-11-15 01:08:45,319 - INFO - root - ====================
2025-11-15 01:08:45,319 - INFO - root - 正在使用检索策略: semantic
2025-11-15 01:08:45,320 - INFO - root - 使用 Semantic Scholar 高引用搜索模式 (API)
2025-11-15 01:08:45,321 - INFO - root - Semantic API 查询: query=hybrid attention, limit=100, sort=citationCount:desc
2025-11-15 01:08:45,321 - INFO - root - 正在调用 Semantic Scholar API...
2025-11-15 01:08:47,508 - WARNING - root - 【手动下载提示】(无PDF): An Instrument Indication Acquisition Algorithm Based on Lightweight Deep Convolutional Neural Network and Hybrid Attention Fine-Grained Features
	  URL: https://www.semanticscholar.org/paper/49f99d7a21e2ded7915676753a180983763b9a22
	  Citations: 66 | Authors: Jiaquan Shen, Ningzhong Liu, Han Sun, Deguang Li, Yongxin Zhang | Date: N/A
2025-11-15 01:08:47,512 - WARNING - root - 【手动下载提示】(无PDF): Enhancing ASD classification through hybrid attention-based learning of facial features
	  URL: https://www.semanticscholar.org/paper/22547aa4c72c7c2799932a0f451ab3f2db6d7d0f
	  Citations: 35 | Authors: Inzamam Shahzad, Saif Ur Rehman Khan, Waseem Abbas, Z. U. Abideen, Jin Liu | Date: 2024-04-21
2025-11-15 01:08:47,513 - WARNING - root - 【手动下载提示】(无PDF): Dual-Hybrid Attention Network for Specular Highlight Removal
	  URL: https://www.semanticscholar.org/paper/d56ce689cc0f8b1cf0e5f58882503a5e59ec440b
	  Citations: 33 | Authors: Xiaojiao Guo, Xuhang Chen, Shenghong Luo, Shuqiang Wang, Chi-Man Pun | Date: 2024-07-17
2025-11-15 01:08:47,514 - WARNING - root - 【手动下载提示】(无PDF): HyA-GAN: remote sensing image cloud removal based on hybrid attention generation adversarial network
	  URL: https://www.semanticscholar.org/paper/905b42f2f8d912d98fd7cbec4f7b244401176acc
	  Citations: 16 | Authors: Minghao Jin, Pengwei Wang, Yusong Li | Date: 2024-02-27
2025-11-15 01:08:47,514 - WARNING - root - 【手动下载提示】(无PDF): Radar Signal Recognition Based on CNN With a Hybrid Attention Mechanism and Skip Feature Aggregation
	  URL: https://www.semanticscholar.org/paper/dacad703c49e9434321c91220219638f871fd9d2
	  Citations: 26 | Authors: Yuanpu Guo, Haixin Sun, Hui Liu, Zhen-miao Deng | Date: N/A
2025-11-15 01:08:47,515 - WARNING - root - 【手动下载提示】(无PDF): Hybrid Attention-Aware Transformer Network Collaborative Multiscale Feature Alignment for Building Change Detection
	  URL: https://www.semanticscholar.org/paper/a0f8053046622628073ac6f051b5181a80cb7ad3
	  Citations: 28 | Authors: Chuan Xu, Zhaoyi Ye, Liye Mei, Haonan Yu, Jianchen Liu, Yaxiaer Yalikun, Shuangtong Jin, Sheng Liu, Wei Yang, Cheng Lei | Date: N/A
2025-11-15 01:08:47,515 - WARNING - root - 【手动下载提示】(无PDF): Probabilistic Multienergy Load Forecasting Based on Hybrid Attention-Enabled Transformer Network and Gaussian Process-Aided Residual Learning
	  URL: https://www.semanticscholar.org/paper/a2d81cc04f73e2898fb16e7e8c8f9cf69adadfd5
	  Citations: 16 | Authors: Pengfei Zhao, Weihao Hu, Di Cao, Zhenyuan Zhang, Yuehui Huang, Longcheng Dai, Zhe Chen | Date: 2024-06-01
2025-11-15 01:08:47,518 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\hybrid attention\Hybrid Attention Fusion Embedded in Transformer for Remote Sensing Image Semantic Segmentation.pdf
2025-11-15 01:08:47,519 - INFO - root - 成功下载 (Semantic Scholar): Hybrid Attention Fusion Embedded in Transformer for Remote Sensing Image Semantic Segmentation
2025-11-15 01:08:47,520 - INFO - root - 正在下载: https://www.mdpi.com/2306-5354/11/3/240/pdf?version=1709132347
2025-11-15 01:08:52,541 - INFO - root - 正在下载: https://www.mdpi.com/2306-5354/11/3/240/pdf?version=1709132347
2025-11-15 01:08:57,281 - INFO - root - 正在下载: https://www.mdpi.com/2306-5354/11/3/240/pdf?version=1709132347
2025-11-15 01:09:02,069 - INFO - root - 正在下载: https://www.mdpi.com/2306-5354/11/3/240/pdf?version=1709132347
2025-11-15 01:09:10,969 - INFO - root - 正在下载: https://www.mdpi.com/2306-5354/11/3/240/pdf?version=1709132347
2025-11-15 01:09:11,586 - WARNING - root - 下载 Advancing Ocular Imaging: A Hybrid Attention Mechanism-Based U-Net Model for Precise Segmentation of Sub-Retinal Layers in OCT Images (https://www.mdpi.com/2306-5354/11/3/240/pdf?version=1709132347) 失败: 403 Client Error: Forbidden for url: https://www.mdpi.com/2306-5354/11/3/240/pdf?version=1709132347
2025-11-15 01:09:11,586 - WARNING - root - 【手动下载提示】(无PDF): Enhancing Time Series Product Demand Forecasting With Hybrid Attention-Based Deep Learning Models
	  URL: https://www.semanticscholar.org/paper/4848b35cbe515f8909a67a82dcb83d7c5e48f74b
	  Citations: 14 | Authors: Xuguang Zhang, Pan Li, Xu Han, Yongbin Yang, Yiwen Cui | Date: N/A
2025-11-15 01:09:11,588 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\hybrid attention\YOLO Algorithm With Hybrid Attention Feature Pyramid Network for Solder Joint Defect Detection.pdf
2025-11-15 01:09:11,589 - INFO - root - 成功下载 (Semantic Scholar): YOLO Algorithm With Hybrid Attention Feature Pyramid Network for Solder Joint Defect Detection
2025-11-15 01:09:11,589 - WARNING - root - 【手动下载提示】(无PDF): A novel approach for bearings multiclass fault diagnosis fusing multiscale deep convolution and hybrid attention networks
	  URL: https://www.semanticscholar.org/paper/bf72523fe518b2e4ce4d75d125dd5220177043f6
	  Citations: 13 | Authors: Fule Li, Xinlong Zhao | Date: 2024-01-08
2025-11-15 01:09:11,589 - WARNING - root - 【手动下载提示】(无PDF): Drone-HAT: Hybrid Attention Transformer for Complex Action Recognition in Drone Surveillance Videos
	  URL: https://www.semanticscholar.org/paper/a76690fb96dc7d3dfd5f8fec62c3949cc7ec96f6
	  Citations: 12 | Authors: Mustaqeem Khan, Jamil Ahmad, Abdulmotaleb El-Saddik, W. Gueaieb, Giulia De Masi, Fakhri Karray | Date: 2024-06-17
2025-11-15 01:09:11,590 - WARNING - root - 【手动下载提示】(无PDF): Dense Hybrid Attention Network for Palmprint Image Super-Resolution
	  URL: https://www.semanticscholar.org/paper/75746d8d52509b24d9975d9b3b07ae91311dc7ed
	  Citations: 12 | Authors: Yao Wang, Lunke Fei, Shuping Zhao, Qi Zhu, Jie Wen, Wei Jia, Imad Rida | Date: 2024-04-01
2025-11-15 01:09:11,591 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\hybrid attention\Frequency Enhanced Hybrid Attention Network for Sequential Recommendation.pdf
2025-11-15 01:09:11,591 - INFO - root - 成功下载 (Semantic Scholar): Frequency Enhanced Hybrid Attention Network for Sequential Recommendation
2025-11-15 01:09:11,592 - WARNING - root - 【手动下载提示】(无PDF): A Multiscale Hybrid Attention Networks Based on Multiview Images for the Diagnosis of Parkinson’s Disease
	  URL: https://www.semanticscholar.org/paper/b2af0577ee8ac56b527bd108ce57755a4a4b04e7
	  Citations: 11 | Authors: Xinchun Cui, Youshi Zhou, Chao Zhao, Jianlong Li, Xiangwei Zheng, Xiuli Li, Shixiao Shan, JinXing Liu, Xiaoli Liu | Date: N/A
2025-11-15 01:09:11,593 - WARNING - root - 【手动下载提示】(无PDF): Hybrid Attention Feature Refinement Network for Lightweight Image Super-Resolution in Metaverse Immersive Display
	  URL: https://www.semanticscholar.org/paper/c4d95a47eec1a23320d60dd95848d41e10820ee4
	  Citations: 10 | Authors: Kexin Wang, Xiaomin Yang, Gwanggil Jeon | Date: 2024-02-01
2025-11-15 01:09:11,595 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\hybrid attention\HAT_ Hybrid Attention Transformer for Image Restoration.pdf
2025-11-15 01:09:11,596 - INFO - root - 成功下载 (Semantic Scholar): HAT: Hybrid Attention Transformer for Image Restoration
2025-11-15 01:09:11,597 - INFO - root - 正在下载: https://www.mdpi.com/2076-3417/14/3/1293/pdf?version=1707037901
2025-11-15 01:09:16,326 - INFO - root - 正在下载: https://www.mdpi.com/2076-3417/14/3/1293/pdf?version=1707037901
2025-11-15 01:09:20,973 - INFO - root - 正在下载: https://www.mdpi.com/2076-3417/14/3/1293/pdf?version=1707037901
2025-11-15 01:09:26,205 - INFO - root - 正在下载: https://www.mdpi.com/2076-3417/14/3/1293/pdf?version=1707037901
2025-11-15 01:09:34,813 - INFO - root - 正在下载: https://www.mdpi.com/2076-3417/14/3/1293/pdf?version=1707037901
2025-11-15 01:09:35,408 - WARNING - root - 下载 Dual Hybrid Attention Mechanism-Based U-Net for Building Segmentation in Remote Sensing Images (https://www.mdpi.com/2076-3417/14/3/1293/pdf?version=1707037901) 失败: 403 Client Error: Forbidden for url: https://www.mdpi.com/2076-3417/14/3/1293/pdf?version=1707037901
2025-11-15 01:09:35,409 - WARNING - root - 【手动下载提示】(无PDF): Abundance Matrix Correlation Analysis Network Based on Hierarchical Multihead Self-Cross-Hybrid Attention for Hyperspectral Change Detection
	  URL: https://www.semanticscholar.org/paper/6aae02a41656cecba872b29bb3d71c414a58f57b
	  Citations: 66 | Authors: Wenqian Dong, Jing Zhao, Jiahui Qu, Song Xiao, Nan Li, Shaoxiong Hou, Yunsong Li | Date: N/A
2025-11-15 01:09:35,409 - WARNING - root - 【手动下载提示】(无PDF): Hybrid Attention Module and Transformer Based Fuze DRFM Jamming Signal Recognition
	  URL: https://www.semanticscholar.org/paper/0fb8059c6aaf0c86c9e9a623fa1ad73d0f737c37
	  Citations: 7 | Authors: Jikai Yang, Zhiquan Bai, Zhaoxia Xian, Hongwu Xiang, Jingxin Li, Huili Hu, Jian Dai, Xinhong Hao | Date: 2024-09-01
2025-11-15 01:09:35,409 - WARNING - root - 【手动下载提示】(无PDF): DenseNet model incorporating hybrid attention mechanisms and clinical features for pancreatic cystic tumor classification
	  URL: https://www.semanticscholar.org/paper/7c520ed397a3d9e6863a840325b3b0643eb15fa7
	  Citations: 7 | Authors: Hui Tian, Bo Zhang, Zhiwei Zhang, Zhenshun Xu, Liang Jin, Yun Bian, Jie Wu | Date: 2024-05-07
2025-11-15 01:09:35,411 - WARNING - root - 【手动下载提示】(无PDF): HA-Net: a SAR image ship detector based on hybrid attention
	  URL: https://www.semanticscholar.org/paper/4c40b6f75ab19e1402ae88e38013a64c504c3a80
	  Citations: 6 | Authors: Shouwen Cai, Hao Meng, Ming Yuan, Fei Gao | Date: 2024-06-10
2025-11-15 01:09:35,411 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\hybrid attention\Multi-scale deep residual shrinkage networks with a hybrid attention mechanism for rolling bearing f.pdf
2025-11-15 01:09:35,412 - INFO - root - 成功下载 (Semantic Scholar): Multi-scale deep residual shrinkage networks with a hybrid attention mechanism for rolling bearing fault diagnosis
2025-11-15 01:09:35,412 - WARNING - root - 【手动下载提示】(无PDF): Towards Effective Author Name Disambiguation by Hybrid Attention
	  URL: https://www.semanticscholar.org/paper/fc2dcb9e544a0aaad3034a61eaf0563a79c65cbf
	  Citations: 6 | Authors: Qian Zhou, Wei Chen, Peng-Peng Zhao, An Liu, Jia-Jie Xu, Jianfeng Qu, Lei Zhao | Date: 2024-07-01
2025-11-15 01:09:35,412 - WARNING - root - 【手动下载提示】(无PDF): Actor-Hybrid-Attention-Critic for Multi-Logistic Robots Path Planning
	  URL: https://www.semanticscholar.org/paper/5260da08f9f524b8fa77a37e2884b22804a47c6a
	  Citations: 6 | Authors: Chunjie Yang, Bodi Yuan, Pengzhao Zhai | Date: 2024-06-01
2025-11-15 01:09:35,412 - WARNING - root - 【手动下载提示】(无PDF): Deep Hashing Network With Hybrid Attention and Adaptive Weighting for Image Retrieval
	  URL: https://www.semanticscholar.org/paper/1c688a4da1c546ea783f5743c371732ace568498
	  Citations: 8 | Authors: Yingjiao Pei, Zhongyuan Wang, Na Li, Heling Chen, Baojin Huang, Weiping Tu | Date: N/A
2025-11-15 01:09:35,413 - WARNING - root - 【手动下载提示】(无PDF): Multi-modal bilinear fusion with hybrid attention mechanism for multi-label skin lesion classification
	  URL: https://www.semanticscholar.org/paper/2a89c443cf8b93abc7413ee32257f66fad5af684
	  Citations: 7 | Authors: Yun Wei, Lin Ji | Date: 2024-01-15
2025-11-15 01:09:35,414 - INFO - root - 正在下载: https://www.mdpi.com/2306-5354/10/6/714/pdf?version=1686635187
2025-11-15 01:09:40,131 - INFO - root - 正在下载: https://www.mdpi.com/2306-5354/10/6/714/pdf?version=1686635187
2025-11-15 01:09:44,776 - INFO - root - 正在下载: https://www.mdpi.com/2306-5354/10/6/714/pdf?version=1686635187
2025-11-15 01:09:49,443 - INFO - root - 正在下载: https://www.mdpi.com/2306-5354/10/6/714/pdf?version=1686635187
2025-11-15 01:09:58,088 - INFO - root - 正在下载: https://www.mdpi.com/2306-5354/10/6/714/pdf?version=1686635187
2025-11-15 01:09:59,024 - WARNING - root - 下载 AHANet: Adaptive Hybrid Attention Network for Alzheimer’s Disease Classification Using Brain Magnetic Resonance Imaging (https://www.mdpi.com/2306-5354/10/6/714/pdf?version=1686635187) 失败: 403 Client Error: Forbidden for url: https://www.mdpi.com/2306-5354/10/6/714/pdf?version=1686635187
2025-11-15 01:09:59,025 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\hybrid attention\Physics Inspired Hybrid Attention for SAR Target Recognition.pdf
2025-11-15 01:09:59,025 - INFO - root - 成功下载 (Semantic Scholar): Physics Inspired Hybrid Attention for SAR Target Recognition
2025-11-15 01:09:59,026 - WARNING - root - 【手动下载提示】(无PDF): WHEN: A Wavelet-DTW Hybrid Attention Network for Heterogeneous Time Series Analysis
	  URL: https://www.semanticscholar.org/paper/c2e57a1926217f67a72c617d09fa12ec8e667d0e
	  Citations: 33 | Authors: Jingyuan Wang, Chen Yang, Xiaohan Jiang, Junjie Wu | Date: 2023-08-04
2025-11-15 01:09:59,026 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\hybrid attention\Fine-grained image classification method based on hybrid attention module.pdf
2025-11-15 01:09:59,027 - INFO - root - 成功下载 (Semantic Scholar): Fine-grained image classification method based on hybrid attention module
2025-11-15 01:09:59,027 - WARNING - root - 【手动下载提示】(无PDF): Hybrid Attention-Aware Learning Network for Facial Expression Recognition in the Wild
	  URL: https://www.semanticscholar.org/paper/a13c5a80a32c0e2dbf589d9fca9daa9b2300165d
	  Citations: 4 | Authors: Weijun Gong, Zhiyao La, Yurong Qian, Weihang Zhou | Date: 2024-01-05
2025-11-15 01:09:59,028 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\hybrid attention\Hybrid Attention-Based U-Shaped Network for Remote Sensing Image Super-Resolution.pdf
2025-11-15 01:09:59,029 - INFO - root - 成功下载 (Semantic Scholar): Hybrid Attention-Based U-Shaped Network for Remote Sensing Image Super-Resolution
2025-11-15 01:09:59,029 - INFO - root - 正在下载: https://www.mdpi.com/2076-3417/13/2/770/pdf?version=1673518878
2025-11-15 01:10:03,745 - INFO - root - 正在下载: https://www.mdpi.com/2076-3417/13/2/770/pdf?version=1673518878
2025-11-15 01:10:08,376 - INFO - root - 正在下载: https://www.mdpi.com/2076-3417/13/2/770/pdf?version=1673518878
2025-11-15 01:10:13,877 - INFO - root - 正在下载: https://www.mdpi.com/2076-3417/13/2/770/pdf?version=1673518878
2025-11-15 01:10:22,572 - INFO - root - 正在下载: https://www.mdpi.com/2076-3417/13/2/770/pdf?version=1673518878
2025-11-15 01:10:23,182 - WARNING - root - 下载 Smart Contract Vulnerability Detection Based on Hybrid Attention Mechanism Model (https://www.mdpi.com/2076-3417/13/2/770/pdf?version=1673518878) 失败: 403 Client Error: Forbidden for url: https://www.mdpi.com/2076-3417/13/2/770/pdf?version=1673518878
2025-11-15 01:10:23,183 - WARNING - root - 【手动下载提示】(无PDF): Mutiscale Hybrid Attention Transformer for Remote Sensing Image Pansharpening
	  URL: https://www.semanticscholar.org/paper/3b8404c8b16dd7abb86aa5f13139fa9a9c5f5ca8
	  Citations: 22 | Authors: Wengang Zhu, Jinjiang Li, Zhi-Yonga An, Zhen Hua | Date: N/A
2025-11-15 01:10:23,183 - WARNING - root - 【手动下载提示】(无PDF): Multimodal emotion recognition based on audio and text by using hybrid attention networks
	  URL: https://www.semanticscholar.org/paper/5a35815f9d5f7ed5697b4638b1158f42837051c1
	  Citations: 42 | Authors: Shiqing Zhang, Yijiao Yang, Ruixin Liu, Chen Chen, Xin Tao, Wenping Guo, Yicheng Xu, Xiaoming Zhao | Date: N/A
2025-11-15 01:10:23,184 - WARNING - root - 【手动下载提示】(无PDF): A Novel Approach for Surface Integrity Monitoring in High-Energy Nanosecond-Pulse Laser Shock Peening: Acoustic Emission and Hybrid-Attention CNN
	  URL: https://www.semanticscholar.org/paper/9608f2b16d1d302f7507505b51a5be96fdf0b542
	  Citations: 19 | Authors: Zhifen Zhang, Rui Qin, Gengze Li, Z. Du, G. Wen, Weifeng He | Date: 2023-03-01
2025-11-15 01:10:23,184 - WARNING - root - 【手动下载提示】(无PDF): Intention-convolution and hybrid-attention network for vehicle trajectory prediction
	  URL: https://www.semanticscholar.org/paper/3bcb4d2994896053a5a8da42d09eb621d3b2b221
	  Citations: 34 | Authors: Chao Li, Zhanwen Liu, Shang Lin, Yang Wang, Xiangmo Zhao | Date: 2023-09-01
2025-11-15 01:10:23,185 - WARNING - root - 【手动下载提示】(无PDF): Hybrid Attention Network for Epileptic EEG Classification
	  URL: https://www.semanticscholar.org/paper/f282fa85469cc789c2f3b62e57e3446a49528afa
	  Citations: 17 | Authors: Yanna Zhao, Jiatong He, Fenglin Zhu, Tiantian Xiao, Yongfeng Zhang, Ziwei Wang, Fangzhou Xu, Yi Niu | Date: 2023-03-31
2025-11-15 01:10:23,186 - INFO - root - 正在下载: https://www.mdpi.com/1424-8220/23/13/6052/pdf?version=1688107163
2025-11-15 01:10:27,867 - INFO - root - 正在下载: https://www.mdpi.com/1424-8220/23/13/6052/pdf?version=1688107163
2025-11-15 01:10:33,166 - INFO - root - 正在下载: https://www.mdpi.com/1424-8220/23/13/6052/pdf?version=1688107163
2025-11-15 01:10:37,808 - INFO - root - 正在下载: https://www.mdpi.com/1424-8220/23/13/6052/pdf?version=1688107163
2025-11-15 01:10:46,850 - INFO - root - 正在下载: https://www.mdpi.com/1424-8220/23/13/6052/pdf?version=1688107163
2025-11-15 01:10:47,554 - WARNING - root - 下载 PHAM-YOLO: A Parallel Hybrid Attention Mechanism Network for Defect Detection of Meter in Substation (https://www.mdpi.com/1424-8220/23/13/6052/pdf?version=1688107163) 失败: 403 Client Error: Forbidden for url: https://www.mdpi.com/1424-8220/23/13/6052/pdf?version=1688107163
2025-11-15 01:10:47,557 - INFO - root - 正在下载: https://www.mdpi.com/1424-8220/23/15/6982/pdf?version=1691312141
2025-11-15 01:10:52,241 - INFO - root - 正在下载: https://www.mdpi.com/1424-8220/23/15/6982/pdf?version=1691312141
2025-11-15 01:10:57,161 - INFO - root - 正在下载: https://www.mdpi.com/1424-8220/23/15/6982/pdf?version=1691312141
2025-11-15 01:11:01,820 - INFO - root - 正在下载: https://www.mdpi.com/1424-8220/23/15/6982/pdf?version=1691312141
2025-11-15 01:11:10,515 - INFO - root - 正在下载: https://www.mdpi.com/1424-8220/23/15/6982/pdf?version=1691312141
2025-11-15 01:11:11,309 - WARNING - root - 下载 Defect Detection in Steel Using a Hybrid Attention Network (https://www.mdpi.com/1424-8220/23/15/6982/pdf?version=1691312141) 失败: 403 Client Error: Forbidden for url: https://www.mdpi.com/1424-8220/23/15/6982/pdf?version=1691312141
2025-11-15 01:11:11,310 - WARNING - root - 【手动下载提示】(无PDF): Hybrid Attention and Motion Constraint for Anomaly Detection in Crowded Scenes
	  URL: https://www.semanticscholar.org/paper/a5e107a1112c88294f44989f6622433fb402fb31
	  Citations: 30 | Authors: Xinfeng Zhang, Jinpeng Fang, Baoqing Yang, Shuhan Chen, Bin Li | Date: 2023-05-01
2025-11-15 01:11:11,312 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\hybrid attention\Hybrid Attention-Based Prototypical Networks for Noisy Few-Shot Relation Classification.pdf
2025-11-15 01:11:11,313 - INFO - root - 成功下载 (Semantic Scholar): Hybrid Attention-Based Prototypical Networks for Noisy Few-Shot Relation Classification
2025-11-15 01:11:11,315 - INFO - root - 正在下载: https://www.mdpi.com/2072-4292/15/2/526/pdf?version=1673863751
2025-11-15 01:11:16,815 - INFO - root - 正在下载: https://www.mdpi.com/2072-4292/15/2/526/pdf?version=1673863751
2025-11-15 01:11:21,441 - INFO - root - 正在下载: https://www.mdpi.com/2072-4292/15/2/526/pdf?version=1673863751
2025-11-15 01:11:34,010 - INFO - root - 正在下载: https://www.mdpi.com/2072-4292/15/2/526/pdf?version=1673863751
2025-11-15 01:11:42,692 - INFO - root - 正在下载: https://www.mdpi.com/2072-4292/15/2/526/pdf?version=1673863751
2025-11-15 01:11:43,409 - WARNING - root - 下载 Hybrid Attention-Based Encoder-Decoder Fully Convolutional Network for PolSAR Image Classification (https://www.mdpi.com/2072-4292/15/2/526/pdf?version=1673863751) 失败: 403 Client Error: Forbidden for url: https://www.mdpi.com/2072-4292/15/2/526/pdf?version=1673863751
2025-11-15 01:11:43,409 - WARNING - root - 【手动下载提示】(无PDF): Hybrid Attention Compression Network With Light Graph Attention Module for Remote Sensing Images
	  URL: https://www.semanticscholar.org/paper/11ab89aa34dae52624533795ebbe1ce707a66fd4
	  Citations: 9 | Authors: Tianpeng Pan, Lili Zhang, Yingchao Song, Yuxuan Liu | Date: N/A
2025-11-15 01:11:43,409 - WARNING - root - 【手动下载提示】(无PDF): An Adaptive Hybrid Attention Based Convolutional Neural Net for Intelligent Transportation Object Recognition
	  URL: https://www.semanticscholar.org/paper/269fed3c9a541a4073cde6e205878c2618b2f973
	  Citations: 11 | Authors: Qili Chen, Guangyuan Pan, Lin Zhao, Junfang Fan, Wenbai Chen, A. Zhang | Date: 2023-07-01
2025-11-15 01:11:43,410 - WARNING - root - 【手动下载提示】(无PDF): HEU-Net: hybrid attention residual block-based network with external skip connections for metal corrosion semantic segmentation
	  URL: https://www.semanticscholar.org/paper/80e0948897bc53edf4eba2e31e443010d8a2e19a
	  Citations: 9 | Authors: Tianchen Zhu, Shiqiang Zhu, Tao Zheng, Hongliang Ding, Wei Song, Cunjun Li | Date: 2023-06-22
2025-11-15 01:11:43,410 - WARNING - root - 【手动下载提示】(无PDF): Face-Periocular Cross-Identification via Contrastive Hybrid Attention Vision Transformer
	  URL: https://www.semanticscholar.org/paper/5765cc795e642e1a8e834d6af93cda3ac65a753a
	  Citations: 6 | Authors: Leslie Ching Ow Tiong, D. Sigmund, A. Teoh | Date: N/A
2025-11-15 01:11:43,411 - WARNING - root - 【手动下载提示】(无PDF): Image Super-Resolution with Multi-scale Hybrid Attention
	  URL: https://www.semanticscholar.org/paper/09691760c37f27ddf4d4b7908a348b20b110db6d
	  Citations: 0 | Authors: Ningzhi Wang, Hanyi Shi, Wenna Ruan, Lingbin Zeng | Date: N/A
2025-11-15 01:11:43,411 - WARNING - root - 【手动下载提示】(无PDF): Multi-level wavelet network based on CNN-Transformer hybrid attention for single image deraining
	  URL: https://www.semanticscholar.org/paper/97c485dbb41b68c193decdec5a4618ce3f5b4ee2
	  Citations: 8 | Authors: B. Liu, Siyan Fang | Date: 2023-08-09
2025-11-15 01:11:43,412 - INFO - root - 正在下载: https://www.mdpi.com/1424-8220/23/19/8285/pdf?version=1696663695
2025-11-15 01:11:48,157 - INFO - root - 正在下载: https://www.mdpi.com/1424-8220/23/19/8285/pdf?version=1696663695
2025-11-15 01:11:53,131 - INFO - root - 正在下载: https://www.mdpi.com/1424-8220/23/19/8285/pdf?version=1696663695
2025-11-15 01:11:57,738 - INFO - root - 正在下载: https://www.mdpi.com/1424-8220/23/19/8285/pdf?version=1696663695
2025-11-15 01:12:06,454 - INFO - root - 正在下载: https://www.mdpi.com/1424-8220/23/19/8285/pdf?version=1696663695
2025-11-15 01:12:07,119 - WARNING - root - 下载 A Fast and Robust Lane Detection via Online Re-Parameterization and Hybrid Attention (https://www.mdpi.com/1424-8220/23/19/8285/pdf?version=1696663695) 失败: 403 Client Error: Forbidden for url: https://www.mdpi.com/1424-8220/23/19/8285/pdf?version=1696663695
2025-11-15 01:12:07,120 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\hybrid attention\Dual-view Correlation Hybrid Attention Network for Robust Holistic Mammogram Classification.pdf
2025-11-15 01:12:07,120 - INFO - root - 成功下载 (Semantic Scholar): Dual-view Correlation Hybrid Attention Network for Robust Holistic Mammogram Classification
2025-11-15 01:12:07,121 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\hybrid attention\Stacked Hybrid-Attention and Group Collaborative Learning for Unbiased Scene Graph Generation.pdf
2025-11-15 01:12:07,122 - INFO - root - 成功下载 (Semantic Scholar): Stacked Hybrid-Attention and Group Collaborative Learning for Unbiased Scene Graph Generation
2025-11-15 01:12:07,122 - INFO - root - 正在下载: https://onlinelibrary.wiley.com/doi/pdfdirect/10.1049/ipr2.12934
2025-11-15 01:12:11,853 - INFO - root - 正在下载: https://onlinelibrary.wiley.com/doi/pdfdirect/10.1049/ipr2.12934
2025-11-15 01:12:16,549 - INFO - root - 正在下载: https://onlinelibrary.wiley.com/doi/pdfdirect/10.1049/ipr2.12934
2025-11-15 01:12:21,232 - INFO - root - 正在下载: https://onlinelibrary.wiley.com/doi/pdfdirect/10.1049/ipr2.12934
2025-11-15 01:12:29,921 - INFO - root - 正在下载: https://onlinelibrary.wiley.com/doi/pdfdirect/10.1049/ipr2.12934
2025-11-15 01:12:30,588 - WARNING - root - 下载 Hybrid attention mechanism of feature fusion for medical image segmentation (https://onlinelibrary.wiley.com/doi/pdfdirect/10.1049/ipr2.12934) 失败: 403 Client Error: Forbidden for url: https://onlinelibrary.wiley.com/doi/pdfdirect/10.1049/ipr2.12934
2025-11-15 01:12:30,594 - INFO - root - 正在下载: https://www.mdpi.com/2073-8994/15/10/1947/pdf?version=1697811500
2025-11-15 01:12:35,563 - INFO - root - 正在下载: https://www.mdpi.com/2073-8994/15/10/1947/pdf?version=1697811500
2025-11-15 01:12:40,253 - INFO - root - 正在下载: https://www.mdpi.com/2073-8994/15/10/1947/pdf?version=1697811500
2025-11-15 01:12:44,899 - INFO - root - 正在下载: https://www.mdpi.com/2073-8994/15/10/1947/pdf?version=1697811500
2025-11-15 01:12:53,543 - INFO - root - 正在下载: https://www.mdpi.com/2073-8994/15/10/1947/pdf?version=1697811500
2025-11-15 01:12:54,196 - WARNING - root - 下载 Transformer with Hybrid Attention Mechanism for Stereo Endoscopic Video Super Resolution (https://www.mdpi.com/2073-8994/15/10/1947/pdf?version=1697811500) 失败: 403 Client Error: Forbidden for url: https://www.mdpi.com/2073-8994/15/10/1947/pdf?version=1697811500
2025-11-15 01:12:54,197 - WARNING - root - 【手动下载提示】(无PDF): HHTrack: Hyperspectral Object Tracking Based on Hybrid Attention
	  URL: https://www.semanticscholar.org/paper/c1c5c93f3bd9b99ec5fe55b4c2b5bc29abf4b12a
	  Citations: 1 | Authors: Yuedong Tan, Wenfang Sun, Jieran Yuan, Wenwang Du, Zhe Wang, Nan Mao, Beibei Song | Date: 2023-08-14
2025-11-15 01:12:54,199 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\hybrid attention\Hybridformer_ Improving Squeezeformer with Hybrid Attention and NSR Mechanism.pdf
2025-11-15 01:12:54,201 - INFO - root - 成功下载 (Semantic Scholar): Hybridformer: Improving Squeezeformer with Hybrid Attention and NSR Mechanism
2025-11-15 01:12:54,202 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\hybrid attention\HAC-Net_ A Hybrid Attention-Based Convolutional Neural Network for Highly Accurate Protein-Ligand Bi.pdf
2025-11-15 01:12:54,203 - INFO - root - 成功下载 (Semantic Scholar): HAC-Net: A Hybrid Attention-Based Convolutional Neural Network for Highly Accurate Protein-Ligand Binding Affinity Prediction
2025-11-15 01:12:54,205 - WARNING - root - 【手动下载提示】(无PDF): A hybrid-attention semantic segmentation network for remote sensing interpretation in land-use surveillance
	  URL: https://www.semanticscholar.org/paper/4905315ab99ea19871a65e52be8c8c51624748aa
	  Citations: 49 | Authors: Ning Lv, Zenghui Zhang, Cong Li, Jiaxuan Deng, Tao Su, Chen Chen, Yang Zhou | Date: 2022-02-07
2025-11-15 01:12:54,207 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\hybrid attention\A Hybrid Attention Mechanism for Weakly-Supervised Temporal Action Localization.pdf
2025-11-15 01:12:54,208 - INFO - root - 成功下载 (Semantic Scholar): A Hybrid Attention Mechanism for Weakly-Supervised Temporal Action Localization
2025-11-15 01:12:54,208 - WARNING - root - 【手动下载提示】(无PDF): A hybrid attention-based deep learning approach for wind power prediction
	  URL: https://www.semanticscholar.org/paper/9d591544b9f179d93ad85720e8382e8e1c04c916
	  Citations: 128 | Authors: Zhengjing Ma, Gang Mei | Date: 2022-10-01
2025-11-15 01:12:54,209 - WARNING - root - 【手动下载提示】(无PDF): ColorFormer: Image Colorization via Color Memory Assisted Hybrid-Attention Transformer
	  URL: https://www.semanticscholar.org/paper/33618e85644d6705fd74086c13ee3b7e2a2a466a
	  Citations: 28 | Authors: Xiaozhong Ji, Boyuan Jiang, Donghao Luo, Guangpin Tao, Wenqing Chu, Zhifeng Xie, Chengjie Wang, Ying Tai | Date: N/A
2025-11-15 01:12:54,209 - WARNING - root - 【手动下载提示】(无PDF): HAM: Hybrid attention module in deep convolutional neural networks for image classification
	  URL: https://www.semanticscholar.org/paper/2cfa77f582ee36f2d1fe8869505aa5a71a5f99f3
	  Citations: 92 | Authors: Guoqiang Li, Qianhao Fang, Li Zha, Xin Gao, Nenggan Zheng | Date: 2022-05-01
2025-11-15 01:12:54,210 - WARNING - root - 【手动下载提示】(无PDF): State of health estimation for lithium-ion batteries based on hybrid attention and deep learning
	  URL: https://www.semanticscholar.org/paper/f91dcfd8df66da9bf3649c176869f980b9205115
	  Citations: 91 | Authors: Hongqian Zhao, Zheng Chen, Xing Shu, Jiangwei Shen, Zhenzhen Lei, Yuanjian Zhang | Date: 2022-12-01
2025-11-15 01:12:54,211 - INFO - root - 正在下载: https://downloads.hindawi.com/journals/cin/2022/4189500.pdf
2025-11-15 01:12:59,263 - INFO - root - 正在下载: https://downloads.hindawi.com/journals/cin/2022/4189500.pdf
2025-11-15 01:13:03,925 - INFO - root - 正在下载: https://downloads.hindawi.com/journals/cin/2022/4189500.pdf
2025-11-15 01:13:08,590 - INFO - root - 正在下载: https://downloads.hindawi.com/journals/cin/2022/4189500.pdf
2025-11-15 01:13:17,435 - INFO - root - 正在下载: https://downloads.hindawi.com/journals/cin/2022/4189500.pdf
2025-11-15 01:13:18,243 - WARNING - root - 下载 Aircraft Image Recognition Network Based on Hybrid Attention Mechanism (https://downloads.hindawi.com/journals/cin/2022/4189500.pdf) 失败: 403 Client Error: Forbidden for url: https://downloads.hindawi.com/journals/cin/2022/4189500.pdf
2025-11-15 01:13:18,245 - WARNING - root - 【手动下载提示】(无PDF): Hybrid attention based vehicle trajectory prediction
	  URL: https://www.semanticscholar.org/paper/a2778f12363b79e0a604ddd21a878f3abb0acced
	  Citations: 6 | Authors: Lingyang Wang, Wenping Jiang | Date: 2023-04-06
2025-11-15 01:13:18,248 - WARNING - root - 【手动下载提示】(无PDF): A Hybrid Attention-Based Paralleled Deep Learning model for tool wear prediction
	  URL: https://www.semanticscholar.org/paper/27da7ffd2319f8a2f47eec128894be31f88fc35c
	  Citations: 87 | Authors: Jian Duan, Xi Zhang, Tielin Shi | Date: 2022-08-01
2025-11-15 01:13:18,250 - INFO - root - 正在下载: https://ieeexplore.ieee.org/ielx7/6287639/9668973/09693977.pdf
2025-11-15 01:13:23,112 - INFO - root - 正在下载: https://ieeexplore.ieee.org/ielx7/6287639/9668973/09693977.pdf
2025-11-15 01:13:28,053 - INFO - root - 正在下载: https://ieeexplore.ieee.org/ielx7/6287639/9668973/09693977.pdf
2025-11-15 01:13:32,932 - INFO - root - 正在下载: https://ieeexplore.ieee.org/ielx7/6287639/9668973/09693977.pdf
2025-11-15 01:13:37,085 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\hybrid attention\HANN_ Hybrid Attention Neural Network for Detecting Covid-19 Related Rumors.pdf
2025-11-15 01:13:37,088 - INFO - root - 成功下载 (Semantic Scholar): HANN: Hybrid Attention Neural Network for Detecting Covid-19 Related Rumors
2025-11-15 01:13:37,089 - WARNING - root - 【手动下载提示】(无PDF): Hybrid Attention-Based Prototypical Networks for Few-Shot Sound Classification
	  URL: https://www.semanticscholar.org/paper/e0ddd13d74fe020c8e63eb2ef5a2daa687565953
	  Citations: 15 | Authors: You Wang, D.V. Anderson | Date: 2022-05-23
2025-11-15 01:13:37,089 - INFO - root - 正在下载: https://www.mdpi.com/1424-8220/22/10/3701/pdf?version=1652360619
2025-11-15 01:13:41,714 - INFO - root - 正在下载: https://www.mdpi.com/1424-8220/22/10/3701/pdf?version=1652360619
2025-11-15 01:13:46,390 - INFO - root - 正在下载: https://www.mdpi.com/1424-8220/22/10/3701/pdf?version=1652360619
2025-11-15 01:13:51,098 - INFO - root - 正在下载: https://www.mdpi.com/1424-8220/22/10/3701/pdf?version=1652360619
2025-11-15 01:13:59,828 - INFO - root - 正在下载: https://www.mdpi.com/1424-8220/22/10/3701/pdf?version=1652360619
2025-11-15 01:14:00,481 - WARNING - root - 下载 An Anti-UAV Long-Term Tracking Method with Hybrid Attention Mechanism and Hierarchical Discriminator (https://www.mdpi.com/1424-8220/22/10/3701/pdf?version=1652360619) 失败: 403 Client Error: Forbidden for url: https://www.mdpi.com/1424-8220/22/10/3701/pdf?version=1652360619
2025-11-15 01:14:00,482 - WARNING - root - 【手动下载提示】(无PDF): A Hybrid Attention-Based Deep Neural Network for Simultaneous Multi-Sensor Pruning and Human Activity Recognition
	  URL: https://www.semanticscholar.org/paper/06f82dcfa03d18408410b03b4203fff9bbeceeac
	  Citations: 21 | Authors: Yu Zhou, Zhuo Yang, Xiao Zhang, Yufan Wang | Date: 2022-12-15
2025-11-15 01:14:00,482 - WARNING - root - 【手动下载提示】(无PDF): End-to-End Multilevel Hybrid Attention Framework for Hyperspectral Image Classification
	  URL: https://www.semanticscholar.org/paper/6cbd2101b7faff37d402cc8574c95477af70f3aa
	  Citations: 19 | Authors: Jianhong Xiang, Chen Wei, Minhui Wang, Long Teng | Date: N/A
2025-11-15 01:14:00,483 - WARNING - root - 【手动下载提示】(无PDF): Parallel Deep Learning Algorithms With Hybrid Attention Mechanism for Image Segmentation of Lung Tumors
	  URL: https://www.semanticscholar.org/paper/05c67b073bde463686697eb553576958c8403a60
	  Citations: 88 | Authors: Hexuan Hu, Qingqiu Li, Yun-feng Zhao, Ye Zhang | Date: 2021-04-01
2025-11-15 01:14:00,483 - WARNING - root - 【手动下载提示】(无PDF): Hybrid attention network for semantic segmentation
	  URL: https://www.semanticscholar.org/paper/ee93962e142d4e7fa0b84f5d59970cb30a0b8960
	  Citations: 0 | Authors: Yin Yang, Juan Yang, Ronggui Wang | Date: 2023-10-19
2025-11-15 01:14:00,484 - WARNING - root - 【手动下载提示】(无PDF): A hybrid attention semantic segmentation network for unstructured terrain on Mars
	  URL: https://www.semanticscholar.org/paper/7b71919c1e0adafaa102cf03849b6c21841c8e54
	  Citations: 53 | Authors: Haiqiang Liu, Meibao Yao, Xueming Xiao, Hutao Cui | Date: 2022-08-01
2025-11-15 01:14:00,485 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\hybrid attention\RHA-Net_ An Encoder-Decoder Network with Residual Blocks and Hybrid Attention Mechanisms for Pavemen.pdf
2025-11-15 01:14:00,486 - INFO - root - 成功下载 (Semantic Scholar): RHA-Net: An Encoder-Decoder Network with Residual Blocks and Hybrid Attention Mechanisms for Pavement Crack Segmentation
2025-11-15 01:14:00,490 - INFO - root - 正在下载: https://downloads.hindawi.com/journals/wcmc/2022/5441366.pdf
2025-11-15 01:14:05,204 - INFO - root - 正在下载: https://downloads.hindawi.com/journals/wcmc/2022/5441366.pdf
2025-11-15 01:14:10,515 - INFO - root - 正在下载: https://downloads.hindawi.com/journals/wcmc/2022/5441366.pdf
2025-11-15 01:14:15,508 - INFO - root - 正在下载: https://downloads.hindawi.com/journals/wcmc/2022/5441366.pdf
2025-11-15 01:14:24,313 - INFO - root - 正在下载: https://downloads.hindawi.com/journals/wcmc/2022/5441366.pdf
2025-11-15 01:14:25,037 - WARNING - root - 下载 Classification of Diabetic Retinopathy Based on Multiscale Hybrid Attention Mechanism and Residual Algorithm (https://downloads.hindawi.com/journals/wcmc/2022/5441366.pdf) 失败: 403 Client Error: Forbidden for url: https://downloads.hindawi.com/journals/wcmc/2022/5441366.pdf
2025-11-15 01:14:25,037 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\hybrid attention\HHTrack_ Hyperspectral Object Tracking Using Hybrid Attention.pdf
2025-11-15 01:14:25,038 - INFO - root - 成功下载 (Semantic Scholar): HHTrack: Hyperspectral Object Tracking Using Hybrid Attention
2025-11-15 01:14:25,038 - WARNING - root - 【手动下载提示】(无PDF): Hybrid attention network for image captioning
	  URL: https://www.semanticscholar.org/paper/45acf57fd885b60d858dc6c49da4ff536a901d67
	  Citations: 22 | Authors: Wenhui Jiang, Qin Li, K. Zhan, Yuming Fang, Fei Shen | Date: 2022-05-01
2025-11-15 01:14:25,039 - INFO - root - 正在下载: https://downloads.hindawi.com/journals/wcmc/2022/3301718.pdf
2025-11-15 01:14:30,162 - INFO - root - 正在下载: https://downloads.hindawi.com/journals/wcmc/2022/3301718.pdf
2025-11-15 01:14:34,843 - INFO - root - 正在下载: https://downloads.hindawi.com/journals/wcmc/2022/3301718.pdf
2025-11-15 01:14:40,053 - INFO - root - 正在下载: https://downloads.hindawi.com/journals/wcmc/2022/3301718.pdf
2025-11-15 01:14:49,001 - INFO - root - 正在下载: https://downloads.hindawi.com/journals/wcmc/2022/3301718.pdf
2025-11-15 01:14:49,765 - WARNING - root - 下载 Malicious Code Classification Method Based on Deep Residual Network and Hybrid Attention Mechanism for Edge Security (https://downloads.hindawi.com/journals/wcmc/2022/3301718.pdf) 失败: 403 Client Error: Forbidden for url: https://downloads.hindawi.com/journals/wcmc/2022/3301718.pdf
2025-11-15 01:14:49,767 - INFO - root - 正在下载: https://www.mdpi.com/2079-9292/11/17/2709/pdf?version=1661780513
2025-11-15 01:14:54,514 - INFO - root - 正在下载: https://www.mdpi.com/2079-9292/11/17/2709/pdf?version=1661780513
2025-11-15 01:14:59,266 - INFO - root - 正在下载: https://www.mdpi.com/2079-9292/11/17/2709/pdf?version=1661780513
2025-11-15 01:15:04,021 - INFO - root - 正在下载: https://www.mdpi.com/2079-9292/11/17/2709/pdf?version=1661780513
2025-11-15 01:15:12,931 - INFO - root - 正在下载: https://www.mdpi.com/2079-9292/11/17/2709/pdf?version=1661780513
2025-11-15 01:15:13,613 - WARNING - root - 下载 Occluded Vehicle Detection via Multi-Scale Hybrid Attention Mechanism in the Road Scene (https://www.mdpi.com/2079-9292/11/17/2709/pdf?version=1661780513) 失败: 403 Client Error: Forbidden for url: https://www.mdpi.com/2079-9292/11/17/2709/pdf?version=1661780513
2025-11-15 01:15:13,614 - WARNING - root - 【手动下载提示】(无PDF): Generative adversarial network with hybrid attention and compromised normalization for multi-scene image conversion
	  URL: https://www.semanticscholar.org/paper/1defd0b952f393b189dc61bc421c8ae7dd4df3c2
	  Citations: 11 | Authors: Jinsheng Xiao, Shuhao Zhang, Yuntao Yao, Zhongyuan Wang, Yongqin Zhang, Yuan-fang Wang | Date: 2022-01-29
2025-11-15 01:15:13,615 - INFO - root - 正在下载: https://www.mdpi.com/2227-7390/10/11/1915/pdf?version=1654510435
2025-11-15 01:15:18,232 - INFO - root - 正在下载: https://www.mdpi.com/2227-7390/10/11/1915/pdf?version=1654510435
2025-11-15 01:15:22,845 - INFO - root - 正在下载: https://www.mdpi.com/2227-7390/10/11/1915/pdf?version=1654510435
2025-11-15 01:15:27,461 - INFO - root - 正在下载: https://www.mdpi.com/2227-7390/10/11/1915/pdf?version=1654510435
2025-11-15 01:15:36,088 - INFO - root - 正在下载: https://www.mdpi.com/2227-7390/10/11/1915/pdf?version=1654510435
2025-11-15 01:15:36,975 - WARNING - root - 下载 HA-RoadFormer: Hybrid Attention Transformer with Multi-Branch for Large-Scale High-Resolution Dense Road Segmentation (https://www.mdpi.com/2227-7390/10/11/1915/pdf?version=1654510435) 失败: 403 Client Error: Forbidden for url: https://www.mdpi.com/2227-7390/10/11/1915/pdf?version=1654510435
2025-11-15 01:15:36,975 - INFO - root - 正在下载: https://www.mdpi.com/2079-9292/11/22/3787/pdf?version=1669096288
2025-11-15 01:15:41,871 - INFO - root - 正在下载: https://www.mdpi.com/2079-9292/11/22/3787/pdf?version=1669096288
2025-11-15 01:15:46,536 - INFO - root - 正在下载: https://www.mdpi.com/2079-9292/11/22/3787/pdf?version=1669096288
2025-11-15 01:15:51,175 - INFO - root - 正在下载: https://www.mdpi.com/2079-9292/11/22/3787/pdf?version=1669096288
2025-11-15 01:15:59,826 - INFO - root - 正在下载: https://www.mdpi.com/2079-9292/11/22/3787/pdf?version=1669096288
2025-11-15 01:16:01,062 - WARNING - root - 下载 HA-Unet: A Modified Unet Based on Hybrid Attention for Urban Water Extraction in SAR Images (https://www.mdpi.com/2079-9292/11/22/3787/pdf?version=1669096288) 失败: 403 Client Error: Forbidden for url: https://www.mdpi.com/2079-9292/11/22/3787/pdf?version=1669096288
2025-11-15 01:16:01,062 - WARNING - root - 【手动下载提示】(无PDF): A hybrid attention improved ResNet based fault diagnosis method of wind turbines gearbox
	  URL: https://www.semanticscholar.org/paper/c71d11b59d8a85d413af1dab9337e39e52910774
	  Citations: 161 | Authors: Kai Zhang, B. Tang, Lei Deng, Xiaoli Liu | Date: 2021-05-03
2025-11-15 01:16:01,062 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\hybrid attention\RAIN_ Reinforced Hybrid Attention Inference Network for Motion Forecasting.pdf
2025-11-15 01:16:01,063 - INFO - root - 成功下载 (Semantic Scholar): RAIN: Reinforced Hybrid Attention Inference Network for Motion Forecasting
2025-11-15 01:16:01,063 - WARNING - root - 【手动下载提示】(无PDF): A hybrid attention mechanism for blind automatic modulation classification
	  URL: https://www.semanticscholar.org/paper/f226e86f57129dfa31db5c69c14163b9d3904988
	  Citations: 8 | Authors: Fan Jia, Yueyi Yang, Junyi Zhang, Yong Yang | Date: 2022-04-05
2025-11-15 01:16:01,064 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\hybrid attention\A Hybrid-Attention Nested UNet for Nuclear Segmentation in Histopathological Images.pdf
2025-11-15 01:16:01,064 - INFO - root - 成功下载 (Semantic Scholar): A Hybrid-Attention Nested UNet for Nuclear Segmentation in Histopathological Images
2025-11-15 01:16:01,065 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\hybrid attention\MHA-Net_ Multipath Hybrid Attention Network for Building Footprint Extraction From High-Resolution R.pdf
2025-11-15 01:16:01,065 - INFO - root - 成功下载 (Semantic Scholar): MHA-Net: Multipath Hybrid Attention Network for Building Footprint Extraction From High-Resolution Remote Sensing Imagery
2025-11-15 01:16:01,067 - INFO - root - 正在下载: https://ieeexplore.ieee.org/ielx7/6287639/6514899/09837031.pdf
2025-11-15 01:16:06,959 - INFO - root - 正在下载: https://ieeexplore.ieee.org/ielx7/6287639/6514899/09837031.pdf
2025-11-15 01:16:11,843 - INFO - root - 正在下载: https://ieeexplore.ieee.org/ielx7/6287639/6514899/09837031.pdf
2025-11-15 01:16:17,044 - INFO - root - 正在下载: https://ieeexplore.ieee.org/ielx7/6287639/6514899/09837031.pdf
2025-11-15 01:16:26,625 - INFO - root - 正在下载: https://ieeexplore.ieee.org/ielx7/6287639/6514899/09837031.pdf
2025-11-15 01:16:27,504 - WARNING - root - 下载 Dual-Path Hybrid Attention Network for Monaural Speech Separation (https://ieeexplore.ieee.org/ielx7/6287639/6514899/09837031.pdf) 失败: 418 Client Error: Unknown Code for url: https://ieeexplore.ieee.org/ielx7/6287639/6514899/09837031.pdf
2025-11-15 01:16:27,504 - WARNING - root - 【手动下载提示】(无PDF): Neural machine translation for Indian language pair using hybrid attention mechanism
	  URL: https://www.semanticscholar.org/paper/3479ff37a0bb3858b1761a871b81f4ca3dd26454
	  Citations: 7 | Authors: Basab Nath, Sunita Sarkar, Surajeet Das, Somnath Mukhopadhyay | Date: 2022-02-01
2025-11-15 01:16:27,504 - WARNING - root - 【手动下载提示】(无PDF): Hybrid Attention Fusion Segmentation Network for Diffuse Large B-cell Lymphoma in PET-CT
	  URL: https://www.semanticscholar.org/paper/80c16017651e0fc33b4bb10e2686a582ae119459
	  Citations: 6 | Authors: Shun Chen, Ang Li, Jianxin Chen, Xuguang Zhang, Chong Jiang, Jingyan Xu | Date: 2022-11-01
2025-11-15 01:16:27,505 - WARNING - root - 【手动下载提示】(无PDF): Hybrid attention mechanism for liver tumor segmentation in CT images
	  URL: https://www.semanticscholar.org/paper/9410e41c65c34be9a745cda06f430de0d53084d9
	  Citations: 6 | Authors: Ming Gong, Baixiang Zhao, J. Soraghan, G. D. Caterina, D. Grose | Date: 2022-09-11
2025-11-15 01:16:27,505 - WARNING - root - 【手动下载提示】(无PDF): Two-stream LSTM Network with Hybrid Attention for Vehicle Trajectory Prediction
	  URL: https://www.semanticscholar.org/paper/9d3d3290e715e5027b5cce97e10071ca0a6a06eb
	  Citations: 6 | Authors: Chao Li, Zhanwen Liu, Jiaying Zhang, Yang Wang, Fan Ding, Xiangmo Zhao | Date: 2022-10-08
2025-11-15 01:16:27,506 - INFO - root - 正在下载: https://www.mdpi.com/2072-4292/12/22/3764/pdf?version=1605536539
2025-11-15 01:16:32,147 - INFO - root - 正在下载: https://www.mdpi.com/2072-4292/12/22/3764/pdf?version=1605536539
2025-11-15 01:16:36,797 - INFO - root - 正在下载: https://www.mdpi.com/2072-4292/12/22/3764/pdf?version=1605536539
2025-11-15 01:16:41,599 - INFO - root - 正在下载: https://www.mdpi.com/2072-4292/12/22/3764/pdf?version=1605536539
2025-11-15 01:16:50,294 - INFO - root - 正在下载: https://www.mdpi.com/2072-4292/12/22/3764/pdf?version=1605536539
2025-11-15 01:16:50,955 - WARNING - root - 下载 A Hybrid Attention-Aware Fusion Network (HAFNet) for Building Extraction from High-Resolution Imagery and LiDAR Data (https://www.mdpi.com/2072-4292/12/22/3764/pdf?version=1605536539) 失败: 403 Client Error: Forbidden for url: https://www.mdpi.com/2072-4292/12/22/3764/pdf?version=1605536539
2025-11-15 01:16:50,956 - WARNING - root - 【手动下载提示】(无PDF): DA-DETR: Domain Adaptive Detection Transformer by Hybrid Attention
	  URL: https://www.semanticscholar.org/paper/c0f715596b2f557806c2de2404cf9a0ad5781cef
	  Citations: 33 | Authors: Jingyi Zhang, Jiaxing Huang, Zhipeng Luo, Gongjie Zhang, Shijian Lu | Date: N/A
2025-11-15 01:16:50,959 - INFO - root - 正在下载: https://www.mdpi.com/1424-8220/21/6/2003/pdf?version=1615879962
2025-11-15 01:16:55,615 - INFO - root - 正在下载: https://www.mdpi.com/1424-8220/21/6/2003/pdf?version=1615879962
2025-11-15 01:17:00,270 - INFO - root - 正在下载: https://www.mdpi.com/1424-8220/21/6/2003/pdf?version=1615879962
2025-11-15 01:17:05,060 - INFO - root - 正在下载: https://www.mdpi.com/1424-8220/21/6/2003/pdf?version=1615879962
2025-11-15 01:17:13,782 - INFO - root - 正在下载: https://www.mdpi.com/1424-8220/21/6/2003/pdf?version=1615879962
2025-11-15 01:17:15,721 - WARNING - root - 下载 Hybrid Attention Cascade Network for Facial Expression Recognition (https://www.mdpi.com/1424-8220/21/6/2003/pdf?version=1615879962) 失败: 403 Client Error: Forbidden for url: https://www.mdpi.com/1424-8220/21/6/2003/pdf?version=1615879962
2025-11-15 01:17:15,723 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\hybrid attention\HADLN_ Hybrid Attention-Based Deep Learning Network for Automated Arrhythmia Classification.pdf
2025-11-15 01:17:15,724 - INFO - root - 成功下载 (Semantic Scholar): HADLN: Hybrid Attention-Based Deep Learning Network for Automated Arrhythmia Classification
2025-11-15 01:17:15,726 - INFO - root - 正在下载: https://www.mdpi.com/2072-4292/13/10/1962/pdf?version=1621496001
2025-11-15 01:17:20,357 - INFO - root - 正在下载: https://www.mdpi.com/2072-4292/13/10/1962/pdf?version=1621496001
2025-11-15 01:17:24,996 - INFO - root - 正在下载: https://www.mdpi.com/2072-4292/13/10/1962/pdf?version=1621496001
2025-11-15 01:17:29,606 - INFO - root - 正在下载: https://www.mdpi.com/2072-4292/13/10/1962/pdf?version=1621496001
2025-11-15 01:17:38,272 - INFO - root - 正在下载: https://www.mdpi.com/2072-4292/13/10/1962/pdf?version=1621496001
2025-11-15 01:17:38,908 - WARNING - root - 下载 Hybrid Attention Based Residual Network for Pansharpening (https://www.mdpi.com/2072-4292/13/10/1962/pdf?version=1621496001) 失败: 403 Client Error: Forbidden for url: https://www.mdpi.com/2072-4292/13/10/1962/pdf?version=1621496001
2025-11-15 01:17:38,908 - INFO - root - 检索到 100 篇论文（包括待手动下载的），开始总结...
2025-11-15 01:17:38,909 - INFO - root - --- 开始论文总结阶段 ---
2025-11-15 01:17:38,909 - INFO - root - 跳过总结 (手动下载): An Instrument Indication Acquisition Algorithm Based on Lightweight Deep Convolutional Neural Network and Hybrid Attention Fine-Grained Features
2025-11-15 01:17:38,910 - INFO - root - 跳过总结 (手动下载): Enhancing ASD classification through hybrid attention-based learning of facial features
2025-11-15 01:17:38,910 - INFO - root - 跳过总结 (手动下载): Dual-Hybrid Attention Network for Specular Highlight Removal
2025-11-15 01:17:38,910 - INFO - root - 跳过总结 (手动下载): HyA-GAN: remote sensing image cloud removal based on hybrid attention generation adversarial network
2025-11-15 01:17:38,912 - INFO - root - 跳过总结 (手动下载): Radar Signal Recognition Based on CNN With a Hybrid Attention Mechanism and Skip Feature Aggregation
2025-11-15 01:17:38,912 - INFO - root - 跳过总结 (手动下载): Hybrid Attention-Aware Transformer Network Collaborative Multiscale Feature Alignment for Building Change Detection
2025-11-15 01:17:38,912 - INFO - root - 跳过总结 (手动下载): Probabilistic Multienergy Load Forecasting Based on Hybrid Attention-Enabled Transformer Network and Gaussian Process-Aided Residual Learning
2025-11-15 01:17:38,913 - INFO - root - 跳过已处理论文 Hybrid Attention Fusion Embedded in Transformer for Remote Sensing Image Semantic Segmentation：D:\ChatPaper\api_downloads\hybrid attention\Hybrid Attention Fusion Embedded in Transformer for Remote Sensing Image Semantic Segmentation.pdf
2025-11-15 01:17:38,913 - INFO - root - 跳过总结 (手动下载): Advancing Ocular Imaging: A Hybrid Attention Mechanism-Based U-Net Model for Precise Segmentation of Sub-Retinal Layers in OCT Images
2025-11-15 01:17:38,913 - INFO - root - 跳过总结 (手动下载): Enhancing Time Series Product Demand Forecasting With Hybrid Attention-Based Deep Learning Models
2025-11-15 01:17:38,914 - INFO - root - 跳过已处理论文 YOLO Algorithm With Hybrid Attention Feature Pyramid Network for Solder Joint Defect Detection：D:\ChatPaper\api_downloads\hybrid attention\YOLO Algorithm With Hybrid Attention Feature Pyramid Network for Solder Joint Defect Detection.pdf
2025-11-15 01:17:38,915 - INFO - root - 跳过总结 (手动下载): A novel approach for bearings multiclass fault diagnosis fusing multiscale deep convolution and hybrid attention networks
2025-11-15 01:17:38,915 - INFO - root - 跳过总结 (手动下载): Drone-HAT: Hybrid Attention Transformer for Complex Action Recognition in Drone Surveillance Videos
2025-11-15 01:17:38,916 - INFO - root - 跳过总结 (手动下载): Dense Hybrid Attention Network for Palmprint Image Super-Resolution
2025-11-15 01:17:38,917 - INFO - root - 跳过已处理论文 Frequency Enhanced Hybrid Attention Network for Sequential Recommendation：D:\ChatPaper\api_downloads\hybrid attention\Frequency Enhanced Hybrid Attention Network for Sequential Recommendation.pdf
2025-11-15 01:17:38,917 - INFO - root - 跳过总结 (手动下载): A Multiscale Hybrid Attention Networks Based on Multiview Images for the Diagnosis of Parkinson’s Disease
2025-11-15 01:17:38,918 - INFO - root - 跳过总结 (手动下载): Hybrid Attention Feature Refinement Network for Lightweight Image Super-Resolution in Metaverse Immersive Display
2025-11-15 01:17:38,918 - INFO - root - 跳过已处理论文 HAT: Hybrid Attention Transformer for Image Restoration：D:\ChatPaper\api_downloads\hybrid attention\HAT_ Hybrid Attention Transformer for Image Restoration.pdf
2025-11-15 01:17:38,920 - INFO - root - 跳过总结 (手动下载): Dual Hybrid Attention Mechanism-Based U-Net for Building Segmentation in Remote Sensing Images
2025-11-15 01:17:38,925 - INFO - root - 跳过总结 (手动下载): Abundance Matrix Correlation Analysis Network Based on Hierarchical Multihead Self-Cross-Hybrid Attention for Hyperspectral Change Detection
2025-11-15 01:17:38,925 - INFO - root - 跳过总结 (手动下载): Hybrid Attention Module and Transformer Based Fuze DRFM Jamming Signal Recognition
2025-11-15 01:17:38,926 - INFO - root - 跳过总结 (手动下载): DenseNet model incorporating hybrid attention mechanisms and clinical features for pancreatic cystic tumor classification
2025-11-15 01:17:38,926 - INFO - root - 跳过总结 (手动下载): HA-Net: a SAR image ship detector based on hybrid attention
2025-11-15 01:17:38,927 - INFO - root - 跳过已处理论文 Multi-scale deep residual shrinkage networks with a hybrid attention mechanism for rolling bearing fault diagnosis：D:\ChatPaper\api_downloads\hybrid attention\Multi-scale deep residual shrinkage networks with a hybrid attention mechanism for rolling bearing f.pdf
2025-11-15 01:17:38,928 - INFO - root - 跳过总结 (手动下载): Towards Effective Author Name Disambiguation by Hybrid Attention
2025-11-15 01:17:38,928 - INFO - root - 跳过总结 (手动下载): Actor-Hybrid-Attention-Critic for Multi-Logistic Robots Path Planning
2025-11-15 01:17:38,928 - INFO - root - 跳过总结 (手动下载): Deep Hashing Network With Hybrid Attention and Adaptive Weighting for Image Retrieval
2025-11-15 01:17:38,930 - INFO - root - 跳过总结 (手动下载): Multi-modal bilinear fusion with hybrid attention mechanism for multi-label skin lesion classification
2025-11-15 01:17:38,931 - INFO - root - 跳过总结 (手动下载): AHANet: Adaptive Hybrid Attention Network for Alzheimer’s Disease Classification Using Brain Magnetic Resonance Imaging
2025-11-15 01:17:38,933 - INFO - root - 跳过已处理论文 Physics Inspired Hybrid Attention for SAR Target Recognition：D:\ChatPaper\api_downloads\hybrid attention\Physics Inspired Hybrid Attention for SAR Target Recognition.pdf
2025-11-15 01:17:38,933 - INFO - root - 跳过总结 (手动下载): WHEN: A Wavelet-DTW Hybrid Attention Network for Heterogeneous Time Series Analysis
2025-11-15 01:17:38,933 - INFO - root - 跳过已处理论文 Fine-grained image classification method based on hybrid attention module：D:\ChatPaper\api_downloads\hybrid attention\Fine-grained image classification method based on hybrid attention module.pdf
2025-11-15 01:17:38,934 - INFO - root - 跳过总结 (手动下载): Hybrid Attention-Aware Learning Network for Facial Expression Recognition in the Wild
2025-11-15 01:17:38,934 - INFO - root - 跳过已处理论文 Hybrid Attention-Based U-Shaped Network for Remote Sensing Image Super-Resolution：D:\ChatPaper\api_downloads\hybrid attention\Hybrid Attention-Based U-Shaped Network for Remote Sensing Image Super-Resolution.pdf
2025-11-15 01:17:38,935 - INFO - root - 跳过总结 (手动下载): Smart Contract Vulnerability Detection Based on Hybrid Attention Mechanism Model
2025-11-15 01:17:38,935 - INFO - root - 跳过总结 (手动下载): Mutiscale Hybrid Attention Transformer for Remote Sensing Image Pansharpening
2025-11-15 01:17:38,935 - INFO - root - 跳过总结 (手动下载): Multimodal emotion recognition based on audio and text by using hybrid attention networks
2025-11-15 01:17:38,936 - INFO - root - 跳过总结 (手动下载): A Novel Approach for Surface Integrity Monitoring in High-Energy Nanosecond-Pulse Laser Shock Peening: Acoustic Emission and Hybrid-Attention CNN
2025-11-15 01:17:38,936 - INFO - root - 跳过总结 (手动下载): Intention-convolution and hybrid-attention network for vehicle trajectory prediction
2025-11-15 01:17:38,941 - INFO - root - 跳过总结 (手动下载): Hybrid Attention Network for Epileptic EEG Classification
2025-11-15 01:17:38,943 - INFO - root - 跳过总结 (手动下载): PHAM-YOLO: A Parallel Hybrid Attention Mechanism Network for Defect Detection of Meter in Substation
2025-11-15 01:17:38,944 - INFO - root - 跳过总结 (手动下载): Defect Detection in Steel Using a Hybrid Attention Network
2025-11-15 01:17:38,944 - INFO - root - 跳过总结 (手动下载): Hybrid Attention and Motion Constraint for Anomaly Detection in Crowded Scenes
2025-11-15 01:17:38,945 - INFO - root - 跳过已处理论文 Hybrid Attention-Based Prototypical Networks for Noisy Few-Shot Relation Classification：D:\ChatPaper\api_downloads\hybrid attention\Hybrid Attention-Based Prototypical Networks for Noisy Few-Shot Relation Classification.pdf
2025-11-15 01:17:38,946 - INFO - root - 跳过总结 (手动下载): Hybrid Attention-Based Encoder-Decoder Fully Convolutional Network for PolSAR Image Classification
2025-11-15 01:17:38,948 - INFO - root - 跳过总结 (手动下载): Hybrid Attention Compression Network With Light Graph Attention Module for Remote Sensing Images
2025-11-15 01:17:38,948 - INFO - root - 跳过总结 (手动下载): An Adaptive Hybrid Attention Based Convolutional Neural Net for Intelligent Transportation Object Recognition
2025-11-15 01:17:38,948 - INFO - root - 跳过总结 (手动下载): HEU-Net: hybrid attention residual block-based network with external skip connections for metal corrosion semantic segmentation
2025-11-15 01:17:38,950 - INFO - root - 跳过总结 (手动下载): Face-Periocular Cross-Identification via Contrastive Hybrid Attention Vision Transformer
2025-11-15 01:17:38,950 - INFO - root - 跳过总结 (手动下载): Image Super-Resolution with Multi-scale Hybrid Attention
2025-11-15 01:17:38,950 - INFO - root - 跳过总结 (手动下载): Multi-level wavelet network based on CNN-Transformer hybrid attention for single image deraining
2025-11-15 01:17:38,950 - INFO - root - 跳过总结 (手动下载): A Fast and Robust Lane Detection via Online Re-Parameterization and Hybrid Attention
2025-11-15 01:17:38,951 - INFO - root - 跳过已处理论文 Dual-view Correlation Hybrid Attention Network for Robust Holistic Mammogram Classification：D:\ChatPaper\api_downloads\hybrid attention\Dual-view Correlation Hybrid Attention Network for Robust Holistic Mammogram Classification.pdf
2025-11-15 01:17:38,951 - INFO - root - 跳过已处理论文 Stacked Hybrid-Attention and Group Collaborative Learning for Unbiased Scene Graph Generation：D:\ChatPaper\api_downloads\hybrid attention\Stacked Hybrid-Attention and Group Collaborative Learning for Unbiased Scene Graph Generation.pdf
2025-11-15 01:17:38,952 - INFO - root - 跳过总结 (手动下载): Hybrid attention mechanism of feature fusion for medical image segmentation
2025-11-15 01:17:38,952 - INFO - root - 跳过总结 (手动下载): Transformer with Hybrid Attention Mechanism for Stereo Endoscopic Video Super Resolution
2025-11-15 01:17:38,952 - INFO - root - 跳过总结 (手动下载): HHTrack: Hyperspectral Object Tracking Based on Hybrid Attention
2025-11-15 01:17:38,952 - INFO - root - 跳过已处理论文 Hybridformer: Improving Squeezeformer with Hybrid Attention and NSR Mechanism：D:\ChatPaper\api_downloads\hybrid attention\Hybridformer_ Improving Squeezeformer with Hybrid Attention and NSR Mechanism.pdf
2025-11-15 01:17:38,953 - INFO - root - 跳过已处理论文 HAC-Net: A Hybrid Attention-Based Convolutional Neural Network for Highly Accurate Protein-Ligand Binding Affinity Prediction：D:\ChatPaper\api_downloads\hybrid attention\HAC-Net_ A Hybrid Attention-Based Convolutional Neural Network for Highly Accurate Protein-Ligand Bi.pdf
2025-11-15 01:17:38,957 - INFO - root - 跳过总结 (手动下载): A hybrid-attention semantic segmentation network for remote sensing interpretation in land-use surveillance
2025-11-15 01:17:38,958 - INFO - root - 跳过已处理论文 A Hybrid Attention Mechanism for Weakly-Supervised Temporal Action Localization：D:\ChatPaper\api_downloads\hybrid attention\A Hybrid Attention Mechanism for Weakly-Supervised Temporal Action Localization.pdf
2025-11-15 01:17:38,958 - INFO - root - 跳过总结 (手动下载): A hybrid attention-based deep learning approach for wind power prediction
2025-11-15 01:17:38,959 - INFO - root - 跳过总结 (手动下载): ColorFormer: Image Colorization via Color Memory Assisted Hybrid-Attention Transformer
2025-11-15 01:17:38,959 - INFO - root - 跳过总结 (手动下载): HAM: Hybrid attention module in deep convolutional neural networks for image classification
2025-11-15 01:17:38,960 - INFO - root - 跳过总结 (手动下载): State of health estimation for lithium-ion batteries based on hybrid attention and deep learning
2025-11-15 01:17:38,960 - INFO - root - 跳过总结 (手动下载): Aircraft Image Recognition Network Based on Hybrid Attention Mechanism
2025-11-15 01:17:38,960 - INFO - root - 跳过总结 (手动下载): Hybrid attention based vehicle trajectory prediction
2025-11-15 01:17:38,960 - INFO - root - 跳过总结 (手动下载): A Hybrid Attention-Based Paralleled Deep Learning model for tool wear prediction
2025-11-15 01:17:38,961 - INFO - root - 正在总结论文 69/100: HANN: Hybrid Attention Neural Network for Detecting Covid-19 Related Rumors
2025-11-15 01:19:49,087 - INFO - root - 正在提取论文图片到目录: ./export\hybrid attention\images\HANN_ Hybrid Attention Neural Network for Detecting Covid-19 Related Rumors
2025-11-15 01:19:49,358 - INFO - root - 已保存图片 1/10：./export\hybrid attention\images\HANN_ Hybrid Attention Neural Network for Detecting Covid-19 Related Rumors\figure_1_page11.jpeg
2025-11-15 01:19:49,398 - INFO - root - 已保存图片 2/10：./export\hybrid attention\images\HANN_ Hybrid Attention Neural Network for Detecting Covid-19 Related Rumors\figure_2_page9.jpeg
2025-11-15 01:19:49,418 - INFO - root - 已保存图片 3/10：./export\hybrid attention\images\HANN_ Hybrid Attention Neural Network for Detecting Covid-19 Related Rumors\figure_3_page7.jpeg
2025-11-15 01:19:49,466 - INFO - root - 已保存图片 4/10：./export\hybrid attention\images\HANN_ Hybrid Attention Neural Network for Detecting Covid-19 Related Rumors\figure_4_page7.png
2025-11-15 01:19:49,517 - INFO - root - 已保存图片 5/10：./export\hybrid attention\images\HANN_ Hybrid Attention Neural Network for Detecting Covid-19 Related Rumors\figure_5_page6.jpeg
2025-11-15 01:19:49,562 - INFO - root - 已保存图片 6/10：./export\hybrid attention\images\HANN_ Hybrid Attention Neural Network for Detecting Covid-19 Related Rumors\figure_6_page9.jpeg
2025-11-15 01:19:49,611 - INFO - root - 已保存图片 7/10：./export\hybrid attention\images\HANN_ Hybrid Attention Neural Network for Detecting Covid-19 Related Rumors\figure_7_page4.png
2025-11-15 01:19:49,640 - INFO - root - 已保存图片 8/10：./export\hybrid attention\images\HANN_ Hybrid Attention Neural Network for Detecting Covid-19 Related Rumors\figure_8_page11.jpeg
2025-11-15 01:19:49,666 - INFO - root - 已保存图片 9/10：./export\hybrid attention\images\HANN_ Hybrid Attention Neural Network for Detecting Covid-19 Related Rumors\figure_9_page11.jpeg
2025-11-15 01:19:49,709 - INFO - root - 已保存图片 10/10：./export\hybrid attention\images\HANN_ Hybrid Attention Neural Network for Detecting Covid-19 Related Rumors\figure_10_page3.png
2025-11-15 01:19:49,713 - INFO - root - 成功添加图片 1：./export\hybrid attention\images\HANN_ Hybrid Attention Neural Network for Detecting Covid-19 Related Rumors\figure_1_page11.jpeg
2025-11-15 01:19:49,713 - INFO - root - 成功添加图片 2：./export\hybrid attention\images\HANN_ Hybrid Attention Neural Network for Detecting Covid-19 Related Rumors\figure_2_page9.jpeg
2025-11-15 01:19:49,713 - INFO - root - 成功添加图片 3：./export\hybrid attention\images\HANN_ Hybrid Attention Neural Network for Detecting Covid-19 Related Rumors\figure_3_page7.jpeg
2025-11-15 01:19:49,713 - INFO - root - 成功添加图片 4：./export\hybrid attention\images\HANN_ Hybrid Attention Neural Network for Detecting Covid-19 Related Rumors\figure_4_page7.png
2025-11-15 01:19:49,714 - INFO - root - 成功添加图片 5：./export\hybrid attention\images\HANN_ Hybrid Attention Neural Network for Detecting Covid-19 Related Rumors\figure_5_page6.jpeg
2025-11-15 01:19:49,714 - INFO - root - 成功添加图片 6：./export\hybrid attention\images\HANN_ Hybrid Attention Neural Network for Detecting Covid-19 Related Rumors\figure_6_page9.jpeg
2025-11-15 01:19:49,714 - INFO - root - 成功添加图片 7：./export\hybrid attention\images\HANN_ Hybrid Attention Neural Network for Detecting Covid-19 Related Rumors\figure_7_page4.png
2025-11-15 01:19:49,714 - INFO - root - 成功添加图片 8：./export\hybrid attention\images\HANN_ Hybrid Attention Neural Network for Detecting Covid-19 Related Rumors\figure_8_page11.jpeg
2025-11-15 01:19:49,715 - INFO - root - 成功添加图片 9：./export\hybrid attention\images\HANN_ Hybrid Attention Neural Network for Detecting Covid-19 Related Rumors\figure_9_page11.jpeg
2025-11-15 01:19:49,715 - INFO - root - 成功添加图片 10：./export\hybrid attention\images\HANN_ Hybrid Attention Neural Network for Detecting Covid-19 Related Rumors\figure_10_page3.png
2025-11-15 01:19:49,719 - INFO - root - 论文《HANN: Hybrid Attention Neural Network for Detecting Covid-19 Related Rumors》的分析已保存到 ./export\hybrid attention\HANN_ Hybrid Attention Neural Network for Detecting Covid-19 Related Rumors.md
2025-11-15 01:19:49,721 - INFO - root - 跳过总结 (手动下载): Hybrid Attention-Based Prototypical Networks for Few-Shot Sound Classification
2025-11-15 01:19:49,722 - INFO - root - 跳过总结 (手动下载): An Anti-UAV Long-Term Tracking Method with Hybrid Attention Mechanism and Hierarchical Discriminator
2025-11-15 01:19:49,722 - INFO - root - 跳过总结 (手动下载): A Hybrid Attention-Based Deep Neural Network for Simultaneous Multi-Sensor Pruning and Human Activity Recognition
2025-11-15 01:19:49,725 - INFO - root - 跳过总结 (手动下载): End-to-End Multilevel Hybrid Attention Framework for Hyperspectral Image Classification
2025-11-15 01:19:49,725 - INFO - root - 跳过总结 (手动下载): Parallel Deep Learning Algorithms With Hybrid Attention Mechanism for Image Segmentation of Lung Tumors
2025-11-15 01:19:49,725 - INFO - root - 跳过总结 (手动下载): Hybrid attention network for semantic segmentation
2025-11-15 01:19:49,726 - INFO - root - 跳过总结 (手动下载): A hybrid attention semantic segmentation network for unstructured terrain on Mars
2025-11-15 01:19:49,727 - INFO - root - 跳过已处理论文 RHA-Net: An Encoder-Decoder Network with Residual Blocks and Hybrid Attention Mechanisms for Pavement Crack Segmentation：D:\ChatPaper\api_downloads\hybrid attention\RHA-Net_ An Encoder-Decoder Network with Residual Blocks and Hybrid Attention Mechanisms for Pavemen.pdf
2025-11-15 01:19:49,727 - INFO - root - 跳过总结 (手动下载): Classification of Diabetic Retinopathy Based on Multiscale Hybrid Attention Mechanism and Residual Algorithm
2025-11-15 01:19:49,728 - INFO - root - 跳过已处理论文 HHTrack: Hyperspectral Object Tracking Using Hybrid Attention：D:\ChatPaper\api_downloads\hybrid attention\HHTrack_ Hyperspectral Object Tracking Using Hybrid Attention.pdf
2025-11-15 01:19:49,728 - INFO - root - 跳过总结 (手动下载): Hybrid attention network for image captioning
2025-11-15 01:19:49,728 - INFO - root - 跳过总结 (手动下载): Malicious Code Classification Method Based on Deep Residual Network and Hybrid Attention Mechanism for Edge Security
2025-11-15 01:19:49,729 - INFO - root - 跳过总结 (手动下载): Occluded Vehicle Detection via Multi-Scale Hybrid Attention Mechanism in the Road Scene
2025-11-15 01:19:49,729 - INFO - root - 跳过总结 (手动下载): Generative adversarial network with hybrid attention and compromised normalization for multi-scene image conversion
2025-11-15 01:19:49,729 - INFO - root - 跳过总结 (手动下载): HA-RoadFormer: Hybrid Attention Transformer with Multi-Branch for Large-Scale High-Resolution Dense Road Segmentation
2025-11-15 01:19:49,730 - INFO - root - 跳过总结 (手动下载): HA-Unet: A Modified Unet Based on Hybrid Attention for Urban Water Extraction in SAR Images
2025-11-15 01:19:49,730 - INFO - root - 跳过总结 (手动下载): A hybrid attention improved ResNet based fault diagnosis method of wind turbines gearbox
2025-11-15 01:19:49,730 - INFO - root - 跳过已处理论文 RAIN: Reinforced Hybrid Attention Inference Network for Motion Forecasting：D:\ChatPaper\api_downloads\hybrid attention\RAIN_ Reinforced Hybrid Attention Inference Network for Motion Forecasting.pdf
2025-11-15 01:19:49,731 - INFO - root - 跳过总结 (手动下载): A hybrid attention mechanism for blind automatic modulation classification
2025-11-15 01:19:49,731 - INFO - root - 跳过已处理论文 A Hybrid-Attention Nested UNet for Nuclear Segmentation in Histopathological Images：D:\ChatPaper\api_downloads\hybrid attention\A Hybrid-Attention Nested UNet for Nuclear Segmentation in Histopathological Images.pdf
2025-11-15 01:19:49,731 - INFO - root - 跳过已处理论文 MHA-Net: Multipath Hybrid Attention Network for Building Footprint Extraction From High-Resolution Remote Sensing Imagery：D:\ChatPaper\api_downloads\hybrid attention\MHA-Net_ Multipath Hybrid Attention Network for Building Footprint Extraction From High-Resolution R.pdf
2025-11-15 01:19:49,733 - INFO - root - 跳过总结 (手动下载): Dual-Path Hybrid Attention Network for Monaural Speech Separation
2025-11-15 01:19:49,733 - INFO - root - 跳过总结 (手动下载): Neural machine translation for Indian language pair using hybrid attention mechanism
2025-11-15 01:19:49,733 - INFO - root - 跳过总结 (手动下载): Hybrid Attention Fusion Segmentation Network for Diffuse Large B-cell Lymphoma in PET-CT
2025-11-15 01:19:49,734 - INFO - root - 跳过总结 (手动下载): Hybrid attention mechanism for liver tumor segmentation in CT images
2025-11-15 01:19:49,737 - INFO - root - 跳过总结 (手动下载): Two-stream LSTM Network with Hybrid Attention for Vehicle Trajectory Prediction
2025-11-15 01:19:49,738 - INFO - root - 跳过总结 (手动下载): A Hybrid Attention-Aware Fusion Network (HAFNet) for Building Extraction from High-Resolution Imagery and LiDAR Data
2025-11-15 01:19:49,739 - INFO - root - 跳过总结 (手动下载): DA-DETR: Domain Adaptive Detection Transformer by Hybrid Attention
2025-11-15 01:19:49,739 - INFO - root - 跳过总结 (手动下载): Hybrid Attention Cascade Network for Facial Expression Recognition
2025-11-15 01:19:49,739 - INFO - root - 跳过已处理论文 HADLN: Hybrid Attention-Based Deep Learning Network for Automated Arrhythmia Classification：D:\ChatPaper\api_downloads\hybrid attention\HADLN_ Hybrid Attention-Based Deep Learning Network for Automated Arrhythmia Classification.pdf
2025-11-15 01:19:49,740 - INFO - root - 跳过总结 (手动下载): Hybrid Attention Based Residual Network for Pansharpening
2025-11-15 01:19:49,740 - INFO - root - --- 论文总结阶段结束 ---
2025-11-15 01:19:49,740 - INFO - root - --- 开始生成 Excel 报告 (包含 100 篇论文) ---
2025-11-15 01:19:49,767 - INFO - root - 检测到已存在的 Excel 文件: export\hybrid_attention_summary.xlsx。正在追加...
2025-11-15 01:19:49,806 - INFO - root - 合并后: 102 条记录 (新增 80 条, 更新 20 条)
2025-11-15 01:19:49,932 - INFO - root - 成功保存 Excel: export\hybrid_attention_summary.xlsx
2025-11-15 01:19:49,932 - INFO - root - 已生成或更新汇总 Excel 表格: export\hybrid_attention_summary.xlsx
2025-11-15 01:19:49,933 - INFO - root - 总运行时间: 677.60 seconds
2025-11-15 01:21:54,438 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-15 01:21:54,439 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-15 01:21:54,441 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-15 01:21:57,566 - INFO - root - LLMClientManager: 指定使用客户端: Deepseek
2025-11-15 01:21:57,567 - INFO - root - DeepSeekClient: API key found: 9f9e270e-b...
2025-11-15 01:21:57,567 - INFO - root - DeepSeekClient: 使用模式: 火山引擎
2025-11-15 01:21:57,567 - INFO - root - DeepSeekClient: 模型名称: deepseek-v3-1-terminus
2025-11-15 01:22:00,606 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-15 01:22:00,637 - INFO - root - DeepSeekClient: initialized successfully with model deepseek-v3-1-terminus
2025-11-15 01:22:00,637 - INFO - root - LLMClientManager: DeepSeek 客户端初始化成功
2025-11-15 01:22:00,638 - INFO - root - LLMClientManager: switched to DeepSeek client (case-insensitive match)
2025-11-15 01:22:00,638 - INFO - root - 已手动切换到 LLM 客户端: Deepseek
2025-11-15 01:22:00,638 - INFO - root - 使用 LLM 模型: deepseek-v3-1-terminus
2025-11-15 01:22:00,639 - INFO - root - 可用客户端: ['DeepSeek']
2025-11-15 01:22:00,640 - INFO - root - === 运行配置 ===
2025-11-15 01:22:00,641 - INFO - root - 处理模式: Semantic Scholar 高引用搜索 (API)
2025-11-15 01:22:00,642 - INFO - root - 查询 (关键词): CVPR
2025-11-15 01:22:00,642 - INFO - root - 关键词 (用于保存): CVPR
2025-11-15 01:22:00,644 - INFO - root - 排序: citationCount:desc
2025-11-15 01:22:00,644 - INFO - root - 最大处理数量: 100
2025-11-15 01:22:00,645 - INFO - root - 保存图片: 是
2025-11-15 01:22:00,645 - INFO - root - 输出语言: 中文
2025-11-15 01:22:00,647 - INFO - root - 强制重新处理: 否
2025-11-15 01:22:00,647 - INFO - root - LLM 客户端: Deepseek
2025-11-15 01:22:00,647 - INFO - root - ====================
2025-11-15 01:22:00,647 - INFO - root - 正在使用检索策略: semantic
2025-11-15 01:22:00,648 - INFO - root - 使用 Semantic Scholar 高引用搜索模式 (API)
2025-11-15 01:22:00,653 - INFO - root - Semantic API 查询: query=CVPR, limit=100, sort=citationCount:desc
2025-11-15 01:22:00,653 - INFO - root - 正在调用 Semantic Scholar API...
2025-11-15 01:22:03,026 - INFO - root - 正在下载: https://arxiv.org/pdf/2305.17382
2025-11-15 01:22:05,095 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\CVPR\A Zero-_Few-Shot Anomaly Classification and Segmentation Method for CVPR 2023 VAND Workshop Challeng.pdf
2025-11-15 01:22:05,100 - INFO - root - 成功下载 (Semantic Scholar): A Zero-/Few-Shot Anomaly Classification and Segmentation Method for CVPR 2023 VAND Workshop Challenge Tracks 1&2: 1st Place on Zero-shot AD and 4th Place on Few-shot AD
2025-11-15 01:22:05,101 - INFO - root - 正在下载: https://arxiv.org/pdf/2404.10378
2025-11-15 01:22:07,256 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\CVPR\Second Edition FRCSyn Challenge at CVPR 2024_ Face Recognition Challenge in the Era of Synthetic Dat.pdf
2025-11-15 01:22:07,260 - INFO - root - 成功下载 (Semantic Scholar): Second Edition FRCSyn Challenge at CVPR 2024: Face Recognition Challenge in the Era of Synthetic Data
2025-11-15 01:22:07,260 - WARNING - root - 【手动下载提示】(无PDF): Multi-Modal UAV Detection, Classification and Tracking Algorithm - Technical Report for CVPR 2024 UG2 Challenge
	  URL: https://www.semanticscholar.org/paper/7dab3fcda6a1b1d2178c4483e74d29f7294f6c02
	  Citations: 15 | Authors: Tianchen Deng, Yi Zhou, Wenhua Wu, Mingrui Li, Jingwei Huang, Shuhong Liu, Yanzeng Song, Hao Zuo, Yanbo Wang, Yutao Yue, Hesheng Wang, Weidong Chen | Date: 2024-05-26
2025-11-15 01:22:07,260 - WARNING - root - 【手动下载提示】(无PDF): CVPR 2023 Text Guided Video Editing Competition
	  URL: https://www.semanticscholar.org/paper/f8e63df903d95f08839016db3d59d07af7f1275f
	  Citations: 44 | Authors: Jay Zhangjie Wu, Xiuyu Li, Difei Gao, Zhen Dong, Jinbin Bai, Aishani Singh, Xiaoyu Xiang, Youzeng Li, Zuwei Huang, Yuanxi Sun, Rui He, Feng Hu, Junhua Hu, Hai Huang, Hanyu Zhu, Xu Cheng, Jie Tang, Mike Zheng Shou, Kurt Keutzer, Forrest Iandola | Date: 2023-10-24
2025-11-15 01:22:07,260 - WARNING - root - 【手动下载提示】(无PDF): Multimodal Structured Generation: CVPR's 2nd MMFM Challenge Technical Report
	  URL: https://www.semanticscholar.org/paper/031a265c1f2fc500fd02820f6e07e3f53c2aa5af
	  Citations: 8 | Authors: Franz Louis Cesista | Date: 2024-06-17
2025-11-15 01:22:07,261 - INFO - root - 正在下载: https://arxiv.org/pdf/2405.01028
2025-11-15 01:22:08,824 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\CVPR\Technical Report of NICE Challenge at CVPR 2024_ Caption Re-ranking Evaluation Using Ensembled CLIP.pdf
2025-11-15 01:22:08,829 - INFO - root - 成功下载 (Semantic Scholar): Technical Report of NICE Challenge at CVPR 2024: Caption Re-ranking Evaluation Using Ensembled CLIP and Consensus Scores
2025-11-15 01:22:08,830 - INFO - root - 正在下载: http://arxiv.org/pdf/2306.14895
2025-11-15 01:22:17,274 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\CVPR\Large Multimodal Models_ Notes on CVPR 2023 Tutorial.pdf
2025-11-15 01:22:17,277 - INFO - root - 成功下载 (Semantic Scholar): Large Multimodal Models: Notes on CVPR 2023 Tutorial
2025-11-15 01:22:17,278 - WARNING - root - 【手动下载提示】(无PDF): Black-Box Sparse Adversarial Attack via Multi-Objective Optimisation CVPR Proceedings
	  URL: https://www.semanticscholar.org/paper/260ffc8b860ccb7ed3951020861f14fee1330aba
	  Citations: 32 | Authors: P. Williams, Ke Li | Date: 2023-06-01
2025-11-15 01:22:17,278 - WARNING - root - 【手动下载提示】(无PDF): Learning the Bitter Lesson: Empirical Evidence from 20 Years of CVPR Proceedings
	  URL: https://www.semanticscholar.org/paper/63e5063a384c3429a7689111a376b6a1d17606ae
	  Citations: 2 | Authors: Mojtaba Yousefi, Jack Collins | Date: 2024-10-12
2025-11-15 01:22:17,278 - WARNING - root - 【手动下载提示】(无PDF): Driving with InternVL: Oustanding Champion in the Track on Driving with Language of the Autonomous Grand Challenge at CVPR 2024
	  URL: https://www.semanticscholar.org/paper/fce6522994bfeaf55cc6ee00d8f128f5ea84b3d0
	  Citations: 2 | Authors: Jiahan Li, Zhiqi Li, Tong Lu | Date: 2024-12-10
2025-11-15 01:22:17,278 - WARNING - root - 【手动下载提示】(无PDF): 2nd Place Solution for MeViS Track in CVPR 2024 PVUW Workshop: Motion Expression guided Video Segmentation
	  URL: https://www.semanticscholar.org/paper/287dec8cd109598478a76909a9085b9094488d31
	  Citations: 2 | Authors: Bin Cao, Yisi Zhang, Xuanxu Lin, Xingjian He, Bo Zhao, Jing Liu | Date: 2024-06-20
2025-11-15 01:22:17,280 - WARNING - root - 【手动下载提示】(无PDF): MapVision: CVPR 2024 Autonomous Grand Challenge Mapless Driving Tech Report
	  URL: https://www.semanticscholar.org/paper/fe4d10121780ed3e34a675aa01f303af73155748
	  Citations: 4 | Authors: Zhongyu Yang, Mai Liu, Jinluo Xie, Yueming Zhang, Chen Shen, Wei Shao, Jichao Jiao, Tengfei Xing, Runbo Hu, Pengfei Xu | Date: 2024-06-14
2025-11-15 01:22:17,280 - WARNING - root - 【手动下载提示】(无PDF): IEEE/CVF Conference on Computer Vision and Pattern Recognition, CVPR 2024, Seattle, WA, USA, June 16-22, 2024
	  URL: https://www.semanticscholar.org/paper/1ce4b067e620e7f843e9103484be4d1d20f719ac
	  Citations: 3 | Authors: N/A | Date: N/A
2025-11-15 01:22:17,282 - WARNING - root - 【手动下载提示】(无PDF): MetaFood CVPR 2024 Challenge on Physically Informed 3D Food Reconstruction: Methods and Results
	  URL: https://www.semanticscholar.org/paper/5405dae91dc4c9288ba07a5f933684e40f80c3df
	  Citations: 3 | Authors: Jiangpeng He, Yuhao Chen, Gautham Vinod, Talha Ibn Mahmud, F. Zhu, E. Delp, Alexander Wong, Pengcheng Xi, Ahmad AlMughrabi, Umair Haroon, Ricardo Marques, P. Radeva, Jiadong Tang, Dianyi Yang, Yu Gao, Zhaoxiang Liang, Yawei Jueluo, Chengyu Shi, Pengyu Wang | Date: 2024-07-12
2025-11-15 01:22:17,282 - WARNING - root - 【手动下载提示】(无PDF): 3rd Place Solution for MeViS Track in CVPR 2024 PVUW workshop: Motion Expression guided Video Segmentation
	  URL: https://www.semanticscholar.org/paper/d87b54ebf9532bf61ef8123844d5be1e5cf71992
	  Citations: 3 | Authors: Feiyu Pan, Hao Fang, Xiankai Lu | Date: 2024-06-07
2025-11-15 01:22:17,283 - WARNING - root - 【手动下载提示】(无PDF): Separating Drone Point Clouds From Complex Backgrounds by Cluster Filter - Technical Report for CVPR 2024 UG2 Challenge
	  URL: https://www.semanticscholar.org/paper/f25de413a85b977a681f8b2c0ffa4d2138195cca
	  Citations: 3 | Authors: Hanfang Liang, Jinming Hu, Xiaohuan Ling, Bing Wang | Date: 2024-12-22
2025-11-15 01:22:17,283 - WARNING - root - 【手动下载提示】(无PDF): Solution for SMART-101 Challenge of CVPR Multi-modal Algorithmic Reasoning Task 2024
	  URL: https://www.semanticscholar.org/paper/8fd14bb28d4a65d1c336de0652971ccb3b160809
	  Citations: 0 | Authors: Jinwoo Ahn, Junhyeok Park, Min-Jun Kim, Kang-Hyeon Kim, So-Yeong Sohn, Yun-Ji Lee, Du-Seong Chang, Yu-Jung Heo, Eun-Sol Kim | Date: 2024-06-10
2025-11-15 01:22:17,284 - WARNING - root - 【手动下载提示】(无PDF): Technique Report of CVPR 2024 PBDL Challenges
	  URL: https://www.semanticscholar.org/paper/e963b836d95373fc73e745e975af83a194a26851
	  Citations: 0 | Authors: Ying Fu, Yu Li, Shaodi You, Boxin Shi, Jose Alvarez, Coert Van Gemeren, Linwei Chen, Yunhao Zou, Zichun Wang, Yichen Li, Yuze Han, Yingkai Zhang, Jianan Wang, Qinglin Liu, Wei Yu, Xiao-ming Lv, Jianing Li, Shengping Zhang, Xiangyang Ji, Y. Chen, Yuhan Zhang, Weihang Peng, Liwen Zhang, Zhe Xu, Dingyong Gou, Cong Li, Senyan Xu, Yunkang Zhang, Siyuan Jiang, Xiaoqiang Lu, Licheng Jiao, Fang Liu, Xu Liu, Lingling Li, Wen-wen Ma, S. Yang, Haiyang Xie, Jian Zhao, Shihuang Huang, Peng Cheng, Xiaomei Shen, Zheng Wang, Shuai An, Caizhi Zhu, Xuelong Li, Tao Zhang, Liang Li, Yu Liu, Chenggang Yan, Gengchen Zhang, Linyan Jiang, Bingyi Song, Zhuoyu An, Haibo Lei, Qing Luo, Jie Song, Yuan Liu, Qihang Li, Haoyuan Zhang, Ling-Ling Wang, Wei Chen, Aling Luo, Cheng Li, Jun Cao, Shu Chen, Zifei Dou, Xinyu Liu, Jing Zhang, Kexin Zhang, Yuting Yang, Xue Gou, Qinliang Wang, Yang Liu, Shizhan Zhao, Yanzhao Zhang, Libo Yan, Yuwei Guo, Guoxin Li, Qiong Gao, Chenyue Che, Long Sun, Xiang Chen, Hao Li, Jinshan Pan, Chuanlong Xie, Hongming Chen, Mingrui Li, Tianchen Deng, Jing-Bo Huang, Yufeng Li, Fei Wan, Bin Xu, Jian Cheng, Hongzhe Liu, Cheng Xu, Yuxiang Zou, Weiguo Pan, Songyin Dai, Sen Jia, Junpei Zhang | Date: 2024-06-15
2025-11-15 01:22:17,284 - WARNING - root - 【手动下载提示】(无PDF): 1st Place Winner of the 2024 Pixel-level Video Understanding in the Wild (CVPR'24 PVUW) Challenge in Video Panoptic Segmentation and Best Long Video Consistency of Video Semantic Segmentation
	  URL: https://www.semanticscholar.org/paper/44efa304eeb29423dd5be250fe3661093ed4dbe1
	  Citations: 0 | Authors: Qingfeng Liu, Mostafa El-Khamy, Kee-Bong Song | Date: 2024-06-08
2025-11-15 01:22:17,285 - WARNING - root - 【手动下载提示】(无PDF): WiCV@CVPR2024: The Thirteenth Women In Computer Vision Workshop at the Annual CVPR Conference
	  URL: https://www.semanticscholar.org/paper/78a7217aebe2c0433886961cc2b68740dd36c6eb
	  Citations: 0 | Authors: Asra Aslam, Sachini Herath, Ziqi Huang, Estefania Talavera, Deblina Bhattacharjee, Himangi Mittal, Vanessa Staderini, Mengwei Ren, Azade Farshad | Date: 2024-11-03
2025-11-15 01:22:17,286 - WARNING - root - 【手动下载提示】(无PDF): Solution for CVPR 2024 UG2+ Challenge Track on All Weather Semantic Segmentation
	  URL: https://www.semanticscholar.org/paper/31e5432b6c76a9be9b719ca89130699826c3fd3a
	  Citations: 0 | Authors: Jun Yu, Yunxiang Zhang, Fengzhao Sun, Leilei Wang, Renjie Lu | Date: 2024-06-09
2025-11-15 01:22:17,286 - WARNING - root - 【手动下载提示】(无PDF): A Two-Stage Adverse Weather Semantic Segmentation Method for WeatherProof Challenge CVPR 2024 Workshop UG2+
	  URL: https://www.semanticscholar.org/paper/cd15d2fd959f7122ad57f02b242c74de6e5e9035
	  Citations: 0 | Authors: Jianzhao Wang, Yanyan Wei, Dehua Hu, Yilin Zhang, Shengeng Tang, Kun Li, Zhao Zhang | Date: 2024-06-08
2025-11-15 01:22:17,288 - WARNING - root - 【手动下载提示】(无PDF): Technical Report for CVPR 2024 WeatherProof Dataset Challenge: Semantic Segmentation on Paired Real Data
	  URL: https://www.semanticscholar.org/paper/c71cd4425b0381b0b4d66b04719879f196a90170
	  Citations: 0 | Authors: Guojin Cao, Jiaxu Li, Jia He, Ying Min, Yunhao Zhang | Date: 2024-06-09
2025-11-15 01:22:17,288 - WARNING - root - 【手动下载提示】(无PDF): 1st Place Solution for MeViS Track in CVPR 2024 PVUW Workshop: Motion Expression guided Video Segmentation
	  URL: https://www.semanticscholar.org/paper/01574c76e5ec82fa984ab0a8d4a96bd7ffbde433
	  Citations: 2 | Authors: Mingqi Gao, Jingnan Luo, Jinyu Yang, Jungong Han, Feng Zheng | Date: 2024-06-11
2025-11-15 01:22:17,288 - WARNING - root - 【手动下载提示】(无PDF): 1st Place Solution for MOSE Track in CVPR 2024 PVUW Workshop: Complex Video Object Segmentation
	  URL: https://www.semanticscholar.org/paper/c2c0524380325ae12ddad11b9d16b875dce6f652
	  Citations: 1 | Authors: Deshui Miao, Xin Li, Zhenyu He, Yaowei Wang, Ming-Hsuan Yang | Date: 2024-06-07
2025-11-15 01:22:17,289 - WARNING - root - 【手动下载提示】(无PDF): 2nd Place Solution for MOSE Track in CVPR 2024 PVUW workshop: Complex Video Object Segmentation
	  URL: https://www.semanticscholar.org/paper/e4cae801e9f400fc9784a86315da02e45465993f
	  Citations: 1 | Authors: Zhensong Xu, Jiangtao Yao, Chengjing Wu, Ting Liu, Luoqi Liu | Date: 2024-06-12
2025-11-15 01:22:17,289 - WARNING - root - 【手动下载提示】(无PDF): 3rd Place Solution for MOSE Track in CVPR 2024 PVUW workshop: Complex Video Object Segmentation
	  URL: https://www.semanticscholar.org/paper/9f259a06db52173e27b518981c9a919229aae304
	  Citations: 1 | Authors: Xinyu Liu, Jing Zhang, Kexin Zhang, Yuting Yang, Licheng Jiao, Shuyuan Yang | Date: 2024-06-06
2025-11-15 01:22:17,289 - WARNING - root - 【手动下载提示】(无PDF): IEEE/CVF Conference on Computer Vision and Pattern Recognition, CVPR 2024 - Workshops, Seattle, WA, USA, June 17-18, 2024
	  URL: https://www.semanticscholar.org/paper/11f70056c4d2a6846492cf514900ab936b78aada
	  Citations: 0 | Authors: N/A | Date: N/A
2025-11-15 01:22:17,290 - WARNING - root - 【手动下载提示】(无PDF): The Solution for the CVPR 2023 1st foundation model challenge-Track2
	  URL: https://www.semanticscholar.org/paper/a82ccea47cef07179facce2ca4e179cf5575d99b
	  Citations: 0 | Authors: Haonan Xu, YuRui Huang, Sishun Pan, Zhihao Guan, Yi Xu, Yang Yang | Date: 2024-03-26
2025-11-15 01:22:17,290 - INFO - root - 正在下载: http://arxiv.org/pdf/2306.11414
2025-11-15 01:22:18,936 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\CVPR\Multi-Scale Occ_ 4th Place Solution for CVPR 2023 3D Occupancy Prediction Challenge.pdf
2025-11-15 01:22:18,937 - INFO - root - 成功下载 (Semantic Scholar): Multi-Scale Occ: 4th Place Solution for CVPR 2023 3D Occupancy Prediction Challenge
2025-11-15 01:22:18,938 - INFO - root - 正在下载: http://arxiv.org/pdf/2306.09590
2025-11-15 01:22:20,436 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\CVPR\The 1st-place Solution for CVPR 2023 OpenLane Topology in Autonomous Driving Challenge.pdf
2025-11-15 01:22:20,440 - INFO - root - 成功下载 (Semantic Scholar): The 1st-place Solution for CVPR 2023 OpenLane Topology in Autonomous Driving Challenge
2025-11-15 01:22:20,440 - WARNING - root - 【手动下载提示】(无PDF): IEEE/CVF Conference on Computer Vision and Pattern Recognition, CVPR 2023, Vancouver, BC, Canada, June 17-24, 2023
	  URL: https://www.semanticscholar.org/paper/1ff4e20b329454a055a7c380be62dfbd1aa5b1ff
	  Citations: 12 | Authors: N/A | Date: N/A
2025-11-15 01:22:20,441 - WARNING - root - 【手动下载提示】(无PDF): IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops, CVPR Workshops 2022, New Orleans, LA, USA, June 19-20, 2022
	  URL: https://www.semanticscholar.org/paper/2fa1c532b5db1cbbab7ee42015993bc643f9e8e1
	  Citations: 54 | Authors: N/A | Date: N/A
2025-11-15 01:22:20,441 - INFO - root - 正在下载: http://arxiv.org/pdf/2306.05772
2025-11-15 01:22:22,163 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\CVPR\A Boosted Model Ensembling Approach to Ball Action Spotting in Videos_ The Runner-Up Solution to CVP.pdf
2025-11-15 01:22:22,165 - INFO - root - 成功下载 (Semantic Scholar): A Boosted Model Ensembling Approach to Ball Action Spotting in Videos: The Runner-Up Solution to CVPR'23 SoccerNet Challenge
2025-11-15 01:22:22,166 - INFO - root - 正在下载: http://arxiv.org/pdf/2306.13380
2025-11-15 01:22:27,992 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\CVPR\First Place Solution to the CVPR'2023 AQTC Challenge_ A Function-Interaction Centric Approach with S.pdf
2025-11-15 01:22:27,995 - INFO - root - 成功下载 (Semantic Scholar): First Place Solution to the CVPR'2023 AQTC Challenge: A Function-Interaction Centric Approach with Spatiotemporal Visual-Language Alignment
2025-11-15 01:22:27,996 - INFO - root - 正在下载: http://arxiv.org/pdf/2305.07979
2025-11-15 01:22:33,552 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\CVPR\A Two-Stage Real Image Deraining Method for GT-RAIN Challenge CVPR 2023 Workshop UG2 + Track 3.pdf
2025-11-15 01:22:33,554 - INFO - root - 成功下载 (Semantic Scholar): A Two-Stage Real Image Deraining Method for GT-RAIN Challenge CVPR 2023 Workshop UG2 + Track 3
2025-11-15 01:22:33,555 - INFO - root - 正在下载: http://arxiv.org/pdf/2305.05454
2025-11-15 01:22:36,779 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\CVPR\Restormer-Plus for Real World Image Deraining_ the Runner-up Solution to the GT-RAIN Challenge (CVPR.pdf
2025-11-15 01:22:36,782 - INFO - root - 成功下载 (Semantic Scholar): Restormer-Plus for Real World Image Deraining: the Runner-up Solution to the GT-RAIN Challenge (CVPR 2023 UG2+ Track 3)
2025-11-15 01:22:36,782 - WARNING - root - 【手动下载提示】(无PDF): Restormer-Plus for Real World Image Deraining: One State-of-the-Art Solution to the GT-RAIN Challenge (CVPR 2023 UG2+ Track 3)
	  URL: https://www.semanticscholar.org/paper/8103e80438f11f3d6ab16d6a3df3c221ae003c68
	  Citations: 1 | Authors: Chao-Yuan Zheng, Luping Wang, Bin Liu | Date: 2023-05-09
2025-11-15 01:22:36,783 - INFO - root - 正在下载: https://arxiv.org/pdf/2309.12768
2025-11-15 01:22:38,572 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\CVPR\WiCV@CVPR2023_ The Eleventh Women In Computer Vision Workshop at the Annual CVPR Conference.pdf
2025-11-15 01:22:38,576 - INFO - root - 成功下载 (Semantic Scholar): WiCV@CVPR2023: The Eleventh Women In Computer Vision Workshop at the Annual CVPR Conference
2025-11-15 01:22:38,578 - INFO - root - 正在下载: https://arxiv.org/pdf/2309.01961
2025-11-15 01:22:42,672 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\CVPR\NICE_ CVPR 2023 Challenge on Zero-shot Image Captioning.pdf
2025-11-15 01:22:42,684 - INFO - root - 成功下载 (Semantic Scholar): NICE: CVPR 2023 Challenge on Zero-shot Image Captioning
2025-11-15 01:22:42,685 - WARNING - root - 【手动下载提示】(无PDF): 1st Solution Places for CVPR 2023 UG$^{\textbf{2}}$+ Challenge Track 2.1-Text Recognition through Atmospheric Turbulence
	  URL: https://www.semanticscholar.org/paper/e85efe0aed1ed1ea02acda3b6ab3583d05e522d3
	  Citations: 0 | Authors: Shengqi Xu, Xu Xiao, Shuning Cao, Yi Chang, Luxin Yan | Date: 2023-06-15
2025-11-15 01:22:42,687 - INFO - root - 正在下载: http://arxiv.org/pdf/2306.14412
2025-11-15 01:22:46,355 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\CVPR\A Solution to CVPR'2023 AQTC Challenge_ Video Alignment for Multi-Step Inference.pdf
2025-11-15 01:22:46,360 - INFO - root - 成功下载 (Semantic Scholar): A Solution to CVPR'2023 AQTC Challenge: Video Alignment for Multi-Step Inference
2025-11-15 01:22:46,363 - INFO - root - 正在下载: http://arxiv.org/pdf/2306.09379
2025-11-15 01:22:48,392 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\CVPR\1st Solution Places for CVPR 2023 UG2+ Challenge Track 2.2-Coded Target Restoration through Atmosphe.pdf
2025-11-15 01:22:48,394 - INFO - root - 成功下载 (Semantic Scholar): 1st Solution Places for CVPR 2023 UG2+ Challenge Track 2.2-Coded Target Restoration through Atmospheric Turbulence
2025-11-15 01:22:48,394 - WARNING - root - 【手动下载提示】(无PDF): Restormer-Plus for Real World Image Deraining: One State-of-the-Art to the GT-RAIN Challenge (CVPR 2023 UG2+ Track 3)
	  URL: https://www.semanticscholar.org/paper/b2b2d13fbada3c25484d4a00963bf3d8e321b1e9
	  Citations: 0 | Authors: Chaochao Zheng, Luping Wang, Bin Liu | Date: N/A
2025-11-15 01:22:48,395 - WARNING - root - 【手动下载提示】(无PDF): WoodScape Motion Segmentation for Autonomous Driving - CVPR 2023 OmniCV Workshop Challenge
	  URL: https://www.semanticscholar.org/paper/5c4f3fef9623cd0cb01a939ec951dabcec9d5103
	  Citations: 0 | Authors: Saravanabalagi Ramachandran, Nathaniel Cibik, Ganesh Sistu, John McDonald | Date: 2023-12-31
2025-11-15 01:22:48,396 - INFO - root - 正在下载: https://openresearch.surrey.ac.uk/view/delivery/44SUR_INST/12161580690002346/13167169950002346
2025-11-15 01:22:55,324 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\CVPR\2021 IEEE_CVF Conference on Computer Vision and Pattern Recognition (CVPR).pdf
2025-11-15 01:22:55,329 - INFO - root - 成功下载 (Semantic Scholar): 2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)
2025-11-15 01:22:55,332 - INFO - root - 正在下载: https://arxiv.org/pdf/2206.11610
2025-11-15 01:22:57,457 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\CVPR\1st Place Solutions for RxR-Habitat Vision-and-Language Navigation Competition (CVPR 2022).pdf
2025-11-15 01:22:57,459 - INFO - root - 成功下载 (Semantic Scholar): 1st Place Solutions for RxR-Habitat Vision-and-Language Navigation Competition (CVPR 2022)
2025-11-15 01:22:57,460 - WARNING - root - 【手动下载提示】(无PDF): Technical Report of NICE Challenge at CVPR 2023: Retrieval-based Data Discovery and Fusion for Zero-shot Image Captioning
	  URL: https://www.semanticscholar.org/paper/8aa76774a6ffebe4e6f89eedc39256606d5240fc
	  Citations: 2 | Authors: Youngtaek Oh, Jae-Won Cho, Dong-Jin Kim, In-So Kweon, Junmo Kim, Kaist | Date: N/A
2025-11-15 01:22:57,460 - WARNING - root - 【手动下载提示】(无PDF): Conference on Computer Vision and Pattern Recognition (CVPR) 2022
	  URL: https://www.semanticscholar.org/paper/0877c7ca0d00c3586b5ac9f2eee07cd9372ddbb6
	  Citations: 14 | Authors: N/A | Date: 2022-06-01
2025-11-15 01:22:57,460 - WARNING - root - 【手动下载提示】(无PDF): HGNet: Learning Hierarchical Geometry from Points, Edges, and Surfaces ——CVPR 2023 Supplementary Material
	  URL: https://www.semanticscholar.org/paper/aa7a11f16936dfb83e89d6016aeff639b8a82f84
	  Citations: 1 | Authors: Ting Yao, Yehao Li, Yingwei Pan, Tao Mei | Date: N/A
2025-11-15 01:22:57,462 - INFO - root - 正在下载: http://arxiv.org/pdf/2306.15704
2025-11-15 01:22:58,642 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\CVPR\MAE-GEBD_ Winning the CVPR'2023 LOVEU-GEBD Challenge.pdf
2025-11-15 01:22:58,644 - INFO - root - 成功下载 (Semantic Scholar): MAE-GEBD: Winning the CVPR'2023 LOVEU-GEBD Challenge
2025-11-15 01:22:58,644 - WARNING - root - 【手动下载提示】(无PDF): Conference on Computer Vision and Pattern Recognition (CVPR) 2022
	  URL: https://www.semanticscholar.org/paper/c4d0c9f5d3d495282f384ab84c73e6473ed26385
	  Citations: 73 | Authors: N/A | Date: 2021-12-01
2025-11-15 01:22:58,645 - WARNING - root - 【手动下载提示】(无PDF): CVPR 2023 Workshop
	  URL: https://www.semanticscholar.org/paper/879341e3fcf05b5e2a8aa30653042056be932d2e
	  Citations: 0 | Authors: N/A | Date: 2023-06-01
2025-11-15 01:22:58,646 - INFO - root - 正在下载: https://openresearch.surrey.ac.uk/view/delivery/44SUR_INST/12185320530002346/13185320520002346
2025-11-15 01:23:05,822 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\CVPR\IEEE_CVF Conference on Computer Vision and Pattern Recognition, CVPR 2023 - Workshops, Vancouver, BC.pdf
2025-11-15 01:23:05,827 - INFO - root - 成功下载 (Semantic Scholar): IEEE/CVF Conference on Computer Vision and Pattern Recognition, CVPR 2023 - Workshops, Vancouver, BC, Canada, June 17-24, 2023
2025-11-15 01:23:05,827 - WARNING - root - 【手动下载提示】(无PDF): 3D Human Pose Estimation with Spatio-Temporal Criss-cross Attention — CVPR 2023 Supplementary Material *
	  URL: https://www.semanticscholar.org/paper/5cc786a198a4586e91e524544e9ba20ced1f33f6
	  Citations: 0 | Authors: Z. Tang, Zhaofan Qiu, Y. Hao, Richang Hong, Ting Yao | Date: N/A
2025-11-15 01:23:05,827 - WARNING - root - 【手动下载提示】(无PDF): Supplementary Material for CVPR 2023 Paper: Object Detection with Self-Supervised Scene Adaptation
	  URL: https://www.semanticscholar.org/paper/39103a105a33dadd9c29f3d3407c560236409d3a
	  Citations: 0 | Authors: Ze Zhang, Minh Hoai | Date: N/A
2025-11-15 01:23:05,828 - INFO - root - 正在下载: http://arxiv.org/pdf/2306.14116
2025-11-15 01:23:09,556 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\CVPR\The Second-place Solution for CVPR VISION 23 Challenge Track 1 - Data Effificient Defect Detection.pdf
2025-11-15 01:23:09,558 - INFO - root - 成功下载 (Semantic Scholar): The Second-place Solution for CVPR VISION 23 Challenge Track 1 - Data Effificient Defect Detection
2025-11-15 01:23:09,559 - INFO - root - 正在下载: https://arxiv.org/pdf/2307.04715
2025-11-15 01:23:10,553 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\CVPR\CVPR MultiEarth 2023 Deforestation Estimation Challenge_ SpaceVision4Amazon.pdf
2025-11-15 01:23:10,557 - INFO - root - 成功下载 (Semantic Scholar): CVPR MultiEarth 2023 Deforestation Estimation Challenge: SpaceVision4Amazon
2025-11-15 01:23:10,557 - WARNING - root - 【手动下载提示】(无PDF): SuperAD: A Training-free Anomaly Classification and Segmentation Method for CVPR 2025 VAND 3.0 Workshop Challenge Track 1: Adapt & Detect
	  URL: https://www.semanticscholar.org/paper/717d0f7f2b2a37593a0535c58cca878cf96c27ea
	  Citations: 2 | Authors: Huaiyuan Zhang, Hang Chen, Yu Cheng, Shunyi Wu, Linghao Sun, Linao Han, Zeyu Shi, Lei Qi | Date: 2025-05-26
2025-11-15 01:23:10,558 - WARNING - root - 【手动下载提示】(无PDF): Benchmarking Generalizable Bimanual Manipulation: RoboTwin Dual-Arm Collaboration Challenge at CVPR 2025 MEIS Workshop
	  URL: https://www.semanticscholar.org/paper/ef19d2bbbbb1ea4eeebba4396cca45e41d782e67
	  Citations: 4 | Authors: Tianxing Chen, Kaixuan Wang, Zhaohui Yang, Yuhao Zhang, Zanxin Chen, Baijun Chen, Wanxi Dong, Ziyuan Liu, Dong Chen, Tianshuo Yang, Haibao Yu, Xiaokang Yang, Yusen Qin, Zhiqiang Xie, Yao Mu, Ping Luo, Tian Nian, Weiliang Deng, Yiheng Ge, Yibin Liu, Zixuan Li, Dehui Wang, Zhixuan Liang, Haohui Xie, Rijie Zeng, Yunfei Ge, Peiqing Cong, Guannan He, Zhaoming Han, Ruocheng Yin, Jingxiang Guo, Lunkai Lin, Tianling Xu, Hongzhe Bi, Xuewu Lin, Tianwei Lin, Shujie Luo, Keyu Li, Ziyan Zhao, Ke Fan, Heyang Xu, Bo Peng, Wenlong Gao, Dongjiang Li, Feng Jin, Hui Shen, Jinming Li, Chaowei Cui, Yu Chen, Yaxin Peng, Lingdong Zeng, Wenlong Dong, Tengfei Li, Weijie Ke, Jun Chen, Erdemt Bao, Tian Lan, Tenglong Liu, Jin Yang, Huiping Zhuang, Baozhi Jia, Shuai Zhang, Zhengfeng Zou, Fangheng Guan, Tianyi Jia, Ke Zhou, Hongjiu Zhang, Yating Han, Cheng Fang, Yixian Zou, Chongyang Xu, Qinglun Zhang, Shen Cheng, Xiaohe Wang, Ping Tan, Haoqiang Fan, Shuaicheng Liu, Jiaheng Chen, Chuxuan Huang, Chengliang Lin, Kaijun Luo, Boyu Yue, Yi Liu, Jinyu Chen, Zichang Tan, Liming Deng, Shuo Xu, Zijian Cai, Shilong Yin, Hao Wang, Hongshan Liu, Tianyang Li, Long Shi, Ran Xu, Huilin Xu, Zhengquan Zhang, Congsheng Xu, Jinchang Yang, Feng Xu | Date: 2025-06-29
2025-11-15 01:23:10,558 - WARNING - root - 【手动下载提示】(无PDF): ReferDINO-Plus: 2nd Solution for 4th PVUW MeViS Challenge at CVPR 2025
	  URL: https://www.semanticscholar.org/paper/f5c5303751e489ab69fb7fde8f66a542d93c4abb
	  Citations: 1 | Authors: Tianming Liang, Haichao Jiang, Wei-Shi Zheng, Jian-Fang Hu | Date: 2025-03-30
2025-11-15 01:23:10,559 - WARNING - root - 【手动下载提示】(无PDF): The System Description of CPS Team for Track on Driving with Language of CVPR 2024 Autonomous Grand Challenge
	  URL: https://www.semanticscholar.org/paper/ca9841469f1e93a1d32df8986eeefb8fdc6a1e8a
	  Citations: 1 | Authors: Jinghan Peng, Jingwen Wang, Xing Yu, Dehui Du | Date: 2025-09-14
2025-11-15 01:23:10,559 - WARNING - root - 【手动下载提示】(无PDF): IEEE/CVF Conference on Computer Vision and Pattern Recognition, CVPR 2025, Nashville, TN, USA, June 11-15, 2025
	  URL: https://www.semanticscholar.org/paper/1355fda39207dfcaa741af5a41696bdf73f5cb2a
	  Citations: 6 | Authors: N/A | Date: N/A
2025-11-15 01:23:10,560 - WARNING - root - 【手动下载提示】(无PDF): IEEE/CVF Conference on Computer Vision and Pattern Recognition, CVPR 2022, New Orleans, LA, USA, June 18-24, 2022
	  URL: https://www.semanticscholar.org/paper/915056b8bad88c41506cc2a16e3993a0d235c7c4
	  Citations: 11 | Authors: N/A | Date: N/A
2025-11-15 01:23:10,560 - WARNING - root - 【手动下载提示】(无PDF): SIS-Challenge: Event-based Spatio-temporal Instance Segmentation Challenge at the CVPR 2025 Event-based Vision Workshop
	  URL: https://www.semanticscholar.org/paper/95dbabc42947524e36b2d1dbe3bd7fdd8f8ffd36
	  Citations: 0 | Authors: Friedhelm Hamann, Emil Mededovic, Fabian Gülhan, Yue Wu, Johannes Stegmaier, Jing He, Yiqing Wang, Kexin Zhang, Lingling Li, Licheng Jiao, Mengru Ma, Hongxiang Huang, Yuhao Yan, Hong Ren, Xiaopeng Lin, Yulong Huang, Bo-Xun Cheng, Se Hyun Lee, Gyu-Sung Ham, Kanghan Oh, Gi Hyun Lim, Boxuan Yang, Bowen Du, Guillermo Gallego | Date: 2025-08-18
2025-11-15 01:23:10,561 - WARNING - root - 【手动下载提示】(无PDF): Geospatial Foundational Embedder: Top-1 Winning Solution on EarthVision Embed2Scale Challenge (CVPR 2025)
	  URL: https://www.semanticscholar.org/paper/746a1c2e92a046e856fd044cbfa774b70b420836
	  Citations: 0 | Authors: Zirui Xu, Raphael Tang, Mike Bianco, Qi Zhang, R. Madhok, Nikolaos Karianakis, Fuxun Yu | Date: 2025-09-03
2025-11-15 01:23:10,562 - WARNING - root - 【手动下载提示】(无PDF): Technical Report for the 5th CLVision Challenge at CVPR: Addressing the Class-Incremental with Repetition using Unlabeled Data - 4th Place Solution
	  URL: https://www.semanticscholar.org/paper/1bfd7b91b99c8c45e905cb06d15d3a35ea70b5b8
	  Citations: 0 | Authors: Panagiota Moraiti, Efstathios Karypidis | Date: 2025-03-19
2025-11-15 01:23:10,562 - WARNING - root - 【手动下载提示】(无PDF): WiCV at CVPR 2025: The Women in Computer Vision Workshop
	  URL: https://www.semanticscholar.org/paper/89c665ad0e032155b51f23ba2c2b2e3914b36625
	  Citations: 0 | Authors: Estefania Talavera, Deblina Bhattacharjee, Himangi Mittal, Mengwei Ren, Karen Sanchez, Carla Muntean, JungEun Kim, Mona Jalal | Date: 2025-11-11
2025-11-15 01:23:10,563 - INFO - root - 正在下载: https://arxiv.org/pdf/2206.12912
2025-11-15 01:23:13,107 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\CVPR\Woodscape Fisheye Object Detection for Autonomous Driving - CVPR 2022 OmniCV Workshop Challenge.pdf
2025-11-15 01:23:13,109 - INFO - root - 成功下载 (Semantic Scholar): Woodscape Fisheye Object Detection for Autonomous Driving - CVPR 2022 OmniCV Workshop Challenge
2025-11-15 01:23:13,109 - WARNING - root - 【手动下载提示】(无PDF): VizWiz grand challenge workshop at CVPR 2022
	  URL: https://www.semanticscholar.org/paper/cdb1b854013682df873633be9b2b9d44805a5099
	  Citations: 4 | Authors: Daniela Massiceti, Samreen Anjum, D. Gurari | Date: 2022-06-01
2025-11-15 01:23:13,110 - INFO - root - 正在下载: https://arxiv.org/pdf/2211.13481
2025-11-15 01:23:17,051 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\CVPR\The Second-place Solution for CVPR 2022 SoccerNet Tracking Challenge.pdf
2025-11-15 01:23:17,055 - INFO - root - 成功下载 (Semantic Scholar): The Second-place Solution for CVPR 2022 SoccerNet Tracking Challenge
2025-11-15 01:23:17,055 - WARNING - root - 【手动下载提示】(无PDF): DIVE: Deep-search Iterative Video Exploration A Technical Report for the CVRR Challenge at CVPR 2025
	  URL: https://www.semanticscholar.org/paper/0139ca112cfaf8a1f855a218efb2e68d380369cc
	  Citations: 1 | Authors: Umihiro Kamoto, Tatsuya Ishibashi, Noriyuki Kugo | Date: 2025-06-26
2025-11-15 01:23:17,055 - WARNING - root - 【手动下载提示】(无PDF): Medical Image Segmentation Foundation Models. CVPR 2024 Challenge: Segment Anything in Medical Images on Laptop: MedSAM on Laptop 2024, Held in Conjunction with CVPR 2024, Seattle, WA, USA, June 17–21, 2024, Proceedings
	  URL: https://www.semanticscholar.org/paper/be7e23a02af21de329d52d9355310972cdef2117
	  Citations: 0 | Authors: N/A | Date: N/A
2025-11-15 01:23:17,055 - WARNING - root - 【手动下载提示】(无PDF): IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops, CVPR Workshops 2025, Nashville, TN, USA, June 11-15, 2025
	  URL: https://www.semanticscholar.org/paper/41c8e3928e641a9481e76a6bb8a3e25ff392a81f
	  Citations: 0 | Authors: N/A | Date: N/A
2025-11-15 01:23:17,056 - WARNING - root - 【手动下载提示】(无PDF): Conference on Computer Vision and Pattern Recognition (CVPR) 2022
	  URL: https://www.semanticscholar.org/paper/18698ad856aeef11eac7aa300f31b59b58eeb816
	  Citations: 7 | Authors: L. Polidori, T. Landes, C. Mallet, Florent Lafarge, P. Grussenmeyer, E. Labergerie, Ian Dowman President, N. Paparoditis, S. Hinz, F. Remondino, Jie Jiang, Senthil Kumar | Date: 2022-03-01
2025-11-15 01:23:17,056 - WARNING - root - 【手动下载提示】(无PDF): EgoVIS@CVPR: What Changed and What Could Have Changed? State-Change Counterfactuals for Procedure-Aware Video Representation Learning
	  URL: https://www.semanticscholar.org/paper/a739bb4074e6c9992c0fa1ac62ca8cbc382117b6
	  Citations: 0 | Authors: Chi-Hsi Kung, Frangil M. Ramirez, Juhyung Ha, Yi-Ting Chen, David Crandall, Yi-Hsuan Tsai | Date: 2025-05-30
2025-11-15 01:23:17,057 - WARNING - root - 【手动下载提示】(无PDF): Editorial: Introduction to the Special Section on Best of CVPR'2022
	  URL: https://www.semanticscholar.org/paper/c20af8e3202c21e4c28ee84ff7031b2ab0c01d5a
	  Citations: 0 | Authors: Kristin J. Dana, Gang Hua, Stefan Roth, Dimitris Samaras, Richa Singh | Date: 2025-11-01
2025-11-15 01:23:17,059 - INFO - root - 正在下载: https://arxiv.org/pdf/2206.09597
2025-11-15 01:23:18,783 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\CVPR\Winning the CVPR'2022 AQTC Challenge_ A Two-stage Function-centric Approach.pdf
2025-11-15 01:23:18,786 - INFO - root - 成功下载 (Semantic Scholar): Winning the CVPR'2022 AQTC Challenge: A Two-stage Function-centric Approach
2025-11-15 01:23:18,788 - INFO - root - 正在下载: https://arxiv.org/pdf/2206.08610
2025-11-15 01:23:24,611 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\CVPR\Masked Autoencoders for Generic Event Boundary Detection CVPR'2022 Kinetics-GEBD Challenge.pdf
2025-11-15 01:23:24,613 - INFO - root - 成功下载 (Semantic Scholar): Masked Autoencoders for Generic Event Boundary Detection CVPR'2022 Kinetics-GEBD Challenge
2025-11-15 01:23:24,614 - INFO - root - 正在下载: http://arxiv.org/pdf/2206.14555
2025-11-15 01:23:25,906 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\CVPR\Technical Report for CVPR 2022 LOVEU AQTC Challenge.pdf
2025-11-15 01:23:25,908 - INFO - root - 成功下载 (Semantic Scholar): Technical Report for CVPR 2022 LOVEU AQTC Challenge
2025-11-15 01:23:25,908 - WARNING - root - 【手动下载提示】(无PDF): On the Robustness of the CVPR 2018 White-Box Adversarial Example Defenses
	  URL: https://www.semanticscholar.org/paper/06b98537324dbf11c7de2040e519b4d110f5d622
	  Citations: 173 | Authors: Anish Athalye, Nicholas Carlini | Date: 2018-04-10
2025-11-15 01:23:25,909 - INFO - root - 正在下载: http://arxiv.org/pdf/2206.15268
2025-11-15 01:23:27,324 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\CVPR\Submission to Generic Event Boundary Detection Challenge@CVPR 2022_ Local Context Modeling and Globa.pdf
2025-11-15 01:23:27,327 - INFO - root - 成功下载 (Semantic Scholar): Submission to Generic Event Boundary Detection Challenge@CVPR 2022: Local Context Modeling and Global Boundary Decoding Approach
2025-11-15 01:23:27,327 - WARNING - root - 【手动下载提示】(无PDF): Woodscape Fisheye Semantic Segmentation for Autonomous Driving - CVPR 2021 OmniCV Workshop Challenge
	  URL: https://www.semanticscholar.org/paper/93cb16ef67ac617d0bfd3af78bc3aa4523def149
	  Citations: 13 | Authors: Saravanabalagi Ramachandran, Ganesh Sistu, J. McDonald, S. Yogamani | Date: 2021-07-17
2025-11-15 01:23:27,329 - WARNING - root - 【手动下载提示】(无PDF): IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2021, virtual, June 19-25, 2021
	  URL: https://www.semanticscholar.org/paper/c5afcd09637d22cfd74faa549046f14ca7840e63
	  Citations: 13 | Authors: N/A | Date: N/A
2025-11-15 01:23:27,329 - INFO - root - 正在下载: https://doi.org/10.1109/cvprw56347.2022.00007
2025-11-15 01:23:33,222 - INFO - root - 正在下载: https://doi.org/10.1109/cvprw56347.2022.00007
2025-11-15 01:23:39,225 - INFO - root - 正在下载: https://doi.org/10.1109/cvprw56347.2022.00007
2025-11-15 01:23:44,880 - INFO - root - 正在下载: https://doi.org/10.1109/cvprw56347.2022.00007
2025-11-15 01:23:56,412 - INFO - root - 正在下载: https://doi.org/10.1109/cvprw56347.2022.00007
2025-11-15 01:23:57,911 - WARNING - root - 下载 CVPR 2022 Area Chairs (https://doi.org/10.1109/cvprw56347.2022.00007) 失败: 418 Client Error: Unknown Code for url: https://ieeexplore.ieee.org/document/9857048/
2025-11-15 01:23:57,915 - INFO - root - 正在下载: https://ieeexplore.ieee.org/ielx7/9856930/9856648/09857066.pdf
2025-11-15 01:24:03,224 - INFO - root - 正在下载: https://ieeexplore.ieee.org/ielx7/9856930/9856648/09857066.pdf
2025-11-15 01:24:08,097 - INFO - root - 正在下载: https://ieeexplore.ieee.org/ielx7/9856930/9856648/09857066.pdf
2025-11-15 01:24:13,487 - INFO - root - 正在下载: https://ieeexplore.ieee.org/ielx7/9856930/9856648/09857066.pdf
2025-11-15 01:24:22,304 - INFO - root - 正在下载: https://ieeexplore.ieee.org/ielx7/9856930/9856648/09857066.pdf
2025-11-15 01:24:26,194 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\CVPR\CVPR 2022 Outstanding Reviewers.pdf
2025-11-15 01:24:26,196 - INFO - root - 成功下载 (Semantic Scholar): CVPR 2022 Outstanding Reviewers
2025-11-15 01:24:26,197 - INFO - root - 正在下载: https://ieeexplore.ieee.org/ielx7/9856930/9856648/09857453.pdf
2025-11-15 01:24:31,070 - INFO - root - 正在下载: https://ieeexplore.ieee.org/ielx7/9856930/9856648/09857453.pdf
2025-11-15 01:24:35,986 - INFO - root - 正在下载: https://ieeexplore.ieee.org/ielx7/9856930/9856648/09857453.pdf
2025-11-15 01:24:41,095 - INFO - root - 正在下载: https://ieeexplore.ieee.org/ielx7/9856930/9856648/09857453.pdf
2025-11-15 01:24:49,965 - INFO - root - 正在下载: https://ieeexplore.ieee.org/ielx7/9856930/9856648/09857453.pdf
2025-11-15 01:24:50,820 - WARNING - root - 下载 CVPR 2022 Organizing Committee (https://ieeexplore.ieee.org/ielx7/9856930/9856648/09857453.pdf) 失败: 418 Client Error: Unknown Code for url: https://ieeexplore.ieee.org/ielx7/9856930/9856648/09857453.pdf
2025-11-15 01:24:50,821 - WARNING - root - 【手动下载提示】(无PDF): 2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)
	  URL: https://www.semanticscholar.org/paper/45c3863931acb7e8ac74032ef19bb618a8bb754a
	  Citations: 103 | Authors: N/A | Date: N/A
2025-11-15 01:24:50,821 - WARNING - root - 【手动下载提示】(无PDF): Winning the CVPR'2021 Kinetics-GEBD Challenge: Contrastive Learning Approach
	  URL: https://www.semanticscholar.org/paper/715bf5338f1776288b41f41df20e3d17b32d8fcd
	  Citations: 18 | Authors: Hyolim Kang, Jinwoo Kim, Kyungmin Kim, Taehyun Kim, Seon Joo Kim | Date: 2021-06-22
2025-11-15 01:24:50,822 - WARNING - root - 【手动下载提示】(无PDF): Supplementary Material for CVPR 2022 paper # 9084
	  URL: https://www.semanticscholar.org/paper/d6af81d369524e81063f1ce6ffad409539026632
	  Citations: 0 | Authors: Jinseong Jang, D. Hwang | Date: N/A
2025-11-15 01:24:50,823 - INFO - root - 正在下载: https://doi.org/10.1109/tpami.2022.3201636
2025-11-15 01:24:56,377 - INFO - root - 正在下载: https://doi.org/10.1109/tpami.2022.3201636
2025-11-15 01:24:58,283 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\CVPR\Introduction to the Special Section of CVPR 2017.pdf
2025-11-15 01:24:58,285 - INFO - root - 成功下载 (Semantic Scholar): Introduction to the Special Section of CVPR 2017
2025-11-15 01:24:58,287 - INFO - root - 正在下载: https://arxiv.org/pdf/2009.09929
2025-11-15 01:24:59,971 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\CVPR\CVPR 2020 Continual Learning in Computer Vision Competition_ Approaches, Results, Current Challenges.pdf
2025-11-15 01:24:59,973 - INFO - root - 成功下载 (Semantic Scholar): CVPR 2020 Continual Learning in Computer Vision Competition: Approaches, Results, Current Challenges and Future Directions
2025-11-15 01:24:59,974 - WARNING - root - 【手动下载提示】(无PDF): Generic Event Boundary Detection Challenge at CVPR 2021 Technical Report: Cascaded Temporal Attention Network (CASTANET)
	  URL: https://www.semanticscholar.org/paper/eadcb68ae3ef1ccbf33790df6ba5bc7ed1c93f28
	  Citations: 13 | Authors: Dexiang Hong, Congcong Li, Longyin Wen, Xinyao Wang, Libo Zhang | Date: 2021-07-01
2025-11-15 01:24:59,974 - WARNING - root - 【手动下载提示】(无PDF): Method Towards CVPR 2021 Image Matching Challenge
	  URL: https://www.semanticscholar.org/paper/1bcdf5a4d3cb4cea6eb31aa9f009a8e978b36be9
	  Citations: 4 | Authors: Xiaopeng Bi, Y. Chen, Xinyang Liu, Dehao Zhang, Ran Yan, Zheng Chai, Haotian Zhang, Xiao Liu | Date: 2021-08-10
2025-11-15 01:24:59,974 - WARNING - root - 【手动下载提示】(无PDF): Workshop on Autonomous Driving at CVPR 2021: Technical Report for Streaming Perception Challenge
	  URL: https://www.semanticscholar.org/paper/1ed30065022d1e0c0aa624364e5aefc661f66140
	  Citations: 10 | Authors: Songyang Zhang, Lin Song, Songtao Liu, Zheng Ge, Zeming Li, Xuming He, Jian Sun | Date: 2021-07-27
2025-11-15 01:24:59,974 - WARNING - root - 【手动下载提示】(无PDF): IEEE Conference on Computer Vision and Pattern Recognition Workshops, CVPR Workshops 2021, virtual, June 19-25, 2021
	  URL: https://www.semanticscholar.org/paper/f802a14e6e271dc70633e868b778f94fb1b09725
	  Citations: 9 | Authors: N/A | Date: N/A
2025-11-15 01:24:59,976 - WARNING - root - 【手动下载提示】(无PDF): SuperMix : Supplementary Material Anonymous CVPR submission
	  URL: https://www.semanticscholar.org/paper/1f026035863c95e4b9ae4fb537e20814d3be4369
	  Citations: 0 | Authors: N/A | Date: N/A
2025-11-15 01:24:59,976 - WARNING - root - 【手动下载提示】(无PDF): Supplementary Material for CVPR 2021 paper
	  URL: https://www.semanticscholar.org/paper/3c77e4ebb57c35f5543b6fd9b69e00edbf7738ec
	  Citations: 0 | Authors: N/A | Date: N/A
2025-11-15 01:24:59,977 - WARNING - root - 【手动下载提示】(无PDF): Method Towards CVPR 2021 SimLocMatch Challenge
	  URL: https://www.semanticscholar.org/paper/0d0286f994b6b50405733afaf2b434a443463f36
	  Citations: 0 | Authors: Xiaopeng Bi, Ran Yan, Zheng Chai, Haotian Zhang, Xiao Liu | Date: 2021-08-10
2025-11-15 01:24:59,978 - WARNING - root - 【手动下载提示】(无PDF): Coding Standards as Anchors for the CVPR CLIC video track
	  URL: https://www.semanticscholar.org/paper/0e6d858cd4b497519caffc22d4e08c30c51a4531
	  Citations: 1 | Authors: Théo Ladune, Pierrick Philippe | Date: 2021-05-20
2025-11-15 01:24:59,981 - INFO - root - 检索到 100 篇论文（包括待手动下载的），开始总结...
2025-11-15 01:24:59,981 - INFO - root - --- 开始论文总结阶段 ---
2025-11-15 01:24:59,983 - INFO - root - 正在总结论文 1/100: A Zero-/Few-Shot Anomaly Classification and Segmentation Method for CVPR 2023 VAND Workshop Challenge Tracks 1&2: 1st Place on Zero-shot AD and 4th Place on Few-shot AD
2025-11-15 01:25:14,088 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-15 01:26:06,270 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-15 01:26:41,269 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-15 01:26:41,279 - INFO - root - 正在提取论文图片到目录: ./export\CVPR\images\A Zero-_Few-Shot Anomaly Classification and Segmentation Method for CVPR 2023 VAND Workshop Challeng
2025-11-15 01:26:41,527 - INFO - root - 已保存图片 1/10：./export\CVPR\images\A Zero-_Few-Shot Anomaly Classification and Segmentation Method for CVPR 2023 VAND Workshop Challeng\figure_1_page5.jpeg
2025-11-15 01:26:41,585 - INFO - root - 已保存图片 2/10：./export\CVPR\images\A Zero-_Few-Shot Anomaly Classification and Segmentation Method for CVPR 2023 VAND Workshop Challeng\figure_2_page5.jpeg
2025-11-15 01:26:41,642 - INFO - root - 已保存图片 3/10：./export\CVPR\images\A Zero-_Few-Shot Anomaly Classification and Segmentation Method for CVPR 2023 VAND Workshop Challeng\figure_3_page5.jpeg
2025-11-15 01:26:41,698 - INFO - root - 已保存图片 4/10：./export\CVPR\images\A Zero-_Few-Shot Anomaly Classification and Segmentation Method for CVPR 2023 VAND Workshop Challeng\figure_4_page5.jpeg
2025-11-15 01:26:41,766 - INFO - root - 已保存图片 5/10：./export\CVPR\images\A Zero-_Few-Shot Anomaly Classification and Segmentation Method for CVPR 2023 VAND Workshop Challeng\figure_5_page5.jpeg
2025-11-15 01:26:41,821 - INFO - root - 已保存图片 6/10：./export\CVPR\images\A Zero-_Few-Shot Anomaly Classification and Segmentation Method for CVPR 2023 VAND Workshop Challeng\figure_6_page5.jpeg
2025-11-15 01:26:41,879 - INFO - root - 已保存图片 7/10：./export\CVPR\images\A Zero-_Few-Shot Anomaly Classification and Segmentation Method for CVPR 2023 VAND Workshop Challeng\figure_7_page5.jpeg
2025-11-15 01:26:41,934 - INFO - root - 已保存图片 8/10：./export\CVPR\images\A Zero-_Few-Shot Anomaly Classification and Segmentation Method for CVPR 2023 VAND Workshop Challeng\figure_8_page5.jpeg
2025-11-15 01:26:41,984 - INFO - root - 已保存图片 9/10：./export\CVPR\images\A Zero-_Few-Shot Anomaly Classification and Segmentation Method for CVPR 2023 VAND Workshop Challeng\figure_9_page5.jpeg
2025-11-15 01:26:42,032 - INFO - root - 已保存图片 10/10：./export\CVPR\images\A Zero-_Few-Shot Anomaly Classification and Segmentation Method for CVPR 2023 VAND Workshop Challeng\figure_10_page5.jpeg
2025-11-15 01:26:42,039 - INFO - root - 成功添加图片 1：./export\CVPR\images\A Zero-_Few-Shot Anomaly Classification and Segmentation Method for CVPR 2023 VAND Workshop Challeng\figure_1_page5.jpeg
2025-11-15 01:26:42,039 - INFO - root - 成功添加图片 2：./export\CVPR\images\A Zero-_Few-Shot Anomaly Classification and Segmentation Method for CVPR 2023 VAND Workshop Challeng\figure_2_page5.jpeg
2025-11-15 01:26:42,040 - INFO - root - 成功添加图片 3：./export\CVPR\images\A Zero-_Few-Shot Anomaly Classification and Segmentation Method for CVPR 2023 VAND Workshop Challeng\figure_3_page5.jpeg
2025-11-15 01:26:42,040 - INFO - root - 成功添加图片 4：./export\CVPR\images\A Zero-_Few-Shot Anomaly Classification and Segmentation Method for CVPR 2023 VAND Workshop Challeng\figure_4_page5.jpeg
2025-11-15 01:26:42,040 - INFO - root - 成功添加图片 5：./export\CVPR\images\A Zero-_Few-Shot Anomaly Classification and Segmentation Method for CVPR 2023 VAND Workshop Challeng\figure_5_page5.jpeg
2025-11-15 01:26:42,041 - INFO - root - 成功添加图片 6：./export\CVPR\images\A Zero-_Few-Shot Anomaly Classification and Segmentation Method for CVPR 2023 VAND Workshop Challeng\figure_6_page5.jpeg
2025-11-15 01:26:42,041 - INFO - root - 成功添加图片 7：./export\CVPR\images\A Zero-_Few-Shot Anomaly Classification and Segmentation Method for CVPR 2023 VAND Workshop Challeng\figure_7_page5.jpeg
2025-11-15 01:26:42,041 - INFO - root - 成功添加图片 8：./export\CVPR\images\A Zero-_Few-Shot Anomaly Classification and Segmentation Method for CVPR 2023 VAND Workshop Challeng\figure_8_page5.jpeg
2025-11-15 01:26:42,042 - INFO - root - 成功添加图片 9：./export\CVPR\images\A Zero-_Few-Shot Anomaly Classification and Segmentation Method for CVPR 2023 VAND Workshop Challeng\figure_9_page5.jpeg
2025-11-15 01:26:42,042 - INFO - root - 成功添加图片 10：./export\CVPR\images\A Zero-_Few-Shot Anomaly Classification and Segmentation Method for CVPR 2023 VAND Workshop Challeng\figure_10_page5.jpeg
2025-11-15 01:26:42,043 - INFO - root - 论文《A Zero-/Few-Shot Anomaly Classification and Segmentation Method for CVPR 2023 VAND Workshop Challenge Tracks 1&2: 1st Place on Zero-shot AD and 4th Place on Few-shot AD》的分析已保存到 ./export\CVPR\A Zero-_Few-Shot Anomaly Classification and Segmentation Method for CVPR 2023 VAND Workshop Challeng.md
2025-11-15 01:26:42,051 - INFO - root - 正在总结论文 2/100: Second Edition FRCSyn Challenge at CVPR 2024: Face Recognition Challenge in the Era of Synthetic Data
2025-11-15 01:26:54,795 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-15 01:26:54,796 - INFO - root - LLMClient: rate limit reached, sleeping 11.5s
2025-11-15 01:27:43,920 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-15 01:28:16,803 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-15 01:28:16,812 - INFO - root - 正在提取论文图片到目录: ./export\CVPR\images\Second Edition FRCSyn Challenge at CVPR 2024_ Face Recognition Challenge in the Era of Synthetic Dat
2025-11-15 01:28:17,247 - INFO - root - 已保存图片 1/10：./export\CVPR\images\Second Edition FRCSyn Challenge at CVPR 2024_ Face Recognition Challenge in the Era of Synthetic Dat\figure_1_page2.png
2025-11-15 01:28:17,249 - INFO - root - 成功添加图片 1：./export\CVPR\images\Second Edition FRCSyn Challenge at CVPR 2024_ Face Recognition Challenge in the Era of Synthetic Dat\figure_1_page2.png
2025-11-15 01:28:17,252 - INFO - root - 论文《Second Edition FRCSyn Challenge at CVPR 2024: Face Recognition Challenge in the Era of Synthetic Data》的分析已保存到 ./export\CVPR\Second Edition FRCSyn Challenge at CVPR 2024_ Face Recognition Challenge in the Era of Synthetic Dat.md
2025-11-15 01:28:17,253 - INFO - root - 跳过总结 (手动下载): Multi-Modal UAV Detection, Classification and Tracking Algorithm - Technical Report for CVPR 2024 UG2 Challenge
2025-11-15 01:28:17,253 - INFO - root - 跳过总结 (手动下载): CVPR 2023 Text Guided Video Editing Competition
2025-11-15 01:28:17,254 - INFO - root - 跳过总结 (手动下载): Multimodal Structured Generation: CVPR's 2nd MMFM Challenge Technical Report
2025-11-15 01:28:17,255 - INFO - root - 正在总结论文 6/100: Technical Report of NICE Challenge at CVPR 2024: Caption Re-ranking Evaluation Using Ensembled CLIP and Consensus Scores
2025-11-15 01:28:29,681 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-15 01:28:29,682 - INFO - root - LLMClient: rate limit reached, sleeping 14.2s
2025-11-15 01:29:32,908 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-15 01:30:03,430 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-15 01:30:03,440 - INFO - root - 正在提取论文图片到目录: ./export\CVPR\images\Technical Report of NICE Challenge at CVPR 2024_ Caption Re-ranking Evaluation Using Ensembled CLIP
2025-11-15 01:30:03,622 - INFO - root - 已保存图片 1/10：./export\CVPR\images\Technical Report of NICE Challenge at CVPR 2024_ Caption Re-ranking Evaluation Using Ensembled CLIP\figure_1_page1.png
2025-11-15 01:30:03,772 - INFO - root - 已保存图片 2/10：./export\CVPR\images\Technical Report of NICE Challenge at CVPR 2024_ Caption Re-ranking Evaluation Using Ensembled CLIP\figure_2_page3.png
2025-11-15 01:30:03,773 - INFO - root - 成功添加图片 1：./export\CVPR\images\Technical Report of NICE Challenge at CVPR 2024_ Caption Re-ranking Evaluation Using Ensembled CLIP\figure_1_page1.png
2025-11-15 01:30:03,773 - INFO - root - 成功添加图片 2：./export\CVPR\images\Technical Report of NICE Challenge at CVPR 2024_ Caption Re-ranking Evaluation Using Ensembled CLIP\figure_2_page3.png
2025-11-15 01:30:03,775 - INFO - root - 论文《Technical Report of NICE Challenge at CVPR 2024: Caption Re-ranking Evaluation Using Ensembled CLIP and Consensus Scores》的分析已保存到 ./export\CVPR\Technical Report of NICE Challenge at CVPR 2024_ Caption Re-ranking Evaluation Using Ensembled CLIP.md
2025-11-15 01:30:03,777 - INFO - root - 正在总结论文 7/100: Large Multimodal Models: Notes on CVPR 2023 Tutorial
2025-11-15 01:30:13,179 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-15 01:30:13,182 - INFO - root - LLMClient: rate limit reached, sleeping 19.7s
2025-11-15 01:31:28,033 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-15 01:32:06,821 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-15 01:32:06,823 - INFO - root - 正在提取论文图片到目录: ./export\CVPR\images\Large Multimodal Models_ Notes on CVPR 2023 Tutorial
2025-11-15 01:32:08,865 - INFO - root - 已保存图片 1/10：./export\CVPR\images\Large Multimodal Models_ Notes on CVPR 2023 Tutorial\figure_1_page11.jpeg
2025-11-15 01:32:08,979 - INFO - root - 已保存图片 2/10：./export\CVPR\images\Large Multimodal Models_ Notes on CVPR 2023 Tutorial\figure_2_page11.jpeg
2025-11-15 01:32:09,078 - INFO - root - 已保存图片 3/10：./export\CVPR\images\Large Multimodal Models_ Notes on CVPR 2023 Tutorial\figure_3_page6.png
2025-11-15 01:32:09,146 - INFO - root - 已保存图片 4/10：./export\CVPR\images\Large Multimodal Models_ Notes on CVPR 2023 Tutorial\figure_4_page20.png
2025-11-15 01:32:09,230 - INFO - root - 已保存图片 5/10：./export\CVPR\images\Large Multimodal Models_ Notes on CVPR 2023 Tutorial\figure_5_page17.jpeg
2025-11-15 01:32:09,310 - INFO - root - 已保存图片 6/10：./export\CVPR\images\Large Multimodal Models_ Notes on CVPR 2023 Tutorial\figure_6_page17.jpeg
2025-11-15 01:32:09,380 - INFO - root - 已保存图片 7/10：./export\CVPR\images\Large Multimodal Models_ Notes on CVPR 2023 Tutorial\figure_7_page6.png
2025-11-15 01:32:09,460 - INFO - root - 已保存图片 8/10：./export\CVPR\images\Large Multimodal Models_ Notes on CVPR 2023 Tutorial\figure_8_page5.jpeg
2025-11-15 01:32:09,655 - INFO - root - 已保存图片 9/10：./export\CVPR\images\Large Multimodal Models_ Notes on CVPR 2023 Tutorial\figure_9_page1.png
2025-11-15 01:32:09,813 - INFO - root - 已保存图片 10/10：./export\CVPR\images\Large Multimodal Models_ Notes on CVPR 2023 Tutorial\figure_10_page13.png
2025-11-15 01:32:09,833 - INFO - root - 成功添加图片 1：./export\CVPR\images\Large Multimodal Models_ Notes on CVPR 2023 Tutorial\figure_1_page11.jpeg
2025-11-15 01:32:09,833 - INFO - root - 成功添加图片 2：./export\CVPR\images\Large Multimodal Models_ Notes on CVPR 2023 Tutorial\figure_2_page11.jpeg
2025-11-15 01:32:09,834 - INFO - root - 成功添加图片 3：./export\CVPR\images\Large Multimodal Models_ Notes on CVPR 2023 Tutorial\figure_3_page6.png
2025-11-15 01:32:09,834 - INFO - root - 成功添加图片 4：./export\CVPR\images\Large Multimodal Models_ Notes on CVPR 2023 Tutorial\figure_4_page20.png
2025-11-15 01:32:09,834 - INFO - root - 成功添加图片 5：./export\CVPR\images\Large Multimodal Models_ Notes on CVPR 2023 Tutorial\figure_5_page17.jpeg
2025-11-15 01:32:09,836 - INFO - root - 成功添加图片 6：./export\CVPR\images\Large Multimodal Models_ Notes on CVPR 2023 Tutorial\figure_6_page17.jpeg
2025-11-15 01:32:09,836 - INFO - root - 成功添加图片 7：./export\CVPR\images\Large Multimodal Models_ Notes on CVPR 2023 Tutorial\figure_7_page6.png
2025-11-15 01:32:09,836 - INFO - root - 成功添加图片 8：./export\CVPR\images\Large Multimodal Models_ Notes on CVPR 2023 Tutorial\figure_8_page5.jpeg
2025-11-15 01:32:09,842 - INFO - root - 成功添加图片 9：./export\CVPR\images\Large Multimodal Models_ Notes on CVPR 2023 Tutorial\figure_9_page1.png
2025-11-15 01:32:09,843 - INFO - root - 成功添加图片 10：./export\CVPR\images\Large Multimodal Models_ Notes on CVPR 2023 Tutorial\figure_10_page13.png
2025-11-15 01:32:09,846 - INFO - root - 论文《Large Multimodal Models: Notes on CVPR 2023 Tutorial》的分析已保存到 ./export\CVPR\Large Multimodal Models_ Notes on CVPR 2023 Tutorial.md
2025-11-15 01:32:09,848 - INFO - root - 跳过总结 (手动下载): Black-Box Sparse Adversarial Attack via Multi-Objective Optimisation CVPR Proceedings
2025-11-15 01:32:09,849 - INFO - root - 跳过总结 (手动下载): Learning the Bitter Lesson: Empirical Evidence from 20 Years of CVPR Proceedings
2025-11-15 01:32:09,849 - INFO - root - 跳过总结 (手动下载): Driving with InternVL: Oustanding Champion in the Track on Driving with Language of the Autonomous Grand Challenge at CVPR 2024
2025-11-15 01:32:09,849 - INFO - root - 跳过总结 (手动下载): 2nd Place Solution for MeViS Track in CVPR 2024 PVUW Workshop: Motion Expression guided Video Segmentation
2025-11-15 01:32:09,849 - INFO - root - 跳过总结 (手动下载): MapVision: CVPR 2024 Autonomous Grand Challenge Mapless Driving Tech Report
2025-11-15 01:32:09,849 - INFO - root - 跳过总结 (手动下载): IEEE/CVF Conference on Computer Vision and Pattern Recognition, CVPR 2024, Seattle, WA, USA, June 16-22, 2024
2025-11-15 01:32:09,850 - INFO - root - 跳过总结 (手动下载): MetaFood CVPR 2024 Challenge on Physically Informed 3D Food Reconstruction: Methods and Results
2025-11-15 01:32:09,850 - INFO - root - 跳过总结 (手动下载): 3rd Place Solution for MeViS Track in CVPR 2024 PVUW workshop: Motion Expression guided Video Segmentation
2025-11-15 01:32:09,850 - INFO - root - 跳过总结 (手动下载): Separating Drone Point Clouds From Complex Backgrounds by Cluster Filter - Technical Report for CVPR 2024 UG2 Challenge
2025-11-15 01:32:09,850 - INFO - root - 跳过总结 (手动下载): Solution for SMART-101 Challenge of CVPR Multi-modal Algorithmic Reasoning Task 2024
2025-11-15 01:32:09,851 - INFO - root - 跳过总结 (手动下载): Technique Report of CVPR 2024 PBDL Challenges
2025-11-15 01:32:09,851 - INFO - root - 跳过总结 (手动下载): 1st Place Winner of the 2024 Pixel-level Video Understanding in the Wild (CVPR'24 PVUW) Challenge in Video Panoptic Segmentation and Best Long Video Consistency of Video Semantic Segmentation
2025-11-15 01:32:09,851 - INFO - root - 跳过总结 (手动下载): WiCV@CVPR2024: The Thirteenth Women In Computer Vision Workshop at the Annual CVPR Conference
2025-11-15 01:32:09,851 - INFO - root - 跳过总结 (手动下载): Solution for CVPR 2024 UG2+ Challenge Track on All Weather Semantic Segmentation
2025-11-15 01:32:09,852 - INFO - root - 跳过总结 (手动下载): A Two-Stage Adverse Weather Semantic Segmentation Method for WeatherProof Challenge CVPR 2024 Workshop UG2+
2025-11-15 01:32:09,852 - INFO - root - 跳过总结 (手动下载): Technical Report for CVPR 2024 WeatherProof Dataset Challenge: Semantic Segmentation on Paired Real Data
2025-11-15 01:32:09,852 - INFO - root - 跳过总结 (手动下载): 1st Place Solution for MeViS Track in CVPR 2024 PVUW Workshop: Motion Expression guided Video Segmentation
2025-11-15 01:32:09,852 - INFO - root - 跳过总结 (手动下载): 1st Place Solution for MOSE Track in CVPR 2024 PVUW Workshop: Complex Video Object Segmentation
2025-11-15 01:32:09,855 - INFO - root - 跳过总结 (手动下载): 2nd Place Solution for MOSE Track in CVPR 2024 PVUW workshop: Complex Video Object Segmentation
2025-11-15 01:32:09,855 - INFO - root - 跳过总结 (手动下载): 3rd Place Solution for MOSE Track in CVPR 2024 PVUW workshop: Complex Video Object Segmentation
2025-11-15 01:32:09,857 - INFO - root - 跳过总结 (手动下载): IEEE/CVF Conference on Computer Vision and Pattern Recognition, CVPR 2024 - Workshops, Seattle, WA, USA, June 17-18, 2024
2025-11-15 01:32:09,857 - INFO - root - 跳过总结 (手动下载): The Solution for the CVPR 2023 1st foundation model challenge-Track2
2025-11-15 01:32:09,857 - INFO - root - 正在总结论文 30/100: Multi-Scale Occ: 4th Place Solution for CVPR 2023 3D Occupancy Prediction Challenge
2025-11-15 01:32:21,797 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-15 01:32:21,802 - INFO - root - LLMClient: rate limit reached, sleeping 6.2s
2025-11-15 01:33:26,740 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-15 01:33:59,863 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-15 01:33:59,866 - INFO - root - 正在提取论文图片到目录: ./export\CVPR\images\Multi-Scale Occ_ 4th Place Solution for CVPR 2023 3D Occupancy Prediction Challenge
2025-11-15 01:34:00,028 - INFO - root - 已保存图片 1/10：./export\CVPR\images\Multi-Scale Occ_ 4th Place Solution for CVPR 2023 3D Occupancy Prediction Challenge\figure_1_page2.png
2025-11-15 01:34:00,030 - INFO - root - 成功添加图片 1：./export\CVPR\images\Multi-Scale Occ_ 4th Place Solution for CVPR 2023 3D Occupancy Prediction Challenge\figure_1_page2.png
2025-11-15 01:34:00,033 - INFO - root - 论文《Multi-Scale Occ: 4th Place Solution for CVPR 2023 3D Occupancy Prediction Challenge》的分析已保存到 ./export\CVPR\Multi-Scale Occ_ 4th Place Solution for CVPR 2023 3D Occupancy Prediction Challenge.md
2025-11-15 01:34:00,036 - INFO - root - 正在总结论文 31/100: The 1st-place Solution for CVPR 2023 OpenLane Topology in Autonomous Driving Challenge
2025-11-15 01:34:09,451 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-15 01:34:09,452 - INFO - root - LLMClient: rate limit reached, sleeping 17.3s
2025-11-15 01:35:12,942 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-15 01:35:52,869 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-15 01:35:52,876 - INFO - root - 正在提取论文图片到目录: ./export\CVPR\images\The 1st-place Solution for CVPR 2023 OpenLane Topology in Autonomous Driving Challenge
2025-11-15 01:35:53,049 - INFO - root - 已保存图片 1/10：./export\CVPR\images\The 1st-place Solution for CVPR 2023 OpenLane Topology in Autonomous Driving Challenge\figure_1_page1.jpeg
2025-11-15 01:35:53,162 - INFO - root - 已保存图片 2/10：./export\CVPR\images\The 1st-place Solution for CVPR 2023 OpenLane Topology in Autonomous Driving Challenge\figure_2_page2.png
2025-11-15 01:35:53,200 - INFO - root - 已保存图片 3/10：./export\CVPR\images\The 1st-place Solution for CVPR 2023 OpenLane Topology in Autonomous Driving Challenge\figure_3_page1.jpeg
2025-11-15 01:35:53,211 - INFO - root - 已保存图片 4/10：./export\CVPR\images\The 1st-place Solution for CVPR 2023 OpenLane Topology in Autonomous Driving Challenge\figure_4_page1.jpeg
2025-11-15 01:35:53,223 - INFO - root - 已保存图片 5/10：./export\CVPR\images\The 1st-place Solution for CVPR 2023 OpenLane Topology in Autonomous Driving Challenge\figure_5_page1.jpeg
2025-11-15 01:35:53,246 - INFO - root - 已保存图片 6/10：./export\CVPR\images\The 1st-place Solution for CVPR 2023 OpenLane Topology in Autonomous Driving Challenge\figure_6_page1.jpeg
2025-11-15 01:35:53,267 - INFO - root - 已保存图片 7/10：./export\CVPR\images\The 1st-place Solution for CVPR 2023 OpenLane Topology in Autonomous Driving Challenge\figure_7_page1.jpeg
2025-11-15 01:35:53,294 - INFO - root - 已保存图片 8/10：./export\CVPR\images\The 1st-place Solution for CVPR 2023 OpenLane Topology in Autonomous Driving Challenge\figure_8_page1.jpeg
2025-11-15 01:35:53,318 - INFO - root - 已保存图片 9/10：./export\CVPR\images\The 1st-place Solution for CVPR 2023 OpenLane Topology in Autonomous Driving Challenge\figure_9_page1.jpeg
2025-11-15 01:35:53,345 - INFO - root - 已保存图片 10/10：./export\CVPR\images\The 1st-place Solution for CVPR 2023 OpenLane Topology in Autonomous Driving Challenge\figure_10_page1.jpeg
2025-11-15 01:35:53,348 - INFO - root - 成功添加图片 1：./export\CVPR\images\The 1st-place Solution for CVPR 2023 OpenLane Topology in Autonomous Driving Challenge\figure_1_page1.jpeg
2025-11-15 01:35:53,349 - INFO - root - 成功添加图片 2：./export\CVPR\images\The 1st-place Solution for CVPR 2023 OpenLane Topology in Autonomous Driving Challenge\figure_2_page2.png
2025-11-15 01:35:53,350 - INFO - root - 成功添加图片 3：./export\CVPR\images\The 1st-place Solution for CVPR 2023 OpenLane Topology in Autonomous Driving Challenge\figure_3_page1.jpeg
2025-11-15 01:35:53,350 - INFO - root - 成功添加图片 4：./export\CVPR\images\The 1st-place Solution for CVPR 2023 OpenLane Topology in Autonomous Driving Challenge\figure_4_page1.jpeg
2025-11-15 01:35:53,350 - INFO - root - 成功添加图片 5：./export\CVPR\images\The 1st-place Solution for CVPR 2023 OpenLane Topology in Autonomous Driving Challenge\figure_5_page1.jpeg
2025-11-15 01:35:53,351 - INFO - root - 成功添加图片 6：./export\CVPR\images\The 1st-place Solution for CVPR 2023 OpenLane Topology in Autonomous Driving Challenge\figure_6_page1.jpeg
2025-11-15 01:35:53,352 - INFO - root - 成功添加图片 7：./export\CVPR\images\The 1st-place Solution for CVPR 2023 OpenLane Topology in Autonomous Driving Challenge\figure_7_page1.jpeg
2025-11-15 01:35:53,352 - INFO - root - 成功添加图片 8：./export\CVPR\images\The 1st-place Solution for CVPR 2023 OpenLane Topology in Autonomous Driving Challenge\figure_8_page1.jpeg
2025-11-15 01:35:53,353 - INFO - root - 成功添加图片 9：./export\CVPR\images\The 1st-place Solution for CVPR 2023 OpenLane Topology in Autonomous Driving Challenge\figure_9_page1.jpeg
2025-11-15 01:35:53,353 - INFO - root - 成功添加图片 10：./export\CVPR\images\The 1st-place Solution for CVPR 2023 OpenLane Topology in Autonomous Driving Challenge\figure_10_page1.jpeg
2025-11-15 01:35:53,356 - INFO - root - 论文《The 1st-place Solution for CVPR 2023 OpenLane Topology in Autonomous Driving Challenge》的分析已保存到 ./export\CVPR\The 1st-place Solution for CVPR 2023 OpenLane Topology in Autonomous Driving Challenge.md
2025-11-15 01:35:53,361 - INFO - root - 跳过总结 (手动下载): IEEE/CVF Conference on Computer Vision and Pattern Recognition, CVPR 2023, Vancouver, BC, Canada, June 17-24, 2023
2025-11-15 01:35:53,363 - INFO - root - 跳过总结 (手动下载): IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops, CVPR Workshops 2022, New Orleans, LA, USA, June 19-20, 2022
2025-11-15 01:35:53,364 - INFO - root - 正在总结论文 34/100: A Boosted Model Ensembling Approach to Ball Action Spotting in Videos: The Runner-Up Solution to CVPR'23 SoccerNet Challenge
2025-11-15 01:36:04,411 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-15 01:36:04,412 - INFO - root - LLMClient: rate limit reached, sleeping 8.5s
2025-11-15 01:37:02,391 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-15 01:37:31,311 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-15 01:37:31,322 - INFO - root - 正在提取论文图片到目录: ./export\CVPR\images\A Boosted Model Ensembling Approach to Ball Action Spotting in Videos_ The Runner-Up Solution to CVP
2025-11-15 01:37:31,403 - INFO - root - 已保存图片 1/10：./export\CVPR\images\A Boosted Model Ensembling Approach to Ball Action Spotting in Videos_ The Runner-Up Solution to CVP\figure_1_page3.jpeg
2025-11-15 01:37:31,439 - INFO - root - 已保存图片 2/10：./export\CVPR\images\A Boosted Model Ensembling Approach to Ball Action Spotting in Videos_ The Runner-Up Solution to CVP\figure_2_page3.jpeg
2025-11-15 01:37:31,469 - INFO - root - 已保存图片 3/10：./export\CVPR\images\A Boosted Model Ensembling Approach to Ball Action Spotting in Videos_ The Runner-Up Solution to CVP\figure_3_page3.jpeg
2025-11-15 01:37:31,508 - INFO - root - 已保存图片 4/10：./export\CVPR\images\A Boosted Model Ensembling Approach to Ball Action Spotting in Videos_ The Runner-Up Solution to CVP\figure_4_page3.jpeg
2025-11-15 01:37:31,533 - INFO - root - 已保存图片 5/10：./export\CVPR\images\A Boosted Model Ensembling Approach to Ball Action Spotting in Videos_ The Runner-Up Solution to CVP\figure_5_page3.jpeg
2025-11-15 01:37:31,561 - INFO - root - 已保存图片 6/10：./export\CVPR\images\A Boosted Model Ensembling Approach to Ball Action Spotting in Videos_ The Runner-Up Solution to CVP\figure_6_page3.jpeg
2025-11-15 01:37:31,590 - INFO - root - 已保存图片 7/10：./export\CVPR\images\A Boosted Model Ensembling Approach to Ball Action Spotting in Videos_ The Runner-Up Solution to CVP\figure_7_page3.jpeg
2025-11-15 01:37:31,617 - INFO - root - 已保存图片 8/10：./export\CVPR\images\A Boosted Model Ensembling Approach to Ball Action Spotting in Videos_ The Runner-Up Solution to CVP\figure_8_page3.jpeg
2025-11-15 01:37:31,644 - INFO - root - 已保存图片 9/10：./export\CVPR\images\A Boosted Model Ensembling Approach to Ball Action Spotting in Videos_ The Runner-Up Solution to CVP\figure_9_page3.jpeg
2025-11-15 01:37:31,724 - INFO - root - 已保存图片 10/10：./export\CVPR\images\A Boosted Model Ensembling Approach to Ball Action Spotting in Videos_ The Runner-Up Solution to CVP\figure_10_page3.png
2025-11-15 01:37:31,725 - INFO - root - 成功添加图片 1：./export\CVPR\images\A Boosted Model Ensembling Approach to Ball Action Spotting in Videos_ The Runner-Up Solution to CVP\figure_1_page3.jpeg
2025-11-15 01:37:31,725 - INFO - root - 成功添加图片 2：./export\CVPR\images\A Boosted Model Ensembling Approach to Ball Action Spotting in Videos_ The Runner-Up Solution to CVP\figure_2_page3.jpeg
2025-11-15 01:37:31,725 - INFO - root - 成功添加图片 3：./export\CVPR\images\A Boosted Model Ensembling Approach to Ball Action Spotting in Videos_ The Runner-Up Solution to CVP\figure_3_page3.jpeg
2025-11-15 01:37:31,725 - INFO - root - 成功添加图片 4：./export\CVPR\images\A Boosted Model Ensembling Approach to Ball Action Spotting in Videos_ The Runner-Up Solution to CVP\figure_4_page3.jpeg
2025-11-15 01:37:31,725 - INFO - root - 成功添加图片 5：./export\CVPR\images\A Boosted Model Ensembling Approach to Ball Action Spotting in Videos_ The Runner-Up Solution to CVP\figure_5_page3.jpeg
2025-11-15 01:37:31,726 - INFO - root - 成功添加图片 6：./export\CVPR\images\A Boosted Model Ensembling Approach to Ball Action Spotting in Videos_ The Runner-Up Solution to CVP\figure_6_page3.jpeg
2025-11-15 01:37:31,726 - INFO - root - 成功添加图片 7：./export\CVPR\images\A Boosted Model Ensembling Approach to Ball Action Spotting in Videos_ The Runner-Up Solution to CVP\figure_7_page3.jpeg
2025-11-15 01:37:31,726 - INFO - root - 成功添加图片 8：./export\CVPR\images\A Boosted Model Ensembling Approach to Ball Action Spotting in Videos_ The Runner-Up Solution to CVP\figure_8_page3.jpeg
2025-11-15 01:37:31,726 - INFO - root - 成功添加图片 9：./export\CVPR\images\A Boosted Model Ensembling Approach to Ball Action Spotting in Videos_ The Runner-Up Solution to CVP\figure_9_page3.jpeg
2025-11-15 01:37:31,727 - INFO - root - 成功添加图片 10：./export\CVPR\images\A Boosted Model Ensembling Approach to Ball Action Spotting in Videos_ The Runner-Up Solution to CVP\figure_10_page3.png
2025-11-15 01:37:31,728 - INFO - root - 论文《A Boosted Model Ensembling Approach to Ball Action Spotting in Videos: The Runner-Up Solution to CVPR'23 SoccerNet Challenge》的分析已保存到 ./export\CVPR\A Boosted Model Ensembling Approach to Ball Action Spotting in Videos_ The Runner-Up Solution to CVP.md
2025-11-15 01:37:31,731 - INFO - root - 正在总结论文 35/100: First Place Solution to the CVPR'2023 AQTC Challenge: A Function-Interaction Centric Approach with Spatiotemporal Visual-Language Alignment
2025-11-15 01:37:41,659 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-15 01:37:41,663 - INFO - root - LLMClient: rate limit reached, sleeping 20.7s
2025-11-15 01:39:03,132 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-15 01:39:38,808 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-15 01:39:38,820 - INFO - root - 正在提取论文图片到目录: ./export\CVPR\images\First Place Solution to the CVPR'2023 AQTC Challenge_ A Function-Interaction Centric Approach with S
2025-11-15 01:39:38,890 - INFO - root - 已保存图片 1/10：./export\CVPR\images\First Place Solution to the CVPR'2023 AQTC Challenge_ A Function-Interaction Centric Approach with S\figure_1_page4.jpeg
2025-11-15 01:39:38,939 - INFO - root - 已保存图片 2/10：./export\CVPR\images\First Place Solution to the CVPR'2023 AQTC Challenge_ A Function-Interaction Centric Approach with S\figure_2_page4.jpeg
2025-11-15 01:39:38,976 - INFO - root - 已保存图片 3/10：./export\CVPR\images\First Place Solution to the CVPR'2023 AQTC Challenge_ A Function-Interaction Centric Approach with S\figure_3_page4.jpeg
2025-11-15 01:39:39,011 - INFO - root - 已保存图片 4/10：./export\CVPR\images\First Place Solution to the CVPR'2023 AQTC Challenge_ A Function-Interaction Centric Approach with S\figure_4_page4.jpeg
2025-11-15 01:39:39,052 - INFO - root - 已保存图片 5/10：./export\CVPR\images\First Place Solution to the CVPR'2023 AQTC Challenge_ A Function-Interaction Centric Approach with S\figure_5_page4.jpeg
2025-11-15 01:39:39,077 - INFO - root - 已保存图片 6/10：./export\CVPR\images\First Place Solution to the CVPR'2023 AQTC Challenge_ A Function-Interaction Centric Approach with S\figure_6_page1.jpeg
2025-11-15 01:39:39,102 - INFO - root - 已保存图片 7/10：./export\CVPR\images\First Place Solution to the CVPR'2023 AQTC Challenge_ A Function-Interaction Centric Approach with S\figure_7_page1.jpeg
2025-11-15 01:39:39,132 - INFO - root - 已保存图片 8/10：./export\CVPR\images\First Place Solution to the CVPR'2023 AQTC Challenge_ A Function-Interaction Centric Approach with S\figure_8_page1.jpeg
2025-11-15 01:39:39,157 - INFO - root - 已保存图片 9/10：./export\CVPR\images\First Place Solution to the CVPR'2023 AQTC Challenge_ A Function-Interaction Centric Approach with S\figure_9_page1.jpeg
2025-11-15 01:39:39,188 - INFO - root - 已保存图片 10/10：./export\CVPR\images\First Place Solution to the CVPR'2023 AQTC Challenge_ A Function-Interaction Centric Approach with S\figure_10_page1.jpeg
2025-11-15 01:39:39,191 - INFO - root - 成功添加图片 1：./export\CVPR\images\First Place Solution to the CVPR'2023 AQTC Challenge_ A Function-Interaction Centric Approach with S\figure_1_page4.jpeg
2025-11-15 01:39:39,191 - INFO - root - 成功添加图片 2：./export\CVPR\images\First Place Solution to the CVPR'2023 AQTC Challenge_ A Function-Interaction Centric Approach with S\figure_2_page4.jpeg
2025-11-15 01:39:39,192 - INFO - root - 成功添加图片 3：./export\CVPR\images\First Place Solution to the CVPR'2023 AQTC Challenge_ A Function-Interaction Centric Approach with S\figure_3_page4.jpeg
2025-11-15 01:39:39,192 - INFO - root - 成功添加图片 4：./export\CVPR\images\First Place Solution to the CVPR'2023 AQTC Challenge_ A Function-Interaction Centric Approach with S\figure_4_page4.jpeg
2025-11-15 01:39:39,192 - INFO - root - 成功添加图片 5：./export\CVPR\images\First Place Solution to the CVPR'2023 AQTC Challenge_ A Function-Interaction Centric Approach with S\figure_5_page4.jpeg
2025-11-15 01:39:39,193 - INFO - root - 成功添加图片 6：./export\CVPR\images\First Place Solution to the CVPR'2023 AQTC Challenge_ A Function-Interaction Centric Approach with S\figure_6_page1.jpeg
2025-11-15 01:39:39,194 - INFO - root - 成功添加图片 7：./export\CVPR\images\First Place Solution to the CVPR'2023 AQTC Challenge_ A Function-Interaction Centric Approach with S\figure_7_page1.jpeg
2025-11-15 01:39:39,194 - INFO - root - 成功添加图片 8：./export\CVPR\images\First Place Solution to the CVPR'2023 AQTC Challenge_ A Function-Interaction Centric Approach with S\figure_8_page1.jpeg
2025-11-15 01:39:39,196 - INFO - root - 成功添加图片 9：./export\CVPR\images\First Place Solution to the CVPR'2023 AQTC Challenge_ A Function-Interaction Centric Approach with S\figure_9_page1.jpeg
2025-11-15 01:39:39,196 - INFO - root - 成功添加图片 10：./export\CVPR\images\First Place Solution to the CVPR'2023 AQTC Challenge_ A Function-Interaction Centric Approach with S\figure_10_page1.jpeg
2025-11-15 01:39:39,197 - INFO - root - 论文《First Place Solution to the CVPR'2023 AQTC Challenge: A Function-Interaction Centric Approach with Spatiotemporal Visual-Language Alignment》的分析已保存到 ./export\CVPR\First Place Solution to the CVPR'2023 AQTC Challenge_ A Function-Interaction Centric Approach with S.md
2025-11-15 01:39:39,200 - INFO - root - 正在总结论文 36/100: A Two-Stage Real Image Deraining Method for GT-RAIN Challenge CVPR 2023 Workshop UG2 + Track 3
2025-11-15 01:39:52,103 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-15 01:39:52,106 - INFO - root - LLMClient: rate limit reached, sleeping 11.0s
2025-11-15 01:41:05,463 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-15 01:41:37,825 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-15 01:41:37,837 - INFO - root - 正在提取论文图片到目录: ./export\CVPR\images\A Two-Stage Real Image Deraining Method for GT-RAIN Challenge CVPR 2023 Workshop UG2 + Track 3
2025-11-15 01:41:38,044 - INFO - root - 已保存图片 1/10：./export\CVPR\images\A Two-Stage Real Image Deraining Method for GT-RAIN Challenge CVPR 2023 Workshop UG2 + Track 3\figure_1_page5.jpeg
2025-11-15 01:41:38,148 - INFO - root - 已保存图片 2/10：./export\CVPR\images\A Two-Stage Real Image Deraining Method for GT-RAIN Challenge CVPR 2023 Workshop UG2 + Track 3\figure_2_page5.png
2025-11-15 01:41:38,260 - INFO - root - 已保存图片 3/10：./export\CVPR\images\A Two-Stage Real Image Deraining Method for GT-RAIN Challenge CVPR 2023 Workshop UG2 + Track 3\figure_3_page5.png
2025-11-15 01:41:38,362 - INFO - root - 已保存图片 4/10：./export\CVPR\images\A Two-Stage Real Image Deraining Method for GT-RAIN Challenge CVPR 2023 Workshop UG2 + Track 3\figure_4_page5.png
2025-11-15 01:41:38,386 - INFO - root - 已保存图片 5/10：./export\CVPR\images\A Two-Stage Real Image Deraining Method for GT-RAIN Challenge CVPR 2023 Workshop UG2 + Track 3\figure_5_page2.jpeg
2025-11-15 01:41:38,415 - INFO - root - 已保存图片 6/10：./export\CVPR\images\A Two-Stage Real Image Deraining Method for GT-RAIN Challenge CVPR 2023 Workshop UG2 + Track 3\figure_6_page5.jpeg
2025-11-15 01:41:38,436 - INFO - root - 已保存图片 7/10：./export\CVPR\images\A Two-Stage Real Image Deraining Method for GT-RAIN Challenge CVPR 2023 Workshop UG2 + Track 3\figure_7_page1.jpeg
2025-11-15 01:41:38,458 - INFO - root - 已保存图片 8/10：./export\CVPR\images\A Two-Stage Real Image Deraining Method for GT-RAIN Challenge CVPR 2023 Workshop UG2 + Track 3\figure_8_page2.jpeg
2025-11-15 01:41:38,483 - INFO - root - 已保存图片 9/10：./export\CVPR\images\A Two-Stage Real Image Deraining Method for GT-RAIN Challenge CVPR 2023 Workshop UG2 + Track 3\figure_9_page2.jpeg
2025-11-15 01:41:38,508 - INFO - root - 已保存图片 10/10：./export\CVPR\images\A Two-Stage Real Image Deraining Method for GT-RAIN Challenge CVPR 2023 Workshop UG2 + Track 3\figure_10_page2.jpeg
2025-11-15 01:41:38,509 - INFO - root - 成功添加图片 1：./export\CVPR\images\A Two-Stage Real Image Deraining Method for GT-RAIN Challenge CVPR 2023 Workshop UG2 + Track 3\figure_1_page5.jpeg
2025-11-15 01:41:38,510 - INFO - root - 成功添加图片 2：./export\CVPR\images\A Two-Stage Real Image Deraining Method for GT-RAIN Challenge CVPR 2023 Workshop UG2 + Track 3\figure_2_page5.png
2025-11-15 01:41:38,510 - INFO - root - 成功添加图片 3：./export\CVPR\images\A Two-Stage Real Image Deraining Method for GT-RAIN Challenge CVPR 2023 Workshop UG2 + Track 3\figure_3_page5.png
2025-11-15 01:41:38,510 - INFO - root - 成功添加图片 4：./export\CVPR\images\A Two-Stage Real Image Deraining Method for GT-RAIN Challenge CVPR 2023 Workshop UG2 + Track 3\figure_4_page5.png
2025-11-15 01:41:38,511 - INFO - root - 成功添加图片 5：./export\CVPR\images\A Two-Stage Real Image Deraining Method for GT-RAIN Challenge CVPR 2023 Workshop UG2 + Track 3\figure_5_page2.jpeg
2025-11-15 01:41:38,511 - INFO - root - 成功添加图片 6：./export\CVPR\images\A Two-Stage Real Image Deraining Method for GT-RAIN Challenge CVPR 2023 Workshop UG2 + Track 3\figure_6_page5.jpeg
2025-11-15 01:41:38,511 - INFO - root - 成功添加图片 7：./export\CVPR\images\A Two-Stage Real Image Deraining Method for GT-RAIN Challenge CVPR 2023 Workshop UG2 + Track 3\figure_7_page1.jpeg
2025-11-15 01:41:38,512 - INFO - root - 成功添加图片 8：./export\CVPR\images\A Two-Stage Real Image Deraining Method for GT-RAIN Challenge CVPR 2023 Workshop UG2 + Track 3\figure_8_page2.jpeg
2025-11-15 01:41:38,512 - INFO - root - 成功添加图片 9：./export\CVPR\images\A Two-Stage Real Image Deraining Method for GT-RAIN Challenge CVPR 2023 Workshop UG2 + Track 3\figure_9_page2.jpeg
2025-11-15 01:41:38,512 - INFO - root - 成功添加图片 10：./export\CVPR\images\A Two-Stage Real Image Deraining Method for GT-RAIN Challenge CVPR 2023 Workshop UG2 + Track 3\figure_10_page2.jpeg
2025-11-15 01:41:38,515 - INFO - root - 论文《A Two-Stage Real Image Deraining Method for GT-RAIN Challenge CVPR 2023 Workshop UG2 + Track 3》的分析已保存到 ./export\CVPR\A Two-Stage Real Image Deraining Method for GT-RAIN Challenge CVPR 2023 Workshop UG2 + Track 3.md
2025-11-15 01:41:38,516 - INFO - root - 正在总结论文 37/100: Restormer-Plus for Real World Image Deraining: the Runner-up Solution to the GT-RAIN Challenge (CVPR 2023 UG2+ Track 3)
2025-11-15 01:41:51,346 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-15 01:41:51,349 - INFO - root - LLMClient: rate limit reached, sleeping 14.1s
2025-11-15 01:42:49,959 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-15 01:43:22,297 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-15 01:43:22,308 - INFO - root - 正在提取论文图片到目录: ./export\CVPR\images\Restormer-Plus for Real World Image Deraining_ the Runner-up Solution to the GT-RAIN Challenge (CVPR
2025-11-15 01:43:22,389 - INFO - root - 已保存图片 1/10：./export\CVPR\images\Restormer-Plus for Real World Image Deraining_ the Runner-up Solution to the GT-RAIN Challenge (CVPR\figure_1_page3.jpeg
2025-11-15 01:43:22,419 - INFO - root - 已保存图片 2/10：./export\CVPR\images\Restormer-Plus for Real World Image Deraining_ the Runner-up Solution to the GT-RAIN Challenge (CVPR\figure_2_page3.jpeg
2025-11-15 01:43:22,440 - INFO - root - 已保存图片 3/10：./export\CVPR\images\Restormer-Plus for Real World Image Deraining_ the Runner-up Solution to the GT-RAIN Challenge (CVPR\figure_3_page1.jpeg
2025-11-15 01:43:22,464 - INFO - root - 已保存图片 4/10：./export\CVPR\images\Restormer-Plus for Real World Image Deraining_ the Runner-up Solution to the GT-RAIN Challenge (CVPR\figure_4_page1.jpeg
2025-11-15 01:43:22,488 - INFO - root - 已保存图片 5/10：./export\CVPR\images\Restormer-Plus for Real World Image Deraining_ the Runner-up Solution to the GT-RAIN Challenge (CVPR\figure_5_page1.jpeg
2025-11-15 01:43:22,511 - INFO - root - 已保存图片 6/10：./export\CVPR\images\Restormer-Plus for Real World Image Deraining_ the Runner-up Solution to the GT-RAIN Challenge (CVPR\figure_6_page2.jpeg
2025-11-15 01:43:22,538 - INFO - root - 已保存图片 7/10：./export\CVPR\images\Restormer-Plus for Real World Image Deraining_ the Runner-up Solution to the GT-RAIN Challenge (CVPR\figure_7_page2.jpeg
2025-11-15 01:43:22,565 - INFO - root - 已保存图片 8/10：./export\CVPR\images\Restormer-Plus for Real World Image Deraining_ the Runner-up Solution to the GT-RAIN Challenge (CVPR\figure_8_page3.jpeg
2025-11-15 01:43:22,592 - INFO - root - 已保存图片 9/10：./export\CVPR\images\Restormer-Plus for Real World Image Deraining_ the Runner-up Solution to the GT-RAIN Challenge (CVPR\figure_9_page3.jpeg
2025-11-15 01:43:22,615 - INFO - root - 已保存图片 10/10：./export\CVPR\images\Restormer-Plus for Real World Image Deraining_ the Runner-up Solution to the GT-RAIN Challenge (CVPR\figure_10_page3.jpeg
2025-11-15 01:43:22,616 - INFO - root - 成功添加图片 1：./export\CVPR\images\Restormer-Plus for Real World Image Deraining_ the Runner-up Solution to the GT-RAIN Challenge (CVPR\figure_1_page3.jpeg
2025-11-15 01:43:22,616 - INFO - root - 成功添加图片 2：./export\CVPR\images\Restormer-Plus for Real World Image Deraining_ the Runner-up Solution to the GT-RAIN Challenge (CVPR\figure_2_page3.jpeg
2025-11-15 01:43:22,618 - INFO - root - 成功添加图片 3：./export\CVPR\images\Restormer-Plus for Real World Image Deraining_ the Runner-up Solution to the GT-RAIN Challenge (CVPR\figure_3_page1.jpeg
2025-11-15 01:43:22,618 - INFO - root - 成功添加图片 4：./export\CVPR\images\Restormer-Plus for Real World Image Deraining_ the Runner-up Solution to the GT-RAIN Challenge (CVPR\figure_4_page1.jpeg
2025-11-15 01:43:22,618 - INFO - root - 成功添加图片 5：./export\CVPR\images\Restormer-Plus for Real World Image Deraining_ the Runner-up Solution to the GT-RAIN Challenge (CVPR\figure_5_page1.jpeg
2025-11-15 01:43:22,619 - INFO - root - 成功添加图片 6：./export\CVPR\images\Restormer-Plus for Real World Image Deraining_ the Runner-up Solution to the GT-RAIN Challenge (CVPR\figure_6_page2.jpeg
2025-11-15 01:43:22,619 - INFO - root - 成功添加图片 7：./export\CVPR\images\Restormer-Plus for Real World Image Deraining_ the Runner-up Solution to the GT-RAIN Challenge (CVPR\figure_7_page2.jpeg
2025-11-15 01:43:22,619 - INFO - root - 成功添加图片 8：./export\CVPR\images\Restormer-Plus for Real World Image Deraining_ the Runner-up Solution to the GT-RAIN Challenge (CVPR\figure_8_page3.jpeg
2025-11-15 01:43:22,623 - INFO - root - 成功添加图片 9：./export\CVPR\images\Restormer-Plus for Real World Image Deraining_ the Runner-up Solution to the GT-RAIN Challenge (CVPR\figure_9_page3.jpeg
2025-11-15 01:43:22,624 - INFO - root - 成功添加图片 10：./export\CVPR\images\Restormer-Plus for Real World Image Deraining_ the Runner-up Solution to the GT-RAIN Challenge (CVPR\figure_10_page3.jpeg
2025-11-15 01:43:22,625 - INFO - root - 论文《Restormer-Plus for Real World Image Deraining: the Runner-up Solution to the GT-RAIN Challenge (CVPR 2023 UG2+ Track 3)》的分析已保存到 ./export\CVPR\Restormer-Plus for Real World Image Deraining_ the Runner-up Solution to the GT-RAIN Challenge (CVPR.md
2025-11-15 01:43:22,627 - INFO - root - 跳过总结 (手动下载): Restormer-Plus for Real World Image Deraining: One State-of-the-Art Solution to the GT-RAIN Challenge (CVPR 2023 UG2+ Track 3)
2025-11-15 01:43:22,629 - INFO - root - 正在总结论文 39/100: WiCV@CVPR2023: The Eleventh Women In Computer Vision Workshop at the Annual CVPR Conference
2025-11-15 01:43:32,605 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-15 01:43:32,609 - INFO - root - LLMClient: rate limit reached, sleeping 17.4s
2025-11-15 01:44:39,312 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-15 01:45:18,283 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-15 01:45:18,294 - INFO - root - 正在提取论文图片到目录: ./export\CVPR\images\WiCV@CVPR2023_ The Eleventh Women In Computer Vision Workshop at the Annual CVPR Conference
2025-11-15 01:45:18,582 - INFO - root - 已保存图片 1/10：./export\CVPR\images\WiCV@CVPR2023_ The Eleventh Women In Computer Vision Workshop at the Annual CVPR Conference\figure_1_page3.png
2025-11-15 01:45:18,660 - INFO - root - 已保存图片 2/10：./export\CVPR\images\WiCV@CVPR2023_ The Eleventh Women In Computer Vision Workshop at the Annual CVPR Conference\figure_2_page3.png
2025-11-15 01:45:18,662 - INFO - root - 成功添加图片 1：./export\CVPR\images\WiCV@CVPR2023_ The Eleventh Women In Computer Vision Workshop at the Annual CVPR Conference\figure_1_page3.png
2025-11-15 01:45:18,663 - INFO - root - 成功添加图片 2：./export\CVPR\images\WiCV@CVPR2023_ The Eleventh Women In Computer Vision Workshop at the Annual CVPR Conference\figure_2_page3.png
2025-11-15 01:45:18,665 - INFO - root - 论文《WiCV@CVPR2023: The Eleventh Women In Computer Vision Workshop at the Annual CVPR Conference》的分析已保存到 ./export\CVPR\WiCV@CVPR2023_ The Eleventh Women In Computer Vision Workshop at the Annual CVPR Conference.md
2025-11-15 01:45:18,667 - INFO - root - 正在总结论文 40/100: NICE: CVPR 2023 Challenge on Zero-shot Image Captioning
2025-11-15 01:45:29,845 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-15 01:45:29,847 - INFO - root - LLMClient: rate limit reached, sleeping 9.5s
2025-11-15 01:46:26,475 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-15 01:47:00,879 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-15 01:47:00,885 - INFO - root - 正在提取论文图片到目录: ./export\CVPR\images\NICE_ CVPR 2023 Challenge on Zero-shot Image Captioning
2025-11-15 01:47:01,310 - INFO - root - 已保存图片 1/10：./export\CVPR\images\NICE_ CVPR 2023 Challenge on Zero-shot Image Captioning\figure_1_page8.png
2025-11-15 01:47:01,379 - INFO - root - 已保存图片 2/10：./export\CVPR\images\NICE_ CVPR 2023 Challenge on Zero-shot Image Captioning\figure_2_page4.jpeg
2025-11-15 01:47:01,447 - INFO - root - 已保存图片 3/10：./export\CVPR\images\NICE_ CVPR 2023 Challenge on Zero-shot Image Captioning\figure_3_page4.jpeg
2025-11-15 01:47:01,522 - INFO - root - 已保存图片 4/10：./export\CVPR\images\NICE_ CVPR 2023 Challenge on Zero-shot Image Captioning\figure_4_page4.jpeg
2025-11-15 01:47:01,558 - INFO - root - 已保存图片 5/10：./export\CVPR\images\NICE_ CVPR 2023 Challenge on Zero-shot Image Captioning\figure_5_page7.jpeg
2025-11-15 01:47:01,564 - INFO - root - 已保存图片 6/10：./export\CVPR\images\NICE_ CVPR 2023 Challenge on Zero-shot Image Captioning\figure_6_page4.jpeg
2025-11-15 01:47:01,598 - INFO - root - 已保存图片 7/10：./export\CVPR\images\NICE_ CVPR 2023 Challenge on Zero-shot Image Captioning\figure_7_page2.jpeg
2025-11-15 01:47:01,633 - INFO - root - 已保存图片 8/10：./export\CVPR\images\NICE_ CVPR 2023 Challenge on Zero-shot Image Captioning\figure_8_page2.jpeg
2025-11-15 01:47:01,659 - INFO - root - 已保存图片 9/10：./export\CVPR\images\NICE_ CVPR 2023 Challenge on Zero-shot Image Captioning\figure_9_page2.jpeg
2025-11-15 01:47:01,680 - INFO - root - 已保存图片 10/10：./export\CVPR\images\NICE_ CVPR 2023 Challenge on Zero-shot Image Captioning\figure_10_page6.jpeg
2025-11-15 01:47:01,692 - INFO - root - 成功添加图片 1：./export\CVPR\images\NICE_ CVPR 2023 Challenge on Zero-shot Image Captioning\figure_1_page8.png
2025-11-15 01:47:01,692 - INFO - root - 成功添加图片 2：./export\CVPR\images\NICE_ CVPR 2023 Challenge on Zero-shot Image Captioning\figure_2_page4.jpeg
2025-11-15 01:47:01,693 - INFO - root - 成功添加图片 3：./export\CVPR\images\NICE_ CVPR 2023 Challenge on Zero-shot Image Captioning\figure_3_page4.jpeg
2025-11-15 01:47:01,693 - INFO - root - 成功添加图片 4：./export\CVPR\images\NICE_ CVPR 2023 Challenge on Zero-shot Image Captioning\figure_4_page4.jpeg
2025-11-15 01:47:01,693 - INFO - root - 成功添加图片 5：./export\CVPR\images\NICE_ CVPR 2023 Challenge on Zero-shot Image Captioning\figure_5_page7.jpeg
2025-11-15 01:47:01,693 - INFO - root - 成功添加图片 6：./export\CVPR\images\NICE_ CVPR 2023 Challenge on Zero-shot Image Captioning\figure_6_page4.jpeg
2025-11-15 01:47:01,694 - INFO - root - 成功添加图片 7：./export\CVPR\images\NICE_ CVPR 2023 Challenge on Zero-shot Image Captioning\figure_7_page2.jpeg
2025-11-15 01:47:01,694 - INFO - root - 成功添加图片 8：./export\CVPR\images\NICE_ CVPR 2023 Challenge on Zero-shot Image Captioning\figure_8_page2.jpeg
2025-11-15 01:47:01,694 - INFO - root - 成功添加图片 9：./export\CVPR\images\NICE_ CVPR 2023 Challenge on Zero-shot Image Captioning\figure_9_page2.jpeg
2025-11-15 01:47:01,695 - INFO - root - 成功添加图片 10：./export\CVPR\images\NICE_ CVPR 2023 Challenge on Zero-shot Image Captioning\figure_10_page6.jpeg
2025-11-15 01:47:01,696 - INFO - root - 论文《NICE: CVPR 2023 Challenge on Zero-shot Image Captioning》的分析已保存到 ./export\CVPR\NICE_ CVPR 2023 Challenge on Zero-shot Image Captioning.md
2025-11-15 01:47:01,698 - INFO - root - 跳过总结 (手动下载): 1st Solution Places for CVPR 2023 UG$^{\textbf{2}}$+ Challenge Track 2.1-Text Recognition through Atmospheric Turbulence
2025-11-15 01:47:01,699 - INFO - root - 正在总结论文 42/100: A Solution to CVPR'2023 AQTC Challenge: Video Alignment for Multi-Step Inference
2025-11-15 01:47:13,239 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-15 01:47:13,241 - INFO - root - LLMClient: rate limit reached, sleeping 13.2s
2025-11-15 01:48:12,324 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-15 01:48:48,202 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-15 01:48:48,209 - INFO - root - 正在提取论文图片到目录: ./export\CVPR\images\A Solution to CVPR'2023 AQTC Challenge_ Video Alignment for Multi-Step Inference
2025-11-15 01:48:48,281 - INFO - root - 已保存图片 1/10：./export\CVPR\images\A Solution to CVPR'2023 AQTC Challenge_ Video Alignment for Multi-Step Inference\figure_1_page2.jpeg
2025-11-15 01:48:48,295 - INFO - root - 已保存图片 2/10：./export\CVPR\images\A Solution to CVPR'2023 AQTC Challenge_ Video Alignment for Multi-Step Inference\figure_2_page2.jpeg
2025-11-15 01:48:48,307 - INFO - root - 已保存图片 3/10：./export\CVPR\images\A Solution to CVPR'2023 AQTC Challenge_ Video Alignment for Multi-Step Inference\figure_3_page2.jpeg
2025-11-15 01:48:48,321 - INFO - root - 已保存图片 4/10：./export\CVPR\images\A Solution to CVPR'2023 AQTC Challenge_ Video Alignment for Multi-Step Inference\figure_4_page2.jpeg
2025-11-15 01:48:48,333 - INFO - root - 已保存图片 5/10：./export\CVPR\images\A Solution to CVPR'2023 AQTC Challenge_ Video Alignment for Multi-Step Inference\figure_5_page2.jpeg
2025-11-15 01:48:48,342 - INFO - root - 已保存图片 6/10：./export\CVPR\images\A Solution to CVPR'2023 AQTC Challenge_ Video Alignment for Multi-Step Inference\figure_6_page2.jpeg
2025-11-15 01:48:48,350 - INFO - root - 已保存图片 7/10：./export\CVPR\images\A Solution to CVPR'2023 AQTC Challenge_ Video Alignment for Multi-Step Inference\figure_7_page2.jpeg
2025-11-15 01:48:48,359 - INFO - root - 已保存图片 8/10：./export\CVPR\images\A Solution to CVPR'2023 AQTC Challenge_ Video Alignment for Multi-Step Inference\figure_8_page2.jpeg
2025-11-15 01:48:48,369 - INFO - root - 已保存图片 9/10：./export\CVPR\images\A Solution to CVPR'2023 AQTC Challenge_ Video Alignment for Multi-Step Inference\figure_9_page2.jpeg
2025-11-15 01:48:48,385 - INFO - root - 已保存图片 10/10：./export\CVPR\images\A Solution to CVPR'2023 AQTC Challenge_ Video Alignment for Multi-Step Inference\figure_10_page2.jpeg
2025-11-15 01:48:48,387 - INFO - root - 成功添加图片 1：./export\CVPR\images\A Solution to CVPR'2023 AQTC Challenge_ Video Alignment for Multi-Step Inference\figure_1_page2.jpeg
2025-11-15 01:48:48,387 - INFO - root - 成功添加图片 2：./export\CVPR\images\A Solution to CVPR'2023 AQTC Challenge_ Video Alignment for Multi-Step Inference\figure_2_page2.jpeg
2025-11-15 01:48:48,387 - INFO - root - 成功添加图片 3：./export\CVPR\images\A Solution to CVPR'2023 AQTC Challenge_ Video Alignment for Multi-Step Inference\figure_3_page2.jpeg
2025-11-15 01:48:48,387 - INFO - root - 成功添加图片 4：./export\CVPR\images\A Solution to CVPR'2023 AQTC Challenge_ Video Alignment for Multi-Step Inference\figure_4_page2.jpeg
2025-11-15 01:48:48,388 - INFO - root - 成功添加图片 5：./export\CVPR\images\A Solution to CVPR'2023 AQTC Challenge_ Video Alignment for Multi-Step Inference\figure_5_page2.jpeg
2025-11-15 01:48:48,388 - INFO - root - 成功添加图片 6：./export\CVPR\images\A Solution to CVPR'2023 AQTC Challenge_ Video Alignment for Multi-Step Inference\figure_6_page2.jpeg
2025-11-15 01:48:48,388 - INFO - root - 成功添加图片 7：./export\CVPR\images\A Solution to CVPR'2023 AQTC Challenge_ Video Alignment for Multi-Step Inference\figure_7_page2.jpeg
2025-11-15 01:48:48,389 - INFO - root - 成功添加图片 8：./export\CVPR\images\A Solution to CVPR'2023 AQTC Challenge_ Video Alignment for Multi-Step Inference\figure_8_page2.jpeg
2025-11-15 01:48:48,389 - INFO - root - 成功添加图片 9：./export\CVPR\images\A Solution to CVPR'2023 AQTC Challenge_ Video Alignment for Multi-Step Inference\figure_9_page2.jpeg
2025-11-15 01:48:48,389 - INFO - root - 成功添加图片 10：./export\CVPR\images\A Solution to CVPR'2023 AQTC Challenge_ Video Alignment for Multi-Step Inference\figure_10_page2.jpeg
2025-11-15 01:48:48,391 - INFO - root - 论文《A Solution to CVPR'2023 AQTC Challenge: Video Alignment for Multi-Step Inference》的分析已保存到 ./export\CVPR\A Solution to CVPR'2023 AQTC Challenge_ Video Alignment for Multi-Step Inference.md
2025-11-15 01:48:48,395 - INFO - root - 正在总结论文 43/100: 1st Solution Places for CVPR 2023 UG2+ Challenge Track 2.2-Coded Target Restoration through Atmospheric Turbulence
2025-11-15 01:48:59,837 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-15 01:48:59,841 - INFO - root - LLMClient: rate limit reached, sleeping 12.5s
2025-11-15 01:50:10,508 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-15 01:50:39,063 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-15 01:50:39,072 - INFO - root - 正在提取论文图片到目录: ./export\CVPR\images\1st Solution Places for CVPR 2023 UG2+ Challenge Track 2.2-Coded Target Restoration through Atmosphe
2025-11-15 01:50:40,124 - INFO - root - 已保存图片 1/10：./export\CVPR\images\1st Solution Places for CVPR 2023 UG2+ Challenge Track 2.2-Coded Target Restoration through Atmosphe\figure_1_page2.jpeg
2025-11-15 01:50:40,192 - INFO - root - 已保存图片 2/10：./export\CVPR\images\1st Solution Places for CVPR 2023 UG2+ Challenge Track 2.2-Coded Target Restoration through Atmosphe\figure_2_page2.jpeg
2025-11-15 01:50:40,247 - INFO - root - 已保存图片 3/10：./export\CVPR\images\1st Solution Places for CVPR 2023 UG2+ Challenge Track 2.2-Coded Target Restoration through Atmosphe\figure_3_page4.jpeg
2025-11-15 01:50:40,316 - INFO - root - 已保存图片 4/10：./export\CVPR\images\1st Solution Places for CVPR 2023 UG2+ Challenge Track 2.2-Coded Target Restoration through Atmosphe\figure_4_page4.jpeg
2025-11-15 01:50:40,387 - INFO - root - 已保存图片 5/10：./export\CVPR\images\1st Solution Places for CVPR 2023 UG2+ Challenge Track 2.2-Coded Target Restoration through Atmosphe\figure_5_page4.jpeg
2025-11-15 01:50:40,441 - INFO - root - 已保存图片 6/10：./export\CVPR\images\1st Solution Places for CVPR 2023 UG2+ Challenge Track 2.2-Coded Target Restoration through Atmosphe\figure_6_page4.jpeg
2025-11-15 01:50:40,508 - INFO - root - 已保存图片 7/10：./export\CVPR\images\1st Solution Places for CVPR 2023 UG2+ Challenge Track 2.2-Coded Target Restoration through Atmosphe\figure_7_page4.jpeg
2025-11-15 01:50:40,576 - INFO - root - 已保存图片 8/10：./export\CVPR\images\1st Solution Places for CVPR 2023 UG2+ Challenge Track 2.2-Coded Target Restoration through Atmosphe\figure_8_page1.jpeg
2025-11-15 01:50:40,647 - INFO - root - 已保存图片 9/10：./export\CVPR\images\1st Solution Places for CVPR 2023 UG2+ Challenge Track 2.2-Coded Target Restoration through Atmosphe\figure_9_page1.jpeg
2025-11-15 01:50:40,724 - INFO - root - 已保存图片 10/10：./export\CVPR\images\1st Solution Places for CVPR 2023 UG2+ Challenge Track 2.2-Coded Target Restoration through Atmosphe\figure_10_page1.jpeg
2025-11-15 01:50:40,726 - INFO - root - 成功添加图片 1：./export\CVPR\images\1st Solution Places for CVPR 2023 UG2+ Challenge Track 2.2-Coded Target Restoration through Atmosphe\figure_1_page2.jpeg
2025-11-15 01:50:40,726 - INFO - root - 成功添加图片 2：./export\CVPR\images\1st Solution Places for CVPR 2023 UG2+ Challenge Track 2.2-Coded Target Restoration through Atmosphe\figure_2_page2.jpeg
2025-11-15 01:50:40,726 - INFO - root - 成功添加图片 3：./export\CVPR\images\1st Solution Places for CVPR 2023 UG2+ Challenge Track 2.2-Coded Target Restoration through Atmosphe\figure_3_page4.jpeg
2025-11-15 01:50:40,726 - INFO - root - 成功添加图片 4：./export\CVPR\images\1st Solution Places for CVPR 2023 UG2+ Challenge Track 2.2-Coded Target Restoration through Atmosphe\figure_4_page4.jpeg
2025-11-15 01:50:40,727 - INFO - root - 成功添加图片 5：./export\CVPR\images\1st Solution Places for CVPR 2023 UG2+ Challenge Track 2.2-Coded Target Restoration through Atmosphe\figure_5_page4.jpeg
2025-11-15 01:50:40,727 - INFO - root - 成功添加图片 6：./export\CVPR\images\1st Solution Places for CVPR 2023 UG2+ Challenge Track 2.2-Coded Target Restoration through Atmosphe\figure_6_page4.jpeg
2025-11-15 01:50:40,727 - INFO - root - 成功添加图片 7：./export\CVPR\images\1st Solution Places for CVPR 2023 UG2+ Challenge Track 2.2-Coded Target Restoration through Atmosphe\figure_7_page4.jpeg
2025-11-15 01:50:40,727 - INFO - root - 成功添加图片 8：./export\CVPR\images\1st Solution Places for CVPR 2023 UG2+ Challenge Track 2.2-Coded Target Restoration through Atmosphe\figure_8_page1.jpeg
2025-11-15 01:50:40,728 - INFO - root - 成功添加图片 9：./export\CVPR\images\1st Solution Places for CVPR 2023 UG2+ Challenge Track 2.2-Coded Target Restoration through Atmosphe\figure_9_page1.jpeg
2025-11-15 01:50:40,728 - INFO - root - 成功添加图片 10：./export\CVPR\images\1st Solution Places for CVPR 2023 UG2+ Challenge Track 2.2-Coded Target Restoration through Atmosphe\figure_10_page1.jpeg
2025-11-15 01:50:40,729 - INFO - root - 论文《1st Solution Places for CVPR 2023 UG2+ Challenge Track 2.2-Coded Target Restoration through Atmospheric Turbulence》的分析已保存到 ./export\CVPR\1st Solution Places for CVPR 2023 UG2+ Challenge Track 2.2-Coded Target Restoration through Atmosphe.md
2025-11-15 01:50:40,732 - INFO - root - 跳过总结 (手动下载): Restormer-Plus for Real World Image Deraining: One State-of-the-Art to the GT-RAIN Challenge (CVPR 2023 UG2+ Track 3)
2025-11-15 01:50:40,732 - INFO - root - 跳过总结 (手动下载): WoodScape Motion Segmentation for Autonomous Driving - CVPR 2023 OmniCV Workshop Challenge
2025-11-15 01:50:40,732 - INFO - root - 正在总结论文 46/100: 2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)
2025-11-15 01:50:55,832 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-15 01:50:55,835 - INFO - root - LLMClient: rate limit reached, sleeping 14.7s
2025-11-15 01:52:12,686 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-15 01:52:41,139 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-15 01:52:41,147 - INFO - root - 正在提取论文图片到目录: ./export\CVPR\images\2021 IEEE_CVF Conference on Computer Vision and Pattern Recognition (CVPR)
2025-11-15 01:52:42,037 - INFO - root - 已保存图片 1/10：./export\CVPR\images\2021 IEEE_CVF Conference on Computer Vision and Pattern Recognition (CVPR)\figure_1_page8.jpeg
2025-11-15 01:52:42,415 - INFO - root - 已保存图片 2/10：./export\CVPR\images\2021 IEEE_CVF Conference on Computer Vision and Pattern Recognition (CVPR)\figure_2_page8.jpeg
2025-11-15 01:52:42,640 - INFO - root - 已保存图片 3/10：./export\CVPR\images\2021 IEEE_CVF Conference on Computer Vision and Pattern Recognition (CVPR)\figure_3_page1.png
2025-11-15 01:52:42,713 - INFO - root - 已保存图片 4/10：./export\CVPR\images\2021 IEEE_CVF Conference on Computer Vision and Pattern Recognition (CVPR)\figure_4_page8.jpeg
2025-11-15 01:52:42,787 - INFO - root - 已保存图片 5/10：./export\CVPR\images\2021 IEEE_CVF Conference on Computer Vision and Pattern Recognition (CVPR)\figure_5_page8.jpeg
2025-11-15 01:52:42,816 - INFO - root - 已保存图片 6/10：./export\CVPR\images\2021 IEEE_CVF Conference on Computer Vision and Pattern Recognition (CVPR)\figure_6_page4.jpeg
2025-11-15 01:52:42,834 - INFO - root - 已保存图片 7/10：./export\CVPR\images\2021 IEEE_CVF Conference on Computer Vision and Pattern Recognition (CVPR)\figure_7_page4.png
2025-11-15 01:52:42,903 - INFO - root - 已保存图片 8/10：./export\CVPR\images\2021 IEEE_CVF Conference on Computer Vision and Pattern Recognition (CVPR)\figure_8_page4.jpeg
2025-11-15 01:52:42,937 - INFO - root - 已保存图片 9/10：./export\CVPR\images\2021 IEEE_CVF Conference on Computer Vision and Pattern Recognition (CVPR)\figure_9_page7.jpeg
2025-11-15 01:52:42,967 - INFO - root - 已保存图片 10/10：./export\CVPR\images\2021 IEEE_CVF Conference on Computer Vision and Pattern Recognition (CVPR)\figure_10_page7.jpeg
2025-11-15 01:52:43,003 - INFO - root - 成功添加图片 1：./export\CVPR\images\2021 IEEE_CVF Conference on Computer Vision and Pattern Recognition (CVPR)\figure_1_page8.jpeg
2025-11-15 01:52:43,003 - INFO - root - 成功添加图片 2：./export\CVPR\images\2021 IEEE_CVF Conference on Computer Vision and Pattern Recognition (CVPR)\figure_2_page8.jpeg
2025-11-15 01:52:43,004 - INFO - root - 成功添加图片 3：./export\CVPR\images\2021 IEEE_CVF Conference on Computer Vision and Pattern Recognition (CVPR)\figure_3_page1.png
2025-11-15 01:52:43,004 - INFO - root - 成功添加图片 4：./export\CVPR\images\2021 IEEE_CVF Conference on Computer Vision and Pattern Recognition (CVPR)\figure_4_page8.jpeg
2025-11-15 01:52:43,004 - INFO - root - 成功添加图片 5：./export\CVPR\images\2021 IEEE_CVF Conference on Computer Vision and Pattern Recognition (CVPR)\figure_5_page8.jpeg
2025-11-15 01:52:43,004 - INFO - root - 成功添加图片 6：./export\CVPR\images\2021 IEEE_CVF Conference on Computer Vision and Pattern Recognition (CVPR)\figure_6_page4.jpeg
2025-11-15 01:52:43,005 - INFO - root - 成功添加图片 7：./export\CVPR\images\2021 IEEE_CVF Conference on Computer Vision and Pattern Recognition (CVPR)\figure_7_page4.png
2025-11-15 01:52:43,005 - INFO - root - 成功添加图片 8：./export\CVPR\images\2021 IEEE_CVF Conference on Computer Vision and Pattern Recognition (CVPR)\figure_8_page4.jpeg
2025-11-15 01:52:43,005 - INFO - root - 成功添加图片 9：./export\CVPR\images\2021 IEEE_CVF Conference on Computer Vision and Pattern Recognition (CVPR)\figure_9_page7.jpeg
2025-11-15 01:52:43,005 - INFO - root - 成功添加图片 10：./export\CVPR\images\2021 IEEE_CVF Conference on Computer Vision and Pattern Recognition (CVPR)\figure_10_page7.jpeg
2025-11-15 01:52:43,085 - INFO - root - 论文《2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)》的分析已保存到 ./export\CVPR\2021 IEEE_CVF Conference on Computer Vision and Pattern Recognition (CVPR).md
2025-11-15 01:52:43,088 - INFO - root - 正在总结论文 47/100: 1st Place Solutions for RxR-Habitat Vision-and-Language Navigation Competition (CVPR 2022)
2025-11-15 01:52:57,412 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-15 01:52:57,415 - INFO - root - LLMClient: rate limit reached, sleeping 15.3s
2025-11-15 01:54:09,058 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-15 01:54:46,218 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-15 01:54:46,223 - INFO - root - 正在提取论文图片到目录: ./export\CVPR\images\1st Place Solutions for RxR-Habitat Vision-and-Language Navigation Competition (CVPR 2022)
2025-11-15 01:54:46,304 - INFO - root - 已保存图片 1/10：./export\CVPR\images\1st Place Solutions for RxR-Habitat Vision-and-Language Navigation Competition (CVPR 2022)\figure_1_page2.png
2025-11-15 01:54:46,342 - INFO - root - 已保存图片 2/10：./export\CVPR\images\1st Place Solutions for RxR-Habitat Vision-and-Language Navigation Competition (CVPR 2022)\figure_2_page2.jpeg
2025-11-15 01:54:46,397 - INFO - root - 已保存图片 3/10：./export\CVPR\images\1st Place Solutions for RxR-Habitat Vision-and-Language Navigation Competition (CVPR 2022)\figure_3_page2.jpeg
2025-11-15 01:54:46,466 - INFO - root - 已保存图片 4/10：./export\CVPR\images\1st Place Solutions for RxR-Habitat Vision-and-Language Navigation Competition (CVPR 2022)\figure_4_page2.png
2025-11-15 01:54:46,559 - INFO - root - 已保存图片 5/10：./export\CVPR\images\1st Place Solutions for RxR-Habitat Vision-and-Language Navigation Competition (CVPR 2022)\figure_5_page2.png
2025-11-15 01:54:46,560 - INFO - root - 成功添加图片 1：./export\CVPR\images\1st Place Solutions for RxR-Habitat Vision-and-Language Navigation Competition (CVPR 2022)\figure_1_page2.png
2025-11-15 01:54:46,560 - INFO - root - 成功添加图片 2：./export\CVPR\images\1st Place Solutions for RxR-Habitat Vision-and-Language Navigation Competition (CVPR 2022)\figure_2_page2.jpeg
2025-11-15 01:54:46,561 - INFO - root - 成功添加图片 3：./export\CVPR\images\1st Place Solutions for RxR-Habitat Vision-and-Language Navigation Competition (CVPR 2022)\figure_3_page2.jpeg
2025-11-15 01:54:46,561 - INFO - root - 成功添加图片 4：./export\CVPR\images\1st Place Solutions for RxR-Habitat Vision-and-Language Navigation Competition (CVPR 2022)\figure_4_page2.png
2025-11-15 01:54:46,561 - INFO - root - 成功添加图片 5：./export\CVPR\images\1st Place Solutions for RxR-Habitat Vision-and-Language Navigation Competition (CVPR 2022)\figure_5_page2.png
2025-11-15 01:54:46,563 - INFO - root - 论文《1st Place Solutions for RxR-Habitat Vision-and-Language Navigation Competition (CVPR 2022)》的分析已保存到 ./export\CVPR\1st Place Solutions for RxR-Habitat Vision-and-Language Navigation Competition (CVPR 2022).md
2025-11-15 01:54:46,566 - INFO - root - 跳过总结 (手动下载): Technical Report of NICE Challenge at CVPR 2023: Retrieval-based Data Discovery and Fusion for Zero-shot Image Captioning
2025-11-15 01:54:46,567 - INFO - root - 跳过总结 (手动下载): Conference on Computer Vision and Pattern Recognition (CVPR) 2022
2025-11-15 01:54:46,567 - INFO - root - 跳过总结 (手动下载): HGNet: Learning Hierarchical Geometry from Points, Edges, and Surfaces ——CVPR 2023 Supplementary Material
2025-11-15 01:54:46,569 - INFO - root - 正在总结论文 51/100: MAE-GEBD: Winning the CVPR'2023 LOVEU-GEBD Challenge
2025-11-15 01:54:57,792 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-15 01:54:57,794 - INFO - root - LLMClient: rate limit reached, sleeping 11.3s
2025-11-15 01:55:55,149 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-15 01:56:29,183 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-15 01:56:29,186 - INFO - root - 正在提取论文图片到目录: ./export\CVPR\images\MAE-GEBD_ Winning the CVPR'2023 LOVEU-GEBD Challenge
2025-11-15 01:56:29,449 - INFO - root - 已保存图片 1/10：./export\CVPR\images\MAE-GEBD_ Winning the CVPR'2023 LOVEU-GEBD Challenge\figure_1_page2.png
2025-11-15 01:56:29,509 - INFO - root - 已保存图片 2/10：./export\CVPR\images\MAE-GEBD_ Winning the CVPR'2023 LOVEU-GEBD Challenge\figure_2_page5.png
2025-11-15 01:56:29,511 - INFO - root - 成功添加图片 1：./export\CVPR\images\MAE-GEBD_ Winning the CVPR'2023 LOVEU-GEBD Challenge\figure_1_page2.png
2025-11-15 01:56:29,511 - INFO - root - 成功添加图片 2：./export\CVPR\images\MAE-GEBD_ Winning the CVPR'2023 LOVEU-GEBD Challenge\figure_2_page5.png
2025-11-15 01:56:29,512 - INFO - root - 论文《MAE-GEBD: Winning the CVPR'2023 LOVEU-GEBD Challenge》的分析已保存到 ./export\CVPR\MAE-GEBD_ Winning the CVPR'2023 LOVEU-GEBD Challenge.md
2025-11-15 01:56:29,515 - INFO - root - 跳过总结 (手动下载): Conference on Computer Vision and Pattern Recognition (CVPR) 2022
2025-11-15 01:56:29,516 - INFO - root - 跳过总结 (手动下载): CVPR 2023 Workshop
2025-11-15 01:56:29,516 - INFO - root - 正在总结论文 54/100: IEEE/CVF Conference on Computer Vision and Pattern Recognition, CVPR 2023 - Workshops, Vancouver, BC, Canada, June 17-24, 2023
2025-11-15 01:56:46,980 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-15 01:56:46,983 - INFO - root - LLMClient: rate limit reached, sleeping 8.2s
2025-11-15 01:57:31,689 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-15 01:58:02,306 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-15 01:58:02,309 - INFO - root - 正在提取论文图片到目录: ./export\CVPR\images\IEEE_CVF Conference on Computer Vision and Pattern Recognition, CVPR 2023 - Workshops, Vancouver, BC
2025-11-15 01:58:03,256 - INFO - root - 已保存图片 1/10：./export\CVPR\images\IEEE_CVF Conference on Computer Vision and Pattern Recognition, CVPR 2023 - Workshops, Vancouver, BC\figure_1_page1.png
2025-11-15 01:58:03,316 - INFO - root - 已保存图片 2/10：./export\CVPR\images\IEEE_CVF Conference on Computer Vision and Pattern Recognition, CVPR 2023 - Workshops, Vancouver, BC\figure_2_page4.jpeg
2025-11-15 01:58:03,428 - INFO - root - 已保存图片 3/10：./export\CVPR\images\IEEE_CVF Conference on Computer Vision and Pattern Recognition, CVPR 2023 - Workshops, Vancouver, BC\figure_3_page7.png
2025-11-15 01:58:03,460 - INFO - root - 已保存图片 4/10：./export\CVPR\images\IEEE_CVF Conference on Computer Vision and Pattern Recognition, CVPR 2023 - Workshops, Vancouver, BC\figure_4_page2.jpeg
2025-11-15 01:58:03,496 - INFO - root - 已保存图片 5/10：./export\CVPR\images\IEEE_CVF Conference on Computer Vision and Pattern Recognition, CVPR 2023 - Workshops, Vancouver, BC\figure_5_page5.jpeg
2025-11-15 01:58:03,531 - INFO - root - 已保存图片 6/10：./export\CVPR\images\IEEE_CVF Conference on Computer Vision and Pattern Recognition, CVPR 2023 - Workshops, Vancouver, BC\figure_6_page4.jpeg
2025-11-15 01:58:03,576 - INFO - root - 已保存图片 7/10：./export\CVPR\images\IEEE_CVF Conference on Computer Vision and Pattern Recognition, CVPR 2023 - Workshops, Vancouver, BC\figure_7_page9.jpeg
2025-11-15 01:58:03,625 - INFO - root - 已保存图片 8/10：./export\CVPR\images\IEEE_CVF Conference on Computer Vision and Pattern Recognition, CVPR 2023 - Workshops, Vancouver, BC\figure_8_page7.png
2025-11-15 01:58:03,667 - INFO - root - 已保存图片 9/10：./export\CVPR\images\IEEE_CVF Conference on Computer Vision and Pattern Recognition, CVPR 2023 - Workshops, Vancouver, BC\figure_9_page8.png
2025-11-15 01:58:03,720 - INFO - root - 已保存图片 10/10：./export\CVPR\images\IEEE_CVF Conference on Computer Vision and Pattern Recognition, CVPR 2023 - Workshops, Vancouver, BC\figure_10_page8.png
2025-11-15 01:58:03,726 - INFO - root - 成功添加图片 1：./export\CVPR\images\IEEE_CVF Conference on Computer Vision and Pattern Recognition, CVPR 2023 - Workshops, Vancouver, BC\figure_1_page1.png
2025-11-15 01:58:03,726 - INFO - root - 成功添加图片 2：./export\CVPR\images\IEEE_CVF Conference on Computer Vision and Pattern Recognition, CVPR 2023 - Workshops, Vancouver, BC\figure_2_page4.jpeg
2025-11-15 01:58:03,727 - INFO - root - 成功添加图片 3：./export\CVPR\images\IEEE_CVF Conference on Computer Vision and Pattern Recognition, CVPR 2023 - Workshops, Vancouver, BC\figure_3_page7.png
2025-11-15 01:58:03,727 - INFO - root - 成功添加图片 4：./export\CVPR\images\IEEE_CVF Conference on Computer Vision and Pattern Recognition, CVPR 2023 - Workshops, Vancouver, BC\figure_4_page2.jpeg
2025-11-15 01:58:03,728 - INFO - root - 成功添加图片 5：./export\CVPR\images\IEEE_CVF Conference on Computer Vision and Pattern Recognition, CVPR 2023 - Workshops, Vancouver, BC\figure_5_page5.jpeg
2025-11-15 01:58:03,728 - INFO - root - 成功添加图片 6：./export\CVPR\images\IEEE_CVF Conference on Computer Vision and Pattern Recognition, CVPR 2023 - Workshops, Vancouver, BC\figure_6_page4.jpeg
2025-11-15 01:58:03,728 - INFO - root - 成功添加图片 7：./export\CVPR\images\IEEE_CVF Conference on Computer Vision and Pattern Recognition, CVPR 2023 - Workshops, Vancouver, BC\figure_7_page9.jpeg
2025-11-15 01:58:03,729 - INFO - root - 成功添加图片 8：./export\CVPR\images\IEEE_CVF Conference on Computer Vision and Pattern Recognition, CVPR 2023 - Workshops, Vancouver, BC\figure_8_page7.png
2025-11-15 01:58:03,729 - INFO - root - 成功添加图片 9：./export\CVPR\images\IEEE_CVF Conference on Computer Vision and Pattern Recognition, CVPR 2023 - Workshops, Vancouver, BC\figure_9_page8.png
2025-11-15 01:58:03,730 - INFO - root - 成功添加图片 10：./export\CVPR\images\IEEE_CVF Conference on Computer Vision and Pattern Recognition, CVPR 2023 - Workshops, Vancouver, BC\figure_10_page8.png
2025-11-15 01:58:03,735 - INFO - root - 论文《IEEE/CVF Conference on Computer Vision and Pattern Recognition, CVPR 2023 - Workshops, Vancouver, BC, Canada, June 17-24, 2023》的分析已保存到 ./export\CVPR\IEEE_CVF Conference on Computer Vision and Pattern Recognition, CVPR 2023 - Workshops, Vancouver, BC.md
2025-11-15 01:58:03,737 - INFO - root - 跳过总结 (手动下载): 3D Human Pose Estimation with Spatio-Temporal Criss-cross Attention — CVPR 2023 Supplementary Material *
2025-11-15 01:58:03,737 - INFO - root - 跳过总结 (手动下载): Supplementary Material for CVPR 2023 Paper: Object Detection with Self-Supervised Scene Adaptation
2025-11-15 01:58:03,737 - INFO - root - 正在总结论文 57/100: The Second-place Solution for CVPR VISION 23 Challenge Track 1 - Data Effificient Defect Detection
2025-11-15 01:58:16,532 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-15 01:58:16,533 - INFO - root - LLMClient: rate limit reached, sleeping 15.2s
2025-11-15 01:59:24,580 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-15 01:59:55,066 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-15 01:59:55,069 - INFO - root - 正在提取论文图片到目录: ./export\CVPR\images\The Second-place Solution for CVPR VISION 23 Challenge Track 1 - Data Effificient Defect Detection
2025-11-15 01:59:55,716 - INFO - root - 已保存图片 1/10：./export\CVPR\images\The Second-place Solution for CVPR VISION 23 Challenge Track 1 - Data Effificient Defect Detection\figure_1_page3.png
2025-11-15 01:59:55,798 - INFO - root - 已保存图片 2/10：./export\CVPR\images\The Second-place Solution for CVPR VISION 23 Challenge Track 1 - Data Effificient Defect Detection\figure_2_page3.png
2025-11-15 01:59:55,836 - INFO - root - 已保存图片 3/10：./export\CVPR\images\The Second-place Solution for CVPR VISION 23 Challenge Track 1 - Data Effificient Defect Detection\figure_3_page4.jpeg
2025-11-15 01:59:55,875 - INFO - root - 已保存图片 4/10：./export\CVPR\images\The Second-place Solution for CVPR VISION 23 Challenge Track 1 - Data Effificient Defect Detection\figure_4_page4.jpeg
2025-11-15 01:59:55,915 - INFO - root - 已保存图片 5/10：./export\CVPR\images\The Second-place Solution for CVPR VISION 23 Challenge Track 1 - Data Effificient Defect Detection\figure_5_page4.jpeg
2025-11-15 01:59:55,979 - INFO - root - 已保存图片 6/10：./export\CVPR\images\The Second-place Solution for CVPR VISION 23 Challenge Track 1 - Data Effificient Defect Detection\figure_6_page4.jpeg
2025-11-15 01:59:56,022 - INFO - root - 已保存图片 7/10：./export\CVPR\images\The Second-place Solution for CVPR VISION 23 Challenge Track 1 - Data Effificient Defect Detection\figure_7_page4.jpeg
2025-11-15 01:59:56,065 - INFO - root - 已保存图片 8/10：./export\CVPR\images\The Second-place Solution for CVPR VISION 23 Challenge Track 1 - Data Effificient Defect Detection\figure_8_page4.jpeg
2025-11-15 01:59:56,113 - INFO - root - 已保存图片 9/10：./export\CVPR\images\The Second-place Solution for CVPR VISION 23 Challenge Track 1 - Data Effificient Defect Detection\figure_9_page4.jpeg
2025-11-15 01:59:56,153 - INFO - root - 已保存图片 10/10：./export\CVPR\images\The Second-place Solution for CVPR VISION 23 Challenge Track 1 - Data Effificient Defect Detection\figure_10_page4.jpeg
2025-11-15 01:59:56,158 - INFO - root - 成功添加图片 1：./export\CVPR\images\The Second-place Solution for CVPR VISION 23 Challenge Track 1 - Data Effificient Defect Detection\figure_1_page3.png
2025-11-15 01:59:56,158 - INFO - root - 成功添加图片 2：./export\CVPR\images\The Second-place Solution for CVPR VISION 23 Challenge Track 1 - Data Effificient Defect Detection\figure_2_page3.png
2025-11-15 01:59:56,158 - INFO - root - 成功添加图片 3：./export\CVPR\images\The Second-place Solution for CVPR VISION 23 Challenge Track 1 - Data Effificient Defect Detection\figure_3_page4.jpeg
2025-11-15 01:59:56,159 - INFO - root - 成功添加图片 4：./export\CVPR\images\The Second-place Solution for CVPR VISION 23 Challenge Track 1 - Data Effificient Defect Detection\figure_4_page4.jpeg
2025-11-15 01:59:56,159 - INFO - root - 成功添加图片 5：./export\CVPR\images\The Second-place Solution for CVPR VISION 23 Challenge Track 1 - Data Effificient Defect Detection\figure_5_page4.jpeg
2025-11-15 01:59:56,160 - INFO - root - 成功添加图片 6：./export\CVPR\images\The Second-place Solution for CVPR VISION 23 Challenge Track 1 - Data Effificient Defect Detection\figure_6_page4.jpeg
2025-11-15 01:59:56,160 - INFO - root - 成功添加图片 7：./export\CVPR\images\The Second-place Solution for CVPR VISION 23 Challenge Track 1 - Data Effificient Defect Detection\figure_7_page4.jpeg
2025-11-15 01:59:56,160 - INFO - root - 成功添加图片 8：./export\CVPR\images\The Second-place Solution for CVPR VISION 23 Challenge Track 1 - Data Effificient Defect Detection\figure_8_page4.jpeg
2025-11-15 01:59:56,161 - INFO - root - 成功添加图片 9：./export\CVPR\images\The Second-place Solution for CVPR VISION 23 Challenge Track 1 - Data Effificient Defect Detection\figure_9_page4.jpeg
2025-11-15 01:59:56,161 - INFO - root - 成功添加图片 10：./export\CVPR\images\The Second-place Solution for CVPR VISION 23 Challenge Track 1 - Data Effificient Defect Detection\figure_10_page4.jpeg
2025-11-15 01:59:56,163 - INFO - root - 论文《The Second-place Solution for CVPR VISION 23 Challenge Track 1 - Data Effificient Defect Detection》的分析已保存到 ./export\CVPR\The Second-place Solution for CVPR VISION 23 Challenge Track 1 - Data Effificient Defect Detection.md
2025-11-15 01:59:56,167 - INFO - root - 正在总结论文 58/100: CVPR MultiEarth 2023 Deforestation Estimation Challenge: SpaceVision4Amazon
2025-11-15 02:00:06,626 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-15 02:00:06,628 - INFO - root - LLMClient: rate limit reached, sleeping 18.0s
2025-11-15 02:01:15,970 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-15 02:01:51,241 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-15 02:01:51,248 - INFO - root - 正在提取论文图片到目录: ./export\CVPR\images\CVPR MultiEarth 2023 Deforestation Estimation Challenge_ SpaceVision4Amazon
2025-11-15 02:01:51,504 - INFO - root - 已保存图片 1/10：./export\CVPR\images\CVPR MultiEarth 2023 Deforestation Estimation Challenge_ SpaceVision4Amazon\figure_1_page3.png
2025-11-15 02:01:51,581 - INFO - root - 已保存图片 2/10：./export\CVPR\images\CVPR MultiEarth 2023 Deforestation Estimation Challenge_ SpaceVision4Amazon\figure_2_page2.png
2025-11-15 02:01:51,610 - INFO - root - 已保存图片 3/10：./export\CVPR\images\CVPR MultiEarth 2023 Deforestation Estimation Challenge_ SpaceVision4Amazon\figure_3_page4.png
2025-11-15 02:01:51,640 - INFO - root - 已保存图片 4/10：./export\CVPR\images\CVPR MultiEarth 2023 Deforestation Estimation Challenge_ SpaceVision4Amazon\figure_4_page4.png
2025-11-15 02:01:51,686 - INFO - root - 已保存图片 5/10：./export\CVPR\images\CVPR MultiEarth 2023 Deforestation Estimation Challenge_ SpaceVision4Amazon\figure_5_page2.png
2025-11-15 02:01:51,689 - INFO - root - 成功添加图片 1：./export\CVPR\images\CVPR MultiEarth 2023 Deforestation Estimation Challenge_ SpaceVision4Amazon\figure_1_page3.png
2025-11-15 02:01:51,689 - INFO - root - 成功添加图片 2：./export\CVPR\images\CVPR MultiEarth 2023 Deforestation Estimation Challenge_ SpaceVision4Amazon\figure_2_page2.png
2025-11-15 02:01:51,689 - INFO - root - 成功添加图片 3：./export\CVPR\images\CVPR MultiEarth 2023 Deforestation Estimation Challenge_ SpaceVision4Amazon\figure_3_page4.png
2025-11-15 02:01:51,690 - INFO - root - 成功添加图片 4：./export\CVPR\images\CVPR MultiEarth 2023 Deforestation Estimation Challenge_ SpaceVision4Amazon\figure_4_page4.png
2025-11-15 02:01:51,690 - INFO - root - 成功添加图片 5：./export\CVPR\images\CVPR MultiEarth 2023 Deforestation Estimation Challenge_ SpaceVision4Amazon\figure_5_page2.png
2025-11-15 02:01:51,691 - INFO - root - 论文《CVPR MultiEarth 2023 Deforestation Estimation Challenge: SpaceVision4Amazon》的分析已保存到 ./export\CVPR\CVPR MultiEarth 2023 Deforestation Estimation Challenge_ SpaceVision4Amazon.md
2025-11-15 02:01:51,695 - INFO - root - 跳过总结 (手动下载): SuperAD: A Training-free Anomaly Classification and Segmentation Method for CVPR 2025 VAND 3.0 Workshop Challenge Track 1: Adapt & Detect
2025-11-15 02:01:51,695 - INFO - root - 跳过总结 (手动下载): Benchmarking Generalizable Bimanual Manipulation: RoboTwin Dual-Arm Collaboration Challenge at CVPR 2025 MEIS Workshop
2025-11-15 02:01:51,695 - INFO - root - 跳过总结 (手动下载): ReferDINO-Plus: 2nd Solution for 4th PVUW MeViS Challenge at CVPR 2025
2025-11-15 02:01:51,696 - INFO - root - 跳过总结 (手动下载): The System Description of CPS Team for Track on Driving with Language of CVPR 2024 Autonomous Grand Challenge
2025-11-15 02:01:51,696 - INFO - root - 跳过总结 (手动下载): IEEE/CVF Conference on Computer Vision and Pattern Recognition, CVPR 2025, Nashville, TN, USA, June 11-15, 2025
2025-11-15 02:01:51,696 - INFO - root - 跳过总结 (手动下载): IEEE/CVF Conference on Computer Vision and Pattern Recognition, CVPR 2022, New Orleans, LA, USA, June 18-24, 2022
2025-11-15 02:01:51,696 - INFO - root - 跳过总结 (手动下载): SIS-Challenge: Event-based Spatio-temporal Instance Segmentation Challenge at the CVPR 2025 Event-based Vision Workshop
2025-11-15 02:01:51,697 - INFO - root - 跳过总结 (手动下载): Geospatial Foundational Embedder: Top-1 Winning Solution on EarthVision Embed2Scale Challenge (CVPR 2025)
2025-11-15 02:01:51,697 - INFO - root - 跳过总结 (手动下载): Technical Report for the 5th CLVision Challenge at CVPR: Addressing the Class-Incremental with Repetition using Unlabeled Data - 4th Place Solution
2025-11-15 02:01:51,697 - INFO - root - 跳过总结 (手动下载): WiCV at CVPR 2025: The Women in Computer Vision Workshop
2025-11-15 02:01:51,697 - INFO - root - 正在总结论文 69/100: Woodscape Fisheye Object Detection for Autonomous Driving - CVPR 2022 OmniCV Workshop Challenge
2025-11-15 02:02:04,363 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-15 02:02:04,366 - INFO - root - LLMClient: rate limit reached, sleeping 11.6s
2025-11-15 02:03:08,418 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-15 02:03:45,013 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-15 02:03:45,015 - INFO - root - 正在提取论文图片到目录: ./export\CVPR\images\Woodscape Fisheye Object Detection for Autonomous Driving - CVPR 2022 OmniCV Workshop Challenge
2025-11-15 02:03:45,354 - INFO - root - 已保存图片 1/10：./export\CVPR\images\Woodscape Fisheye Object Detection for Autonomous Driving - CVPR 2022 OmniCV Workshop Challenge\figure_1_page3.jpeg
2025-11-15 02:03:45,494 - INFO - root - 已保存图片 2/10：./export\CVPR\images\Woodscape Fisheye Object Detection for Autonomous Driving - CVPR 2022 OmniCV Workshop Challenge\figure_2_page4.png
2025-11-15 02:03:45,544 - INFO - root - 已保存图片 3/10：./export\CVPR\images\Woodscape Fisheye Object Detection for Autonomous Driving - CVPR 2022 OmniCV Workshop Challenge\figure_3_page1.jpeg
2025-11-15 02:03:45,590 - INFO - root - 已保存图片 4/10：./export\CVPR\images\Woodscape Fisheye Object Detection for Autonomous Driving - CVPR 2022 OmniCV Workshop Challenge\figure_4_page1.jpeg
2025-11-15 02:03:45,638 - INFO - root - 已保存图片 5/10：./export\CVPR\images\Woodscape Fisheye Object Detection for Autonomous Driving - CVPR 2022 OmniCV Workshop Challenge\figure_5_page1.jpeg
2025-11-15 02:03:45,681 - INFO - root - 已保存图片 6/10：./export\CVPR\images\Woodscape Fisheye Object Detection for Autonomous Driving - CVPR 2022 OmniCV Workshop Challenge\figure_6_page1.jpeg
2025-11-15 02:03:45,723 - INFO - root - 已保存图片 7/10：./export\CVPR\images\Woodscape Fisheye Object Detection for Autonomous Driving - CVPR 2022 OmniCV Workshop Challenge\figure_7_page1.jpeg
2025-11-15 02:03:45,779 - INFO - root - 已保存图片 8/10：./export\CVPR\images\Woodscape Fisheye Object Detection for Autonomous Driving - CVPR 2022 OmniCV Workshop Challenge\figure_8_page3.png
2025-11-15 02:03:45,814 - INFO - root - 已保存图片 9/10：./export\CVPR\images\Woodscape Fisheye Object Detection for Autonomous Driving - CVPR 2022 OmniCV Workshop Challenge\figure_9_page4.png
2025-11-15 02:03:45,825 - INFO - root - 已保存图片 10/10：./export\CVPR\images\Woodscape Fisheye Object Detection for Autonomous Driving - CVPR 2022 OmniCV Workshop Challenge\figure_10_page1.jpeg
2025-11-15 02:03:45,829 - INFO - root - 成功添加图片 1：./export\CVPR\images\Woodscape Fisheye Object Detection for Autonomous Driving - CVPR 2022 OmniCV Workshop Challenge\figure_1_page3.jpeg
2025-11-15 02:03:45,830 - INFO - root - 成功添加图片 2：./export\CVPR\images\Woodscape Fisheye Object Detection for Autonomous Driving - CVPR 2022 OmniCV Workshop Challenge\figure_2_page4.png
2025-11-15 02:03:45,831 - INFO - root - 成功添加图片 3：./export\CVPR\images\Woodscape Fisheye Object Detection for Autonomous Driving - CVPR 2022 OmniCV Workshop Challenge\figure_3_page1.jpeg
2025-11-15 02:03:45,831 - INFO - root - 成功添加图片 4：./export\CVPR\images\Woodscape Fisheye Object Detection for Autonomous Driving - CVPR 2022 OmniCV Workshop Challenge\figure_4_page1.jpeg
2025-11-15 02:03:45,833 - INFO - root - 成功添加图片 5：./export\CVPR\images\Woodscape Fisheye Object Detection for Autonomous Driving - CVPR 2022 OmniCV Workshop Challenge\figure_5_page1.jpeg
2025-11-15 02:03:45,833 - INFO - root - 成功添加图片 6：./export\CVPR\images\Woodscape Fisheye Object Detection for Autonomous Driving - CVPR 2022 OmniCV Workshop Challenge\figure_6_page1.jpeg
2025-11-15 02:03:45,834 - INFO - root - 成功添加图片 7：./export\CVPR\images\Woodscape Fisheye Object Detection for Autonomous Driving - CVPR 2022 OmniCV Workshop Challenge\figure_7_page1.jpeg
2025-11-15 02:03:45,834 - INFO - root - 成功添加图片 8：./export\CVPR\images\Woodscape Fisheye Object Detection for Autonomous Driving - CVPR 2022 OmniCV Workshop Challenge\figure_8_page3.png
2025-11-15 02:03:45,834 - INFO - root - 成功添加图片 9：./export\CVPR\images\Woodscape Fisheye Object Detection for Autonomous Driving - CVPR 2022 OmniCV Workshop Challenge\figure_9_page4.png
2025-11-15 02:03:45,835 - INFO - root - 成功添加图片 10：./export\CVPR\images\Woodscape Fisheye Object Detection for Autonomous Driving - CVPR 2022 OmniCV Workshop Challenge\figure_10_page1.jpeg
2025-11-15 02:03:45,836 - INFO - root - 论文《Woodscape Fisheye Object Detection for Autonomous Driving - CVPR 2022 OmniCV Workshop Challenge》的分析已保存到 ./export\CVPR\Woodscape Fisheye Object Detection for Autonomous Driving - CVPR 2022 OmniCV Workshop Challenge.md
2025-11-15 02:03:45,840 - INFO - root - 跳过总结 (手动下载): VizWiz grand challenge workshop at CVPR 2022
2025-11-15 02:03:45,840 - INFO - root - 正在总结论文 71/100: The Second-place Solution for CVPR 2022 SoccerNet Tracking Challenge
2025-11-15 02:03:58,237 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-15 02:03:58,247 - INFO - root - LLMClient: rate limit reached, sleeping 10.2s
2025-11-15 02:05:15,087 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-15 02:05:58,826 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-15 02:05:58,829 - INFO - root - 正在提取论文图片到目录: ./export\CVPR\images\The Second-place Solution for CVPR 2022 SoccerNet Tracking Challenge
2025-11-15 02:05:59,897 - INFO - root - 已保存图片 1/10：./export\CVPR\images\The Second-place Solution for CVPR 2022 SoccerNet Tracking Challenge\figure_1_page3.png
2025-11-15 02:05:59,934 - INFO - root - 已保存图片 2/10：./export\CVPR\images\The Second-place Solution for CVPR 2022 SoccerNet Tracking Challenge\figure_2_page2.png
2025-11-15 02:05:59,937 - INFO - root - 成功添加图片 1：./export\CVPR\images\The Second-place Solution for CVPR 2022 SoccerNet Tracking Challenge\figure_1_page3.png
2025-11-15 02:05:59,937 - INFO - root - 成功添加图片 2：./export\CVPR\images\The Second-place Solution for CVPR 2022 SoccerNet Tracking Challenge\figure_2_page2.png
2025-11-15 02:05:59,939 - INFO - root - 论文《The Second-place Solution for CVPR 2022 SoccerNet Tracking Challenge》的分析已保存到 ./export\CVPR\The Second-place Solution for CVPR 2022 SoccerNet Tracking Challenge.md
2025-11-15 02:05:59,942 - INFO - root - 跳过总结 (手动下载): DIVE: Deep-search Iterative Video Exploration A Technical Report for the CVRR Challenge at CVPR 2025
2025-11-15 02:05:59,943 - INFO - root - 跳过总结 (手动下载): Medical Image Segmentation Foundation Models. CVPR 2024 Challenge: Segment Anything in Medical Images on Laptop: MedSAM on Laptop 2024, Held in Conjunction with CVPR 2024, Seattle, WA, USA, June 17–21, 2024, Proceedings
2025-11-15 02:05:59,943 - INFO - root - 跳过总结 (手动下载): IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops, CVPR Workshops 2025, Nashville, TN, USA, June 11-15, 2025
2025-11-15 02:05:59,943 - INFO - root - 跳过总结 (手动下载): Conference on Computer Vision and Pattern Recognition (CVPR) 2022
2025-11-15 02:05:59,944 - INFO - root - 跳过总结 (手动下载): EgoVIS@CVPR: What Changed and What Could Have Changed? State-Change Counterfactuals for Procedure-Aware Video Representation Learning
2025-11-15 02:05:59,944 - INFO - root - 跳过总结 (手动下载): Editorial: Introduction to the Special Section on Best of CVPR'2022
2025-11-15 02:05:59,944 - INFO - root - 正在总结论文 78/100: Winning the CVPR'2022 AQTC Challenge: A Two-stage Function-centric Approach
2025-11-15 02:06:10,957 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-15 02:06:10,959 - INFO - root - LLMClient: rate limit reached, sleeping 4.1s
2025-11-15 02:07:05,000 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-15 02:07:46,137 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-15 02:07:46,143 - INFO - root - 正在提取论文图片到目录: ./export\CVPR\images\Winning the CVPR'2022 AQTC Challenge_ A Two-stage Function-centric Approach
2025-11-15 02:07:46,209 - INFO - root - 已保存图片 1/10：./export\CVPR\images\Winning the CVPR'2022 AQTC Challenge_ A Two-stage Function-centric Approach\figure_1_page3.png
2025-11-15 02:07:46,227 - INFO - root - 已保存图片 2/10：./export\CVPR\images\Winning the CVPR'2022 AQTC Challenge_ A Two-stage Function-centric Approach\figure_2_page3.jpeg
2025-11-15 02:07:46,255 - INFO - root - 已保存图片 3/10：./export\CVPR\images\Winning the CVPR'2022 AQTC Challenge_ A Two-stage Function-centric Approach\figure_3_page3.jpeg
2025-11-15 02:07:46,256 - INFO - root - 成功添加图片 1：./export\CVPR\images\Winning the CVPR'2022 AQTC Challenge_ A Two-stage Function-centric Approach\figure_1_page3.png
2025-11-15 02:07:46,257 - INFO - root - 成功添加图片 2：./export\CVPR\images\Winning the CVPR'2022 AQTC Challenge_ A Two-stage Function-centric Approach\figure_2_page3.jpeg
2025-11-15 02:07:46,257 - INFO - root - 成功添加图片 3：./export\CVPR\images\Winning the CVPR'2022 AQTC Challenge_ A Two-stage Function-centric Approach\figure_3_page3.jpeg
2025-11-15 02:07:46,258 - INFO - root - 论文《Winning the CVPR'2022 AQTC Challenge: A Two-stage Function-centric Approach》的分析已保存到 ./export\CVPR\Winning the CVPR'2022 AQTC Challenge_ A Two-stage Function-centric Approach.md
2025-11-15 02:07:46,263 - INFO - root - 正在总结论文 79/100: Masked Autoencoders for Generic Event Boundary Detection CVPR'2022 Kinetics-GEBD Challenge
2025-11-15 02:07:57,956 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-15 02:07:57,957 - INFO - root - LLMClient: rate limit reached, sleeping 7.0s
2025-11-15 02:09:00,614 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-15 02:09:29,808 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-15 02:09:29,817 - INFO - root - 正在提取论文图片到目录: ./export\CVPR\images\Masked Autoencoders for Generic Event Boundary Detection CVPR'2022 Kinetics-GEBD Challenge
2025-11-15 02:09:30,089 - INFO - root - 已保存图片 1/10：./export\CVPR\images\Masked Autoencoders for Generic Event Boundary Detection CVPR'2022 Kinetics-GEBD Challenge\figure_1_page2.png
2025-11-15 02:09:30,110 - INFO - root - 已保存图片 2/10：./export\CVPR\images\Masked Autoencoders for Generic Event Boundary Detection CVPR'2022 Kinetics-GEBD Challenge\figure_2_page4.png
2025-11-15 02:09:30,133 - INFO - root - 已保存图片 3/10：./export\CVPR\images\Masked Autoencoders for Generic Event Boundary Detection CVPR'2022 Kinetics-GEBD Challenge\figure_3_page4.png
2025-11-15 02:09:30,135 - INFO - root - 成功添加图片 1：./export\CVPR\images\Masked Autoencoders for Generic Event Boundary Detection CVPR'2022 Kinetics-GEBD Challenge\figure_1_page2.png
2025-11-15 02:09:30,136 - INFO - root - 成功添加图片 2：./export\CVPR\images\Masked Autoencoders for Generic Event Boundary Detection CVPR'2022 Kinetics-GEBD Challenge\figure_2_page4.png
2025-11-15 02:09:30,136 - INFO - root - 成功添加图片 3：./export\CVPR\images\Masked Autoencoders for Generic Event Boundary Detection CVPR'2022 Kinetics-GEBD Challenge\figure_3_page4.png
2025-11-15 02:09:30,138 - INFO - root - 论文《Masked Autoencoders for Generic Event Boundary Detection CVPR'2022 Kinetics-GEBD Challenge》的分析已保存到 ./export\CVPR\Masked Autoencoders for Generic Event Boundary Detection CVPR'2022 Kinetics-GEBD Challenge.md
2025-11-15 02:09:30,140 - INFO - root - 正在总结论文 80/100: Technical Report for CVPR 2022 LOVEU AQTC Challenge
2025-11-15 02:09:41,644 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-15 02:09:41,650 - INFO - root - LLMClient: rate limit reached, sleeping 19.0s
2025-11-15 02:10:58,063 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-15 02:11:25,102 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-15 02:11:25,109 - INFO - root - 正在提取论文图片到目录: ./export\CVPR\images\Technical Report for CVPR 2022 LOVEU AQTC Challenge
2025-11-15 02:11:25,355 - INFO - root - 已保存图片 1/10：./export\CVPR\images\Technical Report for CVPR 2022 LOVEU AQTC Challenge\figure_1_page1.png
2025-11-15 02:11:25,416 - INFO - root - 已保存图片 2/10：./export\CVPR\images\Technical Report for CVPR 2022 LOVEU AQTC Challenge\figure_2_page2.png
2025-11-15 02:11:25,457 - INFO - root - 已保存图片 3/10：./export\CVPR\images\Technical Report for CVPR 2022 LOVEU AQTC Challenge\figure_3_page3.png
2025-11-15 02:11:25,459 - INFO - root - 成功添加图片 1：./export\CVPR\images\Technical Report for CVPR 2022 LOVEU AQTC Challenge\figure_1_page1.png
2025-11-15 02:11:25,459 - INFO - root - 成功添加图片 2：./export\CVPR\images\Technical Report for CVPR 2022 LOVEU AQTC Challenge\figure_2_page2.png
2025-11-15 02:11:25,459 - INFO - root - 成功添加图片 3：./export\CVPR\images\Technical Report for CVPR 2022 LOVEU AQTC Challenge\figure_3_page3.png
2025-11-15 02:11:25,461 - INFO - root - 论文《Technical Report for CVPR 2022 LOVEU AQTC Challenge》的分析已保存到 ./export\CVPR\Technical Report for CVPR 2022 LOVEU AQTC Challenge.md
2025-11-15 02:11:25,463 - INFO - root - 跳过总结 (手动下载): On the Robustness of the CVPR 2018 White-Box Adversarial Example Defenses
2025-11-15 02:11:25,464 - INFO - root - 正在总结论文 82/100: Submission to Generic Event Boundary Detection Challenge@CVPR 2022: Local Context Modeling and Global Boundary Decoding Approach
2025-11-15 02:11:36,088 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-15 02:11:36,091 - INFO - root - LLMClient: rate limit reached, sleeping 22.0s
2025-11-15 02:12:44,637 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-15 02:13:09,413 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-15 02:13:09,414 - INFO - root - 正在提取论文图片到目录: ./export\CVPR\images\Submission to Generic Event Boundary Detection Challenge@CVPR 2022_ Local Context Modeling and Globa
2025-11-15 02:13:09,447 - INFO - root - 已保存图片 1/10：./export\CVPR\images\Submission to Generic Event Boundary Detection Challenge@CVPR 2022_ Local Context Modeling and Globa\figure_1_page2.jpeg
2025-11-15 02:13:09,459 - INFO - root - 已保存图片 2/10：./export\CVPR\images\Submission to Generic Event Boundary Detection Challenge@CVPR 2022_ Local Context Modeling and Globa\figure_2_page2.jpeg
2025-11-15 02:13:09,484 - INFO - root - 已保存图片 3/10：./export\CVPR\images\Submission to Generic Event Boundary Detection Challenge@CVPR 2022_ Local Context Modeling and Globa\figure_3_page2.jpeg
2025-11-15 02:13:09,511 - INFO - root - 已保存图片 4/10：./export\CVPR\images\Submission to Generic Event Boundary Detection Challenge@CVPR 2022_ Local Context Modeling and Globa\figure_4_page2.jpeg
2025-11-15 02:13:09,537 - INFO - root - 已保存图片 5/10：./export\CVPR\images\Submission to Generic Event Boundary Detection Challenge@CVPR 2022_ Local Context Modeling and Globa\figure_5_page2.jpeg
2025-11-15 02:13:09,563 - INFO - root - 已保存图片 6/10：./export\CVPR\images\Submission to Generic Event Boundary Detection Challenge@CVPR 2022_ Local Context Modeling and Globa\figure_6_page2.jpeg
2025-11-15 02:13:09,571 - INFO - root - 已保存图片 7/10：./export\CVPR\images\Submission to Generic Event Boundary Detection Challenge@CVPR 2022_ Local Context Modeling and Globa\figure_7_page2.jpeg
2025-11-15 02:13:09,580 - INFO - root - 已保存图片 8/10：./export\CVPR\images\Submission to Generic Event Boundary Detection Challenge@CVPR 2022_ Local Context Modeling and Globa\figure_8_page2.jpeg
2025-11-15 02:13:09,583 - INFO - root - 成功添加图片 1：./export\CVPR\images\Submission to Generic Event Boundary Detection Challenge@CVPR 2022_ Local Context Modeling and Globa\figure_1_page2.jpeg
2025-11-15 02:13:09,584 - INFO - root - 成功添加图片 2：./export\CVPR\images\Submission to Generic Event Boundary Detection Challenge@CVPR 2022_ Local Context Modeling and Globa\figure_2_page2.jpeg
2025-11-15 02:13:09,584 - INFO - root - 成功添加图片 3：./export\CVPR\images\Submission to Generic Event Boundary Detection Challenge@CVPR 2022_ Local Context Modeling and Globa\figure_3_page2.jpeg
2025-11-15 02:13:09,585 - INFO - root - 成功添加图片 4：./export\CVPR\images\Submission to Generic Event Boundary Detection Challenge@CVPR 2022_ Local Context Modeling and Globa\figure_4_page2.jpeg
2025-11-15 02:13:09,585 - INFO - root - 成功添加图片 5：./export\CVPR\images\Submission to Generic Event Boundary Detection Challenge@CVPR 2022_ Local Context Modeling and Globa\figure_5_page2.jpeg
2025-11-15 02:13:09,586 - INFO - root - 成功添加图片 6：./export\CVPR\images\Submission to Generic Event Boundary Detection Challenge@CVPR 2022_ Local Context Modeling and Globa\figure_6_page2.jpeg
2025-11-15 02:13:09,586 - INFO - root - 成功添加图片 7：./export\CVPR\images\Submission to Generic Event Boundary Detection Challenge@CVPR 2022_ Local Context Modeling and Globa\figure_7_page2.jpeg
2025-11-15 02:13:09,587 - INFO - root - 成功添加图片 8：./export\CVPR\images\Submission to Generic Event Boundary Detection Challenge@CVPR 2022_ Local Context Modeling and Globa\figure_8_page2.jpeg
2025-11-15 02:13:09,589 - INFO - root - 论文《Submission to Generic Event Boundary Detection Challenge@CVPR 2022: Local Context Modeling and Global Boundary Decoding Approach》的分析已保存到 ./export\CVPR\Submission to Generic Event Boundary Detection Challenge@CVPR 2022_ Local Context Modeling and Globa.md
2025-11-15 02:13:09,593 - INFO - root - 跳过总结 (手动下载): Woodscape Fisheye Semantic Segmentation for Autonomous Driving - CVPR 2021 OmniCV Workshop Challenge
2025-11-15 02:13:09,593 - INFO - root - 跳过总结 (手动下载): IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2021, virtual, June 19-25, 2021
2025-11-15 02:13:09,594 - INFO - root - 跳过总结 (手动下载): CVPR 2022 Area Chairs
2025-11-15 02:13:09,594 - INFO - root - 正在总结论文 86/100: CVPR 2022 Outstanding Reviewers
2025-11-15 02:13:21,305 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-15 02:13:21,308 - INFO - root - LLMClient: rate limit reached, sleeping 23.3s
2025-11-15 02:14:40,883 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-15 02:15:17,310 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-15 02:15:17,312 - INFO - root - 正在提取论文图片到目录: ./export\CVPR\images\CVPR 2022 Outstanding Reviewers
2025-11-15 02:15:17,319 - INFO - root - 论文《CVPR 2022 Outstanding Reviewers》的分析已保存到 ./export\CVPR\CVPR 2022 Outstanding Reviewers.md
2025-11-15 02:15:17,324 - INFO - root - 跳过总结 (手动下载): CVPR 2022 Organizing Committee
2025-11-15 02:15:17,324 - INFO - root - 跳过总结 (手动下载): 2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)
2025-11-15 02:15:17,325 - INFO - root - 跳过总结 (手动下载): Winning the CVPR'2021 Kinetics-GEBD Challenge: Contrastive Learning Approach
2025-11-15 02:15:17,325 - INFO - root - 跳过总结 (手动下载): Supplementary Material for CVPR 2022 paper # 9084
2025-11-15 02:15:17,326 - INFO - root - 正在总结论文 91/100: Introduction to the Special Section of CVPR 2017
2025-11-15 02:15:33,725 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-15 02:15:33,727 - INFO - root - LLMClient: rate limit reached, sleeping 7.2s
2025-11-15 02:16:27,199 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-15 02:16:54,457 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-15 02:16:54,459 - INFO - root - 正在提取论文图片到目录: ./export\CVPR\images\Introduction to the Special Section of CVPR 2017
2025-11-15 02:16:54,501 - INFO - root - 论文《Introduction to the Special Section of CVPR 2017》的分析已保存到 ./export\CVPR\Introduction to the Special Section of CVPR 2017.md
2025-11-15 02:16:54,503 - INFO - root - 正在总结论文 92/100: CVPR 2020 Continual Learning in Computer Vision Competition: Approaches, Results, Current Challenges and Future Directions
2025-11-15 02:17:07,312 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-15 02:17:07,315 - INFO - root - LLMClient: rate limit reached, sleeping 19.9s
2025-11-15 02:18:17,105 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-15 02:18:45,316 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-15 02:18:45,318 - INFO - root - 正在提取论文图片到目录: ./export\CVPR\images\CVPR 2020 Continual Learning in Computer Vision Competition_ Approaches, Results, Current Challenges
2025-11-15 02:18:45,527 - INFO - root - 已保存图片 1/10：./export\CVPR\images\CVPR 2020 Continual Learning in Computer Vision Competition_ Approaches, Results, Current Challenges\figure_1_page2.png
2025-11-15 02:18:45,573 - INFO - root - 已保存图片 2/10：./export\CVPR\images\CVPR 2020 Continual Learning in Computer Vision Competition_ Approaches, Results, Current Challenges\figure_2_page1.png
2025-11-15 02:18:45,605 - INFO - root - 已保存图片 3/10：./export\CVPR\images\CVPR 2020 Continual Learning in Computer Vision Competition_ Approaches, Results, Current Challenges\figure_3_page1.png
2025-11-15 02:18:45,630 - INFO - root - 已保存图片 4/10：./export\CVPR\images\CVPR 2020 Continual Learning in Computer Vision Competition_ Approaches, Results, Current Challenges\figure_4_page1.png
2025-11-15 02:18:45,672 - INFO - root - 已保存图片 5/10：./export\CVPR\images\CVPR 2020 Continual Learning in Computer Vision Competition_ Approaches, Results, Current Challenges\figure_5_page6.png
2025-11-15 02:18:45,674 - INFO - root - 成功添加图片 1：./export\CVPR\images\CVPR 2020 Continual Learning in Computer Vision Competition_ Approaches, Results, Current Challenges\figure_1_page2.png
2025-11-15 02:18:45,674 - INFO - root - 成功添加图片 2：./export\CVPR\images\CVPR 2020 Continual Learning in Computer Vision Competition_ Approaches, Results, Current Challenges\figure_2_page1.png
2025-11-15 02:18:45,675 - INFO - root - 成功添加图片 3：./export\CVPR\images\CVPR 2020 Continual Learning in Computer Vision Competition_ Approaches, Results, Current Challenges\figure_3_page1.png
2025-11-15 02:18:45,676 - INFO - root - 成功添加图片 4：./export\CVPR\images\CVPR 2020 Continual Learning in Computer Vision Competition_ Approaches, Results, Current Challenges\figure_4_page1.png
2025-11-15 02:18:45,676 - INFO - root - 成功添加图片 5：./export\CVPR\images\CVPR 2020 Continual Learning in Computer Vision Competition_ Approaches, Results, Current Challenges\figure_5_page6.png
2025-11-15 02:18:45,677 - INFO - root - 论文《CVPR 2020 Continual Learning in Computer Vision Competition: Approaches, Results, Current Challenges and Future Directions》的分析已保存到 ./export\CVPR\CVPR 2020 Continual Learning in Computer Vision Competition_ Approaches, Results, Current Challenges.md
2025-11-15 02:18:45,682 - INFO - root - 跳过总结 (手动下载): Generic Event Boundary Detection Challenge at CVPR 2021 Technical Report: Cascaded Temporal Attention Network (CASTANET)
2025-11-15 02:18:45,682 - INFO - root - 跳过总结 (手动下载): Method Towards CVPR 2021 Image Matching Challenge
2025-11-15 02:18:45,682 - INFO - root - 跳过总结 (手动下载): Workshop on Autonomous Driving at CVPR 2021: Technical Report for Streaming Perception Challenge
2025-11-15 02:18:45,682 - INFO - root - 跳过总结 (手动下载): IEEE Conference on Computer Vision and Pattern Recognition Workshops, CVPR Workshops 2021, virtual, June 19-25, 2021
2025-11-15 02:18:45,684 - INFO - root - 跳过总结 (手动下载): SuperMix : Supplementary Material Anonymous CVPR submission
2025-11-15 02:18:45,684 - INFO - root - 跳过总结 (手动下载): Supplementary Material for CVPR 2021 paper
2025-11-15 02:18:45,684 - INFO - root - 跳过总结 (手动下载): Method Towards CVPR 2021 SimLocMatch Challenge
2025-11-15 02:18:45,684 - INFO - root - 跳过总结 (手动下载): Coding Standards as Anchors for the CVPR CLIC video track
2025-11-15 02:18:45,684 - INFO - root - --- 论文总结阶段结束 ---
2025-11-15 02:18:45,685 - INFO - root - --- 开始生成 Excel 报告 (包含 100 篇论文) ---
2025-11-15 02:18:45,713 - INFO - root - 未找到旧 Excel 文件。正在创建新文件: export\CVPR_summary.xlsx
2025-11-15 02:18:45,799 - INFO - root - 成功保存 Excel: export\CVPR_summary.xlsx
2025-11-15 02:18:45,799 - INFO - root - 已生成或更新汇总 Excel 表格: export\CVPR_summary.xlsx
2025-11-15 02:18:45,800 - INFO - root - 总运行时间: 3411.36 seconds
2025-11-16 19:27:13,653 - WARNING - root - Google Scholar 检索器依赖未能加载: No module named 'selenium'。 'scholar' 策略将不可用。
2025-11-16 19:27:13,657 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-16 19:27:13,659 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-16 19:27:13,662 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-16 19:27:22,245 - INFO - root - LLMClientManager: 指定使用客户端: DeekSeek
2025-11-16 19:27:22,246 - WARNING - root - LLMClientManager: 指定的客户端 DeekSeek 不可用，将尝试其他客户端
2025-11-16 19:27:23,119 - INFO - root - GeminiClient: trying model models/gemini-2.5-flash
2025-11-16 19:27:27,997 - INFO - root - GeminiClient: initialized model gemini-2.5-flash
2025-11-16 19:27:27,998 - INFO - root - LLMClientManager: Gemini client initialized successfully
2025-11-16 19:27:27,998 - INFO - root - LLMClientManager: using Gemini as default client
2025-11-16 19:27:28,000 - INFO - root - DeepSeekClient: API key found: 9f9e270e-b...
2025-11-16 19:27:28,000 - INFO - root - DeepSeekClient: 使用模式: 火山引擎
2025-11-16 19:27:28,003 - INFO - root - DeepSeekClient: 模型名称: deepseek-v3-1-terminus
2025-11-16 19:27:31,444 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-16 19:27:31,465 - INFO - root - DeepSeekClient: initialized successfully with model deepseek-v3-1-terminus
2025-11-16 19:27:31,467 - INFO - root - LLMClientManager: DeepSeek client initialized successfully
2025-11-16 19:27:31,468 - WARNING - root - KimiClient: API key not provided. LLM disabled.
2025-11-16 19:27:31,468 - WARNING - root - LLMClientManager: Kimi client initialization failed
2025-11-16 19:27:31,469 - WARNING - root - QwenClient: API key not provided. LLM disabled.
2025-11-16 19:27:31,469 - WARNING - root - LLMClientManager: Qwen client initialization failed
2025-11-16 19:27:31,469 - INFO - root - DoubaoClient: API key found: 9f9e270e-b...
2025-11-16 19:27:48,942 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-11-16 19:27:48,944 - INFO - openai._base_client - Retrying request to /chat/completions in 0.391923 seconds
2025-11-16 19:27:57,275 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-16 19:27:57,277 - INFO - root - DoubaoClient: initialized successfully with model doubao-seed-1-6-lite-251015
2025-11-16 19:27:57,277 - INFO - root - LLMClientManager: Doubao client initialized successfully
2025-11-16 19:27:57,278 - WARNING - root - LLMClientManager: client DeekSeek not available. Available clients: ['Gemini', 'DeepSeek', 'Doubao']
2025-11-16 19:27:57,281 - WARNING - root - 无法切换到指定的客户端 DeekSeek，将使用默认客户端
2025-11-16 19:27:57,281 - INFO - root - 可用客户端: ['Gemini', 'DeepSeek', 'Doubao']
2025-11-16 19:27:57,282 - INFO - root - 使用 LLM 模型: gemini-2.5-flash
2025-11-16 19:27:57,286 - INFO - root - 可用客户端: ['Gemini', 'DeepSeek', 'Doubao']
2025-11-16 19:27:57,287 - INFO - root - === 运行配置 ===
2025-11-16 19:27:57,288 - INFO - root - 处理模式: Semantic Scholar 高引用搜索 (API)
2025-11-16 19:27:57,289 - INFO - root - 查询 (关键词): hybrid attention
2025-11-16 19:27:57,289 - INFO - root - 关键词 (用于保存): hybrid attention
2025-11-16 19:27:57,291 - INFO - root - 排序: citationCount:desc
2025-11-16 19:27:57,292 - INFO - root - 最大处理数量: 50
2025-11-16 19:27:57,293 - INFO - root - 保存图片: 是
2025-11-16 19:27:57,293 - INFO - root - 输出语言: 中文
2025-11-16 19:27:57,293 - INFO - root - 强制重新处理: 否
2025-11-16 19:27:57,295 - INFO - root - LLM 客户端: DeekSeek
2025-11-16 19:27:57,295 - INFO - root - ====================
2025-11-16 19:27:57,296 - INFO - root - 正在使用检索策略: semantic
2025-11-16 19:27:57,296 - INFO - root - 使用 Semantic Scholar 高引用搜索模式 (API)
2025-11-16 19:27:57,296 - INFO - root - Semantic API 查询: query=hybrid attention, limit=50, sort=citationCount:desc
2025-11-16 19:27:57,297 - INFO - root - 正在调用 Semantic Scholar API...
2025-11-16 19:28:02,653 - ERROR - root - 处理 Semantic Scholar 结果时出错: HTTPSConnectionPool(host='api.semanticscholar.org', port=443): Max retries exceeded with url: /graph/v1/paper/search?query=hybrid+attention&limit=50&sort=citationCount%3Adesc&fields=title%2Curl%2Cabstract%2Cauthors%2CpublicationDate%2CcitationCount%2CopenAccessPdf (Caused by SSLError(SSLEOFError(8, '[SSL: UNEXPECTED_EOF_WHILE_READING] EOF occurred in violation of protocol (_ssl.c:1010)')))
urllib3.exceptions.SSLError: [SSL: UNEXPECTED_EOF_WHILE_READING] EOF occurred in violation of protocol (_ssl.c:1010)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\requests\adapters.py", line 667, in send
    resp = conn.urlopen(
           ^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\urllib3\connectionpool.py", line 841, in urlopen
    retries = retries.increment(
              ^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\urllib3\util\retry.py", line 519, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='api.semanticscholar.org', port=443): Max retries exceeded with url: /graph/v1/paper/search?query=hybrid+attention&limit=50&sort=citationCount%3Adesc&fields=title%2Curl%2Cabstract%2Cauthors%2CpublicationDate%2CcitationCount%2CopenAccessPdf (Caused by SSLError(SSLEOFError(8, '[SSL: UNEXPECTED_EOF_WHILE_READING] EOF occurred in violation of protocol (_ssl.c:1010)')))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\ChatPaper\retrievers.py", line 294, in retrieve
    response = self._call_api(params)
               ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\tenacity\__init__.py", line 338, in wrapped_f
    return copy(f, *args, **kw)
           ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\tenacity\__init__.py", line 477, in __call__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\tenacity\__init__.py", line 378, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\tenacity\__init__.py", line 400, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\tenacity\__init__.py", line 480, in __call__
    result = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\retrievers.py", line 274, in _call_api
    response = requests.get(self.API_URL, params=params, timeout=30)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\requests\api.py", line 73, in get
    return request("get", url, params=params, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\requests\api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\requests\sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\requests\sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\requests\adapters.py", line 698, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: HTTPSConnectionPool(host='api.semanticscholar.org', port=443): Max retries exceeded with url: /graph/v1/paper/search?query=hybrid+attention&limit=50&sort=citationCount%3Adesc&fields=title%2Curl%2Cabstract%2Cauthors%2CpublicationDate%2CcitationCount%2CopenAccessPdf (Caused by SSLError(SSLEOFError(8, '[SSL: UNEXPECTED_EOF_WHILE_READING] EOF occurred in violation of protocol (_ssl.c:1010)')))
2025-11-16 19:28:02,683 - INFO - root - 没有找到要处理的论文，程序退出
2025-11-16 19:28:02,683 - INFO - root - 总运行时间: 49.03 seconds
2025-11-16 19:30:08,352 - WARNING - root - Google Scholar 检索器依赖未能加载: No module named 'selenium'。 'scholar' 策略将不可用。
2025-11-16 19:30:08,354 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-16 19:30:08,355 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-16 19:30:08,357 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-16 19:30:13,035 - INFO - root - LLMClientManager: 指定使用客户端: DeekSeek
2025-11-16 19:30:13,036 - WARNING - root - LLMClientManager: 指定的客户端 DeekSeek 不可用，将尝试其他客户端
2025-11-16 19:30:17,338 - INFO - root - GeminiClient: trying model models/gemini-2.5-flash
2025-11-16 19:30:20,082 - INFO - root - GeminiClient: initialized model gemini-2.5-flash
2025-11-16 19:30:20,086 - INFO - root - LLMClientManager: Gemini client initialized successfully
2025-11-16 19:30:20,088 - INFO - root - LLMClientManager: using Gemini as default client
2025-11-16 19:30:20,089 - INFO - root - DeepSeekClient: API key found: 9f9e270e-b...
2025-11-16 19:30:20,091 - INFO - root - DeepSeekClient: 使用模式: 火山引擎
2025-11-16 19:30:20,092 - INFO - root - DeepSeekClient: 模型名称: ep-20251112215738-bz78g
2025-11-16 19:30:23,100 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-16 19:30:23,126 - INFO - root - DeepSeekClient: initialized successfully with model ep-20251112215738-bz78g
2025-11-16 19:30:23,126 - INFO - root - LLMClientManager: DeepSeek client initialized successfully
2025-11-16 19:30:23,127 - WARNING - root - KimiClient: API key not provided. LLM disabled.
2025-11-16 19:30:23,127 - WARNING - root - LLMClientManager: Kimi client initialization failed
2025-11-16 19:30:23,129 - WARNING - root - QwenClient: API key not provided. LLM disabled.
2025-11-16 19:30:23,133 - WARNING - root - LLMClientManager: Qwen client initialization failed
2025-11-16 19:30:23,134 - INFO - root - DoubaoClient: API key found: 9f9e270e-b...
2025-11-16 19:30:33,165 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-16 19:30:33,168 - INFO - root - DoubaoClient: initialized successfully with model doubao-seed-1-6-lite-251015
2025-11-16 19:30:33,169 - INFO - root - LLMClientManager: Doubao client initialized successfully
2025-11-16 19:30:33,170 - WARNING - root - LLMClientManager: client DeekSeek not available. Available clients: ['Gemini', 'DeepSeek', 'Doubao']
2025-11-16 19:30:33,172 - WARNING - root - 无法切换到指定的客户端 DeekSeek，将使用默认客户端
2025-11-16 19:30:33,177 - INFO - root - 可用客户端: ['Gemini', 'DeepSeek', 'Doubao']
2025-11-16 19:30:33,178 - INFO - root - 使用 LLM 模型: gemini-2.5-flash
2025-11-16 19:30:33,180 - INFO - root - 可用客户端: ['Gemini', 'DeepSeek', 'Doubao']
2025-11-16 19:30:33,181 - INFO - root - === 运行配置 ===
2025-11-16 19:30:33,182 - INFO - root - 处理模式: Semantic Scholar 高引用搜索 (API)
2025-11-16 19:30:33,183 - INFO - root - 查询 (关键词): hybrid attention
2025-11-16 19:30:33,185 - INFO - root - 关键词 (用于保存): hybrid attention
2025-11-16 19:30:33,187 - INFO - root - 排序: citationCount:desc
2025-11-16 19:30:33,188 - INFO - root - 最大处理数量: 50
2025-11-16 19:30:33,193 - INFO - root - 保存图片: 是
2025-11-16 19:30:33,194 - INFO - root - 输出语言: 中文
2025-11-16 19:30:33,194 - INFO - root - 强制重新处理: 否
2025-11-16 19:30:33,195 - INFO - root - LLM 客户端: DeekSeek
2025-11-16 19:30:33,195 - INFO - root - ====================
2025-11-16 19:30:33,196 - INFO - root - 正在使用检索策略: semantic
2025-11-16 19:30:33,196 - INFO - root - 使用 Semantic Scholar 高引用搜索模式 (API)
2025-11-16 19:30:33,197 - INFO - root - Semantic API 查询: query=hybrid attention, limit=50, sort=citationCount:desc
2025-11-16 19:30:33,197 - INFO - root - 正在调用 Semantic Scholar API...
2025-11-16 19:30:35,393 - WARNING - root - 【手动下载提示】(无PDF): An Instrument Indication Acquisition Algorithm Based on Lightweight Deep Convolutional Neural Network and Hybrid Attention Fine-Grained Features
	  URL: https://www.semanticscholar.org/paper/49f99d7a21e2ded7915676753a180983763b9a22
	  Citations: 67 | Authors: Jiaquan Shen, Ningzhong Liu, Han Sun, Deguang Li, Yongxin Zhang | Date: N/A
2025-11-16 19:30:35,398 - WARNING - root - 【手动下载提示】(无PDF): Dual-Hybrid Attention Network for Specular Highlight Removal
	  URL: https://www.semanticscholar.org/paper/d56ce689cc0f8b1cf0e5f58882503a5e59ec440b
	  Citations: 40 | Authors: Xiaojiao Guo, Xuhang Chen, Shenghong Luo, Shuqiang Wang, Chi-Man Pun | Date: 2024-07-17
2025-11-16 19:30:35,399 - WARNING - root - 【手动下载提示】(无PDF): Enhancing ASD classification through hybrid attention-based learning of facial features
	  URL: https://www.semanticscholar.org/paper/22547aa4c72c7c2799932a0f451ab3f2db6d7d0f
	  Citations: 35 | Authors: Inzamam Shahzad, Saif Ur Rehman Khan, Waseem Abbas, Z. U. Abideen, Jin Liu | Date: 2024-04-21
2025-11-16 19:30:35,399 - WARNING - root - 【手动下载提示】(无PDF): HyA-GAN: remote sensing image cloud removal based on hybrid attention generation adversarial network
	  URL: https://www.semanticscholar.org/paper/905b42f2f8d912d98fd7cbec4f7b244401176acc
	  Citations: 16 | Authors: Minghao Jin, Pengwei Wang, Yusong Li | Date: 2024-02-27
2025-11-16 19:30:35,400 - WARNING - root - 【手动下载提示】(无PDF): Hybrid Attention-Aware Transformer Network Collaborative Multiscale Feature Alignment for Building Change Detection
	  URL: https://www.semanticscholar.org/paper/a0f8053046622628073ac6f051b5181a80cb7ad3
	  Citations: 28 | Authors: Chuan Xu, Zhaoyi Ye, Liye Mei, Haonan Yu, Jianchen Liu, Yaxiaer Yalikun, Shuangtong Jin, Sheng Liu, Wei Yang, Cheng Lei | Date: N/A
2025-11-16 19:30:35,401 - WARNING - root - 【手动下载提示】(无PDF): Radar Signal Recognition Based on CNN With a Hybrid Attention Mechanism and Skip Feature Aggregation
	  URL: https://www.semanticscholar.org/paper/dacad703c49e9434321c91220219638f871fd9d2
	  Citations: 26 | Authors: Yuanpu Guo, Haixin Sun, Hui Liu, Zhen-miao Deng | Date: N/A
2025-11-16 19:30:35,401 - WARNING - root - 【手动下载提示】(无PDF): Probabilistic Multienergy Load Forecasting Based on Hybrid Attention-Enabled Transformer Network and Gaussian Process-Aided Residual Learning
	  URL: https://www.semanticscholar.org/paper/a2d81cc04f73e2898fb16e7e8c8f9cf69adadfd5
	  Citations: 17 | Authors: Pengfei Zhao, Weihao Hu, Di Cao, Zhenyuan Zhang, Yuehui Huang, Longcheng Dai, Zhe Chen | Date: 2024-06-01
2025-11-16 19:30:35,404 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\hybrid attention\Hybrid Attention Fusion Embedded in Transformer for Remote Sensing Image Semantic Segmentation.pdf
2025-11-16 19:30:35,404 - INFO - root - 成功下载 (Semantic Scholar): Hybrid Attention Fusion Embedded in Transformer for Remote Sensing Image Semantic Segmentation
2025-11-16 19:30:35,405 - WARNING - root - 【手动下载提示】(无PDF): Drone-HAT: Hybrid Attention Transformer for Complex Action Recognition in Drone Surveillance Videos
	  URL: https://www.semanticscholar.org/paper/a76690fb96dc7d3dfd5f8fec62c3949cc7ec96f6
	  Citations: 13 | Authors: Mustaqeem Khan, Jamil Ahmad, Abdulmotaleb El-Saddik, W. Gueaieb, Giulia De Masi, Fakhri Karray | Date: 2024-06-17
2025-11-16 19:30:35,405 - WARNING - root - 【手动下载提示】(无PDF): Enhancing Time Series Product Demand Forecasting With Hybrid Attention-Based Deep Learning Models
	  URL: https://www.semanticscholar.org/paper/4848b35cbe515f8909a67a82dcb83d7c5e48f74b
	  Citations: 14 | Authors: Xuguang Zhang, Pan Li, Xu Han, Yongbin Yang, Yiwen Cui | Date: N/A
2025-11-16 19:30:35,408 - INFO - root - 正在下载: https://www.mdpi.com/2306-5354/11/3/240/pdf?version=1709132347
2025-11-16 19:30:40,116 - INFO - root - 正在下载: https://www.mdpi.com/2306-5354/11/3/240/pdf?version=1709132347
2025-11-16 19:30:44,585 - INFO - root - 正在下载: https://www.mdpi.com/2306-5354/11/3/240/pdf?version=1709132347
2025-11-16 19:30:53,598 - INFO - root - 正在下载: https://www.mdpi.com/2306-5354/11/3/240/pdf?version=1709132347
2025-11-16 19:31:05,578 - INFO - root - 正在下载: https://www.mdpi.com/2306-5354/11/3/240/pdf?version=1709132347
2025-11-16 19:31:06,151 - WARNING - root - 下载 Advancing Ocular Imaging: A Hybrid Attention Mechanism-Based U-Net Model for Precise Segmentation of Sub-Retinal Layers in OCT Images (https://www.mdpi.com/2306-5354/11/3/240/pdf?version=1709132347) 失败: 403 Client Error: Forbidden for url: https://www.mdpi.com/2306-5354/11/3/240/pdf?version=1709132347
2025-11-16 19:31:06,152 - WARNING - root - 【手动下载提示】(无PDF): A novel approach for bearings multiclass fault diagnosis fusing multiscale deep convolution and hybrid attention networks
	  URL: https://www.semanticscholar.org/paper/bf72523fe518b2e4ce4d75d125dd5220177043f6
	  Citations: 13 | Authors: Fule Li, Xinlong Zhao | Date: 2024-01-08
2025-11-16 19:31:06,154 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\hybrid attention\YOLO Algorithm With Hybrid Attention Feature Pyramid Network for Solder Joint Defect Detection.pdf
2025-11-16 19:31:06,156 - INFO - root - 成功下载 (Semantic Scholar): YOLO Algorithm With Hybrid Attention Feature Pyramid Network for Solder Joint Defect Detection
2025-11-16 19:31:06,157 - WARNING - root - 【手动下载提示】(无PDF): Hybrid attention network for citrus disease identification
	  URL: https://www.semanticscholar.org/paper/856672ed8dfa8bebd3738fc3be20d3cbfff43593
	  Citations: 19 | Authors: Fukai Zhang, Xiaobo Jin, Gang Lin, Jie Jiang, Mingzhi Wang, Shan An, Junhua Hu, Qiang Lyu | Date: 2024-05-01
2025-11-16 19:31:06,159 - WARNING - root - 【手动下载提示】(无PDF): Dense Hybrid Attention Network for Palmprint Image Super-Resolution
	  URL: https://www.semanticscholar.org/paper/75746d8d52509b24d9975d9b3b07ae91311dc7ed
	  Citations: 12 | Authors: Yao Wang, Lunke Fei, Shuping Zhao, Qi Zhu, Jie Wen, Wei Jia, Imad Rida | Date: 2024-04-01
2025-11-16 19:31:06,160 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\hybrid attention\Frequency Enhanced Hybrid Attention Network for Sequential Recommendation.pdf
2025-11-16 19:31:06,161 - INFO - root - 成功下载 (Semantic Scholar): Frequency Enhanced Hybrid Attention Network for Sequential Recommendation
2025-11-16 19:31:06,162 - WARNING - root - 【手动下载提示】(无PDF): Hybrid Attention Feature Refinement Network for Lightweight Image Super-Resolution in Metaverse Immersive Display
	  URL: https://www.semanticscholar.org/paper/c4d95a47eec1a23320d60dd95848d41e10820ee4
	  Citations: 10 | Authors: Kexin Wang, Xiaomin Yang, Gwanggil Jeon | Date: 2024-02-01
2025-11-16 19:31:06,162 - WARNING - root - 【手动下载提示】(无PDF): A Multiscale Hybrid Attention Networks Based on Multiview Images for the Diagnosis of Parkinson’s Disease
	  URL: https://www.semanticscholar.org/paper/b2af0577ee8ac56b527bd108ce57755a4a4b04e7
	  Citations: 11 | Authors: Xinchun Cui, Youshi Zhou, Chao Zhao, Jianlong Li, Xiangwei Zheng, Xiuli Li, Shixiao Shan, JinXing Liu, Xiaoli Liu | Date: N/A
2025-11-16 19:31:06,168 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\hybrid attention\HAT_ Hybrid Attention Transformer for Image Restoration.pdf
2025-11-16 19:31:06,169 - INFO - root - 成功下载 (Semantic Scholar): HAT: Hybrid Attention Transformer for Image Restoration
2025-11-16 19:31:06,173 - INFO - root - 正在下载: https://www.mdpi.com/2076-3417/14/3/1293/pdf?version=1707037901
2025-11-16 19:31:13,845 - INFO - root - 正在下载: https://www.mdpi.com/2076-3417/14/3/1293/pdf?version=1707037901
2025-11-16 19:31:21,479 - INFO - root - 正在下载: https://www.mdpi.com/2076-3417/14/3/1293/pdf?version=1707037901
2025-11-16 19:31:25,940 - INFO - root - 正在下载: https://www.mdpi.com/2076-3417/14/3/1293/pdf?version=1707037901
2025-11-16 19:39:49,215 - WARNING - root - Google Scholar 检索器依赖未能加载: No module named 'selenium'。 'scholar' 策略将不可用。
2025-11-16 19:39:49,218 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-16 19:39:49,219 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-16 19:39:49,222 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-16 19:39:54,154 - INFO - root - LLMClientManager: 指定使用客户端: DeekSeek
2025-11-16 19:39:54,154 - WARNING - root - LLMClientManager: 指定的客户端 DeekSeek 不可用，将尝试其他客户端
2025-11-16 19:39:54,886 - INFO - root - GeminiClient: trying model models/gemini-2.5-flash
2025-11-16 19:41:21,409 - WARNING - root - Google Scholar 检索器依赖未能加载: No module named 'selenium'。 'scholar' 策略将不可用。
2025-11-16 19:41:21,411 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-16 19:41:21,412 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-16 19:41:21,414 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-16 19:41:26,016 - INFO - root - LLMClientManager: 指定使用客户端: DeepSeek
2025-11-16 19:41:26,017 - INFO - root - DeepSeekClient: API key found: 9f9e270e-b...
2025-11-16 19:41:26,017 - INFO - root - DeepSeekClient: 使用模式: 火山引擎
2025-11-16 19:41:26,022 - INFO - root - DeepSeekClient: 模型名称: ep-20251112215738-bz78g
2025-11-16 19:41:28,441 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-16 19:41:28,458 - INFO - root - DeepSeekClient: initialized successfully with model ep-20251112215738-bz78g
2025-11-16 19:41:28,459 - INFO - root - LLMClientManager: DeepSeek 客户端初始化成功
2025-11-16 19:41:28,460 - INFO - root - LLMClientManager: switched to DeepSeek client
2025-11-16 19:41:28,462 - INFO - root - 已手动切换到 LLM 客户端: DeepSeek
2025-11-16 19:41:28,462 - INFO - root - 使用 LLM 模型: ep-20251112215738-bz78g
2025-11-16 19:41:28,463 - INFO - root - 可用客户端: ['DeepSeek']
2025-11-16 19:41:28,464 - INFO - root - === 运行配置 ===
2025-11-16 19:41:28,464 - INFO - root - 处理模式: Semantic Scholar 高引用搜索 (API)
2025-11-16 19:41:28,464 - INFO - root - 查询 (关键词): hybrid attention
2025-11-16 19:41:28,465 - INFO - root - 关键词 (用于保存): hybrid attention
2025-11-16 19:41:28,465 - INFO - root - 排序: citationCount:desc
2025-11-16 19:41:28,465 - INFO - root - 最大处理数量: 50
2025-11-16 19:41:28,467 - INFO - root - 保存图片: 是
2025-11-16 19:41:28,468 - INFO - root - 输出语言: 中文
2025-11-16 19:41:28,469 - INFO - root - 强制重新处理: 否
2025-11-16 19:41:28,469 - INFO - root - LLM 客户端: DeepSeek
2025-11-16 19:41:28,470 - INFO - root - ====================
2025-11-16 19:41:28,470 - INFO - root - 正在使用检索策略: semantic
2025-11-16 19:41:28,471 - INFO - root - 使用 Semantic Scholar 高引用搜索模式 (API)
2025-11-16 19:41:28,471 - INFO - root - Semantic API 查询: query=hybrid attention, limit=50, sort=citationCount:desc
2025-11-16 19:41:28,472 - INFO - root - 正在调用 Semantic Scholar API...
2025-11-16 19:41:30,433 - WARNING - root - 【手动下载提示】(无PDF): An Instrument Indication Acquisition Algorithm Based on Lightweight Deep Convolutional Neural Network and Hybrid Attention Fine-Grained Features
	  URL: https://www.semanticscholar.org/paper/49f99d7a21e2ded7915676753a180983763b9a22
	  Citations: 67 | Authors: Jiaquan Shen, Ningzhong Liu, Han Sun, Deguang Li, Yongxin Zhang | Date: N/A
2025-11-16 19:41:30,434 - WARNING - root - 【手动下载提示】(无PDF): Dual-Hybrid Attention Network for Specular Highlight Removal
	  URL: https://www.semanticscholar.org/paper/d56ce689cc0f8b1cf0e5f58882503a5e59ec440b
	  Citations: 40 | Authors: Xiaojiao Guo, Xuhang Chen, Shenghong Luo, Shuqiang Wang, Chi-Man Pun | Date: 2024-07-17
2025-11-16 19:41:30,434 - WARNING - root - 【手动下载提示】(无PDF): Enhancing ASD classification through hybrid attention-based learning of facial features
	  URL: https://www.semanticscholar.org/paper/22547aa4c72c7c2799932a0f451ab3f2db6d7d0f
	  Citations: 35 | Authors: Inzamam Shahzad, Saif Ur Rehman Khan, Waseem Abbas, Z. U. Abideen, Jin Liu | Date: 2024-04-21
2025-11-16 19:41:30,436 - WARNING - root - 【手动下载提示】(无PDF): HyA-GAN: remote sensing image cloud removal based on hybrid attention generation adversarial network
	  URL: https://www.semanticscholar.org/paper/905b42f2f8d912d98fd7cbec4f7b244401176acc
	  Citations: 16 | Authors: Minghao Jin, Pengwei Wang, Yusong Li | Date: 2024-02-27
2025-11-16 19:41:30,436 - WARNING - root - 【手动下载提示】(无PDF): Radar Signal Recognition Based on CNN With a Hybrid Attention Mechanism and Skip Feature Aggregation
	  URL: https://www.semanticscholar.org/paper/dacad703c49e9434321c91220219638f871fd9d2
	  Citations: 26 | Authors: Yuanpu Guo, Haixin Sun, Hui Liu, Zhen-miao Deng | Date: N/A
2025-11-16 19:41:30,437 - WARNING - root - 【手动下载提示】(无PDF): Hybrid Attention-Aware Transformer Network Collaborative Multiscale Feature Alignment for Building Change Detection
	  URL: https://www.semanticscholar.org/paper/a0f8053046622628073ac6f051b5181a80cb7ad3
	  Citations: 28 | Authors: Chuan Xu, Zhaoyi Ye, Liye Mei, Haonan Yu, Jianchen Liu, Yaxiaer Yalikun, Shuangtong Jin, Sheng Liu, Wei Yang, Cheng Lei | Date: N/A
2025-11-16 19:41:30,444 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\hybrid attention\Hybrid Attention Fusion Embedded in Transformer for Remote Sensing Image Semantic Segmentation.pdf
2025-11-16 19:41:30,446 - INFO - root - 成功下载 (Semantic Scholar): Hybrid Attention Fusion Embedded in Transformer for Remote Sensing Image Semantic Segmentation
2025-11-16 19:41:30,447 - WARNING - root - 【手动下载提示】(无PDF): Probabilistic Multienergy Load Forecasting Based on Hybrid Attention-Enabled Transformer Network and Gaussian Process-Aided Residual Learning
	  URL: https://www.semanticscholar.org/paper/a2d81cc04f73e2898fb16e7e8c8f9cf69adadfd5
	  Citations: 17 | Authors: Pengfei Zhao, Weihao Hu, Di Cao, Zhenyuan Zhang, Yuehui Huang, Longcheng Dai, Zhe Chen | Date: 2024-06-01
2025-11-16 19:41:30,448 - WARNING - root - 【手动下载提示】(无PDF): Enhancing Time Series Product Demand Forecasting With Hybrid Attention-Based Deep Learning Models
	  URL: https://www.semanticscholar.org/paper/4848b35cbe515f8909a67a82dcb83d7c5e48f74b
	  Citations: 14 | Authors: Xuguang Zhang, Pan Li, Xu Han, Yongbin Yang, Yiwen Cui | Date: N/A
2025-11-16 19:41:30,451 - INFO - root - 正在下载: https://www.mdpi.com/2306-5354/11/3/240/pdf?version=1709132347
2025-11-16 19:41:34,897 - INFO - root - 正在下载: https://www.mdpi.com/2306-5354/11/3/240/pdf?version=1709132347
2025-11-16 19:41:39,675 - INFO - root - 正在下载: https://www.mdpi.com/2306-5354/11/3/240/pdf?version=1709132347
2025-11-16 19:41:44,516 - INFO - root - 正在下载: https://www.mdpi.com/2306-5354/11/3/240/pdf?version=1709132347
2025-11-16 19:42:40,136 - WARNING - root - Google Scholar 检索器依赖未能加载: No module named 'selenium'。 'scholar' 策略将不可用。
2025-11-16 19:42:40,140 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-16 19:42:40,141 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-16 19:42:40,143 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-16 19:42:44,598 - INFO - root - LLMClientManager: 指定使用客户端: DeepSeek
2025-11-16 19:42:44,598 - INFO - root - DeepSeekClient: API key found: 9f9e270e-b...
2025-11-16 19:42:44,598 - INFO - root - DeepSeekClient: 使用模式: 火山引擎
2025-11-16 19:42:44,599 - INFO - root - DeepSeekClient: 模型名称: ep-20251112215738-bz78g
2025-11-16 19:42:47,605 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-16 19:42:47,629 - INFO - root - DeepSeekClient: initialized successfully with model ep-20251112215738-bz78g
2025-11-16 19:42:47,631 - INFO - root - LLMClientManager: DeepSeek 客户端初始化成功
2025-11-16 19:42:47,632 - INFO - root - LLMClientManager: switched to DeepSeek client
2025-11-16 19:42:47,633 - INFO - root - 已手动切换到 LLM 客户端: DeepSeek
2025-11-16 19:42:47,634 - INFO - root - 使用 LLM 模型: ep-20251112215738-bz78g
2025-11-16 19:42:47,635 - INFO - root - 可用客户端: ['DeepSeek']
2025-11-16 19:42:47,635 - INFO - root - === 运行配置 ===
2025-11-16 19:42:47,636 - INFO - root - 处理模式: Semantic Scholar 高引用搜索 (API)
2025-11-16 19:42:47,637 - INFO - root - 查询 (关键词): SNN
2025-11-16 19:42:47,637 - INFO - root - 关键词 (用于保存): SNN
2025-11-16 19:42:47,638 - INFO - root - 排序: citationCount:desc
2025-11-16 19:42:47,645 - INFO - root - 最大处理数量: 50
2025-11-16 19:42:47,647 - INFO - root - 保存图片: 是
2025-11-16 19:42:47,647 - INFO - root - 输出语言: 中文
2025-11-16 19:42:47,647 - INFO - root - 强制重新处理: 否
2025-11-16 19:42:47,649 - INFO - root - LLM 客户端: DeepSeek
2025-11-16 19:42:47,649 - INFO - root - ====================
2025-11-16 19:42:47,649 - INFO - root - 正在使用检索策略: semantic
2025-11-16 19:42:47,650 - INFO - root - 使用 Semantic Scholar 高引用搜索模式 (API)
2025-11-16 19:42:47,650 - INFO - root - Semantic API 查询: query=SNN, limit=50, sort=citationCount:desc
2025-11-16 19:42:47,651 - INFO - root - 正在调用 Semantic Scholar API...
2025-11-16 19:42:52,782 - INFO - root - 正在下载: http://arxiv.org/pdf/2303.04347
2025-11-16 19:43:01,697 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\SNN\Optimal ANN-SNN Conversion for High-accuracy and Ultra-low-latency Spiking Neural Networks.pdf
2025-11-16 19:43:01,699 - INFO - root - 成功下载 (Semantic Scholar): Optimal ANN-SNN Conversion for High-accuracy and Ultra-low-latency Spiking Neural Networks
2025-11-16 19:43:01,700 - WARNING - root - 【手动下载提示】(无PDF): Spikformer V2: Join the High Accuracy Club on ImageNet with an SNN Ticket
	  URL: https://www.semanticscholar.org/paper/ea686f0d933b8e6e4c753a45e433ad386e421272
	  Citations: 44 | Authors: Zhaokun Zhou, Kaiwei Che, Wei Fang, Keyu Tian, Yuesheng Zhu, Shuicheng Yan, Yonghong Tian, Liuliang Yuan | Date: 2024-01-04
2025-11-16 19:43:01,700 - WARNING - root - 【手动下载提示】(无PDF): EC-SNN: Splitting Deep Spiking Neural Networks for Edge Devices
	  URL: https://www.semanticscholar.org/paper/2ddd772431afa27b4b1057bdfe9f78f1180c20c9
	  Citations: 14 | Authors: Di Yu, Xin Du, Linshan Jiang, Wentao Tong, Shuiguang Deng | Date: 2024-08-01
2025-11-16 19:43:01,700 - WARNING - root - 【手动下载提示】(无PDF): Stellar: Energy-Efficient and Low-Latency SNN Algorithm and Hardware Co-Design with Spatiotemporal Computation
	  URL: https://www.semanticscholar.org/paper/be395b1fbff024dd692339295e96405cdb3b90be
	  Citations: 14 | Authors: Ruixin Mao, Lin Tang, Xingyu Yuan, Ye Liu, Jun Zhou | Date: 2024-03-02
2025-11-16 19:43:01,701 - WARNING - root - 【手动下载提示】(无PDF): SpikeZIP-TF: Conversion is All You Need for Transformer-based SNN
	  URL: https://www.semanticscholar.org/paper/c0e12df9837da93ba4ff0786a832cb30710c1039
	  Citations: 15 | Authors: Kang You, Zekai Xu, Chen Nie, Zhijie Deng, Qinghai Guo, Xiang Wang, Zhezhi He | Date: 2024-06-05
2025-11-16 19:43:01,701 - WARNING - root - 【手动下载提示】(无PDF): C-DNN: An Energy-Efficient Complementary Deep-Neural-Network Processor With Heterogeneous CNN/SNN Core Architecture
	  URL: https://www.semanticscholar.org/paper/8de631b5a085cc00c89c30073a83635a60e6dbf6
	  Citations: 15 | Authors: Sangyeob Kim, Soyeon Kim, Seongyon Hong, Sangjin Kim, Donghyeon Han, Jiwon Choi, H.-J. Yoo | Date: 2024-01-01
2025-11-16 19:43:01,703 - INFO - root - 正在下载: https://arxiv.org/pdf/2305.19868
2025-11-16 19:43:10,715 - INFO - root - 正在下载: https://arxiv.org/pdf/2305.19868
2025-11-16 19:43:15,437 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\SNN\Fast-SNN_ Fast Spiking Neural Network by Converting Quantized ANN.pdf
2025-11-16 19:43:15,438 - INFO - root - 成功下载 (Semantic Scholar): Fast-SNN: Fast Spiking Neural Network by Converting Quantized ANN
2025-11-16 19:43:15,439 - INFO - root - 正在下载: http://arxiv.org/pdf/2302.02091
2025-11-16 19:43:19,695 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\SNN\Reducing ANN-SNN Conversion Error through Residual Membrane Potential.pdf
2025-11-16 19:43:19,697 - INFO - root - 成功下载 (Semantic Scholar): Reducing ANN-SNN Conversion Error through Residual Membrane Potential
2025-11-16 19:43:19,697 - INFO - root - 正在下载: https://figshare.com/articles/journal_contribution/CDNA-SNN_A_new_spiking_neural_network_for_pattern_classification_using_neuronal_assemblies/25531474/1/files/45431524.pdf
2025-11-16 19:43:37,761 - WARNING - root - Google Scholar 检索器依赖未能加载: No module named 'selenium'。 'scholar' 策略将不可用。
2025-11-16 19:43:37,764 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-16 19:43:37,765 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-16 19:43:37,770 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-16 19:43:42,209 - INFO - root - LLMClientManager: 指定使用客户端: DeepSeek
2025-11-16 19:43:42,210 - INFO - root - DeepSeekClient: API key found: 9f9e270e-b...
2025-11-16 19:43:42,211 - INFO - root - DeepSeekClient: 使用模式: 火山引擎
2025-11-16 19:43:42,211 - INFO - root - DeepSeekClient: 模型名称: ep-20251112215738-bz78g
2025-11-16 19:43:44,741 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-16 19:43:44,758 - INFO - root - DeepSeekClient: initialized successfully with model ep-20251112215738-bz78g
2025-11-16 19:43:44,759 - INFO - root - LLMClientManager: DeepSeek 客户端初始化成功
2025-11-16 19:43:44,760 - INFO - root - LLMClientManager: switched to DeepSeek client
2025-11-16 19:43:44,760 - INFO - root - 已手动切换到 LLM 客户端: DeepSeek
2025-11-16 19:43:44,768 - INFO - root - 使用 LLM 模型: ep-20251112215738-bz78g
2025-11-16 19:43:44,770 - INFO - root - 可用客户端: ['DeepSeek']
2025-11-16 19:43:44,771 - INFO - root - === 运行配置 ===
2025-11-16 19:43:44,771 - INFO - root - 处理模式: Semantic Scholar 高引用搜索 (API)
2025-11-16 19:43:44,772 - INFO - root - 查询 (关键词): SNN
2025-11-16 19:43:44,772 - INFO - root - 关键词 (用于保存): SNN
2025-11-16 19:43:44,773 - INFO - root - 排序: citationCount:desc
2025-11-16 19:43:44,774 - INFO - root - 最大处理数量: 100
2025-11-16 19:43:44,775 - INFO - root - 保存图片: 是
2025-11-16 19:43:44,775 - INFO - root - 输出语言: 中文
2025-11-16 19:43:44,776 - INFO - root - 强制重新处理: 否
2025-11-16 19:43:44,777 - INFO - root - LLM 客户端: DeepSeek
2025-11-16 19:43:44,777 - INFO - root - ====================
2025-11-16 19:43:44,778 - INFO - root - 正在使用检索策略: semantic
2025-11-16 19:43:44,782 - INFO - root - 使用 Semantic Scholar 高引用搜索模式 (API)
2025-11-16 19:43:44,786 - INFO - root - Semantic API 查询: query=SNN, limit=100, sort=citationCount:desc
2025-11-16 19:43:44,787 - INFO - root - 正在调用 Semantic Scholar API...
2025-11-16 19:43:49,416 - INFO - root - 正在调用 Semantic Scholar API...
2025-11-16 19:43:54,056 - INFO - root - 正在调用 Semantic Scholar API...
2025-11-16 19:44:00,394 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\SNN\Optimal ANN-SNN Conversion for High-accuracy and Ultra-low-latency Spiking Neural Networks.pdf
2025-11-16 19:44:00,395 - INFO - root - 成功下载 (Semantic Scholar): Optimal ANN-SNN Conversion for High-accuracy and Ultra-low-latency Spiking Neural Networks
2025-11-16 19:44:00,396 - WARNING - root - 【手动下载提示】(无PDF): Spikformer V2: Join the High Accuracy Club on ImageNet with an SNN Ticket
	  URL: https://www.semanticscholar.org/paper/ea686f0d933b8e6e4c753a45e433ad386e421272
	  Citations: 44 | Authors: Zhaokun Zhou, Kaiwei Che, Wei Fang, Keyu Tian, Yuesheng Zhu, Shuicheng Yan, Yonghong Tian, Liuliang Yuan | Date: 2024-01-04
2025-11-16 19:44:00,397 - WARNING - root - 【手动下载提示】(无PDF): Stellar: Energy-Efficient and Low-Latency SNN Algorithm and Hardware Co-Design with Spatiotemporal Computation
	  URL: https://www.semanticscholar.org/paper/be395b1fbff024dd692339295e96405cdb3b90be
	  Citations: 14 | Authors: Ruixin Mao, Lin Tang, Xingyu Yuan, Ye Liu, Jun Zhou | Date: 2024-03-02
2025-11-16 19:44:00,397 - WARNING - root - 【手动下载提示】(无PDF): EC-SNN: Splitting Deep Spiking Neural Networks for Edge Devices
	  URL: https://www.semanticscholar.org/paper/2ddd772431afa27b4b1057bdfe9f78f1180c20c9
	  Citations: 14 | Authors: Di Yu, Xin Du, Linshan Jiang, Wentao Tong, Shuiguang Deng | Date: 2024-08-01
2025-11-16 19:44:00,397 - WARNING - root - 【手动下载提示】(无PDF): C-DNN: An Energy-Efficient Complementary Deep-Neural-Network Processor With Heterogeneous CNN/SNN Core Architecture
	  URL: https://www.semanticscholar.org/paper/8de631b5a085cc00c89c30073a83635a60e6dbf6
	  Citations: 15 | Authors: Sangyeob Kim, Soyeon Kim, Seongyon Hong, Sangjin Kim, Donghyeon Han, Jiwon Choi, H.-J. Yoo | Date: 2024-01-01
2025-11-16 19:44:00,399 - WARNING - root - 【手动下载提示】(无PDF): SpikeZIP-TF: Conversion is All You Need for Transformer-based SNN
	  URL: https://www.semanticscholar.org/paper/c0e12df9837da93ba4ff0786a832cb30710c1039
	  Citations: 15 | Authors: Kang You, Zekai Xu, Chen Nie, Zhijie Deng, Qinghai Guo, Xiang Wang, Zhezhi He | Date: 2024-06-05
2025-11-16 19:44:00,400 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\SNN\Fast-SNN_ Fast Spiking Neural Network by Converting Quantized ANN.pdf
2025-11-16 19:44:00,401 - INFO - root - 成功下载 (Semantic Scholar): Fast-SNN: Fast Spiking Neural Network by Converting Quantized ANN
2025-11-16 19:44:00,404 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\SNN\Reducing ANN-SNN Conversion Error through Residual Membrane Potential.pdf
2025-11-16 19:44:00,405 - INFO - root - 成功下载 (Semantic Scholar): Reducing ANN-SNN Conversion Error through Residual Membrane Potential
2025-11-16 19:44:00,406 - INFO - root - 正在下载: https://figshare.com/articles/journal_contribution/CDNA-SNN_A_new_spiking_neural_network_for_pattern_classification_using_neuronal_assemblies/25531474/1/files/45431524.pdf
2025-11-16 19:44:10,392 - INFO - root - 正在下载: https://figshare.com/articles/journal_contribution/CDNA-SNN_A_new_spiking_neural_network_for_pattern_classification_using_neuronal_assemblies/25531474/1/files/45431524.pdf
2025-11-16 19:44:19,411 - INFO - root - 正在下载: https://figshare.com/articles/journal_contribution/CDNA-SNN_A_new_spiking_neural_network_for_pattern_classification_using_neuronal_assemblies/25531474/1/files/45431524.pdf
2025-11-16 19:44:28,429 - INFO - root - 正在下载: https://figshare.com/articles/journal_contribution/CDNA-SNN_A_new_spiking_neural_network_for_pattern_classification_using_neuronal_assemblies/25531474/1/files/45431524.pdf
2025-11-16 19:44:39,608 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\SNN\CDNA-SNN_ A New Spiking Neural Network for Pattern Classification Using Neuronal Assemblies.pdf
2025-11-16 19:44:39,612 - INFO - root - 成功下载 (Semantic Scholar): CDNA-SNN: A New Spiking Neural Network for Pattern Classification Using Neuronal Assemblies
2025-11-16 19:44:39,613 - INFO - root - 正在下载: https://arxiv.org/pdf/2403.08786
2025-11-16 19:44:40,952 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\SNN\One-Spike SNN_ Single-Spike Phase Coding With Base Manipulation for ANN-to-SNN Conversion Loss Minim.pdf
2025-11-16 19:44:40,957 - INFO - root - 成功下载 (Semantic Scholar): One-Spike SNN: Single-Spike Phase Coding With Base Manipulation for ANN-to-SNN Conversion Loss Minimization
2025-11-16 19:44:40,959 - INFO - root - 正在下载: https://arxiv.org/pdf/2003.01811
2025-11-16 19:44:44,117 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\SNN\RMP-SNN_ Residual Membrane Potential Neuron for Enabling Deeper High-Accuracy and Low-Latency Spikin.pdf
2025-11-16 19:44:44,118 - INFO - root - 成功下载 (Semantic Scholar): RMP-SNN: Residual Membrane Potential Neuron for Enabling Deeper High-Accuracy and Low-Latency Spiking Neural Network
2025-11-16 19:44:44,119 - WARNING - root - 【手动下载提示】(无PDF): DIET-SNN: A Low-Latency Spiking Neural Network With Direct Input Encoding and Leakage and Threshold Optimization
	  URL: https://www.semanticscholar.org/paper/1921489a2801f053d0906079f0015ba6e68dd505
	  Citations: 288 | Authors: Nitin Rathi, K. Roy | Date: 2021-10-01
2025-11-16 19:44:44,119 - WARNING - root - 【手动下载提示】(无PDF): R-SNN: Region-Based Spiking Neural Network for Object Detection
	  URL: https://www.semanticscholar.org/paper/9505f652ac70760a67bd8737aab5fe258bc59214
	  Citations: 10 | Authors: Xiaobo Jin, Ming Zhang, Rui Yan, Gang Pan, De Ma | Date: 2024-06-01
2025-11-16 19:44:44,119 - WARNING - root - 【手动下载提示】(无PDF): A Unified Optimization Framework of ANN-SNN Conversion: Towards Optimal Mapping from Activation Values to Firing Rates
	  URL: https://www.semanticscholar.org/paper/658c731084818742ca776b079e3f9d29ce790afc
	  Citations: 31 | Authors: Haiyan Jiang, Srinivas Anumasa, G. Masi, Huan Xiong, Bin Gu | Date: N/A
2025-11-16 19:44:44,120 - WARNING - root - 【手动下载提示】(无PDF): C-DNN: A 24.5-85.8TOPS/W Complementary-Deep-Neural-Network Processor with Heterogeneous CNN/SNN Core Architecture and Forward-Gradient-Based Sparsity Generation
	  URL: https://www.semanticscholar.org/paper/7f06777be3d030c8558834400b7d44511d4c0de2
	  Citations: 29 | Authors: Sangyeob Kim, Soyeon Kim, Seongyon Hong, Sangjin Kim, Donghyeon Han, H. Yoo | Date: 2023-02-19
2025-11-16 19:44:44,120 - INFO - root - 正在下载: https://arxiv.org/pdf/2303.14176
2025-11-16 19:44:47,953 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\SNN\A Hybrid ANN-SNN Architecture for Low-Power and Low-Latency Visual Perception.pdf
2025-11-16 19:44:47,955 - INFO - root - 成功下载 (Semantic Scholar): A Hybrid ANN-SNN Architecture for Low-Power and Low-Latency Visual Perception
2025-11-16 19:44:47,955 - WARNING - root - 【手动下载提示】(无PDF): Direct Training of SNN using Local Zeroth Order Method
	  URL: https://www.semanticscholar.org/paper/09bc7a4f9dc1f7a105beb980fe0d984f253ad007
	  Citations: 25 | Authors: B. Mukhoty, Velibor Bojkovic, William de Vazelhes, Xiaohan Zhao, Giulia De Masi, Huan Xiong, Bin Gu | Date: N/A
2025-11-16 19:44:47,956 - INFO - root - 正在下载: https://www.ijcai.org/proceedings/2023/0342.pdf
2025-11-16 19:44:51,409 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\SNN\A New ANN-SNN Conversion Method with High Accuracy, Low Latency and Good Robustness.pdf
2025-11-16 19:44:51,412 - INFO - root - 成功下载 (Semantic Scholar): A New ANN-SNN Conversion Method with High Accuracy, Low Latency and Good Robustness
2025-11-16 19:44:51,414 - INFO - root - 正在下载: https://www.frontiersin.org/articles/10.3389/fnins.2023.1141701/pdf
2025-11-16 19:44:57,990 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\SNN\High-accuracy deep ANN-to-SNN conversion using quantization-aware training framework and calcium-gat.pdf
2025-11-16 19:44:57,993 - INFO - root - 成功下载 (Semantic Scholar): High-accuracy deep ANN-to-SNN conversion using quantization-aware training framework and calcium-gated bipolar leaky integrate and fire neuron
2025-11-16 19:44:57,994 - WARNING - root - 【手动下载提示】(无PDF): RecDis-SNN: Rectifying Membrane Potential Distribution for Directly Training Spiking Neural Networks
	  URL: https://www.semanticscholar.org/paper/7531fcc48903d31faa1aea1da34d79c5d9d1167c
	  Citations: 89 | Authors: Yufei Guo, Xin-Yi Tong, Y. Chen, Liwen Zhang, Xiaode Liu, Zhe Ma, Xuhui Huang | Date: 2022-06-01
2025-11-16 19:44:57,996 - INFO - root - 正在下载: https://www.ijcai.org/proceedings/2021/0321.pdf
2025-11-16 19:45:08,740 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\SNN\Optimal ANN-SNN Conversion for Fast and Accurate Inference in Deep Spiking Neural Networks.pdf
2025-11-16 19:45:08,742 - INFO - root - 成功下载 (Semantic Scholar): Optimal ANN-SNN Conversion for Fast and Accurate Inference in Deep Spiking Neural Networks
2025-11-16 19:45:08,742 - INFO - root - 正在下载: https://arxiv.org/pdf/2206.10177
2025-11-16 19:45:17,748 - INFO - root - 正在下载: https://arxiv.org/pdf/2206.10177
2025-11-16 19:45:26,754 - INFO - root - 正在下载: https://arxiv.org/pdf/2206.10177
2025-11-16 19:45:29,645 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\SNN\TCJA-SNN_ Temporal-Channel Joint Attention for Spiking Neural Networks.pdf
2025-11-16 19:45:29,647 - INFO - root - 成功下载 (Semantic Scholar): TCJA-SNN: Temporal-Channel Joint Attention for Spiking Neural Networks
2025-11-16 19:45:29,648 - WARNING - root - 【手动下载提示】(无PDF): Symmetric-threshold ReLU for Fast and Nearly Lossless ANN-SNN Conversion
	  URL: https://www.semanticscholar.org/paper/94b86a09fb8a68776f50d953253340bec8ad4904
	  Citations: 17 | Authors: Jianing Han, Ziming Wang, Jiangrong Shen, Huajin Tang | Date: 2023-03-31
2025-11-16 19:45:29,649 - INFO - root - 正在下载: https://www.ijcai.org/proceedings/2022/0347.pdf
2025-11-16 19:45:37,026 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\SNN\Signed Neuron with Memory_ Towards Simple, Accurate and High-Efficient ANN-SNN Conversion.pdf
2025-11-16 19:45:37,028 - INFO - root - 成功下载 (Semantic Scholar): Signed Neuron with Memory: Towards Simple, Accurate and High-Efficient ANN-SNN Conversion
2025-11-16 19:45:37,029 - INFO - root - 正在下载: https://www.nature.com/articles/s41598-023-32120-7.pdf
2025-11-16 19:45:43,614 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\SNN\A low cost neuromorphic learning engine based on a high performance supervised SNN learning algorith.pdf
2025-11-16 19:45:43,617 - INFO - root - 成功下载 (Semantic Scholar): A low cost neuromorphic learning engine based on a high performance supervised SNN learning algorithm
2025-11-16 19:45:43,617 - WARNING - root - 【手动下载提示】(无PDF): A Neuromorphic Processing System With Spike-Driven SNN Processor for Wearable ECG Classification
	  URL: https://www.semanticscholar.org/paper/300bf970faa9016bdb538443aa53f4755ca14117
	  Citations: 57 | Authors: Haoming Chu, Yulong Yan, Leijing Gan, Hao Jia, Liyu Qian, Y. Huan, Lirong Zheng, Zhuo Zou | Date: 2022-07-08
2025-11-16 19:45:43,617 - INFO - root - 正在下载: https://escholarship.org/content/qt05h3w38z/qt05h3w38z.pdf?t=sb2olf
2025-11-16 19:45:48,078 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\SNN\OpenSpike_ An OpenRAM SNN Accelerator.pdf
2025-11-16 19:45:48,081 - INFO - root - 成功下载 (Semantic Scholar): OpenSpike: An OpenRAM SNN Accelerator
2025-11-16 19:45:48,082 - WARNING - root - 【手动下载提示】(无PDF): ENLARGE: An Efficient SNN Simulation Framework on GPU Clusters
	  URL: https://www.semanticscholar.org/paper/7f2c63ef26fc13d57481965aa49acd1516084ec2
	  Citations: 11 | Authors: Peng Qu, Hui Lin, Meng Pang, Xiaofei Liu, Weimin Zheng, Youhui Zhang | Date: 2023-09-01
2025-11-16 19:45:48,082 - INFO - root - 正在下载: http://arxiv.org/pdf/2304.09101
2025-11-16 19:45:50,631 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\SNN\LaSNN_ Layer-wise ANN-to-SNN Distillation for Effective and Efficient Training in Deep Spiking Neura.pdf
2025-11-16 19:45:50,634 - INFO - root - 成功下载 (Semantic Scholar): LaSNN: Layer-wise ANN-to-SNN Distillation for Effective and Efficient Training in Deep Spiking Neural Networks
2025-11-16 19:45:50,634 - WARNING - root - 【手动下载提示】(无PDF): A Fast and Energy-Efficient SNN Processor With Adaptive Clock/Event-Driven Computation Scheme and Online Learning
	  URL: https://www.semanticscholar.org/paper/9b0678ff3ebf6576dc0b6aac37fba08ab323e1dc
	  Citations: 106 | Authors: Sixu Li, Zhaomin Zhang, R. Mao, Jianbiao Xiao, L. Chang, Jun Zhou | Date: 2021-04-01
2025-11-16 19:45:50,634 - WARNING - root - 【手动下载提示】(无PDF): A Method of Converting ANN to SNN for Image Classification
	  URL: https://www.semanticscholar.org/paper/acf2874c30581a54c7025582cec65f86f248f35f
	  Citations: 8 | Authors: R. Zhou | Date: 2023-05-26
2025-11-16 19:45:50,634 - WARNING - root - 【手动下载提示】(无PDF): DIET-SNN: Direct Input Encoding With Leakage and Threshold Optimization in Deep Spiking Neural Networks
	  URL: https://www.semanticscholar.org/paper/52f0a2d68c39342230be7c9ab46dea71738949a9
	  Citations: 143 | Authors: Nitin Rathi, K. Roy | Date: 2020-08-09
2025-11-16 19:45:50,637 - INFO - root - 正在下载: https://www.frontiersin.org/articles/10.3389/fnins.2022.1079357/pdf
2025-11-16 19:45:54,104 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\SNN\STSC-SNN_ Spatio-Temporal Synaptic Connection with temporal convolution and attention for spiking ne.pdf
2025-11-16 19:45:54,105 - INFO - root - 成功下载 (Semantic Scholar): STSC-SNN: Spatio-Temporal Synaptic Connection with temporal convolution and attention for spiking neural networks
2025-11-16 19:45:54,106 - INFO - root - 正在下载: https://arxiv.org/pdf/2110.11417
2025-11-16 19:46:03,113 - INFO - root - 正在下载: https://arxiv.org/pdf/2110.11417
2025-11-16 19:46:06,148 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\SNN\HIRE-SNN_ Harnessing the Inherent Robustness of Energy-Efficient Deep Spiking Neural Networks by Tra.pdf
2025-11-16 19:46:06,149 - INFO - root - 成功下载 (Semantic Scholar): HIRE-SNN: Harnessing the Inherent Robustness of Energy-Efficient Deep Spiking Neural Networks by Training with Crafted Input Noise
2025-11-16 19:46:06,150 - INFO - root - 正在下载: http://arxiv.org/pdf/2208.12991
2025-11-16 19:46:13,680 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\SNN\Sub-mW Neuromorphic SNN audio processing applications with Rockpool and Xylo.pdf
2025-11-16 19:46:13,682 - INFO - root - 成功下载 (Semantic Scholar): Sub-mW Neuromorphic SNN audio processing applications with Rockpool and Xylo
2025-11-16 19:46:13,682 - INFO - root - 正在下载: https://www.frontiersin.org/articles/10.3389/fnins.2022.815258/pdf
2025-11-16 19:46:20,208 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\SNN\ACE-SNN_ Algorithm-Hardware Co-design of Energy-Efficient & Low-Latency Deep Spiking Neural Networks.pdf
2025-11-16 19:46:20,210 - INFO - root - 成功下载 (Semantic Scholar): ACE-SNN: Algorithm-Hardware Co-design of Energy-Efficient & Low-Latency Deep Spiking Neural Networks for 3D Image Recognition
2025-11-16 19:46:20,210 - WARNING - root - 【手动下载提示】(无PDF): SNN-RAT: Robustness-enhanced Spiking Neural Network through Regularized Adversarial Training
	  URL: https://www.semanticscholar.org/paper/0484f95ef6a6ee544e0a9f9eb5dfe35f7166c09f
	  Citations: 47 | Authors: Jianhao Ding, Tong Bu, Zhaofei Yu, Tiejun Huang, Jian K. Liu | Date: N/A
2025-11-16 19:46:20,211 - WARNING - root - 【手动下载提示】(无PDF): An Energy Efficient STDP-Based SNN Architecture With On-Chip Learning
	  URL: https://www.semanticscholar.org/paper/8060355ba377b32d311ea36c2f61058e62f43d31
	  Citations: 27 | Authors: Congyi Sun, Haohan Sun, Jin Xu, Jianing Han, Xinyuan Wang, Xinyu Wang, Qinyu Chen, Yuxiang Fu, Li Li | Date: 2022-12-01
2025-11-16 19:46:20,212 - WARNING - root - 【手动下载提示】(无PDF): Quantum Tunneling Based Ultra-Compact and Energy Efficient Spiking Neuron Enables Hardware SNN
	  URL: https://www.semanticscholar.org/paper/e493911d6a6b191eb44afd5184a846eb794e667a
	  Citations: 24 | Authors: A. Singh, V. Saraswat, M. Baghini, U. Ganguly | Date: 2022-08-01
2025-11-16 19:46:20,212 - INFO - root - 正在下载: https://www.frontiersin.org/articles/10.3389/fncom.2021.646125/pdf
2025-11-16 19:46:26,386 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\SNN\Spiking Neural Network (SNN) With Memristor Synapses Having Non-linear Weight Update.pdf
2025-11-16 19:46:26,389 - INFO - root - 成功下载 (Semantic Scholar): Spiking Neural Network (SNN) With Memristor Synapses Having Non-linear Weight Update
2025-11-16 19:46:26,391 - INFO - root - 正在下载: http://arxiv.org/pdf/2205.07473
2025-11-16 19:46:30,796 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\SNN\Towards Lossless ANN-SNN Conversion under Ultra-Low Latency with Dual-Phase Optimization.pdf
2025-11-16 19:46:30,798 - INFO - root - 成功下载 (Semantic Scholar): Towards Lossless ANN-SNN Conversion under Ultra-Low Latency with Dual-Phase Optimization
2025-11-16 19:46:30,799 - WARNING - root - 【手动下载提示】(无PDF): Skipper: Enabling efficient SNN training through activation-checkpointing and time-skipping
	  URL: https://www.semanticscholar.org/paper/11ed1db1814d4cc87e5fb416568d063fd8038e7e
	  Citations: 15 | Authors: Sonali Singh, Anup Sarma, Sen Lu, Abhronil Sengupta, M. Kandemir, E. Neftci, N. Vijaykrishnan, C. Das | Date: 2022-10-01
2025-11-16 19:46:30,800 - INFO - root - 正在下载: https://www.frontiersin.org/articles/10.3389/fnsys.2022.838822/pdf
2025-11-16 19:46:35,107 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\SNN\DSNN_ A DenseNet-Based SNN for Explainable Brain Disease Classification.pdf
2025-11-16 19:46:35,110 - INFO - root - 成功下载 (Semantic Scholar): DSNN: A DenseNet-Based SNN for Explainable Brain Disease Classification
2025-11-16 19:46:35,110 - INFO - root - 正在下载: https://repository.tudelft.nl/islandora/object/uuid%3A8fc5e807-1ccd-4593-b017-5c7847ae0cbf/datastream/OBJ/download
2025-11-16 19:46:40,267 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\SNN\Energy-Efficient SNN Implementation Using RRAM-Based Computation In-Memory (CIM).pdf
2025-11-16 19:46:40,269 - INFO - root - 成功下载 (Semantic Scholar): Energy-Efficient SNN Implementation Using RRAM-Based Computation In-Memory (CIM)
2025-11-16 19:46:40,270 - WARNING - root - 【手动下载提示】(无PDF): Ultralow Power Always-On Intelligent and Connected SNN-Based System for Multimedia IoT-Enabled Applications
	  URL: https://www.semanticscholar.org/paper/455244e2498df15682a617f1404fa02e17f61297
	  Citations: 23 | Authors: Qi Liu, Zhixuan Zhang | Date: 2022-09-01
2025-11-16 19:46:40,271 - INFO - root - 正在下载: https://iopscience.iop.org/article/10.1088/2634-4386/ac5ac5/pdf
2025-11-16 19:46:47,509 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\SNN\mlGeNN_ accelerating SNN inference using GPU-enabled neural networks.pdf
2025-11-16 19:46:47,511 - INFO - root - 成功下载 (Semantic Scholar): mlGeNN: accelerating SNN inference using GPU-enabled neural networks
2025-11-16 19:46:47,511 - WARNING - root - 【手动下载提示】(无PDF): Hybrid SNN-ANN: Energy-Efficient Classification and Object Detection for Event-Based Vision
	  URL: https://www.semanticscholar.org/paper/348a2514ef4461385ff8d7c405a5970b36e8c868
	  Citations: 44 | Authors: Alexander Kugele, Thomas Pfeil, Michael Pfeiffer, E. Chicca | Date: 2021-12-06
2025-11-16 19:46:47,511 - WARNING - root - 【手动下载提示】(无PDF): A Neuromorphic Model for Image Recognition using SNN
	  URL: https://www.semanticscholar.org/paper/5a371da4c65a07b57b22e236456ac77a311b0743
	  Citations: 39 | Authors: R. Kabilan, N. Muthukumaran | Date: 2021-01-20
2025-11-16 19:46:47,512 - INFO - root - 正在下载: https://arxiv.org/pdf/2108.00044
2025-11-16 19:46:50,708 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\SNN\Global Λ -hyperon polarization in Au+Au collisions at sNN=3 GeV.pdf
2025-11-16 19:46:50,712 - INFO - root - 成功下载 (Semantic Scholar): Global 
Λ
-hyperon polarization in 
Au+Au
 collisions at 
sNN=3 GeV
2025-11-16 19:46:50,712 - INFO - root - 正在下载: https://doi.org/10.1109/tnnls.2021.3109064
2025-11-16 19:46:55,915 - INFO - root - 正在下载: https://doi.org/10.1109/tnnls.2021.3109064
2025-11-16 19:47:05,527 - INFO - root - 正在下载: https://doi.org/10.1109/tnnls.2021.3109064
2025-11-16 19:47:14,539 - INFO - root - 正在下载: https://doi.org/10.1109/tnnls.2021.3109064
2025-11-16 19:47:23,870 - INFO - root - 正在下载: https://doi.org/10.1109/tnnls.2021.3109064
2025-11-16 19:47:27,115 - WARNING - root - 下载 Comprehensive SNN Compression Using ADMM Optimization and Activity Regularization (https://doi.org/10.1109/tnnls.2021.3109064) 失败: 418 Client Error: Unknown Code for url: https://ieeexplore.ieee.org/document/9597482/
2025-11-16 19:47:27,116 - WARNING - root - 【手动下载提示】(无PDF): Exclusive dimuon production in ultraperipheral Pb + Pb collisions at √ sNN = 5 . 02 TeV with ATLAS
	  URL: https://www.semanticscholar.org/paper/e30f6c9f4b7e176c6b8aac011a1e93ddf5593e3c
	  Citations: 35 | Authors: G. Aad | Date: N/A
2025-11-16 19:47:27,120 - WARNING - root - 【手动下载提示】(无PDF): DCT-SNN: Using DCT to Distribute Spatial Information over Time for Low-Latency Spiking Neural Networks
	  URL: https://www.semanticscholar.org/paper/4ddaa6c0680ea9ecb1509a2561d924a6a4e92fd8
	  Citations: 35 | Authors: Isha Garg, Sayeed Shafayet Chowdhury, Kaushik Roy | Date: 2021-10-01
2025-11-16 19:47:27,123 - INFO - root - 正在下载: https://rss.onlinelibrary.wiley.com/doi/am-pdf/10.1002/aelm.201900060
2025-11-16 19:47:31,780 - INFO - root - 正在下载: https://rss.onlinelibrary.wiley.com/doi/am-pdf/10.1002/aelm.201900060
2025-11-16 19:47:36,269 - INFO - root - 正在下载: https://rss.onlinelibrary.wiley.com/doi/am-pdf/10.1002/aelm.201900060
2025-11-16 19:47:40,967 - INFO - root - 正在下载: https://rss.onlinelibrary.wiley.com/doi/am-pdf/10.1002/aelm.201900060
2025-11-16 19:47:49,505 - INFO - root - 正在下载: https://rss.onlinelibrary.wiley.com/doi/am-pdf/10.1002/aelm.201900060
2025-11-16 19:47:50,120 - WARNING - root - 下载 Artificial Neural Network (ANN) to Spiking Neural Network (SNN) Converters Based on Diffusive Memristors (https://rss.onlinelibrary.wiley.com/doi/am-pdf/10.1002/aelm.201900060) 失败: 403 Client Error: Forbidden for url: https://rss.onlinelibrary.wiley.com/doi/am-pdf/10.1002/aelm.201900060
2025-11-16 19:47:50,127 - INFO - root - 正在下载: https://link.springer.com/content/pdf/10.1007/JHEP05(2018)006.pdf
2025-11-16 19:47:55,433 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\SNN\Jet properties in PbPb and pp collisions at sNN=5.02$$ _sqrt{s_{_mathrm{N}_;_mathrm{N}}}=5.02 $$ TeV.pdf
2025-11-16 19:47:55,434 - INFO - root - 成功下载 (Semantic Scholar): Jet properties in PbPb and pp collisions at sNN=5.02$$ \sqrt{s_{\mathrm{N}\;\mathrm{N}}}=5.02 $$ TeV
2025-11-16 19:47:55,435 - INFO - root - 正在下载: https://arxiv.org/pdf/2007.14005
2025-11-16 19:47:56,633 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\SNN\Flow and interferometry results from Au+Au collisions at sNN=4.5 GeV.pdf
2025-11-16 19:47:56,636 - INFO - root - 成功下载 (Semantic Scholar): Flow and interferometry results from 
Au+Au
 collisions at 
sNN=4.5
 GeV
2025-11-16 19:47:56,637 - INFO - root - 正在下载: http://link.aps.org/pdf/10.1103/PhysRevC.105.014904
2025-11-16 19:48:04,523 - INFO - root - 正在下载: http://link.aps.org/pdf/10.1103/PhysRevC.105.014904
2025-11-16 19:48:14,390 - INFO - root - 正在下载: http://link.aps.org/pdf/10.1103/PhysRevC.105.014904
2025-11-16 19:48:24,277 - INFO - root - 正在下载: http://link.aps.org/pdf/10.1103/PhysRevC.105.014904
2025-11-16 19:48:38,140 - INFO - root - 正在下载: http://link.aps.org/pdf/10.1103/PhysRevC.105.014904
2025-11-16 19:48:41,964 - WARNING - root - 下载 Proton number cumulants and correlation functions in Au-Au collisions at 
sNN=7.7
–200 GeV from hydrodynamics (http://link.aps.org/pdf/10.1103/PhysRevC.105.014904) 失败: 403 Client Error: Forbidden for url: https://journals.aps.org/prc/pdf/10.1103/PhysRevC.105.014904
2025-11-16 19:48:41,967 - INFO - root - 正在下载: https://doi.org/10.1109/tcsii.2021.3090422
2025-11-16 19:48:47,373 - INFO - root - 正在下载: https://doi.org/10.1109/tcsii.2021.3090422
2025-11-16 19:48:52,512 - INFO - root - 正在下载: https://doi.org/10.1109/tcsii.2021.3090422
2025-11-16 19:48:54,525 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\SNN\Balancing the Cost and Performance Trade-Offs in SNN Processors.pdf
2025-11-16 19:48:54,527 - INFO - root - 成功下载 (Semantic Scholar): Balancing the Cost and Performance Trade-Offs in SNN Processors
2025-11-16 19:48:54,527 - WARNING - root - 【手动下载提示】(无PDF): A review of SNN implementation on FPGA
	  URL: https://www.semanticscholar.org/paper/6c1bd9d3a05d9a333a23d72ca09067866c06d925
	  Citations: 24 | Authors: Quoc Trung Pham, Thu Quyen Nguyen, Chi Hoang-Phuong, Quang Hieu Dang, Duc Minh Nguyen, Hoang Nguyen-Huy | Date: 2021-10-01
2025-11-16 19:48:54,529 - INFO - root - 正在下载: https://link.aps.org/accepted/10.1103/PhysRevC.98.014910
2025-11-16 19:48:57,051 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\SNN\Global polarization of Λ hyperons in Au + Au collisions at sNN=200 GeV.pdf
2025-11-16 19:48:57,053 - INFO - root - 成功下载 (Semantic Scholar): Global polarization of 
Λ
 hyperons in Au + Au collisions at 
sNN=200
 GeV
2025-11-16 19:48:57,054 - WARNING - root - 【手动下载提示】(无PDF): A 28nm Configurable Asynchronous SNN Accelerator with Energy-Efficient Learning
	  URL: https://www.semanticscholar.org/paper/723718b9a9152a04c4378d346a700384ed374d2f
	  Citations: 16 | Authors: Jilin Zhang, Mingxuan Liang, Jinsong Wei, Shaojun Wei, Hong Chen | Date: 2021-09-01
2025-11-16 19:48:57,056 - INFO - root - 正在下载: http://link.aps.org/pdf/10.1103/PhysRevC.101.034911
2025-11-16 19:49:11,467 - INFO - root - 正在下载: http://link.aps.org/pdf/10.1103/PhysRevC.101.034911
2025-11-16 19:49:21,271 - INFO - root - 正在下载: http://link.aps.org/pdf/10.1103/PhysRevC.101.034911
2025-11-16 19:49:32,284 - INFO - root - 正在下载: http://link.aps.org/pdf/10.1103/PhysRevC.101.034911
2025-11-16 19:49:44,321 - INFO - root - 正在下载: http://link.aps.org/pdf/10.1103/PhysRevC.101.034911
2025-11-16 19:49:46,908 - WARNING - root - 下载 Measurements of inclusive jet spectra in pp and central Pb-Pb collisions at sNN =5.02 TeV (http://link.aps.org/pdf/10.1103/PhysRevC.101.034911) 失败: 403 Client Error: Forbidden for url: https://journals.aps.org/prc/pdf/10.1103/PhysRevC.101.034911
2025-11-16 19:49:46,911 - INFO - root - 正在下载: http://link.aps.org/pdf/10.1103/PhysRevC.101.044907
2025-11-16 19:49:53,689 - INFO - root - 正在下载: http://link.aps.org/pdf/10.1103/PhysRevC.101.044907
2025-11-16 19:50:02,723 - INFO - root - 正在下载: http://link.aps.org/pdf/10.1103/PhysRevC.101.044907
2025-11-16 19:50:09,144 - INFO - root - 正在下载: http://link.aps.org/pdf/10.1103/PhysRevC.101.044907
2025-11-16 19:50:19,525 - INFO - root - 正在下载: http://link.aps.org/pdf/10.1103/PhysRevC.101.044907
2025-11-16 19:50:25,333 - WARNING - root - 下载 Production of charged pions, kaons, and (anti-)protons in Pb-Pb and inelastic pp collisions at √sNN = 5.02 TeV (http://link.aps.org/pdf/10.1103/PhysRevC.101.044907) 失败: HTTPSConnectionPool(host='link.aps.org', port=443): Max retries exceeded with url: /pdf/10.1103/PhysRevC.101.044907 (Caused by SSLError(SSLEOFError(8, '[SSL: UNEXPECTED_EOF_WHILE_READING] EOF occurred in violation of protocol (_ssl.c:1010)')))
2025-11-16 19:50:25,334 - WARNING - root - 【手动下载提示】(无PDF): Gesture-SNN: Co-optimizing accuracy, latency and energy of SNNs for neuromorphic vision sensors
	  URL: https://www.semanticscholar.org/paper/d1fe42e0adba986368470b42dc4927f687232225
	  Citations: 14 | Authors: Sonali Singh, Anup Sarma, Sen Lu, Abhronil Sengupta, N. Vijaykrishnan, C. Das | Date: 2021-07-26
2025-11-16 19:50:25,336 - INFO - root - 正在下载: https://arxiv.org/pdf/2109.00533
2025-11-16 19:50:26,829 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\SNN\R-SNN_ An Analysis and Design Methodology for Robustifying Spiking Neural Networks against Adversari.pdf
2025-11-16 19:50:26,832 - INFO - root - 成功下载 (Semantic Scholar): R-SNN: An Analysis and Design Methodology for Robustifying Spiking Neural Networks against Adversarial Attacks through Noise Filters for Dynamic Vision Sensors
2025-11-16 19:50:26,832 - WARNING - root - 【手动下载提示】(无PDF): CORDIC-SNN: On-FPGA STDP Learning With Izhikevich Neurons
	  URL: https://www.semanticscholar.org/paper/2f887f267cd5bdc7e04ef363ccfb2bac0db7128d
	  Citations: 108 | Authors: Moslem Heidarpur, A. Ahmadi, M. Ahmadi, Mostafa Rahimi Azghadi | Date: 2019-03-05
2025-11-16 19:50:26,832 - INFO - root - 正在下载: http://arxiv.org/pdf/1906.03732
2025-11-16 19:50:28,577 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\SNN\Strange hadron production in Au+Au collisions at sNN =7.7, 11.5, 19.6, 27, and 39 GeV.pdf
2025-11-16 19:50:28,579 - INFO - root - 成功下载 (Semantic Scholar): Strange hadron production in Au+Au collisions at sNN =7.7, 11.5, 19.6, 27, and 39 GeV
2025-11-16 19:50:28,580 - INFO - root - 正在下载: https://arxiv.org/pdf/2008.04509
2025-11-16 19:50:29,503 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\SNN\TCL_ an ANN-to-SNN Conversion with Trainable Clipping Layers.pdf
2025-11-16 19:50:29,504 - INFO - root - 成功下载 (Semantic Scholar): TCL: an ANN-to-SNN Conversion with Trainable Clipping Layers
2025-11-16 19:50:29,505 - INFO - root - 正在下载: https://doi.org/10.1016/j.physletb.2019.01.055
2025-11-16 19:50:32,944 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\SNN\The proton–Ω correlation function in Au + Au collisions at sNN=200GeV.pdf
2025-11-16 19:50:32,947 - INFO - root - 成功下载 (Semantic Scholar): The proton–Ω correlation function in Au + Au collisions at sNN=200GeV
2025-11-16 19:50:32,947 - WARNING - root - 【手动下载提示】(无PDF): Verification of genuine and forged offline signatures using Siamese Neural Network (SNN)
	  URL: https://www.semanticscholar.org/paper/af598beb133584c4f84f47856535d577919701b2
	  Citations: 50 | Authors: A. Jagtap, Dattatray D. Sawat, Rajendra S. Hegadi, R. Hegadi | Date: 2020-04-02
2025-11-16 19:50:32,948 - INFO - root - 正在下载: https://link.springer.com/content/pdf/10.1007%2FJHEP04%282017%29039.pdf
2025-11-16 19:50:39,898 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\SNN\Charged-particle nuclear modification factors in PbPb and pPb collisions at sNN=5.02$$ _sqrt{s_{_mat.pdf
2025-11-16 19:50:39,899 - INFO - root - 成功下载 (Semantic Scholar): Charged-particle nuclear modification factors in PbPb and pPb collisions at sNN=5.02$$ \sqrt{s_{\mathrm{N}\;\mathrm{N}}}=5.02 $$ TeV
2025-11-16 19:50:39,901 - INFO - root - 正在下载: https://doi.org/10.1016/j.physletb.2019.01.006
2025-11-16 19:50:42,250 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\SNN\Measurement of nuclear modification factors of ϒ(1S), ϒ(2S), and ϒ(3S) mesons in PbPb collisions at.pdf
2025-11-16 19:50:42,252 - INFO - root - 成功下载 (Semantic Scholar): Measurement of nuclear modification factors of ϒ(1S), ϒ(2S), and ϒ(3S) mesons in PbPb collisions at sNN=5.02 TeV
2025-11-16 19:50:42,254 - INFO - root - 正在下载: http://link.aps.org/pdf/10.1103/PhysRevC.101.024906
2025-11-16 19:50:53,300 - INFO - root - 正在下载: http://link.aps.org/pdf/10.1103/PhysRevC.101.024906
2025-11-16 19:51:06,769 - INFO - root - 正在下载: http://link.aps.org/pdf/10.1103/PhysRevC.101.024906
2025-11-16 19:51:13,313 - INFO - root - 正在下载: http://link.aps.org/pdf/10.1103/PhysRevC.101.024906
2025-11-16 19:51:26,322 - INFO - root - 正在下载: http://link.aps.org/pdf/10.1103/PhysRevC.101.024906
2025-11-16 19:51:28,719 - WARNING - root - 下载 Measurement of the azimuthal anisotropy of charged-particle production in Xe+Xe collisions at √sNN =5.44 TeV with the ATLAS detector (http://link.aps.org/pdf/10.1103/PhysRevC.101.024906) 失败: 403 Client Error: Forbidden for url: https://journals.aps.org/prc/pdf/10.1103/PhysRevC.101.024906
2025-11-16 19:51:28,721 - INFO - root - 正在下载: https://link.springer.com/content/pdf/10.1007/JHEP04(2018)108.pdf
2025-11-16 19:51:34,025 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\SNN\Λ c + production in pp collisions at √s=7 TeV and in p-Pb collisions at √sNN=5.02 TeV.pdf
2025-11-16 19:51:34,027 - INFO - root - 成功下载 (Semantic Scholar): Λ c + production in pp collisions at √s=7 TeV and in p-Pb collisions at √sNN=5.02 TeV
2025-11-16 19:51:34,027 - INFO - root - 正在下载: https://www.nature.com/articles/s41598-021-85827-w.pdf
2025-11-16 19:51:40,165 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\SNN\A spiking neural network (SNN) for detecting high frequency oscillations (HFOs) in the intraoperativ.pdf
2025-11-16 19:51:40,166 - INFO - root - 成功下载 (Semantic Scholar): A spiking neural network (SNN) for detecting high frequency oscillations (HFOs) in the intraoperative ECoG
2025-11-16 19:51:40,167 - WARNING - root - 【手动下载提示】(无PDF): Capacitor-less Stochastic Leaky-FeFET Neuron of Both Excitatory and Inhibitory Connections for SNN with Reduced Hardware Cost
	  URL: https://www.semanticscholar.org/paper/44984eb2f7563d6823ebe161a451d7a1ad3a0a6b
	  Citations: 43 | Authors: Jin Luo, Si Wu, Qianqian Huang, Ru Huang, Liutao Yu, Tianyi Liu, Mengxuan Yang, Zhiyuan Fu, Zhongxin Liang, Liang Chen, Cheng Chen, Shuhan Liu | Date: 2019-12-01
2025-11-16 19:51:40,168 - INFO - root - 正在下载: http://link.aps.org/pdf/10.1103/PhysRevC.101.014912
2025-11-16 19:51:48,374 - INFO - root - 正在下载: http://link.aps.org/pdf/10.1103/PhysRevC.101.014912
2025-11-16 19:51:59,396 - INFO - root - 正在下载: http://link.aps.org/pdf/10.1103/PhysRevC.101.014912
2025-11-16 19:52:05,979 - INFO - root - 正在下载: http://link.aps.org/pdf/10.1103/PhysRevC.101.014912
2025-11-16 19:52:18,994 - INFO - root - 正在下载: http://link.aps.org/pdf/10.1103/PhysRevC.101.014912
2025-11-16 19:52:24,810 - WARNING - root - 下载 Multiparticle correlation studies in pPb collisions at sNN =8.16 TeV (http://link.aps.org/pdf/10.1103/PhysRevC.101.014912) 失败: HTTPSConnectionPool(host='link.aps.org', port=443): Max retries exceeded with url: /pdf/10.1103/PhysRevC.101.014912 (Caused by SSLError(SSLEOFError(8, '[SSL: UNEXPECTED_EOF_WHILE_READING] EOF occurred in violation of protocol (_ssl.c:1010)')))
2025-11-16 19:52:24,812 - WARNING - root - 【手动下载提示】(无PDF): DCT-SNN: Using DCT to Distribute Spatial Information over Time for Learning Low-Latency Spiking Neural Networks
	  URL: https://www.semanticscholar.org/paper/717581f2337015907f30729915ab17f236e74c44
	  Citations: 14 | Authors: Isha Garg, Sayeed Shafayet Chowdhury, K. Roy | Date: 2020-10-05
2025-11-16 19:52:24,814 - INFO - root - 正在下载: https://doi.org/10.1016/j.physletb.2016.12.064
2025-11-16 19:52:29,362 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\SNN\J_ψ suppression at forward rapidity in Pb–Pb collisions at √sNN = 5.02 TeV.pdf
2025-11-16 19:52:29,366 - INFO - root - 成功下载 (Semantic Scholar): J/ψ suppression at forward rapidity in Pb–Pb collisions at √sNN = 5.02 TeV
2025-11-16 19:52:29,367 - INFO - root - 正在下载: https://link.springer.com/content/pdf/10.1007/JHEP07(2018)103.pdf
2025-11-16 19:52:33,027 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\SNN\Energy dependence and fluctuations of anisotropic flow in Pb-Pb collisions at √sNN = 5.02 and 2.76 T.pdf
2025-11-16 19:52:33,029 - INFO - root - 成功下载 (Semantic Scholar): Energy dependence and fluctuations of anisotropic flow in Pb-Pb collisions at √sNN = 5.02 and 2.76 TeV
2025-11-16 19:52:33,030 - INFO - root - 正在下载: https://link.springer.com/content/pdf/10.1007%2FJHEP09%282016%29028.pdf
2025-11-16 19:52:38,078 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\SNN\Elliptic flow of electrons from heavy-flavour hadron decays at mid-rapidity in Pb-Pb collisions at √.pdf
2025-11-16 19:52:38,082 - INFO - root - 成功下载 (Semantic Scholar): Elliptic flow of electrons from heavy-flavour hadron decays at mid-rapidity in Pb-Pb collisions at √sNN=2.76 TeV
2025-11-16 19:52:38,082 - WARNING - root - 【手动下载提示】(无PDF): Spike Counts Based Low Complexity SNN Architecture With Binary Synapse
	  URL: https://www.semanticscholar.org/paper/5ac9e1cf6a6250c7946f34ba79a09a95a0d754d1
	  Citations: 31 | Authors: Hoyoung Tang, Heetak Kim, Hyeonseong Kim, Jongsun Park | Date: 2019-10-04
2025-11-16 19:52:38,082 - WARNING - root - 【手动下载提示】(无PDF): An Asynchronous Reconfigurable SNN Accelerator With Event-Driven Time Step Update
	  URL: https://www.semanticscholar.org/paper/44b98ef2cacec788be5ce27d8c15fcf476cb95c8
	  Citations: 25 | Authors: Jilin Zhang, Hui Wu, Jinsong Wei, Shaojun Wei, Hong Chen | Date: 2019-11-01
2025-11-16 19:52:38,084 - INFO - root - 正在下载: http://link.aps.org/pdf/10.1103/PhysRevC.93.034913
2025-11-16 19:52:44,935 - INFO - root - 正在下载: http://link.aps.org/pdf/10.1103/PhysRevC.93.034913
2025-11-16 19:52:52,634 - INFO - root - 正在下载: http://link.aps.org/pdf/10.1103/PhysRevC.93.034913
2025-11-16 19:52:59,732 - INFO - root - 正在下载: http://link.aps.org/pdf/10.1103/PhysRevC.93.034913
2025-11-16 19:53:13,839 - INFO - root - 正在下载: http://link.aps.org/pdf/10.1103/PhysRevC.93.034913
2025-11-16 19:53:18,846 - WARNING - root - 下载 Centrality dependence of the nuclear modification factor of charged pions, kaons, and protons in Pb-Pb collisions at √sNN=2.76 TeV (http://link.aps.org/pdf/10.1103/PhysRevC.93.034913) 失败: 502 Server Error: Bad Gateway for url: http://link.aps.org/pdf/10.1103/PhysRevC.93.034913
2025-11-16 19:53:18,847 - INFO - root - 正在下载: https://mediatum.ub.tum.de/doc/1480838/document.pdf
2025-11-16 19:53:21,068 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\SNN\End to End Learning of a Multi-Layered Snn Based on R-Stdp for a Target Tracking Snake-Like Robot.pdf
2025-11-16 19:53:21,072 - INFO - root - 成功下载 (Semantic Scholar): End to End Learning of a Multi-Layered Snn Based on R-Stdp for a Target Tracking Snake-Like Robot
2025-11-16 19:53:21,076 - INFO - root - 正在下载: https://link.springer.com/content/pdf/10.1007%2FJHEP03%282016%29082.pdf
2025-11-16 19:53:30,101 - INFO - root - 正在下载: https://link.springer.com/content/pdf/10.1007%2FJHEP03%282016%29082.pdf
2025-11-16 19:53:35,472 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\SNN\Measurement of Ds+ production and nuclear modification factor in Pb-Pb collisions at sNN=2.76$$ _sqr.pdf
2025-11-16 19:53:35,473 - INFO - root - 成功下载 (Semantic Scholar): Measurement of Ds+ production and nuclear modification factor in Pb-Pb collisions at sNN=2.76$$ \sqrt{{\mathrm{s}}_{\mathrm{NN}}}=2.76 $$ TeV
2025-11-16 19:53:35,473 - WARNING - root - 【手动下载提示】(无PDF): A Systolic SNN Inference Accelerator and its Co-optimized Software Framework
	  URL: https://www.semanticscholar.org/paper/398af680f3732e269cd11d0a1a4a76bd95d64600
	  Citations: 22 | Authors: Shasha Guo, Lei Wang, Shuquan Wang, Yu Deng, Zhijie Yang, Shiming Li, Zhige Xie, Q. Dou | Date: 2019-05-13
2025-11-16 19:53:35,473 - WARNING - root - 【手动下载提示】(无PDF): MocapNET: Ensemble of SNN Encoders for 3D Human Pose Estimation in RGB Images
	  URL: https://www.semanticscholar.org/paper/cacecd8b61d128fe36a582ecb838d3d4628d4041
	  Citations: 20 | Authors: Ammar Qammaz, Antonis A. Argyros | Date: N/A
2025-11-16 19:53:35,474 - INFO - root - 正在下载: https://doi.org/10.1016/j.physletb.2018.05.074
2025-11-16 19:53:37,640 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\SNN\Nuclear modification factor of D0 mesons in PbPb collisions at sNN=5.02TeV.pdf
2025-11-16 19:53:37,643 - INFO - root - 成功下载 (Semantic Scholar): Nuclear modification factor of D0 mesons in PbPb collisions at sNN=5.02TeV
2025-11-16 19:53:37,643 - WARNING - root - 【手动下载提示】(无PDF): Evolution of atomic structures of SnN, SnN -, and SnNCl- clusters (N = 4-20): Insight from ab initio calculations.
	  URL: https://www.semanticscholar.org/paper/e0d0f06ebaf7a948ecbc092c459a19db7fa266ed
	  Citations: 19 | Authors: Di Wu, Qiuying Du, Xue Wu, Ruili Shi, Linwei Sai, Xiaoqing Liang, Xiaoming Huang, Jijun Zhao | Date: 2019-05-07
2025-11-16 19:53:37,643 - WARNING - root - 【手动下载提示】(无PDF): Homeostasis-Based CNN-to-SNN Conversion of Inception and Residual Architectures
	  URL: https://www.semanticscholar.org/paper/fb8d2bc8b2a753c12e59c6c2d527e5c43222437e
	  Citations: 17 | Authors: Fu Xing, Ye Yuan, H. Huo, T. Fang | Date: 2019-12-12
2025-11-16 19:53:37,644 - INFO - root - 正在下载: https://www.frontiersin.org/articles/10.3389/fnbot.2019.00018/pdf
2025-11-16 19:53:41,108 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\SNN\Supervised Learning in SNN via Reward-Modulated Spike-Timing-Dependent Plasticity for a Target Reach.pdf
2025-11-16 19:53:41,110 - INFO - root - 成功下载 (Semantic Scholar): Supervised Learning in SNN via Reward-Modulated Spike-Timing-Dependent Plasticity for a Target Reaching Vehicle
2025-11-16 19:53:41,110 - WARNING - root - 【手动下载提示】(无PDF): Constraints on jet quenching in p–Pb collisions at √sNN=5.02 TeV measured by the event-activity dependence of semi-inclusive hadron-jet distributions
	  URL: https://www.semanticscholar.org/paper/3b19e22a5ada0ef569a00ffb67249f3f620e2f56
	  Citations: 39 | Authors: R. Lávička, R. Lea, L. Leardini, S. Lee, F. Lehas, S. Lehner, J. Lehrbach, R. Lemmon, E. Leogrande, I. Monzón, P. Lévai, X. Li, X. Li, J. Lien, R. Lietava, B. Lim, S. Lindal, V. Lindenstruth, S. Lindsay, C. Lippmann, M. Lisa, V. Litichevskyi, A. Liu, W. Llope, D. F. Lodato, P. Loenne, V. Loginov, C. Loizides, P. Loncar, X. Lopez, E. L. Torres, A. Lowe, P. Luettig, J. R. Luhder, M. Lunardon, G. Luparello, M. Lupi, T. H. Lutz, A. Maevskaya, M. Mager, S. Mahmood, A. Maire, R. Majka, M. Malaev, L. Malinina, D. Mal’Kevich, P. Malzacher, A. Mamonov, V. Manko, F. Manso, V. Manzari, Y. Mao, M. Marchisone, J. Mareš, G. Margagliotti, A. Margotti, J. Margutti, A. Marín, C. Markert, M. Marquard, N. Martin, P. Martinengo, J. Martinez, M. Martínez, G. García, M. M. Pedreira, S. Masciocchi, M. Masera, A. Masoni, L. Massacrier, E. Masson, A. Mastroserio, A. Mathis, P. Matuoka, A. Matyja, C. Mayer, J. Mazer, M. Mazzilli, M. Mazzoni, F. Meddi, Y. Melikyan, A. Menchaca-Rocha, E. Meninno, J. M. Pérez, M. Meres, S. Mhlanga, Y. Miake, M. Mieskolainen, D. Mihaylov, K. Mikhaylov, A. Mischke, A. N. Mishra, D. Miśkowiec, J. Mitra, C. Mitu, N. Mohammadi, A. Mohanty, B. Mohanty, M. M. Khan, D. Godoy, L. Moreno, S. Moretto, A. Morreale, A. Morsch, V. Muccifora, E. Mudnić, D. Mühlheim, S. Muhuri, M. Mukherjee, J. Mulligan, M. Munhoz, K. Münning, M. Munoz, R. Munzer, H. Murakami, S. Murray, L. Musa, J. Musinsky, C. Myers, J. Myrcha, B. Naik, R. Nair, B. Nandi, R. Nania, E. Nappi, A. Narayan, M. U. Naru, H. N. Luz, C. Nattrass, S. R. Navarro, K. Nayak, R. Nayak, T. Nayak, S. Nazarenko, R. A. Oliveira, L. Nellen, S. V. Nesbø, G. Neskovic, F. Ng, M. Nicassio, M. Niculescu, J. Niedziela, B. Nielsen, S. Nikolaev, S. Nikulin, V. Nikulin, A. Nobuhiro, F. Noferini, P. Nomokonov, G. Nooren, J. Noris, J. Norman, A. Nyanin, J. Nystrand, H. Oeschler, H. Oh, A. Ohlson, L. Oláh, J. Oleniacz, A. C. O. D. Silva, M. Oliver, J. Onderwaater, C. Oppedisano, R. Orava, M. Oravec, A. O. Velasquez, A. Oskarsson, J. Otwinowski, K. Oyama, Y. Pachmayer, V. Pacik, D. Pagano, G. Paic, P. Palni, J. Pan, A. Pandey, S. Panebianco, V. Papikyan, P. Pareek, J. Park, S. Parmar, A. Passfeld, S. Pathak, R. N. Patra, B. Paul, H. Pei, T. Peitzmann, X. Peng, L. G. Pereira, H. P. D. Costa, D. Peresunko, E. P. Lezama, V. Peskov, Y. Pestov, V. Petráček, M. Petrovici, C. Petta, R. P. Pezzi, S. Piano, M. Pikna, P. Pillot, L. Pimentel, O. Pinazza, L. Pinsky, D. Piyarathna, M. Płoskoń, M. Planinić, F. Pliquett, J. Pluta, S. Pochybova, P. Podesta-Lerma, M. Poghosyan, B. Polichtchouk, N. Poljak, W. Poonsawat, A. Pop, H. Poppenborg, S. Porteboeuf-Houssais, V. Pozdniakov, S. Prasad, R. Preghenella, F. Prino, C. Pruneau, I. Pshenichnov, M. Puccio, V. Punin, J. Putschke, S. Raha, S. Rajput, J. Rak, A. Rakotozafindrabe, L. Ramello, F. Rami, D. B. Rana, R. Raniwala, S. Raniwala, S. Räsänen, B. T. Rascanu, D. Rathee, V. Ratza, I. Ravasenga, K. Read, K. Redlich, A. Rehman, P. Reichelt, F. Reidt, X. Ren, R. Renfordt, A. Reshetin, K. Reygers, V. Riabov, T. Richert, M. Richter, P. Riedler, W. Riegler, F. Riggi, C. Ristea, M. R. Cahuantzi, K. Røed, R. Rogalev, E. Rogochaya, D. Rohr, D. Röhrich, P. Rokita, F. Ronchetti, E. Rosas, K. Rosłon, P. Rosnet, A. Rossi, A. Rotondi, F. Roukoutakis, C. Roy, P. Roy, O. V. Rueda, R. Rui, B. Rumyantsev, A. Rustamov, E. Ryabinkin, Y. Ryabov, A. Rybicki, S. Saarinen, S. Sadhu, S. Sadovsky, K. Šafařík, S. Saha, B. Sahoo, P. Sahoo, R. Sahoo, S. Sahoo, P. Sahu, J. Saini, S. Sakai, M. Saleh, J. Salzwedel, S. Sambyal, V. Samsonov, A. Sandoval, A. Sarkar, D. Sarkar, N. Sarkar, P. Sarma, E. Scapparone, F. Scarlassara, B. Schaefer, H. S. Scheid, C. Schiaua, R. Schicker, C. Schmidt, H. Schmidt, M. Schmidt, M. Schmidt, N. Schmidt, J. Schukraft, Y. Schutz, K. Schwarz, K. Schweda, G. Scioli, E. Scomparin, M. Šefčík, J. Seger, Y. Sekiguchi, D. Sekihata, I. Selyuzhenkov, K. Senosi, S. Senyukov, E. Serradilla, P. Sett, A. Sevcenco, A. Shabanov, A. Shabetai, R. Shahoyan, W. Shaikh, A. Shangaraev, A. Sharma, M. Sharma, N. Sharma, A. I. Sheikh, K. Shigaki, M. Shimomura | Date: N/A
2025-11-16 19:53:41,112 - INFO - root - 正在下载: https://doi.org/10.1007/jhep06(2016)050
2025-11-16 19:53:46,654 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\SNN\Centrality dependence of ψ(2S) suppression in p-Pb collisions at √sNN = 5.02 TeV.pdf
2025-11-16 19:53:46,656 - INFO - root - 成功下载 (Semantic Scholar): Centrality dependence of ψ(2S) suppression in p-Pb collisions at √sNN = 5.02 TeV
2025-11-16 19:53:46,657 - INFO - root - 正在下载: http://ijeecs.iaescore.com/index.php/IJEECS/article/download/19876/12905
2025-11-16 19:53:53,299 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\SNN\A review on data clustering using spiking neural network (SNN) models.pdf
2025-11-16 19:53:53,301 - INFO - root - 成功下载 (Semantic Scholar): A review on data clustering using spiking neural network (SNN) models
2025-11-16 19:53:53,302 - WARNING - root - 【手动下载提示】(无PDF): Measurement of Antiproton Production in p−He Collisions at √sNN=110 GeV
	  URL: https://www.semanticscholar.org/paper/0c656868d7ac176aa5c717aab938585619a10fc2
	  Citations: 53 | Authors: R. Aaij, B. Adeva, M. Adinolfi, Z. Ajaltouni, S. Akar, Johannes Albrecht, Federico Alessio, L. Dufour, M. Mulder, C. Onderwater, A. Pellegrino, S. Tolk, M. Veghel | Date: 2018-11-29
2025-11-16 19:53:53,308 - INFO - root - 正在下载: https://link.springer.com/content/pdf/10.1007/JHEP10(2018)138.pdf
2025-11-16 19:54:00,073 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\SNN\Charged-particle nuclear modification factors in XeXe collisions at sNN=5.44$$ _sqrt{s_{_mathrm{NN}}.pdf
2025-11-16 19:54:00,076 - INFO - root - 成功下载 (Semantic Scholar): Charged-particle nuclear modification factors in XeXe collisions at sNN=5.44$$ \sqrt{s_{\mathrm{NN}}} = 5.44 $$ TeV
2025-11-16 19:54:00,077 - INFO - root - 正在下载: https://arxiv.org/pdf/1908.03585
2025-11-16 19:54:05,305 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\SNN\Bulk properties of the system formed in Au+Au collisions at sNN =14.5 GeV at the BNL STAR detector.pdf
2025-11-16 19:54:05,307 - INFO - root - 成功下载 (Semantic Scholar): Bulk properties of the system formed in Au+Au collisions at sNN =14.5 GeV at the BNL STAR detector
2025-11-16 19:54:05,308 - INFO - root - 正在下载: https://link.springer.com/content/pdf/10.1007%2FJHEP11%282016%29055.pdf
2025-11-16 19:54:17,856 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\SNN\Decomposing transverse momentum balance contributions for quenched jets in PbPb collisions at sNN=2..pdf
2025-11-16 19:54:17,857 - INFO - root - 成功下载 (Semantic Scholar): Decomposing transverse momentum balance contributions for quenched jets in PbPb collisions at sNN=2.76$$ \sqrt{s_{\mathrm{N}\;\mathrm{N}}}=2.76 $$ TeV
2025-11-16 19:54:17,857 - WARNING - root - 【手动下载提示】(无PDF): Anisotropic flow of identified particles in Pb-Pb collisions at sNN=5.02 TeV
	  URL: https://www.semanticscholar.org/paper/5e8b447168f53e5a54bbcf884dc6e9bfd9628f5d
	  Citations: 55 | Authors: R. Rogalev, E. Rogochaya, D. Rohr, A. Rossi, A. Rotondi, F. Roukoutakis, C. Roy, B. Rumyantsev, S. Sadovsky, K. Šafařík, B. Sahoo, P. Sahoo, R. Sahoo, A. Sandoval, M. Schmidt, N. Schmidt, J. Schukraft, Y. Schutz, K. Schwarz, K. Schweda, G. Scioli, M. Šefčík, Y. Sekiguchi, D. Sekihata, K. Senosi, S. Senyukov, A. Sevcenco, A. Shabanov, A. Sharma, M. Sharma, K. Shtejer, Y. Sibiriak, T. Siemiarczuk, G. Simatović, G. Simonetti, R. Singaraju, R. Singh, V. Singhal, M. Sitta, N. Smirnov, J. Song, F. Soramel, S. Sorensen, F. Sozzi, J. Stachel, P. Stankus, P. Strmen, T. Sugitate, C. Suire, M. Suleymanov, M. Šuljić, K. Suzuki, S. Swain, A. Szabo, J. Takahashi, N. Tanaka, M. Tarhini, M. Tariq, A. Tauro, G. T. Muñoz, A. Telesca, C. Terrevoli, D. Thakur, S. Thakur, S. Tripathy, G. Trombetta, L. Tropp, V. Trubnikov, A. Tumkin, R. Turrisi, K. Ullaland, A. Utrobicic, J. W. Van, Hoorne, A. Vargas, M. Vargyas, R. Varma, M. Vasileiou, A. Vasiliev, A. Vauthier, V. Vechernin, A. Veen, E. Vercellin, J. Viinikainen, A. Vodopyanov, K. Voloshin, S. Voloshin, G. Volpe, J. Vrláková, B. Wagner, A. Wegrzynek, S. Wenzel, J. Wiechula, J. Wikne, G. Wilk, J. Wilkinson, E. Willsher, B. Windelband, W. Witt, R. Xu, S. Yalcin, K. Yamakawa, S. Yano, H. Yokoyama, V. Yurchenko, V. Zaccolo, A. Zaman, C. Zampolli, N. Zardoshti, A. Zarochentsev, P. Zavada, N. Zaviyalov, H. Zbroszczyk, M. Zhalov, X. Zhang, Y. Zhang, Z. Zhang, C. Zhao, V. Zherebchevskii, N. Zhigareva, D. Zhou, Y. Zhou, Z. Zhou, H. Zhu, J. Zhu, Y. Zhu, A. Zichichi, G. Zinovjev, J. Zmeskal, S. Zou | Date: N/A
2025-11-16 19:54:17,858 - INFO - root - 正在下载: https://doi.org/10.1016/j.nuclphysa.2017.12.004
2025-11-16 19:54:27,505 - INFO - root - 正在下载: https://doi.org/10.1016/j.nuclphysa.2017.12.004
2025-11-16 19:54:29,685 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\SNN\Production of 4He and 4He in Pb–Pb collisions at √sNN = 2.76 TeV at the LHC..pdf
2025-11-16 19:54:29,687 - INFO - root - 成功下载 (Semantic Scholar): Production of 4He and 4He in Pb–Pb collisions at √sNN = 2.76 TeV at the LHC.
2025-11-16 19:54:29,687 - INFO - root - 检索到 100 篇论文（包括待手动下载的），开始总结...
2025-11-16 19:54:29,690 - INFO - root - --- 开始论文总结阶段 ---
2025-11-16 19:54:29,692 - INFO - root - 正在总结论文 1/100: Optimal ANN-SNN Conversion for High-accuracy and Ultra-low-latency Spiking Neural Networks
2025-11-16 19:54:39,997 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-16 19:55:30,815 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-16 19:56:01,767 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-16 19:56:01,781 - INFO - root - 正在提取论文图片到目录: ./export\SNN\images\Optimal ANN-SNN Conversion for High-accuracy and Ultra-low-latency Spiking Neural Networks
2025-11-16 19:56:02,027 - INFO - root - 已保存图片 1/10：./export\SNN\images\Optimal ANN-SNN Conversion for High-accuracy and Ultra-low-latency Spiking Neural Networks\figure_1_page4.png
2025-11-16 19:56:02,071 - INFO - root - 已保存图片 2/10：./export\SNN\images\Optimal ANN-SNN Conversion for High-accuracy and Ultra-low-latency Spiking Neural Networks\figure_2_page4.png
2025-11-16 19:56:02,129 - INFO - root - 已保存图片 3/10：./export\SNN\images\Optimal ANN-SNN Conversion for High-accuracy and Ultra-low-latency Spiking Neural Networks\figure_3_page4.png
2025-11-16 19:56:02,187 - INFO - root - 已保存图片 4/10：./export\SNN\images\Optimal ANN-SNN Conversion for High-accuracy and Ultra-low-latency Spiking Neural Networks\figure_4_page4.png
2025-11-16 19:56:02,254 - INFO - root - 已保存图片 5/10：./export\SNN\images\Optimal ANN-SNN Conversion for High-accuracy and Ultra-low-latency Spiking Neural Networks\figure_5_page4.png
2025-11-16 19:56:02,305 - INFO - root - 已保存图片 6/10：./export\SNN\images\Optimal ANN-SNN Conversion for High-accuracy and Ultra-low-latency Spiking Neural Networks\figure_6_page4.png
2025-11-16 19:56:02,359 - INFO - root - 已保存图片 7/10：./export\SNN\images\Optimal ANN-SNN Conversion for High-accuracy and Ultra-low-latency Spiking Neural Networks\figure_7_page4.png
2025-11-16 19:56:02,433 - INFO - root - 已保存图片 8/10：./export\SNN\images\Optimal ANN-SNN Conversion for High-accuracy and Ultra-low-latency Spiking Neural Networks\figure_8_page4.png
2025-11-16 19:56:02,510 - INFO - root - 已保存图片 9/10：./export\SNN\images\Optimal ANN-SNN Conversion for High-accuracy and Ultra-low-latency Spiking Neural Networks\figure_9_page4.png
2025-11-16 19:56:02,511 - INFO - root - 成功添加图片 1：./export\SNN\images\Optimal ANN-SNN Conversion for High-accuracy and Ultra-low-latency Spiking Neural Networks\figure_1_page4.png
2025-11-16 19:56:02,511 - INFO - root - 成功添加图片 2：./export\SNN\images\Optimal ANN-SNN Conversion for High-accuracy and Ultra-low-latency Spiking Neural Networks\figure_2_page4.png
2025-11-16 19:56:02,512 - INFO - root - 成功添加图片 3：./export\SNN\images\Optimal ANN-SNN Conversion for High-accuracy and Ultra-low-latency Spiking Neural Networks\figure_3_page4.png
2025-11-16 19:56:02,512 - INFO - root - 成功添加图片 4：./export\SNN\images\Optimal ANN-SNN Conversion for High-accuracy and Ultra-low-latency Spiking Neural Networks\figure_4_page4.png
2025-11-16 19:56:02,513 - INFO - root - 成功添加图片 5：./export\SNN\images\Optimal ANN-SNN Conversion for High-accuracy and Ultra-low-latency Spiking Neural Networks\figure_5_page4.png
2025-11-16 19:56:02,513 - INFO - root - 成功添加图片 6：./export\SNN\images\Optimal ANN-SNN Conversion for High-accuracy and Ultra-low-latency Spiking Neural Networks\figure_6_page4.png
2025-11-16 19:56:02,513 - INFO - root - 成功添加图片 7：./export\SNN\images\Optimal ANN-SNN Conversion for High-accuracy and Ultra-low-latency Spiking Neural Networks\figure_7_page4.png
2025-11-16 19:56:02,514 - INFO - root - 成功添加图片 8：./export\SNN\images\Optimal ANN-SNN Conversion for High-accuracy and Ultra-low-latency Spiking Neural Networks\figure_8_page4.png
2025-11-16 19:56:02,514 - INFO - root - 成功添加图片 9：./export\SNN\images\Optimal ANN-SNN Conversion for High-accuracy and Ultra-low-latency Spiking Neural Networks\figure_9_page4.png
2025-11-16 19:56:02,520 - INFO - root - 论文《Optimal ANN-SNN Conversion for High-accuracy and Ultra-low-latency Spiking Neural Networks》的分析已保存到 ./export\SNN\Optimal ANN-SNN Conversion for High-accuracy and Ultra-low-latency Spiking Neural Networks.md
2025-11-16 19:56:02,525 - INFO - root - 跳过总结 (手动下载): Spikformer V2: Join the High Accuracy Club on ImageNet with an SNN Ticket
2025-11-16 19:56:02,525 - INFO - root - 跳过总结 (手动下载): Stellar: Energy-Efficient and Low-Latency SNN Algorithm and Hardware Co-Design with Spatiotemporal Computation
2025-11-16 19:56:02,525 - INFO - root - 跳过总结 (手动下载): EC-SNN: Splitting Deep Spiking Neural Networks for Edge Devices
2025-11-16 19:56:02,525 - INFO - root - 跳过总结 (手动下载): C-DNN: An Energy-Efficient Complementary Deep-Neural-Network Processor With Heterogeneous CNN/SNN Core Architecture
2025-11-16 19:56:02,526 - INFO - root - 跳过总结 (手动下载): SpikeZIP-TF: Conversion is All You Need for Transformer-based SNN
2025-11-16 19:56:02,527 - INFO - root - 正在总结论文 7/100: Fast-SNN: Fast Spiking Neural Network by Converting Quantized ANN
2025-11-16 19:56:14,270 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-16 19:56:14,273 - INFO - root - LLMClient: rate limit reached, sleeping 16.5s
2025-11-16 19:57:26,104 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-16 19:58:00,629 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-16 19:58:00,639 - INFO - root - 正在提取论文图片到目录: ./export\SNN\images\Fast-SNN_ Fast Spiking Neural Network by Converting Quantized ANN
2025-11-16 19:58:00,766 - INFO - root - 已保存图片 1/10：./export\SNN\images\Fast-SNN_ Fast Spiking Neural Network by Converting Quantized ANN\figure_1_page12.jpeg
2025-11-16 19:58:00,790 - INFO - root - 已保存图片 2/10：./export\SNN\images\Fast-SNN_ Fast Spiking Neural Network by Converting Quantized ANN\figure_2_page12.jpeg
2025-11-16 19:58:00,822 - INFO - root - 已保存图片 3/10：./export\SNN\images\Fast-SNN_ Fast Spiking Neural Network by Converting Quantized ANN\figure_3_page12.jpeg
2025-11-16 19:58:00,857 - INFO - root - 已保存图片 4/10：./export\SNN\images\Fast-SNN_ Fast Spiking Neural Network by Converting Quantized ANN\figure_4_page12.jpeg
2025-11-16 19:58:00,879 - INFO - root - 已保存图片 5/10：./export\SNN\images\Fast-SNN_ Fast Spiking Neural Network by Converting Quantized ANN\figure_5_page12.jpeg
2025-11-16 19:58:00,900 - INFO - root - 已保存图片 6/10：./export\SNN\images\Fast-SNN_ Fast Spiking Neural Network by Converting Quantized ANN\figure_6_page12.jpeg
2025-11-16 19:58:00,931 - INFO - root - 已保存图片 7/10：./export\SNN\images\Fast-SNN_ Fast Spiking Neural Network by Converting Quantized ANN\figure_7_page12.jpeg
2025-11-16 19:58:00,955 - INFO - root - 已保存图片 8/10：./export\SNN\images\Fast-SNN_ Fast Spiking Neural Network by Converting Quantized ANN\figure_8_page12.jpeg
2025-11-16 19:58:00,982 - INFO - root - 已保存图片 9/10：./export\SNN\images\Fast-SNN_ Fast Spiking Neural Network by Converting Quantized ANN\figure_9_page12.jpeg
2025-11-16 19:58:01,010 - INFO - root - 已保存图片 10/10：./export\SNN\images\Fast-SNN_ Fast Spiking Neural Network by Converting Quantized ANN\figure_10_page12.jpeg
2025-11-16 19:58:01,012 - INFO - root - 成功添加图片 1：./export\SNN\images\Fast-SNN_ Fast Spiking Neural Network by Converting Quantized ANN\figure_1_page12.jpeg
2025-11-16 19:58:01,013 - INFO - root - 成功添加图片 2：./export\SNN\images\Fast-SNN_ Fast Spiking Neural Network by Converting Quantized ANN\figure_2_page12.jpeg
2025-11-16 19:58:01,013 - INFO - root - 成功添加图片 3：./export\SNN\images\Fast-SNN_ Fast Spiking Neural Network by Converting Quantized ANN\figure_3_page12.jpeg
2025-11-16 19:58:01,013 - INFO - root - 成功添加图片 4：./export\SNN\images\Fast-SNN_ Fast Spiking Neural Network by Converting Quantized ANN\figure_4_page12.jpeg
2025-11-16 19:58:01,013 - INFO - root - 成功添加图片 5：./export\SNN\images\Fast-SNN_ Fast Spiking Neural Network by Converting Quantized ANN\figure_5_page12.jpeg
2025-11-16 19:58:01,014 - INFO - root - 成功添加图片 6：./export\SNN\images\Fast-SNN_ Fast Spiking Neural Network by Converting Quantized ANN\figure_6_page12.jpeg
2025-11-16 19:58:01,014 - INFO - root - 成功添加图片 7：./export\SNN\images\Fast-SNN_ Fast Spiking Neural Network by Converting Quantized ANN\figure_7_page12.jpeg
2025-11-16 19:58:01,014 - INFO - root - 成功添加图片 8：./export\SNN\images\Fast-SNN_ Fast Spiking Neural Network by Converting Quantized ANN\figure_8_page12.jpeg
2025-11-16 19:58:01,014 - INFO - root - 成功添加图片 9：./export\SNN\images\Fast-SNN_ Fast Spiking Neural Network by Converting Quantized ANN\figure_9_page12.jpeg
2025-11-16 19:58:01,015 - INFO - root - 成功添加图片 10：./export\SNN\images\Fast-SNN_ Fast Spiking Neural Network by Converting Quantized ANN\figure_10_page12.jpeg
2025-11-16 19:58:01,016 - INFO - root - 论文《Fast-SNN: Fast Spiking Neural Network by Converting Quantized ANN》的分析已保存到 ./export\SNN\Fast-SNN_ Fast Spiking Neural Network by Converting Quantized ANN.md
2025-11-16 19:58:01,023 - INFO - root - 正在总结论文 8/100: Reducing ANN-SNN Conversion Error through Residual Membrane Potential
2025-11-16 19:58:12,955 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-16 19:58:12,959 - INFO - root - LLMClient: rate limit reached, sleeping 13.1s
2025-11-16 19:59:16,720 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-16 19:59:51,476 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-16 19:59:51,484 - INFO - root - 正在提取论文图片到目录: ./export\SNN\images\Reducing ANN-SNN Conversion Error through Residual Membrane Potential
2025-11-16 19:59:51,856 - INFO - root - 已保存图片 1/10：./export\SNN\images\Reducing ANN-SNN Conversion Error through Residual Membrane Potential\figure_1_page7.png
2025-11-16 19:59:51,927 - INFO - root - 已保存图片 2/10：./export\SNN\images\Reducing ANN-SNN Conversion Error through Residual Membrane Potential\figure_2_page7.png
2025-11-16 19:59:51,995 - INFO - root - 已保存图片 3/10：./export\SNN\images\Reducing ANN-SNN Conversion Error through Residual Membrane Potential\figure_3_page7.png
2025-11-16 19:59:52,063 - INFO - root - 已保存图片 4/10：./export\SNN\images\Reducing ANN-SNN Conversion Error through Residual Membrane Potential\figure_4_page7.png
2025-11-16 19:59:52,119 - INFO - root - 已保存图片 5/10：./export\SNN\images\Reducing ANN-SNN Conversion Error through Residual Membrane Potential\figure_5_page7.png
2025-11-16 19:59:52,179 - INFO - root - 已保存图片 6/10：./export\SNN\images\Reducing ANN-SNN Conversion Error through Residual Membrane Potential\figure_6_page7.png
2025-11-16 19:59:52,183 - INFO - root - 成功添加图片 1：./export\SNN\images\Reducing ANN-SNN Conversion Error through Residual Membrane Potential\figure_1_page7.png
2025-11-16 19:59:52,183 - INFO - root - 成功添加图片 2：./export\SNN\images\Reducing ANN-SNN Conversion Error through Residual Membrane Potential\figure_2_page7.png
2025-11-16 19:59:52,183 - INFO - root - 成功添加图片 3：./export\SNN\images\Reducing ANN-SNN Conversion Error through Residual Membrane Potential\figure_3_page7.png
2025-11-16 19:59:52,184 - INFO - root - 成功添加图片 4：./export\SNN\images\Reducing ANN-SNN Conversion Error through Residual Membrane Potential\figure_4_page7.png
2025-11-16 19:59:52,184 - INFO - root - 成功添加图片 5：./export\SNN\images\Reducing ANN-SNN Conversion Error through Residual Membrane Potential\figure_5_page7.png
2025-11-16 19:59:52,184 - INFO - root - 成功添加图片 6：./export\SNN\images\Reducing ANN-SNN Conversion Error through Residual Membrane Potential\figure_6_page7.png
2025-11-16 19:59:52,186 - INFO - root - 论文《Reducing ANN-SNN Conversion Error through Residual Membrane Potential》的分析已保存到 ./export\SNN\Reducing ANN-SNN Conversion Error through Residual Membrane Potential.md
2025-11-16 19:59:52,189 - INFO - root - 正在总结论文 9/100: CDNA-SNN: A New Spiking Neural Network for Pattern Classification Using Neuronal Assemblies
2025-11-16 20:00:08,322 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-16 20:00:08,326 - INFO - root - LLMClient: rate limit reached, sleeping 8.4s
2025-11-16 20:01:02,816 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-16 20:01:43,224 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-16 20:01:43,238 - INFO - root - 正在提取论文图片到目录: ./export\SNN\images\CDNA-SNN_ A New Spiking Neural Network for Pattern Classification Using Neuronal Assemblies
2025-11-16 20:01:43,352 - INFO - root - 已保存图片 1/10：./export\SNN\images\CDNA-SNN_ A New Spiking Neural Network for Pattern Classification Using Neuronal Assemblies\figure_1_page12.jpeg
2025-11-16 20:01:43,423 - INFO - root - 已保存图片 2/10：./export\SNN\images\CDNA-SNN_ A New Spiking Neural Network for Pattern Classification Using Neuronal Assemblies\figure_2_page13.jpeg
2025-11-16 20:01:43,482 - INFO - root - 已保存图片 3/10：./export\SNN\images\CDNA-SNN_ A New Spiking Neural Network for Pattern Classification Using Neuronal Assemblies\figure_3_page4.jpeg
2025-11-16 20:01:43,525 - INFO - root - 已保存图片 4/10：./export\SNN\images\CDNA-SNN_ A New Spiking Neural Network for Pattern Classification Using Neuronal Assemblies\figure_4_page9.jpeg
2025-11-16 20:01:43,570 - INFO - root - 已保存图片 5/10：./export\SNN\images\CDNA-SNN_ A New Spiking Neural Network for Pattern Classification Using Neuronal Assemblies\figure_5_page13.jpeg
2025-11-16 20:01:43,600 - INFO - root - 已保存图片 6/10：./export\SNN\images\CDNA-SNN_ A New Spiking Neural Network for Pattern Classification Using Neuronal Assemblies\figure_6_page1.png
2025-11-16 20:01:43,606 - INFO - root - 成功添加图片 1：./export\SNN\images\CDNA-SNN_ A New Spiking Neural Network for Pattern Classification Using Neuronal Assemblies\figure_1_page12.jpeg
2025-11-16 20:01:43,607 - INFO - root - 成功添加图片 2：./export\SNN\images\CDNA-SNN_ A New Spiking Neural Network for Pattern Classification Using Neuronal Assemblies\figure_2_page13.jpeg
2025-11-16 20:01:43,607 - INFO - root - 成功添加图片 3：./export\SNN\images\CDNA-SNN_ A New Spiking Neural Network for Pattern Classification Using Neuronal Assemblies\figure_3_page4.jpeg
2025-11-16 20:01:43,608 - INFO - root - 成功添加图片 4：./export\SNN\images\CDNA-SNN_ A New Spiking Neural Network for Pattern Classification Using Neuronal Assemblies\figure_4_page9.jpeg
2025-11-16 20:01:43,608 - INFO - root - 成功添加图片 5：./export\SNN\images\CDNA-SNN_ A New Spiking Neural Network for Pattern Classification Using Neuronal Assemblies\figure_5_page13.jpeg
2025-11-16 20:01:43,608 - INFO - root - 成功添加图片 6：./export\SNN\images\CDNA-SNN_ A New Spiking Neural Network for Pattern Classification Using Neuronal Assemblies\figure_6_page1.png
2025-11-16 20:01:43,610 - INFO - root - 论文《CDNA-SNN: A New Spiking Neural Network for Pattern Classification Using Neuronal Assemblies》的分析已保存到 ./export\SNN\CDNA-SNN_ A New Spiking Neural Network for Pattern Classification Using Neuronal Assemblies.md
2025-11-16 20:01:43,613 - INFO - root - 正在总结论文 10/100: One-Spike SNN: Single-Spike Phase Coding With Base Manipulation for ANN-to-SNN Conversion Loss Minimization
2025-11-16 20:02:00,001 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-16 20:02:00,004 - INFO - root - LLMClient: rate limit reached, sleeping 2.8s
2025-11-16 20:02:54,110 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-16 20:03:29,207 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-16 20:03:29,216 - INFO - root - 正在提取论文图片到目录: ./export\SNN\images\One-Spike SNN_ Single-Spike Phase Coding With Base Manipulation for ANN-to-SNN Conversion Loss Minim
2025-11-16 20:03:29,259 - INFO - root - 论文《One-Spike SNN: Single-Spike Phase Coding With Base Manipulation for ANN-to-SNN Conversion Loss Minimization》的分析已保存到 ./export\SNN\One-Spike SNN_ Single-Spike Phase Coding With Base Manipulation for ANN-to-SNN Conversion Loss Minim.md
2025-11-16 20:03:29,265 - INFO - root - 正在总结论文 11/100: RMP-SNN: Residual Membrane Potential Neuron for Enabling Deeper High-Accuracy and Low-Latency Spiking Neural Network
2025-11-16 20:03:41,947 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-16 20:03:41,953 - INFO - root - LLMClient: rate limit reached, sleeping 12.2s
2025-11-16 20:05:05,841 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-16 20:05:43,036 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-16 20:05:43,041 - INFO - root - 正在提取论文图片到目录: ./export\SNN\images\RMP-SNN_ Residual Membrane Potential Neuron for Enabling Deeper High-Accuracy and Low-Latency Spikin
2025-11-16 20:05:43,125 - INFO - root - 已保存图片 1/10：./export\SNN\images\RMP-SNN_ Residual Membrane Potential Neuron for Enabling Deeper High-Accuracy and Low-Latency Spikin\figure_1_page1.png
2025-11-16 20:05:43,177 - INFO - root - 已保存图片 2/10：./export\SNN\images\RMP-SNN_ Residual Membrane Potential Neuron for Enabling Deeper High-Accuracy and Low-Latency Spikin\figure_2_page1.png
2025-11-16 20:05:43,178 - INFO - root - 成功添加图片 1：./export\SNN\images\RMP-SNN_ Residual Membrane Potential Neuron for Enabling Deeper High-Accuracy and Low-Latency Spikin\figure_1_page1.png
2025-11-16 20:05:43,180 - INFO - root - 成功添加图片 2：./export\SNN\images\RMP-SNN_ Residual Membrane Potential Neuron for Enabling Deeper High-Accuracy and Low-Latency Spikin\figure_2_page1.png
2025-11-16 20:05:43,183 - INFO - root - 论文《RMP-SNN: Residual Membrane Potential Neuron for Enabling Deeper High-Accuracy and Low-Latency Spiking Neural Network》的分析已保存到 ./export\SNN\RMP-SNN_ Residual Membrane Potential Neuron for Enabling Deeper High-Accuracy and Low-Latency Spikin.md
2025-11-16 20:05:43,188 - INFO - root - 跳过总结 (手动下载): DIET-SNN: A Low-Latency Spiking Neural Network With Direct Input Encoding and Leakage and Threshold Optimization
2025-11-16 20:05:43,189 - INFO - root - 跳过总结 (手动下载): R-SNN: Region-Based Spiking Neural Network for Object Detection
2025-11-16 20:05:43,189 - INFO - root - 跳过总结 (手动下载): A Unified Optimization Framework of ANN-SNN Conversion: Towards Optimal Mapping from Activation Values to Firing Rates
2025-11-16 20:05:43,189 - INFO - root - 跳过总结 (手动下载): C-DNN: A 24.5-85.8TOPS/W Complementary-Deep-Neural-Network Processor with Heterogeneous CNN/SNN Core Architecture and Forward-Gradient-Based Sparsity Generation
2025-11-16 20:05:43,190 - INFO - root - 正在总结论文 16/100: A Hybrid ANN-SNN Architecture for Low-Power and Low-Latency Visual Perception
2025-11-16 20:05:55,913 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-16 20:05:55,915 - INFO - root - LLMClient: rate limit reached, sleeping 9.9s
2025-11-16 20:06:54,801 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-16 20:07:23,601 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-16 20:07:23,603 - INFO - root - 正在提取论文图片到目录: ./export\SNN\images\A Hybrid ANN-SNN Architecture for Low-Power and Low-Latency Visual Perception
2025-11-16 20:07:26,533 - INFO - root - 已保存图片 1/10：./export\SNN\images\A Hybrid ANN-SNN Architecture for Low-Power and Low-Latency Visual Perception\figure_1_page8.png
2025-11-16 20:07:26,865 - INFO - root - 已保存图片 2/10：./export\SNN\images\A Hybrid ANN-SNN Architecture for Low-Power and Low-Latency Visual Perception\figure_2_page8.png
2025-11-16 20:07:27,154 - INFO - root - 已保存图片 3/10：./export\SNN\images\A Hybrid ANN-SNN Architecture for Low-Power and Low-Latency Visual Perception\figure_3_page8.png
2025-11-16 20:07:27,391 - INFO - root - 已保存图片 4/10：./export\SNN\images\A Hybrid ANN-SNN Architecture for Low-Power and Low-Latency Visual Perception\figure_4_page8.png
2025-11-16 20:07:27,704 - INFO - root - 已保存图片 5/10：./export\SNN\images\A Hybrid ANN-SNN Architecture for Low-Power and Low-Latency Visual Perception\figure_5_page6.png
2025-11-16 20:07:27,998 - INFO - root - 已保存图片 6/10：./export\SNN\images\A Hybrid ANN-SNN Architecture for Low-Power and Low-Latency Visual Perception\figure_6_page6.png
2025-11-16 20:07:28,173 - INFO - root - 已保存图片 7/10：./export\SNN\images\A Hybrid ANN-SNN Architecture for Low-Power and Low-Latency Visual Perception\figure_7_page1.png
2025-11-16 20:07:28,268 - INFO - root - 已保存图片 8/10：./export\SNN\images\A Hybrid ANN-SNN Architecture for Low-Power and Low-Latency Visual Perception\figure_8_page3.png
2025-11-16 20:07:28,376 - INFO - root - 已保存图片 9/10：./export\SNN\images\A Hybrid ANN-SNN Architecture for Low-Power and Low-Latency Visual Perception\figure_9_page9.png
2025-11-16 20:07:28,420 - INFO - root - 成功添加图片 1：./export\SNN\images\A Hybrid ANN-SNN Architecture for Low-Power and Low-Latency Visual Perception\figure_1_page8.png
2025-11-16 20:07:28,420 - INFO - root - 成功添加图片 2：./export\SNN\images\A Hybrid ANN-SNN Architecture for Low-Power and Low-Latency Visual Perception\figure_2_page8.png
2025-11-16 20:07:28,420 - INFO - root - 成功添加图片 3：./export\SNN\images\A Hybrid ANN-SNN Architecture for Low-Power and Low-Latency Visual Perception\figure_3_page8.png
2025-11-16 20:07:28,421 - INFO - root - 成功添加图片 4：./export\SNN\images\A Hybrid ANN-SNN Architecture for Low-Power and Low-Latency Visual Perception\figure_4_page8.png
2025-11-16 20:07:28,421 - INFO - root - 成功添加图片 5：./export\SNN\images\A Hybrid ANN-SNN Architecture for Low-Power and Low-Latency Visual Perception\figure_5_page6.png
2025-11-16 20:07:28,421 - INFO - root - 成功添加图片 6：./export\SNN\images\A Hybrid ANN-SNN Architecture for Low-Power and Low-Latency Visual Perception\figure_6_page6.png
2025-11-16 20:07:28,422 - INFO - root - 成功添加图片 7：./export\SNN\images\A Hybrid ANN-SNN Architecture for Low-Power and Low-Latency Visual Perception\figure_7_page1.png
2025-11-16 20:07:28,422 - INFO - root - 成功添加图片 8：./export\SNN\images\A Hybrid ANN-SNN Architecture for Low-Power and Low-Latency Visual Perception\figure_8_page3.png
2025-11-16 20:07:28,423 - INFO - root - 成功添加图片 9：./export\SNN\images\A Hybrid ANN-SNN Architecture for Low-Power and Low-Latency Visual Perception\figure_9_page9.png
2025-11-16 20:07:28,443 - INFO - root - 论文《A Hybrid ANN-SNN Architecture for Low-Power and Low-Latency Visual Perception》的分析已保存到 ./export\SNN\A Hybrid ANN-SNN Architecture for Low-Power and Low-Latency Visual Perception.md
2025-11-16 20:07:28,452 - INFO - root - 跳过总结 (手动下载): Direct Training of SNN using Local Zeroth Order Method
2025-11-16 20:07:28,455 - INFO - root - 正在总结论文 18/100: A New ANN-SNN Conversion Method with High Accuracy, Low Latency and Good Robustness
2025-11-16 20:07:37,913 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-16 20:07:37,914 - INFO - root - LLMClient: rate limit reached, sleeping 16.9s
2025-11-16 20:08:47,334 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-16 20:09:25,632 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-16 20:09:25,636 - INFO - root - 正在提取论文图片到目录: ./export\SNN\images\A New ANN-SNN Conversion Method with High Accuracy, Low Latency and Good Robustness
2025-11-16 20:09:26,265 - INFO - root - 已保存图片 1/10：./export\SNN\images\A New ANN-SNN Conversion Method with High Accuracy, Low Latency and Good Robustness\figure_1_page7.png
2025-11-16 20:09:26,391 - INFO - root - 已保存图片 2/10：./export\SNN\images\A New ANN-SNN Conversion Method with High Accuracy, Low Latency and Good Robustness\figure_2_page4.png
2025-11-16 20:09:26,492 - INFO - root - 已保存图片 3/10：./export\SNN\images\A New ANN-SNN Conversion Method with High Accuracy, Low Latency and Good Robustness\figure_3_page4.png
2025-11-16 20:09:26,583 - INFO - root - 已保存图片 4/10：./export\SNN\images\A New ANN-SNN Conversion Method with High Accuracy, Low Latency and Good Robustness\figure_4_page3.png
2025-11-16 20:09:26,634 - INFO - root - 已保存图片 5/10：./export\SNN\images\A New ANN-SNN Conversion Method with High Accuracy, Low Latency and Good Robustness\figure_5_page3.png
2025-11-16 20:09:26,644 - INFO - root - 成功添加图片 1：./export\SNN\images\A New ANN-SNN Conversion Method with High Accuracy, Low Latency and Good Robustness\figure_1_page7.png
2025-11-16 20:09:26,645 - INFO - root - 成功添加图片 2：./export\SNN\images\A New ANN-SNN Conversion Method with High Accuracy, Low Latency and Good Robustness\figure_2_page4.png
2025-11-16 20:09:26,647 - INFO - root - 成功添加图片 3：./export\SNN\images\A New ANN-SNN Conversion Method with High Accuracy, Low Latency and Good Robustness\figure_3_page4.png
2025-11-16 20:09:26,648 - INFO - root - 成功添加图片 4：./export\SNN\images\A New ANN-SNN Conversion Method with High Accuracy, Low Latency and Good Robustness\figure_4_page3.png
2025-11-16 20:09:26,649 - INFO - root - 成功添加图片 5：./export\SNN\images\A New ANN-SNN Conversion Method with High Accuracy, Low Latency and Good Robustness\figure_5_page3.png
2025-11-16 20:09:26,652 - INFO - root - 论文《A New ANN-SNN Conversion Method with High Accuracy, Low Latency and Good Robustness》的分析已保存到 ./export\SNN\A New ANN-SNN Conversion Method with High Accuracy, Low Latency and Good Robustness.md
2025-11-16 20:09:26,659 - INFO - root - 正在总结论文 19/100: High-accuracy deep ANN-to-SNN conversion using quantization-aware training framework and calcium-gated bipolar leaky integrate and fire neuron
2025-11-16 20:09:36,841 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-16 20:09:36,842 - INFO - root - LLMClient: rate limit reached, sleeping 10.5s
2025-11-16 20:10:49,517 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-16 20:11:24,558 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-16 20:11:24,568 - INFO - root - 正在提取论文图片到目录: ./export\SNN\images\High-accuracy deep ANN-to-SNN conversion using quantization-aware training framework and calcium-gat
2025-11-16 20:11:24,773 - INFO - root - 已保存图片 1/10：./export\SNN\images\High-accuracy deep ANN-to-SNN conversion using quantization-aware training framework and calcium-gat\figure_1_page4.jpeg
2025-11-16 20:11:24,833 - INFO - root - 已保存图片 2/10：./export\SNN\images\High-accuracy deep ANN-to-SNN conversion using quantization-aware training framework and calcium-gat\figure_2_page5.jpeg
2025-11-16 20:11:24,873 - INFO - root - 已保存图片 3/10：./export\SNN\images\High-accuracy deep ANN-to-SNN conversion using quantization-aware training framework and calcium-gat\figure_3_page6.jpeg
2025-11-16 20:11:24,901 - INFO - root - 已保存图片 4/10：./export\SNN\images\High-accuracy deep ANN-to-SNN conversion using quantization-aware training framework and calcium-gat\figure_4_page3.jpeg
2025-11-16 20:11:24,929 - INFO - root - 已保存图片 5/10：./export\SNN\images\High-accuracy deep ANN-to-SNN conversion using quantization-aware training framework and calcium-gat\figure_5_page3.jpeg
2025-11-16 20:11:24,932 - INFO - root - 成功添加图片 1：./export\SNN\images\High-accuracy deep ANN-to-SNN conversion using quantization-aware training framework and calcium-gat\figure_1_page4.jpeg
2025-11-16 20:11:24,932 - INFO - root - 成功添加图片 2：./export\SNN\images\High-accuracy deep ANN-to-SNN conversion using quantization-aware training framework and calcium-gat\figure_2_page5.jpeg
2025-11-16 20:11:24,933 - INFO - root - 成功添加图片 3：./export\SNN\images\High-accuracy deep ANN-to-SNN conversion using quantization-aware training framework and calcium-gat\figure_3_page6.jpeg
2025-11-16 20:11:24,933 - INFO - root - 成功添加图片 4：./export\SNN\images\High-accuracy deep ANN-to-SNN conversion using quantization-aware training framework and calcium-gat\figure_4_page3.jpeg
2025-11-16 20:11:24,933 - INFO - root - 成功添加图片 5：./export\SNN\images\High-accuracy deep ANN-to-SNN conversion using quantization-aware training framework and calcium-gat\figure_5_page3.jpeg
2025-11-16 20:11:24,935 - INFO - root - 论文《High-accuracy deep ANN-to-SNN conversion using quantization-aware training framework and calcium-gated bipolar leaky integrate and fire neuron》的分析已保存到 ./export\SNN\High-accuracy deep ANN-to-SNN conversion using quantization-aware training framework and calcium-gat.md
2025-11-16 20:11:24,941 - INFO - root - 跳过总结 (手动下载): RecDis-SNN: Rectifying Membrane Potential Distribution for Directly Training Spiking Neural Networks
2025-11-16 20:11:24,943 - INFO - root - 正在总结论文 21/100: Optimal ANN-SNN Conversion for Fast and Accurate Inference in Deep Spiking Neural Networks
2025-11-16 20:11:35,220 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-16 20:11:35,223 - INFO - root - LLMClient: rate limit reached, sleeping 14.3s
2025-11-16 20:12:35,807 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-16 20:13:08,599 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-16 20:13:08,603 - INFO - root - 正在提取论文图片到目录: ./export\SNN\images\Optimal ANN-SNN Conversion for Fast and Accurate Inference in Deep Spiking Neural Networks
2025-11-16 20:13:08,693 - INFO - root - 已保存图片 1/10：./export\SNN\images\Optimal ANN-SNN Conversion for Fast and Accurate Inference in Deep Spiking Neural Networks\figure_1_page1.png
2025-11-16 20:13:08,719 - INFO - root - 已保存图片 2/10：./export\SNN\images\Optimal ANN-SNN Conversion for Fast and Accurate Inference in Deep Spiking Neural Networks\figure_2_page1.png
2025-11-16 20:13:08,752 - INFO - root - 已保存图片 3/10：./export\SNN\images\Optimal ANN-SNN Conversion for Fast and Accurate Inference in Deep Spiking Neural Networks\figure_3_page1.png
2025-11-16 20:13:08,778 - INFO - root - 已保存图片 4/10：./export\SNN\images\Optimal ANN-SNN Conversion for Fast and Accurate Inference in Deep Spiking Neural Networks\figure_4_page1.jpeg
2025-11-16 20:13:08,857 - INFO - root - 已保存图片 5/10：./export\SNN\images\Optimal ANN-SNN Conversion for Fast and Accurate Inference in Deep Spiking Neural Networks\figure_5_page1.png
2025-11-16 20:13:08,895 - INFO - root - 已保存图片 6/10：./export\SNN\images\Optimal ANN-SNN Conversion for Fast and Accurate Inference in Deep Spiking Neural Networks\figure_6_page1.png
2025-11-16 20:13:08,937 - INFO - root - 已保存图片 7/10：./export\SNN\images\Optimal ANN-SNN Conversion for Fast and Accurate Inference in Deep Spiking Neural Networks\figure_7_page5.png
2025-11-16 20:13:08,982 - INFO - root - 已保存图片 8/10：./export\SNN\images\Optimal ANN-SNN Conversion for Fast and Accurate Inference in Deep Spiking Neural Networks\figure_8_page5.png
2025-11-16 20:13:09,043 - INFO - root - 已保存图片 9/10：./export\SNN\images\Optimal ANN-SNN Conversion for Fast and Accurate Inference in Deep Spiking Neural Networks\figure_9_page5.png
2025-11-16 20:13:09,044 - INFO - root - 成功添加图片 1：./export\SNN\images\Optimal ANN-SNN Conversion for Fast and Accurate Inference in Deep Spiking Neural Networks\figure_1_page1.png
2025-11-16 20:13:09,044 - INFO - root - 成功添加图片 2：./export\SNN\images\Optimal ANN-SNN Conversion for Fast and Accurate Inference in Deep Spiking Neural Networks\figure_2_page1.png
2025-11-16 20:13:09,045 - INFO - root - 成功添加图片 3：./export\SNN\images\Optimal ANN-SNN Conversion for Fast and Accurate Inference in Deep Spiking Neural Networks\figure_3_page1.png
2025-11-16 20:13:09,045 - INFO - root - 成功添加图片 4：./export\SNN\images\Optimal ANN-SNN Conversion for Fast and Accurate Inference in Deep Spiking Neural Networks\figure_4_page1.jpeg
2025-11-16 20:13:09,045 - INFO - root - 成功添加图片 5：./export\SNN\images\Optimal ANN-SNN Conversion for Fast and Accurate Inference in Deep Spiking Neural Networks\figure_5_page1.png
2025-11-16 20:13:09,045 - INFO - root - 成功添加图片 6：./export\SNN\images\Optimal ANN-SNN Conversion for Fast and Accurate Inference in Deep Spiking Neural Networks\figure_6_page1.png
2025-11-16 20:13:09,046 - INFO - root - 成功添加图片 7：./export\SNN\images\Optimal ANN-SNN Conversion for Fast and Accurate Inference in Deep Spiking Neural Networks\figure_7_page5.png
2025-11-16 20:13:09,046 - INFO - root - 成功添加图片 8：./export\SNN\images\Optimal ANN-SNN Conversion for Fast and Accurate Inference in Deep Spiking Neural Networks\figure_8_page5.png
2025-11-16 20:13:09,046 - INFO - root - 成功添加图片 9：./export\SNN\images\Optimal ANN-SNN Conversion for Fast and Accurate Inference in Deep Spiking Neural Networks\figure_9_page5.png
2025-11-16 20:13:09,047 - INFO - root - 论文《Optimal ANN-SNN Conversion for Fast and Accurate Inference in Deep Spiking Neural Networks》的分析已保存到 ./export\SNN\Optimal ANN-SNN Conversion for Fast and Accurate Inference in Deep Spiking Neural Networks.md
2025-11-16 20:13:09,052 - INFO - root - 正在总结论文 22/100: TCJA-SNN: Temporal-Channel Joint Attention for Spiking Neural Networks
2025-11-16 20:13:21,681 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-16 20:13:21,684 - INFO - root - LLMClient: rate limit reached, sleeping 14.1s
2025-11-16 20:14:32,362 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-16 20:15:05,834 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-16 20:15:05,836 - INFO - root - 正在提取论文图片到目录: ./export\SNN\images\TCJA-SNN_ Temporal-Channel Joint Attention for Spiking Neural Networks
2025-11-16 20:15:07,731 - INFO - root - 已保存图片 1/10：./export\SNN\images\TCJA-SNN_ Temporal-Channel Joint Attention for Spiking Neural Networks\figure_1_page12.png
2025-11-16 20:15:07,855 - INFO - root - 已保存图片 2/10：./export\SNN\images\TCJA-SNN_ Temporal-Channel Joint Attention for Spiking Neural Networks\figure_2_page12.png
2025-11-16 20:15:08,074 - INFO - root - 已保存图片 3/10：./export\SNN\images\TCJA-SNN_ Temporal-Channel Joint Attention for Spiking Neural Networks\figure_3_page8.png
2025-11-16 20:15:08,165 - INFO - root - 已保存图片 4/10：./export\SNN\images\TCJA-SNN_ Temporal-Channel Joint Attention for Spiking Neural Networks\figure_4_page10.png
2025-11-16 20:15:08,302 - INFO - root - 已保存图片 5/10：./export\SNN\images\TCJA-SNN_ Temporal-Channel Joint Attention for Spiking Neural Networks\figure_5_page10.png
2025-11-16 20:15:08,379 - INFO - root - 已保存图片 6/10：./export\SNN\images\TCJA-SNN_ Temporal-Channel Joint Attention for Spiking Neural Networks\figure_6_page3.jpeg
2025-11-16 20:15:08,464 - INFO - root - 已保存图片 7/10：./export\SNN\images\TCJA-SNN_ Temporal-Channel Joint Attention for Spiking Neural Networks\figure_7_page3.jpeg
2025-11-16 20:15:08,535 - INFO - root - 已保存图片 8/10：./export\SNN\images\TCJA-SNN_ Temporal-Channel Joint Attention for Spiking Neural Networks\figure_8_page3.jpeg
2025-11-16 20:15:08,606 - INFO - root - 已保存图片 9/10：./export\SNN\images\TCJA-SNN_ Temporal-Channel Joint Attention for Spiking Neural Networks\figure_9_page3.jpeg
2025-11-16 20:15:08,689 - INFO - root - 已保存图片 10/10：./export\SNN\images\TCJA-SNN_ Temporal-Channel Joint Attention for Spiking Neural Networks\figure_10_page3.jpeg
2025-11-16 20:15:08,716 - INFO - root - 成功添加图片 1：./export\SNN\images\TCJA-SNN_ Temporal-Channel Joint Attention for Spiking Neural Networks\figure_1_page12.png
2025-11-16 20:15:08,716 - INFO - root - 成功添加图片 2：./export\SNN\images\TCJA-SNN_ Temporal-Channel Joint Attention for Spiking Neural Networks\figure_2_page12.png
2025-11-16 20:15:08,717 - INFO - root - 成功添加图片 3：./export\SNN\images\TCJA-SNN_ Temporal-Channel Joint Attention for Spiking Neural Networks\figure_3_page8.png
2025-11-16 20:15:08,717 - INFO - root - 成功添加图片 4：./export\SNN\images\TCJA-SNN_ Temporal-Channel Joint Attention for Spiking Neural Networks\figure_4_page10.png
2025-11-16 20:15:08,718 - INFO - root - 成功添加图片 5：./export\SNN\images\TCJA-SNN_ Temporal-Channel Joint Attention for Spiking Neural Networks\figure_5_page10.png
2025-11-16 20:15:08,718 - INFO - root - 成功添加图片 6：./export\SNN\images\TCJA-SNN_ Temporal-Channel Joint Attention for Spiking Neural Networks\figure_6_page3.jpeg
2025-11-16 20:15:08,718 - INFO - root - 成功添加图片 7：./export\SNN\images\TCJA-SNN_ Temporal-Channel Joint Attention for Spiking Neural Networks\figure_7_page3.jpeg
2025-11-16 20:15:08,718 - INFO - root - 成功添加图片 8：./export\SNN\images\TCJA-SNN_ Temporal-Channel Joint Attention for Spiking Neural Networks\figure_8_page3.jpeg
2025-11-16 20:15:08,719 - INFO - root - 成功添加图片 9：./export\SNN\images\TCJA-SNN_ Temporal-Channel Joint Attention for Spiking Neural Networks\figure_9_page3.jpeg
2025-11-16 20:15:08,719 - INFO - root - 成功添加图片 10：./export\SNN\images\TCJA-SNN_ Temporal-Channel Joint Attention for Spiking Neural Networks\figure_10_page3.jpeg
2025-11-16 20:15:08,722 - INFO - root - 论文《TCJA-SNN: Temporal-Channel Joint Attention for Spiking Neural Networks》的分析已保存到 ./export\SNN\TCJA-SNN_ Temporal-Channel Joint Attention for Spiking Neural Networks.md
2025-11-16 20:15:08,726 - INFO - root - 跳过总结 (手动下载): Symmetric-threshold ReLU for Fast and Nearly Lossless ANN-SNN Conversion
2025-11-16 20:15:08,726 - INFO - root - 正在总结论文 24/100: Signed Neuron with Memory: Towards Simple, Accurate and High-Efficient ANN-SNN Conversion
2025-11-16 20:15:22,071 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-16 20:15:22,074 - INFO - root - LLMClient: rate limit reached, sleeping 10.3s
2025-11-16 20:16:26,141 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-16 20:16:56,362 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-16 20:16:56,363 - INFO - root - 正在提取论文图片到目录: ./export\SNN\images\Signed Neuron with Memory_ Towards Simple, Accurate and High-Efficient ANN-SNN Conversion
2025-11-16 20:16:56,618 - INFO - root - 已保存图片 1/10：./export\SNN\images\Signed Neuron with Memory_ Towards Simple, Accurate and High-Efficient ANN-SNN Conversion\figure_1_page4.png
2025-11-16 20:16:56,680 - INFO - root - 已保存图片 2/10：./export\SNN\images\Signed Neuron with Memory_ Towards Simple, Accurate and High-Efficient ANN-SNN Conversion\figure_2_page3.png
2025-11-16 20:16:56,716 - INFO - root - 已保存图片 3/10：./export\SNN\images\Signed Neuron with Memory_ Towards Simple, Accurate and High-Efficient ANN-SNN Conversion\figure_3_page3.jpeg
2025-11-16 20:16:56,727 - INFO - root - 已保存图片 4/10：./export\SNN\images\Signed Neuron with Memory_ Towards Simple, Accurate and High-Efficient ANN-SNN Conversion\figure_4_page5.png
2025-11-16 20:16:56,729 - INFO - root - 成功添加图片 1：./export\SNN\images\Signed Neuron with Memory_ Towards Simple, Accurate and High-Efficient ANN-SNN Conversion\figure_1_page4.png
2025-11-16 20:16:56,729 - INFO - root - 成功添加图片 2：./export\SNN\images\Signed Neuron with Memory_ Towards Simple, Accurate and High-Efficient ANN-SNN Conversion\figure_2_page3.png
2025-11-16 20:16:56,731 - INFO - root - 成功添加图片 3：./export\SNN\images\Signed Neuron with Memory_ Towards Simple, Accurate and High-Efficient ANN-SNN Conversion\figure_3_page3.jpeg
2025-11-16 20:16:56,731 - INFO - root - 成功添加图片 4：./export\SNN\images\Signed Neuron with Memory_ Towards Simple, Accurate and High-Efficient ANN-SNN Conversion\figure_4_page5.png
2025-11-16 20:16:56,732 - INFO - root - 论文《Signed Neuron with Memory: Towards Simple, Accurate and High-Efficient ANN-SNN Conversion》的分析已保存到 ./export\SNN\Signed Neuron with Memory_ Towards Simple, Accurate and High-Efficient ANN-SNN Conversion.md
2025-11-16 20:16:56,735 - INFO - root - 正在总结论文 25/100: A low cost neuromorphic learning engine based on a high performance supervised SNN learning algorithm
2025-11-16 20:17:06,187 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-16 20:17:06,198 - INFO - root - LLMClient: rate limit reached, sleeping 19.9s
2025-11-16 20:18:30,201 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-16 20:19:08,092 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-16 20:19:08,098 - INFO - root - 正在提取论文图片到目录: ./export\SNN\images\A low cost neuromorphic learning engine based on a high performance supervised SNN learning algorith
2025-11-16 20:19:08,518 - INFO - root - 已保存图片 1/10：./export\SNN\images\A low cost neuromorphic learning engine based on a high performance supervised SNN learning algorith\figure_1_page8.png
2025-11-16 20:19:08,586 - INFO - root - 已保存图片 2/10：./export\SNN\images\A low cost neuromorphic learning engine based on a high performance supervised SNN learning algorith\figure_2_page9.png
2025-11-16 20:19:08,660 - INFO - root - 已保存图片 3/10：./export\SNN\images\A low cost neuromorphic learning engine based on a high performance supervised SNN learning algorith\figure_3_page10.png
2025-11-16 20:19:08,721 - INFO - root - 已保存图片 4/10：./export\SNN\images\A low cost neuromorphic learning engine based on a high performance supervised SNN learning algorith\figure_4_page6.png
2025-11-16 20:19:08,729 - INFO - root - 已保存图片 5/10：./export\SNN\images\A low cost neuromorphic learning engine based on a high performance supervised SNN learning algorith\figure_5_page13.png
2025-11-16 20:19:08,732 - INFO - root - 成功添加图片 1：./export\SNN\images\A low cost neuromorphic learning engine based on a high performance supervised SNN learning algorith\figure_1_page8.png
2025-11-16 20:19:08,732 - INFO - root - 成功添加图片 2：./export\SNN\images\A low cost neuromorphic learning engine based on a high performance supervised SNN learning algorith\figure_2_page9.png
2025-11-16 20:19:08,732 - INFO - root - 成功添加图片 3：./export\SNN\images\A low cost neuromorphic learning engine based on a high performance supervised SNN learning algorith\figure_3_page10.png
2025-11-16 20:19:08,733 - INFO - root - 成功添加图片 4：./export\SNN\images\A low cost neuromorphic learning engine based on a high performance supervised SNN learning algorith\figure_4_page6.png
2025-11-16 20:19:08,733 - INFO - root - 成功添加图片 5：./export\SNN\images\A low cost neuromorphic learning engine based on a high performance supervised SNN learning algorith\figure_5_page13.png
2025-11-16 20:19:08,736 - INFO - root - 论文《A low cost neuromorphic learning engine based on a high performance supervised SNN learning algorithm》的分析已保存到 ./export\SNN\A low cost neuromorphic learning engine based on a high performance supervised SNN learning algorith.md
2025-11-16 20:19:08,740 - INFO - root - 跳过总结 (手动下载): A Neuromorphic Processing System With Spike-Driven SNN Processor for Wearable ECG Classification
2025-11-16 20:19:08,740 - INFO - root - 正在总结论文 27/100: OpenSpike: An OpenRAM SNN Accelerator
2025-11-16 20:19:22,408 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-16 20:19:22,409 - INFO - root - LLMClient: rate limit reached, sleeping 7.8s
2025-11-16 20:20:44,461 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-16 20:21:17,560 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-16 20:21:17,569 - INFO - root - 正在提取论文图片到目录: ./export\SNN\images\OpenSpike_ An OpenRAM SNN Accelerator
2025-11-16 20:21:21,394 - INFO - root - 已保存图片 1/10：./export\SNN\images\OpenSpike_ An OpenRAM SNN Accelerator\figure_1_page3.png
2025-11-16 20:21:21,440 - INFO - root - 已保存图片 2/10：./export\SNN\images\OpenSpike_ An OpenRAM SNN Accelerator\figure_2_page4.jpeg
2025-11-16 20:21:21,513 - INFO - root - 已保存图片 3/10：./export\SNN\images\OpenSpike_ An OpenRAM SNN Accelerator\figure_3_page4.png
2025-11-16 20:21:21,646 - INFO - root - 已保存图片 4/10：./export\SNN\images\OpenSpike_ An OpenRAM SNN Accelerator\figure_4_page5.png
2025-11-16 20:21:21,674 - INFO - root - 成功添加图片 1：./export\SNN\images\OpenSpike_ An OpenRAM SNN Accelerator\figure_1_page3.png
2025-11-16 20:21:21,675 - INFO - root - 成功添加图片 2：./export\SNN\images\OpenSpike_ An OpenRAM SNN Accelerator\figure_2_page4.jpeg
2025-11-16 20:21:21,675 - INFO - root - 成功添加图片 3：./export\SNN\images\OpenSpike_ An OpenRAM SNN Accelerator\figure_3_page4.png
2025-11-16 20:21:21,675 - INFO - root - 成功添加图片 4：./export\SNN\images\OpenSpike_ An OpenRAM SNN Accelerator\figure_4_page5.png
2025-11-16 20:21:21,681 - INFO - root - 论文《OpenSpike: An OpenRAM SNN Accelerator》的分析已保存到 ./export\SNN\OpenSpike_ An OpenRAM SNN Accelerator.md
2025-11-16 20:21:21,687 - INFO - root - 跳过总结 (手动下载): ENLARGE: An Efficient SNN Simulation Framework on GPU Clusters
2025-11-16 20:21:21,687 - INFO - root - 正在总结论文 29/100: LaSNN: Layer-wise ANN-to-SNN Distillation for Effective and Efficient Training in Deep Spiking Neural Networks
2025-11-16 20:21:34,489 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-16 20:21:34,490 - INFO - root - LLMClient: rate limit reached, sleeping 10.0s
2025-11-16 20:22:39,283 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-16 20:23:11,219 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-16 20:23:11,224 - INFO - root - 正在提取论文图片到目录: ./export\SNN\images\LaSNN_ Layer-wise ANN-to-SNN Distillation for Effective and Efficient Training in Deep Spiking Neura
2025-11-16 20:23:11,644 - INFO - root - 已保存图片 1/10：./export\SNN\images\LaSNN_ Layer-wise ANN-to-SNN Distillation for Effective and Efficient Training in Deep Spiking Neura\figure_1_page3.jpeg
2025-11-16 20:23:11,682 - INFO - root - 已保存图片 2/10：./export\SNN\images\LaSNN_ Layer-wise ANN-to-SNN Distillation for Effective and Efficient Training in Deep Spiking Neura\figure_2_page8.jpeg
2025-11-16 20:23:11,721 - INFO - root - 已保存图片 3/10：./export\SNN\images\LaSNN_ Layer-wise ANN-to-SNN Distillation for Effective and Efficient Training in Deep Spiking Neura\figure_3_page4.jpeg
2025-11-16 20:23:11,787 - INFO - root - 已保存图片 4/10：./export\SNN\images\LaSNN_ Layer-wise ANN-to-SNN Distillation for Effective and Efficient Training in Deep Spiking Neura\figure_4_page8.jpeg
2025-11-16 20:23:11,852 - INFO - root - 已保存图片 5/10：./export\SNN\images\LaSNN_ Layer-wise ANN-to-SNN Distillation for Effective and Efficient Training in Deep Spiking Neura\figure_5_page9.jpeg
2025-11-16 20:23:11,901 - INFO - root - 已保存图片 6/10：./export\SNN\images\LaSNN_ Layer-wise ANN-to-SNN Distillation for Effective and Efficient Training in Deep Spiking Neura\figure_6_page6.jpeg
2025-11-16 20:23:11,940 - INFO - root - 已保存图片 7/10：./export\SNN\images\LaSNN_ Layer-wise ANN-to-SNN Distillation for Effective and Efficient Training in Deep Spiking Neura\figure_7_page9.jpeg
2025-11-16 20:23:11,950 - INFO - root - 成功添加图片 1：./export\SNN\images\LaSNN_ Layer-wise ANN-to-SNN Distillation for Effective and Efficient Training in Deep Spiking Neura\figure_1_page3.jpeg
2025-11-16 20:23:11,950 - INFO - root - 成功添加图片 2：./export\SNN\images\LaSNN_ Layer-wise ANN-to-SNN Distillation for Effective and Efficient Training in Deep Spiking Neura\figure_2_page8.jpeg
2025-11-16 20:23:11,953 - INFO - root - 成功添加图片 3：./export\SNN\images\LaSNN_ Layer-wise ANN-to-SNN Distillation for Effective and Efficient Training in Deep Spiking Neura\figure_3_page4.jpeg
2025-11-16 20:23:11,953 - INFO - root - 成功添加图片 4：./export\SNN\images\LaSNN_ Layer-wise ANN-to-SNN Distillation for Effective and Efficient Training in Deep Spiking Neura\figure_4_page8.jpeg
2025-11-16 20:23:11,954 - INFO - root - 成功添加图片 5：./export\SNN\images\LaSNN_ Layer-wise ANN-to-SNN Distillation for Effective and Efficient Training in Deep Spiking Neura\figure_5_page9.jpeg
2025-11-16 20:23:11,955 - INFO - root - 成功添加图片 6：./export\SNN\images\LaSNN_ Layer-wise ANN-to-SNN Distillation for Effective and Efficient Training in Deep Spiking Neura\figure_6_page6.jpeg
2025-11-16 20:23:11,955 - INFO - root - 成功添加图片 7：./export\SNN\images\LaSNN_ Layer-wise ANN-to-SNN Distillation for Effective and Efficient Training in Deep Spiking Neura\figure_7_page9.jpeg
2025-11-16 20:23:11,960 - INFO - root - 论文《LaSNN: Layer-wise ANN-to-SNN Distillation for Effective and Efficient Training in Deep Spiking Neural Networks》的分析已保存到 ./export\SNN\LaSNN_ Layer-wise ANN-to-SNN Distillation for Effective and Efficient Training in Deep Spiking Neura.md
2025-11-16 20:23:11,967 - INFO - root - 跳过总结 (手动下载): A Fast and Energy-Efficient SNN Processor With Adaptive Clock/Event-Driven Computation Scheme and Online Learning
2025-11-16 20:23:11,970 - INFO - root - 跳过总结 (手动下载): A Method of Converting ANN to SNN for Image Classification
2025-11-16 20:23:11,971 - INFO - root - 跳过总结 (手动下载): DIET-SNN: Direct Input Encoding With Leakage and Threshold Optimization in Deep Spiking Neural Networks
2025-11-16 20:23:11,973 - INFO - root - 正在总结论文 33/100: STSC-SNN: Spatio-Temporal Synaptic Connection with temporal convolution and attention for spiking neural networks
2025-11-16 20:23:22,866 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-16 20:23:22,867 - INFO - root - LLMClient: rate limit reached, sleeping 16.4s
2025-11-16 20:24:28,817 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-16 20:25:03,230 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-16 20:25:03,242 - INFO - root - 正在提取论文图片到目录: ./export\SNN\images\STSC-SNN_ Spatio-Temporal Synaptic Connection with temporal convolution and attention for spiking ne
2025-11-16 20:25:03,374 - INFO - root - 已保存图片 1/10：./export\SNN\images\STSC-SNN_ Spatio-Temporal Synaptic Connection with temporal convolution and attention for spiking ne\figure_1_page12.jpeg
2025-11-16 20:25:03,482 - INFO - root - 已保存图片 2/10：./export\SNN\images\STSC-SNN_ Spatio-Temporal Synaptic Connection with temporal convolution and attention for spiking ne\figure_2_page11.jpeg
2025-11-16 20:25:03,544 - INFO - root - 已保存图片 3/10：./export\SNN\images\STSC-SNN_ Spatio-Temporal Synaptic Connection with temporal convolution and attention for spiking ne\figure_3_page6.jpeg
2025-11-16 20:25:03,621 - INFO - root - 已保存图片 4/10：./export\SNN\images\STSC-SNN_ Spatio-Temporal Synaptic Connection with temporal convolution and attention for spiking ne\figure_4_page7.jpeg
2025-11-16 20:25:03,672 - INFO - root - 已保存图片 5/10：./export\SNN\images\STSC-SNN_ Spatio-Temporal Synaptic Connection with temporal convolution and attention for spiking ne\figure_5_page5.jpeg
2025-11-16 20:25:03,724 - INFO - root - 已保存图片 6/10：./export\SNN\images\STSC-SNN_ Spatio-Temporal Synaptic Connection with temporal convolution and attention for spiking ne\figure_6_page7.jpeg
2025-11-16 20:25:03,751 - INFO - root - 已保存图片 7/10：./export\SNN\images\STSC-SNN_ Spatio-Temporal Synaptic Connection with temporal convolution and attention for spiking ne\figure_7_page3.jpeg
2025-11-16 20:25:03,778 - INFO - root - 已保存图片 8/10：./export\SNN\images\STSC-SNN_ Spatio-Temporal Synaptic Connection with temporal convolution and attention for spiking ne\figure_8_page13.jpeg
2025-11-16 20:25:03,788 - INFO - root - 成功添加图片 1：./export\SNN\images\STSC-SNN_ Spatio-Temporal Synaptic Connection with temporal convolution and attention for spiking ne\figure_1_page12.jpeg
2025-11-16 20:25:03,788 - INFO - root - 成功添加图片 2：./export\SNN\images\STSC-SNN_ Spatio-Temporal Synaptic Connection with temporal convolution and attention for spiking ne\figure_2_page11.jpeg
2025-11-16 20:25:03,788 - INFO - root - 成功添加图片 3：./export\SNN\images\STSC-SNN_ Spatio-Temporal Synaptic Connection with temporal convolution and attention for spiking ne\figure_3_page6.jpeg
2025-11-16 20:25:03,789 - INFO - root - 成功添加图片 4：./export\SNN\images\STSC-SNN_ Spatio-Temporal Synaptic Connection with temporal convolution and attention for spiking ne\figure_4_page7.jpeg
2025-11-16 20:25:03,790 - INFO - root - 成功添加图片 5：./export\SNN\images\STSC-SNN_ Spatio-Temporal Synaptic Connection with temporal convolution and attention for spiking ne\figure_5_page5.jpeg
2025-11-16 20:25:03,790 - INFO - root - 成功添加图片 6：./export\SNN\images\STSC-SNN_ Spatio-Temporal Synaptic Connection with temporal convolution and attention for spiking ne\figure_6_page7.jpeg
2025-11-16 20:25:03,791 - INFO - root - 成功添加图片 7：./export\SNN\images\STSC-SNN_ Spatio-Temporal Synaptic Connection with temporal convolution and attention for spiking ne\figure_7_page3.jpeg
2025-11-16 20:25:03,791 - INFO - root - 成功添加图片 8：./export\SNN\images\STSC-SNN_ Spatio-Temporal Synaptic Connection with temporal convolution and attention for spiking ne\figure_8_page13.jpeg
2025-11-16 20:25:03,794 - INFO - root - 论文《STSC-SNN: Spatio-Temporal Synaptic Connection with temporal convolution and attention for spiking neural networks》的分析已保存到 ./export\SNN\STSC-SNN_ Spatio-Temporal Synaptic Connection with temporal convolution and attention for spiking ne.md
2025-11-16 20:25:03,802 - INFO - root - 正在总结论文 34/100: HIRE-SNN: Harnessing the Inherent Robustness of Energy-Efficient Deep Spiking Neural Networks by Training with Crafted Input Noise
2025-11-16 20:25:16,926 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-16 20:25:16,931 - INFO - root - LLMClient: rate limit reached, sleeping 11.9s
2025-11-16 20:26:19,003 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-16 20:26:57,844 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-16 20:26:57,850 - INFO - root - 正在提取论文图片到目录: ./export\SNN\images\HIRE-SNN_ Harnessing the Inherent Robustness of Energy-Efficient Deep Spiking Neural Networks by Tra
2025-11-16 20:26:58,670 - INFO - root - 已保存图片 1/10：./export\SNN\images\HIRE-SNN_ Harnessing the Inherent Robustness of Energy-Efficient Deep Spiking Neural Networks by Tra\figure_1_page7.png
2025-11-16 20:26:58,731 - INFO - root - 已保存图片 2/10：./export\SNN\images\HIRE-SNN_ Harnessing the Inherent Robustness of Energy-Efficient Deep Spiking Neural Networks by Tra\figure_2_page8.png
2025-11-16 20:26:58,791 - INFO - root - 已保存图片 3/10：./export\SNN\images\HIRE-SNN_ Harnessing the Inherent Robustness of Energy-Efficient Deep Spiking Neural Networks by Tra\figure_3_page2.png
2025-11-16 20:26:58,853 - INFO - root - 已保存图片 4/10：./export\SNN\images\HIRE-SNN_ Harnessing the Inherent Robustness of Energy-Efficient Deep Spiking Neural Networks by Tra\figure_4_page7.png
2025-11-16 20:26:58,901 - INFO - root - 已保存图片 5/10：./export\SNN\images\HIRE-SNN_ Harnessing the Inherent Robustness of Energy-Efficient Deep Spiking Neural Networks by Tra\figure_5_page4.png
2025-11-16 20:26:58,949 - INFO - root - 已保存图片 6/10：./export\SNN\images\HIRE-SNN_ Harnessing the Inherent Robustness of Energy-Efficient Deep Spiking Neural Networks by Tra\figure_6_page8.png
2025-11-16 20:26:58,993 - INFO - root - 已保存图片 7/10：./export\SNN\images\HIRE-SNN_ Harnessing the Inherent Robustness of Energy-Efficient Deep Spiking Neural Networks by Tra\figure_7_page6.png
2025-11-16 20:26:59,042 - INFO - root - 已保存图片 8/10：./export\SNN\images\HIRE-SNN_ Harnessing the Inherent Robustness of Energy-Efficient Deep Spiking Neural Networks by Tra\figure_8_page3.png
2025-11-16 20:26:59,093 - INFO - root - 已保存图片 9/10：./export\SNN\images\HIRE-SNN_ Harnessing the Inherent Robustness of Energy-Efficient Deep Spiking Neural Networks by Tra\figure_9_page3.png
2025-11-16 20:26:59,162 - INFO - root - 已保存图片 10/10：./export\SNN\images\HIRE-SNN_ Harnessing the Inherent Robustness of Energy-Efficient Deep Spiking Neural Networks by Tra\figure_10_page1.png
2025-11-16 20:26:59,170 - INFO - root - 成功添加图片 1：./export\SNN\images\HIRE-SNN_ Harnessing the Inherent Robustness of Energy-Efficient Deep Spiking Neural Networks by Tra\figure_1_page7.png
2025-11-16 20:26:59,170 - INFO - root - 成功添加图片 2：./export\SNN\images\HIRE-SNN_ Harnessing the Inherent Robustness of Energy-Efficient Deep Spiking Neural Networks by Tra\figure_2_page8.png
2025-11-16 20:26:59,170 - INFO - root - 成功添加图片 3：./export\SNN\images\HIRE-SNN_ Harnessing the Inherent Robustness of Energy-Efficient Deep Spiking Neural Networks by Tra\figure_3_page2.png
2025-11-16 20:26:59,171 - INFO - root - 成功添加图片 4：./export\SNN\images\HIRE-SNN_ Harnessing the Inherent Robustness of Energy-Efficient Deep Spiking Neural Networks by Tra\figure_4_page7.png
2025-11-16 20:26:59,172 - INFO - root - 成功添加图片 5：./export\SNN\images\HIRE-SNN_ Harnessing the Inherent Robustness of Energy-Efficient Deep Spiking Neural Networks by Tra\figure_5_page4.png
2025-11-16 20:26:59,172 - INFO - root - 成功添加图片 6：./export\SNN\images\HIRE-SNN_ Harnessing the Inherent Robustness of Energy-Efficient Deep Spiking Neural Networks by Tra\figure_6_page8.png
2025-11-16 20:26:59,172 - INFO - root - 成功添加图片 7：./export\SNN\images\HIRE-SNN_ Harnessing the Inherent Robustness of Energy-Efficient Deep Spiking Neural Networks by Tra\figure_7_page6.png
2025-11-16 20:26:59,172 - INFO - root - 成功添加图片 8：./export\SNN\images\HIRE-SNN_ Harnessing the Inherent Robustness of Energy-Efficient Deep Spiking Neural Networks by Tra\figure_8_page3.png
2025-11-16 20:26:59,173 - INFO - root - 成功添加图片 9：./export\SNN\images\HIRE-SNN_ Harnessing the Inherent Robustness of Energy-Efficient Deep Spiking Neural Networks by Tra\figure_9_page3.png
2025-11-16 20:26:59,173 - INFO - root - 成功添加图片 10：./export\SNN\images\HIRE-SNN_ Harnessing the Inherent Robustness of Energy-Efficient Deep Spiking Neural Networks by Tra\figure_10_page1.png
2025-11-16 20:26:59,176 - INFO - root - 论文《HIRE-SNN: Harnessing the Inherent Robustness of Energy-Efficient Deep Spiking Neural Networks by Training with Crafted Input Noise》的分析已保存到 ./export\SNN\HIRE-SNN_ Harnessing the Inherent Robustness of Energy-Efficient Deep Spiking Neural Networks by Tra.md
2025-11-16 20:26:59,182 - INFO - root - 正在总结论文 35/100: Sub-mW Neuromorphic SNN audio processing applications with Rockpool and Xylo
2025-11-16 20:27:14,951 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-16 20:27:14,957 - INFO - root - LLMClient: rate limit reached, sleeping 4.1s
2025-11-16 20:28:13,284 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-16 20:28:43,181 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-16 20:28:43,191 - INFO - root - 正在提取论文图片到目录: ./export\SNN\images\Sub-mW Neuromorphic SNN audio processing applications with Rockpool and Xylo
2025-11-16 20:28:43,713 - INFO - root - 已保存图片 1/10：./export\SNN\images\Sub-mW Neuromorphic SNN audio processing applications with Rockpool and Xylo\figure_1_page6.jpeg
2025-11-16 20:28:43,895 - INFO - root - 已保存图片 2/10：./export\SNN\images\Sub-mW Neuromorphic SNN audio processing applications with Rockpool and Xylo\figure_2_page6.png
2025-11-16 20:28:43,937 - INFO - root - 已保存图片 3/10：./export\SNN\images\Sub-mW Neuromorphic SNN audio processing applications with Rockpool and Xylo\figure_3_page4.png
2025-11-16 20:28:43,974 - INFO - root - 已保存图片 4/10：./export\SNN\images\Sub-mW Neuromorphic SNN audio processing applications with Rockpool and Xylo\figure_4_page4.png
2025-11-16 20:28:44,015 - INFO - root - 已保存图片 5/10：./export\SNN\images\Sub-mW Neuromorphic SNN audio processing applications with Rockpool and Xylo\figure_5_page4.png
2025-11-16 20:28:44,057 - INFO - root - 已保存图片 6/10：./export\SNN\images\Sub-mW Neuromorphic SNN audio processing applications with Rockpool and Xylo\figure_6_page4.png
2025-11-16 20:28:44,095 - INFO - root - 已保存图片 7/10：./export\SNN\images\Sub-mW Neuromorphic SNN audio processing applications with Rockpool and Xylo\figure_7_page4.png
2025-11-16 20:28:44,133 - INFO - root - 已保存图片 8/10：./export\SNN\images\Sub-mW Neuromorphic SNN audio processing applications with Rockpool and Xylo\figure_8_page4.png
2025-11-16 20:28:44,175 - INFO - root - 已保存图片 9/10：./export\SNN\images\Sub-mW Neuromorphic SNN audio processing applications with Rockpool and Xylo\figure_9_page4.png
2025-11-16 20:28:44,217 - INFO - root - 已保存图片 10/10：./export\SNN\images\Sub-mW Neuromorphic SNN audio processing applications with Rockpool and Xylo\figure_10_page4.png
2025-11-16 20:28:44,219 - INFO - root - 成功添加图片 1：./export\SNN\images\Sub-mW Neuromorphic SNN audio processing applications with Rockpool and Xylo\figure_1_page6.jpeg
2025-11-16 20:28:44,220 - INFO - root - 成功添加图片 2：./export\SNN\images\Sub-mW Neuromorphic SNN audio processing applications with Rockpool and Xylo\figure_2_page6.png
2025-11-16 20:28:44,220 - INFO - root - 成功添加图片 3：./export\SNN\images\Sub-mW Neuromorphic SNN audio processing applications with Rockpool and Xylo\figure_3_page4.png
2025-11-16 20:28:44,220 - INFO - root - 成功添加图片 4：./export\SNN\images\Sub-mW Neuromorphic SNN audio processing applications with Rockpool and Xylo\figure_4_page4.png
2025-11-16 20:28:44,221 - INFO - root - 成功添加图片 5：./export\SNN\images\Sub-mW Neuromorphic SNN audio processing applications with Rockpool and Xylo\figure_5_page4.png
2025-11-16 20:28:44,221 - INFO - root - 成功添加图片 6：./export\SNN\images\Sub-mW Neuromorphic SNN audio processing applications with Rockpool and Xylo\figure_6_page4.png
2025-11-16 20:28:44,221 - INFO - root - 成功添加图片 7：./export\SNN\images\Sub-mW Neuromorphic SNN audio processing applications with Rockpool and Xylo\figure_7_page4.png
2025-11-16 20:28:44,221 - INFO - root - 成功添加图片 8：./export\SNN\images\Sub-mW Neuromorphic SNN audio processing applications with Rockpool and Xylo\figure_8_page4.png
2025-11-16 20:28:44,223 - INFO - root - 成功添加图片 9：./export\SNN\images\Sub-mW Neuromorphic SNN audio processing applications with Rockpool and Xylo\figure_9_page4.png
2025-11-16 20:28:44,223 - INFO - root - 成功添加图片 10：./export\SNN\images\Sub-mW Neuromorphic SNN audio processing applications with Rockpool and Xylo\figure_10_page4.png
2025-11-16 20:28:44,224 - INFO - root - 论文《Sub-mW Neuromorphic SNN audio processing applications with Rockpool and Xylo》的分析已保存到 ./export\SNN\Sub-mW Neuromorphic SNN audio processing applications with Rockpool and Xylo.md
2025-11-16 20:28:44,228 - INFO - root - 正在总结论文 36/100: ACE-SNN: Algorithm-Hardware Co-design of Energy-Efficient & Low-Latency Deep Spiking Neural Networks for 3D Image Recognition
2025-11-16 20:28:58,856 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-16 20:28:58,860 - INFO - root - LLMClient: rate limit reached, sleeping 14.4s
2025-11-16 20:30:07,387 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-16 20:30:44,596 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-16 20:30:44,602 - INFO - root - 正在提取论文图片到目录: ./export\SNN\images\ACE-SNN_ Algorithm-Hardware Co-design of Energy-Efficient & Low-Latency Deep Spiking Neural Networks
2025-11-16 20:30:44,921 - INFO - root - 已保存图片 1/10：./export\SNN\images\ACE-SNN_ Algorithm-Hardware Co-design of Energy-Efficient & Low-Latency Deep Spiking Neural Networks\figure_1_page15.png
2025-11-16 20:30:45,025 - INFO - root - 已保存图片 2/10：./export\SNN\images\ACE-SNN_ Algorithm-Hardware Co-design of Energy-Efficient & Low-Latency Deep Spiking Neural Networks\figure_2_page15.jpeg
2025-11-16 20:30:45,108 - INFO - root - 已保存图片 3/10：./export\SNN\images\ACE-SNN_ Algorithm-Hardware Co-design of Energy-Efficient & Low-Latency Deep Spiking Neural Networks\figure_3_page7.jpeg
2025-11-16 20:30:45,154 - INFO - root - 已保存图片 4/10：./export\SNN\images\ACE-SNN_ Algorithm-Hardware Co-design of Energy-Efficient & Low-Latency Deep Spiking Neural Networks\figure_4_page11.jpeg
2025-11-16 20:30:45,199 - INFO - root - 已保存图片 5/10：./export\SNN\images\ACE-SNN_ Algorithm-Hardware Co-design of Energy-Efficient & Low-Latency Deep Spiking Neural Networks\figure_5_page8.jpeg
2025-11-16 20:30:45,233 - INFO - root - 已保存图片 6/10：./export\SNN\images\ACE-SNN_ Algorithm-Hardware Co-design of Energy-Efficient & Low-Latency Deep Spiking Neural Networks\figure_6_page13.jpeg
2025-11-16 20:30:45,273 - INFO - root - 已保存图片 7/10：./export\SNN\images\ACE-SNN_ Algorithm-Hardware Co-design of Energy-Efficient & Low-Latency Deep Spiking Neural Networks\figure_7_page9.jpeg
2025-11-16 20:30:45,306 - INFO - root - 已保存图片 8/10：./export\SNN\images\ACE-SNN_ Algorithm-Hardware Co-design of Energy-Efficient & Low-Latency Deep Spiking Neural Networks\figure_8_page3.jpeg
2025-11-16 20:30:45,337 - INFO - root - 已保存图片 9/10：./export\SNN\images\ACE-SNN_ Algorithm-Hardware Co-design of Energy-Efficient & Low-Latency Deep Spiking Neural Networks\figure_9_page17.jpeg
2025-11-16 20:30:45,366 - INFO - root - 已保存图片 10/10：./export\SNN\images\ACE-SNN_ Algorithm-Hardware Co-design of Energy-Efficient & Low-Latency Deep Spiking Neural Networks\figure_10_page10.jpeg
2025-11-16 20:30:45,372 - INFO - root - 成功添加图片 1：./export\SNN\images\ACE-SNN_ Algorithm-Hardware Co-design of Energy-Efficient & Low-Latency Deep Spiking Neural Networks\figure_1_page15.png
2025-11-16 20:30:45,374 - INFO - root - 成功添加图片 2：./export\SNN\images\ACE-SNN_ Algorithm-Hardware Co-design of Energy-Efficient & Low-Latency Deep Spiking Neural Networks\figure_2_page15.jpeg
2025-11-16 20:30:45,375 - INFO - root - 成功添加图片 3：./export\SNN\images\ACE-SNN_ Algorithm-Hardware Co-design of Energy-Efficient & Low-Latency Deep Spiking Neural Networks\figure_3_page7.jpeg
2025-11-16 20:30:45,376 - INFO - root - 成功添加图片 4：./export\SNN\images\ACE-SNN_ Algorithm-Hardware Co-design of Energy-Efficient & Low-Latency Deep Spiking Neural Networks\figure_4_page11.jpeg
2025-11-16 20:30:45,376 - INFO - root - 成功添加图片 5：./export\SNN\images\ACE-SNN_ Algorithm-Hardware Co-design of Energy-Efficient & Low-Latency Deep Spiking Neural Networks\figure_5_page8.jpeg
2025-11-16 20:30:45,376 - INFO - root - 成功添加图片 6：./export\SNN\images\ACE-SNN_ Algorithm-Hardware Co-design of Energy-Efficient & Low-Latency Deep Spiking Neural Networks\figure_6_page13.jpeg
2025-11-16 20:30:45,376 - INFO - root - 成功添加图片 7：./export\SNN\images\ACE-SNN_ Algorithm-Hardware Co-design of Energy-Efficient & Low-Latency Deep Spiking Neural Networks\figure_7_page9.jpeg
2025-11-16 20:30:45,377 - INFO - root - 成功添加图片 8：./export\SNN\images\ACE-SNN_ Algorithm-Hardware Co-design of Energy-Efficient & Low-Latency Deep Spiking Neural Networks\figure_8_page3.jpeg
2025-11-16 20:30:45,377 - INFO - root - 成功添加图片 9：./export\SNN\images\ACE-SNN_ Algorithm-Hardware Co-design of Energy-Efficient & Low-Latency Deep Spiking Neural Networks\figure_9_page17.jpeg
2025-11-16 20:30:45,377 - INFO - root - 成功添加图片 10：./export\SNN\images\ACE-SNN_ Algorithm-Hardware Co-design of Energy-Efficient & Low-Latency Deep Spiking Neural Networks\figure_10_page10.jpeg
2025-11-16 20:30:45,380 - INFO - root - 论文《ACE-SNN: Algorithm-Hardware Co-design of Energy-Efficient & Low-Latency Deep Spiking Neural Networks for 3D Image Recognition》的分析已保存到 ./export\SNN\ACE-SNN_ Algorithm-Hardware Co-design of Energy-Efficient & Low-Latency Deep Spiking Neural Networks.md
2025-11-16 20:30:45,384 - INFO - root - 跳过总结 (手动下载): SNN-RAT: Robustness-enhanced Spiking Neural Network through Regularized Adversarial Training
2025-11-16 20:30:45,384 - INFO - root - 跳过总结 (手动下载): An Energy Efficient STDP-Based SNN Architecture With On-Chip Learning
2025-11-16 20:30:45,385 - INFO - root - 跳过总结 (手动下载): Quantum Tunneling Based Ultra-Compact and Energy Efficient Spiking Neuron Enables Hardware SNN
2025-11-16 20:30:45,385 - INFO - root - 正在总结论文 40/100: Spiking Neural Network (SNN) With Memristor Synapses Having Non-linear Weight Update
2025-11-16 20:30:56,798 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-16 20:30:56,803 - INFO - root - LLMClient: rate limit reached, sleeping 10.6s
2025-11-16 20:32:00,364 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-16 20:32:32,062 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-16 20:32:32,072 - INFO - root - 正在提取论文图片到目录: ./export\SNN\images\Spiking Neural Network (SNN) With Memristor Synapses Having Non-linear Weight Update
2025-11-16 20:32:32,287 - INFO - root - 已保存图片 1/10：./export\SNN\images\Spiking Neural Network (SNN) With Memristor Synapses Having Non-linear Weight Update\figure_1_page6.jpeg
2025-11-16 20:32:32,344 - INFO - root - 已保存图片 2/10：./export\SNN\images\Spiking Neural Network (SNN) With Memristor Synapses Having Non-linear Weight Update\figure_2_page6.jpeg
2025-11-16 20:32:32,400 - INFO - root - 已保存图片 3/10：./export\SNN\images\Spiking Neural Network (SNN) With Memristor Synapses Having Non-linear Weight Update\figure_3_page3.jpeg
2025-11-16 20:32:32,480 - INFO - root - 已保存图片 4/10：./export\SNN\images\Spiking Neural Network (SNN) With Memristor Synapses Having Non-linear Weight Update\figure_4_page7.png
2025-11-16 20:32:32,510 - INFO - root - 已保存图片 5/10：./export\SNN\images\Spiking Neural Network (SNN) With Memristor Synapses Having Non-linear Weight Update\figure_5_page5.jpeg
2025-11-16 20:32:32,537 - INFO - root - 已保存图片 6/10：./export\SNN\images\Spiking Neural Network (SNN) With Memristor Synapses Having Non-linear Weight Update\figure_6_page5.jpeg
2025-11-16 20:32:32,571 - INFO - root - 已保存图片 7/10：./export\SNN\images\Spiking Neural Network (SNN) With Memristor Synapses Having Non-linear Weight Update\figure_7_page7.jpeg
2025-11-16 20:32:32,617 - INFO - root - 已保存图片 8/10：./export\SNN\images\Spiking Neural Network (SNN) With Memristor Synapses Having Non-linear Weight Update\figure_8_page1.png
2025-11-16 20:32:32,621 - INFO - root - 成功添加图片 1：./export\SNN\images\Spiking Neural Network (SNN) With Memristor Synapses Having Non-linear Weight Update\figure_1_page6.jpeg
2025-11-16 20:32:32,621 - INFO - root - 成功添加图片 2：./export\SNN\images\Spiking Neural Network (SNN) With Memristor Synapses Having Non-linear Weight Update\figure_2_page6.jpeg
2025-11-16 20:32:32,622 - INFO - root - 成功添加图片 3：./export\SNN\images\Spiking Neural Network (SNN) With Memristor Synapses Having Non-linear Weight Update\figure_3_page3.jpeg
2025-11-16 20:32:32,622 - INFO - root - 成功添加图片 4：./export\SNN\images\Spiking Neural Network (SNN) With Memristor Synapses Having Non-linear Weight Update\figure_4_page7.png
2025-11-16 20:32:32,622 - INFO - root - 成功添加图片 5：./export\SNN\images\Spiking Neural Network (SNN) With Memristor Synapses Having Non-linear Weight Update\figure_5_page5.jpeg
2025-11-16 20:32:32,624 - INFO - root - 成功添加图片 6：./export\SNN\images\Spiking Neural Network (SNN) With Memristor Synapses Having Non-linear Weight Update\figure_6_page5.jpeg
2025-11-16 20:32:32,624 - INFO - root - 成功添加图片 7：./export\SNN\images\Spiking Neural Network (SNN) With Memristor Synapses Having Non-linear Weight Update\figure_7_page7.jpeg
2025-11-16 20:32:32,624 - INFO - root - 成功添加图片 8：./export\SNN\images\Spiking Neural Network (SNN) With Memristor Synapses Having Non-linear Weight Update\figure_8_page1.png
2025-11-16 20:32:32,626 - INFO - root - 论文《Spiking Neural Network (SNN) With Memristor Synapses Having Non-linear Weight Update》的分析已保存到 ./export\SNN\Spiking Neural Network (SNN) With Memristor Synapses Having Non-linear Weight Update.md
2025-11-16 20:32:32,633 - INFO - root - 正在总结论文 41/100: Towards Lossless ANN-SNN Conversion under Ultra-Low Latency with Dual-Phase Optimization
2025-11-16 20:32:48,719 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-16 20:32:48,722 - INFO - root - LLMClient: rate limit reached, sleeping 11.6s
2025-11-16 20:33:57,522 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-16 20:34:33,195 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-16 20:34:33,202 - INFO - root - 正在提取论文图片到目录: ./export\SNN\images\Towards Lossless ANN-SNN Conversion under Ultra-Low Latency with Dual-Phase Optimization
2025-11-16 20:34:33,358 - INFO - root - 已保存图片 1/10：./export\SNN\images\Towards Lossless ANN-SNN Conversion under Ultra-Low Latency with Dual-Phase Optimization\figure_1_page12.jpeg
2025-11-16 20:34:33,436 - INFO - root - 已保存图片 2/10：./export\SNN\images\Towards Lossless ANN-SNN Conversion under Ultra-Low Latency with Dual-Phase Optimization\figure_2_page12.jpeg
2025-11-16 20:34:33,513 - INFO - root - 已保存图片 3/10：./export\SNN\images\Towards Lossless ANN-SNN Conversion under Ultra-Low Latency with Dual-Phase Optimization\figure_3_page12.jpeg
2025-11-16 20:34:33,570 - INFO - root - 已保存图片 4/10：./export\SNN\images\Towards Lossless ANN-SNN Conversion under Ultra-Low Latency with Dual-Phase Optimization\figure_4_page12.jpeg
2025-11-16 20:34:33,631 - INFO - root - 已保存图片 5/10：./export\SNN\images\Towards Lossless ANN-SNN Conversion under Ultra-Low Latency with Dual-Phase Optimization\figure_5_page12.jpeg
2025-11-16 20:34:33,689 - INFO - root - 已保存图片 6/10：./export\SNN\images\Towards Lossless ANN-SNN Conversion under Ultra-Low Latency with Dual-Phase Optimization\figure_6_page12.jpeg
2025-11-16 20:34:33,749 - INFO - root - 已保存图片 7/10：./export\SNN\images\Towards Lossless ANN-SNN Conversion under Ultra-Low Latency with Dual-Phase Optimization\figure_7_page12.jpeg
2025-11-16 20:34:33,809 - INFO - root - 已保存图片 8/10：./export\SNN\images\Towards Lossless ANN-SNN Conversion under Ultra-Low Latency with Dual-Phase Optimization\figure_8_page12.jpeg
2025-11-16 20:34:33,869 - INFO - root - 已保存图片 9/10：./export\SNN\images\Towards Lossless ANN-SNN Conversion under Ultra-Low Latency with Dual-Phase Optimization\figure_9_page12.jpeg
2025-11-16 20:34:33,928 - INFO - root - 已保存图片 10/10：./export\SNN\images\Towards Lossless ANN-SNN Conversion under Ultra-Low Latency with Dual-Phase Optimization\figure_10_page12.jpeg
2025-11-16 20:34:33,934 - INFO - root - 成功添加图片 1：./export\SNN\images\Towards Lossless ANN-SNN Conversion under Ultra-Low Latency with Dual-Phase Optimization\figure_1_page12.jpeg
2025-11-16 20:34:33,935 - INFO - root - 成功添加图片 2：./export\SNN\images\Towards Lossless ANN-SNN Conversion under Ultra-Low Latency with Dual-Phase Optimization\figure_2_page12.jpeg
2025-11-16 20:34:33,935 - INFO - root - 成功添加图片 3：./export\SNN\images\Towards Lossless ANN-SNN Conversion under Ultra-Low Latency with Dual-Phase Optimization\figure_3_page12.jpeg
2025-11-16 20:34:33,936 - INFO - root - 成功添加图片 4：./export\SNN\images\Towards Lossless ANN-SNN Conversion under Ultra-Low Latency with Dual-Phase Optimization\figure_4_page12.jpeg
2025-11-16 20:34:33,937 - INFO - root - 成功添加图片 5：./export\SNN\images\Towards Lossless ANN-SNN Conversion under Ultra-Low Latency with Dual-Phase Optimization\figure_5_page12.jpeg
2025-11-16 20:34:33,938 - INFO - root - 成功添加图片 6：./export\SNN\images\Towards Lossless ANN-SNN Conversion under Ultra-Low Latency with Dual-Phase Optimization\figure_6_page12.jpeg
2025-11-16 20:34:33,938 - INFO - root - 成功添加图片 7：./export\SNN\images\Towards Lossless ANN-SNN Conversion under Ultra-Low Latency with Dual-Phase Optimization\figure_7_page12.jpeg
2025-11-16 20:34:33,938 - INFO - root - 成功添加图片 8：./export\SNN\images\Towards Lossless ANN-SNN Conversion under Ultra-Low Latency with Dual-Phase Optimization\figure_8_page12.jpeg
2025-11-16 20:34:33,941 - INFO - root - 成功添加图片 9：./export\SNN\images\Towards Lossless ANN-SNN Conversion under Ultra-Low Latency with Dual-Phase Optimization\figure_9_page12.jpeg
2025-11-16 20:34:33,941 - INFO - root - 成功添加图片 10：./export\SNN\images\Towards Lossless ANN-SNN Conversion under Ultra-Low Latency with Dual-Phase Optimization\figure_10_page12.jpeg
2025-11-16 20:34:33,943 - INFO - root - 论文《Towards Lossless ANN-SNN Conversion under Ultra-Low Latency with Dual-Phase Optimization》的分析已保存到 ./export\SNN\Towards Lossless ANN-SNN Conversion under Ultra-Low Latency with Dual-Phase Optimization.md
2025-11-16 20:34:33,947 - INFO - root - 跳过总结 (手动下载): Skipper: Enabling efficient SNN training through activation-checkpointing and time-skipping
2025-11-16 20:34:33,948 - INFO - root - 正在总结论文 43/100: DSNN: A DenseNet-Based SNN for Explainable Brain Disease Classification
2025-11-16 20:34:46,077 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-16 20:34:46,080 - INFO - root - LLMClient: rate limit reached, sleeping 11.4s
2025-11-16 20:35:54,321 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-16 20:36:24,884 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-16 20:36:24,888 - INFO - root - 正在提取论文图片到目录: ./export\SNN\images\DSNN_ A DenseNet-Based SNN for Explainable Brain Disease Classification
2025-11-16 20:36:25,898 - INFO - root - 已保存图片 1/10：./export\SNN\images\DSNN_ A DenseNet-Based SNN for Explainable Brain Disease Classification\figure_1_page6.png
2025-11-16 20:36:26,057 - INFO - root - 已保存图片 2/10：./export\SNN\images\DSNN_ A DenseNet-Based SNN for Explainable Brain Disease Classification\figure_2_page11.png
2025-11-16 20:36:26,125 - INFO - root - 已保存图片 3/10：./export\SNN\images\DSNN_ A DenseNet-Based SNN for Explainable Brain Disease Classification\figure_3_page10.jpeg
2025-11-16 20:36:26,213 - INFO - root - 已保存图片 4/10：./export\SNN\images\DSNN_ A DenseNet-Based SNN for Explainable Brain Disease Classification\figure_4_page7.png
2025-11-16 20:36:26,286 - INFO - root - 已保存图片 5/10：./export\SNN\images\DSNN_ A DenseNet-Based SNN for Explainable Brain Disease Classification\figure_5_page12.jpeg
2025-11-16 20:36:26,386 - INFO - root - 已保存图片 6/10：./export\SNN\images\DSNN_ A DenseNet-Based SNN for Explainable Brain Disease Classification\figure_6_page4.png
2025-11-16 20:36:26,478 - INFO - root - 已保存图片 7/10：./export\SNN\images\DSNN_ A DenseNet-Based SNN for Explainable Brain Disease Classification\figure_7_page8.png
2025-11-16 20:36:26,535 - INFO - root - 已保存图片 8/10：./export\SNN\images\DSNN_ A DenseNet-Based SNN for Explainable Brain Disease Classification\figure_8_page10.png
2025-11-16 20:36:26,598 - INFO - root - 已保存图片 9/10：./export\SNN\images\DSNN_ A DenseNet-Based SNN for Explainable Brain Disease Classification\figure_9_page7.png
2025-11-16 20:36:26,602 - INFO - root - 成功添加图片 1：./export\SNN\images\DSNN_ A DenseNet-Based SNN for Explainable Brain Disease Classification\figure_1_page6.png
2025-11-16 20:36:26,602 - INFO - root - 成功添加图片 2：./export\SNN\images\DSNN_ A DenseNet-Based SNN for Explainable Brain Disease Classification\figure_2_page11.png
2025-11-16 20:36:26,603 - INFO - root - 成功添加图片 3：./export\SNN\images\DSNN_ A DenseNet-Based SNN for Explainable Brain Disease Classification\figure_3_page10.jpeg
2025-11-16 20:36:26,603 - INFO - root - 成功添加图片 4：./export\SNN\images\DSNN_ A DenseNet-Based SNN for Explainable Brain Disease Classification\figure_4_page7.png
2025-11-16 20:36:26,604 - INFO - root - 成功添加图片 5：./export\SNN\images\DSNN_ A DenseNet-Based SNN for Explainable Brain Disease Classification\figure_5_page12.jpeg
2025-11-16 20:36:26,604 - INFO - root - 成功添加图片 6：./export\SNN\images\DSNN_ A DenseNet-Based SNN for Explainable Brain Disease Classification\figure_6_page4.png
2025-11-16 20:36:26,605 - INFO - root - 成功添加图片 7：./export\SNN\images\DSNN_ A DenseNet-Based SNN for Explainable Brain Disease Classification\figure_7_page8.png
2025-11-16 20:36:26,605 - INFO - root - 成功添加图片 8：./export\SNN\images\DSNN_ A DenseNet-Based SNN for Explainable Brain Disease Classification\figure_8_page10.png
2025-11-16 20:36:26,605 - INFO - root - 成功添加图片 9：./export\SNN\images\DSNN_ A DenseNet-Based SNN for Explainable Brain Disease Classification\figure_9_page7.png
2025-11-16 20:36:26,608 - INFO - root - 论文《DSNN: A DenseNet-Based SNN for Explainable Brain Disease Classification》的分析已保存到 ./export\SNN\DSNN_ A DenseNet-Based SNN for Explainable Brain Disease Classification.md
2025-11-16 20:36:26,615 - INFO - root - 正在总结论文 44/100: Energy-Efficient SNN Implementation Using RRAM-Based Computation In-Memory (CIM)
2025-11-16 20:36:35,396 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-16 20:36:35,399 - INFO - root - LLMClient: rate limit reached, sleeping 18.9s
2025-11-16 20:37:56,345 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-16 20:38:34,432 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-16 20:38:34,439 - INFO - root - 正在提取论文图片到目录: ./export\SNN\images\Energy-Efficient SNN Implementation Using RRAM-Based Computation In-Memory (CIM)
2025-11-16 20:38:34,506 - INFO - root - 论文《Energy-Efficient SNN Implementation Using RRAM-Based Computation In-Memory (CIM)》的分析已保存到 ./export\SNN\Energy-Efficient SNN Implementation Using RRAM-Based Computation In-Memory (CIM).md
2025-11-16 20:38:34,509 - INFO - root - 跳过总结 (手动下载): Ultralow Power Always-On Intelligent and Connected SNN-Based System for Multimedia IoT-Enabled Applications
2025-11-16 20:38:34,510 - INFO - root - 正在总结论文 46/100: mlGeNN: accelerating SNN inference using GPU-enabled neural networks
2025-11-16 20:38:47,003 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-16 20:38:47,009 - INFO - root - LLMClient: rate limit reached, sleeping 9.3s
2025-11-16 20:39:49,178 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-16 20:40:23,500 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-16 20:40:23,505 - INFO - root - 正在提取论文图片到目录: ./export\SNN\images\mlGeNN_ accelerating SNN inference using GPU-enabled neural networks
2025-11-16 20:40:23,522 - ERROR - root - 提取图片失败 D:\ChatPaper\api_downloads\SNN\mlGeNN_ accelerating SNN inference using GPU-enabled neural networks.pdf: Failed to open file 'D:\\ChatPaper\\api_downloads\\SNN\\mlGeNN_ accelerating SNN inference using GPU-enabled neural networks.pdf'.
2025-11-16 20:40:23,528 - INFO - root - 论文《mlGeNN: accelerating SNN inference using GPU-enabled neural networks》的分析已保存到 ./export\SNN\mlGeNN_ accelerating SNN inference using GPU-enabled neural networks.md
2025-11-16 20:40:23,533 - INFO - root - 跳过总结 (手动下载): Hybrid SNN-ANN: Energy-Efficient Classification and Object Detection for Event-Based Vision
2025-11-16 20:40:23,536 - INFO - root - 跳过总结 (手动下载): A Neuromorphic Model for Image Recognition using SNN
2025-11-16 20:40:23,539 - INFO - root - 正在总结论文 49/100: Global 
Λ
-hyperon polarization in 
Au+Au
 collisions at 
sNN=3 GeV
2025-11-16 20:40:42,881 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-16 20:40:42,885 - INFO - root - LLMClient: rate limit reached, sleeping 6.3s
2025-11-16 20:41:52,363 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-16 20:42:21,815 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-16 20:42:21,819 - INFO - root - 正在提取论文图片到目录: ./export\SNN\images\Global Λ -hyperon polarization in Au+Au collisions at sNN=3 GeV
2025-11-16 20:42:21,854 - INFO - root - 论文《Global 
Λ
-hyperon polarization in 
Au+Au
 collisions at 
sNN=3 GeV》的分析已保存到 ./export\SNN\Global Λ -hyperon polarization in Au+Au collisions at sNN=3 GeV.md
2025-11-16 20:42:21,861 - INFO - root - 跳过总结 (手动下载): Comprehensive SNN Compression Using ADMM Optimization and Activity Regularization
2025-11-16 20:42:21,862 - INFO - root - 跳过总结 (手动下载): Exclusive dimuon production in ultraperipheral Pb + Pb collisions at √ sNN = 5 . 02 TeV with ATLAS
2025-11-16 20:42:21,863 - INFO - root - 跳过总结 (手动下载): DCT-SNN: Using DCT to Distribute Spatial Information over Time for Low-Latency Spiking Neural Networks
2025-11-16 20:42:21,863 - INFO - root - 跳过总结 (手动下载): Artificial Neural Network (ANN) to Spiking Neural Network (SNN) Converters Based on Diffusive Memristors
2025-11-16 20:42:21,864 - INFO - root - 正在总结论文 54/100: Jet properties in PbPb and pp collisions at sNN=5.02$$ \sqrt{s_{\mathrm{N}\;\mathrm{N}}}=5.02 $$ TeV
2025-11-16 20:42:34,081 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-16 20:42:34,086 - INFO - root - LLMClient: rate limit reached, sleeping 18.3s
2025-11-16 20:43:50,952 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-16 20:44:26,475 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-16 20:44:26,482 - INFO - root - 正在提取论文图片到目录: ./export\SNN\images\Jet properties in PbPb and pp collisions at sNN=5.02$$ _sqrt{s_{_mathrm{N}_;_mathrm{N}}}=5.02 $$ TeV
2025-11-16 20:44:26,629 - INFO - root - 已保存图片 1/10：./export\SNN\images\Jet properties in PbPb and pp collisions at sNN=5.02$$ _sqrt{s_{_mathrm{N}_;_mathrm{N}}}=5.02 $$ TeV\figure_1_page1.png
2025-11-16 20:44:26,664 - INFO - root - 已保存图片 2/10：./export\SNN\images\Jet properties in PbPb and pp collisions at sNN=5.02$$ _sqrt{s_{_mathrm{N}_;_mathrm{N}}}=5.02 $$ TeV\figure_2_page1.png
2025-11-16 20:44:26,665 - INFO - root - 成功添加图片 1：./export\SNN\images\Jet properties in PbPb and pp collisions at sNN=5.02$$ _sqrt{s_{_mathrm{N}_;_mathrm{N}}}=5.02 $$ TeV\figure_1_page1.png
2025-11-16 20:44:26,666 - INFO - root - 成功添加图片 2：./export\SNN\images\Jet properties in PbPb and pp collisions at sNN=5.02$$ _sqrt{s_{_mathrm{N}_;_mathrm{N}}}=5.02 $$ TeV\figure_2_page1.png
2025-11-16 20:44:26,669 - INFO - root - 论文《Jet properties in PbPb and pp collisions at sNN=5.02$$ \sqrt{s_{\mathrm{N}\;\mathrm{N}}}=5.02 $$ TeV》的分析已保存到 ./export\SNN\Jet properties in PbPb and pp collisions at sNN=5.02$$ _sqrt{s_{_mathrm{N}_;_mathrm{N}}}=5.02 $$ TeV.md
2025-11-16 20:44:26,674 - INFO - root - 正在总结论文 55/100: Flow and interferometry results from 
Au+Au
 collisions at 
sNN=4.5
 GeV
2025-11-16 20:44:45,884 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-16 20:44:45,887 - INFO - root - LLMClient: rate limit reached, sleeping 5.1s
2025-11-16 20:45:43,671 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-16 20:46:26,372 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-16 20:46:26,380 - INFO - root - 正在提取论文图片到目录: ./export\SNN\images\Flow and interferometry results from Au+Au collisions at sNN=4.5 GeV
2025-11-16 20:46:27,173 - INFO - root - 已保存图片 1/10：./export\SNN\images\Flow and interferometry results from Au+Au collisions at sNN=4.5 GeV\figure_1_page4.png
2025-11-16 20:46:27,253 - INFO - root - 已保存图片 2/10：./export\SNN\images\Flow and interferometry results from Au+Au collisions at sNN=4.5 GeV\figure_2_page4.png
2025-11-16 20:46:27,363 - INFO - root - 已保存图片 3/10：./export\SNN\images\Flow and interferometry results from Au+Au collisions at sNN=4.5 GeV\figure_3_page5.png
2025-11-16 20:46:27,512 - INFO - root - 已保存图片 4/10：./export\SNN\images\Flow and interferometry results from Au+Au collisions at sNN=4.5 GeV\figure_4_page6.png
2025-11-16 20:46:27,800 - INFO - root - 已保存图片 5/10：./export\SNN\images\Flow and interferometry results from Au+Au collisions at sNN=4.5 GeV\figure_5_page6.png
2025-11-16 20:46:28,025 - INFO - root - 已保存图片 6/10：./export\SNN\images\Flow and interferometry results from Au+Au collisions at sNN=4.5 GeV\figure_6_page3.png
2025-11-16 20:46:28,028 - INFO - root - 成功添加图片 1：./export\SNN\images\Flow and interferometry results from Au+Au collisions at sNN=4.5 GeV\figure_1_page4.png
2025-11-16 20:46:28,029 - INFO - root - 成功添加图片 2：./export\SNN\images\Flow and interferometry results from Au+Au collisions at sNN=4.5 GeV\figure_2_page4.png
2025-11-16 20:46:28,029 - INFO - root - 成功添加图片 3：./export\SNN\images\Flow and interferometry results from Au+Au collisions at sNN=4.5 GeV\figure_3_page5.png
2025-11-16 20:46:28,029 - INFO - root - 成功添加图片 4：./export\SNN\images\Flow and interferometry results from Au+Au collisions at sNN=4.5 GeV\figure_4_page6.png
2025-11-16 20:46:28,029 - INFO - root - 成功添加图片 5：./export\SNN\images\Flow and interferometry results from Au+Au collisions at sNN=4.5 GeV\figure_5_page6.png
2025-11-16 20:46:28,030 - INFO - root - 成功添加图片 6：./export\SNN\images\Flow and interferometry results from Au+Au collisions at sNN=4.5 GeV\figure_6_page3.png
2025-11-16 20:46:28,032 - INFO - root - 论文《Flow and interferometry results from 
Au+Au
 collisions at 
sNN=4.5
 GeV》的分析已保存到 ./export\SNN\Flow and interferometry results from Au+Au collisions at sNN=4.5 GeV.md
2025-11-16 20:46:28,036 - INFO - root - 跳过总结 (手动下载): Proton number cumulants and correlation functions in Au-Au collisions at 
sNN=7.7
–200 GeV from hydrodynamics
2025-11-16 20:46:28,037 - INFO - root - 正在总结论文 57/100: Balancing the Cost and Performance Trade-Offs in SNN Processors
2025-11-16 20:46:39,105 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-16 20:46:39,110 - INFO - root - LLMClient: rate limit reached, sleeping 4.6s
2025-11-16 20:47:33,592 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-16 20:48:11,238 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-16 20:48:11,244 - INFO - root - 正在提取论文图片到目录: ./export\SNN\images\Balancing the Cost and Performance Trade-Offs in SNN Processors
2025-11-16 20:48:11,262 - INFO - root - 论文《Balancing the Cost and Performance Trade-Offs in SNN Processors》的分析已保存到 ./export\SNN\Balancing the Cost and Performance Trade-Offs in SNN Processors.md
2025-11-16 20:48:11,269 - INFO - root - 跳过总结 (手动下载): A review of SNN implementation on FPGA
2025-11-16 20:48:11,271 - INFO - root - 正在总结论文 59/100: Global polarization of 
Λ
 hyperons in Au + Au collisions at 
sNN=200
 GeV
2025-11-16 20:48:27,366 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-16 20:48:27,367 - INFO - root - LLMClient: rate limit reached, sleeping 6.2s
2025-11-16 20:49:35,616 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-16 20:50:16,578 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-16 20:50:16,582 - INFO - root - 正在提取论文图片到目录: ./export\SNN\images\Global polarization of Λ hyperons in Au + Au collisions at sNN=200 GeV
2025-11-16 20:50:16,623 - INFO - root - 已保存图片 1/10：./export\SNN\images\Global polarization of Λ hyperons in Au + Au collisions at sNN=200 GeV\figure_1_page1.png
2025-11-16 20:50:16,694 - INFO - root - 已保存图片 2/10：./export\SNN\images\Global polarization of Λ hyperons in Au + Au collisions at sNN=200 GeV\figure_2_page1.png
2025-11-16 20:50:16,696 - INFO - root - 成功添加图片 1：./export\SNN\images\Global polarization of Λ hyperons in Au + Au collisions at sNN=200 GeV\figure_1_page1.png
2025-11-16 20:50:16,696 - INFO - root - 成功添加图片 2：./export\SNN\images\Global polarization of Λ hyperons in Au + Au collisions at sNN=200 GeV\figure_2_page1.png
2025-11-16 20:50:16,698 - INFO - root - 论文《Global polarization of 
Λ
 hyperons in Au + Au collisions at 
sNN=200
 GeV》的分析已保存到 ./export\SNN\Global polarization of Λ hyperons in Au + Au collisions at sNN=200 GeV.md
2025-11-16 20:50:16,701 - INFO - root - 跳过总结 (手动下载): A 28nm Configurable Asynchronous SNN Accelerator with Energy-Efficient Learning
2025-11-16 20:50:16,702 - INFO - root - 跳过总结 (手动下载): Measurements of inclusive jet spectra in pp and central Pb-Pb collisions at sNN =5.02 TeV
2025-11-16 20:50:16,703 - INFO - root - 跳过总结 (手动下载): Production of charged pions, kaons, and (anti-)protons in Pb-Pb and inelastic pp collisions at √sNN = 5.02 TeV
2025-11-16 20:50:16,703 - INFO - root - 跳过总结 (手动下载): Gesture-SNN: Co-optimizing accuracy, latency and energy of SNNs for neuromorphic vision sensors
2025-11-16 20:50:16,704 - INFO - root - 正在总结论文 64/100: R-SNN: An Analysis and Design Methodology for Robustifying Spiking Neural Networks against Adversarial Attacks through Noise Filters for Dynamic Vision Sensors
2025-11-16 20:50:29,323 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-16 20:50:29,324 - INFO - root - LLMClient: rate limit reached, sleeping 6.3s
2025-11-16 20:51:30,811 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-16 20:52:06,864 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-16 20:52:06,865 - INFO - root - 正在提取论文图片到目录: ./export\SNN\images\R-SNN_ An Analysis and Design Methodology for Robustifying Spiking Neural Networks against Adversari
2025-11-16 20:52:07,082 - INFO - root - 已保存图片 1/10：./export\SNN\images\R-SNN_ An Analysis and Design Methodology for Robustifying Spiking Neural Networks against Adversari\figure_1_page3.png
2025-11-16 20:52:07,110 - INFO - root - 已保存图片 2/10：./export\SNN\images\R-SNN_ An Analysis and Design Methodology for Robustifying Spiking Neural Networks against Adversari\figure_2_page2.jpeg
2025-11-16 20:52:07,139 - INFO - root - 已保存图片 3/10：./export\SNN\images\R-SNN_ An Analysis and Design Methodology for Robustifying Spiking Neural Networks against Adversari\figure_3_page2.jpeg
2025-11-16 20:52:07,210 - INFO - root - 已保存图片 4/10：./export\SNN\images\R-SNN_ An Analysis and Design Methodology for Robustifying Spiking Neural Networks against Adversari\figure_4_page4.png
2025-11-16 20:52:07,234 - INFO - root - 已保存图片 5/10：./export\SNN\images\R-SNN_ An Analysis and Design Methodology for Robustifying Spiking Neural Networks against Adversari\figure_5_page2.jpeg
2025-11-16 20:52:07,301 - INFO - root - 已保存图片 6/10：./export\SNN\images\R-SNN_ An Analysis and Design Methodology for Robustifying Spiking Neural Networks against Adversari\figure_6_page7.png
2025-11-16 20:52:07,360 - INFO - root - 已保存图片 7/10：./export\SNN\images\R-SNN_ An Analysis and Design Methodology for Robustifying Spiking Neural Networks against Adversari\figure_7_page7.png
2025-11-16 20:52:07,482 - INFO - root - 已保存图片 8/10：./export\SNN\images\R-SNN_ An Analysis and Design Methodology for Robustifying Spiking Neural Networks against Adversari\figure_8_page7.png
2025-11-16 20:52:07,569 - INFO - root - 已保存图片 9/10：./export\SNN\images\R-SNN_ An Analysis and Design Methodology for Robustifying Spiking Neural Networks against Adversari\figure_9_page7.png
2025-11-16 20:52:07,643 - INFO - root - 已保存图片 10/10：./export\SNN\images\R-SNN_ An Analysis and Design Methodology for Robustifying Spiking Neural Networks against Adversari\figure_10_page7.png
2025-11-16 20:52:07,644 - INFO - root - 成功添加图片 1：./export\SNN\images\R-SNN_ An Analysis and Design Methodology for Robustifying Spiking Neural Networks against Adversari\figure_1_page3.png
2025-11-16 20:52:07,644 - INFO - root - 成功添加图片 2：./export\SNN\images\R-SNN_ An Analysis and Design Methodology for Robustifying Spiking Neural Networks against Adversari\figure_2_page2.jpeg
2025-11-16 20:52:07,645 - INFO - root - 成功添加图片 3：./export\SNN\images\R-SNN_ An Analysis and Design Methodology for Robustifying Spiking Neural Networks against Adversari\figure_3_page2.jpeg
2025-11-16 20:52:07,645 - INFO - root - 成功添加图片 4：./export\SNN\images\R-SNN_ An Analysis and Design Methodology for Robustifying Spiking Neural Networks against Adversari\figure_4_page4.png
2025-11-16 20:52:07,645 - INFO - root - 成功添加图片 5：./export\SNN\images\R-SNN_ An Analysis and Design Methodology for Robustifying Spiking Neural Networks against Adversari\figure_5_page2.jpeg
2025-11-16 20:52:07,645 - INFO - root - 成功添加图片 6：./export\SNN\images\R-SNN_ An Analysis and Design Methodology for Robustifying Spiking Neural Networks against Adversari\figure_6_page7.png
2025-11-16 20:52:07,646 - INFO - root - 成功添加图片 7：./export\SNN\images\R-SNN_ An Analysis and Design Methodology for Robustifying Spiking Neural Networks against Adversari\figure_7_page7.png
2025-11-16 20:52:07,646 - INFO - root - 成功添加图片 8：./export\SNN\images\R-SNN_ An Analysis and Design Methodology for Robustifying Spiking Neural Networks against Adversari\figure_8_page7.png
2025-11-16 20:52:07,646 - INFO - root - 成功添加图片 9：./export\SNN\images\R-SNN_ An Analysis and Design Methodology for Robustifying Spiking Neural Networks against Adversari\figure_9_page7.png
2025-11-16 20:52:07,646 - INFO - root - 成功添加图片 10：./export\SNN\images\R-SNN_ An Analysis and Design Methodology for Robustifying Spiking Neural Networks against Adversari\figure_10_page7.png
2025-11-16 20:52:07,648 - INFO - root - 论文《R-SNN: An Analysis and Design Methodology for Robustifying Spiking Neural Networks against Adversarial Attacks through Noise Filters for Dynamic Vision Sensors》的分析已保存到 ./export\SNN\R-SNN_ An Analysis and Design Methodology for Robustifying Spiking Neural Networks against Adversari.md
2025-11-16 20:52:07,652 - INFO - root - 跳过总结 (手动下载): CORDIC-SNN: On-FPGA STDP Learning With Izhikevich Neurons
2025-11-16 20:52:07,652 - INFO - root - 正在总结论文 66/100: Strange hadron production in Au+Au collisions at sNN =7.7, 11.5, 19.6, 27, and 39 GeV
2025-11-16 20:52:26,320 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-16 20:52:26,322 - INFO - root - LLMClient: rate limit reached, sleeping 4.5s
2025-11-16 20:53:37,562 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-16 20:54:17,346 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-16 20:54:17,347 - INFO - root - 正在提取论文图片到目录: ./export\SNN\images\Strange hadron production in Au+Au collisions at sNN =7.7, 11.5, 19.6, 27, and 39 GeV
2025-11-16 20:54:17,421 - INFO - root - 论文《Strange hadron production in Au+Au collisions at sNN =7.7, 11.5, 19.6, 27, and 39 GeV》的分析已保存到 ./export\SNN\Strange hadron production in Au+Au collisions at sNN =7.7, 11.5, 19.6, 27, and 39 GeV.md
2025-11-16 20:54:17,424 - INFO - root - 正在总结论文 67/100: TCL: an ANN-to-SNN Conversion with Trainable Clipping Layers
2025-11-16 20:54:26,990 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-16 20:54:26,994 - INFO - root - LLMClient: rate limit reached, sleeping 10.6s
2025-11-16 20:55:33,009 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-16 20:56:07,537 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-16 20:56:07,540 - INFO - root - 正在提取论文图片到目录: ./export\SNN\images\TCL_ an ANN-to-SNN Conversion with Trainable Clipping Layers
2025-11-16 20:56:07,615 - INFO - root - 已保存图片 1/10：./export\SNN\images\TCL_ an ANN-to-SNN Conversion with Trainable Clipping Layers\figure_1_page3.png
2025-11-16 20:56:07,615 - INFO - root - 成功添加图片 1：./export\SNN\images\TCL_ an ANN-to-SNN Conversion with Trainable Clipping Layers\figure_1_page3.png
2025-11-16 20:56:07,618 - INFO - root - 论文《TCL: an ANN-to-SNN Conversion with Trainable Clipping Layers》的分析已保存到 ./export\SNN\TCL_ an ANN-to-SNN Conversion with Trainable Clipping Layers.md
2025-11-16 20:56:07,621 - INFO - root - 正在总结论文 68/100: The proton–Ω correlation function in Au + Au collisions at sNN=200GeV
2025-11-16 20:56:22,056 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-16 20:56:22,056 - INFO - root - LLMClient: rate limit reached, sleeping 11.0s
2025-11-16 20:57:34,752 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-16 20:58:08,443 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-16 20:58:08,447 - INFO - root - 正在提取论文图片到目录: ./export\SNN\images\The proton–Ω correlation function in Au + Au collisions at sNN=200GeV
2025-11-16 20:58:08,457 - INFO - root - 论文《The proton–Ω correlation function in Au + Au collisions at sNN=200GeV》的分析已保存到 ./export\SNN\The proton–Ω correlation function in Au + Au collisions at sNN=200GeV.md
2025-11-16 20:58:08,464 - INFO - root - 跳过总结 (手动下载): Verification of genuine and forged offline signatures using Siamese Neural Network (SNN)
2025-11-16 20:58:08,466 - INFO - root - 正在总结论文 70/100: Charged-particle nuclear modification factors in PbPb and pPb collisions at sNN=5.02$$ \sqrt{s_{\mathrm{N}\;\mathrm{N}}}=5.02 $$ TeV
2025-11-16 20:58:30,773 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-16 20:58:30,773 - INFO - root - LLMClient: rate limit reached, sleeping 4.0s
2025-11-16 20:59:37,556 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-16 21:00:15,422 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-16 21:00:15,430 - INFO - root - 正在提取论文图片到目录: ./export\SNN\images\Charged-particle nuclear modification factors in PbPb and pPb collisions at sNN=5.02$$ _sqrt{s_{_mat
2025-11-16 21:00:15,580 - INFO - root - 已保存图片 1/10：./export\SNN\images\Charged-particle nuclear modification factors in PbPb and pPb collisions at sNN=5.02$$ _sqrt{s_{_mat\figure_1_page1.png
2025-11-16 21:00:15,622 - INFO - root - 已保存图片 2/10：./export\SNN\images\Charged-particle nuclear modification factors in PbPb and pPb collisions at sNN=5.02$$ _sqrt{s_{_mat\figure_2_page1.png
2025-11-16 21:00:15,622 - INFO - root - 成功添加图片 1：./export\SNN\images\Charged-particle nuclear modification factors in PbPb and pPb collisions at sNN=5.02$$ _sqrt{s_{_mat\figure_1_page1.png
2025-11-16 21:00:15,622 - INFO - root - 成功添加图片 2：./export\SNN\images\Charged-particle nuclear modification factors in PbPb and pPb collisions at sNN=5.02$$ _sqrt{s_{_mat\figure_2_page1.png
2025-11-16 21:00:15,624 - INFO - root - 论文《Charged-particle nuclear modification factors in PbPb and pPb collisions at sNN=5.02$$ \sqrt{s_{\mathrm{N}\;\mathrm{N}}}=5.02 $$ TeV》的分析已保存到 ./export\SNN\Charged-particle nuclear modification factors in PbPb and pPb collisions at sNN=5.02$$ _sqrt{s_{_mat.md
2025-11-16 21:00:15,628 - INFO - root - 正在总结论文 71/100: Measurement of nuclear modification factors of ϒ(1S), ϒ(2S), and ϒ(3S) mesons in PbPb collisions at sNN=5.02 TeV
2025-11-16 21:00:35,722 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-16 21:00:35,722 - INFO - root - LLMClient: rate limit reached, sleeping 1.8s
2025-11-16 21:01:48,320 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-16 21:02:30,975 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-16 21:02:30,982 - INFO - root - 正在提取论文图片到目录: ./export\SNN\images\Measurement of nuclear modification factors of ϒ(1S), ϒ(2S), and ϒ(3S) mesons in PbPb collisions at
2025-11-16 21:02:30,987 - INFO - root - 论文《Measurement of nuclear modification factors of ϒ(1S), ϒ(2S), and ϒ(3S) mesons in PbPb collisions at sNN=5.02 TeV》的分析已保存到 ./export\SNN\Measurement of nuclear modification factors of ϒ(1S), ϒ(2S), and ϒ(3S) mesons in PbPb collisions at.md
2025-11-16 21:02:30,994 - INFO - root - 跳过总结 (手动下载): Measurement of the azimuthal anisotropy of charged-particle production in Xe+Xe collisions at √sNN =5.44 TeV with the ATLAS detector
2025-11-16 21:02:30,995 - INFO - root - 正在总结论文 73/100: Λ c + production in pp collisions at √s=7 TeV and in p-Pb collisions at √sNN=5.02 TeV
2025-11-16 21:02:52,036 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-16 21:04:07,623 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-16 21:04:50,623 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-16 21:04:50,629 - INFO - root - 正在提取论文图片到目录: ./export\SNN\images\Λ c + production in pp collisions at √s=7 TeV and in p-Pb collisions at √sNN=5.02 TeV
2025-11-16 21:04:50,983 - INFO - root - 已保存图片 1/10：./export\SNN\images\Λ c + production in pp collisions at √s=7 TeV and in p-Pb collisions at √sNN=5.02 TeV\figure_1_page1.png
2025-11-16 21:04:50,984 - INFO - root - 成功添加图片 1：./export\SNN\images\Λ c + production in pp collisions at √s=7 TeV and in p-Pb collisions at √sNN=5.02 TeV\figure_1_page1.png
2025-11-16 21:04:50,989 - INFO - root - 论文《Λ c + production in pp collisions at √s=7 TeV and in p-Pb collisions at √sNN=5.02 TeV》的分析已保存到 ./export\SNN\Λ c + production in pp collisions at √s=7 TeV and in p-Pb collisions at √sNN=5.02 TeV.md
2025-11-16 21:04:50,996 - INFO - root - 正在总结论文 74/100: A spiking neural network (SNN) for detecting high frequency oscillations (HFOs) in the intraoperative ECoG
2025-11-16 21:05:01,554 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-16 21:05:01,556 - INFO - root - LLMClient: rate limit reached, sleeping 6.1s
2025-11-16 21:06:01,595 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-16 21:06:36,963 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-16 21:06:36,965 - INFO - root - 正在提取论文图片到目录: ./export\SNN\images\A spiking neural network (SNN) for detecting high frequency oscillations (HFOs) in the intraoperativ
2025-11-16 21:06:37,204 - INFO - root - 已保存图片 1/10：./export\SNN\images\A spiking neural network (SNN) for detecting high frequency oscillations (HFOs) in the intraoperativ\figure_1_page5.jpeg
2025-11-16 21:06:37,317 - INFO - root - 已保存图片 2/10：./export\SNN\images\A spiking neural network (SNN) for detecting high frequency oscillations (HFOs) in the intraoperativ\figure_2_page7.jpeg
2025-11-16 21:06:37,380 - INFO - root - 已保存图片 3/10：./export\SNN\images\A spiking neural network (SNN) for detecting high frequency oscillations (HFOs) in the intraoperativ\figure_3_page3.jpeg
2025-11-16 21:06:37,389 - INFO - root - 已保存图片 4/10：./export\SNN\images\A spiking neural network (SNN) for detecting high frequency oscillations (HFOs) in the intraoperativ\figure_4_page8.png
2025-11-16 21:06:37,396 - INFO - root - 成功添加图片 1：./export\SNN\images\A spiking neural network (SNN) for detecting high frequency oscillations (HFOs) in the intraoperativ\figure_1_page5.jpeg
2025-11-16 21:06:37,397 - INFO - root - 成功添加图片 2：./export\SNN\images\A spiking neural network (SNN) for detecting high frequency oscillations (HFOs) in the intraoperativ\figure_2_page7.jpeg
2025-11-16 21:06:37,398 - INFO - root - 成功添加图片 3：./export\SNN\images\A spiking neural network (SNN) for detecting high frequency oscillations (HFOs) in the intraoperativ\figure_3_page3.jpeg
2025-11-16 21:06:37,398 - INFO - root - 成功添加图片 4：./export\SNN\images\A spiking neural network (SNN) for detecting high frequency oscillations (HFOs) in the intraoperativ\figure_4_page8.png
2025-11-16 21:06:37,404 - INFO - root - 论文《A spiking neural network (SNN) for detecting high frequency oscillations (HFOs) in the intraoperative ECoG》的分析已保存到 ./export\SNN\A spiking neural network (SNN) for detecting high frequency oscillations (HFOs) in the intraoperativ.md
2025-11-16 21:06:37,415 - INFO - root - 跳过总结 (手动下载): Capacitor-less Stochastic Leaky-FeFET Neuron of Both Excitatory and Inhibitory Connections for SNN with Reduced Hardware Cost
2025-11-16 21:06:37,418 - INFO - root - 跳过总结 (手动下载): Multiparticle correlation studies in pPb collisions at sNN =8.16 TeV
2025-11-16 21:06:37,419 - INFO - root - 跳过总结 (手动下载): DCT-SNN: Using DCT to Distribute Spatial Information over Time for Learning Low-Latency Spiking Neural Networks
2025-11-16 21:06:37,419 - INFO - root - 正在总结论文 78/100: J/ψ suppression at forward rapidity in Pb–Pb collisions at √sNN = 5.02 TeV
2025-11-16 21:06:55,481 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-16 21:06:55,482 - INFO - root - LLMClient: rate limit reached, sleeping 6.1s
2025-11-16 21:07:59,012 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-16 21:08:30,665 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-16 21:08:30,667 - INFO - root - 正在提取论文图片到目录: ./export\SNN\images\J_ψ suppression at forward rapidity in Pb–Pb collisions at √sNN = 5.02 TeV
2025-11-16 21:08:30,675 - INFO - root - 论文《J/ψ suppression at forward rapidity in Pb–Pb collisions at √sNN = 5.02 TeV》的分析已保存到 ./export\SNN\J_ψ suppression at forward rapidity in Pb–Pb collisions at √sNN = 5.02 TeV.md
2025-11-16 21:08:30,682 - INFO - root - 正在总结论文 79/100: Energy dependence and fluctuations of anisotropic flow in Pb-Pb collisions at √sNN = 5.02 and 2.76 TeV
2025-11-16 21:08:51,284 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-16 21:08:51,285 - INFO - root - LLMClient: rate limit reached, sleeping 7.7s
2025-11-16 21:10:04,598 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-16 21:10:41,966 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-16 21:10:41,970 - INFO - root - 正在提取论文图片到目录: ./export\SNN\images\Energy dependence and fluctuations of anisotropic flow in Pb-Pb collisions at √sNN = 5.02 and 2.76 T
2025-11-16 21:10:42,182 - INFO - root - 已保存图片 1/10：./export\SNN\images\Energy dependence and fluctuations of anisotropic flow in Pb-Pb collisions at √sNN = 5.02 and 2.76 T\figure_1_page1.png
2025-11-16 21:10:42,183 - INFO - root - 成功添加图片 1：./export\SNN\images\Energy dependence and fluctuations of anisotropic flow in Pb-Pb collisions at √sNN = 5.02 and 2.76 T\figure_1_page1.png
2025-11-16 21:10:42,187 - INFO - root - 论文《Energy dependence and fluctuations of anisotropic flow in Pb-Pb collisions at √sNN = 5.02 and 2.76 TeV》的分析已保存到 ./export\SNN\Energy dependence and fluctuations of anisotropic flow in Pb-Pb collisions at √sNN = 5.02 and 2.76 T.md
2025-11-16 21:10:42,194 - INFO - root - 正在总结论文 80/100: Elliptic flow of electrons from heavy-flavour hadron decays at mid-rapidity in Pb-Pb collisions at √sNN=2.76 TeV
2025-11-16 21:10:59,303 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-16 21:10:59,307 - INFO - root - LLMClient: rate limit reached, sleeping 5.3s
2025-11-16 21:12:00,358 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-16 21:12:36,581 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-16 21:12:36,606 - INFO - root - 正在提取论文图片到目录: ./export\SNN\images\Elliptic flow of electrons from heavy-flavour hadron decays at mid-rapidity in Pb-Pb collisions at √
2025-11-16 21:12:36,782 - INFO - root - 已保存图片 1/10：./export\SNN\images\Elliptic flow of electrons from heavy-flavour hadron decays at mid-rapidity in Pb-Pb collisions at √\figure_1_page1.png
2025-11-16 21:12:36,783 - INFO - root - 成功添加图片 1：./export\SNN\images\Elliptic flow of electrons from heavy-flavour hadron decays at mid-rapidity in Pb-Pb collisions at √\figure_1_page1.png
2025-11-16 21:12:36,785 - INFO - root - 论文《Elliptic flow of electrons from heavy-flavour hadron decays at mid-rapidity in Pb-Pb collisions at √sNN=2.76 TeV》的分析已保存到 ./export\SNN\Elliptic flow of electrons from heavy-flavour hadron decays at mid-rapidity in Pb-Pb collisions at √.md
2025-11-16 21:12:36,793 - INFO - root - 跳过总结 (手动下载): Spike Counts Based Low Complexity SNN Architecture With Binary Synapse
2025-11-16 21:12:36,794 - INFO - root - 跳过总结 (手动下载): An Asynchronous Reconfigurable SNN Accelerator With Event-Driven Time Step Update
2025-11-16 21:12:36,794 - INFO - root - 跳过总结 (手动下载): Centrality dependence of the nuclear modification factor of charged pions, kaons, and protons in Pb-Pb collisions at √sNN=2.76 TeV
2025-11-16 21:12:36,795 - INFO - root - 正在总结论文 84/100: End to End Learning of a Multi-Layered Snn Based on R-Stdp for a Target Tracking Snake-Like Robot
2025-11-16 21:12:51,681 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-16 21:12:51,683 - INFO - root - LLMClient: rate limit reached, sleeping 8.7s
2025-11-16 21:13:48,614 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-16 21:14:23,738 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-16 21:14:23,747 - INFO - root - 正在提取论文图片到目录: ./export\SNN\images\End to End Learning of a Multi-Layered Snn Based on R-Stdp for a Target Tracking Snake-Like Robot
2025-11-16 21:14:24,330 - INFO - root - 已保存图片 1/10：./export\SNN\images\End to End Learning of a Multi-Layered Snn Based on R-Stdp for a Target Tracking Snake-Like Robot\figure_1_page2.png
2025-11-16 21:14:24,427 - INFO - root - 已保存图片 2/10：./export\SNN\images\End to End Learning of a Multi-Layered Snn Based on R-Stdp for a Target Tracking Snake-Like Robot\figure_2_page4.png
2025-11-16 21:14:24,521 - INFO - root - 已保存图片 3/10：./export\SNN\images\End to End Learning of a Multi-Layered Snn Based on R-Stdp for a Target Tracking Snake-Like Robot\figure_3_page5.png
2025-11-16 21:14:24,560 - INFO - root - 已保存图片 4/10：./export\SNN\images\End to End Learning of a Multi-Layered Snn Based on R-Stdp for a Target Tracking Snake-Like Robot\figure_4_page3.png
2025-11-16 21:14:24,571 - INFO - root - 成功添加图片 1：./export\SNN\images\End to End Learning of a Multi-Layered Snn Based on R-Stdp for a Target Tracking Snake-Like Robot\figure_1_page2.png
2025-11-16 21:14:24,575 - INFO - root - 成功添加图片 2：./export\SNN\images\End to End Learning of a Multi-Layered Snn Based on R-Stdp for a Target Tracking Snake-Like Robot\figure_2_page4.png
2025-11-16 21:14:24,582 - INFO - root - 成功添加图片 3：./export\SNN\images\End to End Learning of a Multi-Layered Snn Based on R-Stdp for a Target Tracking Snake-Like Robot\figure_3_page5.png
2025-11-16 21:14:24,584 - INFO - root - 成功添加图片 4：./export\SNN\images\End to End Learning of a Multi-Layered Snn Based on R-Stdp for a Target Tracking Snake-Like Robot\figure_4_page3.png
2025-11-16 21:14:24,596 - INFO - root - 论文《End to End Learning of a Multi-Layered Snn Based on R-Stdp for a Target Tracking Snake-Like Robot》的分析已保存到 ./export\SNN\End to End Learning of a Multi-Layered Snn Based on R-Stdp for a Target Tracking Snake-Like Robot.md
2025-11-16 21:14:24,612 - INFO - root - 正在总结论文 85/100: Measurement of Ds+ production and nuclear modification factor in Pb-Pb collisions at sNN=2.76$$ \sqrt{{\mathrm{s}}_{\mathrm{NN}}}=2.76 $$ TeV
2025-11-16 21:14:53,801 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-16 21:15:58,683 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-16 21:16:38,825 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-16 21:16:38,833 - INFO - root - 正在提取论文图片到目录: ./export\SNN\images\Measurement of Ds+ production and nuclear modification factor in Pb-Pb collisions at sNN=2.76$$ _sqr
2025-11-16 21:16:38,984 - INFO - root - 已保存图片 1/10：./export\SNN\images\Measurement of Ds+ production and nuclear modification factor in Pb-Pb collisions at sNN=2.76$$ _sqr\figure_1_page1.png
2025-11-16 21:16:38,985 - INFO - root - 成功添加图片 1：./export\SNN\images\Measurement of Ds+ production and nuclear modification factor in Pb-Pb collisions at sNN=2.76$$ _sqr\figure_1_page1.png
2025-11-16 21:16:38,986 - INFO - root - 论文《Measurement of Ds+ production and nuclear modification factor in Pb-Pb collisions at sNN=2.76$$ \sqrt{{\mathrm{s}}_{\mathrm{NN}}}=2.76 $$ TeV》的分析已保存到 ./export\SNN\Measurement of Ds+ production and nuclear modification factor in Pb-Pb collisions at sNN=2.76$$ _sqr.md
2025-11-16 21:16:38,992 - INFO - root - 跳过总结 (手动下载): A Systolic SNN Inference Accelerator and its Co-optimized Software Framework
2025-11-16 21:16:38,993 - INFO - root - 跳过总结 (手动下载): MocapNET: Ensemble of SNN Encoders for 3D Human Pose Estimation in RGB Images
2025-11-16 21:16:38,993 - INFO - root - 正在总结论文 88/100: Nuclear modification factor of D0 mesons in PbPb collisions at sNN=5.02TeV
2025-11-16 21:16:51,894 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-16 21:16:51,899 - INFO - root - LLMClient: rate limit reached, sleeping 6.8s
2025-11-16 21:18:07,581 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-16 21:18:55,190 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-16 21:18:55,198 - INFO - root - 正在提取论文图片到目录: ./export\SNN\images\Nuclear modification factor of D0 mesons in PbPb collisions at sNN=5.02TeV
2025-11-16 21:18:55,206 - INFO - root - 论文《Nuclear modification factor of D0 mesons in PbPb collisions at sNN=5.02TeV》的分析已保存到 ./export\SNN\Nuclear modification factor of D0 mesons in PbPb collisions at sNN=5.02TeV.md
2025-11-16 21:18:55,212 - INFO - root - 跳过总结 (手动下载): Evolution of atomic structures of SnN, SnN -, and SnNCl- clusters (N = 4-20): Insight from ab initio calculations.
2025-11-16 21:18:55,214 - INFO - root - 跳过总结 (手动下载): Homeostasis-Based CNN-to-SNN Conversion of Inception and Residual Architectures
2025-11-16 21:18:55,216 - INFO - root - 正在总结论文 91/100: Supervised Learning in SNN via Reward-Modulated Spike-Timing-Dependent Plasticity for a Target Reaching Vehicle
2025-11-16 21:19:07,294 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-16 21:19:07,297 - INFO - root - LLMClient: rate limit reached, sleeping 0.3s
2025-11-16 21:19:51,581 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-16 21:19:51,583 - INFO - root - LLMClient: rate limit reached, sleeping 3.6s
2025-11-16 21:20:30,990 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-16 21:20:30,998 - INFO - root - 正在提取论文图片到目录: ./export\SNN\images\Supervised Learning in SNN via Reward-Modulated Spike-Timing-Dependent Plasticity for a Target Reach
2025-11-16 21:20:31,134 - INFO - root - 已保存图片 1/10：./export\SNN\images\Supervised Learning in SNN via Reward-Modulated Spike-Timing-Dependent Plasticity for a Target Reach\figure_1_page8.jpeg
2025-11-16 21:20:31,206 - INFO - root - 已保存图片 2/10：./export\SNN\images\Supervised Learning in SNN via Reward-Modulated Spike-Timing-Dependent Plasticity for a Target Reach\figure_2_page14.jpeg
2025-11-16 21:20:31,262 - INFO - root - 已保存图片 3/10：./export\SNN\images\Supervised Learning in SNN via Reward-Modulated Spike-Timing-Dependent Plasticity for a Target Reach\figure_3_page12.jpeg
2025-11-16 21:20:31,312 - INFO - root - 已保存图片 4/10：./export\SNN\images\Supervised Learning in SNN via Reward-Modulated Spike-Timing-Dependent Plasticity for a Target Reach\figure_4_page9.jpeg
2025-11-16 21:20:31,356 - INFO - root - 已保存图片 5/10：./export\SNN\images\Supervised Learning in SNN via Reward-Modulated Spike-Timing-Dependent Plasticity for a Target Reach\figure_5_page10.jpeg
2025-11-16 21:20:31,405 - INFO - root - 已保存图片 6/10：./export\SNN\images\Supervised Learning in SNN via Reward-Modulated Spike-Timing-Dependent Plasticity for a Target Reach\figure_6_page5.jpeg
2025-11-16 21:20:31,458 - INFO - root - 已保存图片 7/10：./export\SNN\images\Supervised Learning in SNN via Reward-Modulated Spike-Timing-Dependent Plasticity for a Target Reach\figure_7_page13.jpeg
2025-11-16 21:20:31,520 - INFO - root - 已保存图片 8/10：./export\SNN\images\Supervised Learning in SNN via Reward-Modulated Spike-Timing-Dependent Plasticity for a Target Reach\figure_8_page7.jpeg
2025-11-16 21:20:31,557 - INFO - root - 已保存图片 9/10：./export\SNN\images\Supervised Learning in SNN via Reward-Modulated Spike-Timing-Dependent Plasticity for a Target Reach\figure_9_page11.jpeg
2025-11-16 21:20:31,602 - INFO - root - 已保存图片 10/10：./export\SNN\images\Supervised Learning in SNN via Reward-Modulated Spike-Timing-Dependent Plasticity for a Target Reach\figure_10_page13.jpeg
2025-11-16 21:20:31,610 - INFO - root - 成功添加图片 1：./export\SNN\images\Supervised Learning in SNN via Reward-Modulated Spike-Timing-Dependent Plasticity for a Target Reach\figure_1_page8.jpeg
2025-11-16 21:20:31,611 - INFO - root - 成功添加图片 2：./export\SNN\images\Supervised Learning in SNN via Reward-Modulated Spike-Timing-Dependent Plasticity for a Target Reach\figure_2_page14.jpeg
2025-11-16 21:20:31,611 - INFO - root - 成功添加图片 3：./export\SNN\images\Supervised Learning in SNN via Reward-Modulated Spike-Timing-Dependent Plasticity for a Target Reach\figure_3_page12.jpeg
2025-11-16 21:20:31,612 - INFO - root - 成功添加图片 4：./export\SNN\images\Supervised Learning in SNN via Reward-Modulated Spike-Timing-Dependent Plasticity for a Target Reach\figure_4_page9.jpeg
2025-11-16 21:20:31,612 - INFO - root - 成功添加图片 5：./export\SNN\images\Supervised Learning in SNN via Reward-Modulated Spike-Timing-Dependent Plasticity for a Target Reach\figure_5_page10.jpeg
2025-11-16 21:20:31,612 - INFO - root - 成功添加图片 6：./export\SNN\images\Supervised Learning in SNN via Reward-Modulated Spike-Timing-Dependent Plasticity for a Target Reach\figure_6_page5.jpeg
2025-11-16 21:20:31,614 - INFO - root - 成功添加图片 7：./export\SNN\images\Supervised Learning in SNN via Reward-Modulated Spike-Timing-Dependent Plasticity for a Target Reach\figure_7_page13.jpeg
2025-11-16 21:20:31,614 - INFO - root - 成功添加图片 8：./export\SNN\images\Supervised Learning in SNN via Reward-Modulated Spike-Timing-Dependent Plasticity for a Target Reach\figure_8_page7.jpeg
2025-11-16 21:20:31,614 - INFO - root - 成功添加图片 9：./export\SNN\images\Supervised Learning in SNN via Reward-Modulated Spike-Timing-Dependent Plasticity for a Target Reach\figure_9_page11.jpeg
2025-11-16 21:20:31,615 - INFO - root - 成功添加图片 10：./export\SNN\images\Supervised Learning in SNN via Reward-Modulated Spike-Timing-Dependent Plasticity for a Target Reach\figure_10_page13.jpeg
2025-11-16 21:20:31,617 - INFO - root - 论文《Supervised Learning in SNN via Reward-Modulated Spike-Timing-Dependent Plasticity for a Target Reaching Vehicle》的分析已保存到 ./export\SNN\Supervised Learning in SNN via Reward-Modulated Spike-Timing-Dependent Plasticity for a Target Reach.md
2025-11-16 21:20:31,620 - INFO - root - 跳过总结 (手动下载): Constraints on jet quenching in p–Pb collisions at √sNN=5.02 TeV measured by the event-activity dependence of semi-inclusive hadron-jet distributions
2025-11-16 21:20:31,620 - INFO - root - 正在总结论文 93/100: Centrality dependence of ψ(2S) suppression in p-Pb collisions at √sNN = 5.02 TeV
2025-11-16 21:20:51,920 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-16 21:20:51,921 - INFO - root - LLMClient: rate limit reached, sleeping 3.3s
2025-11-16 21:22:07,854 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-16 21:22:52,559 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-16 21:22:52,580 - INFO - root - 正在提取论文图片到目录: ./export\SNN\images\Centrality dependence of ψ(2S) suppression in p-Pb collisions at √sNN = 5.02 TeV
2025-11-16 21:22:53,050 - INFO - root - 论文《Centrality dependence of ψ(2S) suppression in p-Pb collisions at √sNN = 5.02 TeV》的分析已保存到 ./export\SNN\Centrality dependence of ψ(2S) suppression in p-Pb collisions at √sNN = 5.02 TeV.md
2025-11-16 21:22:53,053 - INFO - root - 正在总结论文 94/100: A review on data clustering using spiking neural network (SNN) models
2025-11-16 21:23:02,279 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-16 21:23:02,279 - INFO - root - LLMClient: rate limit reached, sleeping 5.6s
2025-11-16 21:23:56,970 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-16 21:24:26,117 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-16 21:24:26,130 - INFO - root - 正在提取论文图片到目录: ./export\SNN\images\A review on data clustering using spiking neural network (SNN) models
2025-11-16 21:24:26,197 - INFO - root - 已保存图片 1/10：./export\SNN\images\A review on data clustering using spiking neural network (SNN) models\figure_1_page2.jpeg
2025-11-16 21:24:26,217 - INFO - root - 已保存图片 2/10：./export\SNN\images\A review on data clustering using spiking neural network (SNN) models\figure_2_page4.jpeg
2025-11-16 21:24:26,265 - INFO - root - 已保存图片 3/10：./export\SNN\images\A review on data clustering using spiking neural network (SNN) models\figure_3_page5.png
2025-11-16 21:24:26,285 - INFO - root - 已保存图片 4/10：./export\SNN\images\A review on data clustering using spiking neural network (SNN) models\figure_4_page6.jpeg
2025-11-16 21:24:26,310 - INFO - root - 已保存图片 5/10：./export\SNN\images\A review on data clustering using spiking neural network (SNN) models\figure_5_page5.jpeg
2025-11-16 21:24:26,311 - INFO - root - 成功添加图片 1：./export\SNN\images\A review on data clustering using spiking neural network (SNN) models\figure_1_page2.jpeg
2025-11-16 21:24:26,311 - INFO - root - 成功添加图片 2：./export\SNN\images\A review on data clustering using spiking neural network (SNN) models\figure_2_page4.jpeg
2025-11-16 21:24:26,311 - INFO - root - 成功添加图片 3：./export\SNN\images\A review on data clustering using spiking neural network (SNN) models\figure_3_page5.png
2025-11-16 21:24:26,311 - INFO - root - 成功添加图片 4：./export\SNN\images\A review on data clustering using spiking neural network (SNN) models\figure_4_page6.jpeg
2025-11-16 21:24:26,312 - INFO - root - 成功添加图片 5：./export\SNN\images\A review on data clustering using spiking neural network (SNN) models\figure_5_page5.jpeg
2025-11-16 21:24:26,313 - INFO - root - 论文《A review on data clustering using spiking neural network (SNN) models》的分析已保存到 ./export\SNN\A review on data clustering using spiking neural network (SNN) models.md
2025-11-16 21:24:26,317 - INFO - root - 跳过总结 (手动下载): Measurement of Antiproton Production in p−He Collisions at √sNN=110 GeV
2025-11-16 21:24:26,317 - INFO - root - 正在总结论文 96/100: Charged-particle nuclear modification factors in XeXe collisions at sNN=5.44$$ \sqrt{s_{\mathrm{NN}}} = 5.44 $$ TeV
2025-11-16 21:24:45,856 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-16 21:24:45,858 - INFO - root - LLMClient: rate limit reached, sleeping 11.1s
2025-11-16 21:26:11,422 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-16 21:26:48,092 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-16 21:26:48,105 - INFO - root - 正在提取论文图片到目录: ./export\SNN\images\Charged-particle nuclear modification factors in XeXe collisions at sNN=5.44$$ _sqrt{s_{_mathrm{NN}}
2025-11-16 21:26:48,252 - INFO - root - 已保存图片 1/10：./export\SNN\images\Charged-particle nuclear modification factors in XeXe collisions at sNN=5.44$$ _sqrt{s_{_mathrm{NN}}\figure_1_page1.png
2025-11-16 21:26:48,293 - INFO - root - 已保存图片 2/10：./export\SNN\images\Charged-particle nuclear modification factors in XeXe collisions at sNN=5.44$$ _sqrt{s_{_mathrm{NN}}\figure_2_page1.png
2025-11-16 21:26:48,293 - INFO - root - 成功添加图片 1：./export\SNN\images\Charged-particle nuclear modification factors in XeXe collisions at sNN=5.44$$ _sqrt{s_{_mathrm{NN}}\figure_1_page1.png
2025-11-16 21:26:48,294 - INFO - root - 成功添加图片 2：./export\SNN\images\Charged-particle nuclear modification factors in XeXe collisions at sNN=5.44$$ _sqrt{s_{_mathrm{NN}}\figure_2_page1.png
2025-11-16 21:26:48,295 - INFO - root - 论文《Charged-particle nuclear modification factors in XeXe collisions at sNN=5.44$$ \sqrt{s_{\mathrm{NN}}} = 5.44 $$ TeV》的分析已保存到 ./export\SNN\Charged-particle nuclear modification factors in XeXe collisions at sNN=5.44$$ _sqrt{s_{_mathrm{NN}}.md
2025-11-16 21:26:48,298 - INFO - root - 正在总结论文 97/100: Bulk properties of the system formed in Au+Au collisions at sNN =14.5 GeV at the BNL STAR detector
2025-11-16 21:27:04,255 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-16 21:27:04,256 - INFO - root - LLMClient: rate limit reached, sleeping 7.2s
2025-11-16 21:28:06,050 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-16 21:28:49,430 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-16 21:28:49,445 - INFO - root - 正在提取论文图片到目录: ./export\SNN\images\Bulk properties of the system formed in Au+Au collisions at sNN =14.5 GeV at the BNL STAR detector
2025-11-16 21:28:49,484 - INFO - root - 论文《Bulk properties of the system formed in Au+Au collisions at sNN =14.5 GeV at the BNL STAR detector》的分析已保存到 ./export\SNN\Bulk properties of the system formed in Au+Au collisions at sNN =14.5 GeV at the BNL STAR detector.md
2025-11-16 21:28:49,490 - INFO - root - 正在总结论文 98/100: Decomposing transverse momentum balance contributions for quenched jets in PbPb collisions at sNN=2.76$$ \sqrt{s_{\mathrm{N}\;\mathrm{N}}}=2.76 $$ TeV
2025-11-16 21:29:03,926 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-16 21:29:03,929 - INFO - root - LLMClient: rate limit reached, sleeping 2.1s
2025-11-16 21:30:12,713 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-16 21:30:51,800 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-16 21:30:51,809 - INFO - root - 正在提取论文图片到目录: ./export\SNN\images\Decomposing transverse momentum balance contributions for quenched jets in PbPb collisions at sNN=2.
2025-11-16 21:30:51,959 - INFO - root - 已保存图片 1/10：./export\SNN\images\Decomposing transverse momentum balance contributions for quenched jets in PbPb collisions at sNN=2.\figure_1_page1.png
2025-11-16 21:30:51,995 - INFO - root - 已保存图片 2/10：./export\SNN\images\Decomposing transverse momentum balance contributions for quenched jets in PbPb collisions at sNN=2.\figure_2_page1.png
2025-11-16 21:30:51,995 - INFO - root - 成功添加图片 1：./export\SNN\images\Decomposing transverse momentum balance contributions for quenched jets in PbPb collisions at sNN=2.\figure_1_page1.png
2025-11-16 21:30:51,995 - INFO - root - 成功添加图片 2：./export\SNN\images\Decomposing transverse momentum balance contributions for quenched jets in PbPb collisions at sNN=2.\figure_2_page1.png
2025-11-16 21:30:51,998 - INFO - root - 论文《Decomposing transverse momentum balance contributions for quenched jets in PbPb collisions at sNN=2.76$$ \sqrt{s_{\mathrm{N}\;\mathrm{N}}}=2.76 $$ TeV》的分析已保存到 ./export\SNN\Decomposing transverse momentum balance contributions for quenched jets in PbPb collisions at sNN=2..md
2025-11-16 21:30:52,005 - INFO - root - 跳过总结 (手动下载): Anisotropic flow of identified particles in Pb-Pb collisions at sNN=5.02 TeV
2025-11-16 21:30:52,005 - INFO - root - 正在总结论文 100/100: Production of 4He and 4He in Pb–Pb collisions at √sNN = 2.76 TeV at the LHC.
2025-11-16 21:31:11,703 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-16 21:31:11,706 - INFO - root - LLMClient: rate limit reached, sleeping 1.0s
2025-11-16 21:32:02,287 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-16 21:32:36,096 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-16 21:32:36,098 - INFO - root - 正在提取论文图片到目录: ./export\SNN\images\Production of 4He and 4He in Pb–Pb collisions at √sNN = 2.76 TeV at the LHC.
2025-11-16 21:32:36,109 - INFO - root - 论文《Production of 4He and 4He in Pb–Pb collisions at √sNN = 2.76 TeV at the LHC.》的分析已保存到 ./export\SNN\Production of 4He and 4He in Pb–Pb collisions at √sNN = 2.76 TeV at the LHC..md
2025-11-16 21:32:36,116 - INFO - root - --- 论文总结阶段结束 ---
2025-11-16 21:32:36,117 - INFO - root - --- 开始生成 Excel 报告 (包含 100 篇论文) ---
2025-11-16 21:32:36,226 - INFO - root - 未找到旧 Excel 文件。正在创建新文件: export\SNN_summary.xlsx
2025-11-16 21:32:36,432 - INFO - root - 成功保存 Excel: export\SNN_summary.xlsx
2025-11-16 21:32:36,432 - INFO - root - 已生成或更新汇总 Excel 表格: export\SNN_summary.xlsx
2025-11-16 21:32:36,446 - INFO - root - 总运行时间: 6538.68 seconds
2025-11-19 21:25:45,872 - WARNING - root - Google Scholar 检索器依赖未能加载: No module named 'selenium'。 'scholar' 策略将不可用。
2025-11-19 21:25:45,875 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-19 21:25:45,876 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-19 21:25:45,878 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-19 21:26:00,011 - INFO - root - LLMClientManager: 指定使用客户端: Gemini
2025-11-19 21:26:00,992 - INFO - root - GeminiClient: trying model models/gemini-2.5-flash
2025-11-19 21:26:08,634 - INFO - root - GeminiClient: initialized model gemini-2.5-flash
2025-11-19 21:26:08,634 - INFO - root - LLMClientManager: Gemini 客户端初始化成功
2025-11-19 21:26:08,634 - INFO - root - LLMClientManager: switched to Gemini client
2025-11-19 21:26:08,635 - INFO - root - 已手动切换到 LLM 客户端: Gemini
2025-11-19 21:26:08,635 - INFO - root - 使用 LLM 模型: gemini-2.5-flash
2025-11-19 21:26:08,635 - INFO - root - 可用客户端: ['Gemini']
2025-11-19 21:26:08,636 - INFO - root - === 运行配置 ===
2025-11-19 21:26:08,636 - INFO - root - 处理模式: arXiv 最新搜索 (API)
2025-11-19 21:26:08,636 - INFO - root - 查询: hybrid attention
2025-11-19 21:26:08,637 - INFO - root - 关键词 (用于保存): hybrid attention_Recent
2025-11-19 21:26:08,637 - INFO - root - 排序: SubmittedDate
2025-11-19 21:26:08,637 - INFO - root - 最近天数: 180
2025-11-19 21:26:08,638 - INFO - root - 最大处理数量: 40
2025-11-19 21:26:08,639 - INFO - root - 保存图片: 是
2025-11-19 21:26:08,640 - INFO - root - 输出语言: 中文
2025-11-19 21:26:08,640 - INFO - root - 强制重新处理: 否
2025-11-19 21:26:08,641 - INFO - root - LLM 客户端: Gemini
2025-11-19 21:26:08,642 - INFO - root - ====================
2025-11-19 21:26:08,642 - INFO - root - 正在使用检索策略: arxiv
2025-11-19 21:26:08,643 - INFO - root - 使用 arXiv 搜索模式 (API + 并发)
2025-11-19 21:26:08,643 - INFO - root - 正在使用 arXiv API 搜索: query='hybrid attention', sort_by=SubmittedDate
2025-11-19 21:26:08,644 - INFO - arxiv - Requesting page (first: True, try: 0): https://export.arxiv.org/api/query?search_query=hybrid+attention&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=50
2025-11-19 21:26:11,125 - INFO - arxiv - Got first page: 50 of 135596 total results
2025-11-19 21:26:11,129 - INFO - root - API 返回了 50 篇论文
2025-11-19 21:26:11,134 - INFO - root - 开始按 180 天过滤 (检查 50 篇论文)...
2025-11-19 21:26:11,134 - INFO - root - 经过 'days=180' 过滤后，剩余 50 篇论文。
2025-11-19 21:26:11,135 - INFO - root - 将开始并发下载 40 篇论文...
2025-11-19 21:26:11,138 - INFO - root - 正在下载: https://arxiv.org/pdf/2511.14756v1
2025-11-19 21:26:11,140 - INFO - root - 正在下载: https://arxiv.org/pdf/2511.14712v1
2025-11-19 21:26:11,146 - INFO - root - 正在下载: https://arxiv.org/pdf/2511.14708v1
2025-11-19 21:26:11,148 - INFO - root - 正在下载: https://arxiv.org/pdf/2511.14705v1
2025-11-19 21:26:11,157 - INFO - root - 正在下载: https://arxiv.org/pdf/2511.14698v1
2025-11-19 21:26:14,412 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\hybrid_attention_Recent\Systematic_Study_of_the_Self-Renormalized_Nucleon_Gluon_PDF_in_Large-Momentum_Effective_Theory.pdf
2025-11-19 21:26:14,415 - INFO - root - 成功创建 Paper 对象: 2511.14708v1
2025-11-19 21:26:14,420 - INFO - root - 下载进度: 1/40
2025-11-19 21:26:14,421 - INFO - root - 正在下载: https://arxiv.org/pdf/2511.14694v1
2025-11-19 21:26:14,986 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\hybrid_attention_Recent\HMC_Learning_Heterogeneous_Meta-Control_for_Contact-Rich_Loco-Manipulation.pdf
2025-11-19 21:26:14,988 - INFO - root - 成功创建 Paper 对象: 2511.14756v1
2025-11-19 21:26:14,989 - INFO - root - 下载进度: 2/40
2025-11-19 21:26:14,990 - INFO - root - 正在下载: https://arxiv.org/pdf/2511.14691v1
2025-11-19 21:26:15,170 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\hybrid_attention_Recent\HyMAD_A_Hybrid_Multi-Activity_Detection_Approach_for_Border_Surveillance_and_Monitoring.pdf
2025-11-19 21:26:15,172 - INFO - root - 成功创建 Paper 对象: 2511.14698v1
2025-11-19 21:26:15,172 - INFO - root - 下载进度: 3/40
2025-11-19 21:26:15,174 - INFO - root - 正在下载: https://arxiv.org/pdf/2511.14680v1
2025-11-19 21:26:18,373 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\hybrid_attention_Recent\NERD_Network-Regularized_Diffusion_Sampling_For_3D_Computed_Tomography.pdf
2025-11-19 21:26:18,378 - INFO - root - 成功创建 Paper 对象: 2511.14680v1
2025-11-19 21:26:18,379 - INFO - root - 下载进度: 4/40
2025-11-19 21:26:18,380 - INFO - root - 正在下载: https://arxiv.org/pdf/2511.14661v1
2025-11-19 21:26:20,706 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\hybrid_attention_Recent\M-CALLM_Multi-level_Context_Aware_LLM_Framework_for_Group_Interaction_Prediction.pdf
2025-11-19 21:26:20,709 - INFO - root - 成功创建 Paper 对象: 2511.14661v1
2025-11-19 21:26:20,710 - INFO - root - 下载进度: 5/40
2025-11-19 21:26:20,711 - INFO - root - 正在下载: https://arxiv.org/pdf/2511.14654v1
2025-11-19 21:26:22,734 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\hybrid_attention_Recent\Near-Lossless_Model_Compression_Enables_Longer_Context_Inference_in_DNA_Large_Language_Models.pdf
2025-11-19 21:26:22,736 - INFO - root - 成功创建 Paper 对象: 2511.14694v1
2025-11-19 21:26:22,737 - INFO - root - 下载进度: 6/40
2025-11-19 21:26:22,738 - INFO - root - 正在下载: https://arxiv.org/pdf/2511.14652v1
2025-11-19 21:26:26,217 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\hybrid_attention_Recent\Robust_Offset-free_Kernelized_Data-Driven_Predictive_Control_for_Nonlinear_Systems.pdf
2025-11-19 21:26:26,220 - INFO - root - 成功创建 Paper 对象: 2511.14652v1
2025-11-19 21:26:26,221 - INFO - root - 下载进度: 7/40
2025-11-19 21:26:26,221 - INFO - root - 正在下载: https://arxiv.org/pdf/2511.14639v1
2025-11-19 21:26:26,523 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\hybrid_attention_Recent\Improving_segmentation_of_retinal_arteries_and_veins_using_cardiac_signal_in_doppler_holograms.pdf
2025-11-19 21:26:26,525 - INFO - root - 成功创建 Paper 对象: 2511.14654v1
2025-11-19 21:26:26,527 - INFO - root - 下载进度: 8/40
2025-11-19 21:26:26,527 - INFO - root - 正在下载: https://arxiv.org/pdf/2511.14620v1
2025-11-19 21:26:30,176 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\hybrid_attention_Recent\SLAM-AGS_Slide-Label_Aware_Multi-Task_Pretraining_Using_Adaptive_Gradient_Surgery_in_Computational.pdf
2025-11-19 21:26:30,177 - INFO - root - 成功创建 Paper 对象: 2511.14639v1
2025-11-19 21:26:30,179 - INFO - root - 下载进度: 9/40
2025-11-19 21:26:30,180 - INFO - root - 正在下载: https://arxiv.org/pdf/2511.14613v1
2025-11-19 21:28:36,463 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\hybrid_attention_Recent\Systematic_Study_on_the_$α$-particle_preformation_factor_in_the_theory_of_$α$-decay_based_on_the_Tab.pdf
2025-11-19 21:28:36,468 - INFO - root - 成功创建 Paper 对象: 2511.14705v1
2025-11-19 21:28:36,468 - INFO - root - 下载进度: 10/40
2025-11-19 21:28:36,469 - INFO - root - 正在下载: https://arxiv.org/pdf/2511.14606v1
2025-11-19 21:28:38,705 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\hybrid_attention_Recent\Bridging_Human_and_Model_Perspectives_A_Comparative_Analysis_of_Political_Bias_Detection_in_News_Me.pdf
2025-11-19 21:28:38,705 - INFO - root - 成功创建 Paper 对象: 2511.14606v1
2025-11-19 21:28:38,706 - INFO - root - 下载进度: 11/40
2025-11-19 21:28:38,706 - INFO - root - 正在下载: https://arxiv.org/pdf/2511.14604v1
2025-11-19 21:28:44,911 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\hybrid_attention_Recent\XAttn-BMD_Multimodal_Deep_Learning_with_Cross-Attention_for_Femoral_Neck_Bone_Mineral_Density_Estim.pdf
2025-11-19 21:28:44,920 - INFO - root - 成功创建 Paper 对象: 2511.14604v1
2025-11-19 21:28:44,922 - INFO - root - 下载进度: 12/40
2025-11-19 21:28:44,922 - INFO - root - 正在下载: https://arxiv.org/pdf/2511.14582v1
2025-11-19 21:29:05,465 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\hybrid_attention_Recent\OmniZip_Audio-Guided_Dynamic_Token_Compression_for_Fast_Omnimodal_Large_Language_Models.pdf
2025-11-19 21:29:05,470 - INFO - root - 成功创建 Paper 对象: 2511.14582v1
2025-11-19 21:29:05,471 - INFO - root - 下载进度: 13/40
2025-11-19 21:29:05,471 - INFO - root - 正在下载: https://arxiv.org/pdf/2511.14570v1
2025-11-19 21:29:25,598 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\hybrid_attention_Recent\Interlayer_Coupling_Driven_Correlated_and_Charge-Ordered_Electronic_States_in_a_Transition_Metal_Dic.pdf
2025-11-19 21:29:25,602 - INFO - root - 成功创建 Paper 对象: 2511.14570v1
2025-11-19 21:29:25,603 - INFO - root - 下载进度: 14/40
2025-11-19 21:29:25,607 - INFO - root - 正在下载: https://arxiv.org/pdf/2511.14566v1
2025-11-19 21:29:28,301 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\hybrid_attention_Recent\Examining_the_Metrics_for_Document-Level_Claim_Extraction_in_Czech_and_Slovak.pdf
2025-11-19 21:29:28,466 - INFO - root - 成功创建 Paper 对象: 2511.14566v1
2025-11-19 21:29:28,601 - INFO - root - 下载进度: 15/40
2025-11-19 21:29:28,618 - INFO - root - 正在下载: https://arxiv.org/pdf/2511.14554v1
2025-11-19 21:29:30,265 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\hybrid_attention_Recent\Fusing_Biomechanical_and_Spatio-Temporal_Features_for_Fall_Prediction_Characterizing_and_Mitigating.pdf
2025-11-19 21:29:30,269 - INFO - root - 成功创建 Paper 对象: 2511.14620v1
2025-11-19 21:29:30,271 - INFO - root - 下载进度: 16/40
2025-11-19 21:29:30,272 - INFO - root - 正在下载: https://arxiv.org/pdf/2511.14543v1
2025-11-19 21:29:31,860 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\hybrid_attention_Recent\ForensicFlow_A_Tri-Modal_Adaptive_Network_for_Robust_Deepfake_Detection.pdf
2025-11-19 21:29:31,865 - INFO - root - 成功创建 Paper 对象: 2511.14554v1
2025-11-19 21:29:31,866 - INFO - root - 下载进度: 17/40
2025-11-19 21:29:31,867 - INFO - root - 正在下载: https://arxiv.org/pdf/2511.14517v1
2025-11-19 21:29:32,073 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\hybrid_attention_Recent\MissHDD_Hybrid_Deterministic_Diffusion_for_Hetrogeneous_Incomplete_Data_Imputation.pdf
2025-11-19 21:29:32,075 - INFO - root - 成功创建 Paper 对象: 2511.14543v1
2025-11-19 21:29:32,076 - INFO - root - 下载进度: 18/40
2025-11-19 21:29:32,077 - INFO - root - 正在下载: https://arxiv.org/pdf/2511.14515v1
2025-11-19 21:29:35,480 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\hybrid_attention_Recent\IMSE_Efficient_U-Net-based_Speech_Enhancement_using_Inception_Depthwise_Convolution_and_Amplitude-A.pdf
2025-11-19 21:29:35,488 - INFO - root - 成功创建 Paper 对象: 2511.14515v1
2025-11-19 21:29:35,489 - INFO - root - 下载进度: 19/40
2025-11-19 21:29:35,490 - INFO - root - 正在下载: https://arxiv.org/pdf/2511.14510v1
2025-11-19 21:29:37,060 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\hybrid_attention_Recent\Attention_via_Synaptic_Plasticity_is_All_You_Need_A_Biologically_Inspired_Spiking_Neuromorphic_Tran.pdf
2025-11-19 21:29:37,075 - INFO - root - 成功创建 Paper 对象: 2511.14691v1
2025-11-19 21:29:37,106 - INFO - root - 下载进度: 20/40
2025-11-19 21:29:37,123 - INFO - root - 正在下载: https://arxiv.org/pdf/2511.14506v1
2025-11-19 21:29:39,809 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\hybrid_attention_Recent\Simulating_quantum_electrodynamics_in_2+1_dimensions_with_qubits_and_qumodes.pdf
2025-11-19 21:29:39,813 - INFO - root - 成功创建 Paper 对象: 2511.14506v1
2025-11-19 21:29:39,814 - INFO - root - 下载进度: 21/40
2025-11-19 21:29:39,815 - INFO - root - 正在下载: https://arxiv.org/pdf/2511.14505v1
2025-11-19 21:29:48,155 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\hybrid_attention_Recent\Neural_network_impurity_solver_for_real-frequency_dynamical_mean-field_theory.pdf
2025-11-19 21:29:48,173 - INFO - root - 成功创建 Paper 对象: 2511.14505v1
2025-11-19 21:29:48,183 - INFO - root - 下载进度: 22/40
2025-11-19 21:29:48,183 - INFO - root - 正在下载: https://arxiv.org/pdf/2511.14503v1
2025-11-19 21:30:00,947 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\hybrid_attention_Recent\CLO_Efficient_LLM_Inference_System_with_CPU-Light_KVCache_Offloading_via_Algorithm-System_Co-Design.pdf
2025-11-19 21:30:01,028 - INFO - root - 成功创建 Paper 对象: 2511.14510v1
2025-11-19 21:30:01,200 - INFO - root - 下载进度: 23/40
2025-11-19 21:30:01,201 - INFO - root - 正在下载: https://arxiv.org/pdf/2511.14499v1
2025-11-19 21:30:22,708 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\hybrid_attention_Recent\Enhancing_End-to-End_Autonomous_Driving_with_Risk_Semantic_Distillaion_from_VLM.pdf
2025-11-19 21:30:22,723 - INFO - root - 成功创建 Paper 对象: 2511.14499v1
2025-11-19 21:30:22,777 - INFO - root - 下载进度: 24/40
2025-11-19 21:30:22,778 - INFO - root - 正在下载: https://arxiv.org/pdf/2511.14473v1
2025-11-19 21:30:42,781 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\hybrid_attention_Recent\3D-Guided_Scalable_Flow_Matching_for_Generating_Volumetric_Tissue_Spatial_Transcriptomics_from_Seria.pdf
2025-11-19 21:30:42,839 - INFO - root - 成功创建 Paper 对象: 2511.14613v1
2025-11-19 21:30:42,852 - INFO - root - 下载进度: 25/40
2025-11-19 21:30:42,853 - INFO - root - 正在下载: https://arxiv.org/pdf/2511.14465v1
2025-11-19 21:30:45,200 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\hybrid_attention_Recent\nnterp_A_Standardized_Interface_for_Mechanistic_Interpretability_of_Transformers.pdf
2025-11-19 21:30:45,227 - INFO - root - 成功创建 Paper 对象: 2511.14465v1
2025-11-19 21:30:45,262 - INFO - root - 下载进度: 26/40
2025-11-19 21:30:45,281 - INFO - root - 正在下载: https://arxiv.org/pdf/2511.14462v1
2025-11-19 21:30:53,569 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\hybrid_attention_Recent\Tri-Hybrid_Beamforming_Design_for_Fully-Connected_Pinching_Antenna_Systems.pdf
2025-11-19 21:30:53,636 - INFO - root - 成功创建 Paper 对象: 2511.14517v1
2025-11-19 21:30:53,690 - INFO - root - 下载进度: 27/40
2025-11-19 21:30:53,691 - INFO - root - 正在下载: https://arxiv.org/pdf/2511.14456v1
2025-11-19 21:30:57,759 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\hybrid_attention_Recent\Analyzing_the_Impact_of_Participant_Failures_in_Cross-Silo_Federated_Learning.pdf
2025-11-19 21:30:57,934 - INFO - root - 成功创建 Paper 对象: 2511.14456v1
2025-11-19 21:30:58,029 - INFO - root - 下载进度: 28/40
2025-11-19 21:30:58,033 - INFO - root - 正在下载: https://arxiv.org/pdf/2511.14454v1
2025-11-19 21:31:04,947 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\hybrid_attention_Recent\Observation_of_the_surface_hybridization_gap_in_the_electrical_transport_properties_of_the_ultrathin.pdf
2025-11-19 21:31:04,951 - INFO - root - 成功创建 Paper 对象: 2511.14454v1
2025-11-19 21:31:04,952 - INFO - root - 下载进度: 29/40
2025-11-19 21:31:04,953 - INFO - root - 正在下载: https://arxiv.org/pdf/2511.14453v1
2025-11-19 21:31:24,610 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\hybrid_attention_Recent\FreeSwim_Revisiting_Sliding-Window_Attention_Mechanisms_for_Training-Free_Ultra-High-Resolution_Vid.pdf
2025-11-19 21:31:24,617 - INFO - root - 成功创建 Paper 对象: 2511.14712v1
2025-11-19 21:31:24,618 - INFO - root - 下载进度: 30/40
2025-11-19 21:31:24,619 - INFO - root - 正在下载: https://arxiv.org/pdf/2511.14452v1
2025-11-19 21:31:30,649 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\hybrid_attention_Recent\Hybrid_Modeling_of_Photoplethysmography_for_Non-invasive_Monitoring_of_Cardiovascular_Parameters.pdf
2025-11-19 21:31:30,656 - INFO - root - 成功创建 Paper 对象: 2511.14452v1
2025-11-19 21:31:30,657 - INFO - root - 下载进度: 31/40
2025-11-19 21:31:30,658 - INFO - root - 正在下载: https://arxiv.org/pdf/2511.14436v1
2025-11-19 21:31:40,033 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\hybrid_attention_Recent\Cracking_the_Microsecond_An_Efficient_and_Precise_Time_Synchronization_Scheme_for_Hybrid_5G-TSN_Net.pdf
2025-11-19 21:31:40,043 - INFO - root - 成功创建 Paper 对象: 2511.14462v1
2025-11-19 21:31:40,045 - INFO - root - 下载进度: 32/40
2025-11-19 21:31:40,045 - INFO - root - 正在下载: https://arxiv.org/pdf/2511.14427v1
2025-11-19 21:31:50,662 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\hybrid_attention_Recent\Analyzing_Many_Simulations_of_Hybrid_Programs_in_Lince.pdf
2025-11-19 21:31:50,671 - INFO - root - 成功创建 Paper 对象: 2511.14436v1
2025-11-19 21:31:50,672 - INFO - root - 下载进度: 33/40
2025-11-19 21:31:50,673 - INFO - root - 正在下载: https://arxiv.org/pdf/2511.14423v1
2025-11-19 21:31:53,962 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\hybrid_attention_Recent\Unified_Defense_for_Large_Language_Models_against_Jailbreak_and_Fine-Tuning_Attacks_in_Education.pdf
2025-11-19 21:31:53,966 - INFO - root - 成功创建 Paper 对象: 2511.14423v1
2025-11-19 21:31:53,967 - INFO - root - 下载进度: 34/40
2025-11-19 21:31:53,968 - INFO - root - 正在下载: https://arxiv.org/pdf/2511.14417v1
2025-11-19 21:32:10,354 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\hybrid_attention_Recent\Multi-network_Topology_Underlying_Individual_Language_Learning_Success.pdf
2025-11-19 21:32:10,359 - INFO - root - 成功创建 Paper 对象: 2511.14453v1
2025-11-19 21:32:10,360 - INFO - root - 下载进度: 35/40
2025-11-19 21:32:10,361 - INFO - root - 正在下载: https://arxiv.org/pdf/2511.14411v1
2025-11-19 21:32:19,169 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\hybrid_attention_Recent\Cranio-ID_Graph-Based_Craniofacial_Identification_via_Automatic_Landmark_Annotation_in_2D_Multi-Vie.pdf
2025-11-19 21:32:19,172 - INFO - root - 成功创建 Paper 对象: 2511.14411v1
2025-11-19 21:32:19,288 - INFO - root - 下载进度: 36/40
2025-11-19 21:32:26,973 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\hybrid_attention_Recent\Nonlinear_Coherence_for_Vector_Time_Series_Defining_Region-to-Region_Functional_Brain_Connectivity.pdf
2025-11-19 21:32:26,978 - INFO - root - 成功创建 Paper 对象: 2511.14417v1
2025-11-19 21:32:26,978 - INFO - root - 下载进度: 37/40
2025-11-19 21:32:49,657 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\hybrid_attention_Recent\Self-Supervised_Multisensory_Pretraining_for_Contact-Rich_Robot_Reinforcement_Learning.pdf
2025-11-19 21:32:49,662 - INFO - root - 成功创建 Paper 对象: 2511.14427v1
2025-11-19 21:32:49,662 - INFO - root - 下载进度: 38/40
2025-11-19 21:33:26,821 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\hybrid_attention_Recent\Parameter_Aware_Mamba_Model_for_Multi-task_Dense_Prediction.pdf
2025-11-19 21:33:26,833 - INFO - root - 成功创建 Paper 对象: 2511.14503v1
2025-11-19 21:33:26,834 - INFO - root - 下载进度: 39/40
2025-11-19 21:34:28,376 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\hybrid_attention_Recent\Learning_Subglacial_Bed_Topography_from_Sparse_Radar_with_Physics-Guided_Residuals.pdf
2025-11-19 21:34:28,394 - INFO - root - 成功创建 Paper 对象: 2511.14473v1
2025-11-19 21:34:28,396 - INFO - root - 下载进度: 40/40
2025-11-19 21:34:28,427 - INFO - root - 论文处理完成: 40 篇成功下载, 0 篇需手动下载。耗时 497.27 秒。
2025-11-19 21:34:28,512 - INFO - root - 检索到 40 篇论文（包括待手动下载的），开始总结...
2025-11-19 21:34:28,561 - INFO - root - --- 开始论文总结阶段 ---
2025-11-19 21:34:28,572 - INFO - root - 正在总结论文 1/40: Systematic Study of the Self-Renormalized Nucleon Gluon PDF in Large-Momentum Effective Theory
2025-11-19 21:35:55,483 - ERROR - root - GeminiClient: generation error: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. 
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 10, model: gemini-2.5-flash
Please retry in 5.212221317s. [links {
  description: "Learn more about Gemini API quotas"
  url: "https://ai.google.dev/gemini-api/docs/rate-limits"
}
, violations {
  quota_metric: "generativelanguage.googleapis.com/generate_content_free_tier_requests"
  quota_id: "GenerateRequestsPerMinutePerProjectPerModel-FreeTier"
  quota_dimensions {
    key: "model"
    value: "gemini-2.5-flash"
  }
  quota_dimensions {
    key: "location"
    value: "global"
  }
  quota_value: 10
}
, retry_delay {
  seconds: 5
}
]
Traceback (most recent call last):
  File "D:\ChatPaper\llm_client_merged.py", line 141, in generate
    resp = self.model.generate_content(prompt, safety_settings=self.safety_settings)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\google\generativeai\generative_models.py", line 331, in generate_content
    response = self._client.generate_content(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\google\ai\generativelanguage_v1beta\services\generative_service\client.py", line 835, in generate_content
    response = rpc(
               ^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\google\api_core\gapic_v1\method.py", line 131, in __call__
    return wrapped_func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\google\api_core\retry\retry_unary.py", line 294, in retry_wrapped_func
    return retry_target(
           ^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\google\api_core\retry\retry_unary.py", line 156, in retry_target
    next_sleep = _retry_error_helper(
                 ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\google\api_core\retry\retry_base.py", line 214, in _retry_error_helper
    raise final_exc from source_exc
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\google\api_core\retry\retry_unary.py", line 147, in retry_target
    result = target()
             ^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\google\api_core\timeout.py", line 130, in func_with_timeout
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\google\api_core\grpc_helpers.py", line 77, in error_remapped_callable
    raise exceptions.from_grpc_error(exc) from exc
google.api_core.exceptions.ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. 
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 10, model: gemini-2.5-flash
Please retry in 5.212221317s. [links {
  description: "Learn more about Gemini API quotas"
  url: "https://ai.google.dev/gemini-api/docs/rate-limits"
}
, violations {
  quota_metric: "generativelanguage.googleapis.com/generate_content_free_tier_requests"
  quota_id: "GenerateRequestsPerMinutePerProjectPerModel-FreeTier"
  quota_dimensions {
    key: "model"
    value: "gemini-2.5-flash"
  }
  quota_dimensions {
    key: "location"
    value: "global"
  }
  quota_value: 10
}
, retry_delay {
  seconds: 5
}
]
2025-11-19 21:35:55,551 - WARNING - root - GeminiClient: 配额或频率限制 检测到，等待 60 秒后重试
2025-11-19 21:36:55,552 - INFO - root - GeminiClient: retry attempt 2 for generation
2025-11-19 21:46:01,039 - INFO - root - 正在提取论文图片到目录: ./export\hybrid_attention_Recent\images\Systematic_Study_of_the_Self-Renormalized_Nucleon_Gluon_PDF_in_Large-Momentum_Effective_Theory
2025-11-19 21:46:01,231 - INFO - root - 论文《Systematic Study of the Self-Renormalized Nucleon Gluon PDF in Large-Momentum Effective Theory》的分析已保存到 ./export\hybrid_attention_Recent\Systematic_Study_of_the_Self-Renormalized_Nucleon_Gluon_PDF_in_Large-Momentum_Effective_Theory.md
2025-11-19 21:46:01,242 - INFO - root - 正在总结论文 2/40: HMC: Learning Heterogeneous Meta-Control for Contact-Rich Loco-Manipulation
2025-11-19 21:50:54,021 - WARNING - root - Google Scholar 检索器依赖未能加载: No module named 'selenium'。 'scholar' 策略将不可用。
2025-11-19 21:50:54,138 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-19 21:50:54,214 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-19 21:50:54,239 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-19 21:51:07,271 - INFO - root - LLMClientManager: 指定使用客户端: DeepSeek
2025-11-19 21:51:07,275 - INFO - root - DeepSeekClient: API key found: 9f9e270e-b...
2025-11-19 21:51:07,275 - INFO - root - DeepSeekClient: 使用模式: 火山引擎
2025-11-19 21:51:07,275 - INFO - root - DeepSeekClient: 模型名称: ep-20251112215738-bz78g
2025-11-19 21:51:12,753 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-19 21:51:12,774 - INFO - root - DeepSeekClient: initialized successfully with model ep-20251112215738-bz78g
2025-11-19 21:51:12,774 - INFO - root - LLMClientManager: DeepSeek 客户端初始化成功
2025-11-19 21:51:12,776 - INFO - root - LLMClientManager: switched to DeepSeek client
2025-11-19 21:51:12,776 - INFO - root - 已手动切换到 LLM 客户端: DeepSeek
2025-11-19 21:51:12,776 - INFO - root - 使用 LLM 模型: ep-20251112215738-bz78g
2025-11-19 21:51:12,777 - INFO - root - 可用客户端: ['DeepSeek']
2025-11-19 21:51:12,777 - INFO - root - === 运行配置 ===
2025-11-19 21:51:12,778 - INFO - root - 处理模式: arXiv 最新搜索 (API)
2025-11-19 21:51:12,780 - INFO - root - 查询: hybrid attention
2025-11-19 21:51:12,780 - INFO - root - 关键词 (用于保存): hybrid attention_Recent
2025-11-19 21:51:12,781 - INFO - root - 排序: SubmittedDate
2025-11-19 21:51:12,781 - INFO - root - 最近天数: 180
2025-11-19 21:51:12,782 - INFO - root - 最大处理数量: 40
2025-11-19 21:51:12,783 - INFO - root - 保存图片: 是
2025-11-19 21:51:12,783 - INFO - root - 输出语言: 中文
2025-11-19 21:51:12,783 - INFO - root - 强制重新处理: 否
2025-11-19 21:51:12,784 - INFO - root - LLM 客户端: DeepSeek
2025-11-19 21:51:12,784 - INFO - root - ====================
2025-11-19 21:51:12,784 - INFO - root - 正在使用检索策略: arxiv
2025-11-19 21:51:12,785 - INFO - root - 使用 arXiv 搜索模式 (API + 并发)
2025-11-19 21:51:12,785 - INFO - root - 正在使用 arXiv API 搜索: query='hybrid attention', sort_by=SubmittedDate
2025-11-19 21:51:12,786 - INFO - arxiv - Requesting page (first: True, try: 0): https://export.arxiv.org/api/query?search_query=hybrid+attention&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=50
2025-11-19 21:51:15,195 - INFO - arxiv - Got first page: 50 of 135596 total results
2025-11-19 21:51:15,200 - INFO - root - API 返回了 50 篇论文
2025-11-19 21:51:15,202 - INFO - root - 开始按 180 天过滤 (检查 50 篇论文)...
2025-11-19 21:51:15,202 - INFO - root - 经过 'days=180' 过滤后，剩余 50 篇论文。
2025-11-19 21:51:15,202 - INFO - root - 将开始并发下载 40 篇论文...
2025-11-19 21:51:15,210 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\hybrid_attention_Recent\HMC_Learning_Heterogeneous_Meta-Control_for_Contact-Rich_Loco-Manipulation.pdf
2025-11-19 21:51:15,211 - INFO - root - 成功创建 Paper 对象: 2511.14756v1
2025-11-19 21:51:15,212 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\hybrid_attention_Recent\FreeSwim_Revisiting_Sliding-Window_Attention_Mechanisms_for_Training-Free_Ultra-High-Resolution_Vid.pdf
2025-11-19 21:51:15,212 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\hybrid_attention_Recent\Systematic_Study_of_the_Self-Renormalized_Nucleon_Gluon_PDF_in_Large-Momentum_Effective_Theory.pdf
2025-11-19 21:51:15,215 - INFO - root - 下载进度: 1/40
2025-11-19 21:51:15,215 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\hybrid_attention_Recent\Systematic_Study_on_the_$α$-particle_preformation_factor_in_the_theory_of_$α$-decay_based_on_the_Tab.pdf
2025-11-19 21:51:15,216 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\hybrid_attention_Recent\HyMAD_A_Hybrid_Multi-Activity_Detection_Approach_for_Border_Surveillance_and_Monitoring.pdf
2025-11-19 21:51:15,216 - INFO - root - 成功创建 Paper 对象: 2511.14712v1
2025-11-19 21:51:15,217 - INFO - root - 成功创建 Paper 对象: 2511.14708v1
2025-11-19 21:51:15,217 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\hybrid_attention_Recent\Near-Lossless_Model_Compression_Enables_Longer_Context_Inference_in_DNA_Large_Language_Models.pdf
2025-11-19 21:51:15,218 - INFO - root - 成功创建 Paper 对象: 2511.14705v1
2025-11-19 21:51:15,218 - INFO - root - 成功创建 Paper 对象: 2511.14698v1
2025-11-19 21:51:15,218 - INFO - root - 下载进度: 2/40
2025-11-19 21:51:15,219 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\hybrid_attention_Recent\Attention_via_Synaptic_Plasticity_is_All_You_Need_A_Biologically_Inspired_Spiking_Neuromorphic_Tran.pdf
2025-11-19 21:51:15,220 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\hybrid_attention_Recent\NERD_Network-Regularized_Diffusion_Sampling_For_3D_Computed_Tomography.pdf
2025-11-19 21:51:15,220 - INFO - root - 成功创建 Paper 对象: 2511.14694v1
2025-11-19 21:51:15,221 - INFO - root - 下载进度: 3/40
2025-11-19 21:51:15,221 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\hybrid_attention_Recent\M-CALLM_Multi-level_Context_Aware_LLM_Framework_for_Group_Interaction_Prediction.pdf
2025-11-19 21:51:15,221 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\hybrid_attention_Recent\Improving_segmentation_of_retinal_arteries_and_veins_using_cardiac_signal_in_doppler_holograms.pdf
2025-11-19 21:51:15,222 - INFO - root - 成功创建 Paper 对象: 2511.14691v1
2025-11-19 21:51:15,222 - INFO - root - 成功创建 Paper 对象: 2511.14680v1
2025-11-19 21:51:15,224 - INFO - root - 下载进度: 4/40
2025-11-19 21:51:15,224 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\hybrid_attention_Recent\Robust_Offset-free_Kernelized_Data-Driven_Predictive_Control_for_Nonlinear_Systems.pdf
2025-11-19 21:51:15,224 - INFO - root - 成功创建 Paper 对象: 2511.14661v1
2025-11-19 21:51:15,225 - INFO - root - 成功创建 Paper 对象: 2511.14654v1
2025-11-19 21:51:15,227 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\hybrid_attention_Recent\SLAM-AGS_Slide-Label_Aware_Multi-Task_Pretraining_Using_Adaptive_Gradient_Surgery_in_Computational.pdf
2025-11-19 21:51:15,228 - INFO - root - 下载进度: 5/40
2025-11-19 21:51:15,229 - INFO - root - 成功创建 Paper 对象: 2511.14652v1
2025-11-19 21:51:15,229 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\hybrid_attention_Recent\Fusing_Biomechanical_and_Spatio-Temporal_Features_for_Fall_Prediction_Characterizing_and_Mitigating.pdf
2025-11-19 21:51:15,232 - INFO - root - 成功创建 Paper 对象: 2511.14639v1
2025-11-19 21:51:15,235 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\hybrid_attention_Recent\3D-Guided_Scalable_Flow_Matching_for_Generating_Volumetric_Tissue_Spatial_Transcriptomics_from_Seria.pdf
2025-11-19 21:51:15,235 - INFO - root - 下载进度: 6/40
2025-11-19 21:51:15,236 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\hybrid_attention_Recent\Bridging_Human_and_Model_Perspectives_A_Comparative_Analysis_of_Political_Bias_Detection_in_News_Me.pdf
2025-11-19 21:51:15,237 - INFO - root - 成功创建 Paper 对象: 2511.14620v1
2025-11-19 21:51:15,237 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\hybrid_attention_Recent\XAttn-BMD_Multimodal_Deep_Learning_with_Cross-Attention_for_Femoral_Neck_Bone_Mineral_Density_Estim.pdf
2025-11-19 21:51:15,240 - INFO - root - 成功创建 Paper 对象: 2511.14604v1
2025-11-19 21:51:15,238 - INFO - root - 下载进度: 7/40
2025-11-19 21:51:15,238 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\hybrid_attention_Recent\OmniZip_Audio-Guided_Dynamic_Token_Compression_for_Fast_Omnimodal_Large_Language_Models.pdf
2025-11-19 21:51:15,239 - INFO - root - 成功创建 Paper 对象: 2511.14606v1
2025-11-19 21:51:15,241 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\hybrid_attention_Recent\Interlayer_Coupling_Driven_Correlated_and_Charge-Ordered_Electronic_States_in_a_Transition_Metal_Dic.pdf
2025-11-19 21:51:15,238 - INFO - root - 成功创建 Paper 对象: 2511.14613v1
2025-11-19 21:51:15,243 - INFO - root - 下载进度: 8/40
2025-11-19 21:51:15,244 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\hybrid_attention_Recent\Examining_the_Metrics_for_Document-Level_Claim_Extraction_in_Czech_and_Slovak.pdf
2025-11-19 21:51:15,244 - INFO - root - 成功创建 Paper 对象: 2511.14582v1
2025-11-19 21:51:15,246 - INFO - root - 成功创建 Paper 对象: 2511.14570v1
2025-11-19 21:51:15,246 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\hybrid_attention_Recent\ForensicFlow_A_Tri-Modal_Adaptive_Network_for_Robust_Deepfake_Detection.pdf
2025-11-19 21:51:15,246 - INFO - root - 下载进度: 9/40
2025-11-19 21:51:15,247 - INFO - root - 成功创建 Paper 对象: 2511.14566v1
2025-11-19 21:51:15,250 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\hybrid_attention_Recent\MissHDD_Hybrid_Deterministic_Diffusion_for_Hetrogeneous_Incomplete_Data_Imputation.pdf
2025-11-19 21:51:15,252 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\hybrid_attention_Recent\Tri-Hybrid_Beamforming_Design_for_Fully-Connected_Pinching_Antenna_Systems.pdf
2025-11-19 21:51:15,252 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\hybrid_attention_Recent\IMSE_Efficient_U-Net-based_Speech_Enhancement_using_Inception_Depthwise_Convolution_and_Amplitude-A.pdf
2025-11-19 21:51:15,253 - INFO - root - 成功创建 Paper 对象: 2511.14554v1
2025-11-19 21:51:15,253 - INFO - root - 下载进度: 10/40
2025-11-19 21:51:15,254 - INFO - root - 成功创建 Paper 对象: 2511.14543v1
2025-11-19 21:51:15,254 - INFO - root - 成功创建 Paper 对象: 2511.14517v1
2025-11-19 21:51:15,255 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\hybrid_attention_Recent\CLO_Efficient_LLM_Inference_System_with_CPU-Light_KVCache_Offloading_via_Algorithm-System_Co-Design.pdf
2025-11-19 21:51:15,256 - INFO - root - 成功创建 Paper 对象: 2511.14515v1
2025-11-19 21:51:15,257 - INFO - root - 下载进度: 11/40
2025-11-19 21:51:15,257 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\hybrid_attention_Recent\Simulating_quantum_electrodynamics_in_2+1_dimensions_with_qubits_and_qumodes.pdf
2025-11-19 21:51:15,259 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\hybrid_attention_Recent\Neural_network_impurity_solver_for_real-frequency_dynamical_mean-field_theory.pdf
2025-11-19 21:51:15,259 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\hybrid_attention_Recent\Parameter_Aware_Mamba_Model_for_Multi-task_Dense_Prediction.pdf
2025-11-19 21:51:15,260 - INFO - root - 成功创建 Paper 对象: 2511.14510v1
2025-11-19 21:51:15,260 - INFO - root - 下载进度: 12/40
2025-11-19 21:51:15,261 - INFO - root - 成功创建 Paper 对象: 2511.14506v1
2025-11-19 21:51:15,261 - INFO - root - 成功创建 Paper 对象: 2511.14505v1
2025-11-19 21:51:15,262 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\hybrid_attention_Recent\Enhancing_End-to-End_Autonomous_Driving_with_Risk_Semantic_Distillaion_from_VLM.pdf
2025-11-19 21:51:15,262 - INFO - root - 成功创建 Paper 对象: 2511.14503v1
2025-11-19 21:51:15,268 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\hybrid_attention_Recent\Learning_Subglacial_Bed_Topography_from_Sparse_Radar_with_Physics-Guided_Residuals.pdf
2025-11-19 21:51:15,268 - INFO - root - 下载进度: 13/40
2025-11-19 21:51:15,270 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\hybrid_attention_Recent\nnterp_A_Standardized_Interface_for_Mechanistic_Interpretability_of_Transformers.pdf
2025-11-19 21:51:15,270 - INFO - root - 成功创建 Paper 对象: 2511.14499v1
2025-11-19 21:51:15,271 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\hybrid_attention_Recent\Cracking_the_Microsecond_An_Efficient_and_Precise_Time_Synchronization_Scheme_for_Hybrid_5G-TSN_Net.pdf
2025-11-19 21:51:15,272 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\hybrid_attention_Recent\Analyzing_the_Impact_of_Participant_Failures_in_Cross-Silo_Federated_Learning.pdf
2025-11-19 21:51:15,273 - INFO - root - 成功创建 Paper 对象: 2511.14473v1
2025-11-19 21:51:15,273 - INFO - root - 下载进度: 14/40
2025-11-19 21:51:15,274 - INFO - root - 成功创建 Paper 对象: 2511.14465v1
2025-11-19 21:51:15,275 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\hybrid_attention_Recent\Observation_of_the_surface_hybridization_gap_in_the_electrical_transport_properties_of_the_ultrathin.pdf
2025-11-19 21:51:15,276 - INFO - root - 成功创建 Paper 对象: 2511.14462v1
2025-11-19 21:51:15,276 - INFO - root - 成功创建 Paper 对象: 2511.14456v1
2025-11-19 21:51:15,277 - INFO - root - 下载进度: 15/40
2025-11-19 21:51:15,277 - INFO - root - 成功创建 Paper 对象: 2511.14454v1
2025-11-19 21:51:15,278 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\hybrid_attention_Recent\Multi-network_Topology_Underlying_Individual_Language_Learning_Success.pdf
2025-11-19 21:51:15,278 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\hybrid_attention_Recent\Hybrid_Modeling_of_Photoplethysmography_for_Non-invasive_Monitoring_of_Cardiovascular_Parameters.pdf
2025-11-19 21:51:15,278 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\hybrid_attention_Recent\Analyzing_Many_Simulations_of_Hybrid_Programs_in_Lince.pdf
2025-11-19 21:51:15,280 - INFO - root - 下载进度: 16/40
2025-11-19 21:51:15,282 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\hybrid_attention_Recent\Self-Supervised_Multisensory_Pretraining_for_Contact-Rich_Robot_Reinforcement_Learning.pdf
2025-11-19 21:51:15,283 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\hybrid_attention_Recent\Unified_Defense_for_Large_Language_Models_against_Jailbreak_and_Fine-Tuning_Attacks_in_Education.pdf
2025-11-19 21:51:15,284 - INFO - root - 成功创建 Paper 对象: 2511.14453v1
2025-11-19 21:51:15,284 - INFO - root - 成功创建 Paper 对象: 2511.14452v1
2025-11-19 21:51:15,285 - INFO - root - 成功创建 Paper 对象: 2511.14436v1
2025-11-19 21:51:15,285 - INFO - root - 下载进度: 17/40
2025-11-19 21:51:15,285 - INFO - root - 成功创建 Paper 对象: 2511.14427v1
2025-11-19 21:51:15,286 - INFO - root - 成功创建 Paper 对象: 2511.14423v1
2025-11-19 21:51:15,287 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\hybrid_attention_Recent\Nonlinear_Coherence_for_Vector_Time_Series_Defining_Region-to-Region_Functional_Brain_Connectivity.pdf
2025-11-19 21:51:15,288 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\hybrid_attention_Recent\Cranio-ID_Graph-Based_Craniofacial_Identification_via_Automatic_Landmark_Annotation_in_2D_Multi-Vie.pdf
2025-11-19 21:51:15,289 - INFO - root - 下载进度: 18/40
2025-11-19 21:51:15,291 - INFO - root - 成功创建 Paper 对象: 2511.14417v1
2025-11-19 21:51:15,291 - INFO - root - 成功创建 Paper 对象: 2511.14411v1
2025-11-19 21:51:15,291 - INFO - root - 下载进度: 19/40
2025-11-19 21:51:15,292 - INFO - root - 下载进度: 20/40
2025-11-19 21:51:15,292 - INFO - root - 下载进度: 21/40
2025-11-19 21:51:15,293 - INFO - root - 下载进度: 22/40
2025-11-19 21:51:15,293 - INFO - root - 下载进度: 23/40
2025-11-19 21:51:15,293 - INFO - root - 下载进度: 24/40
2025-11-19 21:51:15,294 - INFO - root - 下载进度: 25/40
2025-11-19 21:51:15,294 - INFO - root - 下载进度: 26/40
2025-11-19 21:51:15,294 - INFO - root - 下载进度: 27/40
2025-11-19 21:51:15,296 - INFO - root - 下载进度: 28/40
2025-11-19 21:51:15,297 - INFO - root - 下载进度: 29/40
2025-11-19 21:51:15,300 - INFO - root - 下载进度: 30/40
2025-11-19 21:51:15,301 - INFO - root - 下载进度: 31/40
2025-11-19 21:51:15,301 - INFO - root - 下载进度: 32/40
2025-11-19 21:51:15,303 - INFO - root - 下载进度: 33/40
2025-11-19 21:51:15,303 - INFO - root - 下载进度: 34/40
2025-11-19 21:51:15,306 - INFO - root - 下载进度: 35/40
2025-11-19 21:51:15,307 - INFO - root - 下载进度: 36/40
2025-11-19 21:51:15,308 - INFO - root - 下载进度: 37/40
2025-11-19 21:51:15,308 - INFO - root - 下载进度: 38/40
2025-11-19 21:51:15,309 - INFO - root - 下载进度: 39/40
2025-11-19 21:51:15,310 - INFO - root - 下载进度: 40/40
2025-11-19 21:51:15,311 - INFO - root - 论文处理完成: 40 篇成功下载, 0 篇需手动下载。耗时 0.10 秒。
2025-11-19 21:51:15,312 - INFO - root - 检索到 40 篇论文（包括待手动下载的），开始总结...
2025-11-19 21:51:15,320 - INFO - root - --- 开始论文总结阶段 ---
2025-11-19 21:51:15,329 - INFO - root - 正在总结论文 1/40: HMC: Learning Heterogeneous Meta-Control for Contact-Rich Loco-Manipulation
2025-11-19 21:51:27,352 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-19 21:52:38,470 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-19 21:53:19,074 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-19 21:53:19,076 - INFO - root - 正在提取论文图片到目录: ./export\hybrid_attention_Recent\images\HMC_Learning_Heterogeneous_Meta-Control_for_Contact-Rich_Loco-Manipulation
2025-11-19 21:53:21,977 - INFO - root - 已保存图片 1/10：./export\hybrid_attention_Recent\images\HMC_Learning_Heterogeneous_Meta-Control_for_Contact-Rich_Loco-Manipulation\figure_1_page6.png
2025-11-19 21:53:22,152 - INFO - root - 已保存图片 2/10：./export\hybrid_attention_Recent\images\HMC_Learning_Heterogeneous_Meta-Control_for_Contact-Rich_Loco-Manipulation\figure_2_page3.jpeg
2025-11-19 21:53:22,276 - INFO - root - 已保存图片 3/10：./export\hybrid_attention_Recent\images\HMC_Learning_Heterogeneous_Meta-Control_for_Contact-Rich_Loco-Manipulation\figure_3_page5.jpeg
2025-11-19 21:53:22,352 - INFO - root - 已保存图片 4/10：./export\hybrid_attention_Recent\images\HMC_Learning_Heterogeneous_Meta-Control_for_Contact-Rich_Loco-Manipulation\figure_4_page5.jpeg
2025-11-19 21:53:22,435 - INFO - root - 已保存图片 5/10：./export\hybrid_attention_Recent\images\HMC_Learning_Heterogeneous_Meta-Control_for_Contact-Rich_Loco-Manipulation\figure_5_page5.jpeg
2025-11-19 21:53:22,802 - INFO - root - 已保存图片 6/10：./export\hybrid_attention_Recent\images\HMC_Learning_Heterogeneous_Meta-Control_for_Contact-Rich_Loco-Manipulation\figure_6_page1.png
2025-11-19 21:53:23,255 - INFO - root - 已保存图片 7/10：./export\hybrid_attention_Recent\images\HMC_Learning_Heterogeneous_Meta-Control_for_Contact-Rich_Loco-Manipulation\figure_7_page1.png
2025-11-19 21:53:23,691 - INFO - root - 已保存图片 8/10：./export\hybrid_attention_Recent\images\HMC_Learning_Heterogeneous_Meta-Control_for_Contact-Rich_Loco-Manipulation\figure_8_page1.png
2025-11-19 21:53:23,928 - INFO - root - 已保存图片 9/10：./export\hybrid_attention_Recent\images\HMC_Learning_Heterogeneous_Meta-Control_for_Contact-Rich_Loco-Manipulation\figure_9_page1.png
2025-11-19 21:53:24,118 - INFO - root - 已保存图片 10/10：./export\hybrid_attention_Recent\images\HMC_Learning_Heterogeneous_Meta-Control_for_Contact-Rich_Loco-Manipulation\figure_10_page1.png
2025-11-19 21:53:24,124 - INFO - root - 成功添加图片 1：./export\hybrid_attention_Recent\images\HMC_Learning_Heterogeneous_Meta-Control_for_Contact-Rich_Loco-Manipulation\figure_1_page6.png
2025-11-19 21:53:24,124 - INFO - root - 成功添加图片 2：./export\hybrid_attention_Recent\images\HMC_Learning_Heterogeneous_Meta-Control_for_Contact-Rich_Loco-Manipulation\figure_2_page3.jpeg
2025-11-19 21:53:24,124 - INFO - root - 成功添加图片 3：./export\hybrid_attention_Recent\images\HMC_Learning_Heterogeneous_Meta-Control_for_Contact-Rich_Loco-Manipulation\figure_3_page5.jpeg
2025-11-19 21:53:24,127 - INFO - root - 成功添加图片 4：./export\hybrid_attention_Recent\images\HMC_Learning_Heterogeneous_Meta-Control_for_Contact-Rich_Loco-Manipulation\figure_4_page5.jpeg
2025-11-19 21:53:24,128 - INFO - root - 成功添加图片 5：./export\hybrid_attention_Recent\images\HMC_Learning_Heterogeneous_Meta-Control_for_Contact-Rich_Loco-Manipulation\figure_5_page5.jpeg
2025-11-19 21:53:24,128 - INFO - root - 成功添加图片 6：./export\hybrid_attention_Recent\images\HMC_Learning_Heterogeneous_Meta-Control_for_Contact-Rich_Loco-Manipulation\figure_6_page1.png
2025-11-19 21:53:24,129 - INFO - root - 成功添加图片 7：./export\hybrid_attention_Recent\images\HMC_Learning_Heterogeneous_Meta-Control_for_Contact-Rich_Loco-Manipulation\figure_7_page1.png
2025-11-19 21:53:24,129 - INFO - root - 成功添加图片 8：./export\hybrid_attention_Recent\images\HMC_Learning_Heterogeneous_Meta-Control_for_Contact-Rich_Loco-Manipulation\figure_8_page1.png
2025-11-19 21:53:24,129 - INFO - root - 成功添加图片 9：./export\hybrid_attention_Recent\images\HMC_Learning_Heterogeneous_Meta-Control_for_Contact-Rich_Loco-Manipulation\figure_9_page1.png
2025-11-19 21:53:24,131 - INFO - root - 成功添加图片 10：./export\hybrid_attention_Recent\images\HMC_Learning_Heterogeneous_Meta-Control_for_Contact-Rich_Loco-Manipulation\figure_10_page1.png
2025-11-19 21:53:24,137 - INFO - root - 论文《HMC: Learning Heterogeneous Meta-Control for Contact-Rich Loco-Manipulation》的分析已保存到 ./export\hybrid_attention_Recent\HMC_Learning_Heterogeneous_Meta-Control_for_Contact-Rich_Loco-Manipulation.md
2025-11-19 21:53:24,146 - INFO - root - 正在总结论文 2/40: FreeSwim: Revisiting Sliding-Window Attention Mechanisms for Training-Free Ultra-High-Resolution Video Generation
2025-11-19 21:53:40,832 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-19 21:54:50,462 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-19 21:55:12,759 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-19 21:55:12,784 - INFO - root - 正在提取论文图片到目录: ./export\hybrid_attention_Recent\images\FreeSwim_Revisiting_Sliding-Window_Attention_Mechanisms_for_Training-Free_Ultra-High-Resolution_Vid
2025-11-19 21:55:30,316 - INFO - root - 已保存图片 1/10：./export\hybrid_attention_Recent\images\FreeSwim_Revisiting_Sliding-Window_Attention_Mechanisms_for_Training-Free_Ultra-High-Resolution_Vid\figure_1_page1.jpeg
2025-11-19 21:55:31,232 - INFO - root - 已保存图片 2/10：./export\hybrid_attention_Recent\images\FreeSwim_Revisiting_Sliding-Window_Attention_Mechanisms_for_Training-Free_Ultra-High-Resolution_Vid\figure_2_page1.jpeg
2025-11-19 21:55:31,943 - INFO - root - 已保存图片 3/10：./export\hybrid_attention_Recent\images\FreeSwim_Revisiting_Sliding-Window_Attention_Mechanisms_for_Training-Free_Ultra-High-Resolution_Vid\figure_3_page1.jpeg
2025-11-19 21:55:32,764 - INFO - root - 已保存图片 4/10：./export\hybrid_attention_Recent\images\FreeSwim_Revisiting_Sliding-Window_Attention_Mechanisms_for_Training-Free_Ultra-High-Resolution_Vid\figure_4_page1.jpeg
2025-11-19 21:55:32,965 - INFO - root - 已保存图片 5/10：./export\hybrid_attention_Recent\images\FreeSwim_Revisiting_Sliding-Window_Attention_Mechanisms_for_Training-Free_Ultra-High-Resolution_Vid\figure_5_page1.jpeg
2025-11-19 21:55:33,144 - INFO - root - 已保存图片 6/10：./export\hybrid_attention_Recent\images\FreeSwim_Revisiting_Sliding-Window_Attention_Mechanisms_for_Training-Free_Ultra-High-Resolution_Vid\figure_6_page1.jpeg
2025-11-19 21:55:33,326 - INFO - root - 已保存图片 7/10：./export\hybrid_attention_Recent\images\FreeSwim_Revisiting_Sliding-Window_Attention_Mechanisms_for_Training-Free_Ultra-High-Resolution_Vid\figure_7_page1.jpeg
2025-11-19 21:55:33,514 - INFO - root - 已保存图片 8/10：./export\hybrid_attention_Recent\images\FreeSwim_Revisiting_Sliding-Window_Attention_Mechanisms_for_Training-Free_Ultra-High-Resolution_Vid\figure_8_page1.jpeg
2025-11-19 21:55:34,027 - INFO - root - 已保存图片 9/10：./export\hybrid_attention_Recent\images\FreeSwim_Revisiting_Sliding-Window_Attention_Mechanisms_for_Training-Free_Ultra-High-Resolution_Vid\figure_9_page1.png
2025-11-19 21:55:34,234 - INFO - root - 已保存图片 10/10：./export\hybrid_attention_Recent\images\FreeSwim_Revisiting_Sliding-Window_Attention_Mechanisms_for_Training-Free_Ultra-High-Resolution_Vid\figure_10_page1.jpeg
2025-11-19 21:55:34,304 - INFO - root - 成功添加图片 1：./export\hybrid_attention_Recent\images\FreeSwim_Revisiting_Sliding-Window_Attention_Mechanisms_for_Training-Free_Ultra-High-Resolution_Vid\figure_1_page1.jpeg
2025-11-19 21:55:34,305 - INFO - root - 成功添加图片 2：./export\hybrid_attention_Recent\images\FreeSwim_Revisiting_Sliding-Window_Attention_Mechanisms_for_Training-Free_Ultra-High-Resolution_Vid\figure_2_page1.jpeg
2025-11-19 21:55:34,305 - INFO - root - 成功添加图片 3：./export\hybrid_attention_Recent\images\FreeSwim_Revisiting_Sliding-Window_Attention_Mechanisms_for_Training-Free_Ultra-High-Resolution_Vid\figure_3_page1.jpeg
2025-11-19 21:55:34,312 - INFO - root - 成功添加图片 4：./export\hybrid_attention_Recent\images\FreeSwim_Revisiting_Sliding-Window_Attention_Mechanisms_for_Training-Free_Ultra-High-Resolution_Vid\figure_4_page1.jpeg
2025-11-19 21:55:34,313 - INFO - root - 成功添加图片 5：./export\hybrid_attention_Recent\images\FreeSwim_Revisiting_Sliding-Window_Attention_Mechanisms_for_Training-Free_Ultra-High-Resolution_Vid\figure_5_page1.jpeg
2025-11-19 21:55:34,314 - INFO - root - 成功添加图片 6：./export\hybrid_attention_Recent\images\FreeSwim_Revisiting_Sliding-Window_Attention_Mechanisms_for_Training-Free_Ultra-High-Resolution_Vid\figure_6_page1.jpeg
2025-11-19 21:55:34,314 - INFO - root - 成功添加图片 7：./export\hybrid_attention_Recent\images\FreeSwim_Revisiting_Sliding-Window_Attention_Mechanisms_for_Training-Free_Ultra-High-Resolution_Vid\figure_7_page1.jpeg
2025-11-19 21:55:34,315 - INFO - root - 成功添加图片 8：./export\hybrid_attention_Recent\images\FreeSwim_Revisiting_Sliding-Window_Attention_Mechanisms_for_Training-Free_Ultra-High-Resolution_Vid\figure_8_page1.jpeg
2025-11-19 21:55:34,316 - INFO - root - 成功添加图片 9：./export\hybrid_attention_Recent\images\FreeSwim_Revisiting_Sliding-Window_Attention_Mechanisms_for_Training-Free_Ultra-High-Resolution_Vid\figure_9_page1.png
2025-11-19 21:55:34,343 - INFO - root - 成功添加图片 10：./export\hybrid_attention_Recent\images\FreeSwim_Revisiting_Sliding-Window_Attention_Mechanisms_for_Training-Free_Ultra-High-Resolution_Vid\figure_10_page1.jpeg
2025-11-19 21:55:34,348 - INFO - root - 论文《FreeSwim: Revisiting Sliding-Window Attention Mechanisms for Training-Free Ultra-High-Resolution Video Generation》的分析已保存到 ./export\hybrid_attention_Recent\FreeSwim_Revisiting_Sliding-Window_Attention_Mechanisms_for_Training-Free_Ultra-High-Resolution_Vid.md
2025-11-19 21:55:34,377 - INFO - root - 跳过已处理论文 Systematic Study of the Self-Renormalized Nucleon Gluon PDF in Large-Momentum Effective Theory：D:\ChatPaper\api_downloads\hybrid_attention_Recent\Systematic_Study_of_the_Self-Renormalized_Nucleon_Gluon_PDF_in_Large-Momentum_Effective_Theory.pdf
2025-11-19 21:55:34,378 - INFO - root - 正在总结论文 4/40: Systematic Study on the $α$-particle preformation factor in the theory of $α$-decay based on the Tabular Prior-data Fitted Network (TabPFN)
2025-11-19 21:55:49,869 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-19 21:55:49,870 - INFO - root - LLMClient: rate limit reached, sleeping 0.6s
2025-11-19 21:57:00,770 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-19 21:57:41,493 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-19 21:57:41,543 - INFO - root - 正在提取论文图片到目录: ./export\hybrid_attention_Recent\images\Systematic_Study_on_the_$α$-particle_preformation_factor_in_the_theory_of_$α$-decay_based_on_the_Tab
2025-11-19 21:57:42,264 - INFO - root - 已保存图片 1/10：./export\hybrid_attention_Recent\images\Systematic_Study_on_the_$α$-particle_preformation_factor_in_the_theory_of_$α$-decay_based_on_the_Tab\figure_1_page6.jpeg
2025-11-19 21:57:42,664 - INFO - root - 已保存图片 2/10：./export\hybrid_attention_Recent\images\Systematic_Study_on_the_$α$-particle_preformation_factor_in_the_theory_of_$α$-decay_based_on_the_Tab\figure_2_page7.jpeg
2025-11-19 21:57:42,998 - INFO - root - 已保存图片 3/10：./export\hybrid_attention_Recent\images\Systematic_Study_on_the_$α$-particle_preformation_factor_in_the_theory_of_$α$-decay_based_on_the_Tab\figure_3_page7.jpeg
2025-11-19 21:57:43,370 - INFO - root - 已保存图片 4/10：./export\hybrid_attention_Recent\images\Systematic_Study_on_the_$α$-particle_preformation_factor_in_the_theory_of_$α$-decay_based_on_the_Tab\figure_4_page7.jpeg
2025-11-19 21:57:43,689 - INFO - root - 已保存图片 5/10：./export\hybrid_attention_Recent\images\Systematic_Study_on_the_$α$-particle_preformation_factor_in_the_theory_of_$α$-decay_based_on_the_Tab\figure_5_page7.jpeg
2025-11-19 21:57:43,998 - INFO - root - 已保存图片 6/10：./export\hybrid_attention_Recent\images\Systematic_Study_on_the_$α$-particle_preformation_factor_in_the_theory_of_$α$-decay_based_on_the_Tab\figure_6_page7.jpeg
2025-11-19 21:57:44,533 - INFO - root - 已保存图片 7/10：./export\hybrid_attention_Recent\images\Systematic_Study_on_the_$α$-particle_preformation_factor_in_the_theory_of_$α$-decay_based_on_the_Tab\figure_7_page7.jpeg
2025-11-19 21:57:44,885 - INFO - root - 已保存图片 8/10：./export\hybrid_attention_Recent\images\Systematic_Study_on_the_$α$-particle_preformation_factor_in_the_theory_of_$α$-decay_based_on_the_Tab\figure_8_page7.jpeg
2025-11-19 21:57:45,650 - INFO - root - 已保存图片 9/10：./export\hybrid_attention_Recent\images\Systematic_Study_on_the_$α$-particle_preformation_factor_in_the_theory_of_$α$-decay_based_on_the_Tab\figure_9_page10.jpeg
2025-11-19 21:57:46,552 - INFO - root - 已保存图片 10/10：./export\hybrid_attention_Recent\images\Systematic_Study_on_the_$α$-particle_preformation_factor_in_the_theory_of_$α$-decay_based_on_the_Tab\figure_10_page10.jpeg
2025-11-19 21:57:46,642 - INFO - root - 成功添加图片 1：./export\hybrid_attention_Recent\images\Systematic_Study_on_the_$α$-particle_preformation_factor_in_the_theory_of_$α$-decay_based_on_the_Tab\figure_1_page6.jpeg
2025-11-19 21:57:46,643 - INFO - root - 成功添加图片 2：./export\hybrid_attention_Recent\images\Systematic_Study_on_the_$α$-particle_preformation_factor_in_the_theory_of_$α$-decay_based_on_the_Tab\figure_2_page7.jpeg
2025-11-19 21:57:46,645 - INFO - root - 成功添加图片 3：./export\hybrid_attention_Recent\images\Systematic_Study_on_the_$α$-particle_preformation_factor_in_the_theory_of_$α$-decay_based_on_the_Tab\figure_3_page7.jpeg
2025-11-19 21:57:46,648 - INFO - root - 成功添加图片 4：./export\hybrid_attention_Recent\images\Systematic_Study_on_the_$α$-particle_preformation_factor_in_the_theory_of_$α$-decay_based_on_the_Tab\figure_4_page7.jpeg
2025-11-19 21:57:46,650 - INFO - root - 成功添加图片 5：./export\hybrid_attention_Recent\images\Systematic_Study_on_the_$α$-particle_preformation_factor_in_the_theory_of_$α$-decay_based_on_the_Tab\figure_5_page7.jpeg
2025-11-19 21:57:46,651 - INFO - root - 成功添加图片 6：./export\hybrid_attention_Recent\images\Systematic_Study_on_the_$α$-particle_preformation_factor_in_the_theory_of_$α$-decay_based_on_the_Tab\figure_6_page7.jpeg
2025-11-19 21:57:46,653 - INFO - root - 成功添加图片 7：./export\hybrid_attention_Recent\images\Systematic_Study_on_the_$α$-particle_preformation_factor_in_the_theory_of_$α$-decay_based_on_the_Tab\figure_7_page7.jpeg
2025-11-19 21:57:46,654 - INFO - root - 成功添加图片 8：./export\hybrid_attention_Recent\images\Systematic_Study_on_the_$α$-particle_preformation_factor_in_the_theory_of_$α$-decay_based_on_the_Tab\figure_8_page7.jpeg
2025-11-19 21:57:46,662 - INFO - root - 成功添加图片 9：./export\hybrid_attention_Recent\images\Systematic_Study_on_the_$α$-particle_preformation_factor_in_the_theory_of_$α$-decay_based_on_the_Tab\figure_9_page10.jpeg
2025-11-19 21:57:46,662 - INFO - root - 成功添加图片 10：./export\hybrid_attention_Recent\images\Systematic_Study_on_the_$α$-particle_preformation_factor_in_the_theory_of_$α$-decay_based_on_the_Tab\figure_10_page10.jpeg
2025-11-19 21:57:46,740 - INFO - root - 论文《Systematic Study on the $α$-particle preformation factor in the theory of $α$-decay based on the Tabular Prior-data Fitted Network (TabPFN)》的分析已保存到 ./export\hybrid_attention_Recent\Systematic_Study_on_the_$α$-particle_preformation_factor_in_the_theory_of_$α$-decay_based_on_the_Tab.md
2025-11-19 21:57:46,750 - INFO - root - 正在总结论文 5/40: HyMAD: A Hybrid Multi-Activity Detection Approach for Border Surveillance and Monitoring
2025-11-19 21:57:59,167 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-19 21:57:59,195 - INFO - root - LLMClient: rate limit reached, sleeping 1.6s
2025-11-19 21:59:02,644 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-19 21:59:39,385 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-19 21:59:39,438 - INFO - root - 正在提取论文图片到目录: ./export\hybrid_attention_Recent\images\HyMAD_A_Hybrid_Multi-Activity_Detection_Approach_for_Border_Surveillance_and_Monitoring
2025-11-19 21:59:44,520 - INFO - root - 已保存图片 1/10：./export\hybrid_attention_Recent\images\HyMAD_A_Hybrid_Multi-Activity_Detection_Approach_for_Border_Surveillance_and_Monitoring\figure_1_page5.png
2025-11-19 21:59:45,981 - INFO - root - 已保存图片 2/10：./export\hybrid_attention_Recent\images\HyMAD_A_Hybrid_Multi-Activity_Detection_Approach_for_Border_Surveillance_and_Monitoring\figure_2_page9.png
2025-11-19 21:59:46,364 - INFO - root - 已保存图片 3/10：./export\hybrid_attention_Recent\images\HyMAD_A_Hybrid_Multi-Activity_Detection_Approach_for_Border_Surveillance_and_Monitoring\figure_3_page10.png
2025-11-19 21:59:47,620 - INFO - root - 已保存图片 4/10：./export\hybrid_attention_Recent\images\HyMAD_A_Hybrid_Multi-Activity_Detection_Approach_for_Border_Surveillance_and_Monitoring\figure_4_page10.png
2025-11-19 21:59:47,804 - INFO - root - 已保存图片 5/10：./export\hybrid_attention_Recent\images\HyMAD_A_Hybrid_Multi-Activity_Detection_Approach_for_Border_Surveillance_and_Monitoring\figure_5_page7.jpeg
2025-11-19 21:59:48,003 - INFO - root - 已保存图片 6/10：./export\hybrid_attention_Recent\images\HyMAD_A_Hybrid_Multi-Activity_Detection_Approach_for_Border_Surveillance_and_Monitoring\figure_6_page7.jpeg
2025-11-19 21:59:48,133 - INFO - root - 成功添加图片 1：./export\hybrid_attention_Recent\images\HyMAD_A_Hybrid_Multi-Activity_Detection_Approach_for_Border_Surveillance_and_Monitoring\figure_1_page5.png
2025-11-19 21:59:48,175 - INFO - root - 成功添加图片 2：./export\hybrid_attention_Recent\images\HyMAD_A_Hybrid_Multi-Activity_Detection_Approach_for_Border_Surveillance_and_Monitoring\figure_2_page9.png
2025-11-19 21:59:48,191 - INFO - root - 成功添加图片 3：./export\hybrid_attention_Recent\images\HyMAD_A_Hybrid_Multi-Activity_Detection_Approach_for_Border_Surveillance_and_Monitoring\figure_3_page10.png
2025-11-19 21:59:48,224 - INFO - root - 成功添加图片 4：./export\hybrid_attention_Recent\images\HyMAD_A_Hybrid_Multi-Activity_Detection_Approach_for_Border_Surveillance_and_Monitoring\figure_4_page10.png
2025-11-19 21:59:48,267 - INFO - root - 成功添加图片 5：./export\hybrid_attention_Recent\images\HyMAD_A_Hybrid_Multi-Activity_Detection_Approach_for_Border_Surveillance_and_Monitoring\figure_5_page7.jpeg
2025-11-19 21:59:48,283 - INFO - root - 成功添加图片 6：./export\hybrid_attention_Recent\images\HyMAD_A_Hybrid_Multi-Activity_Detection_Approach_for_Border_Surveillance_and_Monitoring\figure_6_page7.jpeg
2025-11-19 21:59:48,387 - INFO - root - 论文《HyMAD: A Hybrid Multi-Activity Detection Approach for Border Surveillance and Monitoring》的分析已保存到 ./export\hybrid_attention_Recent\HyMAD_A_Hybrid_Multi-Activity_Detection_Approach_for_Border_Surveillance_and_Monitoring.md
2025-11-19 21:59:48,554 - INFO - root - 正在总结论文 6/40: Near-Lossless Model Compression Enables Longer Context Inference in DNA Large Language Models
2025-11-19 22:00:00,381 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-19 22:00:00,384 - INFO - root - LLMClient: rate limit reached, sleeping 2.3s
2025-11-19 22:00:52,865 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-19 22:01:30,866 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-19 22:01:30,878 - INFO - root - 正在提取论文图片到目录: ./export\hybrid_attention_Recent\images\Near-Lossless_Model_Compression_Enables_Longer_Context_Inference_in_DNA_Large_Language_Models
2025-11-19 22:01:31,478 - INFO - root - 已保存图片 1/10：./export\hybrid_attention_Recent\images\Near-Lossless_Model_Compression_Enables_Longer_Context_Inference_in_DNA_Large_Language_Models\figure_1_page10.png
2025-11-19 22:01:31,571 - INFO - root - 已保存图片 2/10：./export\hybrid_attention_Recent\images\Near-Lossless_Model_Compression_Enables_Longer_Context_Inference_in_DNA_Large_Language_Models\figure_2_page3.png
2025-11-19 22:01:31,708 - INFO - root - 已保存图片 3/10：./export\hybrid_attention_Recent\images\Near-Lossless_Model_Compression_Enables_Longer_Context_Inference_in_DNA_Large_Language_Models\figure_3_page11.png
2025-11-19 22:01:31,756 - INFO - root - 已保存图片 4/10：./export\hybrid_attention_Recent\images\Near-Lossless_Model_Compression_Enables_Longer_Context_Inference_in_DNA_Large_Language_Models\figure_4_page9.png
2025-11-19 22:01:31,795 - INFO - root - 已保存图片 5/10：./export\hybrid_attention_Recent\images\Near-Lossless_Model_Compression_Enables_Longer_Context_Inference_in_DNA_Large_Language_Models\figure_5_page10.png
2025-11-19 22:01:31,841 - INFO - root - 已保存图片 6/10：./export\hybrid_attention_Recent\images\Near-Lossless_Model_Compression_Enables_Longer_Context_Inference_in_DNA_Large_Language_Models\figure_6_page10.png
2025-11-19 22:01:31,843 - INFO - root - 成功添加图片 1：./export\hybrid_attention_Recent\images\Near-Lossless_Model_Compression_Enables_Longer_Context_Inference_in_DNA_Large_Language_Models\figure_1_page10.png
2025-11-19 22:01:31,844 - INFO - root - 成功添加图片 2：./export\hybrid_attention_Recent\images\Near-Lossless_Model_Compression_Enables_Longer_Context_Inference_in_DNA_Large_Language_Models\figure_2_page3.png
2025-11-19 22:01:31,844 - INFO - root - 成功添加图片 3：./export\hybrid_attention_Recent\images\Near-Lossless_Model_Compression_Enables_Longer_Context_Inference_in_DNA_Large_Language_Models\figure_3_page11.png
2025-11-19 22:01:31,844 - INFO - root - 成功添加图片 4：./export\hybrid_attention_Recent\images\Near-Lossless_Model_Compression_Enables_Longer_Context_Inference_in_DNA_Large_Language_Models\figure_4_page9.png
2025-11-19 22:01:31,844 - INFO - root - 成功添加图片 5：./export\hybrid_attention_Recent\images\Near-Lossless_Model_Compression_Enables_Longer_Context_Inference_in_DNA_Large_Language_Models\figure_5_page10.png
2025-11-19 22:01:31,846 - INFO - root - 成功添加图片 6：./export\hybrid_attention_Recent\images\Near-Lossless_Model_Compression_Enables_Longer_Context_Inference_in_DNA_Large_Language_Models\figure_6_page10.png
2025-11-19 22:01:31,850 - INFO - root - 论文《Near-Lossless Model Compression Enables Longer Context Inference in DNA Large Language Models》的分析已保存到 ./export\hybrid_attention_Recent\Near-Lossless_Model_Compression_Enables_Longer_Context_Inference_in_DNA_Large_Language_Models.md
2025-11-19 22:01:31,855 - INFO - root - 正在总结论文 7/40: Attention via Synaptic Plasticity is All You Need: A Biologically Inspired Spiking Neuromorphic Transformer
2025-11-19 22:01:46,050 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-19 22:01:46,055 - INFO - root - LLMClient: rate limit reached, sleeping 6.8s
2025-11-19 22:02:45,503 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-19 22:03:20,851 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-19 22:03:20,853 - INFO - root - 正在提取论文图片到目录: ./export\hybrid_attention_Recent\images\Attention_via_Synaptic_Plasticity_is_All_You_Need_A_Biologically_Inspired_Spiking_Neuromorphic_Tran
2025-11-19 22:03:34,518 - INFO - root - 已保存图片 1/10：./export\hybrid_attention_Recent\images\Attention_via_Synaptic_Plasticity_is_All_You_Need_A_Biologically_Inspired_Spiking_Neuromorphic_Tran\figure_1_page7.png
2025-11-19 22:03:34,777 - INFO - root - 已保存图片 2/10：./export\hybrid_attention_Recent\images\Attention_via_Synaptic_Plasticity_is_All_You_Need_A_Biologically_Inspired_Spiking_Neuromorphic_Tran\figure_2_page9.png
2025-11-19 22:03:35,108 - INFO - root - 已保存图片 3/10：./export\hybrid_attention_Recent\images\Attention_via_Synaptic_Plasticity_is_All_You_Need_A_Biologically_Inspired_Spiking_Neuromorphic_Tran\figure_3_page8.png
2025-11-19 22:03:35,384 - INFO - root - 已保存图片 4/10：./export\hybrid_attention_Recent\images\Attention_via_Synaptic_Plasticity_is_All_You_Need_A_Biologically_Inspired_Spiking_Neuromorphic_Tran\figure_4_page13.png
2025-11-19 22:03:35,507 - INFO - root - 已保存图片 5/10：./export\hybrid_attention_Recent\images\Attention_via_Synaptic_Plasticity_is_All_You_Need_A_Biologically_Inspired_Spiking_Neuromorphic_Tran\figure_5_page14.png
2025-11-19 22:03:35,664 - INFO - root - 已保存图片 6/10：./export\hybrid_attention_Recent\images\Attention_via_Synaptic_Plasticity_is_All_You_Need_A_Biologically_Inspired_Spiking_Neuromorphic_Tran\figure_6_page14.png
2025-11-19 22:03:35,835 - INFO - root - 已保存图片 7/10：./export\hybrid_attention_Recent\images\Attention_via_Synaptic_Plasticity_is_All_You_Need_A_Biologically_Inspired_Spiking_Neuromorphic_Tran\figure_7_page14.png
2025-11-19 22:03:35,989 - INFO - root - 已保存图片 8/10：./export\hybrid_attention_Recent\images\Attention_via_Synaptic_Plasticity_is_All_You_Need_A_Biologically_Inspired_Spiking_Neuromorphic_Tran\figure_8_page14.png
2025-11-19 22:03:36,117 - INFO - root - 已保存图片 9/10：./export\hybrid_attention_Recent\images\Attention_via_Synaptic_Plasticity_is_All_You_Need_A_Biologically_Inspired_Spiking_Neuromorphic_Tran\figure_9_page14.png
2025-11-19 22:03:36,145 - INFO - root - 成功添加图片 1：./export\hybrid_attention_Recent\images\Attention_via_Synaptic_Plasticity_is_All_You_Need_A_Biologically_Inspired_Spiking_Neuromorphic_Tran\figure_1_page7.png
2025-11-19 22:03:36,146 - INFO - root - 成功添加图片 2：./export\hybrid_attention_Recent\images\Attention_via_Synaptic_Plasticity_is_All_You_Need_A_Biologically_Inspired_Spiking_Neuromorphic_Tran\figure_2_page9.png
2025-11-19 22:03:36,146 - INFO - root - 成功添加图片 3：./export\hybrid_attention_Recent\images\Attention_via_Synaptic_Plasticity_is_All_You_Need_A_Biologically_Inspired_Spiking_Neuromorphic_Tran\figure_3_page8.png
2025-11-19 22:03:36,148 - INFO - root - 成功添加图片 4：./export\hybrid_attention_Recent\images\Attention_via_Synaptic_Plasticity_is_All_You_Need_A_Biologically_Inspired_Spiking_Neuromorphic_Tran\figure_4_page13.png
2025-11-19 22:03:36,148 - INFO - root - 成功添加图片 5：./export\hybrid_attention_Recent\images\Attention_via_Synaptic_Plasticity_is_All_You_Need_A_Biologically_Inspired_Spiking_Neuromorphic_Tran\figure_5_page14.png
2025-11-19 22:03:36,149 - INFO - root - 成功添加图片 6：./export\hybrid_attention_Recent\images\Attention_via_Synaptic_Plasticity_is_All_You_Need_A_Biologically_Inspired_Spiking_Neuromorphic_Tran\figure_6_page14.png
2025-11-19 22:03:36,149 - INFO - root - 成功添加图片 7：./export\hybrid_attention_Recent\images\Attention_via_Synaptic_Plasticity_is_All_You_Need_A_Biologically_Inspired_Spiking_Neuromorphic_Tran\figure_7_page14.png
2025-11-19 22:03:36,149 - INFO - root - 成功添加图片 8：./export\hybrid_attention_Recent\images\Attention_via_Synaptic_Plasticity_is_All_You_Need_A_Biologically_Inspired_Spiking_Neuromorphic_Tran\figure_8_page14.png
2025-11-19 22:03:36,150 - INFO - root - 成功添加图片 9：./export\hybrid_attention_Recent\images\Attention_via_Synaptic_Plasticity_is_All_You_Need_A_Biologically_Inspired_Spiking_Neuromorphic_Tran\figure_9_page14.png
2025-11-19 22:03:36,152 - INFO - root - 论文《Attention via Synaptic Plasticity is All You Need: A Biologically Inspired Spiking Neuromorphic Transformer》的分析已保存到 ./export\hybrid_attention_Recent\Attention_via_Synaptic_Plasticity_is_All_You_Need_A_Biologically_Inspired_Spiking_Neuromorphic_Tran.md
2025-11-19 22:03:36,162 - INFO - root - 正在总结论文 8/40: NERD: Network-Regularized Diffusion Sampling For 3D Computed Tomography
2025-11-19 22:03:50,096 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-19 22:04:50,477 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-19 22:05:29,784 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-19 22:05:29,787 - INFO - root - 正在提取论文图片到目录: ./export\hybrid_attention_Recent\images\NERD_Network-Regularized_Diffusion_Sampling_For_3D_Computed_Tomography
2025-11-19 22:05:30,001 - INFO - root - 已保存图片 1/10：./export\hybrid_attention_Recent\images\NERD_Network-Regularized_Diffusion_Sampling_For_3D_Computed_Tomography\figure_1_page4.png
2025-11-19 22:05:30,077 - INFO - root - 已保存图片 2/10：./export\hybrid_attention_Recent\images\NERD_Network-Regularized_Diffusion_Sampling_For_3D_Computed_Tomography\figure_2_page4.png
2025-11-19 22:05:30,171 - INFO - root - 已保存图片 3/10：./export\hybrid_attention_Recent\images\NERD_Network-Regularized_Diffusion_Sampling_For_3D_Computed_Tomography\figure_3_page4.png
2025-11-19 22:05:30,262 - INFO - root - 已保存图片 4/10：./export\hybrid_attention_Recent\images\NERD_Network-Regularized_Diffusion_Sampling_For_3D_Computed_Tomography\figure_4_page4.png
2025-11-19 22:05:30,336 - INFO - root - 已保存图片 5/10：./export\hybrid_attention_Recent\images\NERD_Network-Regularized_Diffusion_Sampling_For_3D_Computed_Tomography\figure_5_page4.png
2025-11-19 22:05:30,423 - INFO - root - 已保存图片 6/10：./export\hybrid_attention_Recent\images\NERD_Network-Regularized_Diffusion_Sampling_For_3D_Computed_Tomography\figure_6_page4.png
2025-11-19 22:05:30,522 - INFO - root - 已保存图片 7/10：./export\hybrid_attention_Recent\images\NERD_Network-Regularized_Diffusion_Sampling_For_3D_Computed_Tomography\figure_7_page4.png
2025-11-19 22:05:30,613 - INFO - root - 已保存图片 8/10：./export\hybrid_attention_Recent\images\NERD_Network-Regularized_Diffusion_Sampling_For_3D_Computed_Tomography\figure_8_page4.png
2025-11-19 22:05:30,717 - INFO - root - 已保存图片 9/10：./export\hybrid_attention_Recent\images\NERD_Network-Regularized_Diffusion_Sampling_For_3D_Computed_Tomography\figure_9_page4.png
2025-11-19 22:05:30,784 - INFO - root - 已保存图片 10/10：./export\hybrid_attention_Recent\images\NERD_Network-Regularized_Diffusion_Sampling_For_3D_Computed_Tomography\figure_10_page4.png
2025-11-19 22:05:30,786 - INFO - root - 成功添加图片 1：./export\hybrid_attention_Recent\images\NERD_Network-Regularized_Diffusion_Sampling_For_3D_Computed_Tomography\figure_1_page4.png
2025-11-19 22:05:30,790 - INFO - root - 成功添加图片 2：./export\hybrid_attention_Recent\images\NERD_Network-Regularized_Diffusion_Sampling_For_3D_Computed_Tomography\figure_2_page4.png
2025-11-19 22:05:30,791 - INFO - root - 成功添加图片 3：./export\hybrid_attention_Recent\images\NERD_Network-Regularized_Diffusion_Sampling_For_3D_Computed_Tomography\figure_3_page4.png
2025-11-19 22:05:30,792 - INFO - root - 成功添加图片 4：./export\hybrid_attention_Recent\images\NERD_Network-Regularized_Diffusion_Sampling_For_3D_Computed_Tomography\figure_4_page4.png
2025-11-19 22:05:30,792 - INFO - root - 成功添加图片 5：./export\hybrid_attention_Recent\images\NERD_Network-Regularized_Diffusion_Sampling_For_3D_Computed_Tomography\figure_5_page4.png
2025-11-19 22:05:30,793 - INFO - root - 成功添加图片 6：./export\hybrid_attention_Recent\images\NERD_Network-Regularized_Diffusion_Sampling_For_3D_Computed_Tomography\figure_6_page4.png
2025-11-19 22:05:30,793 - INFO - root - 成功添加图片 7：./export\hybrid_attention_Recent\images\NERD_Network-Regularized_Diffusion_Sampling_For_3D_Computed_Tomography\figure_7_page4.png
2025-11-19 22:05:30,795 - INFO - root - 成功添加图片 8：./export\hybrid_attention_Recent\images\NERD_Network-Regularized_Diffusion_Sampling_For_3D_Computed_Tomography\figure_8_page4.png
2025-11-19 22:05:30,797 - INFO - root - 成功添加图片 9：./export\hybrid_attention_Recent\images\NERD_Network-Regularized_Diffusion_Sampling_For_3D_Computed_Tomography\figure_9_page4.png
2025-11-19 22:05:30,798 - INFO - root - 成功添加图片 10：./export\hybrid_attention_Recent\images\NERD_Network-Regularized_Diffusion_Sampling_For_3D_Computed_Tomography\figure_10_page4.png
2025-11-19 22:05:30,801 - INFO - root - 论文《NERD: Network-Regularized Diffusion Sampling For 3D Computed Tomography》的分析已保存到 ./export\hybrid_attention_Recent\NERD_Network-Regularized_Diffusion_Sampling_For_3D_Computed_Tomography.md
2025-11-19 22:05:30,809 - INFO - root - 正在总结论文 9/40: M-CALLM: Multi-level Context Aware LLM Framework for Group Interaction Prediction
2025-11-19 22:05:44,555 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-19 22:05:44,557 - INFO - root - LLMClient: rate limit reached, sleeping 5.9s
2025-11-19 22:06:48,460 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-19 22:07:20,970 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-19 22:07:20,973 - INFO - root - 正在提取论文图片到目录: ./export\hybrid_attention_Recent\images\M-CALLM_Multi-level_Context_Aware_LLM_Framework_for_Group_Interaction_Prediction
2025-11-19 22:07:21,150 - INFO - root - 已保存图片 1/10：./export\hybrid_attention_Recent\images\M-CALLM_Multi-level_Context_Aware_LLM_Framework_for_Group_Interaction_Prediction\figure_1_page4.png
2025-11-19 22:07:21,207 - INFO - root - 已保存图片 2/10：./export\hybrid_attention_Recent\images\M-CALLM_Multi-level_Context_Aware_LLM_Framework_for_Group_Interaction_Prediction\figure_2_page1.jpeg
2025-11-19 22:07:21,258 - INFO - root - 已保存图片 3/10：./export\hybrid_attention_Recent\images\M-CALLM_Multi-level_Context_Aware_LLM_Framework_for_Group_Interaction_Prediction\figure_3_page1.jpeg
2025-11-19 22:07:21,313 - INFO - root - 已保存图片 4/10：./export\hybrid_attention_Recent\images\M-CALLM_Multi-level_Context_Aware_LLM_Framework_for_Group_Interaction_Prediction\figure_4_page9.jpeg
2025-11-19 22:07:21,378 - INFO - root - 已保存图片 5/10：./export\hybrid_attention_Recent\images\M-CALLM_Multi-level_Context_Aware_LLM_Framework_for_Group_Interaction_Prediction\figure_5_page4.jpeg
2025-11-19 22:07:21,407 - INFO - root - 已保存图片 6/10：./export\hybrid_attention_Recent\images\M-CALLM_Multi-level_Context_Aware_LLM_Framework_for_Group_Interaction_Prediction\figure_6_page4.jpeg
2025-11-19 22:07:21,459 - INFO - root - 已保存图片 7/10：./export\hybrid_attention_Recent\images\M-CALLM_Multi-level_Context_Aware_LLM_Framework_for_Group_Interaction_Prediction\figure_7_page9.jpeg
2025-11-19 22:07:21,499 - INFO - root - 已保存图片 8/10：./export\hybrid_attention_Recent\images\M-CALLM_Multi-level_Context_Aware_LLM_Framework_for_Group_Interaction_Prediction\figure_8_page9.jpeg
2025-11-19 22:07:21,541 - INFO - root - 已保存图片 9/10：./export\hybrid_attention_Recent\images\M-CALLM_Multi-level_Context_Aware_LLM_Framework_for_Group_Interaction_Prediction\figure_9_page1.jpeg
2025-11-19 22:07:21,577 - INFO - root - 已保存图片 10/10：./export\hybrid_attention_Recent\images\M-CALLM_Multi-level_Context_Aware_LLM_Framework_for_Group_Interaction_Prediction\figure_10_page1.jpeg
2025-11-19 22:07:21,581 - INFO - root - 成功添加图片 1：./export\hybrid_attention_Recent\images\M-CALLM_Multi-level_Context_Aware_LLM_Framework_for_Group_Interaction_Prediction\figure_1_page4.png
2025-11-19 22:07:21,582 - INFO - root - 成功添加图片 2：./export\hybrid_attention_Recent\images\M-CALLM_Multi-level_Context_Aware_LLM_Framework_for_Group_Interaction_Prediction\figure_2_page1.jpeg
2025-11-19 22:07:21,582 - INFO - root - 成功添加图片 3：./export\hybrid_attention_Recent\images\M-CALLM_Multi-level_Context_Aware_LLM_Framework_for_Group_Interaction_Prediction\figure_3_page1.jpeg
2025-11-19 22:07:21,584 - INFO - root - 成功添加图片 4：./export\hybrid_attention_Recent\images\M-CALLM_Multi-level_Context_Aware_LLM_Framework_for_Group_Interaction_Prediction\figure_4_page9.jpeg
2025-11-19 22:07:21,585 - INFO - root - 成功添加图片 5：./export\hybrid_attention_Recent\images\M-CALLM_Multi-level_Context_Aware_LLM_Framework_for_Group_Interaction_Prediction\figure_5_page4.jpeg
2025-11-19 22:07:21,586 - INFO - root - 成功添加图片 6：./export\hybrid_attention_Recent\images\M-CALLM_Multi-level_Context_Aware_LLM_Framework_for_Group_Interaction_Prediction\figure_6_page4.jpeg
2025-11-19 22:07:21,586 - INFO - root - 成功添加图片 7：./export\hybrid_attention_Recent\images\M-CALLM_Multi-level_Context_Aware_LLM_Framework_for_Group_Interaction_Prediction\figure_7_page9.jpeg
2025-11-19 22:07:21,587 - INFO - root - 成功添加图片 8：./export\hybrid_attention_Recent\images\M-CALLM_Multi-level_Context_Aware_LLM_Framework_for_Group_Interaction_Prediction\figure_8_page9.jpeg
2025-11-19 22:07:21,588 - INFO - root - 成功添加图片 9：./export\hybrid_attention_Recent\images\M-CALLM_Multi-level_Context_Aware_LLM_Framework_for_Group_Interaction_Prediction\figure_9_page1.jpeg
2025-11-19 22:07:21,590 - INFO - root - 成功添加图片 10：./export\hybrid_attention_Recent\images\M-CALLM_Multi-level_Context_Aware_LLM_Framework_for_Group_Interaction_Prediction\figure_10_page1.jpeg
2025-11-19 22:07:21,593 - INFO - root - 论文《M-CALLM: Multi-level Context Aware LLM Framework for Group Interaction Prediction》的分析已保存到 ./export\hybrid_attention_Recent\M-CALLM_Multi-level_Context_Aware_LLM_Framework_for_Group_Interaction_Prediction.md
2025-11-19 22:07:21,602 - INFO - root - 正在总结论文 10/40: Improving segmentation of retinal arteries and veins using cardiac signal in doppler holograms
2025-11-19 22:07:32,057 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-19 22:07:32,062 - INFO - root - LLMClient: rate limit reached, sleeping 16.4s
2025-11-19 22:08:33,512 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-19 22:09:08,672 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-19 22:09:08,684 - INFO - root - 正在提取论文图片到目录: ./export\hybrid_attention_Recent\images\Improving_segmentation_of_retinal_arteries_and_veins_using_cardiac_signal_in_doppler_holograms
2025-11-19 22:09:10,929 - INFO - root - 已保存图片 1/10：./export\hybrid_attention_Recent\images\Improving_segmentation_of_retinal_arteries_and_veins_using_cardiac_signal_in_doppler_holograms\figure_1_page3.png
2025-11-19 22:09:11,136 - INFO - root - 已保存图片 2/10：./export\hybrid_attention_Recent\images\Improving_segmentation_of_retinal_arteries_and_veins_using_cardiac_signal_in_doppler_holograms\figure_2_page2.png
2025-11-19 22:09:11,498 - INFO - root - 已保存图片 3/10：./export\hybrid_attention_Recent\images\Improving_segmentation_of_retinal_arteries_and_veins_using_cardiac_signal_in_doppler_holograms\figure_3_page2.png
2025-11-19 22:09:12,022 - INFO - root - 已保存图片 4/10：./export\hybrid_attention_Recent\images\Improving_segmentation_of_retinal_arteries_and_veins_using_cardiac_signal_in_doppler_holograms\figure_4_page2.png
2025-11-19 22:09:12,209 - INFO - root - 已保存图片 5/10：./export\hybrid_attention_Recent\images\Improving_segmentation_of_retinal_arteries_and_veins_using_cardiac_signal_in_doppler_holograms\figure_5_page4.png
2025-11-19 22:09:12,387 - INFO - root - 已保存图片 6/10：./export\hybrid_attention_Recent\images\Improving_segmentation_of_retinal_arteries_and_veins_using_cardiac_signal_in_doppler_holograms\figure_6_page4.png
2025-11-19 22:09:12,597 - INFO - root - 已保存图片 7/10：./export\hybrid_attention_Recent\images\Improving_segmentation_of_retinal_arteries_and_veins_using_cardiac_signal_in_doppler_holograms\figure_7_page4.png
2025-11-19 22:09:12,797 - INFO - root - 已保存图片 8/10：./export\hybrid_attention_Recent\images\Improving_segmentation_of_retinal_arteries_and_veins_using_cardiac_signal_in_doppler_holograms\figure_8_page4.png
2025-11-19 22:09:12,945 - INFO - root - 已保存图片 9/10：./export\hybrid_attention_Recent\images\Improving_segmentation_of_retinal_arteries_and_veins_using_cardiac_signal_in_doppler_holograms\figure_9_page4.png
2025-11-19 22:09:13,308 - INFO - root - 已保存图片 10/10：./export\hybrid_attention_Recent\images\Improving_segmentation_of_retinal_arteries_and_veins_using_cardiac_signal_in_doppler_holograms\figure_10_page4.png
2025-11-19 22:09:13,370 - INFO - root - 成功添加图片 1：./export\hybrid_attention_Recent\images\Improving_segmentation_of_retinal_arteries_and_veins_using_cardiac_signal_in_doppler_holograms\figure_1_page3.png
2025-11-19 22:09:13,385 - INFO - root - 成功添加图片 2：./export\hybrid_attention_Recent\images\Improving_segmentation_of_retinal_arteries_and_veins_using_cardiac_signal_in_doppler_holograms\figure_2_page2.png
2025-11-19 22:09:13,386 - INFO - root - 成功添加图片 3：./export\hybrid_attention_Recent\images\Improving_segmentation_of_retinal_arteries_and_veins_using_cardiac_signal_in_doppler_holograms\figure_3_page2.png
2025-11-19 22:09:13,388 - INFO - root - 成功添加图片 4：./export\hybrid_attention_Recent\images\Improving_segmentation_of_retinal_arteries_and_veins_using_cardiac_signal_in_doppler_holograms\figure_4_page2.png
2025-11-19 22:09:13,389 - INFO - root - 成功添加图片 5：./export\hybrid_attention_Recent\images\Improving_segmentation_of_retinal_arteries_and_veins_using_cardiac_signal_in_doppler_holograms\figure_5_page4.png
2025-11-19 22:09:13,390 - INFO - root - 成功添加图片 6：./export\hybrid_attention_Recent\images\Improving_segmentation_of_retinal_arteries_and_veins_using_cardiac_signal_in_doppler_holograms\figure_6_page4.png
2025-11-19 22:09:13,390 - INFO - root - 成功添加图片 7：./export\hybrid_attention_Recent\images\Improving_segmentation_of_retinal_arteries_and_veins_using_cardiac_signal_in_doppler_holograms\figure_7_page4.png
2025-11-19 22:09:13,391 - INFO - root - 成功添加图片 8：./export\hybrid_attention_Recent\images\Improving_segmentation_of_retinal_arteries_and_veins_using_cardiac_signal_in_doppler_holograms\figure_8_page4.png
2025-11-19 22:09:13,391 - INFO - root - 成功添加图片 9：./export\hybrid_attention_Recent\images\Improving_segmentation_of_retinal_arteries_and_veins_using_cardiac_signal_in_doppler_holograms\figure_9_page4.png
2025-11-19 22:09:13,393 - INFO - root - 成功添加图片 10：./export\hybrid_attention_Recent\images\Improving_segmentation_of_retinal_arteries_and_veins_using_cardiac_signal_in_doppler_holograms\figure_10_page4.png
2025-11-19 22:09:13,398 - INFO - root - 论文《Improving segmentation of retinal arteries and veins using cardiac signal in doppler holograms》的分析已保存到 ./export\hybrid_attention_Recent\Improving_segmentation_of_retinal_arteries_and_veins_using_cardiac_signal_in_doppler_holograms.md
2025-11-19 22:09:13,405 - INFO - root - 正在总结论文 11/40: Robust Offset-free Kernelized Data-Driven Predictive Control for Nonlinear Systems
2025-11-19 22:09:29,971 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-19 22:09:30,091 - INFO - root - LLMClient: rate limit reached, sleeping 3.5s
2025-11-19 22:10:31,247 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-19 22:11:03,060 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-19 22:11:03,072 - INFO - root - 正在提取论文图片到目录: ./export\hybrid_attention_Recent\images\Robust_Offset-free_Kernelized_Data-Driven_Predictive_Control_for_Nonlinear_Systems
2025-11-19 22:11:03,109 - INFO - root - 论文《Robust Offset-free Kernelized Data-Driven Predictive Control for Nonlinear Systems》的分析已保存到 ./export\hybrid_attention_Recent\Robust_Offset-free_Kernelized_Data-Driven_Predictive_Control_for_Nonlinear_Systems.md
2025-11-19 22:11:03,180 - INFO - root - 正在总结论文 12/40: SLAM-AGS: Slide-Label Aware Multi-Task Pretraining Using Adaptive Gradient Surgery in Computational Cytology
2025-11-19 22:11:22,899 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-19 22:11:22,933 - INFO - root - LLMClient: rate limit reached, sleeping 8.3s
2025-11-19 22:12:28,761 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-19 22:13:01,535 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-19 22:13:01,542 - INFO - root - 正在提取论文图片到目录: ./export\hybrid_attention_Recent\images\SLAM-AGS_Slide-Label_Aware_Multi-Task_Pretraining_Using_Adaptive_Gradient_Surgery_in_Computational
2025-11-19 22:13:01,667 - INFO - root - 已保存图片 1/10：./export\hybrid_attention_Recent\images\SLAM-AGS_Slide-Label_Aware_Multi-Task_Pretraining_Using_Adaptive_Gradient_Surgery_in_Computational\figure_1_page3.jpeg
2025-11-19 22:13:01,708 - INFO - root - 已保存图片 2/10：./export\hybrid_attention_Recent\images\SLAM-AGS_Slide-Label_Aware_Multi-Task_Pretraining_Using_Adaptive_Gradient_Surgery_in_Computational\figure_2_page3.jpeg
2025-11-19 22:13:01,757 - INFO - root - 已保存图片 3/10：./export\hybrid_attention_Recent\images\SLAM-AGS_Slide-Label_Aware_Multi-Task_Pretraining_Using_Adaptive_Gradient_Surgery_in_Computational\figure_3_page3.jpeg
2025-11-19 22:13:01,806 - INFO - root - 已保存图片 4/10：./export\hybrid_attention_Recent\images\SLAM-AGS_Slide-Label_Aware_Multi-Task_Pretraining_Using_Adaptive_Gradient_Surgery_in_Computational\figure_4_page3.jpeg
2025-11-19 22:13:01,809 - INFO - root - 成功添加图片 1：./export\hybrid_attention_Recent\images\SLAM-AGS_Slide-Label_Aware_Multi-Task_Pretraining_Using_Adaptive_Gradient_Surgery_in_Computational\figure_1_page3.jpeg
2025-11-19 22:13:01,809 - INFO - root - 成功添加图片 2：./export\hybrid_attention_Recent\images\SLAM-AGS_Slide-Label_Aware_Multi-Task_Pretraining_Using_Adaptive_Gradient_Surgery_in_Computational\figure_2_page3.jpeg
2025-11-19 22:13:01,809 - INFO - root - 成功添加图片 3：./export\hybrid_attention_Recent\images\SLAM-AGS_Slide-Label_Aware_Multi-Task_Pretraining_Using_Adaptive_Gradient_Surgery_in_Computational\figure_3_page3.jpeg
2025-11-19 22:13:01,809 - INFO - root - 成功添加图片 4：./export\hybrid_attention_Recent\images\SLAM-AGS_Slide-Label_Aware_Multi-Task_Pretraining_Using_Adaptive_Gradient_Surgery_in_Computational\figure_4_page3.jpeg
2025-11-19 22:13:01,813 - INFO - root - 论文《SLAM-AGS: Slide-Label Aware Multi-Task Pretraining Using Adaptive Gradient Surgery in Computational Cytology》的分析已保存到 ./export\hybrid_attention_Recent\SLAM-AGS_Slide-Label_Aware_Multi-Task_Pretraining_Using_Adaptive_Gradient_Surgery_in_Computational.md
2025-11-19 22:13:01,819 - INFO - root - 正在总结论文 13/40: Fusing Biomechanical and Spatio-Temporal Features for Fall Prediction: Characterizing and Mitigating the Simulation-to-Reality Gap
2025-11-19 22:13:14,746 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-19 22:13:14,748 - INFO - root - LLMClient: rate limit reached, sleeping 14.0s
2025-11-19 22:14:13,731 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-19 22:14:50,957 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-19 22:14:50,965 - INFO - root - 正在提取论文图片到目录: ./export\hybrid_attention_Recent\images\Fusing_Biomechanical_and_Spatio-Temporal_Features_for_Fall_Prediction_Characterizing_and_Mitigating
2025-11-19 22:14:51,740 - INFO - root - 已保存图片 1/10：./export\hybrid_attention_Recent\images\Fusing_Biomechanical_and_Spatio-Temporal_Features_for_Fall_Prediction_Characterizing_and_Mitigating\figure_1_page7.png
2025-11-19 22:14:51,938 - INFO - root - 已保存图片 2/10：./export\hybrid_attention_Recent\images\Fusing_Biomechanical_and_Spatio-Temporal_Features_for_Fall_Prediction_Characterizing_and_Mitigating\figure_2_page7.png
2025-11-19 22:14:52,040 - INFO - root - 已保存图片 3/10：./export\hybrid_attention_Recent\images\Fusing_Biomechanical_and_Spatio-Temporal_Features_for_Fall_Prediction_Characterizing_and_Mitigating\figure_3_page7.png
2025-11-19 22:14:52,142 - INFO - root - 已保存图片 4/10：./export\hybrid_attention_Recent\images\Fusing_Biomechanical_and_Spatio-Temporal_Features_for_Fall_Prediction_Characterizing_and_Mitigating\figure_4_page7.png
2025-11-19 22:14:52,191 - INFO - root - 已保存图片 5/10：./export\hybrid_attention_Recent\images\Fusing_Biomechanical_and_Spatio-Temporal_Features_for_Fall_Prediction_Characterizing_and_Mitigating\figure_5_page7.jpeg
2025-11-19 22:14:52,360 - INFO - root - 已保存图片 6/10：./export\hybrid_attention_Recent\images\Fusing_Biomechanical_and_Spatio-Temporal_Features_for_Fall_Prediction_Characterizing_and_Mitigating\figure_6_page4.png
2025-11-19 22:14:52,572 - INFO - root - 已保存图片 7/10：./export\hybrid_attention_Recent\images\Fusing_Biomechanical_and_Spatio-Temporal_Features_for_Fall_Prediction_Characterizing_and_Mitigating\figure_7_page4.png
2025-11-19 22:14:52,679 - INFO - root - 已保存图片 8/10：./export\hybrid_attention_Recent\images\Fusing_Biomechanical_and_Spatio-Temporal_Features_for_Fall_Prediction_Characterizing_and_Mitigating\figure_8_page4.png
2025-11-19 22:14:52,685 - INFO - root - 成功添加图片 1：./export\hybrid_attention_Recent\images\Fusing_Biomechanical_and_Spatio-Temporal_Features_for_Fall_Prediction_Characterizing_and_Mitigating\figure_1_page7.png
2025-11-19 22:14:52,686 - INFO - root - 成功添加图片 2：./export\hybrid_attention_Recent\images\Fusing_Biomechanical_and_Spatio-Temporal_Features_for_Fall_Prediction_Characterizing_and_Mitigating\figure_2_page7.png
2025-11-19 22:14:52,686 - INFO - root - 成功添加图片 3：./export\hybrid_attention_Recent\images\Fusing_Biomechanical_and_Spatio-Temporal_Features_for_Fall_Prediction_Characterizing_and_Mitigating\figure_3_page7.png
2025-11-19 22:14:52,687 - INFO - root - 成功添加图片 4：./export\hybrid_attention_Recent\images\Fusing_Biomechanical_and_Spatio-Temporal_Features_for_Fall_Prediction_Characterizing_and_Mitigating\figure_4_page7.png
2025-11-19 22:14:52,688 - INFO - root - 成功添加图片 5：./export\hybrid_attention_Recent\images\Fusing_Biomechanical_and_Spatio-Temporal_Features_for_Fall_Prediction_Characterizing_and_Mitigating\figure_5_page7.jpeg
2025-11-19 22:14:52,688 - INFO - root - 成功添加图片 6：./export\hybrid_attention_Recent\images\Fusing_Biomechanical_and_Spatio-Temporal_Features_for_Fall_Prediction_Characterizing_and_Mitigating\figure_6_page4.png
2025-11-19 22:14:52,689 - INFO - root - 成功添加图片 7：./export\hybrid_attention_Recent\images\Fusing_Biomechanical_and_Spatio-Temporal_Features_for_Fall_Prediction_Characterizing_and_Mitigating\figure_7_page4.png
2025-11-19 22:14:52,689 - INFO - root - 成功添加图片 8：./export\hybrid_attention_Recent\images\Fusing_Biomechanical_and_Spatio-Temporal_Features_for_Fall_Prediction_Characterizing_and_Mitigating\figure_8_page4.png
2025-11-19 22:14:52,693 - INFO - root - 论文《Fusing Biomechanical and Spatio-Temporal Features for Fall Prediction: Characterizing and Mitigating the Simulation-to-Reality Gap》的分析已保存到 ./export\hybrid_attention_Recent\Fusing_Biomechanical_and_Spatio-Temporal_Features_for_Fall_Prediction_Characterizing_and_Mitigating.md
2025-11-19 22:14:52,701 - INFO - root - 正在总结论文 14/40: XAttn-BMD: Multimodal Deep Learning with Cross-Attention for Femoral Neck Bone Mineral Density Estimation
2025-11-19 22:15:05,869 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-19 22:15:05,880 - INFO - root - LLMClient: rate limit reached, sleeping 7.9s
2025-11-19 22:16:13,403 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-19 22:16:49,017 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-19 22:16:49,022 - INFO - root - 正在提取论文图片到目录: ./export\hybrid_attention_Recent\images\XAttn-BMD_Multimodal_Deep_Learning_with_Cross-Attention_for_Femoral_Neck_Bone_Mineral_Density_Estim
2025-11-19 22:17:08,873 - INFO - root - 已保存图片 1/10：./export\hybrid_attention_Recent\images\XAttn-BMD_Multimodal_Deep_Learning_with_Cross-Attention_for_Femoral_Neck_Bone_Mineral_Density_Estim\figure_1_page13.png
2025-11-19 22:17:09,573 - INFO - root - 已保存图片 2/10：./export\hybrid_attention_Recent\images\XAttn-BMD_Multimodal_Deep_Learning_with_Cross-Attention_for_Femoral_Neck_Bone_Mineral_Density_Estim\figure_2_page26.png
2025-11-19 22:17:10,129 - INFO - root - 已保存图片 3/10：./export\hybrid_attention_Recent\images\XAttn-BMD_Multimodal_Deep_Learning_with_Cross-Attention_for_Femoral_Neck_Bone_Mineral_Density_Estim\figure_3_page12.png
2025-11-19 22:17:10,861 - INFO - root - 已保存图片 4/10：./export\hybrid_attention_Recent\images\XAttn-BMD_Multimodal_Deep_Learning_with_Cross-Attention_for_Femoral_Neck_Bone_Mineral_Density_Estim\figure_4_page10.png
2025-11-19 22:17:11,379 - INFO - root - 已保存图片 5/10：./export\hybrid_attention_Recent\images\XAttn-BMD_Multimodal_Deep_Learning_with_Cross-Attention_for_Femoral_Neck_Bone_Mineral_Density_Estim\figure_5_page24.png
2025-11-19 22:17:11,770 - INFO - root - 已保存图片 6/10：./export\hybrid_attention_Recent\images\XAttn-BMD_Multimodal_Deep_Learning_with_Cross-Attention_for_Femoral_Neck_Bone_Mineral_Density_Estim\figure_6_page27.png
2025-11-19 22:17:12,102 - INFO - root - 已保存图片 7/10：./export\hybrid_attention_Recent\images\XAttn-BMD_Multimodal_Deep_Learning_with_Cross-Attention_for_Femoral_Neck_Bone_Mineral_Density_Estim\figure_7_page9.png
2025-11-19 22:17:12,212 - INFO - root - 成功添加图片 1：./export\hybrid_attention_Recent\images\XAttn-BMD_Multimodal_Deep_Learning_with_Cross-Attention_for_Femoral_Neck_Bone_Mineral_Density_Estim\figure_1_page13.png
2025-11-19 22:17:12,216 - INFO - root - 成功添加图片 2：./export\hybrid_attention_Recent\images\XAttn-BMD_Multimodal_Deep_Learning_with_Cross-Attention_for_Femoral_Neck_Bone_Mineral_Density_Estim\figure_2_page26.png
2025-11-19 22:17:12,217 - INFO - root - 成功添加图片 3：./export\hybrid_attention_Recent\images\XAttn-BMD_Multimodal_Deep_Learning_with_Cross-Attention_for_Femoral_Neck_Bone_Mineral_Density_Estim\figure_3_page12.png
2025-11-19 22:17:12,217 - INFO - root - 成功添加图片 4：./export\hybrid_attention_Recent\images\XAttn-BMD_Multimodal_Deep_Learning_with_Cross-Attention_for_Femoral_Neck_Bone_Mineral_Density_Estim\figure_4_page10.png
2025-11-19 22:17:12,217 - INFO - root - 成功添加图片 5：./export\hybrid_attention_Recent\images\XAttn-BMD_Multimodal_Deep_Learning_with_Cross-Attention_for_Femoral_Neck_Bone_Mineral_Density_Estim\figure_5_page24.png
2025-11-19 22:17:12,221 - INFO - root - 成功添加图片 6：./export\hybrid_attention_Recent\images\XAttn-BMD_Multimodal_Deep_Learning_with_Cross-Attention_for_Femoral_Neck_Bone_Mineral_Density_Estim\figure_6_page27.png
2025-11-19 22:17:12,222 - INFO - root - 成功添加图片 7：./export\hybrid_attention_Recent\images\XAttn-BMD_Multimodal_Deep_Learning_with_Cross-Attention_for_Femoral_Neck_Bone_Mineral_Density_Estim\figure_7_page9.png
2025-11-19 22:17:12,224 - INFO - root - 论文《XAttn-BMD: Multimodal Deep Learning with Cross-Attention for Femoral Neck Bone Mineral Density Estimation》的分析已保存到 ./export\hybrid_attention_Recent\XAttn-BMD_Multimodal_Deep_Learning_with_Cross-Attention_for_Femoral_Neck_Bone_Mineral_Density_Estim.md
2025-11-19 22:17:12,233 - INFO - root - 正在总结论文 15/40: Bridging Human and Model Perspectives: A Comparative Analysis of Political Bias Detection in News Media Using Large Language Models
2025-11-19 22:17:22,232 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-19 22:18:07,841 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-19 22:18:07,848 - INFO - root - LLMClient: rate limit reached, sleeping 4.4s
2025-11-19 22:18:50,724 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-19 22:18:50,730 - INFO - root - 正在提取论文图片到目录: ./export\hybrid_attention_Recent\images\Bridging_Human_and_Model_Perspectives_A_Comparative_Analysis_of_Political_Bias_Detection_in_News_Me
2025-11-19 22:18:50,838 - INFO - root - 已保存图片 1/10：./export\hybrid_attention_Recent\images\Bridging_Human_and_Model_Perspectives_A_Comparative_Analysis_of_Political_Bias_Detection_in_News_Me\figure_1_page3.png
2025-11-19 22:18:50,839 - INFO - root - 成功添加图片 1：./export\hybrid_attention_Recent\images\Bridging_Human_and_Model_Perspectives_A_Comparative_Analysis_of_Political_Bias_Detection_in_News_Me\figure_1_page3.png
2025-11-19 22:18:50,842 - INFO - root - 论文《Bridging Human and Model Perspectives: A Comparative Analysis of Political Bias Detection in News Media Using Large Language Models》的分析已保存到 ./export\hybrid_attention_Recent\Bridging_Human_and_Model_Perspectives_A_Comparative_Analysis_of_Political_Bias_Detection_in_News_Me.md
2025-11-19 22:18:50,846 - INFO - root - 正在总结论文 16/40: 3D-Guided Scalable Flow Matching for Generating Volumetric Tissue Spatial Transcriptomics from Serial Histology
2025-11-19 22:19:06,795 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-19 22:19:06,798 - INFO - root - LLMClient: rate limit reached, sleeping 5.4s
2025-11-19 22:20:29,482 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-19 22:21:11,571 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-19 22:21:11,576 - INFO - root - 正在提取论文图片到目录: ./export\hybrid_attention_Recent\images\3D-Guided_Scalable_Flow_Matching_for_Generating_Volumetric_Tissue_Spatial_Transcriptomics_from_Seria
2025-11-19 22:21:14,755 - INFO - root - 已保存图片 1/10：./export\hybrid_attention_Recent\images\3D-Guided_Scalable_Flow_Matching_for_Generating_Volumetric_Tissue_Spatial_Transcriptomics_from_Seria\figure_1_page3.png
2025-11-19 22:21:14,834 - INFO - root - 已保存图片 2/10：./export\hybrid_attention_Recent\images\3D-Guided_Scalable_Flow_Matching_for_Generating_Volumetric_Tissue_Spatial_Transcriptomics_from_Seria\figure_2_page7.png
2025-11-19 22:21:14,955 - INFO - root - 已保存图片 3/10：./export\hybrid_attention_Recent\images\3D-Guided_Scalable_Flow_Matching_for_Generating_Volumetric_Tissue_Spatial_Transcriptomics_from_Seria\figure_3_page2.png
2025-11-19 22:21:15,075 - INFO - root - 已保存图片 4/10：./export\hybrid_attention_Recent\images\3D-Guided_Scalable_Flow_Matching_for_Generating_Volumetric_Tissue_Spatial_Transcriptomics_from_Seria\figure_4_page8.png
2025-11-19 22:21:15,208 - INFO - root - 已保存图片 5/10：./export\hybrid_attention_Recent\images\3D-Guided_Scalable_Flow_Matching_for_Generating_Volumetric_Tissue_Spatial_Transcriptomics_from_Seria\figure_5_page8.png
2025-11-19 22:21:15,344 - INFO - root - 已保存图片 6/10：./export\hybrid_attention_Recent\images\3D-Guided_Scalable_Flow_Matching_for_Generating_Volumetric_Tissue_Spatial_Transcriptomics_from_Seria\figure_6_page8.png
2025-11-19 22:21:15,461 - INFO - root - 已保存图片 7/10：./export\hybrid_attention_Recent\images\3D-Guided_Scalable_Flow_Matching_for_Generating_Volumetric_Tissue_Spatial_Transcriptomics_from_Seria\figure_7_page8.png
2025-11-19 22:21:15,591 - INFO - root - 已保存图片 8/10：./export\hybrid_attention_Recent\images\3D-Guided_Scalable_Flow_Matching_for_Generating_Volumetric_Tissue_Spatial_Transcriptomics_from_Seria\figure_8_page8.png
2025-11-19 22:21:15,712 - INFO - root - 已保存图片 9/10：./export\hybrid_attention_Recent\images\3D-Guided_Scalable_Flow_Matching_for_Generating_Volumetric_Tissue_Spatial_Transcriptomics_from_Seria\figure_9_page8.png
2025-11-19 22:21:15,843 - INFO - root - 已保存图片 10/10：./export\hybrid_attention_Recent\images\3D-Guided_Scalable_Flow_Matching_for_Generating_Volumetric_Tissue_Spatial_Transcriptomics_from_Seria\figure_10_page8.png
2025-11-19 22:21:15,848 - INFO - root - 成功添加图片 1：./export\hybrid_attention_Recent\images\3D-Guided_Scalable_Flow_Matching_for_Generating_Volumetric_Tissue_Spatial_Transcriptomics_from_Seria\figure_1_page3.png
2025-11-19 22:21:15,849 - INFO - root - 成功添加图片 2：./export\hybrid_attention_Recent\images\3D-Guided_Scalable_Flow_Matching_for_Generating_Volumetric_Tissue_Spatial_Transcriptomics_from_Seria\figure_2_page7.png
2025-11-19 22:21:15,849 - INFO - root - 成功添加图片 3：./export\hybrid_attention_Recent\images\3D-Guided_Scalable_Flow_Matching_for_Generating_Volumetric_Tissue_Spatial_Transcriptomics_from_Seria\figure_3_page2.png
2025-11-19 22:21:15,850 - INFO - root - 成功添加图片 4：./export\hybrid_attention_Recent\images\3D-Guided_Scalable_Flow_Matching_for_Generating_Volumetric_Tissue_Spatial_Transcriptomics_from_Seria\figure_4_page8.png
2025-11-19 22:21:15,850 - INFO - root - 成功添加图片 5：./export\hybrid_attention_Recent\images\3D-Guided_Scalable_Flow_Matching_for_Generating_Volumetric_Tissue_Spatial_Transcriptomics_from_Seria\figure_5_page8.png
2025-11-19 22:21:15,851 - INFO - root - 成功添加图片 6：./export\hybrid_attention_Recent\images\3D-Guided_Scalable_Flow_Matching_for_Generating_Volumetric_Tissue_Spatial_Transcriptomics_from_Seria\figure_6_page8.png
2025-11-19 22:21:15,851 - INFO - root - 成功添加图片 7：./export\hybrid_attention_Recent\images\3D-Guided_Scalable_Flow_Matching_for_Generating_Volumetric_Tissue_Spatial_Transcriptomics_from_Seria\figure_7_page8.png
2025-11-19 22:21:15,852 - INFO - root - 成功添加图片 8：./export\hybrid_attention_Recent\images\3D-Guided_Scalable_Flow_Matching_for_Generating_Volumetric_Tissue_Spatial_Transcriptomics_from_Seria\figure_8_page8.png
2025-11-19 22:21:15,852 - INFO - root - 成功添加图片 9：./export\hybrid_attention_Recent\images\3D-Guided_Scalable_Flow_Matching_for_Generating_Volumetric_Tissue_Spatial_Transcriptomics_from_Seria\figure_9_page8.png
2025-11-19 22:21:15,852 - INFO - root - 成功添加图片 10：./export\hybrid_attention_Recent\images\3D-Guided_Scalable_Flow_Matching_for_Generating_Volumetric_Tissue_Spatial_Transcriptomics_from_Seria\figure_10_page8.png
2025-11-19 22:21:15,854 - INFO - root - 论文《3D-Guided Scalable Flow Matching for Generating Volumetric Tissue Spatial Transcriptomics from Serial Histology》的分析已保存到 ./export\hybrid_attention_Recent\3D-Guided_Scalable_Flow_Matching_for_Generating_Volumetric_Tissue_Spatial_Transcriptomics_from_Seria.md
2025-11-19 22:21:15,862 - INFO - root - 正在总结论文 17/40: OmniZip: Audio-Guided Dynamic Token Compression for Fast Omnimodal Large Language Models
2025-11-19 22:21:25,335 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-19 22:21:25,339 - INFO - root - LLMClient: rate limit reached, sleeping 4.1s
2025-11-19 22:22:36,801 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-19 22:23:11,504 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-19 22:23:11,507 - INFO - root - 正在提取论文图片到目录: ./export\hybrid_attention_Recent\images\OmniZip_Audio-Guided_Dynamic_Token_Compression_for_Fast_Omnimodal_Large_Language_Models
2025-11-19 22:23:12,353 - INFO - root - 已保存图片 1/10：./export\hybrid_attention_Recent\images\OmniZip_Audio-Guided_Dynamic_Token_Compression_for_Fast_Omnimodal_Large_Language_Models\figure_1_page2.png
2025-11-19 22:23:12,484 - INFO - root - 已保存图片 2/10：./export\hybrid_attention_Recent\images\OmniZip_Audio-Guided_Dynamic_Token_Compression_for_Fast_Omnimodal_Large_Language_Models\figure_2_page1.png
2025-11-19 22:23:12,596 - INFO - root - 已保存图片 3/10：./export\hybrid_attention_Recent\images\OmniZip_Audio-Guided_Dynamic_Token_Compression_for_Fast_Omnimodal_Large_Language_Models\figure_3_page1.png
2025-11-19 22:23:12,610 - INFO - root - 已保存图片 4/10：./export\hybrid_attention_Recent\images\OmniZip_Audio-Guided_Dynamic_Token_Compression_for_Fast_Omnimodal_Large_Language_Models\figure_4_page1.jpeg
2025-11-19 22:23:12,627 - INFO - root - 已保存图片 5/10：./export\hybrid_attention_Recent\images\OmniZip_Audio-Guided_Dynamic_Token_Compression_for_Fast_Omnimodal_Large_Language_Models\figure_5_page4.jpeg
2025-11-19 22:23:12,654 - INFO - root - 已保存图片 6/10：./export\hybrid_attention_Recent\images\OmniZip_Audio-Guided_Dynamic_Token_Compression_for_Fast_Omnimodal_Large_Language_Models\figure_6_page1.jpeg
2025-11-19 22:23:12,728 - INFO - root - 已保存图片 7/10：./export\hybrid_attention_Recent\images\OmniZip_Audio-Guided_Dynamic_Token_Compression_for_Fast_Omnimodal_Large_Language_Models\figure_7_page4.jpeg
2025-11-19 22:23:12,845 - INFO - root - 已保存图片 8/10：./export\hybrid_attention_Recent\images\OmniZip_Audio-Guided_Dynamic_Token_Compression_for_Fast_Omnimodal_Large_Language_Models\figure_8_page4.png
2025-11-19 22:23:13,072 - INFO - root - 已保存图片 9/10：./export\hybrid_attention_Recent\images\OmniZip_Audio-Guided_Dynamic_Token_Compression_for_Fast_Omnimodal_Large_Language_Models\figure_9_page1.png
2025-11-19 22:23:13,177 - INFO - root - 已保存图片 10/10：./export\hybrid_attention_Recent\images\OmniZip_Audio-Guided_Dynamic_Token_Compression_for_Fast_Omnimodal_Large_Language_Models\figure_10_page1.jpeg
2025-11-19 22:23:13,253 - INFO - root - 成功添加图片 1：./export\hybrid_attention_Recent\images\OmniZip_Audio-Guided_Dynamic_Token_Compression_for_Fast_Omnimodal_Large_Language_Models\figure_1_page2.png
2025-11-19 22:23:13,308 - INFO - root - 成功添加图片 2：./export\hybrid_attention_Recent\images\OmniZip_Audio-Guided_Dynamic_Token_Compression_for_Fast_Omnimodal_Large_Language_Models\figure_2_page1.png
2025-11-19 22:23:13,361 - INFO - root - 成功添加图片 3：./export\hybrid_attention_Recent\images\OmniZip_Audio-Guided_Dynamic_Token_Compression_for_Fast_Omnimodal_Large_Language_Models\figure_3_page1.png
2025-11-19 22:23:13,399 - INFO - root - 成功添加图片 4：./export\hybrid_attention_Recent\images\OmniZip_Audio-Guided_Dynamic_Token_Compression_for_Fast_Omnimodal_Large_Language_Models\figure_4_page1.jpeg
2025-11-19 22:23:13,461 - INFO - root - 成功添加图片 5：./export\hybrid_attention_Recent\images\OmniZip_Audio-Guided_Dynamic_Token_Compression_for_Fast_Omnimodal_Large_Language_Models\figure_5_page4.jpeg
2025-11-19 22:23:13,487 - INFO - root - 成功添加图片 6：./export\hybrid_attention_Recent\images\OmniZip_Audio-Guided_Dynamic_Token_Compression_for_Fast_Omnimodal_Large_Language_Models\figure_6_page1.jpeg
2025-11-19 22:23:13,521 - INFO - root - 成功添加图片 7：./export\hybrid_attention_Recent\images\OmniZip_Audio-Guided_Dynamic_Token_Compression_for_Fast_Omnimodal_Large_Language_Models\figure_7_page4.jpeg
2025-11-19 22:23:13,539 - INFO - root - 成功添加图片 8：./export\hybrid_attention_Recent\images\OmniZip_Audio-Guided_Dynamic_Token_Compression_for_Fast_Omnimodal_Large_Language_Models\figure_8_page4.png
2025-11-19 22:23:13,547 - INFO - root - 成功添加图片 9：./export\hybrid_attention_Recent\images\OmniZip_Audio-Guided_Dynamic_Token_Compression_for_Fast_Omnimodal_Large_Language_Models\figure_9_page1.png
2025-11-19 22:23:13,555 - INFO - root - 成功添加图片 10：./export\hybrid_attention_Recent\images\OmniZip_Audio-Guided_Dynamic_Token_Compression_for_Fast_Omnimodal_Large_Language_Models\figure_10_page1.jpeg
2025-11-19 22:23:13,577 - INFO - root - 论文《OmniZip: Audio-Guided Dynamic Token Compression for Fast Omnimodal Large Language Models》的分析已保存到 ./export\hybrid_attention_Recent\OmniZip_Audio-Guided_Dynamic_Token_Compression_for_Fast_Omnimodal_Large_Language_Models.md
2025-11-19 22:23:13,595 - INFO - root - 正在总结论文 18/40: Interlayer Coupling Driven Correlated and Charge-Ordered Electronic States in a Transition Metal Dichalcogenide Superlattice
2025-11-19 22:23:31,779 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-19 22:23:31,780 - INFO - root - LLMClient: rate limit reached, sleeping 5.0s
2025-11-19 22:24:28,539 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-19 22:25:08,426 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-19 22:25:08,431 - INFO - root - 正在提取论文图片到目录: ./export\hybrid_attention_Recent\images\Interlayer_Coupling_Driven_Correlated_and_Charge-Ordered_Electronic_States_in_a_Transition_Metal_Dic
2025-11-19 22:25:09,111 - INFO - root - 已保存图片 1/10：./export\hybrid_attention_Recent\images\Interlayer_Coupling_Driven_Correlated_and_Charge-Ordered_Electronic_States_in_a_Transition_Metal_Dic\figure_1_page19.png
2025-11-19 22:25:09,262 - INFO - root - 已保存图片 2/10：./export\hybrid_attention_Recent\images\Interlayer_Coupling_Driven_Correlated_and_Charge-Ordered_Electronic_States_in_a_Transition_Metal_Dic\figure_2_page16.png
2025-11-19 22:25:09,362 - INFO - root - 已保存图片 3/10：./export\hybrid_attention_Recent\images\Interlayer_Coupling_Driven_Correlated_and_Charge-Ordered_Electronic_States_in_a_Transition_Metal_Dic\figure_3_page17.png
2025-11-19 22:25:09,481 - INFO - root - 已保存图片 4/10：./export\hybrid_attention_Recent\images\Interlayer_Coupling_Driven_Correlated_and_Charge-Ordered_Electronic_States_in_a_Transition_Metal_Dic\figure_4_page18.png
2025-11-19 22:25:09,570 - INFO - root - 已保存图片 5/10：./export\hybrid_attention_Recent\images\Interlayer_Coupling_Driven_Correlated_and_Charge-Ordered_Electronic_States_in_a_Transition_Metal_Dic\figure_5_page20.png
2025-11-19 22:25:09,573 - INFO - root - 成功添加图片 1：./export\hybrid_attention_Recent\images\Interlayer_Coupling_Driven_Correlated_and_Charge-Ordered_Electronic_States_in_a_Transition_Metal_Dic\figure_1_page19.png
2025-11-19 22:25:09,573 - INFO - root - 成功添加图片 2：./export\hybrid_attention_Recent\images\Interlayer_Coupling_Driven_Correlated_and_Charge-Ordered_Electronic_States_in_a_Transition_Metal_Dic\figure_2_page16.png
2025-11-19 22:25:09,574 - INFO - root - 成功添加图片 3：./export\hybrid_attention_Recent\images\Interlayer_Coupling_Driven_Correlated_and_Charge-Ordered_Electronic_States_in_a_Transition_Metal_Dic\figure_3_page17.png
2025-11-19 22:25:09,574 - INFO - root - 成功添加图片 4：./export\hybrid_attention_Recent\images\Interlayer_Coupling_Driven_Correlated_and_Charge-Ordered_Electronic_States_in_a_Transition_Metal_Dic\figure_4_page18.png
2025-11-19 22:25:09,574 - INFO - root - 成功添加图片 5：./export\hybrid_attention_Recent\images\Interlayer_Coupling_Driven_Correlated_and_Charge-Ordered_Electronic_States_in_a_Transition_Metal_Dic\figure_5_page20.png
2025-11-19 22:25:09,576 - INFO - root - 论文《Interlayer Coupling Driven Correlated and Charge-Ordered Electronic States in a Transition Metal Dichalcogenide Superlattice》的分析已保存到 ./export\hybrid_attention_Recent\Interlayer_Coupling_Driven_Correlated_and_Charge-Ordered_Electronic_States_in_a_Transition_Metal_Dic.md
2025-11-19 22:25:09,586 - INFO - root - 正在总结论文 19/40: Examining the Metrics for Document-Level Claim Extraction in Czech and Slovak
2025-11-19 22:25:20,936 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-19 22:25:20,941 - INFO - root - LLMClient: rate limit reached, sleeping 7.6s
2025-11-19 22:26:23,197 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-19 22:27:00,324 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-19 22:27:00,326 - INFO - root - 正在提取论文图片到目录: ./export\hybrid_attention_Recent\images\Examining_the_Metrics_for_Document-Level_Claim_Extraction_in_Czech_and_Slovak
2025-11-19 22:27:00,338 - INFO - root - 论文《Examining the Metrics for Document-Level Claim Extraction in Czech and Slovak》的分析已保存到 ./export\hybrid_attention_Recent\Examining_the_Metrics_for_Document-Level_Claim_Extraction_in_Czech_and_Slovak.md
2025-11-19 22:27:00,346 - INFO - root - 正在总结论文 20/40: ForensicFlow: A Tri-Modal Adaptive Network for Robust Deepfake Detection
2025-11-19 22:27:13,788 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-19 22:27:13,789 - INFO - root - LLMClient: rate limit reached, sleeping 9.4s
2025-11-19 22:28:21,267 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-19 22:29:02,057 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-19 22:29:02,063 - INFO - root - 正在提取论文图片到目录: ./export\hybrid_attention_Recent\images\ForensicFlow_A_Tri-Modal_Adaptive_Network_for_Robust_Deepfake_Detection
2025-11-19 22:29:02,262 - INFO - root - 已保存图片 1/10：./export\hybrid_attention_Recent\images\ForensicFlow_A_Tri-Modal_Adaptive_Network_for_Robust_Deepfake_Detection\figure_1_page9.png
2025-11-19 22:29:02,346 - INFO - root - 已保存图片 2/10：./export\hybrid_attention_Recent\images\ForensicFlow_A_Tri-Modal_Adaptive_Network_for_Robust_Deepfake_Detection\figure_2_page3.png
2025-11-19 22:29:02,605 - INFO - root - 已保存图片 3/10：./export\hybrid_attention_Recent\images\ForensicFlow_A_Tri-Modal_Adaptive_Network_for_Robust_Deepfake_Detection\figure_3_page8.png
2025-11-19 22:29:02,843 - INFO - root - 已保存图片 4/10：./export\hybrid_attention_Recent\images\ForensicFlow_A_Tri-Modal_Adaptive_Network_for_Robust_Deepfake_Detection\figure_4_page8.png
2025-11-19 22:29:02,865 - INFO - root - 成功添加图片 1：./export\hybrid_attention_Recent\images\ForensicFlow_A_Tri-Modal_Adaptive_Network_for_Robust_Deepfake_Detection\figure_1_page9.png
2025-11-19 22:29:02,922 - INFO - root - 成功添加图片 2：./export\hybrid_attention_Recent\images\ForensicFlow_A_Tri-Modal_Adaptive_Network_for_Robust_Deepfake_Detection\figure_2_page3.png
2025-11-19 22:29:02,987 - INFO - root - 成功添加图片 3：./export\hybrid_attention_Recent\images\ForensicFlow_A_Tri-Modal_Adaptive_Network_for_Robust_Deepfake_Detection\figure_3_page8.png
2025-11-19 22:29:03,039 - INFO - root - 成功添加图片 4：./export\hybrid_attention_Recent\images\ForensicFlow_A_Tri-Modal_Adaptive_Network_for_Robust_Deepfake_Detection\figure_4_page8.png
2025-11-19 22:29:03,110 - INFO - root - 论文《ForensicFlow: A Tri-Modal Adaptive Network for Robust Deepfake Detection》的分析已保存到 ./export\hybrid_attention_Recent\ForensicFlow_A_Tri-Modal_Adaptive_Network_for_Robust_Deepfake_Detection.md
2025-11-19 22:29:03,194 - INFO - root - 正在总结论文 21/40: MissHDD: Hybrid Deterministic Diffusion for Hetrogeneous Incomplete Data Imputation
2025-11-19 22:29:15,966 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-19 22:29:15,967 - INFO - root - LLMClient: rate limit reached, sleeping 5.3s
2025-11-19 22:30:30,515 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-19 22:31:08,639 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-19 22:31:08,647 - INFO - root - 正在提取论文图片到目录: ./export\hybrid_attention_Recent\images\MissHDD_Hybrid_Deterministic_Diffusion_for_Hetrogeneous_Incomplete_Data_Imputation
2025-11-19 22:31:08,678 - INFO - root - 论文《MissHDD: Hybrid Deterministic Diffusion for Hetrogeneous Incomplete Data Imputation》的分析已保存到 ./export\hybrid_attention_Recent\MissHDD_Hybrid_Deterministic_Diffusion_for_Hetrogeneous_Incomplete_Data_Imputation.md
2025-11-19 22:31:08,684 - INFO - root - 正在总结论文 22/40: Tri-Hybrid Beamforming Design for Fully-Connected Pinching Antenna Systems
2025-11-19 22:31:21,090 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-19 22:31:21,091 - INFO - root - LLMClient: rate limit reached, sleeping 9.4s
2025-11-19 22:32:26,859 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-19 22:33:03,886 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-19 22:33:03,892 - INFO - root - 正在提取论文图片到目录: ./export\hybrid_attention_Recent\images\Tri-Hybrid_Beamforming_Design_for_Fully-Connected_Pinching_Antenna_Systems
2025-11-19 22:33:04,811 - INFO - root - 已保存图片 1/10：./export\hybrid_attention_Recent\images\Tri-Hybrid_Beamforming_Design_for_Fully-Connected_Pinching_Antenna_Systems\figure_1_page12.png
2025-11-19 22:33:04,900 - INFO - root - 已保存图片 2/10：./export\hybrid_attention_Recent\images\Tri-Hybrid_Beamforming_Design_for_Fully-Connected_Pinching_Antenna_Systems\figure_2_page12.png
2025-11-19 22:33:04,990 - INFO - root - 已保存图片 3/10：./export\hybrid_attention_Recent\images\Tri-Hybrid_Beamforming_Design_for_Fully-Connected_Pinching_Antenna_Systems\figure_3_page12.png
2025-11-19 22:33:05,055 - INFO - root - 已保存图片 4/10：./export\hybrid_attention_Recent\images\Tri-Hybrid_Beamforming_Design_for_Fully-Connected_Pinching_Antenna_Systems\figure_4_page12.png
2025-11-19 22:33:05,101 - INFO - root - 已保存图片 5/10：./export\hybrid_attention_Recent\images\Tri-Hybrid_Beamforming_Design_for_Fully-Connected_Pinching_Antenna_Systems\figure_5_page12.png
2025-11-19 22:33:05,162 - INFO - root - 已保存图片 6/10：./export\hybrid_attention_Recent\images\Tri-Hybrid_Beamforming_Design_for_Fully-Connected_Pinching_Antenna_Systems\figure_6_page12.png
2025-11-19 22:33:05,272 - INFO - root - 已保存图片 7/10：./export\hybrid_attention_Recent\images\Tri-Hybrid_Beamforming_Design_for_Fully-Connected_Pinching_Antenna_Systems\figure_7_page12.png
2025-11-19 22:33:05,396 - INFO - root - 已保存图片 8/10：./export\hybrid_attention_Recent\images\Tri-Hybrid_Beamforming_Design_for_Fully-Connected_Pinching_Antenna_Systems\figure_8_page12.png
2025-11-19 22:33:05,524 - INFO - root - 已保存图片 9/10：./export\hybrid_attention_Recent\images\Tri-Hybrid_Beamforming_Design_for_Fully-Connected_Pinching_Antenna_Systems\figure_9_page12.png
2025-11-19 22:33:05,629 - INFO - root - 已保存图片 10/10：./export\hybrid_attention_Recent\images\Tri-Hybrid_Beamforming_Design_for_Fully-Connected_Pinching_Antenna_Systems\figure_10_page12.png
2025-11-19 22:33:05,632 - INFO - root - 成功添加图片 1：./export\hybrid_attention_Recent\images\Tri-Hybrid_Beamforming_Design_for_Fully-Connected_Pinching_Antenna_Systems\figure_1_page12.png
2025-11-19 22:33:05,632 - INFO - root - 成功添加图片 2：./export\hybrid_attention_Recent\images\Tri-Hybrid_Beamforming_Design_for_Fully-Connected_Pinching_Antenna_Systems\figure_2_page12.png
2025-11-19 22:33:05,632 - INFO - root - 成功添加图片 3：./export\hybrid_attention_Recent\images\Tri-Hybrid_Beamforming_Design_for_Fully-Connected_Pinching_Antenna_Systems\figure_3_page12.png
2025-11-19 22:33:05,633 - INFO - root - 成功添加图片 4：./export\hybrid_attention_Recent\images\Tri-Hybrid_Beamforming_Design_for_Fully-Connected_Pinching_Antenna_Systems\figure_4_page12.png
2025-11-19 22:33:05,633 - INFO - root - 成功添加图片 5：./export\hybrid_attention_Recent\images\Tri-Hybrid_Beamforming_Design_for_Fully-Connected_Pinching_Antenna_Systems\figure_5_page12.png
2025-11-19 22:33:05,633 - INFO - root - 成功添加图片 6：./export\hybrid_attention_Recent\images\Tri-Hybrid_Beamforming_Design_for_Fully-Connected_Pinching_Antenna_Systems\figure_6_page12.png
2025-11-19 22:33:05,633 - INFO - root - 成功添加图片 7：./export\hybrid_attention_Recent\images\Tri-Hybrid_Beamforming_Design_for_Fully-Connected_Pinching_Antenna_Systems\figure_7_page12.png
2025-11-19 22:33:05,633 - INFO - root - 成功添加图片 8：./export\hybrid_attention_Recent\images\Tri-Hybrid_Beamforming_Design_for_Fully-Connected_Pinching_Antenna_Systems\figure_8_page12.png
2025-11-19 22:33:05,635 - INFO - root - 成功添加图片 9：./export\hybrid_attention_Recent\images\Tri-Hybrid_Beamforming_Design_for_Fully-Connected_Pinching_Antenna_Systems\figure_9_page12.png
2025-11-19 22:33:05,635 - INFO - root - 成功添加图片 10：./export\hybrid_attention_Recent\images\Tri-Hybrid_Beamforming_Design_for_Fully-Connected_Pinching_Antenna_Systems\figure_10_page12.png
2025-11-19 22:33:05,637 - INFO - root - 论文《Tri-Hybrid Beamforming Design for Fully-Connected Pinching Antenna Systems》的分析已保存到 ./export\hybrid_attention_Recent\Tri-Hybrid_Beamforming_Design_for_Fully-Connected_Pinching_Antenna_Systems.md
2025-11-19 22:33:05,646 - INFO - root - 正在总结论文 23/40: IMSE: Efficient U-Net-based Speech Enhancement using Inception Depthwise Convolution and Amplitude-Aware Linear Attention
2025-11-19 22:33:20,790 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-19 22:33:20,790 - INFO - root - LLMClient: rate limit reached, sleeping 6.1s
2025-11-19 22:34:38,721 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-19 22:35:16,906 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-19 22:35:16,908 - INFO - root - 正在提取论文图片到目录: ./export\hybrid_attention_Recent\images\IMSE_Efficient_U-Net-based_Speech_Enhancement_using_Inception_Depthwise_Convolution_and_Amplitude-A
2025-11-19 22:35:17,064 - INFO - root - 已保存图片 1/10：./export\hybrid_attention_Recent\images\IMSE_Efficient_U-Net-based_Speech_Enhancement_using_Inception_Depthwise_Convolution_and_Amplitude-A\figure_1_page3.png
2025-11-19 22:35:17,131 - INFO - root - 已保存图片 2/10：./export\hybrid_attention_Recent\images\IMSE_Efficient_U-Net-based_Speech_Enhancement_using_Inception_Depthwise_Convolution_and_Amplitude-A\figure_2_page3.png
2025-11-19 22:35:17,133 - INFO - root - 成功添加图片 1：./export\hybrid_attention_Recent\images\IMSE_Efficient_U-Net-based_Speech_Enhancement_using_Inception_Depthwise_Convolution_and_Amplitude-A\figure_1_page3.png
2025-11-19 22:35:17,134 - INFO - root - 成功添加图片 2：./export\hybrid_attention_Recent\images\IMSE_Efficient_U-Net-based_Speech_Enhancement_using_Inception_Depthwise_Convolution_and_Amplitude-A\figure_2_page3.png
2025-11-19 22:35:17,135 - INFO - root - 论文《IMSE: Efficient U-Net-based Speech Enhancement using Inception Depthwise Convolution and Amplitude-Aware Linear Attention》的分析已保存到 ./export\hybrid_attention_Recent\IMSE_Efficient_U-Net-based_Speech_Enhancement_using_Inception_Depthwise_Convolution_and_Amplitude-A.md
2025-11-19 22:35:17,138 - INFO - root - 正在总结论文 24/40: CLO: Efficient LLM Inference System with CPU-Light KVCache Offloading via Algorithm-System Co-Design
2025-11-19 22:35:32,481 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-19 22:35:32,483 - INFO - root - LLMClient: rate limit reached, sleeping 6.2s
2025-11-19 22:36:46,488 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-19 22:37:25,149 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-19 22:37:25,155 - INFO - root - 正在提取论文图片到目录: ./export\hybrid_attention_Recent\images\CLO_Efficient_LLM_Inference_System_with_CPU-Light_KVCache_Offloading_via_Algorithm-System_Co-Design
2025-11-19 22:37:25,220 - INFO - root - 已保存图片 1/10：./export\hybrid_attention_Recent\images\CLO_Efficient_LLM_Inference_System_with_CPU-Light_KVCache_Offloading_via_Algorithm-System_Co-Design\figure_1_page8.png
2025-11-19 22:37:25,235 - INFO - root - 已保存图片 2/10：./export\hybrid_attention_Recent\images\CLO_Efficient_LLM_Inference_System_with_CPU-Light_KVCache_Offloading_via_Algorithm-System_Co-Design\figure_2_page8.png
2025-11-19 22:37:25,257 - INFO - root - 已保存图片 3/10：./export\hybrid_attention_Recent\images\CLO_Efficient_LLM_Inference_System_with_CPU-Light_KVCache_Offloading_via_Algorithm-System_Co-Design\figure_3_page8.png
2025-11-19 22:37:25,273 - INFO - root - 已保存图片 4/10：./export\hybrid_attention_Recent\images\CLO_Efficient_LLM_Inference_System_with_CPU-Light_KVCache_Offloading_via_Algorithm-System_Co-Design\figure_4_page8.png
2025-11-19 22:37:25,293 - INFO - root - 已保存图片 5/10：./export\hybrid_attention_Recent\images\CLO_Efficient_LLM_Inference_System_with_CPU-Light_KVCache_Offloading_via_Algorithm-System_Co-Design\figure_5_page8.png
2025-11-19 22:37:25,321 - INFO - root - 已保存图片 6/10：./export\hybrid_attention_Recent\images\CLO_Efficient_LLM_Inference_System_with_CPU-Light_KVCache_Offloading_via_Algorithm-System_Co-Design\figure_6_page8.png
2025-11-19 22:37:25,354 - INFO - root - 已保存图片 7/10：./export\hybrid_attention_Recent\images\CLO_Efficient_LLM_Inference_System_with_CPU-Light_KVCache_Offloading_via_Algorithm-System_Co-Design\figure_7_page8.png
2025-11-19 22:37:25,355 - INFO - root - 成功添加图片 1：./export\hybrid_attention_Recent\images\CLO_Efficient_LLM_Inference_System_with_CPU-Light_KVCache_Offloading_via_Algorithm-System_Co-Design\figure_1_page8.png
2025-11-19 22:37:25,356 - INFO - root - 成功添加图片 2：./export\hybrid_attention_Recent\images\CLO_Efficient_LLM_Inference_System_with_CPU-Light_KVCache_Offloading_via_Algorithm-System_Co-Design\figure_2_page8.png
2025-11-19 22:37:25,357 - INFO - root - 成功添加图片 3：./export\hybrid_attention_Recent\images\CLO_Efficient_LLM_Inference_System_with_CPU-Light_KVCache_Offloading_via_Algorithm-System_Co-Design\figure_3_page8.png
2025-11-19 22:37:25,358 - INFO - root - 成功添加图片 4：./export\hybrid_attention_Recent\images\CLO_Efficient_LLM_Inference_System_with_CPU-Light_KVCache_Offloading_via_Algorithm-System_Co-Design\figure_4_page8.png
2025-11-19 22:37:25,359 - INFO - root - 成功添加图片 5：./export\hybrid_attention_Recent\images\CLO_Efficient_LLM_Inference_System_with_CPU-Light_KVCache_Offloading_via_Algorithm-System_Co-Design\figure_5_page8.png
2025-11-19 22:37:25,360 - INFO - root - 成功添加图片 6：./export\hybrid_attention_Recent\images\CLO_Efficient_LLM_Inference_System_with_CPU-Light_KVCache_Offloading_via_Algorithm-System_Co-Design\figure_6_page8.png
2025-11-19 22:37:25,361 - INFO - root - 成功添加图片 7：./export\hybrid_attention_Recent\images\CLO_Efficient_LLM_Inference_System_with_CPU-Light_KVCache_Offloading_via_Algorithm-System_Co-Design\figure_7_page8.png
2025-11-19 22:37:25,363 - INFO - root - 论文《CLO: Efficient LLM Inference System with CPU-Light KVCache Offloading via Algorithm-System Co-Design》的分析已保存到 ./export\hybrid_attention_Recent\CLO_Efficient_LLM_Inference_System_with_CPU-Light_KVCache_Offloading_via_Algorithm-System_Co-Design.md
2025-11-19 22:37:25,366 - INFO - root - 正在总结论文 25/40: Simulating quantum electrodynamics in 2+1 dimensions with qubits and qumodes
2025-11-19 22:37:41,875 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-19 22:37:41,876 - INFO - root - LLMClient: rate limit reached, sleeping 4.6s
2025-11-19 22:38:57,709 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-19 22:39:41,039 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-19 22:39:41,044 - INFO - root - 正在提取论文图片到目录: ./export\hybrid_attention_Recent\images\Simulating_quantum_electrodynamics_in_2+1_dimensions_with_qubits_and_qumodes
2025-11-19 22:39:41,626 - INFO - root - 已保存图片 1/10：./export\hybrid_attention_Recent\images\Simulating_quantum_electrodynamics_in_2+1_dimensions_with_qubits_and_qumodes\figure_1_page28.png
2025-11-19 22:39:41,763 - INFO - root - 已保存图片 2/10：./export\hybrid_attention_Recent\images\Simulating_quantum_electrodynamics_in_2+1_dimensions_with_qubits_and_qumodes\figure_2_page27.png
2025-11-19 22:39:41,897 - INFO - root - 已保存图片 3/10：./export\hybrid_attention_Recent\images\Simulating_quantum_electrodynamics_in_2+1_dimensions_with_qubits_and_qumodes\figure_3_page18.png
2025-11-19 22:39:41,901 - INFO - root - 成功添加图片 1：./export\hybrid_attention_Recent\images\Simulating_quantum_electrodynamics_in_2+1_dimensions_with_qubits_and_qumodes\figure_1_page28.png
2025-11-19 22:39:41,901 - INFO - root - 成功添加图片 2：./export\hybrid_attention_Recent\images\Simulating_quantum_electrodynamics_in_2+1_dimensions_with_qubits_and_qumodes\figure_2_page27.png
2025-11-19 22:39:41,902 - INFO - root - 成功添加图片 3：./export\hybrid_attention_Recent\images\Simulating_quantum_electrodynamics_in_2+1_dimensions_with_qubits_and_qumodes\figure_3_page18.png
2025-11-19 22:39:41,904 - INFO - root - 论文《Simulating quantum electrodynamics in 2+1 dimensions with qubits and qumodes》的分析已保存到 ./export\hybrid_attention_Recent\Simulating_quantum_electrodynamics_in_2+1_dimensions_with_qubits_and_qumodes.md
2025-11-19 22:39:41,911 - INFO - root - 正在总结论文 26/40: Neural network impurity solver for real-frequency dynamical mean-field theory
2025-11-19 22:39:53,859 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-19 22:39:53,860 - INFO - root - LLMClient: rate limit reached, sleeping 3.9s
2025-11-19 22:40:59,141 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-19 22:41:36,105 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-19 22:41:36,107 - INFO - root - 正在提取论文图片到目录: ./export\hybrid_attention_Recent\images\Neural_network_impurity_solver_for_real-frequency_dynamical_mean-field_theory
2025-11-19 22:41:36,135 - INFO - root - 已保存图片 1/10：./export\hybrid_attention_Recent\images\Neural_network_impurity_solver_for_real-frequency_dynamical_mean-field_theory\figure_1_page7.png
2025-11-19 22:41:36,139 - INFO - root - 已保存图片 2/10：./export\hybrid_attention_Recent\images\Neural_network_impurity_solver_for_real-frequency_dynamical_mean-field_theory\figure_2_page7.png
2025-11-19 22:41:36,140 - INFO - root - 成功添加图片 1：./export\hybrid_attention_Recent\images\Neural_network_impurity_solver_for_real-frequency_dynamical_mean-field_theory\figure_1_page7.png
2025-11-19 22:41:36,141 - INFO - root - 成功添加图片 2：./export\hybrid_attention_Recent\images\Neural_network_impurity_solver_for_real-frequency_dynamical_mean-field_theory\figure_2_page7.png
2025-11-19 22:41:36,142 - INFO - root - 论文《Neural network impurity solver for real-frequency dynamical mean-field theory》的分析已保存到 ./export\hybrid_attention_Recent\Neural_network_impurity_solver_for_real-frequency_dynamical_mean-field_theory.md
2025-11-19 22:41:36,149 - INFO - root - 正在总结论文 27/40: Parameter Aware Mamba Model for Multi-task Dense Prediction
2025-11-19 22:41:49,513 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-19 22:41:49,514 - INFO - root - LLMClient: rate limit reached, sleeping 9.6s
2025-11-19 22:42:57,911 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-19 22:43:35,628 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-19 22:43:35,629 - INFO - root - 正在提取论文图片到目录: ./export\hybrid_attention_Recent\images\Parameter_Aware_Mamba_Model_for_Multi-task_Dense_Prediction
2025-11-19 22:43:38,517 - INFO - root - 已保存图片 1/10：./export\hybrid_attention_Recent\images\Parameter_Aware_Mamba_Model_for_Multi-task_Dense_Prediction\figure_1_page2.png
2025-11-19 22:43:38,662 - INFO - root - 已保存图片 2/10：./export\hybrid_attention_Recent\images\Parameter_Aware_Mamba_Model_for_Multi-task_Dense_Prediction\figure_2_page8.png
2025-11-19 22:43:38,805 - INFO - root - 已保存图片 3/10：./export\hybrid_attention_Recent\images\Parameter_Aware_Mamba_Model_for_Multi-task_Dense_Prediction\figure_3_page8.png
2025-11-19 22:43:38,879 - INFO - root - 已保存图片 4/10：./export\hybrid_attention_Recent\images\Parameter_Aware_Mamba_Model_for_Multi-task_Dense_Prediction\figure_4_page2.png
2025-11-19 22:43:38,940 - INFO - root - 已保存图片 5/10：./export\hybrid_attention_Recent\images\Parameter_Aware_Mamba_Model_for_Multi-task_Dense_Prediction\figure_5_page9.png
2025-11-19 22:43:39,012 - INFO - root - 已保存图片 6/10：./export\hybrid_attention_Recent\images\Parameter_Aware_Mamba_Model_for_Multi-task_Dense_Prediction\figure_6_page9.png
2025-11-19 22:43:39,082 - INFO - root - 已保存图片 7/10：./export\hybrid_attention_Recent\images\Parameter_Aware_Mamba_Model_for_Multi-task_Dense_Prediction\figure_7_page9.png
2025-11-19 22:43:39,151 - INFO - root - 已保存图片 8/10：./export\hybrid_attention_Recent\images\Parameter_Aware_Mamba_Model_for_Multi-task_Dense_Prediction\figure_8_page9.png
2025-11-19 22:43:39,224 - INFO - root - 已保存图片 9/10：./export\hybrid_attention_Recent\images\Parameter_Aware_Mamba_Model_for_Multi-task_Dense_Prediction\figure_9_page9.png
2025-11-19 22:43:39,286 - INFO - root - 已保存图片 10/10：./export\hybrid_attention_Recent\images\Parameter_Aware_Mamba_Model_for_Multi-task_Dense_Prediction\figure_10_page2.png
2025-11-19 22:43:39,292 - INFO - root - 成功添加图片 1：./export\hybrid_attention_Recent\images\Parameter_Aware_Mamba_Model_for_Multi-task_Dense_Prediction\figure_1_page2.png
2025-11-19 22:43:39,293 - INFO - root - 成功添加图片 2：./export\hybrid_attention_Recent\images\Parameter_Aware_Mamba_Model_for_Multi-task_Dense_Prediction\figure_2_page8.png
2025-11-19 22:43:39,294 - INFO - root - 成功添加图片 3：./export\hybrid_attention_Recent\images\Parameter_Aware_Mamba_Model_for_Multi-task_Dense_Prediction\figure_3_page8.png
2025-11-19 22:43:39,294 - INFO - root - 成功添加图片 4：./export\hybrid_attention_Recent\images\Parameter_Aware_Mamba_Model_for_Multi-task_Dense_Prediction\figure_4_page2.png
2025-11-19 22:43:39,295 - INFO - root - 成功添加图片 5：./export\hybrid_attention_Recent\images\Parameter_Aware_Mamba_Model_for_Multi-task_Dense_Prediction\figure_5_page9.png
2025-11-19 22:43:39,295 - INFO - root - 成功添加图片 6：./export\hybrid_attention_Recent\images\Parameter_Aware_Mamba_Model_for_Multi-task_Dense_Prediction\figure_6_page9.png
2025-11-19 22:43:39,295 - INFO - root - 成功添加图片 7：./export\hybrid_attention_Recent\images\Parameter_Aware_Mamba_Model_for_Multi-task_Dense_Prediction\figure_7_page9.png
2025-11-19 22:43:39,296 - INFO - root - 成功添加图片 8：./export\hybrid_attention_Recent\images\Parameter_Aware_Mamba_Model_for_Multi-task_Dense_Prediction\figure_8_page9.png
2025-11-19 22:43:39,296 - INFO - root - 成功添加图片 9：./export\hybrid_attention_Recent\images\Parameter_Aware_Mamba_Model_for_Multi-task_Dense_Prediction\figure_9_page9.png
2025-11-19 22:43:39,296 - INFO - root - 成功添加图片 10：./export\hybrid_attention_Recent\images\Parameter_Aware_Mamba_Model_for_Multi-task_Dense_Prediction\figure_10_page2.png
2025-11-19 22:43:39,299 - INFO - root - 论文《Parameter Aware Mamba Model for Multi-task Dense Prediction》的分析已保存到 ./export\hybrid_attention_Recent\Parameter_Aware_Mamba_Model_for_Multi-task_Dense_Prediction.md
2025-11-19 22:43:39,307 - INFO - root - 正在总结论文 28/40: Enhancing End-to-End Autonomous Driving with Risk Semantic Distillaion from VLM
2025-11-19 22:43:53,216 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-19 22:43:53,221 - INFO - root - LLMClient: rate limit reached, sleeping 4.7s
2025-11-19 22:44:54,892 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-19 22:45:39,834 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-19 22:45:39,836 - INFO - root - 正在提取论文图片到目录: ./export\hybrid_attention_Recent\images\Enhancing_End-to-End_Autonomous_Driving_with_Risk_Semantic_Distillaion_from_VLM
2025-11-19 22:45:40,840 - INFO - root - 已保存图片 1/10：./export\hybrid_attention_Recent\images\Enhancing_End-to-End_Autonomous_Driving_with_Risk_Semantic_Distillaion_from_VLM\figure_1_page8.png
2025-11-19 22:45:40,991 - INFO - root - 已保存图片 2/10：./export\hybrid_attention_Recent\images\Enhancing_End-to-End_Autonomous_Driving_with_Risk_Semantic_Distillaion_from_VLM\figure_2_page8.png
2025-11-19 22:45:41,131 - INFO - root - 已保存图片 3/10：./export\hybrid_attention_Recent\images\Enhancing_End-to-End_Autonomous_Driving_with_Risk_Semantic_Distillaion_from_VLM\figure_3_page8.png
2025-11-19 22:45:41,274 - INFO - root - 已保存图片 4/10：./export\hybrid_attention_Recent\images\Enhancing_End-to-End_Autonomous_Driving_with_Risk_Semantic_Distillaion_from_VLM\figure_4_page8.png
2025-11-19 22:45:41,280 - INFO - root - 成功添加图片 1：./export\hybrid_attention_Recent\images\Enhancing_End-to-End_Autonomous_Driving_with_Risk_Semantic_Distillaion_from_VLM\figure_1_page8.png
2025-11-19 22:45:41,280 - INFO - root - 成功添加图片 2：./export\hybrid_attention_Recent\images\Enhancing_End-to-End_Autonomous_Driving_with_Risk_Semantic_Distillaion_from_VLM\figure_2_page8.png
2025-11-19 22:45:41,281 - INFO - root - 成功添加图片 3：./export\hybrid_attention_Recent\images\Enhancing_End-to-End_Autonomous_Driving_with_Risk_Semantic_Distillaion_from_VLM\figure_3_page8.png
2025-11-19 22:45:41,282 - INFO - root - 成功添加图片 4：./export\hybrid_attention_Recent\images\Enhancing_End-to-End_Autonomous_Driving_with_Risk_Semantic_Distillaion_from_VLM\figure_4_page8.png
2025-11-19 22:45:41,285 - INFO - root - 论文《Enhancing End-to-End Autonomous Driving with Risk Semantic Distillaion from VLM》的分析已保存到 ./export\hybrid_attention_Recent\Enhancing_End-to-End_Autonomous_Driving_with_Risk_Semantic_Distillaion_from_VLM.md
2025-11-19 22:45:41,294 - INFO - root - 正在总结论文 29/40: Learning Subglacial Bed Topography from Sparse Radar with Physics-Guided Residuals
2025-11-19 22:45:58,020 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-19 22:47:13,650 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-19 22:47:48,396 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-19 22:47:48,398 - INFO - root - 正在提取论文图片到目录: ./export\hybrid_attention_Recent\images\Learning_Subglacial_Bed_Topography_from_Sparse_Radar_with_Physics-Guided_Residuals
2025-11-19 22:47:52,599 - INFO - root - 已保存图片 1/10：./export\hybrid_attention_Recent\images\Learning_Subglacial_Bed_Topography_from_Sparse_Radar_with_Physics-Guided_Residuals\figure_1_page4.png
2025-11-19 22:47:53,012 - INFO - root - 已保存图片 2/10：./export\hybrid_attention_Recent\images\Learning_Subglacial_Bed_Topography_from_Sparse_Radar_with_Physics-Guided_Residuals\figure_2_page5.png
2025-11-19 22:47:53,166 - INFO - root - 已保存图片 3/10：./export\hybrid_attention_Recent\images\Learning_Subglacial_Bed_Topography_from_Sparse_Radar_with_Physics-Guided_Residuals\figure_3_page13.png
2025-11-19 22:47:53,323 - INFO - root - 已保存图片 4/10：./export\hybrid_attention_Recent\images\Learning_Subglacial_Bed_Topography_from_Sparse_Radar_with_Physics-Guided_Residuals\figure_4_page8.png
2025-11-19 22:47:53,457 - INFO - root - 已保存图片 5/10：./export\hybrid_attention_Recent\images\Learning_Subglacial_Bed_Topography_from_Sparse_Radar_with_Physics-Guided_Residuals\figure_5_page8.png
2025-11-19 22:47:53,581 - INFO - root - 已保存图片 6/10：./export\hybrid_attention_Recent\images\Learning_Subglacial_Bed_Topography_from_Sparse_Radar_with_Physics-Guided_Residuals\figure_6_page13.png
2025-11-19 22:47:53,633 - INFO - root - 已保存图片 7/10：./export\hybrid_attention_Recent\images\Learning_Subglacial_Bed_Topography_from_Sparse_Radar_with_Physics-Guided_Residuals\figure_7_page14.png
2025-11-19 22:47:53,688 - INFO - root - 已保存图片 8/10：./export\hybrid_attention_Recent\images\Learning_Subglacial_Bed_Topography_from_Sparse_Radar_with_Physics-Guided_Residuals\figure_8_page14.png
2025-11-19 22:47:53,741 - INFO - root - 已保存图片 9/10：./export\hybrid_attention_Recent\images\Learning_Subglacial_Bed_Topography_from_Sparse_Radar_with_Physics-Guided_Residuals\figure_9_page13.png
2025-11-19 22:47:53,806 - INFO - root - 已保存图片 10/10：./export\hybrid_attention_Recent\images\Learning_Subglacial_Bed_Topography_from_Sparse_Radar_with_Physics-Guided_Residuals\figure_10_page14.png
2025-11-19 22:47:53,824 - INFO - root - 成功添加图片 1：./export\hybrid_attention_Recent\images\Learning_Subglacial_Bed_Topography_from_Sparse_Radar_with_Physics-Guided_Residuals\figure_1_page4.png
2025-11-19 22:47:53,825 - INFO - root - 成功添加图片 2：./export\hybrid_attention_Recent\images\Learning_Subglacial_Bed_Topography_from_Sparse_Radar_with_Physics-Guided_Residuals\figure_2_page5.png
2025-11-19 22:47:53,825 - INFO - root - 成功添加图片 3：./export\hybrid_attention_Recent\images\Learning_Subglacial_Bed_Topography_from_Sparse_Radar_with_Physics-Guided_Residuals\figure_3_page13.png
2025-11-19 22:47:53,826 - INFO - root - 成功添加图片 4：./export\hybrid_attention_Recent\images\Learning_Subglacial_Bed_Topography_from_Sparse_Radar_with_Physics-Guided_Residuals\figure_4_page8.png
2025-11-19 22:47:53,826 - INFO - root - 成功添加图片 5：./export\hybrid_attention_Recent\images\Learning_Subglacial_Bed_Topography_from_Sparse_Radar_with_Physics-Guided_Residuals\figure_5_page8.png
2025-11-19 22:47:53,827 - INFO - root - 成功添加图片 6：./export\hybrid_attention_Recent\images\Learning_Subglacial_Bed_Topography_from_Sparse_Radar_with_Physics-Guided_Residuals\figure_6_page13.png
2025-11-19 22:47:53,827 - INFO - root - 成功添加图片 7：./export\hybrid_attention_Recent\images\Learning_Subglacial_Bed_Topography_from_Sparse_Radar_with_Physics-Guided_Residuals\figure_7_page14.png
2025-11-19 22:47:53,827 - INFO - root - 成功添加图片 8：./export\hybrid_attention_Recent\images\Learning_Subglacial_Bed_Topography_from_Sparse_Radar_with_Physics-Guided_Residuals\figure_8_page14.png
2025-11-19 22:47:53,829 - INFO - root - 成功添加图片 9：./export\hybrid_attention_Recent\images\Learning_Subglacial_Bed_Topography_from_Sparse_Radar_with_Physics-Guided_Residuals\figure_9_page13.png
2025-11-19 22:47:53,829 - INFO - root - 成功添加图片 10：./export\hybrid_attention_Recent\images\Learning_Subglacial_Bed_Topography_from_Sparse_Radar_with_Physics-Guided_Residuals\figure_10_page14.png
2025-11-19 22:47:53,831 - INFO - root - 论文《Learning Subglacial Bed Topography from Sparse Radar with Physics-Guided Residuals》的分析已保存到 ./export\hybrid_attention_Recent\Learning_Subglacial_Bed_Topography_from_Sparse_Radar_with_Physics-Guided_Residuals.md
2025-11-19 22:47:53,838 - INFO - root - 正在总结论文 30/40: nnterp: A Standardized Interface for Mechanistic Interpretability of Transformers
2025-11-19 22:48:07,073 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-19 22:48:07,074 - INFO - root - LLMClient: rate limit reached, sleeping 6.6s
2025-11-19 22:49:04,334 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-19 22:49:45,000 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-19 22:49:45,002 - INFO - root - 正在提取论文图片到目录: ./export\hybrid_attention_Recent\images\nnterp_A_Standardized_Interface_for_Mechanistic_Interpretability_of_Transformers
2025-11-19 22:49:45,019 - INFO - root - 论文《nnterp: A Standardized Interface for Mechanistic Interpretability of Transformers》的分析已保存到 ./export\hybrid_attention_Recent\nnterp_A_Standardized_Interface_for_Mechanistic_Interpretability_of_Transformers.md
2025-11-19 22:49:45,024 - INFO - root - 正在总结论文 31/40: Cracking the Microsecond: An Efficient and Precise Time Synchronization Scheme for Hybrid 5G-TSN Networks
2025-11-19 22:50:03,208 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-19 22:50:03,210 - INFO - root - LLMClient: rate limit reached, sleeping 1.1s
2025-11-19 22:51:09,366 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-19 22:51:48,899 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-19 22:51:48,902 - INFO - root - 正在提取论文图片到目录: ./export\hybrid_attention_Recent\images\Cracking_the_Microsecond_An_Efficient_and_Precise_Time_Synchronization_Scheme_for_Hybrid_5G-TSN_Net
2025-11-19 22:51:49,260 - INFO - root - 已保存图片 1/10：./export\hybrid_attention_Recent\images\Cracking_the_Microsecond_An_Efficient_and_Precise_Time_Synchronization_Scheme_for_Hybrid_5G-TSN_Net\figure_1_page3.jpeg
2025-11-19 22:51:49,326 - INFO - root - 已保存图片 2/10：./export\hybrid_attention_Recent\images\Cracking_the_Microsecond_An_Efficient_and_Precise_Time_Synchronization_Scheme_for_Hybrid_5G-TSN_Net\figure_2_page5.png
2025-11-19 22:51:49,342 - INFO - root - 已保存图片 3/10：./export\hybrid_attention_Recent\images\Cracking_the_Microsecond_An_Efficient_and_Precise_Time_Synchronization_Scheme_for_Hybrid_5G-TSN_Net\figure_3_page3.png
2025-11-19 22:51:49,359 - INFO - root - 已保存图片 4/10：./export\hybrid_attention_Recent\images\Cracking_the_Microsecond_An_Efficient_and_Precise_Time_Synchronization_Scheme_for_Hybrid_5G-TSN_Net\figure_4_page3.png
2025-11-19 22:51:49,365 - INFO - root - 成功添加图片 1：./export\hybrid_attention_Recent\images\Cracking_the_Microsecond_An_Efficient_and_Precise_Time_Synchronization_Scheme_for_Hybrid_5G-TSN_Net\figure_1_page3.jpeg
2025-11-19 22:51:49,365 - INFO - root - 成功添加图片 2：./export\hybrid_attention_Recent\images\Cracking_the_Microsecond_An_Efficient_and_Precise_Time_Synchronization_Scheme_for_Hybrid_5G-TSN_Net\figure_2_page5.png
2025-11-19 22:51:49,366 - INFO - root - 成功添加图片 3：./export\hybrid_attention_Recent\images\Cracking_the_Microsecond_An_Efficient_and_Precise_Time_Synchronization_Scheme_for_Hybrid_5G-TSN_Net\figure_3_page3.png
2025-11-19 22:51:49,366 - INFO - root - 成功添加图片 4：./export\hybrid_attention_Recent\images\Cracking_the_Microsecond_An_Efficient_and_Precise_Time_Synchronization_Scheme_for_Hybrid_5G-TSN_Net\figure_4_page3.png
2025-11-19 22:51:49,368 - INFO - root - 论文《Cracking the Microsecond: An Efficient and Precise Time Synchronization Scheme for Hybrid 5G-TSN Networks》的分析已保存到 ./export\hybrid_attention_Recent\Cracking_the_Microsecond_An_Efficient_and_Precise_Time_Synchronization_Scheme_for_Hybrid_5G-TSN_Net.md
2025-11-19 22:51:49,377 - INFO - root - 正在总结论文 32/40: Analyzing the Impact of Participant Failures in Cross-Silo Federated Learning
2025-11-19 22:52:02,762 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-19 22:52:02,794 - INFO - root - LLMClient: rate limit reached, sleeping 6.6s
2025-11-19 22:52:58,652 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-19 22:53:36,593 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-19 22:53:36,595 - INFO - root - 正在提取论文图片到目录: ./export\hybrid_attention_Recent\images\Analyzing_the_Impact_of_Participant_Failures_in_Cross-Silo_Federated_Learning
2025-11-19 22:53:36,607 - INFO - root - 论文《Analyzing the Impact of Participant Failures in Cross-Silo Federated Learning》的分析已保存到 ./export\hybrid_attention_Recent\Analyzing_the_Impact_of_Participant_Failures_in_Cross-Silo_Federated_Learning.md
2025-11-19 22:53:36,615 - INFO - root - 正在总结论文 33/40: Observation of the surface hybridization gap in the electrical transport properties of the ultrathin topological insulator (Bi$_{1-x}$Sb$_{x}$)$_2$Te$_3$
2025-11-19 22:53:53,837 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-19 22:53:53,838 - INFO - root - LLMClient: rate limit reached, sleeping 4.8s
2025-11-19 22:54:56,689 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-19 22:55:34,365 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-19 22:55:34,385 - INFO - root - 正在提取论文图片到目录: ./export\hybrid_attention_Recent\images\Observation_of_the_surface_hybridization_gap_in_the_electrical_transport_properties_of_the_ultrathin
2025-11-19 22:55:34,836 - INFO - root - 已保存图片 1/10：./export\hybrid_attention_Recent\images\Observation_of_the_surface_hybridization_gap_in_the_electrical_transport_properties_of_the_ultrathin\figure_1_page13.png
2025-11-19 22:55:34,898 - INFO - root - 已保存图片 2/10：./export\hybrid_attention_Recent\images\Observation_of_the_surface_hybridization_gap_in_the_electrical_transport_properties_of_the_ultrathin\figure_2_page13.png
2025-11-19 22:55:34,930 - INFO - root - 已保存图片 3/10：./export\hybrid_attention_Recent\images\Observation_of_the_surface_hybridization_gap_in_the_electrical_transport_properties_of_the_ultrathin\figure_3_page13.png
2025-11-19 22:55:34,994 - INFO - root - 已保存图片 4/10：./export\hybrid_attention_Recent\images\Observation_of_the_surface_hybridization_gap_in_the_electrical_transport_properties_of_the_ultrathin\figure_4_page13.png
2025-11-19 22:55:35,031 - INFO - root - 已保存图片 5/10：./export\hybrid_attention_Recent\images\Observation_of_the_surface_hybridization_gap_in_the_electrical_transport_properties_of_the_ultrathin\figure_5_page2.png
2025-11-19 22:55:35,053 - INFO - root - 已保存图片 6/10：./export\hybrid_attention_Recent\images\Observation_of_the_surface_hybridization_gap_in_the_electrical_transport_properties_of_the_ultrathin\figure_6_page3.png
2025-11-19 22:55:35,099 - INFO - root - 已保存图片 7/10：./export\hybrid_attention_Recent\images\Observation_of_the_surface_hybridization_gap_in_the_electrical_transport_properties_of_the_ultrathin\figure_7_page3.jpeg
2025-11-19 22:55:35,122 - INFO - root - 已保存图片 8/10：./export\hybrid_attention_Recent\images\Observation_of_the_surface_hybridization_gap_in_the_electrical_transport_properties_of_the_ultrathin\figure_8_page3.png
2025-11-19 22:55:35,180 - INFO - root - 已保存图片 9/10：./export\hybrid_attention_Recent\images\Observation_of_the_surface_hybridization_gap_in_the_electrical_transport_properties_of_the_ultrathin\figure_9_page3.jpeg
2025-11-19 22:55:35,219 - INFO - root - 已保存图片 10/10：./export\hybrid_attention_Recent\images\Observation_of_the_surface_hybridization_gap_in_the_electrical_transport_properties_of_the_ultrathin\figure_10_page3.png
2025-11-19 22:55:35,223 - INFO - root - 成功添加图片 1：./export\hybrid_attention_Recent\images\Observation_of_the_surface_hybridization_gap_in_the_electrical_transport_properties_of_the_ultrathin\figure_1_page13.png
2025-11-19 22:55:35,225 - INFO - root - 成功添加图片 2：./export\hybrid_attention_Recent\images\Observation_of_the_surface_hybridization_gap_in_the_electrical_transport_properties_of_the_ultrathin\figure_2_page13.png
2025-11-19 22:55:35,225 - INFO - root - 成功添加图片 3：./export\hybrid_attention_Recent\images\Observation_of_the_surface_hybridization_gap_in_the_electrical_transport_properties_of_the_ultrathin\figure_3_page13.png
2025-11-19 22:55:35,226 - INFO - root - 成功添加图片 4：./export\hybrid_attention_Recent\images\Observation_of_the_surface_hybridization_gap_in_the_electrical_transport_properties_of_the_ultrathin\figure_4_page13.png
2025-11-19 22:55:35,227 - INFO - root - 成功添加图片 5：./export\hybrid_attention_Recent\images\Observation_of_the_surface_hybridization_gap_in_the_electrical_transport_properties_of_the_ultrathin\figure_5_page2.png
2025-11-19 22:55:35,227 - INFO - root - 成功添加图片 6：./export\hybrid_attention_Recent\images\Observation_of_the_surface_hybridization_gap_in_the_electrical_transport_properties_of_the_ultrathin\figure_6_page3.png
2025-11-19 22:55:35,228 - INFO - root - 成功添加图片 7：./export\hybrid_attention_Recent\images\Observation_of_the_surface_hybridization_gap_in_the_electrical_transport_properties_of_the_ultrathin\figure_7_page3.jpeg
2025-11-19 22:55:35,228 - INFO - root - 成功添加图片 8：./export\hybrid_attention_Recent\images\Observation_of_the_surface_hybridization_gap_in_the_electrical_transport_properties_of_the_ultrathin\figure_8_page3.png
2025-11-19 22:55:35,230 - INFO - root - 成功添加图片 9：./export\hybrid_attention_Recent\images\Observation_of_the_surface_hybridization_gap_in_the_electrical_transport_properties_of_the_ultrathin\figure_9_page3.jpeg
2025-11-19 22:55:35,230 - INFO - root - 成功添加图片 10：./export\hybrid_attention_Recent\images\Observation_of_the_surface_hybridization_gap_in_the_electrical_transport_properties_of_the_ultrathin\figure_10_page3.png
2025-11-19 22:55:35,235 - INFO - root - 论文《Observation of the surface hybridization gap in the electrical transport properties of the ultrathin topological insulator (Bi$_{1-x}$Sb$_{x}$)$_2$Te$_3$》的分析已保存到 ./export\hybrid_attention_Recent\Observation_of_the_surface_hybridization_gap_in_the_electrical_transport_properties_of_the_ultrathin.md
2025-11-19 22:55:35,241 - INFO - root - 正在总结论文 34/40: Multi-network Topology Underlying Individual Language Learning Success
2025-11-19 22:55:49,711 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-19 22:55:49,711 - INFO - root - LLMClient: rate limit reached, sleeping 7.0s
2025-11-19 22:56:52,434 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-19 22:57:29,304 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-19 22:57:29,309 - INFO - root - 正在提取论文图片到目录: ./export\hybrid_attention_Recent\images\Multi-network_Topology_Underlying_Individual_Language_Learning_Success
2025-11-19 22:57:30,107 - INFO - root - 已保存图片 1/10：./export\hybrid_attention_Recent\images\Multi-network_Topology_Underlying_Individual_Language_Learning_Success\figure_1_page18.png
2025-11-19 22:57:30,236 - INFO - root - 已保存图片 2/10：./export\hybrid_attention_Recent\images\Multi-network_Topology_Underlying_Individual_Language_Learning_Success\figure_2_page14.png
2025-11-19 22:57:30,296 - INFO - root - 已保存图片 3/10：./export\hybrid_attention_Recent\images\Multi-network_Topology_Underlying_Individual_Language_Learning_Success\figure_3_page10.jpeg
2025-11-19 22:57:30,398 - INFO - root - 已保存图片 4/10：./export\hybrid_attention_Recent\images\Multi-network_Topology_Underlying_Individual_Language_Learning_Success\figure_4_page42.png
2025-11-19 22:57:30,485 - INFO - root - 已保存图片 5/10：./export\hybrid_attention_Recent\images\Multi-network_Topology_Underlying_Individual_Language_Learning_Success\figure_5_page16.png
2025-11-19 22:57:30,553 - INFO - root - 已保存图片 6/10：./export\hybrid_attention_Recent\images\Multi-network_Topology_Underlying_Individual_Language_Learning_Success\figure_6_page44.png
2025-11-19 22:57:30,627 - INFO - root - 已保存图片 7/10：./export\hybrid_attention_Recent\images\Multi-network_Topology_Underlying_Individual_Language_Learning_Success\figure_7_page7.png
2025-11-19 22:57:30,661 - INFO - root - 已保存图片 8/10：./export\hybrid_attention_Recent\images\Multi-network_Topology_Underlying_Individual_Language_Learning_Success\figure_8_page43.jpeg
2025-11-19 22:57:30,690 - INFO - root - 已保存图片 9/10：./export\hybrid_attention_Recent\images\Multi-network_Topology_Underlying_Individual_Language_Learning_Success\figure_9_page12.jpeg
2025-11-19 22:57:30,781 - INFO - root - 已保存图片 10/10：./export\hybrid_attention_Recent\images\Multi-network_Topology_Underlying_Individual_Language_Learning_Success\figure_10_page45.png
2025-11-19 22:57:30,786 - INFO - root - 成功添加图片 1：./export\hybrid_attention_Recent\images\Multi-network_Topology_Underlying_Individual_Language_Learning_Success\figure_1_page18.png
2025-11-19 22:57:30,787 - INFO - root - 成功添加图片 2：./export\hybrid_attention_Recent\images\Multi-network_Topology_Underlying_Individual_Language_Learning_Success\figure_2_page14.png
2025-11-19 22:57:30,787 - INFO - root - 成功添加图片 3：./export\hybrid_attention_Recent\images\Multi-network_Topology_Underlying_Individual_Language_Learning_Success\figure_3_page10.jpeg
2025-11-19 22:57:30,788 - INFO - root - 成功添加图片 4：./export\hybrid_attention_Recent\images\Multi-network_Topology_Underlying_Individual_Language_Learning_Success\figure_4_page42.png
2025-11-19 22:57:30,788 - INFO - root - 成功添加图片 5：./export\hybrid_attention_Recent\images\Multi-network_Topology_Underlying_Individual_Language_Learning_Success\figure_5_page16.png
2025-11-19 22:57:30,788 - INFO - root - 成功添加图片 6：./export\hybrid_attention_Recent\images\Multi-network_Topology_Underlying_Individual_Language_Learning_Success\figure_6_page44.png
2025-11-19 22:57:30,789 - INFO - root - 成功添加图片 7：./export\hybrid_attention_Recent\images\Multi-network_Topology_Underlying_Individual_Language_Learning_Success\figure_7_page7.png
2025-11-19 22:57:30,790 - INFO - root - 成功添加图片 8：./export\hybrid_attention_Recent\images\Multi-network_Topology_Underlying_Individual_Language_Learning_Success\figure_8_page43.jpeg
2025-11-19 22:57:30,791 - INFO - root - 成功添加图片 9：./export\hybrid_attention_Recent\images\Multi-network_Topology_Underlying_Individual_Language_Learning_Success\figure_9_page12.jpeg
2025-11-19 22:57:30,791 - INFO - root - 成功添加图片 10：./export\hybrid_attention_Recent\images\Multi-network_Topology_Underlying_Individual_Language_Learning_Success\figure_10_page45.png
2025-11-19 22:57:30,796 - INFO - root - 论文《Multi-network Topology Underlying Individual Language Learning Success》的分析已保存到 ./export\hybrid_attention_Recent\Multi-network_Topology_Underlying_Individual_Language_Learning_Success.md
2025-11-19 22:57:30,800 - INFO - root - 正在总结论文 35/40: Hybrid Modeling of Photoplethysmography for Non-invasive Monitoring of Cardiovascular Parameters
2025-11-19 22:57:43,531 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-19 22:57:43,532 - INFO - root - LLMClient: rate limit reached, sleeping 8.9s
2025-11-19 22:59:01,892 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-19 22:59:45,727 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-19 22:59:45,729 - INFO - root - 正在提取论文图片到目录: ./export\hybrid_attention_Recent\images\Hybrid_Modeling_of_Photoplethysmography_for_Non-invasive_Monitoring_of_Cardiovascular_Parameters
2025-11-19 22:59:45,816 - INFO - root - 已保存图片 1/10：./export\hybrid_attention_Recent\images\Hybrid_Modeling_of_Photoplethysmography_for_Non-invasive_Monitoring_of_Cardiovascular_Parameters\figure_1_page1.png
2025-11-19 22:59:45,817 - INFO - root - 成功添加图片 1：./export\hybrid_attention_Recent\images\Hybrid_Modeling_of_Photoplethysmography_for_Non-invasive_Monitoring_of_Cardiovascular_Parameters\figure_1_page1.png
2025-11-19 22:59:45,818 - INFO - root - 论文《Hybrid Modeling of Photoplethysmography for Non-invasive Monitoring of Cardiovascular Parameters》的分析已保存到 ./export\hybrid_attention_Recent\Hybrid_Modeling_of_Photoplethysmography_for_Non-invasive_Monitoring_of_Cardiovascular_Parameters.md
2025-11-19 22:59:45,824 - INFO - root - 正在总结论文 36/40: Analyzing Many Simulations of Hybrid Programs in Lince
2025-11-19 22:59:55,320 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-19 22:59:55,321 - INFO - root - LLMClient: rate limit reached, sleeping 6.6s
2025-11-19 23:00:58,037 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-19 23:01:35,074 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-19 23:01:35,079 - INFO - root - 正在提取论文图片到目录: ./export\hybrid_attention_Recent\images\Analyzing_Many_Simulations_of_Hybrid_Programs_in_Lince
2025-11-19 23:01:35,189 - INFO - root - 已保存图片 1/10：./export\hybrid_attention_Recent\images\Analyzing_Many_Simulations_of_Hybrid_Programs_in_Lince\figure_1_page2.png
2025-11-19 23:01:35,190 - INFO - root - 成功添加图片 1：./export\hybrid_attention_Recent\images\Analyzing_Many_Simulations_of_Hybrid_Programs_in_Lince\figure_1_page2.png
2025-11-19 23:01:35,192 - INFO - root - 论文《Analyzing Many Simulations of Hybrid Programs in Lince》的分析已保存到 ./export\hybrid_attention_Recent\Analyzing_Many_Simulations_of_Hybrid_Programs_in_Lince.md
2025-11-19 23:01:35,199 - INFO - root - 正在总结论文 37/40: Self-Supervised Multisensory Pretraining for Contact-Rich Robot Reinforcement Learning
2025-11-19 23:01:46,079 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-19 23:01:46,080 - INFO - root - LLMClient: rate limit reached, sleeping 12.0s
2025-11-19 23:02:57,521 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-19 23:03:33,384 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-19 23:03:33,386 - INFO - root - 正在提取论文图片到目录: ./export\hybrid_attention_Recent\images\Self-Supervised_Multisensory_Pretraining_for_Contact-Rich_Robot_Reinforcement_Learning
2025-11-19 23:03:34,346 - INFO - root - 已保存图片 1/10：./export\hybrid_attention_Recent\images\Self-Supervised_Multisensory_Pretraining_for_Contact-Rich_Robot_Reinforcement_Learning\figure_1_page1.png
2025-11-19 23:03:34,522 - INFO - root - 已保存图片 2/10：./export\hybrid_attention_Recent\images\Self-Supervised_Multisensory_Pretraining_for_Contact-Rich_Robot_Reinforcement_Learning\figure_2_page7.png
2025-11-19 23:03:34,668 - INFO - root - 已保存图片 3/10：./export\hybrid_attention_Recent\images\Self-Supervised_Multisensory_Pretraining_for_Contact-Rich_Robot_Reinforcement_Learning\figure_3_page7.png
2025-11-19 23:03:34,709 - INFO - root - 已保存图片 4/10：./export\hybrid_attention_Recent\images\Self-Supervised_Multisensory_Pretraining_for_Contact-Rich_Robot_Reinforcement_Learning\figure_4_page6.png
2025-11-19 23:03:34,829 - INFO - root - 已保存图片 5/10：./export\hybrid_attention_Recent\images\Self-Supervised_Multisensory_Pretraining_for_Contact-Rich_Robot_Reinforcement_Learning\figure_5_page4.png
2025-11-19 23:03:34,933 - INFO - root - 已保存图片 6/10：./export\hybrid_attention_Recent\images\Self-Supervised_Multisensory_Pretraining_for_Contact-Rich_Robot_Reinforcement_Learning\figure_6_page4.png
2025-11-19 23:03:34,996 - INFO - root - 已保存图片 7/10：./export\hybrid_attention_Recent\images\Self-Supervised_Multisensory_Pretraining_for_Contact-Rich_Robot_Reinforcement_Learning\figure_7_page4.png
2025-11-19 23:03:35,048 - INFO - root - 已保存图片 8/10：./export\hybrid_attention_Recent\images\Self-Supervised_Multisensory_Pretraining_for_Contact-Rich_Robot_Reinforcement_Learning\figure_8_page4.png
2025-11-19 23:03:35,050 - INFO - root - 成功添加图片 1：./export\hybrid_attention_Recent\images\Self-Supervised_Multisensory_Pretraining_for_Contact-Rich_Robot_Reinforcement_Learning\figure_1_page1.png
2025-11-19 23:03:35,051 - INFO - root - 成功添加图片 2：./export\hybrid_attention_Recent\images\Self-Supervised_Multisensory_Pretraining_for_Contact-Rich_Robot_Reinforcement_Learning\figure_2_page7.png
2025-11-19 23:03:35,051 - INFO - root - 成功添加图片 3：./export\hybrid_attention_Recent\images\Self-Supervised_Multisensory_Pretraining_for_Contact-Rich_Robot_Reinforcement_Learning\figure_3_page7.png
2025-11-19 23:03:35,051 - INFO - root - 成功添加图片 4：./export\hybrid_attention_Recent\images\Self-Supervised_Multisensory_Pretraining_for_Contact-Rich_Robot_Reinforcement_Learning\figure_4_page6.png
2025-11-19 23:03:35,052 - INFO - root - 成功添加图片 5：./export\hybrid_attention_Recent\images\Self-Supervised_Multisensory_Pretraining_for_Contact-Rich_Robot_Reinforcement_Learning\figure_5_page4.png
2025-11-19 23:03:35,052 - INFO - root - 成功添加图片 6：./export\hybrid_attention_Recent\images\Self-Supervised_Multisensory_Pretraining_for_Contact-Rich_Robot_Reinforcement_Learning\figure_6_page4.png
2025-11-19 23:03:35,052 - INFO - root - 成功添加图片 7：./export\hybrid_attention_Recent\images\Self-Supervised_Multisensory_Pretraining_for_Contact-Rich_Robot_Reinforcement_Learning\figure_7_page4.png
2025-11-19 23:03:35,054 - INFO - root - 成功添加图片 8：./export\hybrid_attention_Recent\images\Self-Supervised_Multisensory_Pretraining_for_Contact-Rich_Robot_Reinforcement_Learning\figure_8_page4.png
2025-11-19 23:03:35,057 - INFO - root - 论文《Self-Supervised Multisensory Pretraining for Contact-Rich Robot Reinforcement Learning》的分析已保存到 ./export\hybrid_attention_Recent\Self-Supervised_Multisensory_Pretraining_for_Contact-Rich_Robot_Reinforcement_Learning.md
2025-11-19 23:03:35,064 - INFO - root - 正在总结论文 38/40: Unified Defense for Large Language Models against Jailbreak and Fine-Tuning Attacks in Education
2025-11-19 23:03:49,877 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-19 23:03:49,878 - INFO - root - LLMClient: rate limit reached, sleeping 7.6s
2025-11-19 23:04:58,248 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-19 23:05:37,274 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-19 23:05:37,276 - INFO - root - 正在提取论文图片到目录: ./export\hybrid_attention_Recent\images\Unified_Defense_for_Large_Language_Models_against_Jailbreak_and_Fine-Tuning_Attacks_in_Education
2025-11-19 23:05:37,365 - INFO - root - 已保存图片 1/10：./export\hybrid_attention_Recent\images\Unified_Defense_for_Large_Language_Models_against_Jailbreak_and_Fine-Tuning_Attacks_in_Education\figure_1_page2.jpeg
2025-11-19 23:05:37,397 - INFO - root - 已保存图片 2/10：./export\hybrid_attention_Recent\images\Unified_Defense_for_Large_Language_Models_against_Jailbreak_and_Fine-Tuning_Attacks_in_Education\figure_2_page2.jpeg
2025-11-19 23:05:37,432 - INFO - root - 已保存图片 3/10：./export\hybrid_attention_Recent\images\Unified_Defense_for_Large_Language_Models_against_Jailbreak_and_Fine-Tuning_Attacks_in_Education\figure_3_page1.jpeg
2025-11-19 23:05:37,468 - INFO - root - 已保存图片 4/10：./export\hybrid_attention_Recent\images\Unified_Defense_for_Large_Language_Models_against_Jailbreak_and_Fine-Tuning_Attacks_in_Education\figure_4_page2.jpeg
2025-11-19 23:05:37,504 - INFO - root - 已保存图片 5/10：./export\hybrid_attention_Recent\images\Unified_Defense_for_Large_Language_Models_against_Jailbreak_and_Fine-Tuning_Attacks_in_Education\figure_5_page8.jpeg
2025-11-19 23:05:37,614 - INFO - root - 已保存图片 6/10：./export\hybrid_attention_Recent\images\Unified_Defense_for_Large_Language_Models_against_Jailbreak_and_Fine-Tuning_Attacks_in_Education\figure_6_page8.png
2025-11-19 23:05:37,731 - INFO - root - 已保存图片 7/10：./export\hybrid_attention_Recent\images\Unified_Defense_for_Large_Language_Models_against_Jailbreak_and_Fine-Tuning_Attacks_in_Education\figure_7_page8.png
2025-11-19 23:05:37,810 - INFO - root - 已保存图片 8/10：./export\hybrid_attention_Recent\images\Unified_Defense_for_Large_Language_Models_against_Jailbreak_and_Fine-Tuning_Attacks_in_Education\figure_8_page2.jpeg
2025-11-19 23:05:38,145 - INFO - root - 已保存图片 9/10：./export\hybrid_attention_Recent\images\Unified_Defense_for_Large_Language_Models_against_Jailbreak_and_Fine-Tuning_Attacks_in_Education\figure_9_page8.png
2025-11-19 23:05:38,161 - INFO - root - 成功添加图片 1：./export\hybrid_attention_Recent\images\Unified_Defense_for_Large_Language_Models_against_Jailbreak_and_Fine-Tuning_Attacks_in_Education\figure_1_page2.jpeg
2025-11-19 23:05:38,171 - INFO - root - 成功添加图片 2：./export\hybrid_attention_Recent\images\Unified_Defense_for_Large_Language_Models_against_Jailbreak_and_Fine-Tuning_Attacks_in_Education\figure_2_page2.jpeg
2025-11-19 23:05:38,188 - INFO - root - 成功添加图片 3：./export\hybrid_attention_Recent\images\Unified_Defense_for_Large_Language_Models_against_Jailbreak_and_Fine-Tuning_Attacks_in_Education\figure_3_page1.jpeg
2025-11-19 23:05:38,218 - INFO - root - 成功添加图片 4：./export\hybrid_attention_Recent\images\Unified_Defense_for_Large_Language_Models_against_Jailbreak_and_Fine-Tuning_Attacks_in_Education\figure_4_page2.jpeg
2025-11-19 23:05:38,233 - INFO - root - 成功添加图片 5：./export\hybrid_attention_Recent\images\Unified_Defense_for_Large_Language_Models_against_Jailbreak_and_Fine-Tuning_Attacks_in_Education\figure_5_page8.jpeg
2025-11-19 23:05:38,243 - INFO - root - 成功添加图片 6：./export\hybrid_attention_Recent\images\Unified_Defense_for_Large_Language_Models_against_Jailbreak_and_Fine-Tuning_Attacks_in_Education\figure_6_page8.png
2025-11-19 23:05:38,258 - INFO - root - 成功添加图片 7：./export\hybrid_attention_Recent\images\Unified_Defense_for_Large_Language_Models_against_Jailbreak_and_Fine-Tuning_Attacks_in_Education\figure_7_page8.png
2025-11-19 23:05:38,279 - INFO - root - 成功添加图片 8：./export\hybrid_attention_Recent\images\Unified_Defense_for_Large_Language_Models_against_Jailbreak_and_Fine-Tuning_Attacks_in_Education\figure_8_page2.jpeg
2025-11-19 23:05:38,302 - INFO - root - 成功添加图片 9：./export\hybrid_attention_Recent\images\Unified_Defense_for_Large_Language_Models_against_Jailbreak_and_Fine-Tuning_Attacks_in_Education\figure_9_page8.png
2025-11-19 23:05:38,326 - INFO - root - 论文《Unified Defense for Large Language Models against Jailbreak and Fine-Tuning Attacks in Education》的分析已保存到 ./export\hybrid_attention_Recent\Unified_Defense_for_Large_Language_Models_against_Jailbreak_and_Fine-Tuning_Attacks_in_Education.md
2025-11-19 23:05:38,348 - INFO - root - 正在总结论文 39/40: Nonlinear Coherence for Vector Time Series: Defining Region-to-Region Functional Brain Connectivity
2025-11-19 23:05:50,771 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-19 23:05:50,772 - INFO - root - LLMClient: rate limit reached, sleeping 7.5s
2025-11-19 23:06:56,155 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-19 23:07:30,978 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-19 23:07:30,982 - INFO - root - 正在提取论文图片到目录: ./export\hybrid_attention_Recent\images\Nonlinear_Coherence_for_Vector_Time_Series_Defining_Region-to-Region_Functional_Brain_Connectivity
2025-11-19 23:07:35,946 - INFO - root - 已保存图片 1/10：./export\hybrid_attention_Recent\images\Nonlinear_Coherence_for_Vector_Time_Series_Defining_Region-to-Region_Functional_Brain_Connectivity\figure_1_page26.png
2025-11-19 23:07:36,239 - INFO - root - 已保存图片 2/10：./export\hybrid_attention_Recent\images\Nonlinear_Coherence_for_Vector_Time_Series_Defining_Region-to-Region_Functional_Brain_Connectivity\figure_2_page27.png
2025-11-19 23:07:36,444 - INFO - root - 已保存图片 3/10：./export\hybrid_attention_Recent\images\Nonlinear_Coherence_for_Vector_Time_Series_Defining_Region-to-Region_Functional_Brain_Connectivity\figure_3_page27.png
2025-11-19 23:07:36,644 - INFO - root - 已保存图片 4/10：./export\hybrid_attention_Recent\images\Nonlinear_Coherence_for_Vector_Time_Series_Defining_Region-to-Region_Functional_Brain_Connectivity\figure_4_page27.png
2025-11-19 23:07:36,849 - INFO - root - 已保存图片 5/10：./export\hybrid_attention_Recent\images\Nonlinear_Coherence_for_Vector_Time_Series_Defining_Region-to-Region_Functional_Brain_Connectivity\figure_5_page27.png
2025-11-19 23:07:37,117 - INFO - root - 已保存图片 6/10：./export\hybrid_attention_Recent\images\Nonlinear_Coherence_for_Vector_Time_Series_Defining_Region-to-Region_Functional_Brain_Connectivity\figure_6_page27.png
2025-11-19 23:07:37,347 - INFO - root - 已保存图片 7/10：./export\hybrid_attention_Recent\images\Nonlinear_Coherence_for_Vector_Time_Series_Defining_Region-to-Region_Functional_Brain_Connectivity\figure_7_page28.png
2025-11-19 23:07:37,577 - INFO - root - 已保存图片 8/10：./export\hybrid_attention_Recent\images\Nonlinear_Coherence_for_Vector_Time_Series_Defining_Region-to-Region_Functional_Brain_Connectivity\figure_8_page28.png
2025-11-19 23:07:37,886 - INFO - root - 已保存图片 9/10：./export\hybrid_attention_Recent\images\Nonlinear_Coherence_for_Vector_Time_Series_Defining_Region-to-Region_Functional_Brain_Connectivity\figure_9_page28.png
2025-11-19 23:07:38,207 - INFO - root - 已保存图片 10/10：./export\hybrid_attention_Recent\images\Nonlinear_Coherence_for_Vector_Time_Series_Defining_Region-to-Region_Functional_Brain_Connectivity\figure_10_page28.png
2025-11-19 23:07:38,236 - INFO - root - 成功添加图片 1：./export\hybrid_attention_Recent\images\Nonlinear_Coherence_for_Vector_Time_Series_Defining_Region-to-Region_Functional_Brain_Connectivity\figure_1_page26.png
2025-11-19 23:07:38,236 - INFO - root - 成功添加图片 2：./export\hybrid_attention_Recent\images\Nonlinear_Coherence_for_Vector_Time_Series_Defining_Region-to-Region_Functional_Brain_Connectivity\figure_2_page27.png
2025-11-19 23:07:38,238 - INFO - root - 成功添加图片 3：./export\hybrid_attention_Recent\images\Nonlinear_Coherence_for_Vector_Time_Series_Defining_Region-to-Region_Functional_Brain_Connectivity\figure_3_page27.png
2025-11-19 23:07:38,238 - INFO - root - 成功添加图片 4：./export\hybrid_attention_Recent\images\Nonlinear_Coherence_for_Vector_Time_Series_Defining_Region-to-Region_Functional_Brain_Connectivity\figure_4_page27.png
2025-11-19 23:07:38,239 - INFO - root - 成功添加图片 5：./export\hybrid_attention_Recent\images\Nonlinear_Coherence_for_Vector_Time_Series_Defining_Region-to-Region_Functional_Brain_Connectivity\figure_5_page27.png
2025-11-19 23:07:38,239 - INFO - root - 成功添加图片 6：./export\hybrid_attention_Recent\images\Nonlinear_Coherence_for_Vector_Time_Series_Defining_Region-to-Region_Functional_Brain_Connectivity\figure_6_page27.png
2025-11-19 23:07:38,239 - INFO - root - 成功添加图片 7：./export\hybrid_attention_Recent\images\Nonlinear_Coherence_for_Vector_Time_Series_Defining_Region-to-Region_Functional_Brain_Connectivity\figure_7_page28.png
2025-11-19 23:07:38,240 - INFO - root - 成功添加图片 8：./export\hybrid_attention_Recent\images\Nonlinear_Coherence_for_Vector_Time_Series_Defining_Region-to-Region_Functional_Brain_Connectivity\figure_8_page28.png
2025-11-19 23:07:38,240 - INFO - root - 成功添加图片 9：./export\hybrid_attention_Recent\images\Nonlinear_Coherence_for_Vector_Time_Series_Defining_Region-to-Region_Functional_Brain_Connectivity\figure_9_page28.png
2025-11-19 23:07:38,241 - INFO - root - 成功添加图片 10：./export\hybrid_attention_Recent\images\Nonlinear_Coherence_for_Vector_Time_Series_Defining_Region-to-Region_Functional_Brain_Connectivity\figure_10_page28.png
2025-11-19 23:07:38,248 - INFO - root - 论文《Nonlinear Coherence for Vector Time Series: Defining Region-to-Region Functional Brain Connectivity》的分析已保存到 ./export\hybrid_attention_Recent\Nonlinear_Coherence_for_Vector_Time_Series_Defining_Region-to-Region_Functional_Brain_Connectivity.md
2025-11-19 23:07:38,252 - INFO - root - 正在总结论文 40/40: Cranio-ID: Graph-Based Craniofacial Identification via Automatic Landmark Annotation in 2D Multi-View X-rays
2025-11-19 23:07:48,526 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-19 23:07:48,528 - INFO - root - LLMClient: rate limit reached, sleeping 7.6s
2025-11-19 23:08:49,760 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-19 23:09:23,066 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-19 23:09:23,072 - INFO - root - 正在提取论文图片到目录: ./export\hybrid_attention_Recent\images\Cranio-ID_Graph-Based_Craniofacial_Identification_via_Automatic_Landmark_Annotation_in_2D_Multi-Vie
2025-11-19 23:09:23,578 - INFO - root - 已保存图片 1/10：./export\hybrid_attention_Recent\images\Cranio-ID_Graph-Based_Craniofacial_Identification_via_Automatic_Landmark_Annotation_in_2D_Multi-Vie\figure_1_page7.jpeg
2025-11-19 23:09:23,704 - INFO - root - 已保存图片 2/10：./export\hybrid_attention_Recent\images\Cranio-ID_Graph-Based_Craniofacial_Identification_via_Automatic_Landmark_Annotation_in_2D_Multi-Vie\figure_2_page7.jpeg
2025-11-19 23:09:23,820 - INFO - root - 已保存图片 3/10：./export\hybrid_attention_Recent\images\Cranio-ID_Graph-Based_Craniofacial_Identification_via_Automatic_Landmark_Annotation_in_2D_Multi-Vie\figure_3_page7.jpeg
2025-11-19 23:09:23,939 - INFO - root - 已保存图片 4/10：./export\hybrid_attention_Recent\images\Cranio-ID_Graph-Based_Craniofacial_Identification_via_Automatic_Landmark_Annotation_in_2D_Multi-Vie\figure_4_page3.jpeg
2025-11-19 23:09:24,048 - INFO - root - 已保存图片 5/10：./export\hybrid_attention_Recent\images\Cranio-ID_Graph-Based_Craniofacial_Identification_via_Automatic_Landmark_Annotation_in_2D_Multi-Vie\figure_5_page7.jpeg
2025-11-19 23:09:24,155 - INFO - root - 已保存图片 6/10：./export\hybrid_attention_Recent\images\Cranio-ID_Graph-Based_Craniofacial_Identification_via_Automatic_Landmark_Annotation_in_2D_Multi-Vie\figure_6_page3.jpeg
2025-11-19 23:09:24,254 - INFO - root - 已保存图片 7/10：./export\hybrid_attention_Recent\images\Cranio-ID_Graph-Based_Craniofacial_Identification_via_Automatic_Landmark_Annotation_in_2D_Multi-Vie\figure_7_page7.jpeg
2025-11-19 23:09:24,351 - INFO - root - 已保存图片 8/10：./export\hybrid_attention_Recent\images\Cranio-ID_Graph-Based_Craniofacial_Identification_via_Automatic_Landmark_Annotation_in_2D_Multi-Vie\figure_8_page3.jpeg
2025-11-19 23:09:24,452 - INFO - root - 已保存图片 9/10：./export\hybrid_attention_Recent\images\Cranio-ID_Graph-Based_Craniofacial_Identification_via_Automatic_Landmark_Annotation_in_2D_Multi-Vie\figure_9_page7.jpeg
2025-11-19 23:09:24,550 - INFO - root - 已保存图片 10/10：./export\hybrid_attention_Recent\images\Cranio-ID_Graph-Based_Craniofacial_Identification_via_Automatic_Landmark_Annotation_in_2D_Multi-Vie\figure_10_page7.jpeg
2025-11-19 23:09:24,563 - INFO - root - 成功添加图片 1：./export\hybrid_attention_Recent\images\Cranio-ID_Graph-Based_Craniofacial_Identification_via_Automatic_Landmark_Annotation_in_2D_Multi-Vie\figure_1_page7.jpeg
2025-11-19 23:09:24,563 - INFO - root - 成功添加图片 2：./export\hybrid_attention_Recent\images\Cranio-ID_Graph-Based_Craniofacial_Identification_via_Automatic_Landmark_Annotation_in_2D_Multi-Vie\figure_2_page7.jpeg
2025-11-19 23:09:24,564 - INFO - root - 成功添加图片 3：./export\hybrid_attention_Recent\images\Cranio-ID_Graph-Based_Craniofacial_Identification_via_Automatic_Landmark_Annotation_in_2D_Multi-Vie\figure_3_page7.jpeg
2025-11-19 23:09:24,564 - INFO - root - 成功添加图片 4：./export\hybrid_attention_Recent\images\Cranio-ID_Graph-Based_Craniofacial_Identification_via_Automatic_Landmark_Annotation_in_2D_Multi-Vie\figure_4_page3.jpeg
2025-11-19 23:09:24,566 - INFO - root - 成功添加图片 5：./export\hybrid_attention_Recent\images\Cranio-ID_Graph-Based_Craniofacial_Identification_via_Automatic_Landmark_Annotation_in_2D_Multi-Vie\figure_5_page7.jpeg
2025-11-19 23:09:24,566 - INFO - root - 成功添加图片 6：./export\hybrid_attention_Recent\images\Cranio-ID_Graph-Based_Craniofacial_Identification_via_Automatic_Landmark_Annotation_in_2D_Multi-Vie\figure_6_page3.jpeg
2025-11-19 23:09:24,567 - INFO - root - 成功添加图片 7：./export\hybrid_attention_Recent\images\Cranio-ID_Graph-Based_Craniofacial_Identification_via_Automatic_Landmark_Annotation_in_2D_Multi-Vie\figure_7_page7.jpeg
2025-11-19 23:09:24,567 - INFO - root - 成功添加图片 8：./export\hybrid_attention_Recent\images\Cranio-ID_Graph-Based_Craniofacial_Identification_via_Automatic_Landmark_Annotation_in_2D_Multi-Vie\figure_8_page3.jpeg
2025-11-19 23:09:24,567 - INFO - root - 成功添加图片 9：./export\hybrid_attention_Recent\images\Cranio-ID_Graph-Based_Craniofacial_Identification_via_Automatic_Landmark_Annotation_in_2D_Multi-Vie\figure_9_page7.jpeg
2025-11-19 23:09:24,568 - INFO - root - 成功添加图片 10：./export\hybrid_attention_Recent\images\Cranio-ID_Graph-Based_Craniofacial_Identification_via_Automatic_Landmark_Annotation_in_2D_Multi-Vie\figure_10_page7.jpeg
2025-11-19 23:09:24,573 - INFO - root - 论文《Cranio-ID: Graph-Based Craniofacial Identification via Automatic Landmark Annotation in 2D Multi-View X-rays》的分析已保存到 ./export\hybrid_attention_Recent\Cranio-ID_Graph-Based_Craniofacial_Identification_via_Automatic_Landmark_Annotation_in_2D_Multi-Vie.md
2025-11-19 23:09:24,579 - INFO - root - --- 论文总结阶段结束 ---
2025-11-19 23:09:24,579 - INFO - root - --- 开始生成 Excel 报告 (包含 40 篇论文) ---
2025-11-19 23:09:24,763 - INFO - root - 未找到旧 Excel 文件。正在创建新文件: export\hybrid_attention_Recent_summary.xlsx
2025-11-19 23:09:24,998 - INFO - root - 成功保存 Excel: export\hybrid_attention_Recent_summary.xlsx
2025-11-19 23:09:24,999 - INFO - root - 已生成或更新汇总 Excel 表格: export\hybrid_attention_Recent_summary.xlsx
2025-11-19 23:09:25,006 - INFO - root - 总运行时间: 4710.87 seconds
2025-11-20 22:43:05,598 - WARNING - root - Google Scholar 检索器依赖未能加载: No module named 'selenium'。 'scholar' 策略将不可用。
2025-11-20 22:43:05,603 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-20 22:43:05,604 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-20 22:43:05,606 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-20 22:43:14,999 - INFO - root - LLMClientManager: 指定使用客户端: Gemini
2025-11-20 22:43:15,950 - INFO - root - GeminiClient: trying model models/gemini-2.5-flash
2025-11-20 22:43:22,527 - INFO - root - GeminiClient: initialized model gemini-2.5-flash
2025-11-20 22:43:22,527 - INFO - root - LLMClientManager: Gemini 客户端初始化成功
2025-11-20 22:43:22,528 - INFO - root - LLMClientManager: switched to Gemini client
2025-11-20 22:43:22,528 - INFO - root - 已手动切换到 LLM 客户端: Gemini
2025-11-20 22:43:22,528 - INFO - root - 使用 LLM 模型: gemini-2.5-flash
2025-11-20 22:43:22,529 - INFO - root - 可用客户端: ['Gemini']
2025-11-20 22:43:22,530 - INFO - root - === 运行配置 ===
2025-11-20 22:43:22,530 - INFO - root - 处理模式: arXiv 最新搜索 (API)
2025-11-20 22:43:22,531 - INFO - root - 查询: vision Transformer
2025-11-20 22:43:22,532 - INFO - root - 关键词 (用于保存): vision Transformer
2025-11-20 22:43:22,532 - INFO - root - 排序: SubmittedDate
2025-11-20 22:43:22,532 - INFO - root - 最近天数: 180
2025-11-20 22:43:22,533 - INFO - root - 最大处理数量: 40
2025-11-20 22:43:22,533 - INFO - root - 保存图片: 是
2025-11-20 22:43:22,533 - INFO - root - 输出语言: 中文
2025-11-20 22:43:22,534 - INFO - root - 强制重新处理: 否
2025-11-20 22:43:22,534 - INFO - root - LLM 客户端: Gemini
2025-11-20 22:43:22,535 - INFO - root - ====================
2025-11-20 22:43:22,535 - INFO - root - 正在使用检索策略: arxiv
2025-11-20 22:43:22,535 - INFO - root - 使用 arXiv 搜索模式 (API + 并发)
2025-11-20 22:43:22,536 - INFO - root - 正在使用 arXiv API 搜索: query='vision Transformer', sort_by=SubmittedDate
2025-11-20 22:43:22,536 - INFO - arxiv - Requesting page (first: True, try: 0): https://export.arxiv.org/api/query?search_query=vision+Transformer&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=50
2025-11-20 22:43:36,618 - INFO - arxiv - Got first page: 50 of 314974 total results
2025-11-20 22:43:36,622 - INFO - root - API 返回了 50 篇论文
2025-11-20 22:43:36,627 - INFO - root - 开始按 180 天过滤 (检查 50 篇论文)...
2025-11-20 22:43:36,627 - INFO - root - 经过 'days=180' 过滤后，剩余 50 篇论文。
2025-11-20 22:43:36,628 - INFO - root - 将开始并发下载 40 篇论文...
2025-11-20 22:43:36,631 - INFO - root - 正在下载: https://arxiv.org/pdf/2511.15707v1
2025-11-20 22:43:36,633 - INFO - root - 正在下载: https://arxiv.org/pdf/2511.15706v1
2025-11-20 22:43:36,633 - INFO - root - 正在下载: https://arxiv.org/pdf/2511.15705v1
2025-11-20 22:43:36,637 - INFO - root - 正在下载: https://arxiv.org/pdf/2511.15704v1
2025-11-20 22:43:36,640 - INFO - root - 正在下载: https://arxiv.org/pdf/2511.15703v1
2025-11-20 22:43:47,113 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\vision_Transformer\Think_Visually,_Reason_Textually_Vision-Language_Synergy_in_ARC.pdf
2025-11-20 22:43:47,116 - INFO - root - 成功创建 Paper 对象: 2511.15703v1
2025-11-20 22:43:47,117 - INFO - root - 正在下载: https://arxiv.org/pdf/2511.15700v1
2025-11-20 22:44:15,173 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\vision_Transformer\Resolving_Ratio_Redundancy_in_Chemical_Freeze-out_Studies_with_Principal_Component_Analysis_and_Baye.pdf
2025-11-20 22:44:15,174 - INFO - root - 成功创建 Paper 对象: 2511.15707v1
2025-11-20 22:44:15,175 - INFO - root - 正在下载: https://arxiv.org/pdf/2511.15699v1
2025-11-20 23:11:22,601 - WARNING - root - Google Scholar 检索器依赖未能加载: No module named 'selenium'。 'scholar' 策略将不可用。
2025-11-20 23:11:22,605 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-20 23:11:22,606 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-20 23:11:22,607 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-20 23:11:32,083 - INFO - root - LLMClientManager: 指定使用客户端: Deepseek
2025-11-20 23:11:32,083 - INFO - root - DeepSeekClient: API key found: 9f9e270e-b...
2025-11-20 23:11:32,083 - INFO - root - DeepSeekClient: 使用模式: 火山引擎
2025-11-20 23:11:32,084 - INFO - root - DeepSeekClient: 模型名称: ep-20251112215738-bz78g
2025-11-20 23:11:34,934 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-20 23:11:34,949 - INFO - root - DeepSeekClient: initialized successfully with model ep-20251112215738-bz78g
2025-11-20 23:11:34,950 - INFO - root - LLMClientManager: DeepSeek 客户端初始化成功
2025-11-20 23:11:34,950 - INFO - root - LLMClientManager: switched to DeepSeek client (case-insensitive match)
2025-11-20 23:11:34,950 - INFO - root - 已手动切换到 LLM 客户端: Deepseek
2025-11-20 23:11:34,951 - INFO - root - 使用 LLM 模型: ep-20251112215738-bz78g
2025-11-20 23:11:34,951 - INFO - root - 可用客户端: ['DeepSeek']
2025-11-20 23:11:34,951 - INFO - root - === 运行配置 ===
2025-11-20 23:11:34,951 - INFO - root - 处理模式: arXiv 最新搜索 (API)
2025-11-20 23:11:34,951 - INFO - root - 查询: vision transformer
2025-11-20 23:11:34,953 - INFO - root - 关键词 (用于保存): vision transformer
2025-11-20 23:11:34,953 - INFO - root - 排序: SubmittedDate
2025-11-20 23:11:34,953 - INFO - root - 最近天数: 180
2025-11-20 23:11:34,953 - INFO - root - 最大处理数量: 40
2025-11-20 23:11:34,953 - INFO - root - 保存图片: 是
2025-11-20 23:11:34,953 - INFO - root - 输出语言: 中文
2025-11-20 23:11:34,954 - INFO - root - 强制重新处理: 否
2025-11-20 23:11:34,954 - INFO - root - LLM 客户端: Deepseek
2025-11-20 23:11:34,954 - INFO - root - ====================
2025-11-20 23:11:34,954 - INFO - root - 正在使用检索策略: arxiv
2025-11-20 23:11:34,955 - INFO - root - 使用 arXiv 搜索模式 (API + 并发)
2025-11-20 23:11:34,955 - INFO - root - 正在使用 arXiv API 搜索: query='vision transformer', sort_by=SubmittedDate
2025-11-20 23:11:34,957 - INFO - arxiv - Requesting page (first: True, try: 0): https://export.arxiv.org/api/query?search_query=vision+transformer&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=50
2025-11-20 23:11:43,709 - INFO - arxiv - Got first page: 50 of 314974 total results
2025-11-20 23:11:43,712 - INFO - root - API 返回了 50 篇论文
2025-11-20 23:11:43,717 - INFO - root - 开始按 180 天过滤 (检查 50 篇论文)...
2025-11-20 23:11:43,718 - INFO - root - 经过 'days=180' 过滤后，剩余 50 篇论文。
2025-11-20 23:11:43,718 - INFO - root - 将开始并发下载 40 篇论文...
2025-11-20 23:11:43,723 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\vision_transformer\Resolving_Ratio_Redundancy_in_Chemical_Freeze-out_Studies_with_Principal_Component_Analysis_and_Baye.pdf
2025-11-20 23:11:43,723 - INFO - root - 正在下载: https://arxiv.org/pdf/2511.15706v1
2025-11-20 23:11:43,723 - INFO - root - 成功创建 Paper 对象: 2511.15707v1
2025-11-20 23:11:43,724 - INFO - root - 正在下载: https://arxiv.org/pdf/2511.15704v1
2025-11-20 23:11:43,725 - INFO - root - 正在下载: https://arxiv.org/pdf/2511.15705v1
2025-11-20 23:11:43,729 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\vision_transformer\Think_Visually,_Reason_Textually_Vision-Language_Synergy_in_ARC.pdf
2025-11-20 23:11:43,729 - INFO - root - 下载进度: 1/40
2025-11-20 23:11:43,732 - INFO - root - 正在下载: https://arxiv.org/pdf/2511.15700v1
2025-11-20 23:11:43,735 - INFO - root - 成功创建 Paper 对象: 2511.15703v1
2025-11-20 23:11:43,745 - INFO - root - 下载进度: 2/40
2025-11-20 23:11:43,748 - INFO - root - 正在下载: https://arxiv.org/pdf/2511.15699v1
2025-11-20 23:12:00,315 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\vision_transformer\Joint_Semantic-Channel_Coding_and_Modulation_for_Token_Communications.pdf
2025-11-20 23:12:00,318 - INFO - root - 成功创建 Paper 对象: 2511.15699v1
2025-11-20 23:12:00,318 - INFO - root - 下载进度: 3/40
2025-11-20 23:12:00,321 - INFO - root - 正在下载: https://arxiv.org/pdf/2511.15692v1
2025-11-20 23:12:12,447 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\vision_transformer\Hyperspectral_Image_Classification_using_Spectral-Spatial_Mixer_Network.pdf
2025-11-20 23:12:12,450 - INFO - root - 成功创建 Paper 对象: 2511.15692v1
2025-11-20 23:12:12,451 - INFO - root - 下载进度: 4/40
2025-11-20 23:12:12,451 - INFO - root - 正在下载: https://arxiv.org/pdf/2511.15690v1
2025-11-20 23:12:45,061 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\vision_transformer\MoDES_Accelerating_Mixture-of-Experts_Multimodal_Large_Language_Models_via_Dynamic_Expert_Skipping.pdf
2025-11-20 23:12:45,064 - INFO - root - 成功创建 Paper 对象: 2511.15690v1
2025-11-20 23:12:45,064 - INFO - root - 下载进度: 5/40
2025-11-20 23:12:45,065 - INFO - root - 正在下载: https://arxiv.org/pdf/2511.15684v1
2025-11-20 23:13:56,872 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\vision_transformer\GeoVista_Web-Augmented_Agentic_Visual_Reasoning_for_Geolocalization.pdf
2025-11-20 23:13:56,880 - INFO - root - 成功创建 Paper 对象: 2511.15705v1
2025-11-20 23:13:56,881 - INFO - root - 下载进度: 6/40
2025-11-20 23:13:56,881 - INFO - root - 正在下载: https://arxiv.org/pdf/2511.15675v1
2025-11-20 23:14:18,948 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-20 23:14:18,949 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-20 23:14:18,951 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-20 23:14:24,308 - INFO - root - LLMClientManager: 指定使用客户端: Gemini
2025-11-20 23:14:25,434 - INFO - root - GeminiClient: trying model models/gemini-2.5-flash
2025-11-20 23:14:30,334 - INFO - root - GeminiClient: initialized model gemini-2.5-flash
2025-11-20 23:14:30,335 - INFO - root - LLMClientManager: Gemini 客户端初始化成功
2025-11-20 23:14:30,336 - INFO - root - LLMClientManager: switched to Gemini client
2025-11-20 23:14:30,336 - INFO - root - 已手动切换到 LLM 客户端: Gemini
2025-11-20 23:14:30,337 - INFO - root - 使用 LLM 模型: gemini-2.5-flash
2025-11-20 23:14:30,338 - INFO - root - 可用客户端: ['Gemini']
2025-11-20 23:14:30,339 - INFO - root - === 运行配置 ===
2025-11-20 23:14:30,339 - INFO - root - 处理模式: arXiv 最新搜索 (API)
2025-11-20 23:14:30,339 - INFO - root - 查询: vision transformer
2025-11-20 23:14:30,339 - INFO - root - 关键词 (用于保存): vision transformer
2025-11-20 23:14:30,340 - INFO - root - 排序: SubmittedDate
2025-11-20 23:14:30,340 - INFO - root - 最近天数: 180
2025-11-20 23:14:30,340 - INFO - root - 最大处理数量: 40
2025-11-20 23:14:30,340 - INFO - root - 保存图片: 是
2025-11-20 23:14:30,341 - INFO - root - 输出语言: 中文
2025-11-20 23:14:30,341 - INFO - root - 强制重新处理: 否
2025-11-20 23:14:30,341 - INFO - root - LLM 客户端: Gemini
2025-11-20 23:14:30,342 - INFO - root - ====================
2025-11-20 23:14:30,342 - INFO - root - 正在使用检索策略: arxiv
2025-11-20 23:14:30,342 - INFO - root - 使用 arXiv 搜索模式 (API + 并发)
2025-11-20 23:14:30,342 - INFO - root - 正在使用 arXiv API 搜索: query='vision transformer', sort_by=SubmittedDate
2025-11-20 23:14:30,343 - INFO - arxiv - Requesting page (first: True, try: 0): https://export.arxiv.org/api/query?search_query=vision+transformer&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=50
2025-11-20 23:14:37,255 - INFO - arxiv - Got first page: 50 of 314974 total results
2025-11-20 23:14:37,258 - INFO - root - API 返回了 50 篇论文
2025-11-20 23:14:37,262 - INFO - root - 开始按 180 天过滤 (检查 50 篇论文)...
2025-11-20 23:14:37,262 - INFO - root - 经过 'days=180' 过滤后，剩余 50 篇论文。
2025-11-20 23:14:37,263 - INFO - root - 将开始并发下载 40 篇论文...
2025-11-20 23:14:37,265 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\vision_transformer\Resolving_Ratio_Redundancy_in_Chemical_Freeze-out_Studies_with_Principal_Component_Analysis_and_Baye.pdf
2025-11-20 23:14:37,265 - INFO - root - 正在下载: https://arxiv.org/pdf/2511.15706v1
2025-11-20 23:14:37,266 - INFO - root - 成功创建 Paper 对象: 2511.15707v1
2025-11-20 23:14:37,266 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\vision_transformer\GeoVista_Web-Augmented_Agentic_Visual_Reasoning_for_Geolocalization.pdf
2025-11-20 23:14:37,270 - INFO - root - 正在下载: https://arxiv.org/pdf/2511.15704v1
2025-11-20 23:14:37,270 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\vision_transformer\Think_Visually,_Reason_Textually_Vision-Language_Synergy_in_ARC.pdf
2025-11-20 23:14:37,272 - INFO - root - 成功创建 Paper 对象: 2511.15705v1
2025-11-20 23:14:37,272 - INFO - root - 下载进度: 1/40
2025-11-20 23:14:37,274 - INFO - root - 成功创建 Paper 对象: 2511.15703v1
2025-11-20 23:14:37,274 - INFO - root - 正在下载: https://arxiv.org/pdf/2511.15700v1
2025-11-20 23:14:37,278 - INFO - root - 下载进度: 2/40
2025-11-20 23:14:37,279 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\vision_transformer\Joint_Semantic-Channel_Coding_and_Modulation_for_Token_Communications.pdf
2025-11-20 23:14:37,287 - INFO - root - 成功创建 Paper 对象: 2511.15699v1
2025-11-20 23:14:37,284 - INFO - root - 下载进度: 3/40
2025-11-20 23:14:37,280 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\vision_transformer\Hyperspectral_Image_Classification_using_Spectral-Spatial_Mixer_Network.pdf
2025-11-20 23:14:37,290 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\vision_transformer\MoDES_Accelerating_Mixture-of-Experts_Multimodal_Large_Language_Models_via_Dynamic_Expert_Skipping.pdf
2025-11-20 23:14:37,290 - INFO - root - 下载进度: 4/40
2025-11-20 23:14:37,294 - INFO - root - 成功创建 Paper 对象: 2511.15692v1
2025-11-20 23:14:37,322 - INFO - root - 成功创建 Paper 对象: 2511.15690v1
2025-11-20 23:14:37,328 - INFO - root - 正在下载: https://arxiv.org/pdf/2511.15684v1
2025-11-20 23:14:37,328 - INFO - root - 下载进度: 5/40
2025-11-20 23:14:37,333 - INFO - root - 正在下载: https://arxiv.org/pdf/2511.15675v1
2025-11-20 23:14:37,389 - INFO - root - 下载进度: 6/40
2025-11-20 23:15:05,414 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\vision_transformer\RoMa_v2_Harder_Better_Faster_Denser_Feature_Matching.pdf
2025-11-20 23:15:05,416 - INFO - root - 成功创建 Paper 对象: 2511.15706v1
2025-11-20 23:15:05,417 - INFO - root - 下载进度: 7/40
2025-11-20 23:15:05,417 - INFO - root - 正在下载: https://arxiv.org/pdf/2511.15674v1
2025-11-20 23:15:12,506 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\vision_transformer\Efficient_quantum_state_preparation_of_multivariate_functions_using_tensor_networks.pdf
2025-11-20 23:15:12,509 - INFO - root - 成功创建 Paper 对象: 2511.15674v1
2025-11-20 23:15:12,509 - INFO - root - 下载进度: 8/40
2025-11-20 23:15:12,511 - INFO - root - 正在下载: https://arxiv.org/pdf/2511.15665v1
2025-11-20 23:15:20,063 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\vision_transformer\Quantum-Guided_Test_Case_Minimization_for_LLM-Based_Code_Generation.pdf
2025-11-20 23:15:20,065 - INFO - root - 成功创建 Paper 对象: 2511.15665v1
2025-11-20 23:15:20,066 - INFO - root - 下载进度: 9/40
2025-11-20 23:15:20,067 - INFO - root - 正在下载: https://arxiv.org/pdf/2511.15661v1
2025-11-20 23:16:02,287 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\vision_transformer\VisPlay_Self-Evolving_Vision-Language_Models_from_Images.pdf
2025-11-20 23:16:02,289 - INFO - root - 成功创建 Paper 对象: 2511.15661v1
2025-11-20 23:16:02,290 - INFO - root - 下载进度: 10/40
2025-11-20 23:16:02,290 - INFO - root - 正在下载: https://arxiv.org/pdf/2511.15658v1
2025-11-20 23:16:48,161 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\vision_transformer\Walrus_A_Cross-Domain_Foundation_Model_for_Continuum_Dynamics.pdf
2025-11-20 23:16:48,167 - INFO - root - 成功创建 Paper 对象: 2511.15684v1
2025-11-20 23:16:48,185 - INFO - root - 下载进度: 11/40
2025-11-20 23:16:48,185 - INFO - root - 正在下载: https://arxiv.org/pdf/2511.15656v1
2025-11-20 23:17:18,542 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\vision_transformer\MF-GCN_A_Multi-Frequency_Graph_Convolutional_Network_for_Tri-Modal_Depression_Detection_Using_Eye-T.pdf
2025-11-20 23:17:18,548 - INFO - root - 成功创建 Paper 对象: 2511.15675v1
2025-11-20 23:17:18,549 - INFO - root - 下载进度: 12/40
2025-11-20 23:17:18,549 - INFO - root - 正在下载: https://arxiv.org/pdf/2511.15645v1
2025-11-20 23:17:36,771 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\vision_transformer\In-N-On_Scaling_Egocentric_Manipulation_with_in-the-wild_and_on-task_Data.pdf
2025-11-20 23:17:36,781 - INFO - root - 成功创建 Paper 对象: 2511.15704v1
2025-11-20 23:17:36,781 - INFO - root - 下载进度: 13/40
2025-11-20 23:17:36,781 - INFO - root - 正在下载: https://arxiv.org/pdf/2511.15643v1
2025-11-20 23:17:50,677 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\vision_transformer\MambaIO_Global-Coordinate_Inertial_Odometry_for_Pedestrians_via_Multi-Scale_Frequency-Decoupled_Mod.pdf
2025-11-20 23:17:50,705 - INFO - root - 成功创建 Paper 对象: 2511.15645v1
2025-11-20 23:17:50,736 - INFO - root - 下载进度: 14/40
2025-11-20 23:17:50,737 - INFO - root - 正在下载: https://arxiv.org/pdf/2511.15642v1
2025-11-20 23:18:08,469 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\vision_transformer\MF-GCN_A_Multi-Frequency_Graph_Convolutional_Network_for_Tri-Modal_Depression_Detection_Using_Eye-T.pdf
2025-11-20 23:18:08,477 - INFO - root - 成功创建 Paper 对象: 2511.15675v1
2025-11-20 23:18:08,477 - INFO - root - 下载进度: 7/40
2025-11-20 23:18:08,477 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\vision_transformer\Efficient_quantum_state_preparation_of_multivariate_functions_using_tensor_networks.pdf
2025-11-20 23:18:08,477 - INFO - root - 成功创建 Paper 对象: 2511.15674v1
2025-11-20 23:18:08,477 - INFO - root - 下载进度: 8/40
2025-11-20 23:18:08,477 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\vision_transformer\Quantum-Guided_Test_Case_Minimization_for_LLM-Based_Code_Generation.pdf
2025-11-20 23:18:08,477 - INFO - root - 成功创建 Paper 对象: 2511.15665v1
2025-11-20 23:18:08,477 - INFO - root - 下载进度: 9/40
2025-11-20 23:18:08,477 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\vision_transformer\VisPlay_Self-Evolving_Vision-Language_Models_from_Images.pdf
2025-11-20 23:18:08,477 - INFO - root - 成功创建 Paper 对象: 2511.15661v1
2025-11-20 23:18:08,477 - INFO - root - 下载进度: 10/40
2025-11-20 23:18:08,477 - INFO - root - 正在下载: https://arxiv.org/pdf/2511.15658v1
2025-11-20 23:18:12,160 - INFO - root - 正在下载: https://arxiv.org/pdf/2511.15642v1
2025-11-20 23:18:20,004 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\vision_transformer\Navigating_Quantum_Missteps_in_Agent-Based_Modeling_A_Schelling_Model_Case_Study.pdf
2025-11-20 23:18:20,006 - INFO - root - 成功创建 Paper 对象: 2511.15642v1
2025-11-20 23:18:20,007 - INFO - root - 下载进度: 15/40
2025-11-20 23:18:20,007 - INFO - root - 正在下载: https://arxiv.org/pdf/2511.15640v1
2025-11-20 23:19:25,146 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\vision_transformer\RoMa_v2_Harder_Better_Faster_Denser_Feature_Matching.pdf
2025-11-20 23:19:25,149 - INFO - root - 成功创建 Paper 对象: 2511.15706v1
2025-11-20 23:19:25,149 - INFO - root - 下载进度: 11/40
2025-11-20 23:19:25,151 - INFO - root - 正在下载: https://arxiv.org/pdf/2511.15656v1
2025-11-20 23:20:19,938 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\vision_transformer\INQUIRE-Search_A_Framework_for_Interactive_Discovery_in_Large-Scale_Biodiversity_Databases.pdf
2025-11-20 23:20:19,939 - INFO - root - 成功创建 Paper 对象: 2511.15656v1
2025-11-20 23:20:19,940 - INFO - root - 下载进度: 16/40
2025-11-20 23:20:19,940 - INFO - root - 正在下载: https://arxiv.org/pdf/2511.15633v1
2025-11-20 23:20:27,671 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\vision_transformer\A_Millennium_of_UK_Business_Cycles_Insights_from_Structural_VAR_Analysis.pdf
2025-11-20 23:20:27,674 - INFO - root - 成功创建 Paper 对象: 2511.15643v1
2025-11-20 23:20:27,674 - INFO - root - 下载进度: 17/40
2025-11-20 23:20:27,675 - INFO - root - 正在下载: https://arxiv.org/pdf/2511.15622v1
2025-11-20 23:20:30,700 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\vision_transformer\Hierarchical_Semantic_Tree_Anchoring_for_CLIP-Based_Class-Incremental_Learning.pdf
2025-11-20 23:20:30,702 - INFO - root - 成功创建 Paper 对象: 2511.15633v1
2025-11-20 23:20:30,703 - INFO - root - 下载进度: 18/40
2025-11-20 23:20:30,703 - INFO - root - 正在下载: https://arxiv.org/pdf/2511.15618v1
2025-11-20 23:21:23,923 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\vision_transformer\Walrus_A_Cross-Domain_Foundation_Model_for_Continuum_Dynamics.pdf
2025-11-20 23:21:23,926 - INFO - root - 成功创建 Paper 对象: 2511.15684v1
2025-11-20 23:21:23,927 - INFO - root - 下载进度: 12/40
2025-11-20 23:21:23,928 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\vision_transformer\MambaIO_Global-Coordinate_Inertial_Odometry_for_Pedestrians_via_Multi-Scale_Frequency-Decoupled_Mod.pdf
2025-11-20 23:21:23,928 - INFO - root - 成功创建 Paper 对象: 2511.15645v1
2025-11-20 23:21:23,931 - INFO - root - 下载进度: 13/40
2025-11-20 23:21:23,932 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\vision_transformer\A_Millennium_of_UK_Business_Cycles_Insights_from_Structural_VAR_Analysis.pdf
2025-11-20 23:21:23,933 - INFO - root - 成功创建 Paper 对象: 2511.15643v1
2025-11-20 23:21:23,934 - INFO - root - 下载进度: 14/40
2025-11-20 23:21:23,935 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\vision_transformer\Navigating_Quantum_Missteps_in_Agent-Based_Modeling_A_Schelling_Model_Case_Study.pdf
2025-11-20 23:21:23,935 - INFO - root - 成功创建 Paper 对象: 2511.15642v1
2025-11-20 23:21:23,937 - INFO - root - 下载进度: 15/40
2025-11-20 23:21:23,937 - INFO - root - 正在下载: https://arxiv.org/pdf/2511.15640v1
2025-11-20 23:21:43,401 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\vision_transformer\First_Frame_Is_the_Place_to_Go_for_Video_Content_Customization.pdf
2025-11-20 23:21:43,407 - INFO - root - 成功创建 Paper 对象: 2511.15700v1
2025-11-20 23:21:43,408 - INFO - root - 下载进度: 19/40
2025-11-20 23:21:43,408 - INFO - root - 正在下载: https://arxiv.org/pdf/2511.15614v1
2025-11-20 23:21:53,250 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\vision_transformer\In-N-On_Scaling_Egocentric_Manipulation_with_in-the-wild_and_on-task_Data.pdf
2025-11-20 23:21:53,255 - INFO - root - 成功创建 Paper 对象: 2511.15704v1
2025-11-20 23:21:53,255 - INFO - root - 下载进度: 16/40
2025-11-20 23:21:53,256 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\vision_transformer\Hierarchical_Semantic_Tree_Anchoring_for_CLIP-Based_Class-Incremental_Learning.pdf
2025-11-20 23:21:53,261 - INFO - root - 成功创建 Paper 对象: 2511.15633v1
2025-11-20 23:21:53,262 - INFO - root - 下载进度: 17/40
2025-11-20 23:21:53,263 - INFO - root - 正在下载: https://arxiv.org/pdf/2511.15622v1
2025-11-20 23:21:56,254 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\vision_transformer\Optimus-Q_Utilizing_Federated_Learning_in_Adaptive_Robots_for_Intelligent_Nuclear_Power_Plant_Opera.pdf
2025-11-20 23:21:56,257 - INFO - root - 成功创建 Paper 对象: 2511.15614v1
2025-11-20 23:21:56,257 - INFO - root - 下载进度: 20/40
2025-11-20 23:21:56,258 - INFO - root - 正在下载: https://arxiv.org/pdf/2511.15613v1
2025-11-20 23:22:20,408 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\vision_transformer\INQUIRE-Search_A_Framework_for_Interactive_Discovery_in_Large-Scale_Biodiversity_Databases.pdf
2025-11-20 23:22:20,414 - INFO - root - 成功创建 Paper 对象: 2511.15656v1
2025-11-20 23:22:20,415 - INFO - root - 下载进度: 18/40
2025-11-20 23:22:20,415 - INFO - root - 正在下载: https://arxiv.org/pdf/2511.15618v1
2025-11-20 23:23:31,094 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\vision_transformer\FlashMesh_Faster_and_Better_Autoregressive_Mesh_Synthesis_via_Structured_Speculation.pdf
2025-11-20 23:23:31,099 - INFO - root - 成功创建 Paper 对象: 2511.15618v1
2025-11-20 23:23:31,100 - INFO - root - 下载进度: 21/40
2025-11-20 23:23:31,100 - INFO - root - 正在下载: https://arxiv.org/pdf/2511.15605v1
2025-11-20 23:23:34,973 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\vision_transformer\When_to_Think_and_When_to_Look_Uncertainty-Guided_Lookback.pdf
2025-11-20 23:23:34,978 - INFO - root - 成功创建 Paper 对象: 2511.15613v1
2025-11-20 23:23:34,979 - INFO - root - 下载进度: 22/40
2025-11-20 23:23:34,979 - INFO - root - 正在下载: https://arxiv.org/pdf/2511.15603v1
2025-11-20 23:23:46,134 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\vision_transformer\MaskMed_Decoupled_Mask_and_Class_Prediction_for_Medical_Image_Segmentation.pdf
2025-11-20 23:23:46,138 - INFO - root - 成功创建 Paper 对象: 2511.15603v1
2025-11-20 23:23:46,139 - INFO - root - 下载进度: 23/40
2025-11-20 23:23:46,139 - INFO - root - 正在下载: https://arxiv.org/pdf/2511.15602v1
2025-11-20 23:23:54,853 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\vision_transformer\Endomorphism_and_automorphism_graphs_of_finite_groups.pdf
2025-11-20 23:23:54,857 - INFO - root - 成功创建 Paper 对象: 2511.15602v1
2025-11-20 23:23:54,858 - INFO - root - 下载进度: 24/40
2025-11-20 23:23:54,858 - INFO - root - 正在下载: https://arxiv.org/pdf/2511.15600v1
2025-11-20 23:24:11,039 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\vision_transformer\US-X_Complete_A_Multi-Modal_Approach_to_Anatomical_3D_Shape_Recovery.pdf
2025-11-20 23:24:11,073 - INFO - root - 成功创建 Paper 对象: 2511.15600v1
2025-11-20 23:24:11,089 - INFO - root - 下载进度: 25/40
2025-11-20 23:24:11,093 - INFO - root - 正在下载: https://arxiv.org/pdf/2511.15597v1
2025-11-20 23:24:58,770 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\vision_transformer\Learning_from_Mistakes_Loss-Aware_Memory_Enhanced_Continual_Learning_for_LiDAR_Place_Recognition.pdf
2025-11-20 23:24:58,771 - INFO - root - 成功创建 Paper 对象: 2511.15597v1
2025-11-20 23:24:58,772 - INFO - root - 下载进度: 26/40
2025-11-20 23:24:58,772 - INFO - root - 正在下载: https://arxiv.org/pdf/2511.15589v1
2025-11-20 23:24:59,484 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\vision_transformer\The_SA-FARI_Dataset_Segment_Anything_in_Footage_of_Animals_for_Recognition_and_Identification.pdf
2025-11-20 23:24:59,490 - INFO - root - 成功创建 Paper 对象: 2511.15622v1
2025-11-20 23:24:59,491 - INFO - root - 下载进度: 27/40
2025-11-20 23:24:59,494 - INFO - root - 正在下载: https://arxiv.org/pdf/2511.15588v1
2025-11-20 23:25:06,323 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\vision_transformer\EPSO_A_Caching-Based_Efficient_Superoptimizer_for_BPF_Bytecode.pdf
2025-11-20 23:25:06,325 - INFO - root - 成功创建 Paper 对象: 2511.15589v1
2025-11-20 23:25:06,326 - INFO - root - 下载进度: 28/40
2025-11-20 23:25:06,327 - INFO - root - 正在下载: https://arxiv.org/pdf/2511.15586v1
2025-11-20 23:25:20,153 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\vision_transformer\Real-Time_Optimal_Control_via_Transformer_Networks_and_Bernstein_Polynomials.pdf
2025-11-20 23:25:20,158 - INFO - root - 成功创建 Paper 对象: 2511.15588v1
2025-11-20 23:25:20,158 - INFO - root - 下载进度: 29/40
2025-11-20 23:25:20,160 - INFO - root - 正在下载: https://arxiv.org/pdf/2511.15581v1
2025-11-20 23:25:29,599 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\vision_transformer\FlashMesh_Faster_and_Better_Autoregressive_Mesh_Synthesis_via_Structured_Speculation.pdf
2025-11-20 23:25:29,609 - INFO - root - 成功创建 Paper 对象: 2511.15618v1
2025-11-20 23:25:29,610 - INFO - root - 下载进度: 19/40
2025-11-20 23:25:29,611 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\vision_transformer\Optimus-Q_Utilizing_Federated_Learning_in_Adaptive_Robots_for_Intelligent_Nuclear_Power_Plant_Opera.pdf
2025-11-20 23:25:29,613 - INFO - root - 成功创建 Paper 对象: 2511.15614v1
2025-11-20 23:25:29,615 - INFO - root - 下载进度: 20/40
2025-11-20 23:25:29,615 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\vision_transformer\When_to_Think_and_When_to_Look_Uncertainty-Guided_Lookback.pdf
2025-11-20 23:25:29,616 - INFO - root - 成功创建 Paper 对象: 2511.15613v1
2025-11-20 23:25:29,617 - INFO - root - 下载进度: 21/40
2025-11-20 23:25:29,619 - INFO - root - 正在下载: https://arxiv.org/pdf/2511.15605v1
2025-11-20 23:25:39,856 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\vision_transformer\GEO-Bench-2_From_Performance_to_Capability,_Rethinking_Evaluation_in_Geospatial_AI.pdf
2025-11-20 23:25:39,869 - INFO - root - 成功创建 Paper 对象: 2511.15658v1
2025-11-20 23:25:39,875 - INFO - root - 下载进度: 30/40
2025-11-20 23:25:39,875 - INFO - root - 正在下载: https://arxiv.org/pdf/2511.15580v1
2025-11-20 23:26:09,644 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\vision_transformer\CompTrack_Information_Bottleneck-Guided_Low-Rank_Dynamic_Token_Compression_for_Point_Cloud_Tracking.pdf
2025-11-20 23:26:09,730 - INFO - root - 成功创建 Paper 对象: 2511.15580v1
2025-11-20 23:26:09,845 - INFO - root - 下载进度: 31/40
2025-11-20 23:26:09,882 - INFO - root - 正在下载: https://arxiv.org/pdf/2511.15578v1
2025-11-20 23:27:00,172 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\vision_transformer\Graph_Rewriting_Language_as_a_Platform_for_Quantum_Diagrammatic_Calculi.pdf
2025-11-20 23:27:00,176 - INFO - root - 成功创建 Paper 对象: 2511.15581v1
2025-11-20 23:27:00,177 - INFO - root - 下载进度: 32/40
2025-11-20 23:27:00,177 - INFO - root - 正在下载: https://arxiv.org/pdf/2511.15575v1
2025-11-20 23:27:09,837 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\vision_transformer\A_critical_review_of_pre-post_surveys_designed_to_measure_student_epistemology_in_undergraduate_scie.pdf
2025-11-20 23:27:09,845 - INFO - root - 成功创建 Paper 对象: 2511.15575v1
2025-11-20 23:27:09,847 - INFO - root - 下载进度: 33/40
2025-11-20 23:27:09,848 - INFO - root - 正在下载: https://arxiv.org/pdf/2511.15572v1
2025-11-20 23:27:10,712 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\vision_transformer\First_Frame_Is_the_Place_to_Go_for_Video_Content_Customization.pdf
2025-11-20 23:27:10,785 - INFO - root - 成功创建 Paper 对象: 2511.15700v1
2025-11-20 23:27:10,790 - INFO - root - 下载进度: 22/40
2025-11-20 23:27:10,793 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\vision_transformer\MaskMed_Decoupled_Mask_and_Class_Prediction_for_Medical_Image_Segmentation.pdf
2025-11-20 23:27:10,793 - INFO - root - 成功创建 Paper 对象: 2511.15603v1
2025-11-20 23:27:10,794 - INFO - root - 下载进度: 23/40
2025-11-20 23:27:10,794 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\vision_transformer\Endomorphism_and_automorphism_graphs_of_finite_groups.pdf
2025-11-20 23:27:10,796 - INFO - root - 成功创建 Paper 对象: 2511.15602v1
2025-11-20 23:27:10,799 - INFO - root - 下载进度: 24/40
2025-11-20 23:27:10,800 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\vision_transformer\US-X_Complete_A_Multi-Modal_Approach_to_Anatomical_3D_Shape_Recovery.pdf
2025-11-20 23:27:10,801 - INFO - root - 成功创建 Paper 对象: 2511.15600v1
2025-11-20 23:27:10,802 - INFO - root - 下载进度: 25/40
2025-11-20 23:27:10,802 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\vision_transformer\Learning_from_Mistakes_Loss-Aware_Memory_Enhanced_Continual_Learning_for_LiDAR_Place_Recognition.pdf
2025-11-20 23:27:10,803 - INFO - root - 成功创建 Paper 对象: 2511.15597v1
2025-11-20 23:27:10,804 - INFO - root - 下载进度: 26/40
2025-11-20 23:27:10,805 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\vision_transformer\EPSO_A_Caching-Based_Efficient_Superoptimizer_for_BPF_Bytecode.pdf
2025-11-20 23:27:10,808 - INFO - root - 成功创建 Paper 对象: 2511.15589v1
2025-11-20 23:27:10,810 - INFO - root - 下载进度: 27/40
2025-11-20 23:27:10,812 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\vision_transformer\Real-Time_Optimal_Control_via_Transformer_Networks_and_Bernstein_Polynomials.pdf
2025-11-20 23:27:10,812 - INFO - root - 成功创建 Paper 对象: 2511.15588v1
2025-11-20 23:27:10,812 - INFO - root - 下载进度: 28/40
2025-11-20 23:27:10,812 - INFO - root - 正在下载: https://arxiv.org/pdf/2511.15586v1
2025-11-20 23:27:21,569 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\vision_transformer\The_SA-FARI_Dataset_Segment_Anything_in_Footage_of_Animals_for_Recognition_and_Identification.pdf
2025-11-20 23:27:21,576 - INFO - root - 成功创建 Paper 对象: 2511.15622v1
2025-11-20 23:27:21,576 - INFO - root - 下载进度: 29/40
2025-11-20 23:27:21,576 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\vision_transformer\Graph_Rewriting_Language_as_a_Platform_for_Quantum_Diagrammatic_Calculi.pdf
2025-11-20 23:27:21,576 - INFO - root - 成功创建 Paper 对象: 2511.15581v1
2025-11-20 23:27:21,576 - INFO - root - 下载进度: 30/40
2025-11-20 23:27:21,576 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\vision_transformer\CompTrack_Information_Bottleneck-Guided_Low-Rank_Dynamic_Token_Compression_for_Point_Cloud_Tracking.pdf
2025-11-20 23:27:21,582 - INFO - root - 成功创建 Paper 对象: 2511.15580v1
2025-11-20 23:27:21,582 - INFO - root - 下载进度: 31/40
2025-11-20 23:27:21,583 - INFO - root - 正在下载: https://arxiv.org/pdf/2511.15578v1
2025-11-20 23:27:35,356 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\vision_transformer\MHR_Momentum_Human_Rig.pdf
2025-11-20 23:27:35,359 - INFO - root - 成功创建 Paper 对象: 2511.15586v1
2025-11-20 23:27:35,359 - INFO - root - 下载进度: 34/40
2025-11-20 23:27:35,359 - INFO - root - 正在下载: https://arxiv.org/pdf/2511.15571v1
2025-11-20 23:27:50,220 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\vision_transformer\From_Low-Rank_Features_to_Encoding_Mismatch_Rethinking_Feature_Distillation_in_Vision_Transformers.pdf
2025-11-20 23:27:50,222 - INFO - root - 成功创建 Paper 对象: 2511.15572v1
2025-11-20 23:27:50,223 - INFO - root - 下载进度: 35/40
2025-11-20 23:27:50,223 - INFO - root - 正在下载: https://arxiv.org/pdf/2511.15568v1
2025-11-20 23:27:50,319 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\vision_transformer\AVATAAR_Agentic_Video_Answering_via_Temporal_Adaptive_Alignment_and_Reasoning.pdf
2025-11-20 23:27:50,321 - INFO - root - 成功创建 Paper 对象: 2511.15578v1
2025-11-20 23:27:50,327 - INFO - root - 下载进度: 36/40
2025-11-20 23:28:22,333 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\vision_transformer\Integrability_of_Siegel_transforms_and_an_application.pdf
2025-11-20 23:28:22,346 - INFO - root - 成功创建 Paper 对象: 2511.15568v1
2025-11-20 23:28:22,349 - INFO - root - 下载进度: 37/40
2025-11-20 23:29:02,662 - INFO - root - 正在下载: https://arxiv.org/pdf/2511.15605v1
2025-11-20 23:29:02,674 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\vision_transformer\MHR_Momentum_Human_Rig.pdf
2025-11-20 23:29:02,675 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\vision_transformer\AVATAAR_Agentic_Video_Answering_via_Temporal_Adaptive_Alignment_and_Reasoning.pdf
2025-11-20 23:29:02,675 - INFO - root - 成功创建 Paper 对象: 2511.15586v1
2025-11-20 23:29:02,676 - INFO - root - 成功创建 Paper 对象: 2511.15578v1
2025-11-20 23:29:02,676 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\vision_transformer\GEO-Bench-2_From_Performance_to_Capability,_Rethinking_Evaluation_in_Geospatial_AI.pdf
2025-11-20 23:29:02,678 - INFO - root - 下载进度: 32/40
2025-11-20 23:29:02,679 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\vision_transformer\A_critical_review_of_pre-post_surveys_designed_to_measure_student_epistemology_in_undergraduate_scie.pdf
2025-11-20 23:29:02,679 - INFO - root - 成功创建 Paper 对象: 2511.15658v1
2025-11-20 23:29:02,680 - INFO - root - 下载进度: 33/40
2025-11-20 23:29:02,681 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\vision_transformer\From_Low-Rank_Features_to_Encoding_Mismatch_Rethinking_Feature_Distillation_in_Vision_Transformers.pdf
2025-11-20 23:29:02,682 - INFO - root - 成功创建 Paper 对象: 2511.15575v1
2025-11-20 23:29:02,683 - INFO - root - 下载进度: 34/40
2025-11-20 23:29:02,683 - INFO - root - 正在下载: https://arxiv.org/pdf/2511.15571v1
2025-11-20 23:29:02,684 - INFO - root - 成功创建 Paper 对象: 2511.15572v1
2025-11-20 23:29:02,687 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\vision_transformer\Integrability_of_Siegel_transforms_and_an_application.pdf
2025-11-20 23:29:02,687 - INFO - root - 下载进度: 35/40
2025-11-20 23:29:02,694 - INFO - root - 成功创建 Paper 对象: 2511.15568v1
2025-11-20 23:29:02,694 - INFO - root - 下载进度: 36/40
2025-11-20 23:29:02,696 - INFO - root - 下载进度: 37/40
2025-11-20 23:29:02,707 - INFO - root - 正在下载: https://arxiv.org/pdf/2511.15640v1
2025-11-20 23:29:02,707 - INFO - root - 正在下载: https://arxiv.org/pdf/2511.15640v1
2025-11-20 23:29:02,714 - INFO - root - 正在下载: https://arxiv.org/pdf/2511.15571v1
2025-11-20 23:29:02,761 - INFO - root - 正在下载: https://arxiv.org/pdf/2511.15605v1
2025-11-20 23:29:11,685 - INFO - root - 正在下载: https://arxiv.org/pdf/2511.15571v1
2025-11-20 23:29:11,685 - INFO - root - 正在下载: https://arxiv.org/pdf/2511.15605v1
2025-11-20 23:29:11,685 - INFO - root - 正在下载: https://arxiv.org/pdf/2511.15640v1
2025-11-20 23:29:11,701 - INFO - root - 正在下载: https://arxiv.org/pdf/2511.15640v1
2025-11-20 23:29:11,701 - INFO - root - 正在下载: https://arxiv.org/pdf/2511.15571v1
2025-11-20 23:29:11,701 - INFO - root - 正在下载: https://arxiv.org/pdf/2511.15605v1
2025-11-20 23:29:20,766 - INFO - root - 正在下载: https://arxiv.org/pdf/2511.15640v1
2025-11-20 23:29:20,766 - INFO - root - 正在下载: https://arxiv.org/pdf/2511.15605v1
2025-11-20 23:29:20,778 - INFO - root - 正在下载: https://arxiv.org/pdf/2511.15605v1
2025-11-20 23:29:20,779 - INFO - root - 正在下载: https://arxiv.org/pdf/2511.15640v1
2025-11-20 23:29:20,785 - INFO - root - 正在下载: https://arxiv.org/pdf/2511.15571v1
2025-11-20 23:29:20,781 - INFO - root - 正在下载: https://arxiv.org/pdf/2511.15571v1
2025-11-20 23:29:29,797 - INFO - root - 正在下载: https://arxiv.org/pdf/2511.15571v1
2025-11-20 23:29:33,797 - INFO - root - 正在下载: https://arxiv.org/pdf/2511.15640v1
2025-11-20 23:29:33,797 - INFO - root - 正在下载: https://arxiv.org/pdf/2511.15605v1
2025-11-20 23:29:33,797 - INFO - root - 正在下载: https://arxiv.org/pdf/2511.15605v1
2025-11-20 23:29:33,797 - INFO - root - 正在下载: https://arxiv.org/pdf/2511.15571v1
2025-11-20 23:29:33,797 - INFO - root - 正在下载: https://arxiv.org/pdf/2511.15640v1
2025-11-20 23:29:34,813 - WARNING - root - 处理/下载论文 http://arxiv.org/abs/2511.15605v1 时失败: HTTPSConnectionPool(host='arxiv.org', port=443): Max retries exceeded with url: /pdf/2511.15605v1 (Caused by SSLError(SSLEOFError(8, '[SSL: UNEXPECTED_EOF_WHILE_READING] EOF occurred in violation of protocol (_ssl.c:1010)')))
2025-11-20 23:29:34,814 - WARNING - root - 处理/下载论文 http://arxiv.org/abs/2511.15571v1 时失败: HTTPSConnectionPool(host='arxiv.org', port=443): Max retries exceeded with url: /pdf/2511.15571v1 (Caused by SSLError(SSLEOFError(8, '[SSL: UNEXPECTED_EOF_WHILE_READING] EOF occurred in violation of protocol (_ssl.c:1010)')))
2025-11-20 23:29:34,814 - WARNING - root - 处理/下载论文 http://arxiv.org/abs/2511.15640v1 时失败: HTTPSConnectionPool(host='arxiv.org', port=443): Max retries exceeded with url: /pdf/2511.15640v1 (Caused by SSLError(SSLEOFError(8, '[SSL: UNEXPECTED_EOF_WHILE_READING] EOF occurred in violation of protocol (_ssl.c:1010)')))
2025-11-20 23:29:34,822 - INFO - root - 下载进度: 38/40
2025-11-20 23:29:34,824 - INFO - root - 下载进度: 39/40
2025-11-20 23:29:34,826 - INFO - root - 下载进度: 40/40
2025-11-20 23:29:34,840 - INFO - root - 论文处理完成: 37 篇成功下载, 3 篇需手动下载。耗时 1071.11 秒。
2025-11-20 23:29:34,868 - INFO - root - 检索到 40 篇论文（包括待手动下载的），开始总结...
2025-11-20 23:29:34,898 - INFO - root - --- 开始论文总结阶段 ---
2025-11-20 23:29:34,915 - INFO - root - 正在总结论文 1/40: Resolving Ratio Redundancy in Chemical Freeze-out Studies with Principal Component Analysis and Bayesian Calibration
2025-11-20 23:29:35,114 - WARNING - root - 处理/下载论文 http://arxiv.org/abs/2511.15605v1 时失败: ('Connection aborted.', ConnectionAbortedError(10053, '你的主机中的软件中止了一个已建立的连接。', None, 10053, None))
2025-11-20 23:29:35,121 - WARNING - root - 处理/下载论文 http://arxiv.org/abs/2511.15640v1 时失败: ('Connection aborted.', ConnectionAbortedError(10053, '你的主机中的软件中止了一个已建立的连接。', None, 10053, None))
2025-11-20 23:29:35,123 - INFO - root - 下载进度: 38/40
2025-11-20 23:29:35,124 - INFO - root - 下载进度: 39/40
2025-11-20 23:29:42,818 - INFO - root - 正在下载: https://arxiv.org/pdf/2511.15571v1
2025-11-20 23:29:47,860 - WARNING - root - 处理/下载论文 http://arxiv.org/abs/2511.15571v1 时失败: ('Connection aborted.', ConnectionResetError(10054, '远程主机强迫关闭了一个现有的连接。', None, 10054, None))
2025-11-20 23:29:47,860 - INFO - root - 下载进度: 40/40
2025-11-20 23:29:47,873 - INFO - root - 论文处理完成: 37 篇成功下载, 3 篇需手动下载。耗时 910.61 秒。
2025-11-20 23:29:47,891 - INFO - root - 检索到 40 篇论文（包括待手动下载的），开始总结...
2025-11-20 23:29:47,911 - INFO - root - --- 开始论文总结阶段 ---
2025-11-20 23:29:47,911 - INFO - root - 正在总结论文 1/40: Resolving Ratio Redundancy in Chemical Freeze-out Studies with Principal Component Analysis and Bayesian Calibration
2025-11-20 23:29:50,378 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-20 23:30:48,822 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-20 23:31:13,546 - INFO - openai._base_client - Retrying request to /chat/completions in 0.409094 seconds
2025-11-20 23:31:18,529 - INFO - openai._base_client - Retrying request to /chat/completions in 0.883472 seconds
2025-11-20 23:31:38,809 - ERROR - root - DeepSeekClient: generation error: Connection error.
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpx\_transports\default.py", line 101, in map_httpcore_exceptions
    yield
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpx\_transports\default.py", line 250, in handle_request
    resp = self._pool.handle_request(req)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpcore\_sync\connection_pool.py", line 256, in handle_request
    raise exc from None
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpcore\_sync\connection_pool.py", line 236, in handle_request
    response = connection.handle_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpcore\_sync\http_proxy.py", line 343, in handle_request
    return self._connection.handle_request(request)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpcore\_sync\http11.py", line 136, in handle_request
    raise exc
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpcore\_sync\http11.py", line 106, in handle_request
    ) = self._receive_response_headers(**kwargs)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpcore\_sync\http11.py", line 177, in _receive_response_headers
    event = self._receive_event(timeout=timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpcore\_sync\http11.py", line 231, in _receive_event
    raise RemoteProtocolError(msg)
httpcore.RemoteProtocolError: Server disconnected without sending a response.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\openai\_base_client.py", line 982, in request
    response = self._client.send(
               ^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpx\_client.py", line 914, in send
    response = self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpx\_client.py", line 942, in _send_handling_auth
    response = self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpx\_client.py", line 979, in _send_handling_redirects
    response = self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpx\_client.py", line 1014, in _send_single_request
    response = transport.handle_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpx\_transports\default.py", line 249, in handle_request
    with map_httpcore_exceptions():
         ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(value)
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpx\_transports\default.py", line 118, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.RemoteProtocolError: Server disconnected without sending a response.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "D:\ChatPaper\llm_client_merged.py", line 296, in generate
    completion = self.client.chat.completions.create(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\openai\_utils\_utils.py", line 286, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\openai\resources\chat\completions\completions.py", line 1156, in create
    return self._post(
           ^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\openai\_base_client.py", line 1259, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\openai\_base_client.py", line 1014, in request
    raise APIConnectionError(request=request) from err
openai.APIConnectionError: Connection error.
2025-11-20 23:31:38,966 - WARNING - root - DeepSeekClient: 网络连接问题 检测到，等待 60 秒后重试
2025-11-20 23:32:38,967 - INFO - root - DeepSeekClient: retry attempt 2 for generation
2025-11-20 23:32:49,636 - INFO - openai._base_client - Retrying request to /chat/completions in 0.431988 seconds
2025-11-20 23:32:53,362 - INFO - openai._base_client - Retrying request to /chat/completions in 0.773201 seconds
2025-11-20 23:32:54,995 - ERROR - root - DeepSeekClient: generation error: Connection error.
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpx\_transports\default.py", line 101, in map_httpcore_exceptions
    yield
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpx\_transports\default.py", line 250, in handle_request
    resp = self._pool.handle_request(req)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpcore\_sync\connection_pool.py", line 256, in handle_request
    raise exc from None
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpcore\_sync\connection_pool.py", line 236, in handle_request
    response = connection.handle_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpcore\_sync\http_proxy.py", line 343, in handle_request
    return self._connection.handle_request(request)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpcore\_sync\http11.py", line 136, in handle_request
    raise exc
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpcore\_sync\http11.py", line 106, in handle_request
    ) = self._receive_response_headers(**kwargs)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpcore\_sync\http11.py", line 177, in _receive_response_headers
    event = self._receive_event(timeout=timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpcore\_sync\http11.py", line 231, in _receive_event
    raise RemoteProtocolError(msg)
httpcore.RemoteProtocolError: Server disconnected without sending a response.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\openai\_base_client.py", line 982, in request
    response = self._client.send(
               ^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpx\_client.py", line 914, in send
    response = self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpx\_client.py", line 942, in _send_handling_auth
    response = self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpx\_client.py", line 979, in _send_handling_redirects
    response = self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpx\_client.py", line 1014, in _send_single_request
    response = transport.handle_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpx\_transports\default.py", line 249, in handle_request
    with map_httpcore_exceptions():
         ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(value)
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpx\_transports\default.py", line 118, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.RemoteProtocolError: Server disconnected without sending a response.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "D:\ChatPaper\llm_client_merged.py", line 296, in generate
    completion = self.client.chat.completions.create(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\openai\_utils\_utils.py", line 286, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\openai\resources\chat\completions\completions.py", line 1156, in create
    return self._post(
           ^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\openai\_base_client.py", line 1259, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\openai\_base_client.py", line 1014, in request
    raise APIConnectionError(request=request) from err
openai.APIConnectionError: Connection error.
2025-11-20 23:32:55,043 - WARNING - root - DeepSeekClient: 网络连接问题 检测到，等待 60 秒后重试
2025-11-20 23:33:55,044 - INFO - root - DeepSeekClient: retry attempt 3 for generation
2025-11-20 23:34:38,793 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-20 23:34:38,871 - INFO - root - 正在提取论文图片到目录: ./export\vision_transformer\images\Resolving_Ratio_Redundancy_in_Chemical_Freeze-out_Studies_with_Principal_Component_Analysis_and_Baye
2025-11-20 23:34:42,083 - INFO - root - 已保存图片 1/10：./export\vision_transformer\images\Resolving_Ratio_Redundancy_in_Chemical_Freeze-out_Studies_with_Principal_Component_Analysis_and_Baye\figure_1_page14.png
2025-11-20 23:34:42,266 - INFO - root - 已保存图片 2/10：./export\vision_transformer\images\Resolving_Ratio_Redundancy_in_Chemical_Freeze-out_Studies_with_Principal_Component_Analysis_and_Baye\figure_2_page9.png
2025-11-20 23:34:42,477 - INFO - root - 已保存图片 3/10：./export\vision_transformer\images\Resolving_Ratio_Redundancy_in_Chemical_Freeze-out_Studies_with_Principal_Component_Analysis_and_Baye\figure_3_page8.png
2025-11-20 23:34:42,920 - INFO - root - 已保存图片 4/10：./export\vision_transformer\images\Resolving_Ratio_Redundancy_in_Chemical_Freeze-out_Studies_with_Principal_Component_Analysis_and_Baye\figure_4_page13.png
2025-11-20 23:34:43,086 - INFO - root - 已保存图片 5/10：./export\vision_transformer\images\Resolving_Ratio_Redundancy_in_Chemical_Freeze-out_Studies_with_Principal_Component_Analysis_and_Baye\figure_5_page6.png
2025-11-20 23:34:43,203 - INFO - root - 已保存图片 6/10：./export\vision_transformer\images\Resolving_Ratio_Redundancy_in_Chemical_Freeze-out_Studies_with_Principal_Component_Analysis_and_Baye\figure_6_page13.png
2025-11-20 23:34:43,297 - INFO - root - 已保存图片 7/10：./export\vision_transformer\images\Resolving_Ratio_Redundancy_in_Chemical_Freeze-out_Studies_with_Principal_Component_Analysis_and_Baye\figure_7_page9.png
2025-11-20 23:34:43,464 - INFO - root - 已保存图片 8/10：./export\vision_transformer\images\Resolving_Ratio_Redundancy_in_Chemical_Freeze-out_Studies_with_Principal_Component_Analysis_and_Baye\figure_8_page3.png
2025-11-20 23:34:43,605 - INFO - root - 已保存图片 9/10：./export\vision_transformer\images\Resolving_Ratio_Redundancy_in_Chemical_Freeze-out_Studies_with_Principal_Component_Analysis_and_Baye\figure_9_page4.png
2025-11-20 23:34:43,705 - INFO - root - 已保存图片 10/10：./export\vision_transformer\images\Resolving_Ratio_Redundancy_in_Chemical_Freeze-out_Studies_with_Principal_Component_Analysis_and_Baye\figure_10_page4.png
2025-11-20 23:34:43,828 - INFO - root - 成功添加图片 1：./export\vision_transformer\images\Resolving_Ratio_Redundancy_in_Chemical_Freeze-out_Studies_with_Principal_Component_Analysis_and_Baye\figure_1_page14.png
2025-11-20 23:34:43,831 - INFO - root - 成功添加图片 2：./export\vision_transformer\images\Resolving_Ratio_Redundancy_in_Chemical_Freeze-out_Studies_with_Principal_Component_Analysis_and_Baye\figure_2_page9.png
2025-11-20 23:34:43,832 - INFO - root - 成功添加图片 3：./export\vision_transformer\images\Resolving_Ratio_Redundancy_in_Chemical_Freeze-out_Studies_with_Principal_Component_Analysis_and_Baye\figure_3_page8.png
2025-11-20 23:34:43,833 - INFO - root - 成功添加图片 4：./export\vision_transformer\images\Resolving_Ratio_Redundancy_in_Chemical_Freeze-out_Studies_with_Principal_Component_Analysis_and_Baye\figure_4_page13.png
2025-11-20 23:34:43,834 - INFO - root - 成功添加图片 5：./export\vision_transformer\images\Resolving_Ratio_Redundancy_in_Chemical_Freeze-out_Studies_with_Principal_Component_Analysis_and_Baye\figure_5_page6.png
2025-11-20 23:34:43,836 - INFO - root - 成功添加图片 6：./export\vision_transformer\images\Resolving_Ratio_Redundancy_in_Chemical_Freeze-out_Studies_with_Principal_Component_Analysis_and_Baye\figure_6_page13.png
2025-11-20 23:34:43,837 - INFO - root - 成功添加图片 7：./export\vision_transformer\images\Resolving_Ratio_Redundancy_in_Chemical_Freeze-out_Studies_with_Principal_Component_Analysis_and_Baye\figure_7_page9.png
2025-11-20 23:34:43,838 - INFO - root - 成功添加图片 8：./export\vision_transformer\images\Resolving_Ratio_Redundancy_in_Chemical_Freeze-out_Studies_with_Principal_Component_Analysis_and_Baye\figure_8_page3.png
2025-11-20 23:34:43,839 - INFO - root - 成功添加图片 9：./export\vision_transformer\images\Resolving_Ratio_Redundancy_in_Chemical_Freeze-out_Studies_with_Principal_Component_Analysis_and_Baye\figure_9_page4.png
2025-11-20 23:34:43,840 - INFO - root - 成功添加图片 10：./export\vision_transformer\images\Resolving_Ratio_Redundancy_in_Chemical_Freeze-out_Studies_with_Principal_Component_Analysis_and_Baye\figure_10_page4.png
2025-11-20 23:34:43,851 - INFO - root - 论文《Resolving Ratio Redundancy in Chemical Freeze-out Studies with Principal Component Analysis and Bayesian Calibration》的分析已保存到 ./export\vision_transformer\Resolving_Ratio_Redundancy_in_Chemical_Freeze-out_Studies_with_Principal_Component_Analysis_and_Baye.md
2025-11-20 23:34:43,870 - INFO - root - 正在总结论文 2/40: Think Visually, Reason Textually: Vision-Language Synergy in ARC
2025-11-20 23:34:57,802 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-20 23:35:49,344 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-20 23:36:25,540 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-20 23:36:25,547 - INFO - root - 正在提取论文图片到目录: ./export\vision_transformer\images\Think_Visually,_Reason_Textually_Vision-Language_Synergy_in_ARC
2025-11-20 23:36:25,803 - INFO - root - 已保存图片 1/10：./export\vision_transformer\images\Think_Visually,_Reason_Textually_Vision-Language_Synergy_in_ARC\figure_1_page1.png
2025-11-20 23:36:25,856 - INFO - root - 已保存图片 2/10：./export\vision_transformer\images\Think_Visually,_Reason_Textually_Vision-Language_Synergy_in_ARC\figure_2_page4.jpeg
2025-11-20 23:36:25,906 - INFO - root - 已保存图片 3/10：./export\vision_transformer\images\Think_Visually,_Reason_Textually_Vision-Language_Synergy_in_ARC\figure_3_page4.jpeg
2025-11-20 23:36:25,933 - INFO - root - 已保存图片 4/10：./export\vision_transformer\images\Think_Visually,_Reason_Textually_Vision-Language_Synergy_in_ARC\figure_4_page15.jpeg
2025-11-20 23:36:25,964 - INFO - root - 已保存图片 5/10：./export\vision_transformer\images\Think_Visually,_Reason_Textually_Vision-Language_Synergy_in_ARC\figure_5_page14.jpeg
2025-11-20 23:36:25,987 - INFO - root - 已保存图片 6/10：./export\vision_transformer\images\Think_Visually,_Reason_Textually_Vision-Language_Synergy_in_ARC\figure_6_page12.jpeg
2025-11-20 23:36:26,012 - INFO - root - 已保存图片 7/10：./export\vision_transformer\images\Think_Visually,_Reason_Textually_Vision-Language_Synergy_in_ARC\figure_7_page2.jpeg
2025-11-20 23:36:26,037 - INFO - root - 已保存图片 8/10：./export\vision_transformer\images\Think_Visually,_Reason_Textually_Vision-Language_Synergy_in_ARC\figure_8_page7.jpeg
2025-11-20 23:36:26,050 - INFO - root - 已保存图片 9/10：./export\vision_transformer\images\Think_Visually,_Reason_Textually_Vision-Language_Synergy_in_ARC\figure_9_page13.jpeg
2025-11-20 23:36:26,084 - INFO - root - 已保存图片 10/10：./export\vision_transformer\images\Think_Visually,_Reason_Textually_Vision-Language_Synergy_in_ARC\figure_10_page4.jpeg
2025-11-20 23:36:26,087 - INFO - root - 成功添加图片 1：./export\vision_transformer\images\Think_Visually,_Reason_Textually_Vision-Language_Synergy_in_ARC\figure_1_page1.png
2025-11-20 23:36:26,087 - INFO - root - 成功添加图片 2：./export\vision_transformer\images\Think_Visually,_Reason_Textually_Vision-Language_Synergy_in_ARC\figure_2_page4.jpeg
2025-11-20 23:36:26,087 - INFO - root - 成功添加图片 3：./export\vision_transformer\images\Think_Visually,_Reason_Textually_Vision-Language_Synergy_in_ARC\figure_3_page4.jpeg
2025-11-20 23:36:26,088 - INFO - root - 成功添加图片 4：./export\vision_transformer\images\Think_Visually,_Reason_Textually_Vision-Language_Synergy_in_ARC\figure_4_page15.jpeg
2025-11-20 23:36:26,088 - INFO - root - 成功添加图片 5：./export\vision_transformer\images\Think_Visually,_Reason_Textually_Vision-Language_Synergy_in_ARC\figure_5_page14.jpeg
2025-11-20 23:36:26,088 - INFO - root - 成功添加图片 6：./export\vision_transformer\images\Think_Visually,_Reason_Textually_Vision-Language_Synergy_in_ARC\figure_6_page12.jpeg
2025-11-20 23:36:26,089 - INFO - root - 成功添加图片 7：./export\vision_transformer\images\Think_Visually,_Reason_Textually_Vision-Language_Synergy_in_ARC\figure_7_page2.jpeg
2025-11-20 23:36:26,089 - INFO - root - 成功添加图片 8：./export\vision_transformer\images\Think_Visually,_Reason_Textually_Vision-Language_Synergy_in_ARC\figure_8_page7.jpeg
2025-11-20 23:36:26,089 - INFO - root - 成功添加图片 9：./export\vision_transformer\images\Think_Visually,_Reason_Textually_Vision-Language_Synergy_in_ARC\figure_9_page13.jpeg
2025-11-20 23:36:26,090 - INFO - root - 成功添加图片 10：./export\vision_transformer\images\Think_Visually,_Reason_Textually_Vision-Language_Synergy_in_ARC\figure_10_page4.jpeg
2025-11-20 23:36:26,092 - INFO - root - 论文《Think Visually, Reason Textually: Vision-Language Synergy in ARC》的分析已保存到 ./export\vision_transformer\Think_Visually,_Reason_Textually_Vision-Language_Synergy_in_ARC.md
2025-11-20 23:36:26,096 - INFO - root - 正在总结论文 3/40: Joint Semantic-Channel Coding and Modulation for Token Communications
2025-11-20 23:36:36,977 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-20 23:36:36,979 - INFO - root - LLMClient: rate limit reached, sleeping 12.4s
2025-11-20 23:37:17,028 - INFO - root - 正在提取论文图片到目录: ./export\vision_transformer\images\Resolving_Ratio_Redundancy_in_Chemical_Freeze-out_Studies_with_Principal_Component_Analysis_and_Baye
2025-11-20 23:37:18,162 - INFO - root - 已保存图片 1/10：./export\vision_transformer\images\Resolving_Ratio_Redundancy_in_Chemical_Freeze-out_Studies_with_Principal_Component_Analysis_and_Baye\figure_1_page14.png
2025-11-20 23:37:18,235 - INFO - root - 已保存图片 2/10：./export\vision_transformer\images\Resolving_Ratio_Redundancy_in_Chemical_Freeze-out_Studies_with_Principal_Component_Analysis_and_Baye\figure_2_page9.png
2025-11-20 23:37:18,329 - INFO - root - 已保存图片 3/10：./export\vision_transformer\images\Resolving_Ratio_Redundancy_in_Chemical_Freeze-out_Studies_with_Principal_Component_Analysis_and_Baye\figure_3_page8.png
2025-11-20 23:37:18,405 - INFO - root - 已保存图片 4/10：./export\vision_transformer\images\Resolving_Ratio_Redundancy_in_Chemical_Freeze-out_Studies_with_Principal_Component_Analysis_and_Baye\figure_4_page13.png
2025-11-20 23:37:18,456 - INFO - root - 已保存图片 5/10：./export\vision_transformer\images\Resolving_Ratio_Redundancy_in_Chemical_Freeze-out_Studies_with_Principal_Component_Analysis_and_Baye\figure_5_page6.png
2025-11-20 23:37:18,509 - INFO - root - 已保存图片 6/10：./export\vision_transformer\images\Resolving_Ratio_Redundancy_in_Chemical_Freeze-out_Studies_with_Principal_Component_Analysis_and_Baye\figure_6_page13.png
2025-11-20 23:37:18,562 - INFO - root - 已保存图片 7/10：./export\vision_transformer\images\Resolving_Ratio_Redundancy_in_Chemical_Freeze-out_Studies_with_Principal_Component_Analysis_and_Baye\figure_7_page9.png
2025-11-20 23:37:18,633 - INFO - root - 已保存图片 8/10：./export\vision_transformer\images\Resolving_Ratio_Redundancy_in_Chemical_Freeze-out_Studies_with_Principal_Component_Analysis_and_Baye\figure_8_page3.png
2025-11-20 23:37:18,708 - INFO - root - 已保存图片 9/10：./export\vision_transformer\images\Resolving_Ratio_Redundancy_in_Chemical_Freeze-out_Studies_with_Principal_Component_Analysis_and_Baye\figure_9_page4.png
2025-11-20 23:37:18,753 - INFO - root - 已保存图片 10/10：./export\vision_transformer\images\Resolving_Ratio_Redundancy_in_Chemical_Freeze-out_Studies_with_Principal_Component_Analysis_and_Baye\figure_10_page4.png
2025-11-20 23:37:18,760 - INFO - root - 成功添加图片 1：./export\vision_transformer\images\Resolving_Ratio_Redundancy_in_Chemical_Freeze-out_Studies_with_Principal_Component_Analysis_and_Baye\figure_1_page14.png
2025-11-20 23:37:18,762 - INFO - root - 成功添加图片 2：./export\vision_transformer\images\Resolving_Ratio_Redundancy_in_Chemical_Freeze-out_Studies_with_Principal_Component_Analysis_and_Baye\figure_2_page9.png
2025-11-20 23:37:18,762 - INFO - root - 成功添加图片 3：./export\vision_transformer\images\Resolving_Ratio_Redundancy_in_Chemical_Freeze-out_Studies_with_Principal_Component_Analysis_and_Baye\figure_3_page8.png
2025-11-20 23:37:18,763 - INFO - root - 成功添加图片 4：./export\vision_transformer\images\Resolving_Ratio_Redundancy_in_Chemical_Freeze-out_Studies_with_Principal_Component_Analysis_and_Baye\figure_4_page13.png
2025-11-20 23:37:18,763 - INFO - root - 成功添加图片 5：./export\vision_transformer\images\Resolving_Ratio_Redundancy_in_Chemical_Freeze-out_Studies_with_Principal_Component_Analysis_and_Baye\figure_5_page6.png
2025-11-20 23:37:18,764 - INFO - root - 成功添加图片 6：./export\vision_transformer\images\Resolving_Ratio_Redundancy_in_Chemical_Freeze-out_Studies_with_Principal_Component_Analysis_and_Baye\figure_6_page13.png
2025-11-20 23:37:18,764 - INFO - root - 成功添加图片 7：./export\vision_transformer\images\Resolving_Ratio_Redundancy_in_Chemical_Freeze-out_Studies_with_Principal_Component_Analysis_and_Baye\figure_7_page9.png
2025-11-20 23:37:18,764 - INFO - root - 成功添加图片 8：./export\vision_transformer\images\Resolving_Ratio_Redundancy_in_Chemical_Freeze-out_Studies_with_Principal_Component_Analysis_and_Baye\figure_8_page3.png
2025-11-20 23:37:18,764 - INFO - root - 成功添加图片 9：./export\vision_transformer\images\Resolving_Ratio_Redundancy_in_Chemical_Freeze-out_Studies_with_Principal_Component_Analysis_and_Baye\figure_9_page4.png
2025-11-20 23:37:18,765 - INFO - root - 成功添加图片 10：./export\vision_transformer\images\Resolving_Ratio_Redundancy_in_Chemical_Freeze-out_Studies_with_Principal_Component_Analysis_and_Baye\figure_10_page4.png
2025-11-20 23:37:18,766 - INFO - root - 输出文件已存在，跳过论文 Resolving Ratio Redundancy in Chemical Freeze-out Studies with Principal Component Analysis and Bayesian Calibration 的处理
2025-11-20 23:37:18,767 - INFO - root - 正在总结论文 2/40: GeoVista: Web-Augmented Agentic Visual Reasoning for Geolocalization
2025-11-20 23:37:32,284 - INFO - root - LLMClient: rate limit reached, sleeping 20.6s
2025-11-20 23:37:53,331 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-20 23:38:31,594 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-20 23:38:31,778 - INFO - root - 正在提取论文图片到目录: ./export\vision_transformer\images\Joint_Semantic-Channel_Coding_and_Modulation_for_Token_Communications
2025-11-20 23:38:40,686 - INFO - root - 已保存图片 1/10：./export\vision_transformer\images\Joint_Semantic-Channel_Coding_and_Modulation_for_Token_Communications\figure_1_page12.png
2025-11-20 23:38:40,935 - INFO - root - 已保存图片 2/10：./export\vision_transformer\images\Joint_Semantic-Channel_Coding_and_Modulation_for_Token_Communications\figure_2_page4.jpeg
2025-11-20 23:38:41,291 - INFO - root - 已保存图片 3/10：./export\vision_transformer\images\Joint_Semantic-Channel_Coding_and_Modulation_for_Token_Communications\figure_3_page4.jpeg
2025-11-20 23:38:41,447 - INFO - root - 已保存图片 4/10：./export\vision_transformer\images\Joint_Semantic-Channel_Coding_and_Modulation_for_Token_Communications\figure_4_page1.jpeg
2025-11-20 23:38:41,492 - INFO - root - 已保存图片 5/10：./export\vision_transformer\images\Joint_Semantic-Channel_Coding_and_Modulation_for_Token_Communications\figure_5_page12.png
2025-11-20 23:38:41,769 - INFO - root - 已保存图片 6/10：./export\vision_transformer\images\Joint_Semantic-Channel_Coding_and_Modulation_for_Token_Communications\figure_6_page1.png
2025-11-20 23:38:41,919 - INFO - root - 已保存图片 7/10：./export\vision_transformer\images\Joint_Semantic-Channel_Coding_and_Modulation_for_Token_Communications\figure_7_page1.png
2025-11-20 23:38:42,049 - INFO - root - 已保存图片 8/10：./export\vision_transformer\images\Joint_Semantic-Channel_Coding_and_Modulation_for_Token_Communications\figure_8_page1.png
2025-11-20 23:38:42,125 - INFO - root - 已保存图片 9/10：./export\vision_transformer\images\Joint_Semantic-Channel_Coding_and_Modulation_for_Token_Communications\figure_9_page1.png
2025-11-20 23:38:42,301 - INFO - root - 已保存图片 10/10：./export\vision_transformer\images\Joint_Semantic-Channel_Coding_and_Modulation_for_Token_Communications\figure_10_page1.png
2025-11-20 23:38:42,332 - INFO - root - 成功添加图片 1：./export\vision_transformer\images\Joint_Semantic-Channel_Coding_and_Modulation_for_Token_Communications\figure_1_page12.png
2025-11-20 23:38:42,332 - INFO - root - 成功添加图片 2：./export\vision_transformer\images\Joint_Semantic-Channel_Coding_and_Modulation_for_Token_Communications\figure_2_page4.jpeg
2025-11-20 23:38:42,333 - INFO - root - 成功添加图片 3：./export\vision_transformer\images\Joint_Semantic-Channel_Coding_and_Modulation_for_Token_Communications\figure_3_page4.jpeg
2025-11-20 23:38:42,333 - INFO - root - 成功添加图片 4：./export\vision_transformer\images\Joint_Semantic-Channel_Coding_and_Modulation_for_Token_Communications\figure_4_page1.jpeg
2025-11-20 23:38:42,334 - INFO - root - 成功添加图片 5：./export\vision_transformer\images\Joint_Semantic-Channel_Coding_and_Modulation_for_Token_Communications\figure_5_page12.png
2025-11-20 23:38:42,335 - INFO - root - 成功添加图片 6：./export\vision_transformer\images\Joint_Semantic-Channel_Coding_and_Modulation_for_Token_Communications\figure_6_page1.png
2025-11-20 23:38:42,335 - INFO - root - 成功添加图片 7：./export\vision_transformer\images\Joint_Semantic-Channel_Coding_and_Modulation_for_Token_Communications\figure_7_page1.png
2025-11-20 23:38:42,335 - INFO - root - 成功添加图片 8：./export\vision_transformer\images\Joint_Semantic-Channel_Coding_and_Modulation_for_Token_Communications\figure_8_page1.png
2025-11-20 23:38:42,336 - INFO - root - 成功添加图片 9：./export\vision_transformer\images\Joint_Semantic-Channel_Coding_and_Modulation_for_Token_Communications\figure_9_page1.png
2025-11-20 23:38:42,336 - INFO - root - 成功添加图片 10：./export\vision_transformer\images\Joint_Semantic-Channel_Coding_and_Modulation_for_Token_Communications\figure_10_page1.png
2025-11-20 23:38:42,342 - INFO - root - 论文《Joint Semantic-Channel Coding and Modulation for Token Communications》的分析已保存到 ./export\vision_transformer\Joint_Semantic-Channel_Coding_and_Modulation_for_Token_Communications.md
2025-11-20 23:38:42,353 - INFO - root - 正在总结论文 4/40: Hyperspectral Image Classification using Spectral-Spatial Mixer Network
2025-11-20 23:38:50,315 - INFO - root - 正在提取论文图片到目录: ./export\vision_transformer\images\GeoVista_Web-Augmented_Agentic_Visual_Reasoning_for_Geolocalization
2025-11-20 23:38:51,257 - INFO - root - 已保存图片 1/10：./export\vision_transformer\images\GeoVista_Web-Augmented_Agentic_Visual_Reasoning_for_Geolocalization\figure_1_page2.png
2025-11-20 23:38:51,382 - INFO - root - 已保存图片 2/10：./export\vision_transformer\images\GeoVista_Web-Augmented_Agentic_Visual_Reasoning_for_Geolocalization\figure_2_page4.png
2025-11-20 23:38:51,487 - INFO - root - 已保存图片 3/10：./export\vision_transformer\images\GeoVista_Web-Augmented_Agentic_Visual_Reasoning_for_Geolocalization\figure_3_page13.png
2025-11-20 23:38:51,611 - INFO - root - 已保存图片 4/10：./export\vision_transformer\images\GeoVista_Web-Augmented_Agentic_Visual_Reasoning_for_Geolocalization\figure_4_page5.jpeg
2025-11-20 23:38:51,710 - INFO - root - 已保存图片 5/10：./export\vision_transformer\images\GeoVista_Web-Augmented_Agentic_Visual_Reasoning_for_Geolocalization\figure_5_page5.jpeg
2025-11-20 23:38:52,038 - INFO - root - 已保存图片 6/10：./export\vision_transformer\images\GeoVista_Web-Augmented_Agentic_Visual_Reasoning_for_Geolocalization\figure_6_page4.jpeg
2025-11-20 23:38:52,164 - INFO - root - 已保存图片 7/10：./export\vision_transformer\images\GeoVista_Web-Augmented_Agentic_Visual_Reasoning_for_Geolocalization\figure_7_page5.jpeg
2025-11-20 23:38:52,301 - INFO - root - 已保存图片 8/10：./export\vision_transformer\images\GeoVista_Web-Augmented_Agentic_Visual_Reasoning_for_Geolocalization\figure_8_page6.jpeg
2025-11-20 23:38:52,389 - INFO - root - 已保存图片 9/10：./export\vision_transformer\images\GeoVista_Web-Augmented_Agentic_Visual_Reasoning_for_Geolocalization\figure_9_page2.jpeg
2025-11-20 23:38:52,462 - INFO - root - 已保存图片 10/10：./export\vision_transformer\images\GeoVista_Web-Augmented_Agentic_Visual_Reasoning_for_Geolocalization\figure_10_page12.jpeg
2025-11-20 23:38:52,477 - INFO - root - 成功添加图片 1：./export\vision_transformer\images\GeoVista_Web-Augmented_Agentic_Visual_Reasoning_for_Geolocalization\figure_1_page2.png
2025-11-20 23:38:52,478 - INFO - root - 成功添加图片 2：./export\vision_transformer\images\GeoVista_Web-Augmented_Agentic_Visual_Reasoning_for_Geolocalization\figure_2_page4.png
2025-11-20 23:38:52,478 - INFO - root - 成功添加图片 3：./export\vision_transformer\images\GeoVista_Web-Augmented_Agentic_Visual_Reasoning_for_Geolocalization\figure_3_page13.png
2025-11-20 23:38:52,478 - INFO - root - 成功添加图片 4：./export\vision_transformer\images\GeoVista_Web-Augmented_Agentic_Visual_Reasoning_for_Geolocalization\figure_4_page5.jpeg
2025-11-20 23:38:52,478 - INFO - root - 成功添加图片 5：./export\vision_transformer\images\GeoVista_Web-Augmented_Agentic_Visual_Reasoning_for_Geolocalization\figure_5_page5.jpeg
2025-11-20 23:38:52,478 - INFO - root - 成功添加图片 6：./export\vision_transformer\images\GeoVista_Web-Augmented_Agentic_Visual_Reasoning_for_Geolocalization\figure_6_page4.jpeg
2025-11-20 23:38:52,478 - INFO - root - 成功添加图片 7：./export\vision_transformer\images\GeoVista_Web-Augmented_Agentic_Visual_Reasoning_for_Geolocalization\figure_7_page5.jpeg
2025-11-20 23:38:52,478 - INFO - root - 成功添加图片 8：./export\vision_transformer\images\GeoVista_Web-Augmented_Agentic_Visual_Reasoning_for_Geolocalization\figure_8_page6.jpeg
2025-11-20 23:38:52,478 - INFO - root - 成功添加图片 9：./export\vision_transformer\images\GeoVista_Web-Augmented_Agentic_Visual_Reasoning_for_Geolocalization\figure_9_page2.jpeg
2025-11-20 23:38:52,478 - INFO - root - 成功添加图片 10：./export\vision_transformer\images\GeoVista_Web-Augmented_Agentic_Visual_Reasoning_for_Geolocalization\figure_10_page12.jpeg
2025-11-20 23:38:52,478 - INFO - root - 论文《GeoVista: Web-Augmented Agentic Visual Reasoning for Geolocalization》的分析已保存到 ./export\vision_transformer\GeoVista_Web-Augmented_Agentic_Visual_Reasoning_for_Geolocalization.md
2025-11-20 23:38:52,494 - INFO - root - 跳过已处理论文 Think Visually, Reason Textually: Vision-Language Synergy in ARC：D:\ChatPaper\api_downloads\vision_transformer\Think_Visually,_Reason_Textually_Vision-Language_Synergy_in_ARC.pdf
2025-11-20 23:38:52,494 - INFO - root - 跳过已处理论文 Joint Semantic-Channel Coding and Modulation for Token Communications：D:\ChatPaper\api_downloads\vision_transformer\Joint_Semantic-Channel_Coding_and_Modulation_for_Token_Communications.pdf
2025-11-20 23:38:52,496 - INFO - root - 正在总结论文 5/40: Hyperspectral Image Classification using Spectral-Spatial Mixer Network
2025-11-20 23:38:52,496 - INFO - root - LLMClient: rate limit reached, sleeping 0.4s
2025-11-20 23:38:52,723 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-20 23:38:52,730 - INFO - root - LLMClient: rate limit reached, sleeping 0.6s
2025-11-20 23:39:03,073 - INFO - root - LLMClient: rate limit reached, sleeping 19.0s
2025-11-20 23:39:43,215 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-20 23:39:51,895 - INFO - root - LLMClient: rate limit reached, sleeping 1.0s
2025-11-20 23:40:13,787 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-20 23:40:13,791 - INFO - root - 正在提取论文图片到目录: ./export\vision_transformer\images\Hyperspectral_Image_Classification_using_Spectral-Spatial_Mixer_Network
2025-11-20 23:40:13,866 - INFO - root - 正在提取论文图片到目录: ./export\vision_transformer\images\Hyperspectral_Image_Classification_using_Spectral-Spatial_Mixer_Network
2025-11-20 23:40:14,515 - INFO - root - 已保存图片 1/10：./export\vision_transformer\images\Hyperspectral_Image_Classification_using_Spectral-Spatial_Mixer_Network\figure_1_page3.png
2025-11-20 23:40:14,560 - INFO - root - 已保存图片 1/10：./export\vision_transformer\images\Hyperspectral_Image_Classification_using_Spectral-Spatial_Mixer_Network\figure_1_page3.png
2025-11-20 23:40:14,659 - INFO - root - 已保存图片 2/10：./export\vision_transformer\images\Hyperspectral_Image_Classification_using_Spectral-Spatial_Mixer_Network\figure_2_page2.png
2025-11-20 23:40:14,699 - INFO - root - 已保存图片 2/10：./export\vision_transformer\images\Hyperspectral_Image_Classification_using_Spectral-Spatial_Mixer_Network\figure_2_page2.png
2025-11-20 23:40:14,758 - INFO - root - 已保存图片 3/10：./export\vision_transformer\images\Hyperspectral_Image_Classification_using_Spectral-Spatial_Mixer_Network\figure_3_page4.png
2025-11-20 23:40:14,794 - INFO - root - 已保存图片 3/10：./export\vision_transformer\images\Hyperspectral_Image_Classification_using_Spectral-Spatial_Mixer_Network\figure_3_page4.png
2025-11-20 23:40:14,837 - INFO - root - 已保存图片 4/10：./export\vision_transformer\images\Hyperspectral_Image_Classification_using_Spectral-Spatial_Mixer_Network\figure_4_page4.png
2025-11-20 23:40:14,839 - INFO - root - 成功添加图片 1：./export\vision_transformer\images\Hyperspectral_Image_Classification_using_Spectral-Spatial_Mixer_Network\figure_1_page3.png
2025-11-20 23:40:14,840 - INFO - root - 成功添加图片 2：./export\vision_transformer\images\Hyperspectral_Image_Classification_using_Spectral-Spatial_Mixer_Network\figure_2_page2.png
2025-11-20 23:40:14,841 - INFO - root - 成功添加图片 3：./export\vision_transformer\images\Hyperspectral_Image_Classification_using_Spectral-Spatial_Mixer_Network\figure_3_page4.png
2025-11-20 23:40:14,841 - INFO - root - 成功添加图片 4：./export\vision_transformer\images\Hyperspectral_Image_Classification_using_Spectral-Spatial_Mixer_Network\figure_4_page4.png
2025-11-20 23:40:14,843 - INFO - root - 论文《Hyperspectral Image Classification using Spectral-Spatial Mixer Network》的分析已保存到 ./export\vision_transformer\Hyperspectral_Image_Classification_using_Spectral-Spatial_Mixer_Network.md
2025-11-20 23:40:14,847 - INFO - root - 正在总结论文 5/40: MoDES: Accelerating Mixture-of-Experts Multimodal Large Language Models via Dynamic Expert Skipping
2025-11-20 23:40:14,875 - INFO - root - 已保存图片 4/10：./export\vision_transformer\images\Hyperspectral_Image_Classification_using_Spectral-Spatial_Mixer_Network\figure_4_page4.png
2025-11-20 23:40:14,878 - INFO - root - 成功添加图片 1：./export\vision_transformer\images\Hyperspectral_Image_Classification_using_Spectral-Spatial_Mixer_Network\figure_1_page3.png
2025-11-20 23:40:14,878 - INFO - root - 成功添加图片 2：./export\vision_transformer\images\Hyperspectral_Image_Classification_using_Spectral-Spatial_Mixer_Network\figure_2_page2.png
2025-11-20 23:40:14,879 - INFO - root - 成功添加图片 3：./export\vision_transformer\images\Hyperspectral_Image_Classification_using_Spectral-Spatial_Mixer_Network\figure_3_page4.png
2025-11-20 23:40:14,879 - INFO - root - 成功添加图片 4：./export\vision_transformer\images\Hyperspectral_Image_Classification_using_Spectral-Spatial_Mixer_Network\figure_4_page4.png
2025-11-20 23:40:14,879 - INFO - root - 输出文件已存在，跳过论文 Hyperspectral Image Classification using Spectral-Spatial Mixer Network 的处理
2025-11-20 23:40:14,881 - INFO - root - 正在总结论文 6/40: MoDES: Accelerating Mixture-of-Experts Multimodal Large Language Models via Dynamic Expert Skipping
2025-11-20 23:40:14,881 - INFO - root - LLMClient: rate limit reached, sleeping 7.2s
2025-11-20 23:40:15,687 - INFO - openai._base_client - Retrying request to /chat/completions in 0.413488 seconds
2025-11-20 23:40:28,591 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-20 23:40:28,593 - INFO - root - LLMClient: rate limit reached, sleeping 14.6s
2025-11-20 23:41:24,883 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-20 23:41:48,850 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-20 23:41:48,851 - INFO - root - 正在提取论文图片到目录: ./export\vision_transformer\images\MoDES_Accelerating_Mixture-of-Experts_Multimodal_Large_Language_Models_via_Dynamic_Expert_Skipping
2025-11-20 23:41:49,126 - INFO - root - 已保存图片 1/10：./export\vision_transformer\images\MoDES_Accelerating_Mixture-of-Experts_Multimodal_Large_Language_Models_via_Dynamic_Expert_Skipping\figure_1_page15.jpeg
2025-11-20 23:41:49,193 - INFO - root - 已保存图片 2/10：./export\vision_transformer\images\MoDES_Accelerating_Mixture-of-Experts_Multimodal_Large_Language_Models_via_Dynamic_Expert_Skipping\figure_2_page14.png
2025-11-20 23:41:49,232 - INFO - root - 已保存图片 3/10：./export\vision_transformer\images\MoDES_Accelerating_Mixture-of-Experts_Multimodal_Large_Language_Models_via_Dynamic_Expert_Skipping\figure_3_page14.png
2025-11-20 23:41:49,269 - INFO - root - 已保存图片 4/10：./export\vision_transformer\images\MoDES_Accelerating_Mixture-of-Experts_Multimodal_Large_Language_Models_via_Dynamic_Expert_Skipping\figure_4_page14.jpeg
2025-11-20 23:41:49,322 - INFO - root - 已保存图片 5/10：./export\vision_transformer\images\MoDES_Accelerating_Mixture-of-Experts_Multimodal_Large_Language_Models_via_Dynamic_Expert_Skipping\figure_5_page15.png
2025-11-20 23:41:49,355 - INFO - root - 已保存图片 6/10：./export\vision_transformer\images\MoDES_Accelerating_Mixture-of-Experts_Multimodal_Large_Language_Models_via_Dynamic_Expert_Skipping\figure_6_page15.png
2025-11-20 23:41:49,385 - INFO - root - 已保存图片 7/10：./export\vision_transformer\images\MoDES_Accelerating_Mixture-of-Experts_Multimodal_Large_Language_Models_via_Dynamic_Expert_Skipping\figure_7_page15.jpeg
2025-11-20 23:41:49,406 - INFO - root - 已保存图片 8/10：./export\vision_transformer\images\MoDES_Accelerating_Mixture-of-Experts_Multimodal_Large_Language_Models_via_Dynamic_Expert_Skipping\figure_8_page14.jpeg
2025-11-20 23:41:49,433 - INFO - root - 已保存图片 9/10：./export\vision_transformer\images\MoDES_Accelerating_Mixture-of-Experts_Multimodal_Large_Language_Models_via_Dynamic_Expert_Skipping\figure_9_page14.jpeg
2025-11-20 23:41:49,460 - INFO - root - 已保存图片 10/10：./export\vision_transformer\images\MoDES_Accelerating_Mixture-of-Experts_Multimodal_Large_Language_Models_via_Dynamic_Expert_Skipping\figure_10_page14.jpeg
2025-11-20 23:41:49,466 - INFO - root - 成功添加图片 1：./export\vision_transformer\images\MoDES_Accelerating_Mixture-of-Experts_Multimodal_Large_Language_Models_via_Dynamic_Expert_Skipping\figure_1_page15.jpeg
2025-11-20 23:41:49,466 - INFO - root - 成功添加图片 2：./export\vision_transformer\images\MoDES_Accelerating_Mixture-of-Experts_Multimodal_Large_Language_Models_via_Dynamic_Expert_Skipping\figure_2_page14.png
2025-11-20 23:41:49,466 - INFO - root - 成功添加图片 3：./export\vision_transformer\images\MoDES_Accelerating_Mixture-of-Experts_Multimodal_Large_Language_Models_via_Dynamic_Expert_Skipping\figure_3_page14.png
2025-11-20 23:41:49,468 - INFO - root - 成功添加图片 4：./export\vision_transformer\images\MoDES_Accelerating_Mixture-of-Experts_Multimodal_Large_Language_Models_via_Dynamic_Expert_Skipping\figure_4_page14.jpeg
2025-11-20 23:41:49,468 - INFO - root - 成功添加图片 5：./export\vision_transformer\images\MoDES_Accelerating_Mixture-of-Experts_Multimodal_Large_Language_Models_via_Dynamic_Expert_Skipping\figure_5_page15.png
2025-11-20 23:41:49,468 - INFO - root - 成功添加图片 6：./export\vision_transformer\images\MoDES_Accelerating_Mixture-of-Experts_Multimodal_Large_Language_Models_via_Dynamic_Expert_Skipping\figure_6_page15.png
2025-11-20 23:41:49,469 - INFO - root - 成功添加图片 7：./export\vision_transformer\images\MoDES_Accelerating_Mixture-of-Experts_Multimodal_Large_Language_Models_via_Dynamic_Expert_Skipping\figure_7_page15.jpeg
2025-11-20 23:41:49,470 - INFO - root - 成功添加图片 8：./export\vision_transformer\images\MoDES_Accelerating_Mixture-of-Experts_Multimodal_Large_Language_Models_via_Dynamic_Expert_Skipping\figure_8_page14.jpeg
2025-11-20 23:41:49,470 - INFO - root - 成功添加图片 9：./export\vision_transformer\images\MoDES_Accelerating_Mixture-of-Experts_Multimodal_Large_Language_Models_via_Dynamic_Expert_Skipping\figure_9_page14.jpeg
2025-11-20 23:41:49,471 - INFO - root - 成功添加图片 10：./export\vision_transformer\images\MoDES_Accelerating_Mixture-of-Experts_Multimodal_Large_Language_Models_via_Dynamic_Expert_Skipping\figure_10_page14.jpeg
2025-11-20 23:41:49,472 - INFO - root - 论文《MoDES: Accelerating Mixture-of-Experts Multimodal Large Language Models via Dynamic Expert Skipping》的分析已保存到 ./export\vision_transformer\MoDES_Accelerating_Mixture-of-Experts_Multimodal_Large_Language_Models_via_Dynamic_Expert_Skipping.md
2025-11-20 23:41:49,477 - INFO - root - 跳过已处理论文 GeoVista: Web-Augmented Agentic Visual Reasoning for Geolocalization：D:\ChatPaper\api_downloads\vision_transformer\GeoVista_Web-Augmented_Agentic_Visual_Reasoning_for_Geolocalization.pdf
2025-11-20 23:41:49,477 - INFO - root - 正在总结论文 7/40: RoMa v2: Harder Better Faster Denser Feature Matching
2025-11-20 23:41:52,023 - INFO - openai._base_client - Retrying request to /chat/completions in 0.406810 seconds
2025-11-20 23:42:00,521 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-20 23:42:00,522 - INFO - root - LLMClient: rate limit reached, sleeping 24.4s
2025-11-20 23:43:07,860 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-20 23:43:17,363 - INFO - root - 正在提取论文图片到目录: ./export\vision_transformer\images\MoDES_Accelerating_Mixture-of-Experts_Multimodal_Large_Language_Models_via_Dynamic_Expert_Skipping
2025-11-20 23:43:17,586 - INFO - root - 已保存图片 1/10：./export\vision_transformer\images\MoDES_Accelerating_Mixture-of-Experts_Multimodal_Large_Language_Models_via_Dynamic_Expert_Skipping\figure_1_page15.jpeg
2025-11-20 23:43:17,636 - INFO - root - 已保存图片 2/10：./export\vision_transformer\images\MoDES_Accelerating_Mixture-of-Experts_Multimodal_Large_Language_Models_via_Dynamic_Expert_Skipping\figure_2_page14.png
2025-11-20 23:43:17,681 - INFO - root - 已保存图片 3/10：./export\vision_transformer\images\MoDES_Accelerating_Mixture-of-Experts_Multimodal_Large_Language_Models_via_Dynamic_Expert_Skipping\figure_3_page14.png
2025-11-20 23:43:17,712 - INFO - root - 已保存图片 4/10：./export\vision_transformer\images\MoDES_Accelerating_Mixture-of-Experts_Multimodal_Large_Language_Models_via_Dynamic_Expert_Skipping\figure_4_page14.jpeg
2025-11-20 23:43:17,749 - INFO - root - 已保存图片 5/10：./export\vision_transformer\images\MoDES_Accelerating_Mixture-of-Experts_Multimodal_Large_Language_Models_via_Dynamic_Expert_Skipping\figure_5_page15.png
2025-11-20 23:43:17,786 - INFO - root - 已保存图片 6/10：./export\vision_transformer\images\MoDES_Accelerating_Mixture-of-Experts_Multimodal_Large_Language_Models_via_Dynamic_Expert_Skipping\figure_6_page15.png
2025-11-20 23:43:17,824 - INFO - root - 已保存图片 7/10：./export\vision_transformer\images\MoDES_Accelerating_Mixture-of-Experts_Multimodal_Large_Language_Models_via_Dynamic_Expert_Skipping\figure_7_page15.jpeg
2025-11-20 23:43:17,854 - INFO - root - 已保存图片 8/10：./export\vision_transformer\images\MoDES_Accelerating_Mixture-of-Experts_Multimodal_Large_Language_Models_via_Dynamic_Expert_Skipping\figure_8_page14.jpeg
2025-11-20 23:43:17,882 - INFO - root - 已保存图片 9/10：./export\vision_transformer\images\MoDES_Accelerating_Mixture-of-Experts_Multimodal_Large_Language_Models_via_Dynamic_Expert_Skipping\figure_9_page14.jpeg
2025-11-20 23:43:17,914 - INFO - root - 已保存图片 10/10：./export\vision_transformer\images\MoDES_Accelerating_Mixture-of-Experts_Multimodal_Large_Language_Models_via_Dynamic_Expert_Skipping\figure_10_page14.jpeg
2025-11-20 23:43:17,921 - INFO - root - 成功添加图片 1：./export\vision_transformer\images\MoDES_Accelerating_Mixture-of-Experts_Multimodal_Large_Language_Models_via_Dynamic_Expert_Skipping\figure_1_page15.jpeg
2025-11-20 23:43:17,922 - INFO - root - 成功添加图片 2：./export\vision_transformer\images\MoDES_Accelerating_Mixture-of-Experts_Multimodal_Large_Language_Models_via_Dynamic_Expert_Skipping\figure_2_page14.png
2025-11-20 23:43:17,922 - INFO - root - 成功添加图片 3：./export\vision_transformer\images\MoDES_Accelerating_Mixture-of-Experts_Multimodal_Large_Language_Models_via_Dynamic_Expert_Skipping\figure_3_page14.png
2025-11-20 23:43:17,923 - INFO - root - 成功添加图片 4：./export\vision_transformer\images\MoDES_Accelerating_Mixture-of-Experts_Multimodal_Large_Language_Models_via_Dynamic_Expert_Skipping\figure_4_page14.jpeg
2025-11-20 23:43:17,927 - INFO - root - 成功添加图片 5：./export\vision_transformer\images\MoDES_Accelerating_Mixture-of-Experts_Multimodal_Large_Language_Models_via_Dynamic_Expert_Skipping\figure_5_page15.png
2025-11-20 23:43:17,930 - INFO - root - 成功添加图片 6：./export\vision_transformer\images\MoDES_Accelerating_Mixture-of-Experts_Multimodal_Large_Language_Models_via_Dynamic_Expert_Skipping\figure_6_page15.png
2025-11-20 23:43:17,931 - INFO - root - 成功添加图片 7：./export\vision_transformer\images\MoDES_Accelerating_Mixture-of-Experts_Multimodal_Large_Language_Models_via_Dynamic_Expert_Skipping\figure_7_page15.jpeg
2025-11-20 23:43:17,932 - INFO - root - 成功添加图片 8：./export\vision_transformer\images\MoDES_Accelerating_Mixture-of-Experts_Multimodal_Large_Language_Models_via_Dynamic_Expert_Skipping\figure_8_page14.jpeg
2025-11-20 23:43:17,932 - INFO - root - 成功添加图片 9：./export\vision_transformer\images\MoDES_Accelerating_Mixture-of-Experts_Multimodal_Large_Language_Models_via_Dynamic_Expert_Skipping\figure_9_page14.jpeg
2025-11-20 23:43:17,933 - INFO - root - 成功添加图片 10：./export\vision_transformer\images\MoDES_Accelerating_Mixture-of-Experts_Multimodal_Large_Language_Models_via_Dynamic_Expert_Skipping\figure_10_page14.jpeg
2025-11-20 23:43:17,938 - INFO - root - 输出文件已存在，跳过论文 MoDES: Accelerating Mixture-of-Experts Multimodal Large Language Models via Dynamic Expert Skipping 的处理
2025-11-20 23:43:17,939 - INFO - root - 正在总结论文 7/40: MF-GCN: A Multi-Frequency Graph Convolutional Network for Tri-Modal Depression Detection Using Eye-Tracking, Facial, and Acoustic Features
2025-11-20 23:43:17,939 - INFO - root - LLMClient: rate limit reached, sleeping 4.3s
2025-11-20 23:43:33,847 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-20 23:43:33,847 - INFO - root - 正在提取论文图片到目录: ./export\vision_transformer\images\RoMa_v2_Harder_Better_Faster_Denser_Feature_Matching
2025-11-20 23:43:34,319 - INFO - root - 已保存图片 1/10：./export\vision_transformer\images\RoMa_v2_Harder_Better_Faster_Denser_Feature_Matching\figure_1_page2.jpeg
2025-11-20 23:43:34,487 - INFO - root - 已保存图片 2/10：./export\vision_transformer\images\RoMa_v2_Harder_Better_Faster_Denser_Feature_Matching\figure_2_page2.jpeg
2025-11-20 23:43:34,688 - INFO - root - 已保存图片 3/10：./export\vision_transformer\images\RoMa_v2_Harder_Better_Faster_Denser_Feature_Matching\figure_3_page2.jpeg
2025-11-20 23:43:34,883 - INFO - root - LLMClient: rate limit reached, sleeping 18.0s
2025-11-20 23:43:34,887 - INFO - root - 已保存图片 4/10：./export\vision_transformer\images\RoMa_v2_Harder_Better_Faster_Denser_Feature_Matching\figure_4_page2.jpeg
2025-11-20 23:43:35,087 - INFO - root - 已保存图片 5/10：./export\vision_transformer\images\RoMa_v2_Harder_Better_Faster_Denser_Feature_Matching\figure_5_page2.jpeg
2025-11-20 23:43:35,261 - INFO - root - 已保存图片 6/10：./export\vision_transformer\images\RoMa_v2_Harder_Better_Faster_Denser_Feature_Matching\figure_6_page2.jpeg
2025-11-20 23:43:35,443 - INFO - root - 已保存图片 7/10：./export\vision_transformer\images\RoMa_v2_Harder_Better_Faster_Denser_Feature_Matching\figure_7_page2.jpeg
2025-11-20 23:43:35,623 - INFO - root - 已保存图片 8/10：./export\vision_transformer\images\RoMa_v2_Harder_Better_Faster_Denser_Feature_Matching\figure_8_page2.jpeg
2025-11-20 23:43:35,822 - INFO - root - 已保存图片 9/10：./export\vision_transformer\images\RoMa_v2_Harder_Better_Faster_Denser_Feature_Matching\figure_9_page6.jpeg
2025-11-20 23:43:36,012 - INFO - root - 已保存图片 10/10：./export\vision_transformer\images\RoMa_v2_Harder_Better_Faster_Denser_Feature_Matching\figure_10_page6.jpeg
2025-11-20 23:43:36,043 - INFO - root - 成功添加图片 1：./export\vision_transformer\images\RoMa_v2_Harder_Better_Faster_Denser_Feature_Matching\figure_1_page2.jpeg
2025-11-20 23:43:36,043 - INFO - root - 成功添加图片 2：./export\vision_transformer\images\RoMa_v2_Harder_Better_Faster_Denser_Feature_Matching\figure_2_page2.jpeg
2025-11-20 23:43:36,045 - INFO - root - 成功添加图片 3：./export\vision_transformer\images\RoMa_v2_Harder_Better_Faster_Denser_Feature_Matching\figure_3_page2.jpeg
2025-11-20 23:43:36,045 - INFO - root - 成功添加图片 4：./export\vision_transformer\images\RoMa_v2_Harder_Better_Faster_Denser_Feature_Matching\figure_4_page2.jpeg
2025-11-20 23:43:36,045 - INFO - root - 成功添加图片 5：./export\vision_transformer\images\RoMa_v2_Harder_Better_Faster_Denser_Feature_Matching\figure_5_page2.jpeg
2025-11-20 23:43:36,045 - INFO - root - 成功添加图片 6：./export\vision_transformer\images\RoMa_v2_Harder_Better_Faster_Denser_Feature_Matching\figure_6_page2.jpeg
2025-11-20 23:43:36,045 - INFO - root - 成功添加图片 7：./export\vision_transformer\images\RoMa_v2_Harder_Better_Faster_Denser_Feature_Matching\figure_7_page2.jpeg
2025-11-20 23:43:36,045 - INFO - root - 成功添加图片 8：./export\vision_transformer\images\RoMa_v2_Harder_Better_Faster_Denser_Feature_Matching\figure_8_page2.jpeg
2025-11-20 23:43:36,045 - INFO - root - 成功添加图片 9：./export\vision_transformer\images\RoMa_v2_Harder_Better_Faster_Denser_Feature_Matching\figure_9_page6.jpeg
2025-11-20 23:43:36,045 - INFO - root - 成功添加图片 10：./export\vision_transformer\images\RoMa_v2_Harder_Better_Faster_Denser_Feature_Matching\figure_10_page6.jpeg
2025-11-20 23:43:36,049 - INFO - root - 论文《RoMa v2: Harder Better Faster Denser Feature Matching》的分析已保存到 ./export\vision_transformer\RoMa_v2_Harder_Better_Faster_Denser_Feature_Matching.md
2025-11-20 23:43:36,060 - INFO - root - 正在总结论文 8/40: Efficient quantum state preparation of multivariate functions using tensor networks
2025-11-20 23:43:44,179 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-20 23:43:44,179 - INFO - root - LLMClient: rate limit reached, sleeping 23.7s
2025-11-20 23:44:44,562 - INFO - openai._base_client - Retrying request to /chat/completions in 0.434583 seconds
2025-11-20 23:44:47,173 - INFO - openai._base_client - Retrying request to /chat/completions in 0.865700 seconds
2025-11-20 23:44:50,075 - ERROR - root - DeepSeekClient: generation error: Connection error.
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpx\_transports\default.py", line 101, in map_httpcore_exceptions
    yield
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpx\_transports\default.py", line 250, in handle_request
    resp = self._pool.handle_request(req)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpcore\_sync\connection_pool.py", line 256, in handle_request
    raise exc from None
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpcore\_sync\connection_pool.py", line 236, in handle_request
    response = connection.handle_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpcore\_sync\http_proxy.py", line 288, in handle_request
    connect_response = self._connection.handle_request(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpcore\_sync\connection.py", line 101, in handle_request
    raise exc
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpcore\_sync\connection.py", line 78, in handle_request
    stream = self._connect(request)
             ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpcore\_sync\connection.py", line 124, in _connect
    stream = self._network_backend.connect_tcp(**kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpcore\_backends\sync.py", line 207, in connect_tcp
    with map_exceptions(exc_map):
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(value)
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpcore\_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ConnectError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\openai\_base_client.py", line 982, in request
    response = self._client.send(
               ^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpx\_client.py", line 914, in send
    response = self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpx\_client.py", line 942, in _send_handling_auth
    response = self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpx\_client.py", line 979, in _send_handling_redirects
    response = self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpx\_client.py", line 1014, in _send_single_request
    response = transport.handle_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpx\_transports\default.py", line 249, in handle_request
    with map_httpcore_exceptions():
         ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(value)
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpx\_transports\default.py", line 118, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "D:\ChatPaper\llm_client_merged.py", line 296, in generate
    completion = self.client.chat.completions.create(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\openai\_utils\_utils.py", line 286, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\openai\resources\chat\completions\completions.py", line 1156, in create
    return self._post(
           ^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\openai\_base_client.py", line 1259, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\openai\_base_client.py", line 1014, in request
    raise APIConnectionError(request=request) from err
openai.APIConnectionError: Connection error.
2025-11-20 23:44:50,103 - WARNING - root - DeepSeekClient: 网络连接问题 检测到，等待 60 秒后重试
2025-11-20 23:45:50,104 - INFO - root - DeepSeekClient: retry attempt 2 for generation
2025-11-20 23:46:36,838 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-20 23:47:03,849 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-20 23:47:03,849 - INFO - root - 正在提取论文图片到目录: ./export\vision_transformer\images\Efficient_quantum_state_preparation_of_multivariate_functions_using_tensor_networks
2025-11-20 23:47:03,903 - INFO - root - 论文《Efficient quantum state preparation of multivariate functions using tensor networks》的分析已保存到 ./export\vision_transformer\Efficient_quantum_state_preparation_of_multivariate_functions_using_tensor_networks.md
2025-11-20 23:47:03,916 - INFO - root - 正在总结论文 9/40: Quantum-Guided Test Case Minimization for LLM-Based Code Generation
2025-11-20 23:47:17,316 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-20 23:47:17,319 - INFO - root - LLMClient: rate limit reached, sleeping 19.5s
2025-11-20 23:47:54,862 - INFO - openai._base_client - Retrying request to /chat/completions in 0.402936 seconds
2025-11-20 23:47:57,297 - INFO - openai._base_client - Retrying request to /chat/completions in 0.869714 seconds
2025-11-20 23:48:00,181 - ERROR - root - DeepSeekClient: generation error: Connection error.
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpx\_transports\default.py", line 101, in map_httpcore_exceptions
    yield
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpx\_transports\default.py", line 250, in handle_request
    resp = self._pool.handle_request(req)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpcore\_sync\connection_pool.py", line 256, in handle_request
    raise exc from None
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpcore\_sync\connection_pool.py", line 236, in handle_request
    response = connection.handle_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpcore\_sync\http_proxy.py", line 288, in handle_request
    connect_response = self._connection.handle_request(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpcore\_sync\connection.py", line 101, in handle_request
    raise exc
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpcore\_sync\connection.py", line 78, in handle_request
    stream = self._connect(request)
             ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpcore\_sync\connection.py", line 124, in _connect
    stream = self._network_backend.connect_tcp(**kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpcore\_backends\sync.py", line 207, in connect_tcp
    with map_exceptions(exc_map):
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(value)
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpcore\_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ConnectError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\openai\_base_client.py", line 982, in request
    response = self._client.send(
               ^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpx\_client.py", line 914, in send
    response = self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpx\_client.py", line 942, in _send_handling_auth
    response = self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpx\_client.py", line 979, in _send_handling_redirects
    response = self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpx\_client.py", line 1014, in _send_single_request
    response = transport.handle_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpx\_transports\default.py", line 249, in handle_request
    with map_httpcore_exceptions():
         ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(value)
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpx\_transports\default.py", line 118, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "D:\ChatPaper\llm_client_merged.py", line 296, in generate
    completion = self.client.chat.completions.create(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\openai\_utils\_utils.py", line 286, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\openai\resources\chat\completions\completions.py", line 1156, in create
    return self._post(
           ^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\openai\_base_client.py", line 1259, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\openai\_base_client.py", line 1014, in request
    raise APIConnectionError(request=request) from err
openai.APIConnectionError: Connection error.
2025-11-20 23:48:00,185 - WARNING - root - DeepSeekClient: 网络连接问题 检测到，等待 60 秒后重试
2025-11-20 23:49:00,192 - INFO - root - DeepSeekClient: retry attempt 2 for generation
2025-11-20 23:49:02,217 - INFO - openai._base_client - Retrying request to /chat/completions in 0.427795 seconds
2025-11-20 23:49:04,679 - INFO - openai._base_client - Retrying request to /chat/completions in 0.990074 seconds
2025-11-20 23:49:07,699 - ERROR - root - DeepSeekClient: generation error: Connection error.
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpx\_transports\default.py", line 101, in map_httpcore_exceptions
    yield
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpx\_transports\default.py", line 250, in handle_request
    resp = self._pool.handle_request(req)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpcore\_sync\connection_pool.py", line 256, in handle_request
    raise exc from None
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpcore\_sync\connection_pool.py", line 236, in handle_request
    response = connection.handle_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpcore\_sync\http_proxy.py", line 288, in handle_request
    connect_response = self._connection.handle_request(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpcore\_sync\connection.py", line 101, in handle_request
    raise exc
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpcore\_sync\connection.py", line 78, in handle_request
    stream = self._connect(request)
             ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpcore\_sync\connection.py", line 124, in _connect
    stream = self._network_backend.connect_tcp(**kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpcore\_backends\sync.py", line 207, in connect_tcp
    with map_exceptions(exc_map):
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(value)
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpcore\_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ConnectError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\openai\_base_client.py", line 982, in request
    response = self._client.send(
               ^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpx\_client.py", line 914, in send
    response = self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpx\_client.py", line 942, in _send_handling_auth
    response = self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpx\_client.py", line 979, in _send_handling_redirects
    response = self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpx\_client.py", line 1014, in _send_single_request
    response = transport.handle_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpx\_transports\default.py", line 249, in handle_request
    with map_httpcore_exceptions():
         ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(value)
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpx\_transports\default.py", line 118, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "D:\ChatPaper\llm_client_merged.py", line 296, in generate
    completion = self.client.chat.completions.create(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\openai\_utils\_utils.py", line 286, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\openai\resources\chat\completions\completions.py", line 1156, in create
    return self._post(
           ^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\openai\_base_client.py", line 1259, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\openai\_base_client.py", line 1014, in request
    raise APIConnectionError(request=request) from err
openai.APIConnectionError: Connection error.
2025-11-20 23:49:07,705 - WARNING - root - DeepSeekClient: 网络连接问题 检测到，等待 60 秒后重试
2025-11-20 23:50:07,708 - INFO - root - DeepSeekClient: retry attempt 3 for generation
2025-11-20 23:50:09,761 - INFO - openai._base_client - Retrying request to /chat/completions in 0.467889 seconds
2025-11-20 23:50:12,268 - INFO - openai._base_client - Retrying request to /chat/completions in 0.976799 seconds
2025-11-20 23:50:15,286 - ERROR - root - DeepSeekClient: generation error: Connection error.
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpx\_transports\default.py", line 101, in map_httpcore_exceptions
    yield
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpx\_transports\default.py", line 250, in handle_request
    resp = self._pool.handle_request(req)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpcore\_sync\connection_pool.py", line 256, in handle_request
    raise exc from None
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpcore\_sync\connection_pool.py", line 236, in handle_request
    response = connection.handle_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpcore\_sync\http_proxy.py", line 288, in handle_request
    connect_response = self._connection.handle_request(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpcore\_sync\connection.py", line 101, in handle_request
    raise exc
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpcore\_sync\connection.py", line 78, in handle_request
    stream = self._connect(request)
             ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpcore\_sync\connection.py", line 124, in _connect
    stream = self._network_backend.connect_tcp(**kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpcore\_backends\sync.py", line 207, in connect_tcp
    with map_exceptions(exc_map):
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(value)
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpcore\_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ConnectError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\openai\_base_client.py", line 982, in request
    response = self._client.send(
               ^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpx\_client.py", line 914, in send
    response = self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpx\_client.py", line 942, in _send_handling_auth
    response = self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpx\_client.py", line 979, in _send_handling_redirects
    response = self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpx\_client.py", line 1014, in _send_single_request
    response = transport.handle_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpx\_transports\default.py", line 249, in handle_request
    with map_httpcore_exceptions():
         ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(value)
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpx\_transports\default.py", line 118, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "D:\ChatPaper\llm_client_merged.py", line 296, in generate
    completion = self.client.chat.completions.create(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\openai\_utils\_utils.py", line 286, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\openai\resources\chat\completions\completions.py", line 1156, in create
    return self._post(
           ^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\openai\_base_client.py", line 1259, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\openai\_base_client.py", line 1014, in request
    raise APIConnectionError(request=request) from err
openai.APIConnectionError: Connection error.
2025-11-20 23:50:15,316 - ERROR - root - DeepSeekClient: 最终失败 - 抱歉，DeepSeek生成内容时遇到问题：Connection error.
2025-11-20 23:50:17,366 - INFO - openai._base_client - Retrying request to /chat/completions in 0.484224 seconds
2025-11-20 23:50:19,906 - INFO - openai._base_client - Retrying request to /chat/completions in 0.937088 seconds
2025-11-20 23:50:22,895 - ERROR - root - DeepSeekClient: generation error: Connection error.
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpx\_transports\default.py", line 101, in map_httpcore_exceptions
    yield
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpx\_transports\default.py", line 250, in handle_request
    resp = self._pool.handle_request(req)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpcore\_sync\connection_pool.py", line 256, in handle_request
    raise exc from None
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpcore\_sync\connection_pool.py", line 236, in handle_request
    response = connection.handle_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpcore\_sync\http_proxy.py", line 288, in handle_request
    connect_response = self._connection.handle_request(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpcore\_sync\connection.py", line 101, in handle_request
    raise exc
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpcore\_sync\connection.py", line 78, in handle_request
    stream = self._connect(request)
             ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpcore\_sync\connection.py", line 124, in _connect
    stream = self._network_backend.connect_tcp(**kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpcore\_backends\sync.py", line 207, in connect_tcp
    with map_exceptions(exc_map):
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(value)
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpcore\_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ConnectError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\openai\_base_client.py", line 982, in request
    response = self._client.send(
               ^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpx\_client.py", line 914, in send
    response = self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpx\_client.py", line 942, in _send_handling_auth
    response = self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpx\_client.py", line 979, in _send_handling_redirects
    response = self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpx\_client.py", line 1014, in _send_single_request
    response = transport.handle_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpx\_transports\default.py", line 249, in handle_request
    with map_httpcore_exceptions():
         ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(value)
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpx\_transports\default.py", line 118, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "D:\ChatPaper\llm_client_merged.py", line 296, in generate
    completion = self.client.chat.completions.create(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\openai\_utils\_utils.py", line 286, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\openai\resources\chat\completions\completions.py", line 1156, in create
    return self._post(
           ^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\openai\_base_client.py", line 1259, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\openai\_base_client.py", line 1014, in request
    raise APIConnectionError(request=request) from err
openai.APIConnectionError: Connection error.
2025-11-20 23:50:22,902 - WARNING - root - DeepSeekClient: 网络连接问题 检测到，等待 60 秒后重试
2025-11-20 23:51:22,908 - INFO - root - DeepSeekClient: retry attempt 2 for generation
2025-11-20 23:51:59,440 - INFO - openai._base_client - Retrying request to /chat/completions in 0.420875 seconds
2025-11-20 23:52:36,226 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-20 23:52:36,228 - INFO - root - 正在提取论文图片到目录: ./export\vision_transformer\images\Quantum-Guided_Test_Case_Minimization_for_LLM-Based_Code_Generation
2025-11-20 23:52:36,342 - INFO - root - 已保存图片 1/10：./export\vision_transformer\images\Quantum-Guided_Test_Case_Minimization_for_LLM-Based_Code_Generation\figure_1_page2.png
2025-11-20 23:52:36,343 - INFO - root - 成功添加图片 1：./export\vision_transformer\images\Quantum-Guided_Test_Case_Minimization_for_LLM-Based_Code_Generation\figure_1_page2.png
2025-11-20 23:52:36,345 - INFO - root - 论文《Quantum-Guided Test Case Minimization for LLM-Based Code Generation》的分析已保存到 ./export\vision_transformer\Quantum-Guided_Test_Case_Minimization_for_LLM-Based_Code_Generation.md
2025-11-20 23:52:36,349 - INFO - root - 正在总结论文 10/40: VisPlay: Self-Evolving Vision-Language Models from Images
2025-11-20 23:52:48,804 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-20 23:53:11,109 - INFO - openai._base_client - Retrying request to /chat/completions in 0.483888 seconds
2025-11-20 23:54:04,785 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-20 23:54:21,042 - ERROR - root - GeminiClient: generation error: Timeout of 600.0s exceeded, last exception: 503 failed to connect to all addresses; last error: UNKNOWN: ipv4:142.250.217.74:443: tcp handshaker shutdown
Traceback (most recent call last):
  File "D:\ChatPaper\.venv\Lib\site-packages\google\api_core\grpc_helpers.py", line 75, in error_remapped_callable
    return callable_(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\grpc\_interceptor.py", line 276, in __call__
    response, ignored_call = self._with_call(
                             ^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\grpc\_interceptor.py", line 331, in _with_call
    return call.result(), call
           ^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\grpc\_channel.py", line 438, in result
    raise self
  File "D:\ChatPaper\.venv\Lib\site-packages\grpc\_interceptor.py", line 314, in continuation
    response, call = self._thunk(new_method).with_call(
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\grpc\_channel.py", line 1180, in with_call
    return _end_unary_response_blocking(state, call, True, None)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\grpc\_channel.py", line 996, in _end_unary_response_blocking
    raise _InactiveRpcError(state)  # pytype: disable=not-instantiable
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
grpc._channel._InactiveRpcError: <_InactiveRpcError of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "failed to connect to all addresses; last error: UNKNOWN: ipv4:142.250.217.74:443: tcp handshaker shutdown"
	debug_error_string = "UNKNOWN:Error received from peer  {grpc_message:"failed to connect to all addresses; last error: UNKNOWN: ipv4:142.250.217.74:443: tcp handshaker shutdown", grpc_status:14}"
>

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "D:\ChatPaper\.venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 147, in retry_target
    result = target()
             ^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\google\api_core\timeout.py", line 130, in func_with_timeout
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\google\api_core\grpc_helpers.py", line 77, in error_remapped_callable
    raise exceptions.from_grpc_error(exc) from exc
google.api_core.exceptions.ServiceUnavailable: 503 failed to connect to all addresses; last error: UNKNOWN: ipv4:142.250.217.74:443: tcp handshaker shutdown

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "D:\ChatPaper\llm_client_merged.py", line 141, in generate
    resp = self.model.generate_content(prompt, safety_settings=self.safety_settings)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\google\generativeai\generative_models.py", line 331, in generate_content
    response = self._client.generate_content(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\google\ai\generativelanguage_v1beta\services\generative_service\client.py", line 835, in generate_content
    response = rpc(
               ^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\google\api_core\gapic_v1\method.py", line 131, in __call__
    return wrapped_func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 294, in retry_wrapped_func
    return retry_target(
           ^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 156, in retry_target
    next_sleep = _retry_error_helper(
                 ^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\google\api_core\retry\retry_base.py", line 229, in _retry_error_helper
    raise final_exc from source_exc
google.api_core.exceptions.RetryError: Timeout of 600.0s exceeded, last exception: 503 failed to connect to all addresses; last error: UNKNOWN: ipv4:142.250.217.74:443: tcp handshaker shutdown
2025-11-20 23:54:21,295 - WARNING - root - GeminiClient: 网络连接问题 检测到，等待 60 秒后重试
2025-11-20 23:54:46,793 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-20 23:54:46,795 - INFO - root - 正在提取论文图片到目录: ./export\vision_transformer\images\VisPlay_Self-Evolving_Vision-Language_Models_from_Images
2025-11-20 23:54:48,336 - INFO - root - 已保存图片 1/10：./export\vision_transformer\images\VisPlay_Self-Evolving_Vision-Language_Models_from_Images\figure_1_page3.png
2025-11-20 23:54:48,428 - INFO - root - 已保存图片 2/10：./export\vision_transformer\images\VisPlay_Self-Evolving_Vision-Language_Models_from_Images\figure_2_page6.png
2025-11-20 23:54:48,515 - INFO - root - 已保存图片 3/10：./export\vision_transformer\images\VisPlay_Self-Evolving_Vision-Language_Models_from_Images\figure_3_page6.png
2025-11-20 23:54:48,607 - INFO - root - 已保存图片 4/10：./export\vision_transformer\images\VisPlay_Self-Evolving_Vision-Language_Models_from_Images\figure_4_page6.png
2025-11-20 23:54:48,708 - INFO - root - 已保存图片 5/10：./export\vision_transformer\images\VisPlay_Self-Evolving_Vision-Language_Models_from_Images\figure_5_page1.png
2025-11-20 23:54:48,832 - INFO - root - 已保存图片 6/10：./export\vision_transformer\images\VisPlay_Self-Evolving_Vision-Language_Models_from_Images\figure_6_page12.png
2025-11-20 23:54:48,918 - INFO - root - 已保存图片 7/10：./export\vision_transformer\images\VisPlay_Self-Evolving_Vision-Language_Models_from_Images\figure_7_page7.png
2025-11-20 23:54:48,992 - INFO - root - 已保存图片 8/10：./export\vision_transformer\images\VisPlay_Self-Evolving_Vision-Language_Models_from_Images\figure_8_page5.png
2025-11-20 23:54:49,086 - INFO - root - 已保存图片 9/10：./export\vision_transformer\images\VisPlay_Self-Evolving_Vision-Language_Models_from_Images\figure_9_page7.png
2025-11-20 23:54:49,097 - INFO - root - 成功添加图片 1：./export\vision_transformer\images\VisPlay_Self-Evolving_Vision-Language_Models_from_Images\figure_1_page3.png
2025-11-20 23:54:49,097 - INFO - root - 成功添加图片 2：./export\vision_transformer\images\VisPlay_Self-Evolving_Vision-Language_Models_from_Images\figure_2_page6.png
2025-11-20 23:54:49,097 - INFO - root - 成功添加图片 3：./export\vision_transformer\images\VisPlay_Self-Evolving_Vision-Language_Models_from_Images\figure_3_page6.png
2025-11-20 23:54:49,097 - INFO - root - 成功添加图片 4：./export\vision_transformer\images\VisPlay_Self-Evolving_Vision-Language_Models_from_Images\figure_4_page6.png
2025-11-20 23:54:49,097 - INFO - root - 成功添加图片 5：./export\vision_transformer\images\VisPlay_Self-Evolving_Vision-Language_Models_from_Images\figure_5_page1.png
2025-11-20 23:54:49,097 - INFO - root - 成功添加图片 6：./export\vision_transformer\images\VisPlay_Self-Evolving_Vision-Language_Models_from_Images\figure_6_page12.png
2025-11-20 23:54:49,097 - INFO - root - 成功添加图片 7：./export\vision_transformer\images\VisPlay_Self-Evolving_Vision-Language_Models_from_Images\figure_7_page7.png
2025-11-20 23:54:49,097 - INFO - root - 成功添加图片 8：./export\vision_transformer\images\VisPlay_Self-Evolving_Vision-Language_Models_from_Images\figure_8_page5.png
2025-11-20 23:54:49,097 - INFO - root - 成功添加图片 9：./export\vision_transformer\images\VisPlay_Self-Evolving_Vision-Language_Models_from_Images\figure_9_page7.png
2025-11-20 23:54:49,103 - INFO - root - 论文《VisPlay: Self-Evolving Vision-Language Models from Images》的分析已保存到 ./export\vision_transformer\VisPlay_Self-Evolving_Vision-Language_Models_from_Images.md
2025-11-20 23:54:49,115 - INFO - root - 正在总结论文 11/40: Walrus: A Cross-Domain Foundation Model for Continuum Dynamics
2025-11-20 23:55:04,304 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-20 23:55:04,308 - INFO - root - LLMClient: rate limit reached, sleeping 0.5s
2025-11-20 23:55:21,308 - INFO - root - GeminiClient: retry attempt 2 for generation
2025-11-20 23:56:10,409 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-20 23:56:45,086 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-20 23:56:45,092 - INFO - root - 正在提取论文图片到目录: ./export\vision_transformer\images\Walrus_A_Cross-Domain_Foundation_Model_for_Continuum_Dynamics
2025-11-20 23:56:46,798 - INFO - root - 已保存图片 1/10：./export\vision_transformer\images\Walrus_A_Cross-Domain_Foundation_Model_for_Continuum_Dynamics\figure_1_page8.jpeg
2025-11-20 23:56:47,128 - INFO - root - 已保存图片 2/10：./export\vision_transformer\images\Walrus_A_Cross-Domain_Foundation_Model_for_Continuum_Dynamics\figure_2_page8.png
2025-11-20 23:56:47,308 - INFO - root - 已保存图片 3/10：./export\vision_transformer\images\Walrus_A_Cross-Domain_Foundation_Model_for_Continuum_Dynamics\figure_3_page8.jpeg
2025-11-20 23:56:47,425 - INFO - root - 已保存图片 4/10：./export\vision_transformer\images\Walrus_A_Cross-Domain_Foundation_Model_for_Continuum_Dynamics\figure_4_page8.jpeg
2025-11-20 23:56:47,515 - INFO - root - 已保存图片 5/10：./export\vision_transformer\images\Walrus_A_Cross-Domain_Foundation_Model_for_Continuum_Dynamics\figure_5_page6.jpeg
2025-11-20 23:56:47,611 - INFO - root - 已保存图片 6/10：./export\vision_transformer\images\Walrus_A_Cross-Domain_Foundation_Model_for_Continuum_Dynamics\figure_6_page6.jpeg
2025-11-20 23:56:47,678 - INFO - root - 已保存图片 7/10：./export\vision_transformer\images\Walrus_A_Cross-Domain_Foundation_Model_for_Continuum_Dynamics\figure_7_page6.jpeg
2025-11-20 23:56:47,726 - INFO - root - 已保存图片 8/10：./export\vision_transformer\images\Walrus_A_Cross-Domain_Foundation_Model_for_Continuum_Dynamics\figure_8_page6.jpeg
2025-11-20 23:56:47,764 - INFO - root - 已保存图片 9/10：./export\vision_transformer\images\Walrus_A_Cross-Domain_Foundation_Model_for_Continuum_Dynamics\figure_9_page5.jpeg
2025-11-20 23:56:47,806 - INFO - root - 已保存图片 10/10：./export\vision_transformer\images\Walrus_A_Cross-Domain_Foundation_Model_for_Continuum_Dynamics\figure_10_page4.jpeg
2025-11-20 23:56:47,815 - INFO - root - 成功添加图片 1：./export\vision_transformer\images\Walrus_A_Cross-Domain_Foundation_Model_for_Continuum_Dynamics\figure_1_page8.jpeg
2025-11-20 23:56:47,822 - INFO - root - 成功添加图片 2：./export\vision_transformer\images\Walrus_A_Cross-Domain_Foundation_Model_for_Continuum_Dynamics\figure_2_page8.png
2025-11-20 23:56:47,822 - INFO - root - 成功添加图片 3：./export\vision_transformer\images\Walrus_A_Cross-Domain_Foundation_Model_for_Continuum_Dynamics\figure_3_page8.jpeg
2025-11-20 23:56:47,823 - INFO - root - 成功添加图片 4：./export\vision_transformer\images\Walrus_A_Cross-Domain_Foundation_Model_for_Continuum_Dynamics\figure_4_page8.jpeg
2025-11-20 23:56:47,823 - INFO - root - 成功添加图片 5：./export\vision_transformer\images\Walrus_A_Cross-Domain_Foundation_Model_for_Continuum_Dynamics\figure_5_page6.jpeg
2025-11-20 23:56:47,823 - INFO - root - 成功添加图片 6：./export\vision_transformer\images\Walrus_A_Cross-Domain_Foundation_Model_for_Continuum_Dynamics\figure_6_page6.jpeg
2025-11-20 23:56:47,825 - INFO - root - 成功添加图片 7：./export\vision_transformer\images\Walrus_A_Cross-Domain_Foundation_Model_for_Continuum_Dynamics\figure_7_page6.jpeg
2025-11-20 23:56:47,825 - INFO - root - 成功添加图片 8：./export\vision_transformer\images\Walrus_A_Cross-Domain_Foundation_Model_for_Continuum_Dynamics\figure_8_page6.jpeg
2025-11-20 23:56:47,825 - INFO - root - 成功添加图片 9：./export\vision_transformer\images\Walrus_A_Cross-Domain_Foundation_Model_for_Continuum_Dynamics\figure_9_page5.jpeg
2025-11-20 23:56:47,826 - INFO - root - 成功添加图片 10：./export\vision_transformer\images\Walrus_A_Cross-Domain_Foundation_Model_for_Continuum_Dynamics\figure_10_page4.jpeg
2025-11-20 23:56:47,828 - INFO - root - 论文《Walrus: A Cross-Domain Foundation Model for Continuum Dynamics》的分析已保存到 ./export\vision_transformer\Walrus_A_Cross-Domain_Foundation_Model_for_Continuum_Dynamics.md
2025-11-20 23:56:47,833 - INFO - root - 正在总结论文 12/40: MF-GCN: A Multi-Frequency Graph Convolutional Network for Tri-Modal Depression Detection Using Eye-Tracking, Facial, and Acoustic Features
2025-11-20 23:57:00,089 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-20 23:57:00,092 - INFO - root - LLMClient: rate limit reached, sleeping 10.3s
2025-11-20 23:57:55,854 - INFO - openai._base_client - Retrying request to /chat/completions in 0.398462 seconds
2025-11-20 23:57:58,283 - INFO - openai._base_client - Retrying request to /chat/completions in 0.839132 seconds
2025-11-20 23:58:01,156 - ERROR - root - DeepSeekClient: generation error: Connection error.
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpx\_transports\default.py", line 101, in map_httpcore_exceptions
    yield
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpx\_transports\default.py", line 250, in handle_request
    resp = self._pool.handle_request(req)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpcore\_sync\connection_pool.py", line 256, in handle_request
    raise exc from None
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpcore\_sync\connection_pool.py", line 236, in handle_request
    response = connection.handle_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpcore\_sync\http_proxy.py", line 288, in handle_request
    connect_response = self._connection.handle_request(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpcore\_sync\connection.py", line 101, in handle_request
    raise exc
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpcore\_sync\connection.py", line 78, in handle_request
    stream = self._connect(request)
             ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpcore\_sync\connection.py", line 124, in _connect
    stream = self._network_backend.connect_tcp(**kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpcore\_backends\sync.py", line 207, in connect_tcp
    with map_exceptions(exc_map):
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(value)
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpcore\_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ConnectError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\openai\_base_client.py", line 982, in request
    response = self._client.send(
               ^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpx\_client.py", line 914, in send
    response = self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpx\_client.py", line 942, in _send_handling_auth
    response = self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpx\_client.py", line 979, in _send_handling_redirects
    response = self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpx\_client.py", line 1014, in _send_single_request
    response = transport.handle_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpx\_transports\default.py", line 249, in handle_request
    with map_httpcore_exceptions():
         ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(value)
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpx\_transports\default.py", line 118, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "D:\ChatPaper\llm_client_merged.py", line 296, in generate
    completion = self.client.chat.completions.create(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\openai\_utils\_utils.py", line 286, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\openai\resources\chat\completions\completions.py", line 1156, in create
    return self._post(
           ^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\openai\_base_client.py", line 1259, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\openai\_base_client.py", line 1014, in request
    raise APIConnectionError(request=request) from err
openai.APIConnectionError: Connection error.
2025-11-20 23:58:01,172 - WARNING - root - DeepSeekClient: 网络连接问题 检测到，等待 60 秒后重试
2025-11-20 23:59:01,176 - INFO - root - DeepSeekClient: retry attempt 2 for generation
2025-11-20 23:59:03,206 - INFO - openai._base_client - Retrying request to /chat/completions in 0.393221 seconds
2025-11-20 23:59:05,640 - INFO - openai._base_client - Retrying request to /chat/completions in 0.764533 seconds
2025-11-20 23:59:08,447 - ERROR - root - DeepSeekClient: generation error: Connection error.
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpx\_transports\default.py", line 101, in map_httpcore_exceptions
    yield
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpx\_transports\default.py", line 250, in handle_request
    resp = self._pool.handle_request(req)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpcore\_sync\connection_pool.py", line 256, in handle_request
    raise exc from None
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpcore\_sync\connection_pool.py", line 236, in handle_request
    response = connection.handle_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpcore\_sync\http_proxy.py", line 288, in handle_request
    connect_response = self._connection.handle_request(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpcore\_sync\connection.py", line 101, in handle_request
    raise exc
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpcore\_sync\connection.py", line 78, in handle_request
    stream = self._connect(request)
             ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpcore\_sync\connection.py", line 124, in _connect
    stream = self._network_backend.connect_tcp(**kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpcore\_backends\sync.py", line 207, in connect_tcp
    with map_exceptions(exc_map):
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(value)
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpcore\_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ConnectError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\openai\_base_client.py", line 982, in request
    response = self._client.send(
               ^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpx\_client.py", line 914, in send
    response = self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpx\_client.py", line 942, in _send_handling_auth
    response = self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpx\_client.py", line 979, in _send_handling_redirects
    response = self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpx\_client.py", line 1014, in _send_single_request
    response = transport.handle_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpx\_transports\default.py", line 249, in handle_request
    with map_httpcore_exceptions():
         ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(value)
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpx\_transports\default.py", line 118, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "D:\ChatPaper\llm_client_merged.py", line 296, in generate
    completion = self.client.chat.completions.create(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\openai\_utils\_utils.py", line 286, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\openai\resources\chat\completions\completions.py", line 1156, in create
    return self._post(
           ^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\openai\_base_client.py", line 1259, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\openai\_base_client.py", line 1014, in request
    raise APIConnectionError(request=request) from err
openai.APIConnectionError: Connection error.
2025-11-20 23:59:08,454 - WARNING - root - DeepSeekClient: 网络连接问题 检测到，等待 60 秒后重试
2025-11-21 00:00:08,455 - INFO - root - DeepSeekClient: retry attempt 3 for generation
2025-11-21 00:00:10,480 - INFO - openai._base_client - Retrying request to /chat/completions in 0.455028 seconds
2025-11-21 00:00:12,958 - INFO - openai._base_client - Retrying request to /chat/completions in 0.980061 seconds
2025-11-21 00:00:15,945 - ERROR - root - DeepSeekClient: generation error: Connection error.
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpx\_transports\default.py", line 101, in map_httpcore_exceptions
    yield
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpx\_transports\default.py", line 250, in handle_request
    resp = self._pool.handle_request(req)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpcore\_sync\connection_pool.py", line 256, in handle_request
    raise exc from None
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpcore\_sync\connection_pool.py", line 236, in handle_request
    response = connection.handle_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpcore\_sync\http_proxy.py", line 288, in handle_request
    connect_response = self._connection.handle_request(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpcore\_sync\connection.py", line 101, in handle_request
    raise exc
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpcore\_sync\connection.py", line 78, in handle_request
    stream = self._connect(request)
             ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpcore\_sync\connection.py", line 124, in _connect
    stream = self._network_backend.connect_tcp(**kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpcore\_backends\sync.py", line 207, in connect_tcp
    with map_exceptions(exc_map):
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(value)
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpcore\_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ConnectError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\openai\_base_client.py", line 982, in request
    response = self._client.send(
               ^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpx\_client.py", line 914, in send
    response = self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpx\_client.py", line 942, in _send_handling_auth
    response = self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpx\_client.py", line 979, in _send_handling_redirects
    response = self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpx\_client.py", line 1014, in _send_single_request
    response = transport.handle_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpx\_transports\default.py", line 249, in handle_request
    with map_httpcore_exceptions():
         ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(value)
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpx\_transports\default.py", line 118, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "D:\ChatPaper\llm_client_merged.py", line 296, in generate
    completion = self.client.chat.completions.create(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\openai\_utils\_utils.py", line 286, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\openai\resources\chat\completions\completions.py", line 1156, in create
    return self._post(
           ^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\openai\_base_client.py", line 1259, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\openai\_base_client.py", line 1014, in request
    raise APIConnectionError(request=request) from err
openai.APIConnectionError: Connection error.
2025-11-21 00:00:15,955 - ERROR - root - DeepSeekClient: 最终失败 - 抱歉，DeepSeek生成内容时遇到问题：Connection error.
2025-11-21 00:00:17,979 - INFO - openai._base_client - Retrying request to /chat/completions in 0.401229 seconds
2025-11-21 00:00:20,415 - INFO - openai._base_client - Retrying request to /chat/completions in 0.859636 seconds
2025-11-21 00:00:23,311 - ERROR - root - DeepSeekClient: generation error: Connection error.
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpx\_transports\default.py", line 101, in map_httpcore_exceptions
    yield
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpx\_transports\default.py", line 250, in handle_request
    resp = self._pool.handle_request(req)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpcore\_sync\connection_pool.py", line 256, in handle_request
    raise exc from None
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpcore\_sync\connection_pool.py", line 236, in handle_request
    response = connection.handle_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpcore\_sync\http_proxy.py", line 288, in handle_request
    connect_response = self._connection.handle_request(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpcore\_sync\connection.py", line 101, in handle_request
    raise exc
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpcore\_sync\connection.py", line 78, in handle_request
    stream = self._connect(request)
             ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpcore\_sync\connection.py", line 124, in _connect
    stream = self._network_backend.connect_tcp(**kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpcore\_backends\sync.py", line 207, in connect_tcp
    with map_exceptions(exc_map):
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(value)
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpcore\_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ConnectError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\openai\_base_client.py", line 982, in request
    response = self._client.send(
               ^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpx\_client.py", line 914, in send
    response = self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpx\_client.py", line 942, in _send_handling_auth
    response = self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpx\_client.py", line 979, in _send_handling_redirects
    response = self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpx\_client.py", line 1014, in _send_single_request
    response = transport.handle_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpx\_transports\default.py", line 249, in handle_request
    with map_httpcore_exceptions():
         ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(value)
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpx\_transports\default.py", line 118, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "D:\ChatPaper\llm_client_merged.py", line 296, in generate
    completion = self.client.chat.completions.create(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\openai\_utils\_utils.py", line 286, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\openai\resources\chat\completions\completions.py", line 1156, in create
    return self._post(
           ^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\openai\_base_client.py", line 1259, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\openai\_base_client.py", line 1014, in request
    raise APIConnectionError(request=request) from err
openai.APIConnectionError: Connection error.
2025-11-21 00:00:23,315 - WARNING - root - DeepSeekClient: 网络连接问题 检测到，等待 60 秒后重试
2025-11-21 00:01:23,317 - INFO - root - DeepSeekClient: retry attempt 2 for generation
2025-11-21 00:01:25,330 - INFO - openai._base_client - Retrying request to /chat/completions in 0.400181 seconds
2025-11-21 00:01:27,763 - INFO - openai._base_client - Retrying request to /chat/completions in 0.934984 seconds
2025-11-21 00:01:30,734 - ERROR - root - DeepSeekClient: generation error: Connection error.
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpx\_transports\default.py", line 101, in map_httpcore_exceptions
    yield
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpx\_transports\default.py", line 250, in handle_request
    resp = self._pool.handle_request(req)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpcore\_sync\connection_pool.py", line 256, in handle_request
    raise exc from None
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpcore\_sync\connection_pool.py", line 236, in handle_request
    response = connection.handle_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpcore\_sync\http_proxy.py", line 288, in handle_request
    connect_response = self._connection.handle_request(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpcore\_sync\connection.py", line 101, in handle_request
    raise exc
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpcore\_sync\connection.py", line 78, in handle_request
    stream = self._connect(request)
             ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpcore\_sync\connection.py", line 124, in _connect
    stream = self._network_backend.connect_tcp(**kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpcore\_backends\sync.py", line 207, in connect_tcp
    with map_exceptions(exc_map):
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(value)
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpcore\_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ConnectError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\openai\_base_client.py", line 982, in request
    response = self._client.send(
               ^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpx\_client.py", line 914, in send
    response = self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpx\_client.py", line 942, in _send_handling_auth
    response = self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpx\_client.py", line 979, in _send_handling_redirects
    response = self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpx\_client.py", line 1014, in _send_single_request
    response = transport.handle_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpx\_transports\default.py", line 249, in handle_request
    with map_httpcore_exceptions():
         ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(value)
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpx\_transports\default.py", line 118, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "D:\ChatPaper\llm_client_merged.py", line 296, in generate
    completion = self.client.chat.completions.create(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\openai\_utils\_utils.py", line 286, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\openai\resources\chat\completions\completions.py", line 1156, in create
    return self._post(
           ^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\openai\_base_client.py", line 1259, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\openai\_base_client.py", line 1014, in request
    raise APIConnectionError(request=request) from err
openai.APIConnectionError: Connection error.
2025-11-21 00:01:30,736 - WARNING - root - DeepSeekClient: 网络连接问题 检测到，等待 60 秒后重试
2025-11-21 00:02:30,739 - INFO - root - DeepSeekClient: retry attempt 3 for generation
2025-11-21 00:02:32,785 - INFO - openai._base_client - Retrying request to /chat/completions in 0.462766 seconds
2025-11-21 00:02:35,282 - INFO - openai._base_client - Retrying request to /chat/completions in 0.824864 seconds
2025-11-21 00:02:38,136 - ERROR - root - DeepSeekClient: generation error: Connection error.
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpx\_transports\default.py", line 101, in map_httpcore_exceptions
    yield
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpx\_transports\default.py", line 250, in handle_request
    resp = self._pool.handle_request(req)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpcore\_sync\connection_pool.py", line 256, in handle_request
    raise exc from None
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpcore\_sync\connection_pool.py", line 236, in handle_request
    response = connection.handle_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpcore\_sync\http_proxy.py", line 288, in handle_request
    connect_response = self._connection.handle_request(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpcore\_sync\connection.py", line 101, in handle_request
    raise exc
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpcore\_sync\connection.py", line 78, in handle_request
    stream = self._connect(request)
             ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpcore\_sync\connection.py", line 124, in _connect
    stream = self._network_backend.connect_tcp(**kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpcore\_backends\sync.py", line 207, in connect_tcp
    with map_exceptions(exc_map):
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(value)
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpcore\_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ConnectError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\openai\_base_client.py", line 982, in request
    response = self._client.send(
               ^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpx\_client.py", line 914, in send
    response = self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpx\_client.py", line 942, in _send_handling_auth
    response = self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpx\_client.py", line 979, in _send_handling_redirects
    response = self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpx\_client.py", line 1014, in _send_single_request
    response = transport.handle_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpx\_transports\default.py", line 249, in handle_request
    with map_httpcore_exceptions():
         ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(value)
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpx\_transports\default.py", line 118, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "D:\ChatPaper\llm_client_merged.py", line 296, in generate
    completion = self.client.chat.completions.create(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\openai\_utils\_utils.py", line 286, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\openai\resources\chat\completions\completions.py", line 1156, in create
    return self._post(
           ^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\openai\_base_client.py", line 1259, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\openai\_base_client.py", line 1014, in request
    raise APIConnectionError(request=request) from err
openai.APIConnectionError: Connection error.
2025-11-21 00:02:38,142 - ERROR - root - DeepSeekClient: 最终失败 - 抱歉，DeepSeek生成内容时遇到问题：Connection error.
2025-11-21 00:02:38,144 - INFO - root - 正在提取论文图片到目录: ./export\vision_transformer\images\MF-GCN_A_Multi-Frequency_Graph_Convolutional_Network_for_Tri-Modal_Depression_Detection_Using_Eye-T
2025-11-21 00:02:43,011 - INFO - root - 已保存图片 1/10：./export\vision_transformer\images\MF-GCN_A_Multi-Frequency_Graph_Convolutional_Network_for_Tri-Modal_Depression_Detection_Using_Eye-T\figure_1_page12.png
2025-11-21 00:02:43,228 - INFO - root - 已保存图片 2/10：./export\vision_transformer\images\MF-GCN_A_Multi-Frequency_Graph_Convolutional_Network_for_Tri-Modal_Depression_Detection_Using_Eye-T\figure_2_page21.png
2025-11-21 00:02:43,368 - INFO - root - 已保存图片 3/10：./export\vision_transformer\images\MF-GCN_A_Multi-Frequency_Graph_Convolutional_Network_for_Tri-Modal_Depression_Detection_Using_Eye-T\figure_3_page21.png
2025-11-21 00:02:43,511 - INFO - root - 已保存图片 4/10：./export\vision_transformer\images\MF-GCN_A_Multi-Frequency_Graph_Convolutional_Network_for_Tri-Modal_Depression_Detection_Using_Eye-T\figure_4_page21.png
2025-11-21 00:02:43,677 - INFO - root - 已保存图片 5/10：./export\vision_transformer\images\MF-GCN_A_Multi-Frequency_Graph_Convolutional_Network_for_Tri-Modal_Depression_Detection_Using_Eye-T\figure_5_page12.png
2025-11-21 00:02:43,752 - INFO - root - 已保存图片 6/10：./export\vision_transformer\images\MF-GCN_A_Multi-Frequency_Graph_Convolutional_Network_for_Tri-Modal_Depression_Detection_Using_Eye-T\figure_6_page15.png
2025-11-21 00:02:43,865 - INFO - root - 已保存图片 7/10：./export\vision_transformer\images\MF-GCN_A_Multi-Frequency_Graph_Convolutional_Network_for_Tri-Modal_Depression_Detection_Using_Eye-T\figure_7_page15.png
2025-11-21 00:02:43,898 - INFO - root - 已保存图片 8/10：./export\vision_transformer\images\MF-GCN_A_Multi-Frequency_Graph_Convolutional_Network_for_Tri-Modal_Depression_Detection_Using_Eye-T\figure_8_page12.jpeg
2025-11-21 00:02:43,921 - INFO - root - 已保存图片 9/10：./export\vision_transformer\images\MF-GCN_A_Multi-Frequency_Graph_Convolutional_Network_for_Tri-Modal_Depression_Detection_Using_Eye-T\figure_9_page12.jpeg
2025-11-21 00:02:43,978 - INFO - root - 已保存图片 10/10：./export\vision_transformer\images\MF-GCN_A_Multi-Frequency_Graph_Convolutional_Network_for_Tri-Modal_Depression_Detection_Using_Eye-T\figure_10_page12.jpeg
2025-11-21 00:02:44,020 - INFO - root - 成功添加图片 1：./export\vision_transformer\images\MF-GCN_A_Multi-Frequency_Graph_Convolutional_Network_for_Tri-Modal_Depression_Detection_Using_Eye-T\figure_1_page12.png
2025-11-21 00:02:44,020 - INFO - root - 成功添加图片 2：./export\vision_transformer\images\MF-GCN_A_Multi-Frequency_Graph_Convolutional_Network_for_Tri-Modal_Depression_Detection_Using_Eye-T\figure_2_page21.png
2025-11-21 00:02:44,021 - INFO - root - 成功添加图片 3：./export\vision_transformer\images\MF-GCN_A_Multi-Frequency_Graph_Convolutional_Network_for_Tri-Modal_Depression_Detection_Using_Eye-T\figure_3_page21.png
2025-11-21 00:02:44,021 - INFO - root - 成功添加图片 4：./export\vision_transformer\images\MF-GCN_A_Multi-Frequency_Graph_Convolutional_Network_for_Tri-Modal_Depression_Detection_Using_Eye-T\figure_4_page21.png
2025-11-21 00:02:44,021 - INFO - root - 成功添加图片 5：./export\vision_transformer\images\MF-GCN_A_Multi-Frequency_Graph_Convolutional_Network_for_Tri-Modal_Depression_Detection_Using_Eye-T\figure_5_page12.png
2025-11-21 00:02:44,021 - INFO - root - 成功添加图片 6：./export\vision_transformer\images\MF-GCN_A_Multi-Frequency_Graph_Convolutional_Network_for_Tri-Modal_Depression_Detection_Using_Eye-T\figure_6_page15.png
2025-11-21 00:02:44,022 - INFO - root - 成功添加图片 7：./export\vision_transformer\images\MF-GCN_A_Multi-Frequency_Graph_Convolutional_Network_for_Tri-Modal_Depression_Detection_Using_Eye-T\figure_7_page15.png
2025-11-21 00:02:44,022 - INFO - root - 成功添加图片 8：./export\vision_transformer\images\MF-GCN_A_Multi-Frequency_Graph_Convolutional_Network_for_Tri-Modal_Depression_Detection_Using_Eye-T\figure_8_page12.jpeg
2025-11-21 00:02:44,028 - INFO - root - 成功添加图片 9：./export\vision_transformer\images\MF-GCN_A_Multi-Frequency_Graph_Convolutional_Network_for_Tri-Modal_Depression_Detection_Using_Eye-T\figure_9_page12.jpeg
2025-11-21 00:02:44,032 - INFO - root - 成功添加图片 10：./export\vision_transformer\images\MF-GCN_A_Multi-Frequency_Graph_Convolutional_Network_for_Tri-Modal_Depression_Detection_Using_Eye-T\figure_10_page12.jpeg
2025-11-21 00:02:44,035 - INFO - root - 论文《MF-GCN: A Multi-Frequency Graph Convolutional Network for Tri-Modal Depression Detection Using Eye-Tracking, Facial, and Acoustic Features》的分析已保存到 ./export\vision_transformer\MF-GCN_A_Multi-Frequency_Graph_Convolutional_Network_for_Tri-Modal_Depression_Detection_Using_Eye-T.md
2025-11-21 00:02:44,050 - INFO - root - 正在总结论文 13/40: In-N-On: Scaling Egocentric Manipulation with in-the-wild and on-task Data
2025-11-21 00:02:46,096 - INFO - openai._base_client - Retrying request to /chat/completions in 0.445702 seconds
2025-11-21 00:02:48,580 - INFO - openai._base_client - Retrying request to /chat/completions in 0.910406 seconds
2025-11-21 00:02:51,501 - ERROR - root - DeepSeekClient: generation error: Connection error.
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpx\_transports\default.py", line 101, in map_httpcore_exceptions
    yield
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpx\_transports\default.py", line 250, in handle_request
    resp = self._pool.handle_request(req)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpcore\_sync\connection_pool.py", line 256, in handle_request
    raise exc from None
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpcore\_sync\connection_pool.py", line 236, in handle_request
    response = connection.handle_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpcore\_sync\http_proxy.py", line 288, in handle_request
    connect_response = self._connection.handle_request(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpcore\_sync\connection.py", line 101, in handle_request
    raise exc
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpcore\_sync\connection.py", line 78, in handle_request
    stream = self._connect(request)
             ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpcore\_sync\connection.py", line 124, in _connect
    stream = self._network_backend.connect_tcp(**kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpcore\_backends\sync.py", line 207, in connect_tcp
    with map_exceptions(exc_map):
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(value)
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpcore\_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ConnectError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\openai\_base_client.py", line 982, in request
    response = self._client.send(
               ^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpx\_client.py", line 914, in send
    response = self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpx\_client.py", line 942, in _send_handling_auth
    response = self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpx\_client.py", line 979, in _send_handling_redirects
    response = self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpx\_client.py", line 1014, in _send_single_request
    response = transport.handle_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpx\_transports\default.py", line 249, in handle_request
    with map_httpcore_exceptions():
         ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(value)
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpx\_transports\default.py", line 118, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "D:\ChatPaper\llm_client_merged.py", line 296, in generate
    completion = self.client.chat.completions.create(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\openai\_utils\_utils.py", line 286, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\openai\resources\chat\completions\completions.py", line 1156, in create
    return self._post(
           ^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\openai\_base_client.py", line 1259, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\openai\_base_client.py", line 1014, in request
    raise APIConnectionError(request=request) from err
openai.APIConnectionError: Connection error.
2025-11-21 00:02:51,507 - WARNING - root - DeepSeekClient: 网络连接问题 检测到，等待 60 秒后重试
2025-11-21 00:03:51,854 - INFO - root - DeepSeekClient: retry attempt 2 for generation
2025-11-21 00:03:54,005 - INFO - openai._base_client - Retrying request to /chat/completions in 0.391808 seconds
2025-11-21 00:03:57,134 - INFO - openai._base_client - Retrying request to /chat/completions in 0.895017 seconds
2025-11-21 00:04:00,058 - ERROR - root - DeepSeekClient: generation error: Connection error.
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpx\_transports\default.py", line 101, in map_httpcore_exceptions
    yield
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpx\_transports\default.py", line 250, in handle_request
    resp = self._pool.handle_request(req)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpcore\_sync\connection_pool.py", line 256, in handle_request
    raise exc from None
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpcore\_sync\connection_pool.py", line 236, in handle_request
    response = connection.handle_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpcore\_sync\http_proxy.py", line 288, in handle_request
    connect_response = self._connection.handle_request(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpcore\_sync\connection.py", line 101, in handle_request
    raise exc
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpcore\_sync\connection.py", line 78, in handle_request
    stream = self._connect(request)
             ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpcore\_sync\connection.py", line 124, in _connect
    stream = self._network_backend.connect_tcp(**kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpcore\_backends\sync.py", line 207, in connect_tcp
    with map_exceptions(exc_map):
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(value)
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpcore\_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ConnectError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\openai\_base_client.py", line 982, in request
    response = self._client.send(
               ^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpx\_client.py", line 914, in send
    response = self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpx\_client.py", line 942, in _send_handling_auth
    response = self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpx\_client.py", line 979, in _send_handling_redirects
    response = self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpx\_client.py", line 1014, in _send_single_request
    response = transport.handle_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpx\_transports\default.py", line 249, in handle_request
    with map_httpcore_exceptions():
         ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(value)
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpx\_transports\default.py", line 118, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "D:\ChatPaper\llm_client_merged.py", line 296, in generate
    completion = self.client.chat.completions.create(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\openai\_utils\_utils.py", line 286, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\openai\resources\chat\completions\completions.py", line 1156, in create
    return self._post(
           ^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\openai\_base_client.py", line 1259, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\site-packages\openai\_base_client.py", line 1014, in request
    raise APIConnectionError(request=request) from err
openai.APIConnectionError: Connection error.
2025-11-21 00:04:00,065 - WARNING - root - DeepSeekClient: 网络连接问题 检测到，等待 60 秒后重试
2025-11-21 00:31:50,881 - WARNING - root - Google Scholar 检索器依赖未能加载: No module named 'selenium'。 'scholar' 策略将不可用。
2025-11-21 00:31:50,885 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-21 00:31:50,887 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-21 00:31:50,889 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-21 00:32:00,483 - INFO - root - LLMClientManager: 指定使用客户端: Gemini
2025-11-21 00:33:00,004 - ERROR - root - GeminiClient: error during initialization: Timeout of 60.0s exceeded, last exception: 503 failed to connect to all addresses; last error: UNKNOWN: ipv4:142.251.34.202:443: socket is null
2025-11-21 00:33:00,008 - ERROR - root - LLMClientManager: 指定的客户端 Gemini 初始化失败
2025-11-21 00:33:00,010 - WARNING - root - LLMClientManager: 指定的客户端 Gemini 不可用，将尝试其他客户端
2025-11-21 00:33:00,010 - INFO - root - DeepSeekClient: API key found: 9f9e270e-b...
2025-11-21 00:33:00,021 - INFO - root - DeepSeekClient: 使用模式: 火山引擎
2025-11-21 00:33:00,023 - INFO - root - DeepSeekClient: 模型名称: ep-20251112215738-bz78g
2025-11-21 00:33:07,174 - INFO - openai._base_client - Retrying request to /chat/completions in 0.436600 seconds
2025-11-21 00:33:12,622 - INFO - openai._base_client - Retrying request to /chat/completions in 0.935902 seconds
2025-11-21 00:33:18,583 - ERROR - root - DeepSeekClient: error during initialization: Request timed out.
2025-11-21 00:33:18,588 - WARNING - root - LLMClientManager: DeepSeek client initialization failed
2025-11-21 00:33:18,589 - WARNING - root - KimiClient: API key not provided. LLM disabled.
2025-11-21 00:33:18,591 - WARNING - root - LLMClientManager: Kimi client initialization failed
2025-11-21 00:33:18,591 - WARNING - root - QwenClient: API key not provided. LLM disabled.
2025-11-21 00:33:18,592 - WARNING - root - LLMClientManager: Qwen client initialization failed
2025-11-21 00:33:18,592 - INFO - root - DoubaoClient: API key found: 9f9e270e-b...
2025-11-21 00:33:25,134 - INFO - openai._base_client - Retrying request to /chat/completions in 0.434271 seconds
2025-11-21 00:33:30,583 - INFO - openai._base_client - Retrying request to /chat/completions in 0.998138 seconds
2025-11-21 00:33:36,595 - ERROR - root - DoubaoClient: error during initialization: Request timed out.
2025-11-21 00:33:36,595 - WARNING - root - LLMClientManager: Doubao client initialization failed
2025-11-21 00:33:36,596 - WARNING - root - LLMClientManager: no LLM client available
2025-11-21 00:33:36,596 - WARNING - root - LLMClientManager: client Gemini not available. Available clients: []
2025-11-21 00:33:36,598 - WARNING - root - 无法切换到指定的客户端 Gemini，将使用默认客户端
2025-11-21 00:33:36,598 - INFO - root - 可用客户端: []
2025-11-21 00:33:36,598 - INFO - root - LLM 未初始化或不可用，后续生成将返回备用消息
2025-11-21 00:33:36,604 - INFO - root - === 运行配置 ===
2025-11-21 00:33:36,605 - INFO - root - 处理模式: arXiv 最新搜索 (API)
2025-11-21 00:33:36,605 - INFO - root - 查询: vision transformer
2025-11-21 00:33:36,606 - INFO - root - 关键词 (用于保存): vision transformer
2025-11-21 00:33:36,606 - INFO - root - 排序: SubmittedDate
2025-11-21 00:33:36,608 - INFO - root - 最近天数: 180
2025-11-21 00:33:36,608 - INFO - root - 最大处理数量: 40
2025-11-21 00:33:36,609 - INFO - root - 保存图片: 是
2025-11-21 00:33:36,615 - INFO - root - 输出语言: 中文
2025-11-21 00:33:36,617 - INFO - root - 强制重新处理: 否
2025-11-21 00:33:36,620 - INFO - root - LLM 客户端: Gemini
2025-11-21 00:33:36,621 - INFO - root - ====================
2025-11-21 00:33:36,621 - INFO - root - 正在使用检索策略: arxiv
2025-11-21 00:33:36,622 - INFO - root - 使用 arXiv 搜索模式 (API + 并发)
2025-11-21 00:33:36,622 - INFO - root - 正在使用 arXiv API 搜索: query='vision transformer', sort_by=SubmittedDate
2025-11-21 00:33:36,622 - INFO - arxiv - Requesting page (first: True, try: 0): https://export.arxiv.org/api/query?search_query=vision+transformer&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=50
2025-11-21 00:33:40,038 - INFO - arxiv - Got first page: 50 of 314974 total results
2025-11-21 00:33:40,041 - INFO - root - API 返回了 50 篇论文
2025-11-21 00:33:40,046 - INFO - root - 开始按 180 天过滤 (检查 50 篇论文)...
2025-11-21 00:33:40,047 - INFO - root - 经过 'days=180' 过滤后，剩余 50 篇论文。
2025-11-21 00:33:40,048 - INFO - root - 将开始并发下载 40 篇论文...
2025-11-21 00:33:40,050 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\vision_transformer\Resolving_Ratio_Redundancy_in_Chemical_Freeze-out_Studies_with_Principal_Component_Analysis_and_Baye.pdf
2025-11-21 00:33:40,051 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\vision_transformer\RoMa_v2_Harder_Better_Faster_Denser_Feature_Matching.pdf
2025-11-21 00:33:40,054 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\vision_transformer\GeoVista_Web-Augmented_Agentic_Visual_Reasoning_for_Geolocalization.pdf
2025-11-21 00:33:40,055 - INFO - root - 成功创建 Paper 对象: 2511.15707v1
2025-11-21 00:33:40,055 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\vision_transformer\In-N-On_Scaling_Egocentric_Manipulation_with_in-the-wild_and_on-task_Data.pdf
2025-11-21 00:33:40,057 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\vision_transformer\Think_Visually,_Reason_Textually_Vision-Language_Synergy_in_ARC.pdf
2025-11-21 00:33:40,057 - INFO - root - 成功创建 Paper 对象: 2511.15706v1
2025-11-21 00:33:40,057 - INFO - root - 成功创建 Paper 对象: 2511.15705v1
2025-11-21 00:33:40,057 - INFO - root - 下载进度: 1/40
2025-11-21 00:33:40,057 - INFO - root - 成功创建 Paper 对象: 2511.15704v1
2025-11-21 00:33:40,059 - INFO - root - 成功创建 Paper 对象: 2511.15703v1
2025-11-21 00:33:40,059 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\vision_transformer\First_Frame_Is_the_Place_to_Go_for_Video_Content_Customization.pdf
2025-11-21 00:33:40,061 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\vision_transformer\Hyperspectral_Image_Classification_using_Spectral-Spatial_Mixer_Network.pdf
2025-11-21 00:33:40,062 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\vision_transformer\Joint_Semantic-Channel_Coding_and_Modulation_for_Token_Communications.pdf
2025-11-21 00:33:40,063 - INFO - root - 下载进度: 2/40
2025-11-21 00:33:40,066 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\vision_transformer\MoDES_Accelerating_Mixture-of-Experts_Multimodal_Large_Language_Models_via_Dynamic_Expert_Skipping.pdf
2025-11-21 00:33:40,067 - INFO - root - 成功创建 Paper 对象: 2511.15700v1
2025-11-21 00:33:40,067 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\vision_transformer\Walrus_A_Cross-Domain_Foundation_Model_for_Continuum_Dynamics.pdf
2025-11-21 00:33:40,073 - INFO - root - 成功创建 Paper 对象: 2511.15692v1
2025-11-21 00:33:40,077 - INFO - root - 成功创建 Paper 对象: 2511.15699v1
2025-11-21 00:33:40,078 - INFO - root - 下载进度: 3/40
2025-11-21 00:33:40,079 - INFO - root - 成功创建 Paper 对象: 2511.15690v1
2025-11-21 00:33:40,080 - INFO - root - 成功创建 Paper 对象: 2511.15684v1
2025-11-21 00:33:40,081 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\vision_transformer\MF-GCN_A_Multi-Frequency_Graph_Convolutional_Network_for_Tri-Modal_Depression_Detection_Using_Eye-T.pdf
2025-11-21 00:33:40,081 - INFO - root - 下载进度: 4/40
2025-11-21 00:33:40,081 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\vision_transformer\Efficient_quantum_state_preparation_of_multivariate_functions_using_tensor_networks.pdf
2025-11-21 00:33:40,082 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\vision_transformer\Quantum-Guided_Test_Case_Minimization_for_LLM-Based_Code_Generation.pdf
2025-11-21 00:33:40,083 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\vision_transformer\VisPlay_Self-Evolving_Vision-Language_Models_from_Images.pdf
2025-11-21 00:33:40,083 - INFO - root - 成功创建 Paper 对象: 2511.15675v1
2025-11-21 00:33:40,083 - INFO - root - 下载进度: 5/40
2025-11-21 00:33:40,084 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\vision_transformer\GEO-Bench-2_From_Performance_to_Capability,_Rethinking_Evaluation_in_Geospatial_AI.pdf
2025-11-21 00:33:40,084 - INFO - root - 成功创建 Paper 对象: 2511.15674v1
2025-11-21 00:33:40,088 - INFO - root - 成功创建 Paper 对象: 2511.15665v1
2025-11-21 00:33:40,089 - INFO - root - 成功创建 Paper 对象: 2511.15661v1
2025-11-21 00:33:40,090 - INFO - root - 下载进度: 6/40
2025-11-21 00:33:40,091 - INFO - root - 成功创建 Paper 对象: 2511.15658v1
2025-11-21 00:33:40,091 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\vision_transformer\INQUIRE-Search_A_Framework_for_Interactive_Discovery_in_Large-Scale_Biodiversity_Databases.pdf
2025-11-21 00:33:40,093 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\vision_transformer\MambaIO_Global-Coordinate_Inertial_Odometry_for_Pedestrians_via_Multi-Scale_Frequency-Decoupled_Mod.pdf
2025-11-21 00:33:40,093 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\vision_transformer\A_Millennium_of_UK_Business_Cycles_Insights_from_Structural_VAR_Analysis.pdf
2025-11-21 00:33:40,093 - INFO - root - 下载进度: 7/40
2025-11-21 00:33:40,094 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\vision_transformer\Navigating_Quantum_Missteps_in_Agent-Based_Modeling_A_Schelling_Model_Case_Study.pdf
2025-11-21 00:33:40,096 - INFO - root - 成功创建 Paper 对象: 2511.15656v1
2025-11-21 00:33:40,096 - INFO - root - 正在下载: https://arxiv.org/pdf/2511.15640v1
2025-11-21 00:33:40,097 - INFO - root - 成功创建 Paper 对象: 2511.15645v1
2025-11-21 00:33:40,097 - INFO - root - 成功创建 Paper 对象: 2511.15643v1
2025-11-21 00:33:40,098 - INFO - root - 下载进度: 8/40
2025-11-21 00:33:40,099 - INFO - root - 成功创建 Paper 对象: 2511.15642v1
2025-11-21 00:33:40,106 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\vision_transformer\Hierarchical_Semantic_Tree_Anchoring_for_CLIP-Based_Class-Incremental_Learning.pdf
2025-11-21 00:33:40,108 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\vision_transformer\The_SA-FARI_Dataset_Segment_Anything_in_Footage_of_Animals_for_Recognition_and_Identification.pdf
2025-11-21 00:33:40,111 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\vision_transformer\FlashMesh_Faster_and_Better_Autoregressive_Mesh_Synthesis_via_Structured_Speculation.pdf
2025-11-21 00:33:40,109 - INFO - root - 下载进度: 9/40
2025-11-21 00:33:40,112 - INFO - root - 成功创建 Paper 对象: 2511.15622v1
2025-11-21 00:33:40,111 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\vision_transformer\Optimus-Q_Utilizing_Federated_Learning_in_Adaptive_Robots_for_Intelligent_Nuclear_Power_Plant_Opera.pdf
2025-11-21 00:33:40,111 - INFO - root - 成功创建 Paper 对象: 2511.15633v1
2025-11-21 00:33:40,112 - INFO - root - 下载进度: 10/40
2025-11-21 00:33:40,113 - INFO - root - 成功创建 Paper 对象: 2511.15618v1
2025-11-21 00:33:40,115 - INFO - root - 成功创建 Paper 对象: 2511.15614v1
2025-11-21 00:33:40,115 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\vision_transformer\When_to_Think_and_When_to_Look_Uncertainty-Guided_Lookback.pdf
2025-11-21 00:33:40,116 - INFO - root - 正在下载: https://arxiv.org/pdf/2511.15605v1
2025-11-21 00:33:40,116 - INFO - root - 下载进度: 11/40
2025-11-21 00:33:40,117 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\vision_transformer\MaskMed_Decoupled_Mask_and_Class_Prediction_for_Medical_Image_Segmentation.pdf
2025-11-21 00:33:40,121 - INFO - root - 成功创建 Paper 对象: 2511.15613v1
2025-11-21 00:33:40,121 - INFO - root - 下载进度: 12/40
2025-11-21 00:33:40,121 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\vision_transformer\Endomorphism_and_automorphism_graphs_of_finite_groups.pdf
2025-11-21 00:33:40,128 - INFO - root - 成功创建 Paper 对象: 2511.15603v1
2025-11-21 00:33:40,129 - INFO - root - 下载进度: 13/40
2025-11-21 00:33:40,129 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\vision_transformer\US-X_Complete_A_Multi-Modal_Approach_to_Anatomical_3D_Shape_Recovery.pdf
2025-11-21 00:33:40,130 - INFO - root - 成功创建 Paper 对象: 2511.15602v1
2025-11-21 00:33:40,130 - INFO - root - 下载进度: 14/40
2025-11-21 00:33:40,132 - INFO - root - 下载进度: 15/40
2025-11-21 00:33:40,134 - INFO - root - 下载进度: 16/40
2025-11-21 00:33:40,131 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\vision_transformer\Learning_from_Mistakes_Loss-Aware_Memory_Enhanced_Continual_Learning_for_LiDAR_Place_Recognition.pdf
2025-11-21 00:33:40,133 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\vision_transformer\EPSO_A_Caching-Based_Efficient_Superoptimizer_for_BPF_Bytecode.pdf
2025-11-21 00:33:40,140 - INFO - root - 成功创建 Paper 对象: 2511.15589v1
2025-11-21 00:33:40,135 - INFO - root - 下载进度: 17/40
2025-11-21 00:33:40,139 - INFO - root - 成功创建 Paper 对象: 2511.15597v1
2025-11-21 00:33:40,132 - INFO - root - 成功创建 Paper 对象: 2511.15600v1
2025-11-21 00:33:40,143 - INFO - root - 下载进度: 18/40
2025-11-21 00:33:40,143 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\vision_transformer\Real-Time_Optimal_Control_via_Transformer_Networks_and_Bernstein_Polynomials.pdf
2025-11-21 00:33:40,144 - INFO - root - 下载进度: 19/40
2025-11-21 00:33:40,145 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\vision_transformer\MHR_Momentum_Human_Rig.pdf
2025-11-21 00:33:40,145 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\vision_transformer\Graph_Rewriting_Language_as_a_Platform_for_Quantum_Diagrammatic_Calculi.pdf
2025-11-21 00:33:40,146 - INFO - root - 成功创建 Paper 对象: 2511.15588v1
2025-11-21 00:33:40,146 - INFO - root - 下载进度: 20/40
2025-11-21 00:33:40,148 - INFO - root - 下载进度: 21/40
2025-11-21 00:33:40,147 - INFO - root - 成功创建 Paper 对象: 2511.15581v1
2025-11-21 00:33:40,146 - INFO - root - 成功创建 Paper 对象: 2511.15586v1
2025-11-21 00:33:40,149 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\vision_transformer\CompTrack_Information_Bottleneck-Guided_Low-Rank_Dynamic_Token_Compression_for_Point_Cloud_Tracking.pdf
2025-11-21 00:33:40,156 - INFO - root - 成功创建 Paper 对象: 2511.15580v1
2025-11-21 00:33:40,155 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\vision_transformer\A_critical_review_of_pre-post_surveys_designed_to_measure_student_epistemology_in_undergraduate_scie.pdf
2025-11-21 00:33:40,156 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\vision_transformer\AVATAAR_Agentic_Video_Answering_via_Temporal_Adaptive_Alignment_and_Reasoning.pdf
2025-11-21 00:33:40,149 - INFO - root - 下载进度: 22/40
2025-11-21 00:33:40,158 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\vision_transformer\From_Low-Rank_Features_to_Encoding_Mismatch_Rethinking_Feature_Distillation_in_Vision_Transformers.pdf
2025-11-21 00:33:40,159 - INFO - root - 成功创建 Paper 对象: 2511.15575v1
2025-11-21 00:33:40,159 - INFO - root - 成功创建 Paper 对象: 2511.15578v1
2025-11-21 00:33:40,159 - INFO - root - 下载进度: 23/40
2025-11-21 00:33:40,160 - INFO - root - 成功创建 Paper 对象: 2511.15572v1
2025-11-21 00:33:40,162 - INFO - root - 正在下载: https://arxiv.org/pdf/2511.15571v1
2025-11-21 00:33:40,163 - INFO - root - 下载进度: 24/40
2025-11-21 00:33:40,163 - INFO - root - 文件已存在, 跳过下载: D:\ChatPaper\api_downloads\vision_transformer\Integrability_of_Siegel_transforms_and_an_application.pdf
2025-11-21 00:33:40,165 - INFO - root - 下载进度: 25/40
2025-11-21 00:33:40,166 - INFO - root - 成功创建 Paper 对象: 2511.15568v1
2025-11-21 00:33:40,169 - INFO - root - 下载进度: 26/40
2025-11-21 00:33:40,173 - INFO - root - 下载进度: 27/40
2025-11-21 00:33:40,174 - INFO - root - 下载进度: 28/40
2025-11-21 00:33:40,175 - INFO - root - 下载进度: 29/40
2025-11-21 00:33:40,175 - INFO - root - 下载进度: 30/40
2025-11-21 00:33:40,176 - INFO - root - 下载进度: 31/40
2025-11-21 00:33:40,176 - INFO - root - 下载进度: 32/40
2025-11-21 00:33:40,177 - INFO - root - 下载进度: 33/40
2025-11-21 00:33:40,177 - INFO - root - 下载进度: 34/40
2025-11-21 00:33:40,178 - INFO - root - 下载进度: 35/40
2025-11-21 00:33:40,179 - INFO - root - 下载进度: 36/40
2025-11-21 00:33:40,179 - INFO - root - 下载进度: 37/40
2025-11-21 00:34:06,764 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\vision_transformer\SRPO_Self-Referential_Policy_Optimization_for_Vision-Language-Action_Models.pdf
2025-11-21 00:34:06,769 - INFO - root - 成功创建 Paper 对象: 2511.15605v1
2025-11-21 00:34:06,769 - INFO - root - 下载进度: 38/40
2025-11-21 00:34:17,585 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\vision_transformer\Transferable_Dual-Domain_Feature_Importance_Attack_against_AI-Generated_Image_Detector.pdf
2025-11-21 00:34:17,587 - INFO - root - 成功创建 Paper 对象: 2511.15571v1
2025-11-21 00:34:17,588 - INFO - root - 下载进度: 39/40
2025-11-21 00:34:18,557 - INFO - root - 已保存到: D:\ChatPaper\api_downloads\vision_transformer\Multi-Stage_Residual-Aware_Unsupervised_Deep_Learning_Framework_for_Consistent_Ultrasound_Strain_Ela.pdf
2025-11-21 00:34:18,564 - INFO - root - 成功创建 Paper 对象: 2511.15640v1
2025-11-21 00:34:18,564 - INFO - root - 下载进度: 40/40
2025-11-21 00:34:18,565 - INFO - root - 论文处理完成: 40 篇成功下载, 0 篇需手动下载。耗时 38.51 秒。
2025-11-21 00:34:18,565 - INFO - root - 检索到 40 篇论文（包括待手动下载的），开始总结...
2025-11-21 00:34:18,571 - INFO - root - --- 开始论文总结阶段 ---
2025-11-21 00:34:18,571 - INFO - root - 跳过已处理论文 Resolving Ratio Redundancy in Chemical Freeze-out Studies with Principal Component Analysis and Bayesian Calibration：D:\ChatPaper\api_downloads\vision_transformer\Resolving_Ratio_Redundancy_in_Chemical_Freeze-out_Studies_with_Principal_Component_Analysis_and_Baye.pdf
2025-11-21 00:34:18,572 - INFO - root - 跳过已处理论文 RoMa v2: Harder Better Faster Denser Feature Matching：D:\ChatPaper\api_downloads\vision_transformer\RoMa_v2_Harder_Better_Faster_Denser_Feature_Matching.pdf
2025-11-21 00:34:18,574 - INFO - root - 跳过已处理论文 GeoVista: Web-Augmented Agentic Visual Reasoning for Geolocalization：D:\ChatPaper\api_downloads\vision_transformer\GeoVista_Web-Augmented_Agentic_Visual_Reasoning_for_Geolocalization.pdf
2025-11-21 00:34:18,576 - INFO - root - 正在总结论文 4/40: In-N-On: Scaling Egocentric Manipulation with in-the-wild and on-task Data
2025-11-21 00:34:18,577 - INFO - root - 正在提取论文图片到目录: ./export\vision_transformer\images\In-N-On_Scaling_Egocentric_Manipulation_with_in-the-wild_and_on-task_Data
2025-11-21 00:34:21,041 - INFO - root - 已保存图片 1/10：./export\vision_transformer\images\In-N-On_Scaling_Egocentric_Manipulation_with_in-the-wild_and_on-task_Data\figure_1_page14.jpeg
2025-11-21 00:34:21,148 - INFO - root - 已保存图片 2/10：./export\vision_transformer\images\In-N-On_Scaling_Egocentric_Manipulation_with_in-the-wild_and_on-task_Data\figure_2_page13.jpeg
2025-11-21 00:34:21,266 - INFO - root - 已保存图片 3/10：./export\vision_transformer\images\In-N-On_Scaling_Egocentric_Manipulation_with_in-the-wild_and_on-task_Data\figure_3_page13.jpeg
2025-11-21 00:34:21,359 - INFO - root - 已保存图片 4/10：./export\vision_transformer\images\In-N-On_Scaling_Egocentric_Manipulation_with_in-the-wild_and_on-task_Data\figure_4_page4.jpeg
2025-11-21 00:34:21,454 - INFO - root - 已保存图片 5/10：./export\vision_transformer\images\In-N-On_Scaling_Egocentric_Manipulation_with_in-the-wild_and_on-task_Data\figure_5_page13.jpeg
2025-11-21 00:34:21,555 - INFO - root - 已保存图片 6/10：./export\vision_transformer\images\In-N-On_Scaling_Egocentric_Manipulation_with_in-the-wild_and_on-task_Data\figure_6_page5.png
2025-11-21 00:34:21,713 - INFO - root - 已保存图片 7/10：./export\vision_transformer\images\In-N-On_Scaling_Egocentric_Manipulation_with_in-the-wild_and_on-task_Data\figure_7_page7.png
2025-11-21 00:34:21,902 - INFO - root - 已保存图片 8/10：./export\vision_transformer\images\In-N-On_Scaling_Egocentric_Manipulation_with_in-the-wild_and_on-task_Data\figure_8_page7.png
2025-11-21 00:34:22,109 - INFO - root - 已保存图片 9/10：./export\vision_transformer\images\In-N-On_Scaling_Egocentric_Manipulation_with_in-the-wild_and_on-task_Data\figure_9_page7.png
2025-11-21 00:34:22,310 - INFO - root - 已保存图片 10/10：./export\vision_transformer\images\In-N-On_Scaling_Egocentric_Manipulation_with_in-the-wild_and_on-task_Data\figure_10_page7.png
2025-11-21 00:34:22,335 - INFO - root - 成功添加图片 1：./export\vision_transformer\images\In-N-On_Scaling_Egocentric_Manipulation_with_in-the-wild_and_on-task_Data\figure_1_page14.jpeg
2025-11-21 00:34:22,335 - INFO - root - 成功添加图片 2：./export\vision_transformer\images\In-N-On_Scaling_Egocentric_Manipulation_with_in-the-wild_and_on-task_Data\figure_2_page13.jpeg
2025-11-21 00:34:22,336 - INFO - root - 成功添加图片 3：./export\vision_transformer\images\In-N-On_Scaling_Egocentric_Manipulation_with_in-the-wild_and_on-task_Data\figure_3_page13.jpeg
2025-11-21 00:34:22,337 - INFO - root - 成功添加图片 4：./export\vision_transformer\images\In-N-On_Scaling_Egocentric_Manipulation_with_in-the-wild_and_on-task_Data\figure_4_page4.jpeg
2025-11-21 00:34:22,337 - INFO - root - 成功添加图片 5：./export\vision_transformer\images\In-N-On_Scaling_Egocentric_Manipulation_with_in-the-wild_and_on-task_Data\figure_5_page13.jpeg
2025-11-21 00:34:22,337 - INFO - root - 成功添加图片 6：./export\vision_transformer\images\In-N-On_Scaling_Egocentric_Manipulation_with_in-the-wild_and_on-task_Data\figure_6_page5.png
2025-11-21 00:34:22,338 - INFO - root - 成功添加图片 7：./export\vision_transformer\images\In-N-On_Scaling_Egocentric_Manipulation_with_in-the-wild_and_on-task_Data\figure_7_page7.png
2025-11-21 00:34:22,338 - INFO - root - 成功添加图片 8：./export\vision_transformer\images\In-N-On_Scaling_Egocentric_Manipulation_with_in-the-wild_and_on-task_Data\figure_8_page7.png
2025-11-21 00:34:22,339 - INFO - root - 成功添加图片 9：./export\vision_transformer\images\In-N-On_Scaling_Egocentric_Manipulation_with_in-the-wild_and_on-task_Data\figure_9_page7.png
2025-11-21 00:34:22,339 - INFO - root - 成功添加图片 10：./export\vision_transformer\images\In-N-On_Scaling_Egocentric_Manipulation_with_in-the-wild_and_on-task_Data\figure_10_page7.png
2025-11-21 00:34:22,341 - INFO - root - 论文《In-N-On: Scaling Egocentric Manipulation with in-the-wild and on-task Data》的分析已保存到 ./export\vision_transformer\In-N-On_Scaling_Egocentric_Manipulation_with_in-the-wild_and_on-task_Data.md
2025-11-21 00:34:22,352 - INFO - root - 跳过已处理论文 Think Visually, Reason Textually: Vision-Language Synergy in ARC：D:\ChatPaper\api_downloads\vision_transformer\Think_Visually,_Reason_Textually_Vision-Language_Synergy_in_ARC.pdf
2025-11-21 00:34:22,355 - INFO - root - 正在总结论文 6/40: First Frame Is the Place to Go for Video Content Customization
2025-11-21 00:34:22,356 - INFO - root - 正在提取论文图片到目录: ./export\vision_transformer\images\First_Frame_Is_the_Place_to_Go_for_Video_Content_Customization
2025-11-21 00:34:27,009 - INFO - root - 已保存图片 1/10：./export\vision_transformer\images\First_Frame_Is_the_Place_to_Go_for_Video_Content_Customization\figure_1_page12.png
2025-11-21 00:34:27,288 - INFO - root - 已保存图片 2/10：./export\vision_transformer\images\First_Frame_Is_the_Place_to_Go_for_Video_Content_Customization\figure_2_page14.png
2025-11-21 00:34:27,457 - INFO - root - 已保存图片 3/10：./export\vision_transformer\images\First_Frame_Is_the_Place_to_Go_for_Video_Content_Customization\figure_3_page14.png
2025-11-21 00:34:27,594 - INFO - root - 已保存图片 4/10：./export\vision_transformer\images\First_Frame_Is_the_Place_to_Go_for_Video_Content_Customization\figure_4_page3.png
2025-11-21 00:34:27,723 - INFO - root - 已保存图片 5/10：./export\vision_transformer\images\First_Frame_Is_the_Place_to_Go_for_Video_Content_Customization\figure_5_page3.png
2025-11-21 00:34:27,881 - INFO - root - 已保存图片 6/10：./export\vision_transformer\images\First_Frame_Is_the_Place_to_Go_for_Video_Content_Customization\figure_6_page3.png
2025-11-21 00:34:28,081 - INFO - root - 已保存图片 7/10：./export\vision_transformer\images\First_Frame_Is_the_Place_to_Go_for_Video_Content_Customization\figure_7_page3.png
2025-11-21 00:34:28,267 - INFO - root - 已保存图片 8/10：./export\vision_transformer\images\First_Frame_Is_the_Place_to_Go_for_Video_Content_Customization\figure_8_page3.png
2025-11-21 00:34:28,431 - INFO - root - 已保存图片 9/10：./export\vision_transformer\images\First_Frame_Is_the_Place_to_Go_for_Video_Content_Customization\figure_9_page3.png
2025-11-21 00:34:28,612 - INFO - root - 已保存图片 10/10：./export\vision_transformer\images\First_Frame_Is_the_Place_to_Go_for_Video_Content_Customization\figure_10_page3.png
2025-11-21 00:34:28,640 - INFO - root - 成功添加图片 1：./export\vision_transformer\images\First_Frame_Is_the_Place_to_Go_for_Video_Content_Customization\figure_1_page12.png
2025-11-21 00:34:28,640 - INFO - root - 成功添加图片 2：./export\vision_transformer\images\First_Frame_Is_the_Place_to_Go_for_Video_Content_Customization\figure_2_page14.png
2025-11-21 00:34:28,641 - INFO - root - 成功添加图片 3：./export\vision_transformer\images\First_Frame_Is_the_Place_to_Go_for_Video_Content_Customization\figure_3_page14.png
2025-11-21 00:34:28,641 - INFO - root - 成功添加图片 4：./export\vision_transformer\images\First_Frame_Is_the_Place_to_Go_for_Video_Content_Customization\figure_4_page3.png
2025-11-21 00:34:28,641 - INFO - root - 成功添加图片 5：./export\vision_transformer\images\First_Frame_Is_the_Place_to_Go_for_Video_Content_Customization\figure_5_page3.png
2025-11-21 00:34:28,643 - INFO - root - 成功添加图片 6：./export\vision_transformer\images\First_Frame_Is_the_Place_to_Go_for_Video_Content_Customization\figure_6_page3.png
2025-11-21 00:34:28,643 - INFO - root - 成功添加图片 7：./export\vision_transformer\images\First_Frame_Is_the_Place_to_Go_for_Video_Content_Customization\figure_7_page3.png
2025-11-21 00:34:28,643 - INFO - root - 成功添加图片 8：./export\vision_transformer\images\First_Frame_Is_the_Place_to_Go_for_Video_Content_Customization\figure_8_page3.png
2025-11-21 00:34:28,643 - INFO - root - 成功添加图片 9：./export\vision_transformer\images\First_Frame_Is_the_Place_to_Go_for_Video_Content_Customization\figure_9_page3.png
2025-11-21 00:34:28,644 - INFO - root - 成功添加图片 10：./export\vision_transformer\images\First_Frame_Is_the_Place_to_Go_for_Video_Content_Customization\figure_10_page3.png
2025-11-21 00:34:28,645 - INFO - root - 论文《First Frame Is the Place to Go for Video Content Customization》的分析已保存到 ./export\vision_transformer\First_Frame_Is_the_Place_to_Go_for_Video_Content_Customization.md
2025-11-21 00:34:28,657 - INFO - root - 跳过已处理论文 Hyperspectral Image Classification using Spectral-Spatial Mixer Network：D:\ChatPaper\api_downloads\vision_transformer\Hyperspectral_Image_Classification_using_Spectral-Spatial_Mixer_Network.pdf
2025-11-21 00:34:28,658 - INFO - root - 跳过已处理论文 Joint Semantic-Channel Coding and Modulation for Token Communications：D:\ChatPaper\api_downloads\vision_transformer\Joint_Semantic-Channel_Coding_and_Modulation_for_Token_Communications.pdf
2025-11-21 00:34:28,659 - INFO - root - 跳过已处理论文 MoDES: Accelerating Mixture-of-Experts Multimodal Large Language Models via Dynamic Expert Skipping：D:\ChatPaper\api_downloads\vision_transformer\MoDES_Accelerating_Mixture-of-Experts_Multimodal_Large_Language_Models_via_Dynamic_Expert_Skipping.pdf
2025-11-21 00:34:28,659 - INFO - root - 跳过已处理论文 Walrus: A Cross-Domain Foundation Model for Continuum Dynamics：D:\ChatPaper\api_downloads\vision_transformer\Walrus_A_Cross-Domain_Foundation_Model_for_Continuum_Dynamics.pdf
2025-11-21 00:34:28,660 - INFO - root - 跳过已处理论文 MF-GCN: A Multi-Frequency Graph Convolutional Network for Tri-Modal Depression Detection Using Eye-Tracking, Facial, and Acoustic Features：D:\ChatPaper\api_downloads\vision_transformer\MF-GCN_A_Multi-Frequency_Graph_Convolutional_Network_for_Tri-Modal_Depression_Detection_Using_Eye-T.pdf
2025-11-21 00:34:28,660 - INFO - root - 跳过已处理论文 Efficient quantum state preparation of multivariate functions using tensor networks：D:\ChatPaper\api_downloads\vision_transformer\Efficient_quantum_state_preparation_of_multivariate_functions_using_tensor_networks.pdf
2025-11-21 00:34:28,660 - INFO - root - 跳过已处理论文 Quantum-Guided Test Case Minimization for LLM-Based Code Generation：D:\ChatPaper\api_downloads\vision_transformer\Quantum-Guided_Test_Case_Minimization_for_LLM-Based_Code_Generation.pdf
2025-11-21 00:34:28,660 - INFO - root - 跳过已处理论文 VisPlay: Self-Evolving Vision-Language Models from Images：D:\ChatPaper\api_downloads\vision_transformer\VisPlay_Self-Evolving_Vision-Language_Models_from_Images.pdf
2025-11-21 00:34:28,661 - INFO - root - 正在总结论文 15/40: GEO-Bench-2: From Performance to Capability, Rethinking Evaluation in Geospatial AI
2025-11-21 00:34:28,663 - INFO - root - 正在提取论文图片到目录: ./export\vision_transformer\images\GEO-Bench-2_From_Performance_to_Capability,_Rethinking_Evaluation_in_Geospatial_AI
2025-11-21 00:34:45,757 - INFO - root - 已保存图片 1/10：./export\vision_transformer\images\GEO-Bench-2_From_Performance_to_Capability,_Rethinking_Evaluation_in_Geospatial_AI\figure_1_page19.png
2025-11-21 00:34:46,353 - INFO - root - 已保存图片 2/10：./export\vision_transformer\images\GEO-Bench-2_From_Performance_to_Capability,_Rethinking_Evaluation_in_Geospatial_AI\figure_2_page19.png
2025-11-21 00:34:46,912 - INFO - root - 已保存图片 3/10：./export\vision_transformer\images\GEO-Bench-2_From_Performance_to_Capability,_Rethinking_Evaluation_in_Geospatial_AI\figure_3_page21.png
2025-11-21 00:34:47,663 - INFO - root - 已保存图片 4/10：./export\vision_transformer\images\GEO-Bench-2_From_Performance_to_Capability,_Rethinking_Evaluation_in_Geospatial_AI\figure_4_page18.png
2025-11-21 00:34:48,297 - INFO - root - 已保存图片 5/10：./export\vision_transformer\images\GEO-Bench-2_From_Performance_to_Capability,_Rethinking_Evaluation_in_Geospatial_AI\figure_5_page23.png
2025-11-21 00:34:48,929 - INFO - root - 已保存图片 6/10：./export\vision_transformer\images\GEO-Bench-2_From_Performance_to_Capability,_Rethinking_Evaluation_in_Geospatial_AI\figure_6_page23.png
2025-11-21 00:34:49,713 - INFO - root - 已保存图片 7/10：./export\vision_transformer\images\GEO-Bench-2_From_Performance_to_Capability,_Rethinking_Evaluation_in_Geospatial_AI\figure_7_page21.png
2025-11-21 00:34:50,404 - INFO - root - 已保存图片 8/10：./export\vision_transformer\images\GEO-Bench-2_From_Performance_to_Capability,_Rethinking_Evaluation_in_Geospatial_AI\figure_8_page20.png
2025-11-21 00:34:50,855 - INFO - root - 已保存图片 9/10：./export\vision_transformer\images\GEO-Bench-2_From_Performance_to_Capability,_Rethinking_Evaluation_in_Geospatial_AI\figure_9_page7.png
2025-11-21 00:34:51,298 - INFO - root - 已保存图片 10/10：./export\vision_transformer\images\GEO-Bench-2_From_Performance_to_Capability,_Rethinking_Evaluation_in_Geospatial_AI\figure_10_page20.png
2025-11-21 00:34:51,445 - INFO - root - 成功添加图片 1：./export\vision_transformer\images\GEO-Bench-2_From_Performance_to_Capability,_Rethinking_Evaluation_in_Geospatial_AI\figure_1_page19.png
2025-11-21 00:34:51,445 - INFO - root - 成功添加图片 2：./export\vision_transformer\images\GEO-Bench-2_From_Performance_to_Capability,_Rethinking_Evaluation_in_Geospatial_AI\figure_2_page19.png
2025-11-21 00:34:51,446 - INFO - root - 成功添加图片 3：./export\vision_transformer\images\GEO-Bench-2_From_Performance_to_Capability,_Rethinking_Evaluation_in_Geospatial_AI\figure_3_page21.png
2025-11-21 00:34:51,446 - INFO - root - 成功添加图片 4：./export\vision_transformer\images\GEO-Bench-2_From_Performance_to_Capability,_Rethinking_Evaluation_in_Geospatial_AI\figure_4_page18.png
2025-11-21 00:34:51,446 - INFO - root - 成功添加图片 5：./export\vision_transformer\images\GEO-Bench-2_From_Performance_to_Capability,_Rethinking_Evaluation_in_Geospatial_AI\figure_5_page23.png
2025-11-21 00:34:51,446 - INFO - root - 成功添加图片 6：./export\vision_transformer\images\GEO-Bench-2_From_Performance_to_Capability,_Rethinking_Evaluation_in_Geospatial_AI\figure_6_page23.png
2025-11-21 00:34:51,447 - INFO - root - 成功添加图片 7：./export\vision_transformer\images\GEO-Bench-2_From_Performance_to_Capability,_Rethinking_Evaluation_in_Geospatial_AI\figure_7_page21.png
2025-11-21 00:34:51,447 - INFO - root - 成功添加图片 8：./export\vision_transformer\images\GEO-Bench-2_From_Performance_to_Capability,_Rethinking_Evaluation_in_Geospatial_AI\figure_8_page20.png
2025-11-21 00:34:51,447 - INFO - root - 成功添加图片 9：./export\vision_transformer\images\GEO-Bench-2_From_Performance_to_Capability,_Rethinking_Evaluation_in_Geospatial_AI\figure_9_page7.png
2025-11-21 00:34:51,447 - INFO - root - 成功添加图片 10：./export\vision_transformer\images\GEO-Bench-2_From_Performance_to_Capability,_Rethinking_Evaluation_in_Geospatial_AI\figure_10_page20.png
2025-11-21 00:34:51,448 - INFO - root - 论文《GEO-Bench-2: From Performance to Capability, Rethinking Evaluation in Geospatial AI》的分析已保存到 ./export\vision_transformer\GEO-Bench-2_From_Performance_to_Capability,_Rethinking_Evaluation_in_Geospatial_AI.md
2025-11-21 00:34:51,452 - INFO - root - 正在总结论文 16/40: INQUIRE-Search: A Framework for Interactive Discovery in Large-Scale Biodiversity Databases
2025-11-21 00:34:51,453 - INFO - root - 正在提取论文图片到目录: ./export\vision_transformer\images\INQUIRE-Search_A_Framework_for_Interactive_Discovery_in_Large-Scale_Biodiversity_Databases
2025-11-21 00:34:52,568 - INFO - root - 已保存图片 1/10：./export\vision_transformer\images\INQUIRE-Search_A_Framework_for_Interactive_Discovery_in_Large-Scale_Biodiversity_Databases\figure_1_page7.png
2025-11-21 00:34:52,706 - INFO - root - 已保存图片 2/10：./export\vision_transformer\images\INQUIRE-Search_A_Framework_for_Interactive_Discovery_in_Large-Scale_Biodiversity_Databases\figure_2_page15.jpeg
2025-11-21 00:34:52,805 - INFO - root - 已保存图片 3/10：./export\vision_transformer\images\INQUIRE-Search_A_Framework_for_Interactive_Discovery_in_Large-Scale_Biodiversity_Databases\figure_3_page7.png
2025-11-21 00:34:52,886 - INFO - root - 已保存图片 4/10：./export\vision_transformer\images\INQUIRE-Search_A_Framework_for_Interactive_Discovery_in_Large-Scale_Biodiversity_Databases\figure_4_page9.jpeg
2025-11-21 00:34:53,062 - INFO - root - 已保存图片 5/10：./export\vision_transformer\images\INQUIRE-Search_A_Framework_for_Interactive_Discovery_in_Large-Scale_Biodiversity_Databases\figure_5_page23.png
2025-11-21 00:34:53,133 - INFO - root - 已保存图片 6/10：./export\vision_transformer\images\INQUIRE-Search_A_Framework_for_Interactive_Discovery_in_Large-Scale_Biodiversity_Databases\figure_6_page13.jpeg
2025-11-21 00:34:53,191 - INFO - root - 已保存图片 7/10：./export\vision_transformer\images\INQUIRE-Search_A_Framework_for_Interactive_Discovery_in_Large-Scale_Biodiversity_Databases\figure_7_page9.jpeg
2025-11-21 00:34:53,269 - INFO - root - 已保存图片 8/10：./export\vision_transformer\images\INQUIRE-Search_A_Framework_for_Interactive_Discovery_in_Large-Scale_Biodiversity_Databases\figure_8_page7.jpeg
2025-11-21 00:34:53,319 - INFO - root - 已保存图片 9/10：./export\vision_transformer\images\INQUIRE-Search_A_Framework_for_Interactive_Discovery_in_Large-Scale_Biodiversity_Databases\figure_9_page13.jpeg
2025-11-21 00:34:53,418 - INFO - root - 已保存图片 10/10：./export\vision_transformer\images\INQUIRE-Search_A_Framework_for_Interactive_Discovery_in_Large-Scale_Biodiversity_Databases\figure_10_page3.jpeg
2025-11-21 00:34:53,432 - INFO - root - 成功添加图片 1：./export\vision_transformer\images\INQUIRE-Search_A_Framework_for_Interactive_Discovery_in_Large-Scale_Biodiversity_Databases\figure_1_page7.png
2025-11-21 00:34:53,433 - INFO - root - 成功添加图片 2：./export\vision_transformer\images\INQUIRE-Search_A_Framework_for_Interactive_Discovery_in_Large-Scale_Biodiversity_Databases\figure_2_page15.jpeg
2025-11-21 00:34:53,434 - INFO - root - 成功添加图片 3：./export\vision_transformer\images\INQUIRE-Search_A_Framework_for_Interactive_Discovery_in_Large-Scale_Biodiversity_Databases\figure_3_page7.png
2025-11-21 00:34:53,436 - INFO - root - 成功添加图片 4：./export\vision_transformer\images\INQUIRE-Search_A_Framework_for_Interactive_Discovery_in_Large-Scale_Biodiversity_Databases\figure_4_page9.jpeg
2025-11-21 00:34:53,436 - INFO - root - 成功添加图片 5：./export\vision_transformer\images\INQUIRE-Search_A_Framework_for_Interactive_Discovery_in_Large-Scale_Biodiversity_Databases\figure_5_page23.png
2025-11-21 00:34:53,437 - INFO - root - 成功添加图片 6：./export\vision_transformer\images\INQUIRE-Search_A_Framework_for_Interactive_Discovery_in_Large-Scale_Biodiversity_Databases\figure_6_page13.jpeg
2025-11-21 00:34:53,438 - INFO - root - 成功添加图片 7：./export\vision_transformer\images\INQUIRE-Search_A_Framework_for_Interactive_Discovery_in_Large-Scale_Biodiversity_Databases\figure_7_page9.jpeg
2025-11-21 00:34:53,438 - INFO - root - 成功添加图片 8：./export\vision_transformer\images\INQUIRE-Search_A_Framework_for_Interactive_Discovery_in_Large-Scale_Biodiversity_Databases\figure_8_page7.jpeg
2025-11-21 00:34:53,439 - INFO - root - 成功添加图片 9：./export\vision_transformer\images\INQUIRE-Search_A_Framework_for_Interactive_Discovery_in_Large-Scale_Biodiversity_Databases\figure_9_page13.jpeg
2025-11-21 00:34:53,445 - INFO - root - 成功添加图片 10：./export\vision_transformer\images\INQUIRE-Search_A_Framework_for_Interactive_Discovery_in_Large-Scale_Biodiversity_Databases\figure_10_page3.jpeg
2025-11-21 00:34:53,447 - INFO - root - 论文《INQUIRE-Search: A Framework for Interactive Discovery in Large-Scale Biodiversity Databases》的分析已保存到 ./export\vision_transformer\INQUIRE-Search_A_Framework_for_Interactive_Discovery_in_Large-Scale_Biodiversity_Databases.md
2025-11-21 00:34:53,455 - INFO - root - 正在总结论文 17/40: MambaIO: Global-Coordinate Inertial Odometry for Pedestrians via Multi-Scale Frequency-Decoupled Modeling
2025-11-21 00:34:53,461 - INFO - root - 正在提取论文图片到目录: ./export\vision_transformer\images\MambaIO_Global-Coordinate_Inertial_Odometry_for_Pedestrians_via_Multi-Scale_Frequency-Decoupled_Mod
2025-11-21 00:34:54,740 - INFO - root - 已保存图片 1/10：./export\vision_transformer\images\MambaIO_Global-Coordinate_Inertial_Odometry_for_Pedestrians_via_Multi-Scale_Frequency-Decoupled_Mod\figure_1_page4.png
2025-11-21 00:34:54,783 - INFO - root - 已保存图片 2/10：./export\vision_transformer\images\MambaIO_Global-Coordinate_Inertial_Odometry_for_Pedestrians_via_Multi-Scale_Frequency-Decoupled_Mod\figure_2_page5.jpeg
2025-11-21 00:34:54,896 - INFO - root - 已保存图片 3/10：./export\vision_transformer\images\MambaIO_Global-Coordinate_Inertial_Odometry_for_Pedestrians_via_Multi-Scale_Frequency-Decoupled_Mod\figure_3_page3.png
2025-11-21 00:34:54,956 - INFO - root - 已保存图片 4/10：./export\vision_transformer\images\MambaIO_Global-Coordinate_Inertial_Odometry_for_Pedestrians_via_Multi-Scale_Frequency-Decoupled_Mod\figure_4_page4.png
2025-11-21 00:34:54,966 - INFO - root - 成功添加图片 1：./export\vision_transformer\images\MambaIO_Global-Coordinate_Inertial_Odometry_for_Pedestrians_via_Multi-Scale_Frequency-Decoupled_Mod\figure_1_page4.png
2025-11-21 00:34:54,967 - INFO - root - 成功添加图片 2：./export\vision_transformer\images\MambaIO_Global-Coordinate_Inertial_Odometry_for_Pedestrians_via_Multi-Scale_Frequency-Decoupled_Mod\figure_2_page5.jpeg
2025-11-21 00:34:54,967 - INFO - root - 成功添加图片 3：./export\vision_transformer\images\MambaIO_Global-Coordinate_Inertial_Odometry_for_Pedestrians_via_Multi-Scale_Frequency-Decoupled_Mod\figure_3_page3.png
2025-11-21 00:34:54,968 - INFO - root - 成功添加图片 4：./export\vision_transformer\images\MambaIO_Global-Coordinate_Inertial_Odometry_for_Pedestrians_via_Multi-Scale_Frequency-Decoupled_Mod\figure_4_page4.png
2025-11-21 00:34:54,976 - INFO - root - 论文《MambaIO: Global-Coordinate Inertial Odometry for Pedestrians via Multi-Scale Frequency-Decoupled Modeling》的分析已保存到 ./export\vision_transformer\MambaIO_Global-Coordinate_Inertial_Odometry_for_Pedestrians_via_Multi-Scale_Frequency-Decoupled_Mod.md
2025-11-21 00:34:54,984 - INFO - root - 正在总结论文 18/40: A Millennium of UK Business Cycles: Insights from Structural VAR Analysis
2025-11-21 00:34:54,987 - INFO - root - 正在提取论文图片到目录: ./export\vision_transformer\images\A_Millennium_of_UK_Business_Cycles_Insights_from_Structural_VAR_Analysis
2025-11-21 00:34:55,506 - INFO - root - 已保存图片 1/10：./export\vision_transformer\images\A_Millennium_of_UK_Business_Cycles_Insights_from_Structural_VAR_Analysis\figure_1_page8.jpeg
2025-11-21 00:34:55,602 - INFO - root - 已保存图片 2/10：./export\vision_transformer\images\A_Millennium_of_UK_Business_Cycles_Insights_from_Structural_VAR_Analysis\figure_2_page8.jpeg
2025-11-21 00:34:55,700 - INFO - root - 已保存图片 3/10：./export\vision_transformer\images\A_Millennium_of_UK_Business_Cycles_Insights_from_Structural_VAR_Analysis\figure_3_page9.jpeg
2025-11-21 00:34:55,799 - INFO - root - 已保存图片 4/10：./export\vision_transformer\images\A_Millennium_of_UK_Business_Cycles_Insights_from_Structural_VAR_Analysis\figure_4_page14.jpeg
2025-11-21 00:34:55,923 - INFO - root - 已保存图片 5/10：./export\vision_transformer\images\A_Millennium_of_UK_Business_Cycles_Insights_from_Structural_VAR_Analysis\figure_5_page14.jpeg
2025-11-21 00:34:56,019 - INFO - root - 已保存图片 6/10：./export\vision_transformer\images\A_Millennium_of_UK_Business_Cycles_Insights_from_Structural_VAR_Analysis\figure_6_page28.jpeg
2025-11-21 00:34:56,118 - INFO - root - 已保存图片 7/10：./export\vision_transformer\images\A_Millennium_of_UK_Business_Cycles_Insights_from_Structural_VAR_Analysis\figure_7_page29.jpeg
2025-11-21 00:34:56,282 - INFO - root - 已保存图片 8/10：./export\vision_transformer\images\A_Millennium_of_UK_Business_Cycles_Insights_from_Structural_VAR_Analysis\figure_8_page29.jpeg
2025-11-21 00:34:56,383 - INFO - root - 已保存图片 9/10：./export\vision_transformer\images\A_Millennium_of_UK_Business_Cycles_Insights_from_Structural_VAR_Analysis\figure_9_page30.jpeg
2025-11-21 00:34:56,486 - INFO - root - 已保存图片 10/10：./export\vision_transformer\images\A_Millennium_of_UK_Business_Cycles_Insights_from_Structural_VAR_Analysis\figure_10_page30.jpeg
2025-11-21 00:34:56,497 - INFO - root - 成功添加图片 1：./export\vision_transformer\images\A_Millennium_of_UK_Business_Cycles_Insights_from_Structural_VAR_Analysis\figure_1_page8.jpeg
2025-11-21 00:34:56,498 - INFO - root - 成功添加图片 2：./export\vision_transformer\images\A_Millennium_of_UK_Business_Cycles_Insights_from_Structural_VAR_Analysis\figure_2_page8.jpeg
2025-11-21 00:34:56,498 - INFO - root - 成功添加图片 3：./export\vision_transformer\images\A_Millennium_of_UK_Business_Cycles_Insights_from_Structural_VAR_Analysis\figure_3_page9.jpeg
2025-11-21 00:34:56,499 - INFO - root - 成功添加图片 4：./export\vision_transformer\images\A_Millennium_of_UK_Business_Cycles_Insights_from_Structural_VAR_Analysis\figure_4_page14.jpeg
2025-11-21 00:34:56,499 - INFO - root - 成功添加图片 5：./export\vision_transformer\images\A_Millennium_of_UK_Business_Cycles_Insights_from_Structural_VAR_Analysis\figure_5_page14.jpeg
2025-11-21 00:34:56,499 - INFO - root - 成功添加图片 6：./export\vision_transformer\images\A_Millennium_of_UK_Business_Cycles_Insights_from_Structural_VAR_Analysis\figure_6_page28.jpeg
2025-11-21 00:34:56,500 - INFO - root - 成功添加图片 7：./export\vision_transformer\images\A_Millennium_of_UK_Business_Cycles_Insights_from_Structural_VAR_Analysis\figure_7_page29.jpeg
2025-11-21 00:34:56,500 - INFO - root - 成功添加图片 8：./export\vision_transformer\images\A_Millennium_of_UK_Business_Cycles_Insights_from_Structural_VAR_Analysis\figure_8_page29.jpeg
2025-11-21 00:34:56,500 - INFO - root - 成功添加图片 9：./export\vision_transformer\images\A_Millennium_of_UK_Business_Cycles_Insights_from_Structural_VAR_Analysis\figure_9_page30.jpeg
2025-11-21 00:34:56,501 - INFO - root - 成功添加图片 10：./export\vision_transformer\images\A_Millennium_of_UK_Business_Cycles_Insights_from_Structural_VAR_Analysis\figure_10_page30.jpeg
2025-11-21 00:34:56,503 - INFO - root - 论文《A Millennium of UK Business Cycles: Insights from Structural VAR Analysis》的分析已保存到 ./export\vision_transformer\A_Millennium_of_UK_Business_Cycles_Insights_from_Structural_VAR_Analysis.md
2025-11-21 00:34:56,508 - INFO - root - 正在总结论文 19/40: Navigating Quantum Missteps in Agent-Based Modeling: A Schelling Model Case Study
2025-11-21 00:34:56,515 - INFO - root - 正在提取论文图片到目录: ./export\vision_transformer\images\Navigating_Quantum_Missteps_in_Agent-Based_Modeling_A_Schelling_Model_Case_Study
2025-11-21 00:34:57,816 - INFO - root - 已保存图片 1/10：./export\vision_transformer\images\Navigating_Quantum_Missteps_in_Agent-Based_Modeling_A_Schelling_Model_Case_Study\figure_1_page18.png
2025-11-21 00:34:57,926 - INFO - root - 已保存图片 2/10：./export\vision_transformer\images\Navigating_Quantum_Missteps_in_Agent-Based_Modeling_A_Schelling_Model_Case_Study\figure_2_page8.png
2025-11-21 00:34:58,031 - INFO - root - 已保存图片 3/10：./export\vision_transformer\images\Navigating_Quantum_Missteps_in_Agent-Based_Modeling_A_Schelling_Model_Case_Study\figure_3_page10.png
2025-11-21 00:34:58,146 - INFO - root - 已保存图片 4/10：./export\vision_transformer\images\Navigating_Quantum_Missteps_in_Agent-Based_Modeling_A_Schelling_Model_Case_Study\figure_4_page7.png
2025-11-21 00:34:58,210 - INFO - root - 已保存图片 5/10：./export\vision_transformer\images\Navigating_Quantum_Missteps_in_Agent-Based_Modeling_A_Schelling_Model_Case_Study\figure_5_page19.png
2025-11-21 00:34:58,284 - INFO - root - 已保存图片 6/10：./export\vision_transformer\images\Navigating_Quantum_Missteps_in_Agent-Based_Modeling_A_Schelling_Model_Case_Study\figure_6_page3.png
2025-11-21 00:34:58,290 - INFO - root - 成功添加图片 1：./export\vision_transformer\images\Navigating_Quantum_Missteps_in_Agent-Based_Modeling_A_Schelling_Model_Case_Study\figure_1_page18.png
2025-11-21 00:34:58,290 - INFO - root - 成功添加图片 2：./export\vision_transformer\images\Navigating_Quantum_Missteps_in_Agent-Based_Modeling_A_Schelling_Model_Case_Study\figure_2_page8.png
2025-11-21 00:34:58,290 - INFO - root - 成功添加图片 3：./export\vision_transformer\images\Navigating_Quantum_Missteps_in_Agent-Based_Modeling_A_Schelling_Model_Case_Study\figure_3_page10.png
2025-11-21 00:34:58,291 - INFO - root - 成功添加图片 4：./export\vision_transformer\images\Navigating_Quantum_Missteps_in_Agent-Based_Modeling_A_Schelling_Model_Case_Study\figure_4_page7.png
2025-11-21 00:34:58,291 - INFO - root - 成功添加图片 5：./export\vision_transformer\images\Navigating_Quantum_Missteps_in_Agent-Based_Modeling_A_Schelling_Model_Case_Study\figure_5_page19.png
2025-11-21 00:34:58,291 - INFO - root - 成功添加图片 6：./export\vision_transformer\images\Navigating_Quantum_Missteps_in_Agent-Based_Modeling_A_Schelling_Model_Case_Study\figure_6_page3.png
2025-11-21 00:34:58,292 - INFO - root - 论文《Navigating Quantum Missteps in Agent-Based Modeling: A Schelling Model Case Study》的分析已保存到 ./export\vision_transformer\Navigating_Quantum_Missteps_in_Agent-Based_Modeling_A_Schelling_Model_Case_Study.md
2025-11-21 00:34:58,299 - INFO - root - 正在总结论文 20/40: The SA-FARI Dataset: Segment Anything in Footage of Animals for Recognition and Identification
2025-11-21 00:34:58,304 - INFO - root - 正在提取论文图片到目录: ./export\vision_transformer\images\The_SA-FARI_Dataset_Segment_Anything_in_Footage_of_Animals_for_Recognition_and_Identification
2025-11-21 00:35:04,031 - INFO - root - 已保存图片 1/10：./export\vision_transformer\images\The_SA-FARI_Dataset_Segment_Anything_in_Footage_of_Animals_for_Recognition_and_Identification\figure_1_page2.png
2025-11-21 00:35:04,206 - INFO - root - 已保存图片 2/10：./export\vision_transformer\images\The_SA-FARI_Dataset_Segment_Anything_in_Footage_of_Animals_for_Recognition_and_Identification\figure_2_page12.png
2025-11-21 00:35:04,456 - INFO - root - 已保存图片 3/10：./export\vision_transformer\images\The_SA-FARI_Dataset_Segment_Anything_in_Footage_of_Animals_for_Recognition_and_Identification\figure_3_page1.png
2025-11-21 00:35:04,627 - INFO - root - 已保存图片 4/10：./export\vision_transformer\images\The_SA-FARI_Dataset_Segment_Anything_in_Footage_of_Animals_for_Recognition_and_Identification\figure_4_page5.png
2025-11-21 00:35:04,735 - INFO - root - 已保存图片 5/10：./export\vision_transformer\images\The_SA-FARI_Dataset_Segment_Anything_in_Footage_of_Animals_for_Recognition_and_Identification\figure_5_page13.png
2025-11-21 00:35:04,752 - INFO - root - 成功添加图片 1：./export\vision_transformer\images\The_SA-FARI_Dataset_Segment_Anything_in_Footage_of_Animals_for_Recognition_and_Identification\figure_1_page2.png
2025-11-21 00:35:04,754 - INFO - root - 成功添加图片 2：./export\vision_transformer\images\The_SA-FARI_Dataset_Segment_Anything_in_Footage_of_Animals_for_Recognition_and_Identification\figure_2_page12.png
2025-11-21 00:35:04,756 - INFO - root - 成功添加图片 3：./export\vision_transformer\images\The_SA-FARI_Dataset_Segment_Anything_in_Footage_of_Animals_for_Recognition_and_Identification\figure_3_page1.png
2025-11-21 00:35:04,760 - INFO - root - 成功添加图片 4：./export\vision_transformer\images\The_SA-FARI_Dataset_Segment_Anything_in_Footage_of_Animals_for_Recognition_and_Identification\figure_4_page5.png
2025-11-21 00:35:04,760 - INFO - root - 成功添加图片 5：./export\vision_transformer\images\The_SA-FARI_Dataset_Segment_Anything_in_Footage_of_Animals_for_Recognition_and_Identification\figure_5_page13.png
2025-11-21 00:35:04,763 - INFO - root - 论文《The SA-FARI Dataset: Segment Anything in Footage of Animals for Recognition and Identification》的分析已保存到 ./export\vision_transformer\The_SA-FARI_Dataset_Segment_Anything_in_Footage_of_Animals_for_Recognition_and_Identification.md
2025-11-21 00:35:04,774 - INFO - root - 正在总结论文 21/40: Hierarchical Semantic Tree Anchoring for CLIP-Based Class-Incremental Learning
2025-11-21 00:35:04,782 - INFO - root - 正在提取论文图片到目录: ./export\vision_transformer\images\Hierarchical_Semantic_Tree_Anchoring_for_CLIP-Based_Class-Incremental_Learning
2025-11-21 00:35:05,191 - INFO - root - 已保存图片 1/10：./export\vision_transformer\images\Hierarchical_Semantic_Tree_Anchoring_for_CLIP-Based_Class-Incremental_Learning\figure_1_page4.jpeg
2025-11-21 00:35:05,269 - INFO - root - 已保存图片 2/10：./export\vision_transformer\images\Hierarchical_Semantic_Tree_Anchoring_for_CLIP-Based_Class-Incremental_Learning\figure_2_page1.jpeg
2025-11-21 00:35:05,357 - INFO - root - 已保存图片 3/10：./export\vision_transformer\images\Hierarchical_Semantic_Tree_Anchoring_for_CLIP-Based_Class-Incremental_Learning\figure_3_page1.jpeg
2025-11-21 00:35:05,435 - INFO - root - 已保存图片 4/10：./export\vision_transformer\images\Hierarchical_Semantic_Tree_Anchoring_for_CLIP-Based_Class-Incremental_Learning\figure_4_page4.png
2025-11-21 00:35:05,480 - INFO - root - 已保存图片 5/10：./export\vision_transformer\images\Hierarchical_Semantic_Tree_Anchoring_for_CLIP-Based_Class-Incremental_Learning\figure_5_page4.jpeg
2025-11-21 00:35:05,557 - INFO - root - 已保存图片 6/10：./export\vision_transformer\images\Hierarchical_Semantic_Tree_Anchoring_for_CLIP-Based_Class-Incremental_Learning\figure_6_page4.png
2025-11-21 00:35:05,633 - INFO - root - 已保存图片 7/10：./export\vision_transformer\images\Hierarchical_Semantic_Tree_Anchoring_for_CLIP-Based_Class-Incremental_Learning\figure_7_page4.png
2025-11-21 00:35:05,670 - INFO - root - 已保存图片 8/10：./export\vision_transformer\images\Hierarchical_Semantic_Tree_Anchoring_for_CLIP-Based_Class-Incremental_Learning\figure_8_page4.jpeg
2025-11-21 00:35:05,740 - INFO - root - 已保存图片 9/10：./export\vision_transformer\images\Hierarchical_Semantic_Tree_Anchoring_for_CLIP-Based_Class-Incremental_Learning\figure_9_page4.png
2025-11-21 00:35:05,813 - INFO - root - 已保存图片 10/10：./export\vision_transformer\images\Hierarchical_Semantic_Tree_Anchoring_for_CLIP-Based_Class-Incremental_Learning\figure_10_page4.png
2025-11-21 00:35:05,818 - INFO - root - 成功添加图片 1：./export\vision_transformer\images\Hierarchical_Semantic_Tree_Anchoring_for_CLIP-Based_Class-Incremental_Learning\figure_1_page4.jpeg
2025-11-21 00:35:05,819 - INFO - root - 成功添加图片 2：./export\vision_transformer\images\Hierarchical_Semantic_Tree_Anchoring_for_CLIP-Based_Class-Incremental_Learning\figure_2_page1.jpeg
2025-11-21 00:35:05,819 - INFO - root - 成功添加图片 3：./export\vision_transformer\images\Hierarchical_Semantic_Tree_Anchoring_for_CLIP-Based_Class-Incremental_Learning\figure_3_page1.jpeg
2025-11-21 00:35:05,820 - INFO - root - 成功添加图片 4：./export\vision_transformer\images\Hierarchical_Semantic_Tree_Anchoring_for_CLIP-Based_Class-Incremental_Learning\figure_4_page4.png
2025-11-21 00:35:05,820 - INFO - root - 成功添加图片 5：./export\vision_transformer\images\Hierarchical_Semantic_Tree_Anchoring_for_CLIP-Based_Class-Incremental_Learning\figure_5_page4.jpeg
2025-11-21 00:35:05,820 - INFO - root - 成功添加图片 6：./export\vision_transformer\images\Hierarchical_Semantic_Tree_Anchoring_for_CLIP-Based_Class-Incremental_Learning\figure_6_page4.png
2025-11-21 00:35:05,823 - INFO - root - 成功添加图片 7：./export\vision_transformer\images\Hierarchical_Semantic_Tree_Anchoring_for_CLIP-Based_Class-Incremental_Learning\figure_7_page4.png
2025-11-21 00:35:05,823 - INFO - root - 成功添加图片 8：./export\vision_transformer\images\Hierarchical_Semantic_Tree_Anchoring_for_CLIP-Based_Class-Incremental_Learning\figure_8_page4.jpeg
2025-11-21 00:35:05,823 - INFO - root - 成功添加图片 9：./export\vision_transformer\images\Hierarchical_Semantic_Tree_Anchoring_for_CLIP-Based_Class-Incremental_Learning\figure_9_page4.png
2025-11-21 00:35:05,824 - INFO - root - 成功添加图片 10：./export\vision_transformer\images\Hierarchical_Semantic_Tree_Anchoring_for_CLIP-Based_Class-Incremental_Learning\figure_10_page4.png
2025-11-21 00:35:05,826 - INFO - root - 论文《Hierarchical Semantic Tree Anchoring for CLIP-Based Class-Incremental Learning》的分析已保存到 ./export\vision_transformer\Hierarchical_Semantic_Tree_Anchoring_for_CLIP-Based_Class-Incremental_Learning.md
2025-11-21 00:35:05,835 - INFO - root - 正在总结论文 22/40: FlashMesh: Faster and Better Autoregressive Mesh Synthesis via Structured Speculation
2025-11-21 00:35:05,882 - INFO - root - 正在提取论文图片到目录: ./export\vision_transformer\images\FlashMesh_Faster_and_Better_Autoregressive_Mesh_Synthesis_via_Structured_Speculation
2025-11-21 00:35:08,502 - INFO - root - 已保存图片 1/10：./export\vision_transformer\images\FlashMesh_Faster_and_Better_Autoregressive_Mesh_Synthesis_via_Structured_Speculation\figure_1_page12.png
2025-11-21 00:35:08,695 - INFO - root - 已保存图片 2/10：./export\vision_transformer\images\FlashMesh_Faster_and_Better_Autoregressive_Mesh_Synthesis_via_Structured_Speculation\figure_2_page11.jpeg
2025-11-21 00:35:08,864 - INFO - root - 已保存图片 3/10：./export\vision_transformer\images\FlashMesh_Faster_and_Better_Autoregressive_Mesh_Synthesis_via_Structured_Speculation\figure_3_page6.png
2025-11-21 00:35:09,055 - INFO - root - 已保存图片 4/10：./export\vision_transformer\images\FlashMesh_Faster_and_Better_Autoregressive_Mesh_Synthesis_via_Structured_Speculation\figure_4_page4.png
2025-11-21 00:35:09,164 - INFO - root - 已保存图片 5/10：./export\vision_transformer\images\FlashMesh_Faster_and_Better_Autoregressive_Mesh_Synthesis_via_Structured_Speculation\figure_5_page1.jpeg
2025-11-21 00:35:09,274 - INFO - root - 已保存图片 6/10：./export\vision_transformer\images\FlashMesh_Faster_and_Better_Autoregressive_Mesh_Synthesis_via_Structured_Speculation\figure_6_page5.png
2025-11-21 00:35:09,329 - INFO - root - 已保存图片 7/10：./export\vision_transformer\images\FlashMesh_Faster_and_Better_Autoregressive_Mesh_Synthesis_via_Structured_Speculation\figure_7_page1.jpeg
2025-11-21 00:35:09,379 - INFO - root - 已保存图片 8/10：./export\vision_transformer\images\FlashMesh_Faster_and_Better_Autoregressive_Mesh_Synthesis_via_Structured_Speculation\figure_8_page1.jpeg
2025-11-21 00:35:09,434 - INFO - root - 已保存图片 9/10：./export\vision_transformer\images\FlashMesh_Faster_and_Better_Autoregressive_Mesh_Synthesis_via_Structured_Speculation\figure_9_page1.jpeg
2025-11-21 00:35:09,485 - INFO - root - 已保存图片 10/10：./export\vision_transformer\images\FlashMesh_Faster_and_Better_Autoregressive_Mesh_Synthesis_via_Structured_Speculation\figure_10_page1.jpeg
2025-11-21 00:35:09,514 - INFO - root - 成功添加图片 1：./export\vision_transformer\images\FlashMesh_Faster_and_Better_Autoregressive_Mesh_Synthesis_via_Structured_Speculation\figure_1_page12.png
2025-11-21 00:35:09,515 - INFO - root - 成功添加图片 2：./export\vision_transformer\images\FlashMesh_Faster_and_Better_Autoregressive_Mesh_Synthesis_via_Structured_Speculation\figure_2_page11.jpeg
2025-11-21 00:35:09,515 - INFO - root - 成功添加图片 3：./export\vision_transformer\images\FlashMesh_Faster_and_Better_Autoregressive_Mesh_Synthesis_via_Structured_Speculation\figure_3_page6.png
2025-11-21 00:35:09,515 - INFO - root - 成功添加图片 4：./export\vision_transformer\images\FlashMesh_Faster_and_Better_Autoregressive_Mesh_Synthesis_via_Structured_Speculation\figure_4_page4.png
2025-11-21 00:35:09,515 - INFO - root - 成功添加图片 5：./export\vision_transformer\images\FlashMesh_Faster_and_Better_Autoregressive_Mesh_Synthesis_via_Structured_Speculation\figure_5_page1.jpeg
2025-11-21 00:35:09,517 - INFO - root - 成功添加图片 6：./export\vision_transformer\images\FlashMesh_Faster_and_Better_Autoregressive_Mesh_Synthesis_via_Structured_Speculation\figure_6_page5.png
2025-11-21 00:35:09,517 - INFO - root - 成功添加图片 7：./export\vision_transformer\images\FlashMesh_Faster_and_Better_Autoregressive_Mesh_Synthesis_via_Structured_Speculation\figure_7_page1.jpeg
2025-11-21 00:35:09,517 - INFO - root - 成功添加图片 8：./export\vision_transformer\images\FlashMesh_Faster_and_Better_Autoregressive_Mesh_Synthesis_via_Structured_Speculation\figure_8_page1.jpeg
2025-11-21 00:35:09,517 - INFO - root - 成功添加图片 9：./export\vision_transformer\images\FlashMesh_Faster_and_Better_Autoregressive_Mesh_Synthesis_via_Structured_Speculation\figure_9_page1.jpeg
2025-11-21 00:35:09,518 - INFO - root - 成功添加图片 10：./export\vision_transformer\images\FlashMesh_Faster_and_Better_Autoregressive_Mesh_Synthesis_via_Structured_Speculation\figure_10_page1.jpeg
2025-11-21 00:35:09,519 - INFO - root - 论文《FlashMesh: Faster and Better Autoregressive Mesh Synthesis via Structured Speculation》的分析已保存到 ./export\vision_transformer\FlashMesh_Faster_and_Better_Autoregressive_Mesh_Synthesis_via_Structured_Speculation.md
2025-11-21 00:35:09,524 - INFO - root - 正在总结论文 23/40: Optimus-Q: Utilizing Federated Learning in Adaptive Robots for Intelligent Nuclear Power Plant Operations through Quantum Cryptography
2025-11-21 00:35:09,529 - INFO - root - 正在提取论文图片到目录: ./export\vision_transformer\images\Optimus-Q_Utilizing_Federated_Learning_in_Adaptive_Robots_for_Intelligent_Nuclear_Power_Plant_Opera
2025-11-21 00:35:09,786 - INFO - root - 已保存图片 1/10：./export\vision_transformer\images\Optimus-Q_Utilizing_Federated_Learning_in_Adaptive_Robots_for_Intelligent_Nuclear_Power_Plant_Opera\figure_1_page3.png
2025-11-21 00:35:09,869 - INFO - root - 已保存图片 2/10：./export\vision_transformer\images\Optimus-Q_Utilizing_Federated_Learning_in_Adaptive_Robots_for_Intelligent_Nuclear_Power_Plant_Opera\figure_2_page6.png
2025-11-21 00:35:09,923 - INFO - root - 已保存图片 3/10：./export\vision_transformer\images\Optimus-Q_Utilizing_Federated_Learning_in_Adaptive_Robots_for_Intelligent_Nuclear_Power_Plant_Opera\figure_3_page6.png
2025-11-21 00:35:10,020 - INFO - root - 已保存图片 4/10：./export\vision_transformer\images\Optimus-Q_Utilizing_Federated_Learning_in_Adaptive_Robots_for_Intelligent_Nuclear_Power_Plant_Opera\figure_4_page10.png
2025-11-21 00:35:10,022 - INFO - root - 成功添加图片 1：./export\vision_transformer\images\Optimus-Q_Utilizing_Federated_Learning_in_Adaptive_Robots_for_Intelligent_Nuclear_Power_Plant_Opera\figure_1_page3.png
2025-11-21 00:35:10,023 - INFO - root - 成功添加图片 2：./export\vision_transformer\images\Optimus-Q_Utilizing_Federated_Learning_in_Adaptive_Robots_for_Intelligent_Nuclear_Power_Plant_Opera\figure_2_page6.png
2025-11-21 00:35:10,023 - INFO - root - 成功添加图片 3：./export\vision_transformer\images\Optimus-Q_Utilizing_Federated_Learning_in_Adaptive_Robots_for_Intelligent_Nuclear_Power_Plant_Opera\figure_3_page6.png
2025-11-21 00:35:10,024 - INFO - root - 成功添加图片 4：./export\vision_transformer\images\Optimus-Q_Utilizing_Federated_Learning_in_Adaptive_Robots_for_Intelligent_Nuclear_Power_Plant_Opera\figure_4_page10.png
2025-11-21 00:35:10,031 - INFO - root - 论文《Optimus-Q: Utilizing Federated Learning in Adaptive Robots for Intelligent Nuclear Power Plant Operations through Quantum Cryptography》的分析已保存到 ./export\vision_transformer\Optimus-Q_Utilizing_Federated_Learning_in_Adaptive_Robots_for_Intelligent_Nuclear_Power_Plant_Opera.md
2025-11-21 00:35:10,037 - INFO - root - 正在总结论文 24/40: When to Think and When to Look: Uncertainty-Guided Lookback
2025-11-21 00:35:10,038 - INFO - root - 正在提取论文图片到目录: ./export\vision_transformer\images\When_to_Think_and_When_to_Look_Uncertainty-Guided_Lookback
2025-11-21 00:35:12,913 - INFO - root - 已保存图片 1/10：./export\vision_transformer\images\When_to_Think_and_When_to_Look_Uncertainty-Guided_Lookback\figure_1_page5.png
2025-11-21 00:35:13,240 - INFO - root - 已保存图片 2/10：./export\vision_transformer\images\When_to_Think_and_When_to_Look_Uncertainty-Guided_Lookback\figure_2_page4.png
2025-11-21 00:35:13,394 - INFO - root - 已保存图片 3/10：./export\vision_transformer\images\When_to_Think_and_When_to_Look_Uncertainty-Guided_Lookback\figure_3_page7.png
2025-11-21 00:35:13,583 - INFO - root - 已保存图片 4/10：./export\vision_transformer\images\When_to_Think_and_When_to_Look_Uncertainty-Guided_Lookback\figure_4_page1.png
2025-11-21 00:35:13,719 - INFO - root - 已保存图片 5/10：./export\vision_transformer\images\When_to_Think_and_When_to_Look_Uncertainty-Guided_Lookback\figure_5_page4.png
2025-11-21 00:35:13,860 - INFO - root - 已保存图片 6/10：./export\vision_transformer\images\When_to_Think_and_When_to_Look_Uncertainty-Guided_Lookback\figure_6_page4.png
2025-11-21 00:35:13,941 - INFO - root - 已保存图片 7/10：./export\vision_transformer\images\When_to_Think_and_When_to_Look_Uncertainty-Guided_Lookback\figure_7_page6.png
2025-11-21 00:35:13,965 - INFO - root - 成功添加图片 1：./export\vision_transformer\images\When_to_Think_and_When_to_Look_Uncertainty-Guided_Lookback\figure_1_page5.png
2025-11-21 00:35:13,966 - INFO - root - 成功添加图片 2：./export\vision_transformer\images\When_to_Think_and_When_to_Look_Uncertainty-Guided_Lookback\figure_2_page4.png
2025-11-21 00:35:13,966 - INFO - root - 成功添加图片 3：./export\vision_transformer\images\When_to_Think_and_When_to_Look_Uncertainty-Guided_Lookback\figure_3_page7.png
2025-11-21 00:35:13,967 - INFO - root - 成功添加图片 4：./export\vision_transformer\images\When_to_Think_and_When_to_Look_Uncertainty-Guided_Lookback\figure_4_page1.png
2025-11-21 00:35:13,968 - INFO - root - 成功添加图片 5：./export\vision_transformer\images\When_to_Think_and_When_to_Look_Uncertainty-Guided_Lookback\figure_5_page4.png
2025-11-21 00:35:13,968 - INFO - root - 成功添加图片 6：./export\vision_transformer\images\When_to_Think_and_When_to_Look_Uncertainty-Guided_Lookback\figure_6_page4.png
2025-11-21 00:35:13,970 - INFO - root - 成功添加图片 7：./export\vision_transformer\images\When_to_Think_and_When_to_Look_Uncertainty-Guided_Lookback\figure_7_page6.png
2025-11-21 00:35:13,971 - INFO - root - 论文《When to Think and When to Look: Uncertainty-Guided Lookback》的分析已保存到 ./export\vision_transformer\When_to_Think_and_When_to_Look_Uncertainty-Guided_Lookback.md
2025-11-21 00:35:13,977 - INFO - root - 正在总结论文 25/40: MaskMed: Decoupled Mask and Class Prediction for Medical Image Segmentation
2025-11-21 00:35:13,978 - INFO - root - 正在提取论文图片到目录: ./export\vision_transformer\images\MaskMed_Decoupled_Mask_and_Class_Prediction_for_Medical_Image_Segmentation
2025-11-21 00:35:14,958 - INFO - root - 已保存图片 1/10：./export\vision_transformer\images\MaskMed_Decoupled_Mask_and_Class_Prediction_for_Medical_Image_Segmentation\figure_1_page13.png
2025-11-21 00:35:15,092 - INFO - root - 已保存图片 2/10：./export\vision_transformer\images\MaskMed_Decoupled_Mask_and_Class_Prediction_for_Medical_Image_Segmentation\figure_2_page12.png
2025-11-21 00:35:15,227 - INFO - root - 已保存图片 3/10：./export\vision_transformer\images\MaskMed_Decoupled_Mask_and_Class_Prediction_for_Medical_Image_Segmentation\figure_3_page12.png
2025-11-21 00:35:15,256 - INFO - root - 已保存图片 4/10：./export\vision_transformer\images\MaskMed_Decoupled_Mask_and_Class_Prediction_for_Medical_Image_Segmentation\figure_4_page9.png
2025-11-21 00:35:15,287 - INFO - root - 已保存图片 5/10：./export\vision_transformer\images\MaskMed_Decoupled_Mask_and_Class_Prediction_for_Medical_Image_Segmentation\figure_5_page9.png
2025-11-21 00:35:15,321 - INFO - root - 已保存图片 6/10：./export\vision_transformer\images\MaskMed_Decoupled_Mask_and_Class_Prediction_for_Medical_Image_Segmentation\figure_6_page9.png
2025-11-21 00:35:15,349 - INFO - root - 已保存图片 7/10：./export\vision_transformer\images\MaskMed_Decoupled_Mask_and_Class_Prediction_for_Medical_Image_Segmentation\figure_7_page9.png
2025-11-21 00:35:15,384 - INFO - root - 已保存图片 8/10：./export\vision_transformer\images\MaskMed_Decoupled_Mask_and_Class_Prediction_for_Medical_Image_Segmentation\figure_8_page9.png
2025-11-21 00:35:15,478 - INFO - root - 已保存图片 9/10：./export\vision_transformer\images\MaskMed_Decoupled_Mask_and_Class_Prediction_for_Medical_Image_Segmentation\figure_9_page9.png
2025-11-21 00:35:15,567 - INFO - root - 已保存图片 10/10：./export\vision_transformer\images\MaskMed_Decoupled_Mask_and_Class_Prediction_for_Medical_Image_Segmentation\figure_10_page9.png
2025-11-21 00:35:15,576 - INFO - root - 成功添加图片 1：./export\vision_transformer\images\MaskMed_Decoupled_Mask_and_Class_Prediction_for_Medical_Image_Segmentation\figure_1_page13.png
2025-11-21 00:35:15,576 - INFO - root - 成功添加图片 2：./export\vision_transformer\images\MaskMed_Decoupled_Mask_and_Class_Prediction_for_Medical_Image_Segmentation\figure_2_page12.png
2025-11-21 00:35:15,576 - INFO - root - 成功添加图片 3：./export\vision_transformer\images\MaskMed_Decoupled_Mask_and_Class_Prediction_for_Medical_Image_Segmentation\figure_3_page12.png
2025-11-21 00:35:15,578 - INFO - root - 成功添加图片 4：./export\vision_transformer\images\MaskMed_Decoupled_Mask_and_Class_Prediction_for_Medical_Image_Segmentation\figure_4_page9.png
2025-11-21 00:35:15,578 - INFO - root - 成功添加图片 5：./export\vision_transformer\images\MaskMed_Decoupled_Mask_and_Class_Prediction_for_Medical_Image_Segmentation\figure_5_page9.png
2025-11-21 00:35:15,578 - INFO - root - 成功添加图片 6：./export\vision_transformer\images\MaskMed_Decoupled_Mask_and_Class_Prediction_for_Medical_Image_Segmentation\figure_6_page9.png
2025-11-21 00:35:15,578 - INFO - root - 成功添加图片 7：./export\vision_transformer\images\MaskMed_Decoupled_Mask_and_Class_Prediction_for_Medical_Image_Segmentation\figure_7_page9.png
2025-11-21 00:35:15,579 - INFO - root - 成功添加图片 8：./export\vision_transformer\images\MaskMed_Decoupled_Mask_and_Class_Prediction_for_Medical_Image_Segmentation\figure_8_page9.png
2025-11-21 00:35:15,579 - INFO - root - 成功添加图片 9：./export\vision_transformer\images\MaskMed_Decoupled_Mask_and_Class_Prediction_for_Medical_Image_Segmentation\figure_9_page9.png
2025-11-21 00:35:15,579 - INFO - root - 成功添加图片 10：./export\vision_transformer\images\MaskMed_Decoupled_Mask_and_Class_Prediction_for_Medical_Image_Segmentation\figure_10_page9.png
2025-11-21 00:35:15,584 - INFO - root - 论文《MaskMed: Decoupled Mask and Class Prediction for Medical Image Segmentation》的分析已保存到 ./export\vision_transformer\MaskMed_Decoupled_Mask_and_Class_Prediction_for_Medical_Image_Segmentation.md
2025-11-21 00:35:15,590 - INFO - root - 正在总结论文 26/40: Endomorphism and automorphism graphs of finite groups
2025-11-21 00:35:15,592 - INFO - root - 正在提取论文图片到目录: ./export\vision_transformer\images\Endomorphism_and_automorphism_graphs_of_finite_groups
2025-11-21 00:35:15,607 - INFO - root - 论文《Endomorphism and automorphism graphs of finite groups》的分析已保存到 ./export\vision_transformer\Endomorphism_and_automorphism_graphs_of_finite_groups.md
2025-11-21 00:35:15,619 - INFO - root - 正在总结论文 27/40: EPSO: A Caching-Based Efficient Superoptimizer for BPF Bytecode
2025-11-21 00:35:15,621 - INFO - root - 正在提取论文图片到目录: ./export\vision_transformer\images\EPSO_A_Caching-Based_Efficient_Superoptimizer_for_BPF_Bytecode
2025-11-21 00:35:15,787 - INFO - root - 已保存图片 1/10：./export\vision_transformer\images\EPSO_A_Caching-Based_Efficient_Superoptimizer_for_BPF_Bytecode\figure_1_page3.png
2025-11-21 00:35:15,843 - INFO - root - 已保存图片 2/10：./export\vision_transformer\images\EPSO_A_Caching-Based_Efficient_Superoptimizer_for_BPF_Bytecode\figure_2_page3.png
2025-11-21 00:35:15,893 - INFO - root - 已保存图片 3/10：./export\vision_transformer\images\EPSO_A_Caching-Based_Efficient_Superoptimizer_for_BPF_Bytecode\figure_3_page3.png
2025-11-21 00:35:15,957 - INFO - root - 已保存图片 4/10：./export\vision_transformer\images\EPSO_A_Caching-Based_Efficient_Superoptimizer_for_BPF_Bytecode\figure_4_page6.png
2025-11-21 00:35:16,025 - INFO - root - 已保存图片 5/10：./export\vision_transformer\images\EPSO_A_Caching-Based_Efficient_Superoptimizer_for_BPF_Bytecode\figure_5_page6.png
2025-11-21 00:35:16,077 - INFO - root - 已保存图片 6/10：./export\vision_transformer\images\EPSO_A_Caching-Based_Efficient_Superoptimizer_for_BPF_Bytecode\figure_6_page6.png
2025-11-21 00:35:16,143 - INFO - root - 已保存图片 7/10：./export\vision_transformer\images\EPSO_A_Caching-Based_Efficient_Superoptimizer_for_BPF_Bytecode\figure_7_page6.png
2025-11-21 00:35:16,196 - INFO - root - 已保存图片 8/10：./export\vision_transformer\images\EPSO_A_Caching-Based_Efficient_Superoptimizer_for_BPF_Bytecode\figure_8_page6.png
2025-11-21 00:35:16,246 - INFO - root - 已保存图片 9/10：./export\vision_transformer\images\EPSO_A_Caching-Based_Efficient_Superoptimizer_for_BPF_Bytecode\figure_9_page6.png
2025-11-21 00:35:16,247 - INFO - root - 成功添加图片 1：./export\vision_transformer\images\EPSO_A_Caching-Based_Efficient_Superoptimizer_for_BPF_Bytecode\figure_1_page3.png
2025-11-21 00:35:16,248 - INFO - root - 成功添加图片 2：./export\vision_transformer\images\EPSO_A_Caching-Based_Efficient_Superoptimizer_for_BPF_Bytecode\figure_2_page3.png
2025-11-21 00:35:16,251 - INFO - root - 成功添加图片 3：./export\vision_transformer\images\EPSO_A_Caching-Based_Efficient_Superoptimizer_for_BPF_Bytecode\figure_3_page3.png
2025-11-21 00:35:16,253 - INFO - root - 成功添加图片 4：./export\vision_transformer\images\EPSO_A_Caching-Based_Efficient_Superoptimizer_for_BPF_Bytecode\figure_4_page6.png
2025-11-21 00:35:16,254 - INFO - root - 成功添加图片 5：./export\vision_transformer\images\EPSO_A_Caching-Based_Efficient_Superoptimizer_for_BPF_Bytecode\figure_5_page6.png
2025-11-21 00:35:16,255 - INFO - root - 成功添加图片 6：./export\vision_transformer\images\EPSO_A_Caching-Based_Efficient_Superoptimizer_for_BPF_Bytecode\figure_6_page6.png
2025-11-21 00:35:16,255 - INFO - root - 成功添加图片 7：./export\vision_transformer\images\EPSO_A_Caching-Based_Efficient_Superoptimizer_for_BPF_Bytecode\figure_7_page6.png
2025-11-21 00:35:16,256 - INFO - root - 成功添加图片 8：./export\vision_transformer\images\EPSO_A_Caching-Based_Efficient_Superoptimizer_for_BPF_Bytecode\figure_8_page6.png
2025-11-21 00:35:16,256 - INFO - root - 成功添加图片 9：./export\vision_transformer\images\EPSO_A_Caching-Based_Efficient_Superoptimizer_for_BPF_Bytecode\figure_9_page6.png
2025-11-21 00:35:16,258 - INFO - root - 论文《EPSO: A Caching-Based Efficient Superoptimizer for BPF Bytecode》的分析已保存到 ./export\vision_transformer\EPSO_A_Caching-Based_Efficient_Superoptimizer_for_BPF_Bytecode.md
2025-11-21 00:35:16,272 - INFO - root - 正在总结论文 28/40: Learning from Mistakes: Loss-Aware Memory Enhanced Continual Learning for LiDAR Place Recognition
2025-11-21 00:35:16,277 - INFO - root - 正在提取论文图片到目录: ./export\vision_transformer\images\Learning_from_Mistakes_Loss-Aware_Memory_Enhanced_Continual_Learning_for_LiDAR_Place_Recognition
2025-11-21 00:35:18,314 - INFO - root - 已保存图片 1/10：./export\vision_transformer\images\Learning_from_Mistakes_Loss-Aware_Memory_Enhanced_Continual_Learning_for_LiDAR_Place_Recognition\figure_1_page1.png
2025-11-21 00:35:18,596 - INFO - root - 已保存图片 2/10：./export\vision_transformer\images\Learning_from_Mistakes_Loss-Aware_Memory_Enhanced_Continual_Learning_for_LiDAR_Place_Recognition\figure_2_page7.png
2025-11-21 00:35:18,743 - INFO - root - 已保存图片 3/10：./export\vision_transformer\images\Learning_from_Mistakes_Loss-Aware_Memory_Enhanced_Continual_Learning_for_LiDAR_Place_Recognition\figure_3_page4.png
2025-11-21 00:35:18,862 - INFO - root - 已保存图片 4/10：./export\vision_transformer\images\Learning_from_Mistakes_Loss-Aware_Memory_Enhanced_Continual_Learning_for_LiDAR_Place_Recognition\figure_4_page5.png
2025-11-21 00:35:18,876 - INFO - root - 成功添加图片 1：./export\vision_transformer\images\Learning_from_Mistakes_Loss-Aware_Memory_Enhanced_Continual_Learning_for_LiDAR_Place_Recognition\figure_1_page1.png
2025-11-21 00:35:18,876 - INFO - root - 成功添加图片 2：./export\vision_transformer\images\Learning_from_Mistakes_Loss-Aware_Memory_Enhanced_Continual_Learning_for_LiDAR_Place_Recognition\figure_2_page7.png
2025-11-21 00:35:18,876 - INFO - root - 成功添加图片 3：./export\vision_transformer\images\Learning_from_Mistakes_Loss-Aware_Memory_Enhanced_Continual_Learning_for_LiDAR_Place_Recognition\figure_3_page4.png
2025-11-21 00:35:18,877 - INFO - root - 成功添加图片 4：./export\vision_transformer\images\Learning_from_Mistakes_Loss-Aware_Memory_Enhanced_Continual_Learning_for_LiDAR_Place_Recognition\figure_4_page5.png
2025-11-21 00:35:18,879 - INFO - root - 论文《Learning from Mistakes: Loss-Aware Memory Enhanced Continual Learning for LiDAR Place Recognition》的分析已保存到 ./export\vision_transformer\Learning_from_Mistakes_Loss-Aware_Memory_Enhanced_Continual_Learning_for_LiDAR_Place_Recognition.md
2025-11-21 00:35:18,892 - INFO - root - 正在总结论文 29/40: US-X Complete: A Multi-Modal Approach to Anatomical 3D Shape Recovery
2025-11-21 00:35:18,893 - INFO - root - 正在提取论文图片到目录: ./export\vision_transformer\images\US-X_Complete_A_Multi-Modal_Approach_to_Anatomical_3D_Shape_Recovery
2025-11-21 00:35:19,010 - INFO - root - 已保存图片 1/10：./export\vision_transformer\images\US-X_Complete_A_Multi-Modal_Approach_to_Anatomical_3D_Shape_Recovery\figure_1_page12.jpeg
2025-11-21 00:35:19,064 - INFO - root - 已保存图片 2/10：./export\vision_transformer\images\US-X_Complete_A_Multi-Modal_Approach_to_Anatomical_3D_Shape_Recovery\figure_2_page12.jpeg
2025-11-21 00:35:19,098 - INFO - root - 已保存图片 3/10：./export\vision_transformer\images\US-X_Complete_A_Multi-Modal_Approach_to_Anatomical_3D_Shape_Recovery\figure_3_page4.jpeg
2025-11-21 00:35:19,171 - INFO - root - 已保存图片 4/10：./export\vision_transformer\images\US-X_Complete_A_Multi-Modal_Approach_to_Anatomical_3D_Shape_Recovery\figure_4_page4.png
2025-11-21 00:35:19,192 - INFO - root - 已保存图片 5/10：./export\vision_transformer\images\US-X_Complete_A_Multi-Modal_Approach_to_Anatomical_3D_Shape_Recovery\figure_5_page4.jpeg
2025-11-21 00:35:19,216 - INFO - root - 已保存图片 6/10：./export\vision_transformer\images\US-X_Complete_A_Multi-Modal_Approach_to_Anatomical_3D_Shape_Recovery\figure_6_page4.jpeg
2025-11-21 00:35:19,245 - INFO - root - 已保存图片 7/10：./export\vision_transformer\images\US-X_Complete_A_Multi-Modal_Approach_to_Anatomical_3D_Shape_Recovery\figure_7_page6.jpeg
2025-11-21 00:35:19,266 - INFO - root - 已保存图片 8/10：./export\vision_transformer\images\US-X_Complete_A_Multi-Modal_Approach_to_Anatomical_3D_Shape_Recovery\figure_8_page10.jpeg
2025-11-21 00:35:19,294 - INFO - root - 已保存图片 9/10：./export\vision_transformer\images\US-X_Complete_A_Multi-Modal_Approach_to_Anatomical_3D_Shape_Recovery\figure_9_page10.jpeg
2025-11-21 00:35:19,322 - INFO - root - 已保存图片 10/10：./export\vision_transformer\images\US-X_Complete_A_Multi-Modal_Approach_to_Anatomical_3D_Shape_Recovery\figure_10_page10.jpeg
2025-11-21 00:35:19,324 - INFO - root - 成功添加图片 1：./export\vision_transformer\images\US-X_Complete_A_Multi-Modal_Approach_to_Anatomical_3D_Shape_Recovery\figure_1_page12.jpeg
2025-11-21 00:35:19,325 - INFO - root - 成功添加图片 2：./export\vision_transformer\images\US-X_Complete_A_Multi-Modal_Approach_to_Anatomical_3D_Shape_Recovery\figure_2_page12.jpeg
2025-11-21 00:35:19,325 - INFO - root - 成功添加图片 3：./export\vision_transformer\images\US-X_Complete_A_Multi-Modal_Approach_to_Anatomical_3D_Shape_Recovery\figure_3_page4.jpeg
2025-11-21 00:35:19,325 - INFO - root - 成功添加图片 4：./export\vision_transformer\images\US-X_Complete_A_Multi-Modal_Approach_to_Anatomical_3D_Shape_Recovery\figure_4_page4.png
2025-11-21 00:35:19,325 - INFO - root - 成功添加图片 5：./export\vision_transformer\images\US-X_Complete_A_Multi-Modal_Approach_to_Anatomical_3D_Shape_Recovery\figure_5_page4.jpeg
2025-11-21 00:35:19,325 - INFO - root - 成功添加图片 6：./export\vision_transformer\images\US-X_Complete_A_Multi-Modal_Approach_to_Anatomical_3D_Shape_Recovery\figure_6_page4.jpeg
2025-11-21 00:35:19,327 - INFO - root - 成功添加图片 7：./export\vision_transformer\images\US-X_Complete_A_Multi-Modal_Approach_to_Anatomical_3D_Shape_Recovery\figure_7_page6.jpeg
2025-11-21 00:35:19,327 - INFO - root - 成功添加图片 8：./export\vision_transformer\images\US-X_Complete_A_Multi-Modal_Approach_to_Anatomical_3D_Shape_Recovery\figure_8_page10.jpeg
2025-11-21 00:35:19,328 - INFO - root - 成功添加图片 9：./export\vision_transformer\images\US-X_Complete_A_Multi-Modal_Approach_to_Anatomical_3D_Shape_Recovery\figure_9_page10.jpeg
2025-11-21 00:35:19,328 - INFO - root - 成功添加图片 10：./export\vision_transformer\images\US-X_Complete_A_Multi-Modal_Approach_to_Anatomical_3D_Shape_Recovery\figure_10_page10.jpeg
2025-11-21 00:35:19,330 - INFO - root - 论文《US-X Complete: A Multi-Modal Approach to Anatomical 3D Shape Recovery》的分析已保存到 ./export\vision_transformer\US-X_Complete_A_Multi-Modal_Approach_to_Anatomical_3D_Shape_Recovery.md
2025-11-21 00:35:19,339 - INFO - root - 正在总结论文 30/40: Real-Time Optimal Control via Transformer Networks and Bernstein Polynomials
2025-11-21 00:35:19,341 - INFO - root - 正在提取论文图片到目录: ./export\vision_transformer\images\Real-Time_Optimal_Control_via_Transformer_Networks_and_Bernstein_Polynomials
2025-11-21 00:35:19,479 - INFO - root - 已保存图片 1/10：./export\vision_transformer\images\Real-Time_Optimal_Control_via_Transformer_Networks_and_Bernstein_Polynomials\figure_1_page5.jpeg
2025-11-21 00:35:19,540 - INFO - root - 已保存图片 2/10：./export\vision_transformer\images\Real-Time_Optimal_Control_via_Transformer_Networks_and_Bernstein_Polynomials\figure_2_page4.jpeg
2025-11-21 00:35:19,574 - INFO - root - 已保存图片 3/10：./export\vision_transformer\images\Real-Time_Optimal_Control_via_Transformer_Networks_and_Bernstein_Polynomials\figure_3_page5.jpeg
2025-11-21 00:35:19,609 - INFO - root - 已保存图片 4/10：./export\vision_transformer\images\Real-Time_Optimal_Control_via_Transformer_Networks_and_Bernstein_Polynomials\figure_4_page6.jpeg
2025-11-21 00:35:19,650 - INFO - root - 已保存图片 5/10：./export\vision_transformer\images\Real-Time_Optimal_Control_via_Transformer_Networks_and_Bernstein_Polynomials\figure_5_page6.jpeg
2025-11-21 00:35:19,682 - INFO - root - 已保存图片 6/10：./export\vision_transformer\images\Real-Time_Optimal_Control_via_Transformer_Networks_and_Bernstein_Polynomials\figure_6_page6.jpeg
2025-11-21 00:35:19,687 - INFO - root - 成功添加图片 1：./export\vision_transformer\images\Real-Time_Optimal_Control_via_Transformer_Networks_and_Bernstein_Polynomials\figure_1_page5.jpeg
2025-11-21 00:35:19,688 - INFO - root - 成功添加图片 2：./export\vision_transformer\images\Real-Time_Optimal_Control_via_Transformer_Networks_and_Bernstein_Polynomials\figure_2_page4.jpeg
2025-11-21 00:35:19,688 - INFO - root - 成功添加图片 3：./export\vision_transformer\images\Real-Time_Optimal_Control_via_Transformer_Networks_and_Bernstein_Polynomials\figure_3_page5.jpeg
2025-11-21 00:35:19,689 - INFO - root - 成功添加图片 4：./export\vision_transformer\images\Real-Time_Optimal_Control_via_Transformer_Networks_and_Bernstein_Polynomials\figure_4_page6.jpeg
2025-11-21 00:35:19,691 - INFO - root - 成功添加图片 5：./export\vision_transformer\images\Real-Time_Optimal_Control_via_Transformer_Networks_and_Bernstein_Polynomials\figure_5_page6.jpeg
2025-11-21 00:35:19,691 - INFO - root - 成功添加图片 6：./export\vision_transformer\images\Real-Time_Optimal_Control_via_Transformer_Networks_and_Bernstein_Polynomials\figure_6_page6.jpeg
2025-11-21 00:35:19,693 - INFO - root - 论文《Real-Time Optimal Control via Transformer Networks and Bernstein Polynomials》的分析已保存到 ./export\vision_transformer\Real-Time_Optimal_Control_via_Transformer_Networks_and_Bernstein_Polynomials.md
2025-11-21 00:35:19,698 - INFO - root - 正在总结论文 31/40: Graph Rewriting Language as a Platform for Quantum Diagrammatic Calculi
2025-11-21 00:35:19,700 - INFO - root - 正在提取论文图片到目录: ./export\vision_transformer\images\Graph_Rewriting_Language_as_a_Platform_for_Quantum_Diagrammatic_Calculi
2025-11-21 00:35:21,240 - INFO - root - 已保存图片 1/10：./export\vision_transformer\images\Graph_Rewriting_Language_as_a_Platform_for_Quantum_Diagrammatic_Calculi\figure_1_page26.png
2025-11-21 00:35:21,353 - INFO - root - 已保存图片 2/10：./export\vision_transformer\images\Graph_Rewriting_Language_as_a_Platform_for_Quantum_Diagrammatic_Calculi\figure_2_page14.png
2025-11-21 00:35:21,448 - INFO - root - 已保存图片 3/10：./export\vision_transformer\images\Graph_Rewriting_Language_as_a_Platform_for_Quantum_Diagrammatic_Calculi\figure_3_page14.png
2025-11-21 00:35:21,566 - INFO - root - 已保存图片 4/10：./export\vision_transformer\images\Graph_Rewriting_Language_as_a_Platform_for_Quantum_Diagrammatic_Calculi\figure_4_page10.png
2025-11-21 00:35:21,691 - INFO - root - 已保存图片 5/10：./export\vision_transformer\images\Graph_Rewriting_Language_as_a_Platform_for_Quantum_Diagrammatic_Calculi\figure_5_page24.png
2025-11-21 00:35:21,807 - INFO - root - 已保存图片 6/10：./export\vision_transformer\images\Graph_Rewriting_Language_as_a_Platform_for_Quantum_Diagrammatic_Calculi\figure_6_page20.png
2025-11-21 00:35:21,919 - INFO - root - 已保存图片 7/10：./export\vision_transformer\images\Graph_Rewriting_Language_as_a_Platform_for_Quantum_Diagrammatic_Calculi\figure_7_page12.png
2025-11-21 00:35:22,008 - INFO - root - 已保存图片 8/10：./export\vision_transformer\images\Graph_Rewriting_Language_as_a_Platform_for_Quantum_Diagrammatic_Calculi\figure_8_page24.png
2025-11-21 00:35:22,101 - INFO - root - 已保存图片 9/10：./export\vision_transformer\images\Graph_Rewriting_Language_as_a_Platform_for_Quantum_Diagrammatic_Calculi\figure_9_page6.png
2025-11-21 00:35:22,158 - INFO - root - 已保存图片 10/10：./export\vision_transformer\images\Graph_Rewriting_Language_as_a_Platform_for_Quantum_Diagrammatic_Calculi\figure_10_page14.png
2025-11-21 00:35:22,166 - INFO - root - 成功添加图片 1：./export\vision_transformer\images\Graph_Rewriting_Language_as_a_Platform_for_Quantum_Diagrammatic_Calculi\figure_1_page26.png
2025-11-21 00:35:22,166 - INFO - root - 成功添加图片 2：./export\vision_transformer\images\Graph_Rewriting_Language_as_a_Platform_for_Quantum_Diagrammatic_Calculi\figure_2_page14.png
2025-11-21 00:35:22,167 - INFO - root - 成功添加图片 3：./export\vision_transformer\images\Graph_Rewriting_Language_as_a_Platform_for_Quantum_Diagrammatic_Calculi\figure_3_page14.png
2025-11-21 00:35:22,168 - INFO - root - 成功添加图片 4：./export\vision_transformer\images\Graph_Rewriting_Language_as_a_Platform_for_Quantum_Diagrammatic_Calculi\figure_4_page10.png
2025-11-21 00:35:22,169 - INFO - root - 成功添加图片 5：./export\vision_transformer\images\Graph_Rewriting_Language_as_a_Platform_for_Quantum_Diagrammatic_Calculi\figure_5_page24.png
2025-11-21 00:35:22,169 - INFO - root - 成功添加图片 6：./export\vision_transformer\images\Graph_Rewriting_Language_as_a_Platform_for_Quantum_Diagrammatic_Calculi\figure_6_page20.png
2025-11-21 00:35:22,169 - INFO - root - 成功添加图片 7：./export\vision_transformer\images\Graph_Rewriting_Language_as_a_Platform_for_Quantum_Diagrammatic_Calculi\figure_7_page12.png
2025-11-21 00:35:22,170 - INFO - root - 成功添加图片 8：./export\vision_transformer\images\Graph_Rewriting_Language_as_a_Platform_for_Quantum_Diagrammatic_Calculi\figure_8_page24.png
2025-11-21 00:35:22,170 - INFO - root - 成功添加图片 9：./export\vision_transformer\images\Graph_Rewriting_Language_as_a_Platform_for_Quantum_Diagrammatic_Calculi\figure_9_page6.png
2025-11-21 00:35:22,175 - INFO - root - 成功添加图片 10：./export\vision_transformer\images\Graph_Rewriting_Language_as_a_Platform_for_Quantum_Diagrammatic_Calculi\figure_10_page14.png
2025-11-21 00:35:22,178 - INFO - root - 论文《Graph Rewriting Language as a Platform for Quantum Diagrammatic Calculi》的分析已保存到 ./export\vision_transformer\Graph_Rewriting_Language_as_a_Platform_for_Quantum_Diagrammatic_Calculi.md
2025-11-21 00:35:22,193 - INFO - root - 正在总结论文 32/40: MHR: Momentum Human Rig
2025-11-21 00:35:22,198 - INFO - root - 正在提取论文图片到目录: ./export\vision_transformer\images\MHR_Momentum_Human_Rig
2025-11-21 00:35:22,937 - INFO - root - 已保存图片 1/10：./export\vision_transformer\images\MHR_Momentum_Human_Rig\figure_1_page5.jpeg
2025-11-21 00:35:23,080 - INFO - root - 已保存图片 2/10：./export\vision_transformer\images\MHR_Momentum_Human_Rig\figure_2_page5.jpeg
2025-11-21 00:35:23,262 - INFO - root - 已保存图片 3/10：./export\vision_transformer\images\MHR_Momentum_Human_Rig\figure_3_page4.png
2025-11-21 00:35:23,360 - INFO - root - 已保存图片 4/10：./export\vision_transformer\images\MHR_Momentum_Human_Rig\figure_4_page7.jpeg
2025-11-21 00:35:23,437 - INFO - root - 已保存图片 5/10：./export\vision_transformer\images\MHR_Momentum_Human_Rig\figure_5_page6.jpeg
2025-11-21 00:35:23,520 - INFO - root - 已保存图片 6/10：./export\vision_transformer\images\MHR_Momentum_Human_Rig\figure_6_page7.jpeg
2025-11-21 00:35:23,575 - INFO - root - 已保存图片 7/10：./export\vision_transformer\images\MHR_Momentum_Human_Rig\figure_7_page1.jpeg
2025-11-21 00:35:23,680 - INFO - root - 已保存图片 8/10：./export\vision_transformer\images\MHR_Momentum_Human_Rig\figure_8_page9.png
2025-11-21 00:35:23,714 - INFO - root - 已保存图片 9/10：./export\vision_transformer\images\MHR_Momentum_Human_Rig\figure_9_page6.jpeg
2025-11-21 00:35:23,726 - INFO - root - 成功添加图片 1：./export\vision_transformer\images\MHR_Momentum_Human_Rig\figure_1_page5.jpeg
2025-11-21 00:35:23,727 - INFO - root - 成功添加图片 2：./export\vision_transformer\images\MHR_Momentum_Human_Rig\figure_2_page5.jpeg
2025-11-21 00:35:23,727 - INFO - root - 成功添加图片 3：./export\vision_transformer\images\MHR_Momentum_Human_Rig\figure_3_page4.png
2025-11-21 00:35:23,727 - INFO - root - 成功添加图片 4：./export\vision_transformer\images\MHR_Momentum_Human_Rig\figure_4_page7.jpeg
2025-11-21 00:35:23,727 - INFO - root - 成功添加图片 5：./export\vision_transformer\images\MHR_Momentum_Human_Rig\figure_5_page6.jpeg
2025-11-21 00:35:23,729 - INFO - root - 成功添加图片 6：./export\vision_transformer\images\MHR_Momentum_Human_Rig\figure_6_page7.jpeg
2025-11-21 00:35:23,729 - INFO - root - 成功添加图片 7：./export\vision_transformer\images\MHR_Momentum_Human_Rig\figure_7_page1.jpeg
2025-11-21 00:35:23,729 - INFO - root - 成功添加图片 8：./export\vision_transformer\images\MHR_Momentum_Human_Rig\figure_8_page9.png
2025-11-21 00:35:23,730 - INFO - root - 成功添加图片 9：./export\vision_transformer\images\MHR_Momentum_Human_Rig\figure_9_page6.jpeg
2025-11-21 00:35:23,731 - INFO - root - 论文《MHR: Momentum Human Rig》的分析已保存到 ./export\vision_transformer\MHR_Momentum_Human_Rig.md
2025-11-21 00:35:23,736 - INFO - root - 正在总结论文 33/40: CompTrack: Information Bottleneck-Guided Low-Rank Dynamic Token Compression for Point Cloud Tracking
2025-11-21 00:35:23,738 - INFO - root - 正在提取论文图片到目录: ./export\vision_transformer\images\CompTrack_Information_Bottleneck-Guided_Low-Rank_Dynamic_Token_Compression_for_Point_Cloud_Tracking
2025-11-21 00:35:24,164 - INFO - root - 已保存图片 1/10：./export\vision_transformer\images\CompTrack_Information_Bottleneck-Guided_Low-Rank_Dynamic_Token_Compression_for_Point_Cloud_Tracking\figure_1_page7.png
2025-11-21 00:35:24,245 - INFO - root - 已保存图片 2/10：./export\vision_transformer\images\CompTrack_Information_Bottleneck-Guided_Low-Rank_Dynamic_Token_Compression_for_Point_Cloud_Tracking\figure_2_page7.png
2025-11-21 00:35:24,309 - INFO - root - 已保存图片 3/10：./export\vision_transformer\images\CompTrack_Information_Bottleneck-Guided_Low-Rank_Dynamic_Token_Compression_for_Point_Cloud_Tracking\figure_3_page7.png
2025-11-21 00:35:24,394 - INFO - root - 已保存图片 4/10：./export\vision_transformer\images\CompTrack_Information_Bottleneck-Guided_Low-Rank_Dynamic_Token_Compression_for_Point_Cloud_Tracking\figure_4_page7.png
2025-11-21 00:35:24,470 - INFO - root - 已保存图片 5/10：./export\vision_transformer\images\CompTrack_Information_Bottleneck-Guided_Low-Rank_Dynamic_Token_Compression_for_Point_Cloud_Tracking\figure_5_page7.png
2025-11-21 00:35:24,533 - INFO - root - 已保存图片 6/10：./export\vision_transformer\images\CompTrack_Information_Bottleneck-Guided_Low-Rank_Dynamic_Token_Compression_for_Point_Cloud_Tracking\figure_6_page7.png
2025-11-21 00:35:24,618 - INFO - root - 已保存图片 7/10：./export\vision_transformer\images\CompTrack_Information_Bottleneck-Guided_Low-Rank_Dynamic_Token_Compression_for_Point_Cloud_Tracking\figure_7_page7.png
2025-11-21 00:35:24,703 - INFO - root - 已保存图片 8/10：./export\vision_transformer\images\CompTrack_Information_Bottleneck-Guided_Low-Rank_Dynamic_Token_Compression_for_Point_Cloud_Tracking\figure_8_page7.png
2025-11-21 00:35:24,781 - INFO - root - 已保存图片 9/10：./export\vision_transformer\images\CompTrack_Information_Bottleneck-Guided_Low-Rank_Dynamic_Token_Compression_for_Point_Cloud_Tracking\figure_9_page7.png
2025-11-21 00:35:24,849 - INFO - root - 已保存图片 10/10：./export\vision_transformer\images\CompTrack_Information_Bottleneck-Guided_Low-Rank_Dynamic_Token_Compression_for_Point_Cloud_Tracking\figure_10_page7.png
2025-11-21 00:35:24,851 - INFO - root - 成功添加图片 1：./export\vision_transformer\images\CompTrack_Information_Bottleneck-Guided_Low-Rank_Dynamic_Token_Compression_for_Point_Cloud_Tracking\figure_1_page7.png
2025-11-21 00:35:24,852 - INFO - root - 成功添加图片 2：./export\vision_transformer\images\CompTrack_Information_Bottleneck-Guided_Low-Rank_Dynamic_Token_Compression_for_Point_Cloud_Tracking\figure_2_page7.png
2025-11-21 00:35:24,852 - INFO - root - 成功添加图片 3：./export\vision_transformer\images\CompTrack_Information_Bottleneck-Guided_Low-Rank_Dynamic_Token_Compression_for_Point_Cloud_Tracking\figure_3_page7.png
2025-11-21 00:35:24,852 - INFO - root - 成功添加图片 4：./export\vision_transformer\images\CompTrack_Information_Bottleneck-Guided_Low-Rank_Dynamic_Token_Compression_for_Point_Cloud_Tracking\figure_4_page7.png
2025-11-21 00:35:24,853 - INFO - root - 成功添加图片 5：./export\vision_transformer\images\CompTrack_Information_Bottleneck-Guided_Low-Rank_Dynamic_Token_Compression_for_Point_Cloud_Tracking\figure_5_page7.png
2025-11-21 00:35:24,853 - INFO - root - 成功添加图片 6：./export\vision_transformer\images\CompTrack_Information_Bottleneck-Guided_Low-Rank_Dynamic_Token_Compression_for_Point_Cloud_Tracking\figure_6_page7.png
2025-11-21 00:35:24,853 - INFO - root - 成功添加图片 7：./export\vision_transformer\images\CompTrack_Information_Bottleneck-Guided_Low-Rank_Dynamic_Token_Compression_for_Point_Cloud_Tracking\figure_7_page7.png
2025-11-21 00:35:24,854 - INFO - root - 成功添加图片 8：./export\vision_transformer\images\CompTrack_Information_Bottleneck-Guided_Low-Rank_Dynamic_Token_Compression_for_Point_Cloud_Tracking\figure_8_page7.png
2025-11-21 00:35:24,854 - INFO - root - 成功添加图片 9：./export\vision_transformer\images\CompTrack_Information_Bottleneck-Guided_Low-Rank_Dynamic_Token_Compression_for_Point_Cloud_Tracking\figure_9_page7.png
2025-11-21 00:35:24,854 - INFO - root - 成功添加图片 10：./export\vision_transformer\images\CompTrack_Information_Bottleneck-Guided_Low-Rank_Dynamic_Token_Compression_for_Point_Cloud_Tracking\figure_10_page7.png
2025-11-21 00:35:24,859 - INFO - root - 论文《CompTrack: Information Bottleneck-Guided Low-Rank Dynamic Token Compression for Point Cloud Tracking》的分析已保存到 ./export\vision_transformer\CompTrack_Information_Bottleneck-Guided_Low-Rank_Dynamic_Token_Compression_for_Point_Cloud_Tracking.md
2025-11-21 00:35:24,864 - INFO - root - 正在总结论文 34/40: A critical review of pre-post surveys designed to measure student epistemology in undergraduate science courses
2025-11-21 00:35:24,864 - INFO - root - 正在提取论文图片到目录: ./export\vision_transformer\images\A_critical_review_of_pre-post_surveys_designed_to_measure_student_epistemology_in_undergraduate_scie
2025-11-21 00:35:25,017 - INFO - root - 已保存图片 1/10：./export\vision_transformer\images\A_critical_review_of_pre-post_surveys_designed_to_measure_student_epistemology_in_undergraduate_scie\figure_1_page7.png
2025-11-21 00:35:25,019 - INFO - root - 成功添加图片 1：./export\vision_transformer\images\A_critical_review_of_pre-post_surveys_designed_to_measure_student_epistemology_in_undergraduate_scie\figure_1_page7.png
2025-11-21 00:35:25,020 - INFO - root - 论文《A critical review of pre-post surveys designed to measure student epistemology in undergraduate science courses》的分析已保存到 ./export\vision_transformer\A_critical_review_of_pre-post_surveys_designed_to_measure_student_epistemology_in_undergraduate_scie.md
2025-11-21 00:35:25,028 - INFO - root - 正在总结论文 35/40: AVATAAR: Agentic Video Answering via Temporal Adaptive Alignment and Reasoning
2025-11-21 00:35:25,031 - INFO - root - 正在提取论文图片到目录: ./export\vision_transformer\images\AVATAAR_Agentic_Video_Answering_via_Temporal_Adaptive_Alignment_and_Reasoning
2025-11-21 00:35:25,826 - INFO - root - 已保存图片 1/10：./export\vision_transformer\images\AVATAAR_Agentic_Video_Answering_via_Temporal_Adaptive_Alignment_and_Reasoning\figure_1_page3.png
2025-11-21 00:35:25,981 - INFO - root - 已保存图片 2/10：./export\vision_transformer\images\AVATAAR_Agentic_Video_Answering_via_Temporal_Adaptive_Alignment_and_Reasoning\figure_2_page2.png
2025-11-21 00:35:26,011 - INFO - root - 已保存图片 3/10：./export\vision_transformer\images\AVATAAR_Agentic_Video_Answering_via_Temporal_Adaptive_Alignment_and_Reasoning\figure_3_page7.png
2025-11-21 00:35:26,016 - INFO - root - 成功添加图片 1：./export\vision_transformer\images\AVATAAR_Agentic_Video_Answering_via_Temporal_Adaptive_Alignment_and_Reasoning\figure_1_page3.png
2025-11-21 00:35:26,016 - INFO - root - 成功添加图片 2：./export\vision_transformer\images\AVATAAR_Agentic_Video_Answering_via_Temporal_Adaptive_Alignment_and_Reasoning\figure_2_page2.png
2025-11-21 00:35:26,017 - INFO - root - 成功添加图片 3：./export\vision_transformer\images\AVATAAR_Agentic_Video_Answering_via_Temporal_Adaptive_Alignment_and_Reasoning\figure_3_page7.png
2025-11-21 00:35:26,018 - INFO - root - 论文《AVATAAR: Agentic Video Answering via Temporal Adaptive Alignment and Reasoning》的分析已保存到 ./export\vision_transformer\AVATAAR_Agentic_Video_Answering_via_Temporal_Adaptive_Alignment_and_Reasoning.md
2025-11-21 00:35:26,023 - INFO - root - 正在总结论文 36/40: From Low-Rank Features to Encoding Mismatch: Rethinking Feature Distillation in Vision Transformers
2025-11-21 00:35:26,024 - INFO - root - 正在提取论文图片到目录: ./export\vision_transformer\images\From_Low-Rank_Features_to_Encoding_Mismatch_Rethinking_Feature_Distillation_in_Vision_Transformers
2025-11-21 00:35:26,061 - INFO - root - 论文《From Low-Rank Features to Encoding Mismatch: Rethinking Feature Distillation in Vision Transformers》的分析已保存到 ./export\vision_transformer\From_Low-Rank_Features_to_Encoding_Mismatch_Rethinking_Feature_Distillation_in_Vision_Transformers.md
2025-11-21 00:35:26,067 - INFO - root - 正在总结论文 37/40: Integrability of Siegel transforms and an application
2025-11-21 00:35:26,070 - INFO - root - 正在提取论文图片到目录: ./export\vision_transformer\images\Integrability_of_Siegel_transforms_and_an_application
2025-11-21 00:35:26,536 - INFO - root - 已保存图片 1/10：./export\vision_transformer\images\Integrability_of_Siegel_transforms_and_an_application\figure_1_page8.png
2025-11-21 00:35:26,544 - INFO - root - 成功添加图片 1：./export\vision_transformer\images\Integrability_of_Siegel_transforms_and_an_application\figure_1_page8.png
2025-11-21 00:35:26,546 - INFO - root - 论文《Integrability of Siegel transforms and an application》的分析已保存到 ./export\vision_transformer\Integrability_of_Siegel_transforms_and_an_application.md
2025-11-21 00:35:26,550 - INFO - root - 正在总结论文 38/40: SRPO: Self-Referential Policy Optimization for Vision-Language-Action Models
2025-11-21 00:35:26,551 - INFO - root - 正在提取论文图片到目录: ./export\vision_transformer\images\SRPO_Self-Referential_Policy_Optimization_for_Vision-Language-Action_Models
2025-11-21 00:35:27,556 - INFO - root - 已保存图片 1/10：./export\vision_transformer\images\SRPO_Self-Referential_Policy_Optimization_for_Vision-Language-Action_Models\figure_1_page11.jpeg
2025-11-21 00:35:27,713 - INFO - root - 已保存图片 2/10：./export\vision_transformer\images\SRPO_Self-Referential_Policy_Optimization_for_Vision-Language-Action_Models\figure_2_page11.jpeg
2025-11-21 00:35:27,872 - INFO - root - 已保存图片 3/10：./export\vision_transformer\images\SRPO_Self-Referential_Policy_Optimization_for_Vision-Language-Action_Models\figure_3_page11.jpeg
2025-11-21 00:35:28,004 - INFO - root - 已保存图片 4/10：./export\vision_transformer\images\SRPO_Self-Referential_Policy_Optimization_for_Vision-Language-Action_Models\figure_4_page10.jpeg
2025-11-21 00:35:28,147 - INFO - root - 已保存图片 5/10：./export\vision_transformer\images\SRPO_Self-Referential_Policy_Optimization_for_Vision-Language-Action_Models\figure_5_page10.jpeg
2025-11-21 00:35:28,269 - INFO - root - 已保存图片 6/10：./export\vision_transformer\images\SRPO_Self-Referential_Policy_Optimization_for_Vision-Language-Action_Models\figure_6_page10.jpeg
2025-11-21 00:35:28,389 - INFO - root - 已保存图片 7/10：./export\vision_transformer\images\SRPO_Self-Referential_Policy_Optimization_for_Vision-Language-Action_Models\figure_7_page10.jpeg
2025-11-21 00:35:28,491 - INFO - root - 已保存图片 8/10：./export\vision_transformer\images\SRPO_Self-Referential_Policy_Optimization_for_Vision-Language-Action_Models\figure_8_page24.jpeg
2025-11-21 00:35:28,606 - INFO - root - 已保存图片 9/10：./export\vision_transformer\images\SRPO_Self-Referential_Policy_Optimization_for_Vision-Language-Action_Models\figure_9_page24.jpeg
2025-11-21 00:35:28,714 - INFO - root - 已保存图片 10/10：./export\vision_transformer\images\SRPO_Self-Referential_Policy_Optimization_for_Vision-Language-Action_Models\figure_10_page24.jpeg
2025-11-21 00:35:28,738 - INFO - root - 成功添加图片 1：./export\vision_transformer\images\SRPO_Self-Referential_Policy_Optimization_for_Vision-Language-Action_Models\figure_1_page11.jpeg
2025-11-21 00:35:28,738 - INFO - root - 成功添加图片 2：./export\vision_transformer\images\SRPO_Self-Referential_Policy_Optimization_for_Vision-Language-Action_Models\figure_2_page11.jpeg
2025-11-21 00:35:28,739 - INFO - root - 成功添加图片 3：./export\vision_transformer\images\SRPO_Self-Referential_Policy_Optimization_for_Vision-Language-Action_Models\figure_3_page11.jpeg
2025-11-21 00:35:28,739 - INFO - root - 成功添加图片 4：./export\vision_transformer\images\SRPO_Self-Referential_Policy_Optimization_for_Vision-Language-Action_Models\figure_4_page10.jpeg
2025-11-21 00:35:28,739 - INFO - root - 成功添加图片 5：./export\vision_transformer\images\SRPO_Self-Referential_Policy_Optimization_for_Vision-Language-Action_Models\figure_5_page10.jpeg
2025-11-21 00:35:28,740 - INFO - root - 成功添加图片 6：./export\vision_transformer\images\SRPO_Self-Referential_Policy_Optimization_for_Vision-Language-Action_Models\figure_6_page10.jpeg
2025-11-21 00:35:28,740 - INFO - root - 成功添加图片 7：./export\vision_transformer\images\SRPO_Self-Referential_Policy_Optimization_for_Vision-Language-Action_Models\figure_7_page10.jpeg
2025-11-21 00:35:28,741 - INFO - root - 成功添加图片 8：./export\vision_transformer\images\SRPO_Self-Referential_Policy_Optimization_for_Vision-Language-Action_Models\figure_8_page24.jpeg
2025-11-21 00:35:28,741 - INFO - root - 成功添加图片 9：./export\vision_transformer\images\SRPO_Self-Referential_Policy_Optimization_for_Vision-Language-Action_Models\figure_9_page24.jpeg
2025-11-21 00:35:28,742 - INFO - root - 成功添加图片 10：./export\vision_transformer\images\SRPO_Self-Referential_Policy_Optimization_for_Vision-Language-Action_Models\figure_10_page24.jpeg
2025-11-21 00:35:28,746 - INFO - root - 论文《SRPO: Self-Referential Policy Optimization for Vision-Language-Action Models》的分析已保存到 ./export\vision_transformer\SRPO_Self-Referential_Policy_Optimization_for_Vision-Language-Action_Models.md
2025-11-21 00:35:28,754 - INFO - root - 正在总结论文 39/40: Transferable Dual-Domain Feature Importance Attack against AI-Generated Image Detector
2025-11-21 00:35:28,758 - INFO - root - 正在提取论文图片到目录: ./export\vision_transformer\images\Transferable_Dual-Domain_Feature_Importance_Attack_against_AI-Generated_Image_Detector
2025-11-21 00:35:28,925 - INFO - root - 已保存图片 1/10：./export\vision_transformer\images\Transferable_Dual-Domain_Feature_Importance_Attack_against_AI-Generated_Image_Detector\figure_1_page3.jpeg
2025-11-21 00:35:28,993 - INFO - root - 已保存图片 2/10：./export\vision_transformer\images\Transferable_Dual-Domain_Feature_Importance_Attack_against_AI-Generated_Image_Detector\figure_2_page3.jpeg
2025-11-21 00:35:29,066 - INFO - root - 已保存图片 3/10：./export\vision_transformer\images\Transferable_Dual-Domain_Feature_Importance_Attack_against_AI-Generated_Image_Detector\figure_3_page3.jpeg
2025-11-21 00:35:29,137 - INFO - root - 已保存图片 4/10：./export\vision_transformer\images\Transferable_Dual-Domain_Feature_Importance_Attack_against_AI-Generated_Image_Detector\figure_4_page3.jpeg
2025-11-21 00:35:29,213 - INFO - root - 已保存图片 5/10：./export\vision_transformer\images\Transferable_Dual-Domain_Feature_Importance_Attack_against_AI-Generated_Image_Detector\figure_5_page3.jpeg
2025-11-21 00:35:29,284 - INFO - root - 已保存图片 6/10：./export\vision_transformer\images\Transferable_Dual-Domain_Feature_Importance_Attack_against_AI-Generated_Image_Detector\figure_6_page3.jpeg
2025-11-21 00:35:29,355 - INFO - root - 已保存图片 7/10：./export\vision_transformer\images\Transferable_Dual-Domain_Feature_Importance_Attack_against_AI-Generated_Image_Detector\figure_7_page3.jpeg
2025-11-21 00:35:29,424 - INFO - root - 已保存图片 8/10：./export\vision_transformer\images\Transferable_Dual-Domain_Feature_Importance_Attack_against_AI-Generated_Image_Detector\figure_8_page3.jpeg
2025-11-21 00:35:29,499 - INFO - root - 已保存图片 9/10：./export\vision_transformer\images\Transferable_Dual-Domain_Feature_Importance_Attack_against_AI-Generated_Image_Detector\figure_9_page3.jpeg
2025-11-21 00:35:29,566 - INFO - root - 已保存图片 10/10：./export\vision_transformer\images\Transferable_Dual-Domain_Feature_Importance_Attack_against_AI-Generated_Image_Detector\figure_10_page3.jpeg
2025-11-21 00:35:29,573 - INFO - root - 成功添加图片 1：./export\vision_transformer\images\Transferable_Dual-Domain_Feature_Importance_Attack_against_AI-Generated_Image_Detector\figure_1_page3.jpeg
2025-11-21 00:35:29,574 - INFO - root - 成功添加图片 2：./export\vision_transformer\images\Transferable_Dual-Domain_Feature_Importance_Attack_against_AI-Generated_Image_Detector\figure_2_page3.jpeg
2025-11-21 00:35:29,575 - INFO - root - 成功添加图片 3：./export\vision_transformer\images\Transferable_Dual-Domain_Feature_Importance_Attack_against_AI-Generated_Image_Detector\figure_3_page3.jpeg
2025-11-21 00:35:29,575 - INFO - root - 成功添加图片 4：./export\vision_transformer\images\Transferable_Dual-Domain_Feature_Importance_Attack_against_AI-Generated_Image_Detector\figure_4_page3.jpeg
2025-11-21 00:35:29,575 - INFO - root - 成功添加图片 5：./export\vision_transformer\images\Transferable_Dual-Domain_Feature_Importance_Attack_against_AI-Generated_Image_Detector\figure_5_page3.jpeg
2025-11-21 00:35:29,576 - INFO - root - 成功添加图片 6：./export\vision_transformer\images\Transferable_Dual-Domain_Feature_Importance_Attack_against_AI-Generated_Image_Detector\figure_6_page3.jpeg
2025-11-21 00:35:29,576 - INFO - root - 成功添加图片 7：./export\vision_transformer\images\Transferable_Dual-Domain_Feature_Importance_Attack_against_AI-Generated_Image_Detector\figure_7_page3.jpeg
2025-11-21 00:35:29,576 - INFO - root - 成功添加图片 8：./export\vision_transformer\images\Transferable_Dual-Domain_Feature_Importance_Attack_against_AI-Generated_Image_Detector\figure_8_page3.jpeg
2025-11-21 00:35:29,576 - INFO - root - 成功添加图片 9：./export\vision_transformer\images\Transferable_Dual-Domain_Feature_Importance_Attack_against_AI-Generated_Image_Detector\figure_9_page3.jpeg
2025-11-21 00:35:29,578 - INFO - root - 成功添加图片 10：./export\vision_transformer\images\Transferable_Dual-Domain_Feature_Importance_Attack_against_AI-Generated_Image_Detector\figure_10_page3.jpeg
2025-11-21 00:35:29,586 - INFO - root - 论文《Transferable Dual-Domain Feature Importance Attack against AI-Generated Image Detector》的分析已保存到 ./export\vision_transformer\Transferable_Dual-Domain_Feature_Importance_Attack_against_AI-Generated_Image_Detector.md
2025-11-21 00:35:29,591 - INFO - root - 正在总结论文 40/40: Multi-Stage Residual-Aware Unsupervised Deep Learning Framework for Consistent Ultrasound Strain Elastography
2025-11-21 00:35:29,592 - INFO - root - 正在提取论文图片到目录: ./export\vision_transformer\images\Multi-Stage_Residual-Aware_Unsupervised_Deep_Learning_Framework_for_Consistent_Ultrasound_Strain_Ela
2025-11-21 00:35:43,711 - INFO - root - 已保存图片 1/10：./export\vision_transformer\images\Multi-Stage_Residual-Aware_Unsupervised_Deep_Learning_Framework_for_Consistent_Ultrasound_Strain_Ela\figure_1_page8.png
2025-11-21 00:35:44,118 - INFO - root - 已保存图片 2/10：./export\vision_transformer\images\Multi-Stage_Residual-Aware_Unsupervised_Deep_Learning_Framework_for_Consistent_Ultrasound_Strain_Ela\figure_2_page9.png
2025-11-21 00:35:44,375 - INFO - root - 已保存图片 3/10：./export\vision_transformer\images\Multi-Stage_Residual-Aware_Unsupervised_Deep_Learning_Framework_for_Consistent_Ultrasound_Strain_Ela\figure_3_page10.png
2025-11-21 00:35:44,621 - INFO - root - 已保存图片 4/10：./export\vision_transformer\images\Multi-Stage_Residual-Aware_Unsupervised_Deep_Learning_Framework_for_Consistent_Ultrasound_Strain_Ela\figure_4_page10.png
2025-11-21 00:35:44,832 - INFO - root - 已保存图片 5/10：./export\vision_transformer\images\Multi-Stage_Residual-Aware_Unsupervised_Deep_Learning_Framework_for_Consistent_Ultrasound_Strain_Ela\figure_5_page10.png
2025-11-21 00:35:45,066 - INFO - root - 已保存图片 6/10：./export\vision_transformer\images\Multi-Stage_Residual-Aware_Unsupervised_Deep_Learning_Framework_for_Consistent_Ultrasound_Strain_Ela\figure_6_page10.png
2025-11-21 00:35:45,268 - INFO - root - 已保存图片 7/10：./export\vision_transformer\images\Multi-Stage_Residual-Aware_Unsupervised_Deep_Learning_Framework_for_Consistent_Ultrasound_Strain_Ela\figure_7_page4.png
2025-11-21 00:35:45,442 - INFO - root - 已保存图片 8/10：./export\vision_transformer\images\Multi-Stage_Residual-Aware_Unsupervised_Deep_Learning_Framework_for_Consistent_Ultrasound_Strain_Ela\figure_8_page5.png
2025-11-21 00:35:45,596 - INFO - root - 已保存图片 9/10：./export\vision_transformer\images\Multi-Stage_Residual-Aware_Unsupervised_Deep_Learning_Framework_for_Consistent_Ultrasound_Strain_Ela\figure_9_page10.png
2025-11-21 00:35:45,810 - INFO - root - 已保存图片 10/10：./export\vision_transformer\images\Multi-Stage_Residual-Aware_Unsupervised_Deep_Learning_Framework_for_Consistent_Ultrasound_Strain_Ela\figure_10_page6.png
2025-11-21 00:35:45,874 - INFO - root - 成功添加图片 1：./export\vision_transformer\images\Multi-Stage_Residual-Aware_Unsupervised_Deep_Learning_Framework_for_Consistent_Ultrasound_Strain_Ela\figure_1_page8.png
2025-11-21 00:35:45,874 - INFO - root - 成功添加图片 2：./export\vision_transformer\images\Multi-Stage_Residual-Aware_Unsupervised_Deep_Learning_Framework_for_Consistent_Ultrasound_Strain_Ela\figure_2_page9.png
2025-11-21 00:35:45,875 - INFO - root - 成功添加图片 3：./export\vision_transformer\images\Multi-Stage_Residual-Aware_Unsupervised_Deep_Learning_Framework_for_Consistent_Ultrasound_Strain_Ela\figure_3_page10.png
2025-11-21 00:35:45,875 - INFO - root - 成功添加图片 4：./export\vision_transformer\images\Multi-Stage_Residual-Aware_Unsupervised_Deep_Learning_Framework_for_Consistent_Ultrasound_Strain_Ela\figure_4_page10.png
2025-11-21 00:35:45,875 - INFO - root - 成功添加图片 5：./export\vision_transformer\images\Multi-Stage_Residual-Aware_Unsupervised_Deep_Learning_Framework_for_Consistent_Ultrasound_Strain_Ela\figure_5_page10.png
2025-11-21 00:35:45,875 - INFO - root - 成功添加图片 6：./export\vision_transformer\images\Multi-Stage_Residual-Aware_Unsupervised_Deep_Learning_Framework_for_Consistent_Ultrasound_Strain_Ela\figure_6_page10.png
2025-11-21 00:35:45,876 - INFO - root - 成功添加图片 7：./export\vision_transformer\images\Multi-Stage_Residual-Aware_Unsupervised_Deep_Learning_Framework_for_Consistent_Ultrasound_Strain_Ela\figure_7_page4.png
2025-11-21 00:35:45,876 - INFO - root - 成功添加图片 8：./export\vision_transformer\images\Multi-Stage_Residual-Aware_Unsupervised_Deep_Learning_Framework_for_Consistent_Ultrasound_Strain_Ela\figure_8_page5.png
2025-11-21 00:35:45,876 - INFO - root - 成功添加图片 9：./export\vision_transformer\images\Multi-Stage_Residual-Aware_Unsupervised_Deep_Learning_Framework_for_Consistent_Ultrasound_Strain_Ela\figure_9_page10.png
2025-11-21 00:35:45,876 - INFO - root - 成功添加图片 10：./export\vision_transformer\images\Multi-Stage_Residual-Aware_Unsupervised_Deep_Learning_Framework_for_Consistent_Ultrasound_Strain_Ela\figure_10_page6.png
2025-11-21 00:35:45,881 - INFO - root - 论文《Multi-Stage Residual-Aware Unsupervised Deep Learning Framework for Consistent Ultrasound Strain Elastography》的分析已保存到 ./export\vision_transformer\Multi-Stage_Residual-Aware_Unsupervised_Deep_Learning_Framework_for_Consistent_Ultrasound_Strain_Ela.md
2025-11-21 00:35:45,890 - INFO - root - --- 论文总结阶段结束 ---
2025-11-21 00:35:45,890 - INFO - root - --- 开始生成 Excel 报告 (包含 40 篇论文) ---
2025-11-21 00:35:45,940 - INFO - root - 未找到旧 Excel 文件。正在创建新文件: export\vision_transformer_summary.xlsx
2025-11-21 00:35:46,024 - INFO - root - 成功保存 Excel: export\vision_transformer_summary.xlsx
2025-11-21 00:35:46,025 - INFO - root - 已生成或更新汇总 Excel 表格: export\vision_transformer_summary.xlsx
2025-11-21 00:35:46,026 - INFO - root - 总运行时间: 235.14 seconds
