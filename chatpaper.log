2025-11-09 00:54:09,371 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-09 00:54:09,374 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-09 00:54:09,376 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-09 00:54:09,380 - WARNING - root - 初始化 LLM 客户端失败: unexpected indent (llm_client.py, line 96)
2025-11-09 00:54:09,382 - INFO - root - === 运行配置 ===
2025-11-09 00:54:09,382 - INFO - root - 处理模式: 本地PDF文件
2025-11-09 00:54:09,382 - INFO - root - PDF目录: d:\ChatPaper\myPapers
2025-11-09 00:54:09,383 - INFO - root - 最大处理数量: 2
2025-11-09 00:54:09,384 - INFO - root - 保存图片: 是
2025-11-09 00:54:09,384 - INFO - root - 输出语言: 中文
2025-11-09 00:54:09,385 - INFO - root - 强制重新处理: 否
2025-11-09 00:54:09,385 - INFO - root - ====================
2025-11-09 00:54:09,386 - INFO - root - 从本地目录读取PDF文件：d:\ChatPaper\myPapers
2025-11-09 00:54:10,505 - INFO - root - 成功加载PDF文件：demo.pdf
2025-11-09 00:54:10,510 - INFO - root - 正在总结论文 1/1: “Good Robot!”: Efﬁcient Reinforcement Learning for Multi-Step Visual Tasks with Sim to Real Transfer
2025-11-09 00:54:10,510 - ERROR - root - LLM 客户端未初始化，将使用备用响应。
2025-11-09 00:54:10,510 - ERROR - root - LLM 客户端未初始化，将使用备用响应。
2025-11-09 00:54:10,510 - ERROR - root - LLM 客户端未初始化，将使用备用响应。
2025-11-09 00:54:10,513 - INFO - root - 正在提取论文图片...
2025-11-09 00:54:10,726 - INFO - root - 已保存图片 1/10：./export\images_“Good Robot!”_ Efﬁcient Reinforcement Learning for Multi-Step Visual Tasks with\figure_1_page2.jpeg
2025-11-09 00:54:10,833 - INFO - root - 已保存图片 2/10：./export\images_“Good Robot!”_ Efﬁcient Reinforcement Learning for Multi-Step Visual Tasks with\figure_2_page1.jpeg
2025-11-09 00:54:10,920 - INFO - root - 已保存图片 3/10：./export\images_“Good Robot!”_ Efﬁcient Reinforcement Learning for Multi-Step Visual Tasks with\figure_3_page7.jpeg
2025-11-09 00:54:10,982 - INFO - root - 已保存图片 4/10：./export\images_“Good Robot!”_ Efﬁcient Reinforcement Learning for Multi-Step Visual Tasks with\figure_4_page4.jpeg
2025-11-09 00:54:11,019 - INFO - root - 已保存图片 5/10：./export\images_“Good Robot!”_ Efﬁcient Reinforcement Learning for Multi-Step Visual Tasks with\figure_5_page4.png
2025-11-09 00:54:11,053 - INFO - root - 已保存图片 6/10：./export\images_“Good Robot!”_ Efﬁcient Reinforcement Learning for Multi-Step Visual Tasks with\figure_6_page7.jpeg
2025-11-09 00:54:11,069 - INFO - root - 成功添加图片 1：./export\images_“Good Robot!”_ Efﬁcient Reinforcement Learning for Multi-Step Visual Tasks with\figure_1_page2.jpeg
2025-11-09 00:54:11,069 - INFO - root - 成功添加图片 2：./export\images_“Good Robot!”_ Efﬁcient Reinforcement Learning for Multi-Step Visual Tasks with\figure_2_page1.jpeg
2025-11-09 00:54:11,070 - INFO - root - 成功添加图片 3：./export\images_“Good Robot!”_ Efﬁcient Reinforcement Learning for Multi-Step Visual Tasks with\figure_3_page7.jpeg
2025-11-09 00:54:11,071 - INFO - root - 成功添加图片 4：./export\images_“Good Robot!”_ Efﬁcient Reinforcement Learning for Multi-Step Visual Tasks with\figure_4_page4.jpeg
2025-11-09 00:54:11,071 - INFO - root - 成功添加图片 5：./export\images_“Good Robot!”_ Efﬁcient Reinforcement Learning for Multi-Step Visual Tasks with\figure_5_page4.png
2025-11-09 00:54:11,071 - INFO - root - 成功添加图片 6：./export\images_“Good Robot!”_ Efﬁcient Reinforcement Learning for Multi-Step Visual Tasks with\figure_6_page7.jpeg
2025-11-09 00:54:11,076 - INFO - root - 论文《“Good Robot!”: Efﬁcient Reinforcement Learning for Multi-Step Visual Tasks with Sim to Real Transfer》的分析已保存到 ./export\“Good Robot!”_ Efﬁcient Reinforcement Learning for Multi-Step Visual Tasks with.md
2025-11-09 00:54:11,080 - INFO - root - summary time: 1.71 seconds
2025-11-09 00:56:18,518 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-09 00:56:18,518 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-09 00:56:18,518 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-09 00:56:18,518 - WARNING - root - 初始化 LLM 客户端失败: unexpected indent (llm_client.py, line 96)
2025-11-09 00:56:18,524 - INFO - root - === 运行配置 ===
2025-11-09 00:56:18,524 - INFO - root - 处理模式: 本地PDF文件
2025-11-09 00:56:18,524 - INFO - root - PDF目录: d:\ChatPaper\myPapers
2025-11-09 00:56:18,525 - INFO - root - 最大处理数量: 2
2025-11-09 00:56:18,525 - INFO - root - 保存图片: 是
2025-11-09 00:56:18,525 - INFO - root - 输出语言: 中文
2025-11-09 00:56:18,525 - INFO - root - 强制重新处理: 否
2025-11-09 00:56:18,527 - INFO - root - ====================
2025-11-09 00:56:18,527 - INFO - root - 从本地目录读取PDF文件：d:\ChatPaper\myPapers
2025-11-09 00:56:19,108 - INFO - root - 成功加载PDF文件：demo.pdf
2025-11-09 00:56:19,108 - INFO - root - 跳过已处理论文 “Good Robot!”: Efﬁcient Reinforcement Learning for Multi-Step Visual Tasks with Sim to Real Transfer：d:\ChatPaper\myPapers\demo.pdf
2025-11-09 00:56:19,108 - INFO - root - summary time: 0.59 seconds
2025-11-09 00:56:38,605 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-09 00:56:38,606 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-09 00:56:38,607 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-09 00:56:38,610 - WARNING - root - 初始化 LLM 客户端失败: unexpected indent (llm_client.py, line 96)
2025-11-09 00:56:38,610 - INFO - root - === 运行配置 ===
2025-11-09 00:56:38,611 - INFO - root - 处理模式: 本地PDF文件
2025-11-09 00:56:38,611 - INFO - root - PDF目录: d:\ChatPaper\myPapers
2025-11-09 00:56:38,611 - INFO - root - 最大处理数量: 2
2025-11-09 00:56:38,611 - INFO - root - 保存图片: 是
2025-11-09 00:56:38,611 - INFO - root - 输出语言: 中文
2025-11-09 00:56:38,611 - INFO - root - 强制重新处理: 否
2025-11-09 00:56:38,611 - INFO - root - ====================
2025-11-09 00:56:38,611 - INFO - root - 从本地目录读取PDF文件：d:\ChatPaper\myPapers
2025-11-09 00:56:39,256 - INFO - root - 成功加载PDF文件：demo.pdf
2025-11-09 00:56:39,257 - INFO - root - 跳过已处理论文 “Good Robot!”: Efﬁcient Reinforcement Learning for Multi-Step Visual Tasks with Sim to Real Transfer：d:\ChatPaper\myPapers\demo.pdf
2025-11-09 00:56:39,257 - INFO - root - summary time: 0.65 seconds
2025-11-09 00:57:37,925 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-09 00:57:37,926 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-09 00:57:37,928 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-09 00:57:39,179 - INFO - root - LLMClient: trying model gemini-2.5-flash
2025-11-09 00:57:44,038 - INFO - root - LLMClient: initialized model gemini-2.5-flash
2025-11-09 00:57:44,039 - INFO - root - 使用 LLM 模型: gemini-2.5-flash
2025-11-09 00:57:44,040 - INFO - root - === 运行配置 ===
2025-11-09 00:57:44,041 - INFO - root - 处理模式: 本地PDF文件
2025-11-09 00:57:44,045 - INFO - root - PDF目录: d:\ChatPaper\myPapers
2025-11-09 00:57:44,049 - INFO - root - 最大处理数量: 2
2025-11-09 00:57:44,049 - INFO - root - 保存图片: 是
2025-11-09 00:57:44,051 - INFO - root - 输出语言: 中文
2025-11-09 00:57:44,052 - INFO - root - 强制重新处理: 否
2025-11-09 00:57:44,053 - INFO - root - ====================
2025-11-09 00:57:44,054 - INFO - root - 从本地目录读取PDF文件：d:\ChatPaper\myPapers
2025-11-09 00:57:45,100 - INFO - root - 成功加载PDF文件：demo.pdf
2025-11-09 00:57:45,101 - INFO - root - 跳过已处理论文 “Good Robot!”: Efﬁcient Reinforcement Learning for Multi-Step Visual Tasks with Sim to Real Transfer：d:\ChatPaper\myPapers\demo.pdf
2025-11-09 00:57:45,102 - INFO - root - summary time: 7.18 seconds
2025-11-09 00:57:54,670 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-09 00:57:54,670 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-09 00:57:54,670 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-09 00:57:55,831 - INFO - root - LLMClient: trying model gemini-2.5-flash
2025-11-09 00:57:58,715 - INFO - root - LLMClient: initialized model gemini-2.5-flash
2025-11-09 00:57:58,716 - INFO - root - 使用 LLM 模型: gemini-2.5-flash
2025-11-09 00:57:58,718 - INFO - root - === 运行配置 ===
2025-11-09 00:57:58,719 - INFO - root - 处理模式: 本地PDF文件
2025-11-09 00:57:58,720 - INFO - root - PDF目录: d:\ChatPaper\myPapers
2025-11-09 00:57:58,721 - INFO - root - 最大处理数量: 2
2025-11-09 00:57:58,722 - INFO - root - 保存图片: 是
2025-11-09 00:57:58,723 - INFO - root - 输出语言: 中文
2025-11-09 00:57:58,724 - INFO - root - 强制重新处理: 否
2025-11-09 00:57:58,726 - INFO - root - ====================
2025-11-09 00:57:58,727 - INFO - root - 从本地目录读取PDF文件：d:\ChatPaper\myPapers
2025-11-09 00:57:59,367 - INFO - root - 成功加载PDF文件：demo.pdf
2025-11-09 00:57:59,367 - INFO - root - 跳过已处理论文 “Good Robot!”: Efﬁcient Reinforcement Learning for Multi-Step Visual Tasks with Sim to Real Transfer：d:\ChatPaper\myPapers\demo.pdf
2025-11-09 00:57:59,368 - INFO - root - summary time: 4.70 seconds
2025-11-09 00:58:27,401 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-09 00:58:27,401 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-09 00:58:27,405 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-09 00:58:28,300 - INFO - root - LLMClient: trying model gemini-2.5-flash
2025-11-09 00:58:33,329 - INFO - root - LLMClient: initialized model gemini-2.5-flash
2025-11-09 00:58:33,330 - INFO - root - 使用 LLM 模型: gemini-2.5-flash
2025-11-09 00:58:33,331 - INFO - root - === 运行配置 ===
2025-11-09 00:58:33,331 - INFO - root - 处理模式: arxiv在线搜索
2025-11-09 00:58:33,332 - INFO - root - 关键词: Quant
2025-11-09 00:58:33,332 - INFO - root - 查询: block float point
2025-11-09 00:58:33,332 - INFO - root - 排序: None
2025-11-09 00:58:33,332 - INFO - root - 最近天数: 180
2025-11-09 00:58:33,332 - INFO - root - 最大处理数量: 2
2025-11-09 00:58:33,333 - INFO - root - 保存图片: 是
2025-11-09 00:58:33,333 - INFO - root - 输出语言: 中文
2025-11-09 00:58:33,334 - INFO - root - 强制重新处理: 否
2025-11-09 00:58:33,335 - INFO - root - ====================
2025-11-09 00:58:33,335 - INFO - root - 使用 arXiv 搜索模式（通过 chat_arxiv 模块获取）
2025-11-09 00:59:13,415 - INFO - root - 正在总结论文 1/2: From Uniform to Adaptive: General Skip-Block Mechanisms for Efficient PDE Neural Operators
2025-11-09 00:59:51,953 - INFO - root - LLMClient: rate limit reached, sleeping 21.5s
2025-11-09 01:00:34,660 - INFO - root - 正在提取论文图片...
2025-11-09 01:14:08,444 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-09 01:14:08,444 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-09 01:14:08,449 - WARNING - root - LLMClient: Gemini API key not provided. LLM disabled.
2025-11-09 01:14:08,449 - INFO - root - LLM 未初始化或不可用，后续生成将返回备用消息
2025-11-09 01:14:08,454 - INFO - root - 已创建目录：D:\ChatPaper\src\myPapers
2025-11-09 01:14:08,454 - INFO - root - === 运行配置 ===
2025-11-09 01:14:08,455 - INFO - root - 处理模式: arxiv在线搜索
2025-11-09 01:14:08,455 - INFO - root - 关键词: Quant
2025-11-09 01:14:08,456 - INFO - root - 查询: block float point
2025-11-09 01:14:08,456 - INFO - root - 排序: None
2025-11-09 01:14:08,457 - INFO - root - 最近天数: 180
2025-11-09 01:14:08,458 - INFO - root - 最大处理数量: 2
2025-11-09 01:14:08,458 - INFO - root - 保存图片: 是
2025-11-09 01:14:08,460 - INFO - root - 输出语言: 中文
2025-11-09 01:14:08,460 - INFO - root - 强制重新处理: 否
2025-11-09 01:14:08,461 - INFO - root - ====================
2025-11-09 01:14:08,461 - INFO - root - 使用 arXiv 搜索模式（通过 chat_arxiv 模块获取）
2025-11-09 01:14:18,810 - INFO - root - 正在总结论文 1/2: From Uniform to Adaptive: General Skip-Block Mechanisms for Efficient PDE Neural Operators
2025-11-09 01:14:18,810 - INFO - root - 正在提取论文图片...
2025-11-09 01:14:19,325 - INFO - root - 已保存图片 1/10：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_1_page3.png
2025-11-09 01:14:19,410 - INFO - root - 已保存图片 2/10：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_2_page8.png
2025-11-09 01:14:19,483 - INFO - root - 已保存图片 3/10：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_3_page8.png
2025-11-09 01:14:19,540 - INFO - root - 已保存图片 4/10：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_4_page9.png
2025-11-09 01:14:19,595 - INFO - root - 已保存图片 5/10：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_5_page9.png
2025-11-09 01:14:19,662 - INFO - root - 已保存图片 6/10：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_6_page4.png
2025-11-09 01:14:19,707 - INFO - root - 已保存图片 7/10：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_7_page4.png
2025-11-09 01:14:19,783 - INFO - root - 已保存图片 8/10：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_8_page16.png
2025-11-09 01:14:19,793 - INFO - root - 已保存图片 9/10：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_9_page4.png
2025-11-09 01:14:19,810 - INFO - root - 已保存图片 10/10：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_10_page4.png
2025-11-09 01:14:19,815 - INFO - root - 成功添加图片 1：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_1_page3.png
2025-11-09 01:14:19,815 - INFO - root - 成功添加图片 2：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_2_page8.png
2025-11-09 01:14:19,816 - INFO - root - 成功添加图片 3：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_3_page8.png
2025-11-09 01:14:19,818 - INFO - root - 成功添加图片 4：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_4_page9.png
2025-11-09 01:14:19,820 - INFO - root - 成功添加图片 5：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_5_page9.png
2025-11-09 01:14:19,820 - INFO - root - 成功添加图片 6：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_6_page4.png
2025-11-09 01:14:19,822 - INFO - root - 成功添加图片 7：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_7_page4.png
2025-11-09 01:14:19,825 - INFO - root - 成功添加图片 8：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_8_page16.png
2025-11-09 01:14:19,826 - INFO - root - 成功添加图片 9：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_9_page4.png
2025-11-09 01:14:19,827 - INFO - root - 成功添加图片 10：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_10_page4.png
2025-11-09 01:14:19,829 - INFO - root - 论文《From Uniform to Adaptive: General Skip-Block Mechanisms for Efficient PDE Neural Operators》的分析已保存到 ./export\From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural.md
2025-11-09 01:14:19,836 - INFO - root - 正在总结论文 2/2: INT v.s. FP: A Comprehensive Study of Fine-Grained Low-bit Quantization Formats
2025-11-09 01:14:19,845 - INFO - root - 正在提取论文图片...
2025-11-09 01:14:20,289 - INFO - root - 已保存图片 1/10：./export\images_INT v.s. FP_ A Comprehensive Study of Fine-Grained Low-bit Quantization Formats\figure_1_page9.png
2025-11-09 01:14:20,354 - INFO - root - 已保存图片 2/10：./export\images_INT v.s. FP_ A Comprehensive Study of Fine-Grained Low-bit Quantization Formats\figure_2_page1.png
2025-11-09 01:14:20,388 - INFO - root - 已保存图片 3/10：./export\images_INT v.s. FP_ A Comprehensive Study of Fine-Grained Low-bit Quantization Formats\figure_3_page1.jpeg
2025-11-09 01:14:20,450 - INFO - root - 已保存图片 4/10：./export\images_INT v.s. FP_ A Comprehensive Study of Fine-Grained Low-bit Quantization Formats\figure_4_page9.png
2025-11-09 01:14:20,454 - INFO - root - 成功添加图片 1：./export\images_INT v.s. FP_ A Comprehensive Study of Fine-Grained Low-bit Quantization Formats\figure_1_page9.png
2025-11-09 01:14:20,454 - INFO - root - 成功添加图片 2：./export\images_INT v.s. FP_ A Comprehensive Study of Fine-Grained Low-bit Quantization Formats\figure_2_page1.png
2025-11-09 01:14:20,455 - INFO - root - 成功添加图片 3：./export\images_INT v.s. FP_ A Comprehensive Study of Fine-Grained Low-bit Quantization Formats\figure_3_page1.jpeg
2025-11-09 01:14:20,455 - INFO - root - 成功添加图片 4：./export\images_INT v.s. FP_ A Comprehensive Study of Fine-Grained Low-bit Quantization Formats\figure_4_page9.png
2025-11-09 01:14:20,457 - INFO - root - 论文《INT v.s. FP: A Comprehensive Study of Fine-Grained Low-bit Quantization Formats》的分析已保存到 ./export\INT v.s. FP_ A Comprehensive Study of Fine-Grained Low-bit Quantization Formats.md
2025-11-09 01:14:20,461 - INFO - root - summary time: 12.02 seconds
2025-11-09 01:17:35,499 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-09 01:17:35,499 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-09 01:17:35,499 - WARNING - root - LLMClient: Gemini API key not provided. LLM disabled.
2025-11-09 01:17:35,499 - INFO - root - LLM 未初始化或不可用，后续生成将返回备用消息
2025-11-09 01:17:35,499 - INFO - root - === 运行配置 ===
2025-11-09 01:17:35,499 - INFO - root - 处理模式: arxiv在线搜索
2025-11-09 01:17:35,499 - INFO - root - 关键词: Quant
2025-11-09 01:17:35,499 - INFO - root - 查询: block float point
2025-11-09 01:17:35,499 - INFO - root - 排序: None
2025-11-09 01:17:35,499 - INFO - root - 最近天数: 180
2025-11-09 01:17:35,499 - INFO - root - 最大处理数量: 2
2025-11-09 01:17:35,499 - INFO - root - 保存图片: 是
2025-11-09 01:17:35,499 - INFO - root - 输出语言: 中文
2025-11-09 01:17:35,499 - INFO - root - 强制重新处理: 否
2025-11-09 01:17:35,499 - INFO - root - ====================
2025-11-09 01:17:35,499 - INFO - root - 使用 arXiv 搜索模式（通过 chat_arxiv 模块获取）
2025-11-09 01:17:59,345 - INFO - root - 正在总结论文 1/2: From Uniform to Adaptive: General Skip-Block Mechanisms for Efficient PDE Neural Operators
2025-11-09 01:17:59,346 - INFO - root - 正在提取论文图片...
2025-11-09 01:17:59,741 - INFO - root - 已保存图片 1/10：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_1_page3.png
2025-11-09 01:17:59,811 - INFO - root - 已保存图片 2/10：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_2_page8.png
2025-11-09 01:17:59,872 - INFO - root - 已保存图片 3/10：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_3_page8.png
2025-11-09 01:17:59,923 - INFO - root - 已保存图片 4/10：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_4_page9.png
2025-11-09 01:18:00,011 - INFO - root - 已保存图片 5/10：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_5_page9.png
2025-11-09 01:18:00,104 - INFO - root - 已保存图片 6/10：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_6_page4.png
2025-11-09 01:18:00,147 - INFO - root - 已保存图片 7/10：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_7_page4.png
2025-11-09 01:18:00,211 - INFO - root - 已保存图片 8/10：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_8_page16.png
2025-11-09 01:18:00,221 - INFO - root - 已保存图片 9/10：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_9_page4.png
2025-11-09 01:18:00,239 - INFO - root - 已保存图片 10/10：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_10_page4.png
2025-11-09 01:18:00,241 - INFO - root - 成功添加图片 1：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_1_page3.png
2025-11-09 01:18:00,246 - INFO - root - 成功添加图片 2：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_2_page8.png
2025-11-09 01:18:00,246 - INFO - root - 成功添加图片 3：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_3_page8.png
2025-11-09 01:18:00,247 - INFO - root - 成功添加图片 4：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_4_page9.png
2025-11-09 01:18:00,247 - INFO - root - 成功添加图片 5：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_5_page9.png
2025-11-09 01:18:00,249 - INFO - root - 成功添加图片 6：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_6_page4.png
2025-11-09 01:18:00,249 - INFO - root - 成功添加图片 7：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_7_page4.png
2025-11-09 01:18:00,249 - INFO - root - 成功添加图片 8：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_8_page16.png
2025-11-09 01:18:00,249 - INFO - root - 成功添加图片 9：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_9_page4.png
2025-11-09 01:18:00,250 - INFO - root - 成功添加图片 10：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_10_page4.png
2025-11-09 01:18:00,253 - INFO - root - 论文《From Uniform to Adaptive: General Skip-Block Mechanisms for Efficient PDE Neural Operators》的分析已保存到 ./export\From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural-1.md
2025-11-09 01:18:00,268 - INFO - root - 正在总结论文 2/2: INT v.s. FP: A Comprehensive Study of Fine-Grained Low-bit Quantization Formats
2025-11-09 01:18:00,272 - INFO - root - 正在提取论文图片...
2025-11-09 01:18:00,811 - INFO - root - 已保存图片 1/10：./export\images_INT v.s. FP_ A Comprehensive Study of Fine-Grained Low-bit Quantization Formats\figure_1_page9.png
2025-11-09 01:18:00,888 - INFO - root - 已保存图片 2/10：./export\images_INT v.s. FP_ A Comprehensive Study of Fine-Grained Low-bit Quantization Formats\figure_2_page1.png
2025-11-09 01:18:00,915 - INFO - root - 已保存图片 3/10：./export\images_INT v.s. FP_ A Comprehensive Study of Fine-Grained Low-bit Quantization Formats\figure_3_page1.jpeg
2025-11-09 01:18:00,974 - INFO - root - 已保存图片 4/10：./export\images_INT v.s. FP_ A Comprehensive Study of Fine-Grained Low-bit Quantization Formats\figure_4_page9.png
2025-11-09 01:18:00,980 - INFO - root - 成功添加图片 1：./export\images_INT v.s. FP_ A Comprehensive Study of Fine-Grained Low-bit Quantization Formats\figure_1_page9.png
2025-11-09 01:18:00,981 - INFO - root - 成功添加图片 2：./export\images_INT v.s. FP_ A Comprehensive Study of Fine-Grained Low-bit Quantization Formats\figure_2_page1.png
2025-11-09 01:18:00,982 - INFO - root - 成功添加图片 3：./export\images_INT v.s. FP_ A Comprehensive Study of Fine-Grained Low-bit Quantization Formats\figure_3_page1.jpeg
2025-11-09 01:18:00,983 - INFO - root - 成功添加图片 4：./export\images_INT v.s. FP_ A Comprehensive Study of Fine-Grained Low-bit Quantization Formats\figure_4_page9.png
2025-11-09 01:18:00,985 - INFO - root - 论文《INT v.s. FP: A Comprehensive Study of Fine-Grained Low-bit Quantization Formats》的分析已保存到 ./export\INT v.s. FP_ A Comprehensive Study of Fine-Grained Low-bit Quantization Formats-1.md
2025-11-09 01:18:00,999 - INFO - root - summary time: 25.50 seconds
2025-11-09 01:18:24,953 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-09 01:18:24,953 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-09 01:18:24,953 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-09 01:18:26,047 - INFO - root - LLMClient: trying model gemini-2.5-flash
2025-11-09 01:18:30,078 - INFO - root - LLMClient: initialized model gemini-2.5-flash
2025-11-09 01:18:30,079 - INFO - root - 使用 LLM 模型: gemini-2.5-flash
2025-11-09 01:18:30,080 - INFO - root - === 运行配置 ===
2025-11-09 01:18:30,081 - INFO - root - 处理模式: arxiv在线搜索
2025-11-09 01:18:30,081 - INFO - root - 关键词: Quant
2025-11-09 01:18:30,082 - INFO - root - 查询: block float point
2025-11-09 01:18:30,082 - INFO - root - 排序: None
2025-11-09 01:18:30,082 - INFO - root - 最近天数: 180
2025-11-09 01:18:30,083 - INFO - root - 最大处理数量: 2
2025-11-09 01:18:30,083 - INFO - root - 保存图片: 是
2025-11-09 01:18:30,083 - INFO - root - 输出语言: 中文
2025-11-09 01:18:30,083 - INFO - root - 强制重新处理: 否
2025-11-09 01:18:30,084 - INFO - root - ====================
2025-11-09 01:18:30,084 - INFO - root - 使用 arXiv 搜索模式（通过 chat_arxiv 模块获取）
2025-11-09 01:18:42,682 - INFO - root - 正在总结论文 1/2: From Uniform to Adaptive: General Skip-Block Mechanisms for Efficient PDE Neural Operators
2025-11-09 01:19:21,628 - INFO - root - LLMClient: rate limit reached, sleeping 21.1s
2025-11-09 01:20:03,870 - INFO - root - 正在提取论文图片...
2025-11-09 01:20:04,695 - INFO - root - 已保存图片 1/10：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_1_page3.png
2025-11-09 01:20:04,870 - INFO - root - 已保存图片 2/10：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_2_page8.png
2025-11-09 01:20:05,078 - INFO - root - 已保存图片 3/10：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_3_page8.png
2025-11-09 01:20:05,256 - INFO - root - 已保存图片 4/10：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_4_page9.png
2025-11-09 01:20:05,391 - INFO - root - 已保存图片 5/10：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_5_page9.png
2025-11-09 01:20:05,493 - INFO - root - 已保存图片 6/10：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_6_page4.png
2025-11-09 01:20:05,603 - INFO - root - 已保存图片 7/10：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_7_page4.png
2025-11-09 01:20:05,681 - INFO - root - 已保存图片 8/10：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_8_page16.png
2025-11-09 01:20:05,703 - INFO - root - 已保存图片 9/10：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_9_page4.png
2025-11-09 01:20:05,726 - INFO - root - 已保存图片 10/10：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_10_page4.png
2025-11-09 01:20:05,732 - INFO - root - 成功添加图片 1：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_1_page3.png
2025-11-09 01:20:05,732 - INFO - root - 成功添加图片 2：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_2_page8.png
2025-11-09 01:20:05,734 - INFO - root - 成功添加图片 3：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_3_page8.png
2025-11-09 01:20:05,734 - INFO - root - 成功添加图片 4：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_4_page9.png
2025-11-09 01:20:05,734 - INFO - root - 成功添加图片 5：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_5_page9.png
2025-11-09 01:20:05,737 - INFO - root - 成功添加图片 6：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_6_page4.png
2025-11-09 01:20:05,737 - INFO - root - 成功添加图片 7：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_7_page4.png
2025-11-09 01:20:05,738 - INFO - root - 成功添加图片 8：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_8_page16.png
2025-11-09 01:20:05,739 - INFO - root - 成功添加图片 9：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_9_page4.png
2025-11-09 01:20:05,741 - INFO - root - 成功添加图片 10：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_10_page4.png
2025-11-09 01:20:05,749 - INFO - root - 论文《From Uniform to Adaptive: General Skip-Block Mechanisms for Efficient PDE Neural Operators》的分析已保存到 ./export\From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural-2.md
2025-11-09 01:20:05,752 - INFO - root - 正在总结论文 2/2: INT v.s. FP: A Comprehensive Study of Fine-Grained Low-bit Quantization Formats
2025-11-09 01:20:18,101 - INFO - root - LLMClient: rate limit reached, sleeping 24.6s
2025-11-09 01:21:36,061 - INFO - root - 正在提取论文图片...
2025-11-09 01:21:36,446 - INFO - root - 已保存图片 1/10：./export\images_INT v.s. FP_ A Comprehensive Study of Fine-Grained Low-bit Quantization Formats\figure_1_page9.png
2025-11-09 01:21:36,499 - INFO - root - 已保存图片 2/10：./export\images_INT v.s. FP_ A Comprehensive Study of Fine-Grained Low-bit Quantization Formats\figure_2_page1.png
2025-11-09 01:21:36,546 - INFO - root - 已保存图片 3/10：./export\images_INT v.s. FP_ A Comprehensive Study of Fine-Grained Low-bit Quantization Formats\figure_3_page1.jpeg
2025-11-09 01:21:36,592 - INFO - root - 已保存图片 4/10：./export\images_INT v.s. FP_ A Comprehensive Study of Fine-Grained Low-bit Quantization Formats\figure_4_page9.png
2025-11-09 01:21:36,604 - INFO - root - 成功添加图片 1：./export\images_INT v.s. FP_ A Comprehensive Study of Fine-Grained Low-bit Quantization Formats\figure_1_page9.png
2025-11-09 01:21:36,604 - INFO - root - 成功添加图片 2：./export\images_INT v.s. FP_ A Comprehensive Study of Fine-Grained Low-bit Quantization Formats\figure_2_page1.png
2025-11-09 01:21:36,604 - INFO - root - 成功添加图片 3：./export\images_INT v.s. FP_ A Comprehensive Study of Fine-Grained Low-bit Quantization Formats\figure_3_page1.jpeg
2025-11-09 01:21:36,604 - INFO - root - 成功添加图片 4：./export\images_INT v.s. FP_ A Comprehensive Study of Fine-Grained Low-bit Quantization Formats\figure_4_page9.png
2025-11-09 01:21:36,613 - INFO - root - 论文《INT v.s. FP: A Comprehensive Study of Fine-Grained Low-bit Quantization Formats》的分析已保存到 ./export\INT v.s. FP_ A Comprehensive Study of Fine-Grained Low-bit Quantization Formats-2.md
2025-11-09 01:21:36,618 - INFO - root - summary time: 191.66 seconds
2025-11-09 01:26:11,351 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-09 01:26:11,351 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-09 01:26:11,351 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-09 01:26:12,198 - INFO - root - LLMClient: trying model gemini-2.5-flash
2025-11-09 01:26:14,752 - INFO - root - LLMClient: initialized model gemini-2.5-flash
2025-11-09 01:26:14,752 - INFO - root - 使用 LLM 模型: gemini-2.5-flash
2025-11-09 01:26:14,753 - INFO - root - === 运行配置 ===
2025-11-09 01:26:14,754 - INFO - root - 处理模式: arxiv在线搜索
2025-11-09 01:26:14,755 - INFO - root - 关键词: Quant
2025-11-09 01:26:14,756 - INFO - root - 查询: block float point
2025-11-09 01:26:14,757 - INFO - root - 排序: None
2025-11-09 01:26:14,757 - INFO - root - 最近天数: 180
2025-11-09 01:26:14,759 - INFO - root - 最大处理数量: 2
2025-11-09 01:26:14,760 - INFO - root - 保存图片: 是
2025-11-09 01:26:14,760 - INFO - root - 输出语言: 中文
2025-11-09 01:26:14,761 - INFO - root - 强制重新处理: 否
2025-11-09 01:26:14,762 - INFO - root - ====================
2025-11-09 01:26:14,763 - INFO - root - 使用 arXiv 搜索模式（通过 chat_arxiv 模块获取）
2025-11-09 01:26:31,982 - INFO - root - 正在总结论文 1/2: From Uniform to Adaptive: General Skip-Block Mechanisms for Efficient PDE Neural Operators
2025-11-09 01:27:10,578 - INFO - root - LLMClient: rate limit reached, sleeping 21.4s
2025-11-09 01:27:51,208 - INFO - root - 正在提取论文图片...
2025-11-09 01:27:51,587 - INFO - root - 已保存图片 1/10：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_1_page3.png
2025-11-09 01:27:51,674 - INFO - root - 已保存图片 2/10：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_2_page8.png
2025-11-09 01:27:51,738 - INFO - root - 已保存图片 3/10：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_3_page8.png
2025-11-09 01:27:51,809 - INFO - root - 已保存图片 4/10：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_4_page9.png
2025-11-09 01:27:51,866 - INFO - root - 已保存图片 5/10：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_5_page9.png
2025-11-09 01:27:51,923 - INFO - root - 已保存图片 6/10：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_6_page4.png
2025-11-09 01:27:51,979 - INFO - root - 已保存图片 7/10：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_7_page4.png
2025-11-09 01:27:52,046 - INFO - root - 已保存图片 8/10：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_8_page16.png
2025-11-09 01:27:52,057 - INFO - root - 已保存图片 9/10：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_9_page4.png
2025-11-09 01:27:52,073 - INFO - root - 已保存图片 10/10：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_10_page4.png
2025-11-09 01:27:52,081 - INFO - root - 成功添加图片 1：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_1_page3.png
2025-11-09 01:27:52,081 - INFO - root - 成功添加图片 2：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_2_page8.png
2025-11-09 01:27:52,083 - INFO - root - 成功添加图片 3：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_3_page8.png
2025-11-09 01:27:52,083 - INFO - root - 成功添加图片 4：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_4_page9.png
2025-11-09 01:27:52,083 - INFO - root - 成功添加图片 5：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_5_page9.png
2025-11-09 01:27:52,085 - INFO - root - 成功添加图片 6：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_6_page4.png
2025-11-09 01:27:52,086 - INFO - root - 成功添加图片 7：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_7_page4.png
2025-11-09 01:27:52,087 - INFO - root - 成功添加图片 8：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_8_page16.png
2025-11-09 01:27:52,088 - INFO - root - 成功添加图片 9：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_9_page4.png
2025-11-09 01:27:52,089 - INFO - root - 成功添加图片 10：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_10_page4.png
2025-11-09 01:27:52,094 - INFO - root - 论文《From Uniform to Adaptive: General Skip-Block Mechanisms for Efficient PDE Neural Operators》的分析已保存到 ./export\From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural.md
2025-11-09 01:27:52,099 - INFO - root - 正在总结论文 2/2: INT v.s. FP: A Comprehensive Study of Fine-Grained Low-bit Quantization Formats
2025-11-09 01:28:03,710 - INFO - root - LLMClient: rate limit reached, sleeping 28.3s
2025-11-09 01:29:19,818 - INFO - root - 正在提取论文图片...
2025-11-09 01:29:20,248 - INFO - root - 已保存图片 1/10：./export\images_INT v.s. FP_ A Comprehensive Study of Fine-Grained Low-bit Quantization Formats\figure_1_page9.png
2025-11-09 01:29:20,306 - INFO - root - 已保存图片 2/10：./export\images_INT v.s. FP_ A Comprehensive Study of Fine-Grained Low-bit Quantization Formats\figure_2_page1.png
2025-11-09 01:29:20,332 - INFO - root - 已保存图片 3/10：./export\images_INT v.s. FP_ A Comprehensive Study of Fine-Grained Low-bit Quantization Formats\figure_3_page1.jpeg
2025-11-09 01:29:20,412 - INFO - root - 已保存图片 4/10：./export\images_INT v.s. FP_ A Comprehensive Study of Fine-Grained Low-bit Quantization Formats\figure_4_page9.png
2025-11-09 01:29:20,416 - INFO - root - 成功添加图片 1：./export\images_INT v.s. FP_ A Comprehensive Study of Fine-Grained Low-bit Quantization Formats\figure_1_page9.png
2025-11-09 01:29:20,417 - INFO - root - 成功添加图片 2：./export\images_INT v.s. FP_ A Comprehensive Study of Fine-Grained Low-bit Quantization Formats\figure_2_page1.png
2025-11-09 01:29:20,419 - INFO - root - 成功添加图片 3：./export\images_INT v.s. FP_ A Comprehensive Study of Fine-Grained Low-bit Quantization Formats\figure_3_page1.jpeg
2025-11-09 01:29:20,419 - INFO - root - 成功添加图片 4：./export\images_INT v.s. FP_ A Comprehensive Study of Fine-Grained Low-bit Quantization Formats\figure_4_page9.png
2025-11-09 01:29:20,424 - INFO - root - 论文《INT v.s. FP: A Comprehensive Study of Fine-Grained Low-bit Quantization Formats》的分析已保存到 ./export\INT v.s. FP_ A Comprehensive Study of Fine-Grained Low-bit Quantization Formats.md
2025-11-09 01:29:20,428 - INFO - root - summary time: 189.08 seconds
2025-11-09 01:32:09,191 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-09 01:32:09,191 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-09 01:32:09,191 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-09 01:32:10,153 - INFO - root - LLMClient: trying model gemini-2.5-flash
2025-11-09 01:32:14,357 - INFO - root - LLMClient: initialized model gemini-2.5-flash
2025-11-09 01:32:14,358 - INFO - root - 使用 LLM 模型: gemini-2.5-flash
2025-11-09 01:32:14,359 - INFO - root - === 运行配置 ===
2025-11-09 01:32:14,359 - INFO - root - 处理模式: arxiv在线搜索
2025-11-09 01:32:14,359 - INFO - root - 关键词: Quant
2025-11-09 01:32:14,360 - INFO - root - 查询: block float point quant
2025-11-09 01:32:14,361 - INFO - root - 排序: None
2025-11-09 01:32:14,361 - INFO - root - 最近天数: 180
2025-11-09 01:32:14,362 - INFO - root - 最大处理数量: 50
2025-11-09 01:32:14,363 - INFO - root - 保存图片: 是
2025-11-09 01:32:14,364 - INFO - root - 输出语言: 中文
2025-11-09 01:32:14,364 - INFO - root - 强制重新处理: 否
2025-11-09 01:32:14,365 - INFO - root - ====================
2025-11-09 01:32:14,366 - INFO - root - 使用 arXiv 搜索模式（通过 chat_arxiv 模块获取）
2025-11-09 01:32:15,526 - INFO - root - 没有找到要处理的论文，程序退出
2025-11-09 01:32:15,526 - INFO - root - summary time: 6.34 seconds
2025-11-09 01:33:18,608 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-09 01:33:18,608 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-09 01:33:18,608 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-09 01:33:19,613 - INFO - root - LLMClient: trying model gemini-2.5-flash
2025-11-09 01:33:22,894 - INFO - root - LLMClient: initialized model gemini-2.5-flash
2025-11-09 01:33:22,895 - INFO - root - 使用 LLM 模型: gemini-2.5-flash
2025-11-09 01:33:22,896 - INFO - root - === 运行配置 ===
2025-11-09 01:33:22,896 - INFO - root - 处理模式: arxiv在线搜索
2025-11-09 01:33:22,897 - INFO - root - 关键词: Quant
2025-11-09 01:33:22,898 - INFO - root - 查询: block float point
2025-11-09 01:33:22,899 - INFO - root - 排序: None
2025-11-09 01:33:22,899 - INFO - root - 最近天数: 180
2025-11-09 01:33:22,900 - INFO - root - 最大处理数量: 50
2025-11-09 01:33:22,901 - INFO - root - 保存图片: 是
2025-11-09 01:33:22,902 - INFO - root - 输出语言: 中文
2025-11-09 01:33:22,903 - INFO - root - 强制重新处理: 否
2025-11-09 01:33:22,904 - INFO - root - ====================
2025-11-09 01:33:22,904 - INFO - root - 使用 arXiv 搜索模式（通过 chat_arxiv 模块获取）
2025-11-09 01:35:28,889 - INFO - root - 正在总结论文 1/30: From Uniform to Adaptive: General Skip-Block Mechanisms for Efficient PDE Neural Operators
2025-11-09 01:36:07,843 - INFO - root - LLMClient: rate limit reached, sleeping 21.0s
2025-11-09 01:36:46,512 - INFO - root - 正在提取论文图片...
2025-11-09 01:36:46,941 - INFO - root - 已保存图片 1/10：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_1_page3.png
2025-11-09 01:36:47,012 - INFO - root - 已保存图片 2/10：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_2_page8.png
2025-11-09 01:36:47,088 - INFO - root - 已保存图片 3/10：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_3_page8.png
2025-11-09 01:36:47,156 - INFO - root - 已保存图片 4/10：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_4_page9.png
2025-11-09 01:36:47,208 - INFO - root - 已保存图片 5/10：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_5_page9.png
2025-11-09 01:36:47,265 - INFO - root - 已保存图片 6/10：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_6_page4.png
2025-11-09 01:36:47,312 - INFO - root - 已保存图片 7/10：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_7_page4.png
2025-11-09 01:36:47,369 - INFO - root - 已保存图片 8/10：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_8_page16.png
2025-11-09 01:36:47,382 - INFO - root - 已保存图片 9/10：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_9_page4.png
2025-11-09 01:36:47,403 - INFO - root - 已保存图片 10/10：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_10_page4.png
2025-11-09 01:36:47,408 - INFO - root - 成功添加图片 1：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_1_page3.png
2025-11-09 01:36:47,408 - INFO - root - 成功添加图片 2：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_2_page8.png
2025-11-09 01:36:47,410 - INFO - root - 成功添加图片 3：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_3_page8.png
2025-11-09 01:36:47,410 - INFO - root - 成功添加图片 4：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_4_page9.png
2025-11-09 01:36:47,410 - INFO - root - 成功添加图片 5：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_5_page9.png
2025-11-09 01:36:47,411 - INFO - root - 成功添加图片 6：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_6_page4.png
2025-11-09 01:36:47,411 - INFO - root - 成功添加图片 7：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_7_page4.png
2025-11-09 01:36:47,411 - INFO - root - 成功添加图片 8：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_8_page16.png
2025-11-09 01:36:47,411 - INFO - root - 成功添加图片 9：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_9_page4.png
2025-11-09 01:36:47,412 - INFO - root - 成功添加图片 10：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_10_page4.png
2025-11-09 01:36:47,418 - INFO - root - 论文《From Uniform to Adaptive: General Skip-Block Mechanisms for Efficient PDE Neural Operators》的分析已保存到 ./export\From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural.md
2025-11-09 01:36:47,423 - INFO - root - 正在总结论文 2/30: INT v.s. FP: A Comprehensive Study of Fine-Grained Low-bit Quantization Formats
2025-11-09 01:36:58,155 - INFO - root - LLMClient: rate limit reached, sleeping 30.7s
2025-11-09 01:38:16,887 - INFO - root - 正在提取论文图片...
2025-11-09 01:38:17,284 - INFO - root - 已保存图片 1/10：./export\images_INT v.s. FP_ A Comprehensive Study of Fine-Grained Low-bit Quantization Formats\figure_1_page9.png
2025-11-09 01:38:17,342 - INFO - root - 已保存图片 2/10：./export\images_INT v.s. FP_ A Comprehensive Study of Fine-Grained Low-bit Quantization Formats\figure_2_page1.png
2025-11-09 01:38:17,375 - INFO - root - 已保存图片 3/10：./export\images_INT v.s. FP_ A Comprehensive Study of Fine-Grained Low-bit Quantization Formats\figure_3_page1.jpeg
2025-11-09 01:38:17,449 - INFO - root - 已保存图片 4/10：./export\images_INT v.s. FP_ A Comprehensive Study of Fine-Grained Low-bit Quantization Formats\figure_4_page9.png
2025-11-09 01:38:17,451 - INFO - root - 成功添加图片 1：./export\images_INT v.s. FP_ A Comprehensive Study of Fine-Grained Low-bit Quantization Formats\figure_1_page9.png
2025-11-09 01:38:17,452 - INFO - root - 成功添加图片 2：./export\images_INT v.s. FP_ A Comprehensive Study of Fine-Grained Low-bit Quantization Formats\figure_2_page1.png
2025-11-09 01:38:17,452 - INFO - root - 成功添加图片 3：./export\images_INT v.s. FP_ A Comprehensive Study of Fine-Grained Low-bit Quantization Formats\figure_3_page1.jpeg
2025-11-09 01:38:17,453 - INFO - root - 成功添加图片 4：./export\images_INT v.s. FP_ A Comprehensive Study of Fine-Grained Low-bit Quantization Formats\figure_4_page9.png
2025-11-09 01:38:17,459 - INFO - root - 论文《INT v.s. FP: A Comprehensive Study of Fine-Grained Low-bit Quantization Formats》的分析已保存到 ./export\INT v.s. FP_ A Comprehensive Study of Fine-Grained Low-bit Quantization Formats.md
2025-11-09 01:38:17,460 - INFO - root - 正在总结论文 3/30: MX+: Pushing the Limits of Microscaling Formats for Efficient Large Language Model Serving
2025-11-09 01:38:17,464 - INFO - root - LLMClient: rate limit reached, sleeping 11.4s
2025-11-09 01:38:39,386 - INFO - root - LLMClient: rate limit reached, sleeping 17.3s
2025-11-09 01:39:27,594 - INFO - root - LLMClient: rate limit reached, sleeping 1.3s
2025-11-09 01:39:49,790 - INFO - root - 正在提取论文图片...
2025-11-09 01:39:49,913 - INFO - root - 已保存图片 1/10：./export\images_MX+_ Pushing the Limits of Microscaling Formats for Efficient Large Language Mod\figure_1_page3.png
2025-11-09 01:39:49,913 - INFO - root - 成功添加图片 1：./export\images_MX+_ Pushing the Limits of Microscaling Formats for Efficient Large Language Mod\figure_1_page3.png
2025-11-09 01:39:49,919 - INFO - root - 论文《MX+: Pushing the Limits of Microscaling Formats for Efficient Large Language Model Serving》的分析已保存到 ./export\MX+_ Pushing the Limits of Microscaling Formats for Efficient Large Language Mod.md
2025-11-09 01:39:49,920 - INFO - root - 正在总结论文 4/30: F-BFQ: Flexible Block Floating-Point Quantization Accelerator for LLMs
2025-11-09 01:39:49,924 - INFO - root - LLMClient: rate limit reached, sleeping 6.8s
2025-11-09 01:40:08,222 - INFO - root - LLMClient: rate limit reached, sleeping 20.7s
2025-11-09 01:41:47,120 - INFO - root - 正在提取论文图片...
2025-11-09 01:41:47,964 - INFO - root - 已保存图片 1/10：./export\images_F-BFQ_ Flexible Block Floating-Point Quantization Accelerator for LLMs\figure_1_page4.png
2025-11-09 01:41:48,120 - INFO - root - 已保存图片 2/10：./export\images_F-BFQ_ Flexible Block Floating-Point Quantization Accelerator for LLMs\figure_2_page3.png
2025-11-09 01:41:48,183 - INFO - root - 已保存图片 3/10：./export\images_F-BFQ_ Flexible Block Floating-Point Quantization Accelerator for LLMs\figure_3_page2.png
2025-11-09 01:41:48,190 - INFO - root - 成功添加图片 1：./export\images_F-BFQ_ Flexible Block Floating-Point Quantization Accelerator for LLMs\figure_1_page4.png
2025-11-09 01:41:48,190 - INFO - root - 成功添加图片 2：./export\images_F-BFQ_ Flexible Block Floating-Point Quantization Accelerator for LLMs\figure_2_page3.png
2025-11-09 01:41:48,191 - INFO - root - 成功添加图片 3：./export\images_F-BFQ_ Flexible Block Floating-Point Quantization Accelerator for LLMs\figure_3_page2.png
2025-11-09 01:41:48,197 - INFO - root - 论文《F-BFQ: Flexible Block Floating-Point Quantization Accelerator for LLMs》的分析已保存到 ./export\F-BFQ_ Flexible Block Floating-Point Quantization Accelerator for LLMs.md
2025-11-09 01:41:48,204 - INFO - root - 正在总结论文 5/30: Computationally Efficient Neural Receivers via Axial Self-Attention
2025-11-09 01:41:56,029 - INFO - root - LLMClient: rate limit reached, sleeping 30.6s
2025-11-09 01:43:18,247 - INFO - root - 正在提取论文图片...
2025-11-09 01:43:19,213 - INFO - root - 已保存图片 1/10：./export\images_Computationally Efficient Neural Receivers via Axial Self-Attention\figure_1_page5.png
2025-11-09 01:43:19,215 - INFO - root - 成功添加图片 1：./export\images_Computationally Efficient Neural Receivers via Axial Self-Attention\figure_1_page5.png
2025-11-09 01:43:19,222 - INFO - root - 论文《Computationally Efficient Neural Receivers via Axial Self-Attention》的分析已保存到 ./export\Computationally Efficient Neural Receivers via Axial Self-Attention.md
2025-11-09 01:43:19,222 - INFO - root - 正在总结论文 6/30: Efficient In-Memory Acceleration of Sparse Block Diagonal LLMs
2025-11-09 01:43:19,229 - INFO - root - LLMClient: rate limit reached, sleeping 7.4s
2025-11-09 01:43:37,171 - INFO - root - LLMClient: rate limit reached, sleeping 22.5s
2025-11-09 01:44:49,455 - INFO - root - 正在提取论文图片...
2025-11-09 01:44:49,522 - INFO - root - 已保存图片 1/10：./export\images_Efficient In-Memory Acceleration of Sparse Block Diagonal LLMs\figure_1_page3.png
2025-11-09 01:44:49,560 - INFO - root - 已保存图片 2/10：./export\images_Efficient In-Memory Acceleration of Sparse Block Diagonal LLMs\figure_2_page3.png
2025-11-09 01:44:49,671 - INFO - root - 已保存图片 3/10：./export\images_Efficient In-Memory Acceleration of Sparse Block Diagonal LLMs\figure_3_page3.png
2025-11-09 01:44:49,671 - INFO - root - 成功添加图片 1：./export\images_Efficient In-Memory Acceleration of Sparse Block Diagonal LLMs\figure_1_page3.png
2025-11-09 01:44:49,671 - INFO - root - 成功添加图片 2：./export\images_Efficient In-Memory Acceleration of Sparse Block Diagonal LLMs\figure_2_page3.png
2025-11-09 01:44:49,671 - INFO - root - 成功添加图片 3：./export\images_Efficient In-Memory Acceleration of Sparse Block Diagonal LLMs\figure_3_page3.png
2025-11-09 01:44:49,671 - INFO - root - 论文《Efficient In-Memory Acceleration of Sparse Block Diagonal LLMs》的分析已保存到 ./export\Efficient In-Memory Acceleration of Sparse Block Diagonal LLMs.md
2025-11-09 01:44:49,684 - INFO - root - 正在总结论文 7/30: Dissecting Transformers: A CLEAR Perspective towards Green AI
2025-11-09 01:44:49,685 - INFO - root - LLMClient: rate limit reached, sleeping 10.0s
2025-11-09 01:45:09,772 - INFO - root - LLMClient: rate limit reached, sleeping 19.1s
2025-11-09 09:31:54,038 - ERROR - root - LLMClient: generation error: 504 Deadline Exceeded
Traceback (most recent call last):
  File "D:\ChatPaper\llm_client.py", line 117, in generate
    resp = self.model.generate_content(prompt, safety_settings=self.safety_settings)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\google\generativeai\generative_models.py", line 331, in generate_content
    response = self._client.generate_content(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\google\ai\generativelanguage_v1beta\services\generative_service\client.py", line 835, in generate_content
    response = rpc(
               ^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\google\api_core\gapic_v1\method.py", line 131, in __call__
    return wrapped_func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 294, in retry_wrapped_func
    return retry_target(
           ^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 156, in retry_target
    next_sleep = _retry_error_helper(
                 ^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\google\api_core\retry\retry_base.py", line 214, in _retry_error_helper
    raise final_exc from source_exc
  File "D:\ChatPaper\.venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 147, in retry_target
    result = target()
             ^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\google\api_core\timeout.py", line 130, in func_with_timeout
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\google\api_core\grpc_helpers.py", line 77, in error_remapped_callable
    raise exceptions.from_grpc_error(exc) from exc
google.api_core.exceptions.DeadlineExceeded: 504 Deadline Exceeded
2025-11-09 09:32:55,151 - INFO - root - LLMClient: retry attempt 2 for generation
2025-11-09 09:33:40,009 - INFO - root - 正在提取论文图片...
2025-11-09 09:33:40,070 - WARNING - root - 处理页面 19 的图片 1 时出错：Image size (360000000 pixels) exceeds limit of 178956970 pixels, could be decompression bomb DOS attack.
2025-11-09 09:33:40,180 - INFO - root - 已保存图片 1/10：./export\images_Dissecting Transformers_ A CLEAR Perspective towards Green AI\figure_1_page3.png
2025-11-09 09:33:40,254 - INFO - root - 已保存图片 2/10：./export\images_Dissecting Transformers_ A CLEAR Perspective towards Green AI\figure_2_page3.png
2025-11-09 09:33:40,317 - INFO - root - 已保存图片 3/10：./export\images_Dissecting Transformers_ A CLEAR Perspective towards Green AI\figure_3_page3.png
2025-11-09 09:33:40,398 - INFO - root - 已保存图片 4/10：./export\images_Dissecting Transformers_ A CLEAR Perspective towards Green AI\figure_4_page3.png
2025-11-09 09:33:40,475 - INFO - root - 已保存图片 5/10：./export\images_Dissecting Transformers_ A CLEAR Perspective towards Green AI\figure_5_page3.png
2025-11-09 09:33:40,475 - INFO - root - 成功添加图片 1：./export\images_Dissecting Transformers_ A CLEAR Perspective towards Green AI\figure_1_page3.png
2025-11-09 09:33:40,475 - INFO - root - 成功添加图片 2：./export\images_Dissecting Transformers_ A CLEAR Perspective towards Green AI\figure_2_page3.png
2025-11-09 09:33:40,475 - INFO - root - 成功添加图片 3：./export\images_Dissecting Transformers_ A CLEAR Perspective towards Green AI\figure_3_page3.png
2025-11-09 09:33:40,475 - INFO - root - 成功添加图片 4：./export\images_Dissecting Transformers_ A CLEAR Perspective towards Green AI\figure_4_page3.png
2025-11-09 09:33:40,475 - INFO - root - 成功添加图片 5：./export\images_Dissecting Transformers_ A CLEAR Perspective towards Green AI\figure_5_page3.png
2025-11-09 09:33:40,482 - INFO - root - 论文《Dissecting Transformers: A CLEAR Perspective towards Green AI》的分析已保存到 ./export\Dissecting Transformers_ A CLEAR Perspective towards Green AI.md
2025-11-09 09:33:40,490 - INFO - root - 正在总结论文 8/30: Microscaling Floating Point Formats for Large Language Models
2025-11-09 09:33:40,490 - INFO - root - LLMClient: rate limit reached, sleeping 14.7s
2025-11-09 09:34:05,948 - INFO - root - LLMClient: rate limit reached, sleeping 16.8s
2025-11-09 09:34:49,182 - INFO - root - LLMClient: rate limit reached, sleeping 6.0s
2025-11-09 09:35:12,373 - INFO - root - 正在提取论文图片...
2025-11-09 09:35:12,402 - INFO - root - 论文《Microscaling Floating Point Formats for Large Language Models》的分析已保存到 ./export\Microscaling Floating Point Formats for Large Language Models.md
2025-11-09 09:35:12,406 - INFO - root - 正在总结论文 9/30: Automated and Scalable SEM Image Analysis of Perovskite Solar Cell Materials via a Deep Segmentation Framework
2025-11-09 09:35:12,414 - INFO - root - LLMClient: rate limit reached, sleeping 10.4s
2025-11-09 09:35:31,867 - INFO - root - LLMClient: rate limit reached, sleeping 23.3s
2025-11-09 09:36:20,645 - INFO - root - LLMClient: rate limit reached, sleeping 2.1s
2025-11-09 09:36:42,880 - INFO - root - 正在提取论文图片...
2025-11-09 09:37:17,872 - INFO - root - 已保存图片 1/10：./export\images_Automated and Scalable SEM Image Analysis of Perovskite Solar Cell Materials via\figure_1_page8.jpeg
2025-11-09 09:37:18,126 - INFO - root - 已保存图片 2/10：./export\images_Automated and Scalable SEM Image Analysis of Perovskite Solar Cell Materials via\figure_2_page5.jpeg
2025-11-09 09:37:18,414 - INFO - root - 已保存图片 3/10：./export\images_Automated and Scalable SEM Image Analysis of Perovskite Solar Cell Materials via\figure_3_page9.jpeg
2025-11-09 09:37:18,633 - INFO - root - 已保存图片 4/10：./export\images_Automated and Scalable SEM Image Analysis of Perovskite Solar Cell Materials via\figure_4_page9.jpeg
2025-11-09 09:37:18,850 - INFO - root - 已保存图片 5/10：./export\images_Automated and Scalable SEM Image Analysis of Perovskite Solar Cell Materials via\figure_5_page9.jpeg
2025-11-09 09:37:19,059 - INFO - root - 已保存图片 6/10：./export\images_Automated and Scalable SEM Image Analysis of Perovskite Solar Cell Materials via\figure_6_page9.jpeg
2025-11-09 09:37:19,336 - INFO - root - 已保存图片 7/10：./export\images_Automated and Scalable SEM Image Analysis of Perovskite Solar Cell Materials via\figure_7_page9.jpeg
2025-11-09 09:37:19,590 - INFO - root - 已保存图片 8/10：./export\images_Automated and Scalable SEM Image Analysis of Perovskite Solar Cell Materials via\figure_8_page9.jpeg
2025-11-09 09:37:19,794 - INFO - root - 已保存图片 9/10：./export\images_Automated and Scalable SEM Image Analysis of Perovskite Solar Cell Materials via\figure_9_page9.jpeg
2025-11-09 09:37:20,022 - INFO - root - 已保存图片 10/10：./export\images_Automated and Scalable SEM Image Analysis of Perovskite Solar Cell Materials via\figure_10_page9.jpeg
2025-11-09 09:37:20,055 - INFO - root - 成功添加图片 1：./export\images_Automated and Scalable SEM Image Analysis of Perovskite Solar Cell Materials via\figure_1_page8.jpeg
2025-11-09 09:37:20,055 - INFO - root - 成功添加图片 2：./export\images_Automated and Scalable SEM Image Analysis of Perovskite Solar Cell Materials via\figure_2_page5.jpeg
2025-11-09 09:37:20,055 - INFO - root - 成功添加图片 3：./export\images_Automated and Scalable SEM Image Analysis of Perovskite Solar Cell Materials via\figure_3_page9.jpeg
2025-11-09 09:37:20,055 - INFO - root - 成功添加图片 4：./export\images_Automated and Scalable SEM Image Analysis of Perovskite Solar Cell Materials via\figure_4_page9.jpeg
2025-11-09 09:37:20,055 - INFO - root - 成功添加图片 5：./export\images_Automated and Scalable SEM Image Analysis of Perovskite Solar Cell Materials via\figure_5_page9.jpeg
2025-11-09 09:37:20,055 - INFO - root - 成功添加图片 6：./export\images_Automated and Scalable SEM Image Analysis of Perovskite Solar Cell Materials via\figure_6_page9.jpeg
2025-11-09 09:37:20,055 - INFO - root - 成功添加图片 7：./export\images_Automated and Scalable SEM Image Analysis of Perovskite Solar Cell Materials via\figure_7_page9.jpeg
2025-11-09 09:37:20,055 - INFO - root - 成功添加图片 8：./export\images_Automated and Scalable SEM Image Analysis of Perovskite Solar Cell Materials via\figure_8_page9.jpeg
2025-11-09 09:37:20,055 - INFO - root - 成功添加图片 9：./export\images_Automated and Scalable SEM Image Analysis of Perovskite Solar Cell Materials via\figure_9_page9.jpeg
2025-11-09 09:37:20,055 - INFO - root - 成功添加图片 10：./export\images_Automated and Scalable SEM Image Analysis of Perovskite Solar Cell Materials via\figure_10_page9.jpeg
2025-11-09 09:37:20,063 - INFO - root - 论文《Automated and Scalable SEM Image Analysis of Perovskite Solar Cell Materials via a Deep Segmentation Framework》的分析已保存到 ./export\Automated and Scalable SEM Image Analysis of Perovskite Solar Cell Materials via.md
2025-11-09 09:37:20,067 - INFO - root - 正在总结论文 10/30: AMLA: MUL by ADD in FlashAttention Rescaling
2025-11-09 09:38:03,534 - INFO - root - LLMClient: rate limit reached, sleeping 16.5s
2025-11-09 09:38:39,999 - INFO - root - 正在提取论文图片...
2025-11-09 09:38:40,977 - INFO - root - 已保存图片 1/10：./export\images_AMLA_ MUL by ADD in FlashAttention Rescaling\figure_1_page15.png
2025-11-09 09:38:41,030 - INFO - root - 已保存图片 2/10：./export\images_AMLA_ MUL by ADD in FlashAttention Rescaling\figure_2_page4.jpeg
2025-11-09 09:38:41,059 - INFO - root - 已保存图片 3/10：./export\images_AMLA_ MUL by ADD in FlashAttention Rescaling\figure_3_page8.jpeg
2025-11-09 09:38:41,077 - INFO - root - 成功添加图片 1：./export\images_AMLA_ MUL by ADD in FlashAttention Rescaling\figure_1_page15.png
2025-11-09 09:38:41,077 - INFO - root - 成功添加图片 2：./export\images_AMLA_ MUL by ADD in FlashAttention Rescaling\figure_2_page4.jpeg
2025-11-09 09:38:41,078 - INFO - root - 成功添加图片 3：./export\images_AMLA_ MUL by ADD in FlashAttention Rescaling\figure_3_page8.jpeg
2025-11-09 09:38:41,082 - INFO - root - 论文《AMLA: MUL by ADD in FlashAttention Rescaling》的分析已保存到 ./export\AMLA_ MUL by ADD in FlashAttention Rescaling.md
2025-11-09 09:38:41,086 - INFO - root - 正在总结论文 11/30: Pretraining Large Language Models with NVFP4
2025-11-09 09:38:51,473 - INFO - root - LLMClient: rate limit reached, sleeping 28.6s
2025-11-09 09:40:00,161 - INFO - root - 正在提取论文图片...
2025-11-09 09:40:00,308 - INFO - root - 已保存图片 1/10：./export\images_Pretraining Large Language Models with NVFP4\figure_1_page7.png
2025-11-09 09:40:00,337 - INFO - root - 已保存图片 2/10：./export\images_Pretraining Large Language Models with NVFP4\figure_2_page7.jpeg
2025-11-09 09:40:00,356 - INFO - root - 已保存图片 3/10：./export\images_Pretraining Large Language Models with NVFP4\figure_3_page1.png
2025-11-09 09:40:00,378 - INFO - root - 已保存图片 4/10：./export\images_Pretraining Large Language Models with NVFP4\figure_4_page7.jpeg
2025-11-09 09:40:00,398 - INFO - root - 已保存图片 5/10：./export\images_Pretraining Large Language Models with NVFP4\figure_5_page7.jpeg
2025-11-09 09:40:00,422 - INFO - root - 已保存图片 6/10：./export\images_Pretraining Large Language Models with NVFP4\figure_6_page7.jpeg
2025-11-09 09:40:00,440 - INFO - root - 已保存图片 7/10：./export\images_Pretraining Large Language Models with NVFP4\figure_7_page7.png
2025-11-09 09:40:00,472 - INFO - root - 已保存图片 8/10：./export\images_Pretraining Large Language Models with NVFP4\figure_8_page7.jpeg
2025-11-09 09:40:00,487 - INFO - root - 已保存图片 9/10：./export\images_Pretraining Large Language Models with NVFP4\figure_9_page7.jpeg
2025-11-09 09:40:00,532 - INFO - root - 已保存图片 10/10：./export\images_Pretraining Large Language Models with NVFP4\figure_10_page7.jpeg
2025-11-09 09:40:00,535 - INFO - root - 成功添加图片 1：./export\images_Pretraining Large Language Models with NVFP4\figure_1_page7.png
2025-11-09 09:40:00,535 - INFO - root - 成功添加图片 2：./export\images_Pretraining Large Language Models with NVFP4\figure_2_page7.jpeg
2025-11-09 09:40:00,535 - INFO - root - 成功添加图片 3：./export\images_Pretraining Large Language Models with NVFP4\figure_3_page1.png
2025-11-09 09:40:00,535 - INFO - root - 成功添加图片 4：./export\images_Pretraining Large Language Models with NVFP4\figure_4_page7.jpeg
2025-11-09 09:40:00,535 - INFO - root - 成功添加图片 5：./export\images_Pretraining Large Language Models with NVFP4\figure_5_page7.jpeg
2025-11-09 09:40:00,535 - INFO - root - 成功添加图片 6：./export\images_Pretraining Large Language Models with NVFP4\figure_6_page7.jpeg
2025-11-09 09:40:00,535 - INFO - root - 成功添加图片 7：./export\images_Pretraining Large Language Models with NVFP4\figure_7_page7.png
2025-11-09 09:40:00,535 - INFO - root - 成功添加图片 8：./export\images_Pretraining Large Language Models with NVFP4\figure_8_page7.jpeg
2025-11-09 09:40:00,535 - INFO - root - 成功添加图片 9：./export\images_Pretraining Large Language Models with NVFP4\figure_9_page7.jpeg
2025-11-09 09:40:00,535 - INFO - root - 成功添加图片 10：./export\images_Pretraining Large Language Models with NVFP4\figure_10_page7.jpeg
2025-11-09 09:40:00,543 - INFO - root - 论文《Pretraining Large Language Models with NVFP4》的分析已保存到 ./export\Pretraining Large Language Models with NVFP4.md
2025-11-09 09:40:00,543 - INFO - root - 正在总结论文 12/30: Bridging the Gap Between Promise and Performance for Microscaling FP4 Quantization
2025-11-09 09:40:00,543 - INFO - root - LLMClient: rate limit reached, sleeping 19.5s
2025-11-09 09:40:28,694 - INFO - root - LLMClient: rate limit reached, sleeping 13.9s
2025-11-09 09:41:10,576 - INFO - root - LLMClient: rate limit reached, sleeping 9.5s
2025-11-09 09:41:40,505 - INFO - root - 正在提取论文图片...
2025-11-09 09:41:40,613 - INFO - root - 已保存图片 1/10：./export\images_Bridging the Gap Between Promise and Performance for Microscaling FP4 Quantizati\figure_1_page25.png
2025-11-09 09:41:40,615 - INFO - root - 成功添加图片 1：./export\images_Bridging the Gap Between Promise and Performance for Microscaling FP4 Quantizati\figure_1_page25.png
2025-11-09 09:41:40,619 - INFO - root - 论文《Bridging the Gap Between Promise and Performance for Microscaling FP4 Quantization》的分析已保存到 ./export\Bridging the Gap Between Promise and Performance for Microscaling FP4 Quantizati.md
2025-11-09 09:41:40,631 - INFO - root - 正在总结论文 13/30: Towards Verified Compilation of Floating-point Optimization in Scientific Computing Programs
2025-11-09 09:41:40,635 - INFO - root - LLMClient: rate limit reached, sleeping 1.9s
2025-11-09 09:41:51,136 - INFO - root - LLMClient: rate limit reached, sleeping 28.9s
2025-11-09 09:43:15,225 - INFO - root - 正在提取论文图片...
2025-11-09 09:43:15,235 - INFO - root - 论文《Towards Verified Compilation of Floating-point Optimization in Scientific Computing Programs》的分析已保存到 ./export\Towards Verified Compilation of Floating-point Optimization in Scientific Comput.md
2025-11-09 09:43:15,242 - INFO - root - 正在总结论文 14/30: Green Learning for STAR-RIS mmWave Systems with Implicit CSI
2025-11-09 09:43:15,246 - INFO - root - LLMClient: rate limit reached, sleeping 4.8s
2025-11-09 09:43:29,726 - INFO - root - LLMClient: rate limit reached, sleeping 25.1s
2025-11-09 09:44:20,033 - INFO - root - LLMClient: rate limit reached, sleeping 0.0s
2025-11-09 09:44:39,745 - INFO - root - 正在提取论文图片...
2025-11-09 09:44:39,853 - INFO - root - 已保存图片 1/10：./export\images_Green Learning for STAR-RIS mmWave Systems with Implicit CSI\figure_1_page2.jpeg
2025-11-09 09:44:39,931 - INFO - root - 已保存图片 2/10：./export\images_Green Learning for STAR-RIS mmWave Systems with Implicit CSI\figure_2_page2.png
2025-11-09 09:44:39,987 - INFO - root - 已保存图片 3/10：./export\images_Green Learning for STAR-RIS mmWave Systems with Implicit CSI\figure_3_page2.png
2025-11-09 09:44:40,042 - INFO - root - 已保存图片 4/10：./export\images_Green Learning for STAR-RIS mmWave Systems with Implicit CSI\figure_4_page2.png
2025-11-09 09:44:40,044 - INFO - root - 成功添加图片 1：./export\images_Green Learning for STAR-RIS mmWave Systems with Implicit CSI\figure_1_page2.jpeg
2025-11-09 09:44:40,044 - INFO - root - 成功添加图片 2：./export\images_Green Learning for STAR-RIS mmWave Systems with Implicit CSI\figure_2_page2.png
2025-11-09 09:44:40,045 - INFO - root - 成功添加图片 3：./export\images_Green Learning for STAR-RIS mmWave Systems with Implicit CSI\figure_3_page2.png
2025-11-09 09:44:40,045 - INFO - root - 成功添加图片 4：./export\images_Green Learning for STAR-RIS mmWave Systems with Implicit CSI\figure_4_page2.png
2025-11-09 09:44:40,048 - INFO - root - 论文《Green Learning for STAR-RIS mmWave Systems with Implicit CSI》的分析已保存到 ./export\Green Learning for STAR-RIS mmWave Systems with Implicit CSI.md
2025-11-09 09:44:40,055 - INFO - root - 正在总结论文 15/30: A Compute&Memory Efficient Model-Driven Neural 5G Receiver for Edge AI-assisted RAN
2025-11-09 09:44:40,055 - INFO - root - LLMClient: rate limit reached, sleeping 14.7s
2025-11-09 09:45:05,784 - INFO - root - LLMClient: rate limit reached, sleeping 14.3s
2025-11-09 09:45:47,148 - INFO - root - LLMClient: rate limit reached, sleeping 7.6s
2025-11-09 09:46:13,321 - INFO - root - 正在提取论文图片...
2025-11-09 09:46:14,102 - INFO - root - 已保存图片 1/10：./export\images_A Compute&Memory Efficient Model-Driven Neural 5G Receiver for Edge AI-assisted\figure_1_page6.png
2025-11-09 09:46:14,216 - INFO - root - 已保存图片 2/10：./export\images_A Compute&Memory Efficient Model-Driven Neural 5G Receiver for Edge AI-assisted\figure_2_page6.png
2025-11-09 09:46:14,299 - INFO - root - 已保存图片 3/10：./export\images_A Compute&Memory Efficient Model-Driven Neural 5G Receiver for Edge AI-assisted\figure_3_page2.png
2025-11-09 09:46:14,351 - INFO - root - 已保存图片 4/10：./export\images_A Compute&Memory Efficient Model-Driven Neural 5G Receiver for Edge AI-assisted\figure_4_page2.png
2025-11-09 09:46:14,398 - INFO - root - 已保存图片 5/10：./export\images_A Compute&Memory Efficient Model-Driven Neural 5G Receiver for Edge AI-assisted\figure_5_page3.png
2025-11-09 09:46:14,401 - INFO - root - 成功添加图片 1：./export\images_A Compute&Memory Efficient Model-Driven Neural 5G Receiver for Edge AI-assisted\figure_1_page6.png
2025-11-09 09:46:14,401 - INFO - root - 成功添加图片 2：./export\images_A Compute&Memory Efficient Model-Driven Neural 5G Receiver for Edge AI-assisted\figure_2_page6.png
2025-11-09 09:46:14,401 - INFO - root - 成功添加图片 3：./export\images_A Compute&Memory Efficient Model-Driven Neural 5G Receiver for Edge AI-assisted\figure_3_page2.png
2025-11-09 09:46:14,401 - INFO - root - 成功添加图片 4：./export\images_A Compute&Memory Efficient Model-Driven Neural 5G Receiver for Edge AI-assisted\figure_4_page2.png
2025-11-09 09:46:14,401 - INFO - root - 成功添加图片 5：./export\images_A Compute&Memory Efficient Model-Driven Neural 5G Receiver for Edge AI-assisted\figure_5_page3.png
2025-11-09 09:46:14,401 - INFO - root - 论文《A Compute&Memory Efficient Model-Driven Neural 5G Receiver for Edge AI-assisted RAN》的分析已保存到 ./export\A Compute&Memory Efficient Model-Driven Neural 5G Receiver for Edge AI-assisted.md
2025-11-09 09:46:14,413 - INFO - root - 正在总结论文 16/30: SNNSIR: A Simple Spiking Neural Network for Stereo Image Restoration
2025-11-09 09:46:14,414 - INFO - root - LLMClient: rate limit reached, sleeping 5.7s
2025-11-09 09:46:28,571 - INFO - root - LLMClient: rate limit reached, sleeping 26.2s
2025-11-09 09:47:42,531 - INFO - root - 正在提取论文图片...
2025-11-09 09:47:47,298 - INFO - root - 已保存图片 1/10：./export\images_SNNSIR_ A Simple Spiking Neural Network for Stereo Image Restoration\figure_1_page8.jpeg
2025-11-09 09:47:47,342 - INFO - root - 已保存图片 2/10：./export\images_SNNSIR_ A Simple Spiking Neural Network for Stereo Image Restoration\figure_2_page7.jpeg
2025-11-09 09:47:47,388 - INFO - root - 已保存图片 3/10：./export\images_SNNSIR_ A Simple Spiking Neural Network for Stereo Image Restoration\figure_3_page7.jpeg
2025-11-09 09:47:47,418 - INFO - root - 已保存图片 4/10：./export\images_SNNSIR_ A Simple Spiking Neural Network for Stereo Image Restoration\figure_4_page7.jpeg
2025-11-09 09:47:47,447 - INFO - root - 已保存图片 5/10：./export\images_SNNSIR_ A Simple Spiking Neural Network for Stereo Image Restoration\figure_5_page7.jpeg
2025-11-09 09:47:47,576 - INFO - root - 已保存图片 6/10：./export\images_SNNSIR_ A Simple Spiking Neural Network for Stereo Image Restoration\figure_6_page8.png
2025-11-09 09:47:47,711 - INFO - root - 已保存图片 7/10：./export\images_SNNSIR_ A Simple Spiking Neural Network for Stereo Image Restoration\figure_7_page8.png
2025-11-09 09:47:47,837 - INFO - root - 已保存图片 8/10：./export\images_SNNSIR_ A Simple Spiking Neural Network for Stereo Image Restoration\figure_8_page8.png
2025-11-09 09:47:47,970 - INFO - root - 已保存图片 9/10：./export\images_SNNSIR_ A Simple Spiking Neural Network for Stereo Image Restoration\figure_9_page8.png
2025-11-09 09:47:48,087 - INFO - root - 已保存图片 10/10：./export\images_SNNSIR_ A Simple Spiking Neural Network for Stereo Image Restoration\figure_10_page8.png
2025-11-09 09:47:48,104 - INFO - root - 成功添加图片 1：./export\images_SNNSIR_ A Simple Spiking Neural Network for Stereo Image Restoration\figure_1_page8.jpeg
2025-11-09 09:47:48,104 - INFO - root - 成功添加图片 2：./export\images_SNNSIR_ A Simple Spiking Neural Network for Stereo Image Restoration\figure_2_page7.jpeg
2025-11-09 09:47:48,104 - INFO - root - 成功添加图片 3：./export\images_SNNSIR_ A Simple Spiking Neural Network for Stereo Image Restoration\figure_3_page7.jpeg
2025-11-09 09:47:48,104 - INFO - root - 成功添加图片 4：./export\images_SNNSIR_ A Simple Spiking Neural Network for Stereo Image Restoration\figure_4_page7.jpeg
2025-11-09 09:47:48,104 - INFO - root - 成功添加图片 5：./export\images_SNNSIR_ A Simple Spiking Neural Network for Stereo Image Restoration\figure_5_page7.jpeg
2025-11-09 09:47:48,104 - INFO - root - 成功添加图片 6：./export\images_SNNSIR_ A Simple Spiking Neural Network for Stereo Image Restoration\figure_6_page8.png
2025-11-09 09:47:48,104 - INFO - root - 成功添加图片 7：./export\images_SNNSIR_ A Simple Spiking Neural Network for Stereo Image Restoration\figure_7_page8.png
2025-11-09 09:47:48,104 - INFO - root - 成功添加图片 8：./export\images_SNNSIR_ A Simple Spiking Neural Network for Stereo Image Restoration\figure_8_page8.png
2025-11-09 09:47:48,104 - INFO - root - 成功添加图片 9：./export\images_SNNSIR_ A Simple Spiking Neural Network for Stereo Image Restoration\figure_9_page8.png
2025-11-09 09:47:48,104 - INFO - root - 成功添加图片 10：./export\images_SNNSIR_ A Simple Spiking Neural Network for Stereo Image Restoration\figure_10_page8.png
2025-11-09 09:47:48,112 - INFO - root - 论文《SNNSIR: A Simple Spiking Neural Network for Stereo Image Restoration》的分析已保存到 ./export\SNNSIR_ A Simple Spiking Neural Network for Stereo Image Restoration.md
2025-11-09 09:47:48,121 - INFO - root - 正在总结论文 17/30: SpikeSTAG: Spatial-Temporal Forecasting via GNN-SNN Collaboration
2025-11-09 09:47:48,121 - INFO - root - LLMClient: rate limit reached, sleeping 6.7s
2025-11-09 09:48:05,407 - INFO - root - LLMClient: rate limit reached, sleeping 17.7s
2025-11-09 09:48:48,016 - INFO - root - LLMClient: rate limit reached, sleeping 6.8s
2025-11-09 09:49:14,621 - INFO - root - 正在提取论文图片...
2025-11-09 09:49:15,026 - INFO - root - 已保存图片 1/10：./export\images_SpikeSTAG_ Spatial-Temporal Forecasting via GNN-SNN Collaboration\figure_1_page4.png
2025-11-09 09:49:15,087 - INFO - root - 已保存图片 2/10：./export\images_SpikeSTAG_ Spatial-Temporal Forecasting via GNN-SNN Collaboration\figure_2_page2.png
2025-11-09 09:49:15,163 - INFO - root - 已保存图片 3/10：./export\images_SpikeSTAG_ Spatial-Temporal Forecasting via GNN-SNN Collaboration\figure_3_page7.png
2025-11-09 09:49:15,233 - INFO - root - 已保存图片 4/10：./export\images_SpikeSTAG_ Spatial-Temporal Forecasting via GNN-SNN Collaboration\figure_4_page4.png
2025-11-09 09:49:15,237 - INFO - root - 成功添加图片 1：./export\images_SpikeSTAG_ Spatial-Temporal Forecasting via GNN-SNN Collaboration\figure_1_page4.png
2025-11-09 09:49:15,237 - INFO - root - 成功添加图片 2：./export\images_SpikeSTAG_ Spatial-Temporal Forecasting via GNN-SNN Collaboration\figure_2_page2.png
2025-11-09 09:49:15,237 - INFO - root - 成功添加图片 3：./export\images_SpikeSTAG_ Spatial-Temporal Forecasting via GNN-SNN Collaboration\figure_3_page7.png
2025-11-09 09:49:15,237 - INFO - root - 成功添加图片 4：./export\images_SpikeSTAG_ Spatial-Temporal Forecasting via GNN-SNN Collaboration\figure_4_page4.png
2025-11-09 09:49:15,243 - INFO - root - 论文《SpikeSTAG: Spatial-Temporal Forecasting via GNN-SNN Collaboration》的分析已保存到 ./export\SpikeSTAG_ Spatial-Temporal Forecasting via GNN-SNN Collaboration.md
2025-11-09 09:49:15,254 - INFO - root - 正在总结论文 18/30: DGEMM without FP64 Arithmetic - Using FP64 Emulation and FP8 Tensor Cores with Ozaki Scheme
2025-11-09 09:49:15,257 - INFO - root - LLMClient: rate limit reached, sleeping 7.8s
2025-11-09 09:49:32,140 - INFO - root - LLMClient: rate limit reached, sleeping 22.6s
2025-11-09 09:50:22,400 - INFO - root - LLMClient: rate limit reached, sleeping 0.7s
2025-11-09 09:50:42,963 - INFO - root - 正在提取论文图片...
2025-11-09 09:50:42,976 - INFO - root - 论文《DGEMM without FP64 Arithmetic - Using FP64 Emulation and FP8 Tensor Cores with Ozaki Scheme》的分析已保存到 ./export\DGEMM without FP64 Arithmetic - Using FP64 Emulation and FP8 Tensor Cores with O.md
2025-11-09 09:50:42,979 - INFO - root - 正在总结论文 19/30: Scaling Probabilistic Circuits via Monarch Matrices
2025-11-09 09:50:42,985 - INFO - root - LLMClient: rate limit reached, sleeping 11.8s
2025-11-09 09:51:03,291 - INFO - root - LLMClient: rate limit reached, sleeping 19.8s
2025-11-09 09:51:48,985 - INFO - root - LLMClient: rate limit reached, sleeping 5.8s
2025-11-09 09:52:13,915 - INFO - root - 正在提取论文图片...
2025-11-09 09:52:14,011 - INFO - root - 已保存图片 1/10：./export\images_Scaling Probabilistic Circuits via Monarch Matrices\figure_1_page5.png
2025-11-09 09:52:14,075 - INFO - root - 已保存图片 2/10：./export\images_Scaling Probabilistic Circuits via Monarch Matrices\figure_2_page5.png
2025-11-09 09:52:14,132 - INFO - root - 已保存图片 3/10：./export\images_Scaling Probabilistic Circuits via Monarch Matrices\figure_3_page5.png
2025-11-09 09:52:14,193 - INFO - root - 已保存图片 4/10：./export\images_Scaling Probabilistic Circuits via Monarch Matrices\figure_4_page5.png
2025-11-09 09:52:14,253 - INFO - root - 已保存图片 5/10：./export\images_Scaling Probabilistic Circuits via Monarch Matrices\figure_5_page13.png
2025-11-09 09:52:14,319 - INFO - root - 已保存图片 6/10：./export\images_Scaling Probabilistic Circuits via Monarch Matrices\figure_6_page13.png
2025-11-09 09:52:14,379 - INFO - root - 已保存图片 7/10：./export\images_Scaling Probabilistic Circuits via Monarch Matrices\figure_7_page13.png
2025-11-09 09:52:14,429 - INFO - root - 已保存图片 8/10：./export\images_Scaling Probabilistic Circuits via Monarch Matrices\figure_8_page13.png
2025-11-09 09:52:14,429 - INFO - root - 成功添加图片 1：./export\images_Scaling Probabilistic Circuits via Monarch Matrices\figure_1_page5.png
2025-11-09 09:52:14,429 - INFO - root - 成功添加图片 2：./export\images_Scaling Probabilistic Circuits via Monarch Matrices\figure_2_page5.png
2025-11-09 09:52:14,429 - INFO - root - 成功添加图片 3：./export\images_Scaling Probabilistic Circuits via Monarch Matrices\figure_3_page5.png
2025-11-09 09:52:14,429 - INFO - root - 成功添加图片 4：./export\images_Scaling Probabilistic Circuits via Monarch Matrices\figure_4_page5.png
2025-11-09 09:52:14,442 - INFO - root - 成功添加图片 5：./export\images_Scaling Probabilistic Circuits via Monarch Matrices\figure_5_page13.png
2025-11-09 09:52:14,442 - INFO - root - 成功添加图片 6：./export\images_Scaling Probabilistic Circuits via Monarch Matrices\figure_6_page13.png
2025-11-09 09:52:14,442 - INFO - root - 成功添加图片 7：./export\images_Scaling Probabilistic Circuits via Monarch Matrices\figure_7_page13.png
2025-11-09 09:52:14,442 - INFO - root - 成功添加图片 8：./export\images_Scaling Probabilistic Circuits via Monarch Matrices\figure_8_page13.png
2025-11-09 09:52:14,447 - INFO - root - 论文《Scaling Probabilistic Circuits via Monarch Matrices》的分析已保存到 ./export\Scaling Probabilistic Circuits via Monarch Matrices.md
2025-11-09 09:52:14,458 - INFO - root - 正在总结论文 20/30: Starting Positions Matter: A Study on Better Weight Initialization for Neural Network Quantization
2025-11-09 09:52:14,461 - INFO - root - LLMClient: rate limit reached, sleeping 8.6s
2025-11-09 09:52:32,733 - INFO - root - LLMClient: rate limit reached, sleeping 22.1s
2025-11-09 09:53:43,563 - INFO - root - 正在提取论文图片...
2025-11-09 09:53:44,074 - INFO - root - 已保存图片 1/10：./export\images_Starting Positions Matter_ A Study on Better Weight Initialization for Neural Ne\figure_1_page10.png
2025-11-09 09:53:44,111 - INFO - root - 已保存图片 2/10：./export\images_Starting Positions Matter_ A Study on Better Weight Initialization for Neural Ne\figure_2_page5.png
2025-11-09 09:53:44,215 - INFO - root - 已保存图片 3/10：./export\images_Starting Positions Matter_ A Study on Better Weight Initialization for Neural Ne\figure_3_page7.png
2025-11-09 09:53:44,295 - INFO - root - 已保存图片 4/10：./export\images_Starting Positions Matter_ A Study on Better Weight Initialization for Neural Ne\figure_4_page7.png
2025-11-09 09:53:44,362 - INFO - root - 已保存图片 5/10：./export\images_Starting Positions Matter_ A Study on Better Weight Initialization for Neural Ne\figure_5_page7.png
2025-11-09 09:53:44,433 - INFO - root - 已保存图片 6/10：./export\images_Starting Positions Matter_ A Study on Better Weight Initialization for Neural Ne\figure_6_page7.png
2025-11-09 09:53:44,500 - INFO - root - 已保存图片 7/10：./export\images_Starting Positions Matter_ A Study on Better Weight Initialization for Neural Ne\figure_7_page9.png
2025-11-09 09:53:44,567 - INFO - root - 已保存图片 8/10：./export\images_Starting Positions Matter_ A Study on Better Weight Initialization for Neural Ne\figure_8_page9.png
2025-11-09 09:53:44,634 - INFO - root - 已保存图片 9/10：./export\images_Starting Positions Matter_ A Study on Better Weight Initialization for Neural Ne\figure_9_page8.png
2025-11-09 09:53:44,701 - INFO - root - 已保存图片 10/10：./export\images_Starting Positions Matter_ A Study on Better Weight Initialization for Neural Ne\figure_10_page8.png
2025-11-09 09:53:44,703 - INFO - root - 成功添加图片 1：./export\images_Starting Positions Matter_ A Study on Better Weight Initialization for Neural Ne\figure_1_page10.png
2025-11-09 09:53:44,703 - INFO - root - 成功添加图片 2：./export\images_Starting Positions Matter_ A Study on Better Weight Initialization for Neural Ne\figure_2_page5.png
2025-11-09 09:53:44,703 - INFO - root - 成功添加图片 3：./export\images_Starting Positions Matter_ A Study on Better Weight Initialization for Neural Ne\figure_3_page7.png
2025-11-09 09:53:44,703 - INFO - root - 成功添加图片 4：./export\images_Starting Positions Matter_ A Study on Better Weight Initialization for Neural Ne\figure_4_page7.png
2025-11-09 09:53:44,703 - INFO - root - 成功添加图片 5：./export\images_Starting Positions Matter_ A Study on Better Weight Initialization for Neural Ne\figure_5_page7.png
2025-11-09 09:53:44,703 - INFO - root - 成功添加图片 6：./export\images_Starting Positions Matter_ A Study on Better Weight Initialization for Neural Ne\figure_6_page7.png
2025-11-09 09:53:44,703 - INFO - root - 成功添加图片 7：./export\images_Starting Positions Matter_ A Study on Better Weight Initialization for Neural Ne\figure_7_page9.png
2025-11-09 09:53:44,703 - INFO - root - 成功添加图片 8：./export\images_Starting Positions Matter_ A Study on Better Weight Initialization for Neural Ne\figure_8_page9.png
2025-11-09 09:53:44,703 - INFO - root - 成功添加图片 9：./export\images_Starting Positions Matter_ A Study on Better Weight Initialization for Neural Ne\figure_9_page8.png
2025-11-09 09:53:44,703 - INFO - root - 成功添加图片 10：./export\images_Starting Positions Matter_ A Study on Better Weight Initialization for Neural Ne\figure_10_page8.png
2025-11-09 09:53:44,710 - INFO - root - 论文《Starting Positions Matter: A Study on Better Weight Initialization for Neural Network Quantization》的分析已保存到 ./export\Starting Positions Matter_ A Study on Better Weight Initialization for Neural Ne.md
2025-11-09 09:53:44,717 - INFO - root - 正在总结论文 21/30: Recipes for Pre-training LLMs with MXFP8
2025-11-09 09:53:44,719 - INFO - root - LLMClient: rate limit reached, sleeping 10.1s
2025-11-09 09:54:05,661 - INFO - root - LLMClient: rate limit reached, sleeping 18.6s
2025-11-09 09:54:50,756 - INFO - root - LLMClient: rate limit reached, sleeping 4.0s
2025-11-09 09:55:13,138 - INFO - root - 正在提取论文图片...
2025-11-09 09:55:13,159 - INFO - root - 论文《Recipes for Pre-training LLMs with MXFP8》的分析已保存到 ./export\Recipes for Pre-training LLMs with MXFP8.md
2025-11-09 09:55:13,166 - INFO - root - 正在总结论文 22/30: FP4 All the Way: Fully Quantized Training of LLMs
2025-11-09 09:55:13,166 - INFO - root - LLMClient: rate limit reached, sleeping 11.1s
2025-11-09 09:55:32,581 - INFO - root - LLMClient: rate limit reached, sleeping 22.2s
2025-11-09 09:56:22,886 - INFO - root - LLMClient: rate limit reached, sleeping 1.3s
2025-11-09 09:56:41,959 - INFO - root - 正在提取论文图片...
2025-11-09 09:56:41,981 - INFO - root - 论文《FP4 All the Way: Fully Quantized Training of LLMs》的分析已保存到 ./export\FP4 All the Way_ Fully Quantized Training of LLMs.md
2025-11-09 09:56:41,981 - INFO - root - 正在总结论文 23/30: Automatic Verification of Floating-Point Accumulation Networks
2025-11-09 09:56:41,981 - INFO - root - LLMClient: rate limit reached, sleeping 12.8s
2025-11-09 09:57:05,462 - INFO - root - LLMClient: rate limit reached, sleeping 18.8s
2025-11-09 09:57:52,739 - INFO - root - LLMClient: rate limit reached, sleeping 2.1s
2025-11-09 09:58:13,141 - INFO - root - 正在提取论文图片...
2025-11-09 09:58:13,169 - INFO - root - 论文《Automatic Verification of Floating-Point Accumulation Networks》的分析已保存到 ./export\Automatic Verification of Floating-Point Accumulation Networks.md
2025-11-09 09:58:13,174 - INFO - root - 正在总结论文 24/30: MXDOTP: A RISC-V ISA Extension for Enabling Microscaling (MX) Floating-Point Dot Products
2025-11-09 09:58:13,176 - INFO - root - LLMClient: rate limit reached, sleeping 11.0s
2025-11-09 09:58:33,881 - INFO - root - LLMClient: rate limit reached, sleeping 20.9s
2025-11-09 09:59:21,837 - INFO - root - LLMClient: rate limit reached, sleeping 2.4s
2025-11-09 09:59:44,166 - INFO - root - 正在提取论文图片...
2025-11-09 09:59:44,188 - INFO - root - 论文《MXDOTP: A RISC-V ISA Extension for Enabling Microscaling (MX) Floating-Point Dot Products》的分析已保存到 ./export\MXDOTP_ A RISC-V ISA Extension for Enabling Microscaling (MX) Floating-Point Dot.md
2025-11-09 09:59:44,195 - INFO - root - 正在总结论文 25/30: Parameter-Efficient Fine-Tuning with Circulant and Diagonal Vectors
2025-11-09 09:59:44,197 - INFO - root - LLMClient: rate limit reached, sleeping 10.6s
2025-11-09 10:00:04,187 - INFO - root - LLMClient: rate limit reached, sleeping 20.1s
2025-11-09 10:01:54,954 - INFO - root - 正在提取论文图片...
2025-11-09 10:01:54,964 - INFO - root - 论文《Parameter-Efficient Fine-Tuning with Circulant and Diagonal Vectors》的分析已保存到 ./export\Parameter-Efficient Fine-Tuning with Circulant and Diagonal Vectors.md
2025-11-09 10:01:54,969 - INFO - root - 正在总结论文 26/30: Silenzio: Secure Non-Interactive Outsourced MLP Training
2025-11-09 10:02:07,552 - INFO - root - LLMClient: rate limit reached, sleeping 29.5s
2025-11-09 10:03:31,905 - INFO - root - 正在提取论文图片...
2025-11-09 10:03:32,162 - INFO - root - 已保存图片 1/10：./export\images_Silenzio_ Secure Non-Interactive Outsourced MLP Training\figure_1_page11.png
2025-11-09 10:03:32,162 - INFO - root - 成功添加图片 1：./export\images_Silenzio_ Secure Non-Interactive Outsourced MLP Training\figure_1_page11.png
2025-11-09 10:03:32,167 - INFO - root - 论文《Silenzio: Secure Non-Interactive Outsourced MLP Training》的分析已保存到 ./export\Silenzio_ Secure Non-Interactive Outsourced MLP Training.md
2025-11-09 10:03:32,175 - INFO - root - 正在总结论文 27/30: Involution and BSConv Multi-Depth Distillation Network for Lightweight Image Super-Resolution
2025-11-09 10:03:32,175 - INFO - root - LLMClient: rate limit reached, sleeping 4.8s
2025-11-09 10:03:48,557 - INFO - root - LLMClient: rate limit reached, sleeping 22.9s
2025-11-09 10:04:58,538 - INFO - root - 正在提取论文图片...
2025-11-09 10:04:58,608 - INFO - root - 已保存图片 1/10：./export\images_Involution and BSConv Multi-Depth Distillation Network for Lightweight Image Sup\figure_1_page4.jpeg
2025-11-09 10:04:58,624 - INFO - root - 已保存图片 2/10：./export\images_Involution and BSConv Multi-Depth Distillation Network for Lightweight Image Sup\figure_2_page3.jpeg
2025-11-09 10:04:58,688 - INFO - root - 已保存图片 3/10：./export\images_Involution and BSConv Multi-Depth Distillation Network for Lightweight Image Sup\figure_3_page1.png
2025-11-09 10:04:58,764 - INFO - root - 已保存图片 4/10：./export\images_Involution and BSConv Multi-Depth Distillation Network for Lightweight Image Sup\figure_4_page5.png
2025-11-09 10:04:58,797 - INFO - root - 已保存图片 5/10：./export\images_Involution and BSConv Multi-Depth Distillation Network for Lightweight Image Sup\figure_5_page7.jpeg
2025-11-09 10:04:58,842 - INFO - root - 已保存图片 6/10：./export\images_Involution and BSConv Multi-Depth Distillation Network for Lightweight Image Sup\figure_6_page7.jpeg
2025-11-09 10:04:58,876 - INFO - root - 已保存图片 7/10：./export\images_Involution and BSConv Multi-Depth Distillation Network for Lightweight Image Sup\figure_7_page7.jpeg
2025-11-09 10:04:58,912 - INFO - root - 已保存图片 8/10：./export\images_Involution and BSConv Multi-Depth Distillation Network for Lightweight Image Sup\figure_8_page7.jpeg
2025-11-09 10:04:58,940 - INFO - root - 已保存图片 9/10：./export\images_Involution and BSConv Multi-Depth Distillation Network for Lightweight Image Sup\figure_9_page7.jpeg
2025-11-09 10:04:58,977 - INFO - root - 已保存图片 10/10：./export\images_Involution and BSConv Multi-Depth Distillation Network for Lightweight Image Sup\figure_10_page7.jpeg
2025-11-09 10:04:58,983 - INFO - root - 成功添加图片 1：./export\images_Involution and BSConv Multi-Depth Distillation Network for Lightweight Image Sup\figure_1_page4.jpeg
2025-11-09 10:04:58,984 - INFO - root - 成功添加图片 2：./export\images_Involution and BSConv Multi-Depth Distillation Network for Lightweight Image Sup\figure_2_page3.jpeg
2025-11-09 10:04:58,984 - INFO - root - 成功添加图片 3：./export\images_Involution and BSConv Multi-Depth Distillation Network for Lightweight Image Sup\figure_3_page1.png
2025-11-09 10:04:58,985 - INFO - root - 成功添加图片 4：./export\images_Involution and BSConv Multi-Depth Distillation Network for Lightweight Image Sup\figure_4_page5.png
2025-11-09 10:04:58,985 - INFO - root - 成功添加图片 5：./export\images_Involution and BSConv Multi-Depth Distillation Network for Lightweight Image Sup\figure_5_page7.jpeg
2025-11-09 10:04:58,985 - INFO - root - 成功添加图片 6：./export\images_Involution and BSConv Multi-Depth Distillation Network for Lightweight Image Sup\figure_6_page7.jpeg
2025-11-09 10:04:58,986 - INFO - root - 成功添加图片 7：./export\images_Involution and BSConv Multi-Depth Distillation Network for Lightweight Image Sup\figure_7_page7.jpeg
2025-11-09 10:04:58,986 - INFO - root - 成功添加图片 8：./export\images_Involution and BSConv Multi-Depth Distillation Network for Lightweight Image Sup\figure_8_page7.jpeg
2025-11-09 10:04:58,987 - INFO - root - 成功添加图片 9：./export\images_Involution and BSConv Multi-Depth Distillation Network for Lightweight Image Sup\figure_9_page7.jpeg
2025-11-09 10:04:58,987 - INFO - root - 成功添加图片 10：./export\images_Involution and BSConv Multi-Depth Distillation Network for Lightweight Image Sup\figure_10_page7.jpeg
2025-11-09 10:04:58,994 - INFO - root - 论文《Involution and BSConv Multi-Depth Distillation Network for Lightweight Image Super-Resolution》的分析已保存到 ./export\Involution and BSConv Multi-Depth Distillation Network for Lightweight Image Sup.md
2025-11-09 10:04:59,001 - INFO - root - 正在总结论文 28/30: Flopping for FLOPs: Leveraging equivariance for computational efficiency
2025-11-09 10:04:59,002 - INFO - root - LLMClient: rate limit reached, sleeping 12.5s
2025-11-09 10:05:22,017 - INFO - root - LLMClient: rate limit reached, sleeping 18.0s
2025-11-09 10:06:03,248 - INFO - root - LLMClient: rate limit reached, sleeping 8.2s
2025-11-09 10:06:27,546 - INFO - root - 正在提取论文图片...
2025-11-09 10:06:27,990 - INFO - root - 已保存图片 1/10：./export\images_Flopping for FLOPs_ Leveraging equivariance for computational efficiency\figure_1_page3.png
2025-11-09 10:06:28,075 - INFO - root - 已保存图片 2/10：./export\images_Flopping for FLOPs_ Leveraging equivariance for computational efficiency\figure_2_page5.png
2025-11-09 10:06:28,170 - INFO - root - 已保存图片 3/10：./export\images_Flopping for FLOPs_ Leveraging equivariance for computational efficiency\figure_3_page1.png
2025-11-09 10:06:28,170 - INFO - root - 成功添加图片 1：./export\images_Flopping for FLOPs_ Leveraging equivariance for computational efficiency\figure_1_page3.png
2025-11-09 10:06:28,170 - INFO - root - 成功添加图片 2：./export\images_Flopping for FLOPs_ Leveraging equivariance for computational efficiency\figure_2_page5.png
2025-11-09 10:06:28,170 - INFO - root - 成功添加图片 3：./export\images_Flopping for FLOPs_ Leveraging equivariance for computational efficiency\figure_3_page1.png
2025-11-09 10:06:28,185 - INFO - root - 论文《Flopping for FLOPs: Leveraging equivariance for computational efficiency》的分析已保存到 ./export\Flopping for FLOPs_ Leveraging equivariance for computational efficiency.md
2025-11-09 10:06:28,191 - INFO - root - 正在总结论文 29/30: An Effective UNet Using Feature Interaction and Fusion for Organ Segmentation in Medical Image
2025-11-09 10:06:28,191 - INFO - root - LLMClient: rate limit reached, sleeping 11.8s
2025-11-09 10:06:49,350 - INFO - root - LLMClient: rate limit reached, sleeping 22.1s
2025-11-09 10:07:35,800 - INFO - root - LLMClient: rate limit reached, sleeping 4.2s
2025-11-09 10:07:58,300 - INFO - root - 正在提取论文图片...
2025-11-09 10:07:58,489 - INFO - root - 已保存图片 1/10：./export\images_An Effective UNet Using Feature Interaction and Fusion for Organ Segmentation in\figure_1_page14.png
2025-11-09 10:07:58,531 - INFO - root - 已保存图片 2/10：./export\images_An Effective UNet Using Feature Interaction and Fusion for Organ Segmentation in\figure_2_page19.jpeg
2025-11-09 10:07:58,577 - INFO - root - 已保存图片 3/10：./export\images_An Effective UNet Using Feature Interaction and Fusion for Organ Segmentation in\figure_3_page19.jpeg
2025-11-09 10:07:58,672 - INFO - root - 已保存图片 4/10：./export\images_An Effective UNet Using Feature Interaction and Fusion for Organ Segmentation in\figure_4_page19.jpeg
2025-11-09 10:07:58,764 - INFO - root - 已保存图片 5/10：./export\images_An Effective UNet Using Feature Interaction and Fusion for Organ Segmentation in\figure_5_page19.jpeg
2025-11-09 10:07:58,822 - INFO - root - 已保存图片 6/10：./export\images_An Effective UNet Using Feature Interaction and Fusion for Organ Segmentation in\figure_6_page19.jpeg
2025-11-09 10:07:58,889 - INFO - root - 已保存图片 7/10：./export\images_An Effective UNet Using Feature Interaction and Fusion for Organ Segmentation in\figure_7_page19.jpeg
2025-11-09 10:07:58,992 - INFO - root - 已保存图片 8/10：./export\images_An Effective UNet Using Feature Interaction and Fusion for Organ Segmentation in\figure_8_page19.jpeg
2025-11-09 10:07:59,073 - INFO - root - 已保存图片 9/10：./export\images_An Effective UNet Using Feature Interaction and Fusion for Organ Segmentation in\figure_9_page19.jpeg
2025-11-09 10:07:59,146 - INFO - root - 已保存图片 10/10：./export\images_An Effective UNet Using Feature Interaction and Fusion for Organ Segmentation in\figure_10_page19.jpeg
2025-11-09 10:07:59,241 - INFO - root - 成功添加图片 1：./export\images_An Effective UNet Using Feature Interaction and Fusion for Organ Segmentation in\figure_1_page14.png
2025-11-09 10:07:59,253 - INFO - root - 成功添加图片 2：./export\images_An Effective UNet Using Feature Interaction and Fusion for Organ Segmentation in\figure_2_page19.jpeg
2025-11-09 10:07:59,255 - INFO - root - 成功添加图片 3：./export\images_An Effective UNet Using Feature Interaction and Fusion for Organ Segmentation in\figure_3_page19.jpeg
2025-11-09 10:07:59,258 - INFO - root - 成功添加图片 4：./export\images_An Effective UNet Using Feature Interaction and Fusion for Organ Segmentation in\figure_4_page19.jpeg
2025-11-09 10:07:59,263 - INFO - root - 成功添加图片 5：./export\images_An Effective UNet Using Feature Interaction and Fusion for Organ Segmentation in\figure_5_page19.jpeg
2025-11-09 10:07:59,285 - INFO - root - 成功添加图片 6：./export\images_An Effective UNet Using Feature Interaction and Fusion for Organ Segmentation in\figure_6_page19.jpeg
2025-11-09 10:07:59,297 - INFO - root - 成功添加图片 7：./export\images_An Effective UNet Using Feature Interaction and Fusion for Organ Segmentation in\figure_7_page19.jpeg
2025-11-09 10:07:59,321 - INFO - root - 成功添加图片 8：./export\images_An Effective UNet Using Feature Interaction and Fusion for Organ Segmentation in\figure_8_page19.jpeg
2025-11-09 10:07:59,321 - INFO - root - 成功添加图片 9：./export\images_An Effective UNet Using Feature Interaction and Fusion for Organ Segmentation in\figure_9_page19.jpeg
2025-11-09 10:07:59,323 - INFO - root - 成功添加图片 10：./export\images_An Effective UNet Using Feature Interaction and Fusion for Organ Segmentation in\figure_10_page19.jpeg
2025-11-09 10:07:59,333 - INFO - root - 论文《An Effective UNet Using Feature Interaction and Fusion for Organ Segmentation in Medical Image》的分析已保存到 ./export\An Effective UNet Using Feature Interaction and Fusion for Organ Segmentation in.md
2025-11-09 10:07:59,343 - INFO - root - 正在总结论文 30/30: TwinLiteNet+: An Enhanced Multi-Task Segmentation Model for Autonomous Driving
2025-11-09 10:07:59,345 - INFO - root - LLMClient: rate limit reached, sleeping 12.1s
2025-11-09 10:08:22,814 - INFO - root - LLMClient: rate limit reached, sleeping 17.2s
2025-11-09 10:09:04,202 - INFO - root - LLMClient: rate limit reached, sleeping 7.3s
2025-11-09 10:09:11,822 - ERROR - root - LLMClient: generation error: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. 
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 250
Please retry in 47.09277372s. [links {
  description: "Learn more about Gemini API quotas"
  url: "https://ai.google.dev/gemini-api/docs/rate-limits"
}
, violations {
  quota_metric: "generativelanguage.googleapis.com/generate_content_free_tier_requests"
  quota_id: "GenerateRequestsPerDayPerProjectPerModel-FreeTier"
  quota_dimensions {
    key: "model"
    value: "gemini-2.5-flash"
  }
  quota_dimensions {
    key: "location"
    value: "global"
  }
  quota_value: 250
}
, retry_delay {
  seconds: 47
}
]
Traceback (most recent call last):
  File "D:\ChatPaper\llm_client.py", line 117, in generate
    resp = self.model.generate_content(prompt, safety_settings=self.safety_settings)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\google\generativeai\generative_models.py", line 331, in generate_content
    response = self._client.generate_content(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\google\ai\generativelanguage_v1beta\services\generative_service\client.py", line 835, in generate_content
    response = rpc(
               ^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\google\api_core\gapic_v1\method.py", line 131, in __call__
    return wrapped_func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 294, in retry_wrapped_func
    return retry_target(
           ^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 156, in retry_target
    next_sleep = _retry_error_helper(
                 ^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\google\api_core\retry\retry_base.py", line 214, in _retry_error_helper
    raise final_exc from source_exc
  File "D:\ChatPaper\.venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 147, in retry_target
    result = target()
             ^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\google\api_core\timeout.py", line 130, in func_with_timeout
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\google\api_core\grpc_helpers.py", line 77, in error_remapped_callable
    raise exceptions.from_grpc_error(exc) from exc
google.api_core.exceptions.ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. 
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 250
Please retry in 47.09277372s. [links {
  description: "Learn more about Gemini API quotas"
  url: "https://ai.google.dev/gemini-api/docs/rate-limits"
}
, violations {
  quota_metric: "generativelanguage.googleapis.com/generate_content_free_tier_requests"
  quota_id: "GenerateRequestsPerDayPerProjectPerModel-FreeTier"
  quota_dimensions {
    key: "model"
    value: "gemini-2.5-flash"
  }
  quota_dimensions {
    key: "location"
    value: "global"
  }
  quota_value: 250
}
, retry_delay {
  seconds: 47
}
]
2025-11-09 10:09:11,825 - WARNING - root - LLMClient: quota/rate detected, sleeping 60 s then retrying
2025-11-09 10:10:11,826 - INFO - root - LLMClient: retry attempt 2 for generation
2025-11-09 10:10:12,768 - ERROR - root - LLMClient: generation error: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. 
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 250
Please retry in 46.154652662s. [links {
  description: "Learn more about Gemini API quotas"
  url: "https://ai.google.dev/gemini-api/docs/rate-limits"
}
, violations {
  quota_metric: "generativelanguage.googleapis.com/generate_content_free_tier_requests"
  quota_id: "GenerateRequestsPerDayPerProjectPerModel-FreeTier"
  quota_dimensions {
    key: "model"
    value: "gemini-2.5-flash"
  }
  quota_dimensions {
    key: "location"
    value: "global"
  }
  quota_value: 250
}
, retry_delay {
  seconds: 46
}
]
Traceback (most recent call last):
  File "D:\ChatPaper\llm_client.py", line 117, in generate
    resp = self.model.generate_content(prompt, safety_settings=self.safety_settings)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\google\generativeai\generative_models.py", line 331, in generate_content
    response = self._client.generate_content(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\google\ai\generativelanguage_v1beta\services\generative_service\client.py", line 835, in generate_content
    response = rpc(
               ^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\google\api_core\gapic_v1\method.py", line 131, in __call__
    return wrapped_func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 294, in retry_wrapped_func
    return retry_target(
           ^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 156, in retry_target
    next_sleep = _retry_error_helper(
                 ^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\google\api_core\retry\retry_base.py", line 214, in _retry_error_helper
    raise final_exc from source_exc
  File "D:\ChatPaper\.venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 147, in retry_target
    result = target()
             ^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\google\api_core\timeout.py", line 130, in func_with_timeout
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\google\api_core\grpc_helpers.py", line 77, in error_remapped_callable
    raise exceptions.from_grpc_error(exc) from exc
google.api_core.exceptions.ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. 
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 250
Please retry in 46.154652662s. [links {
  description: "Learn more about Gemini API quotas"
  url: "https://ai.google.dev/gemini-api/docs/rate-limits"
}
, violations {
  quota_metric: "generativelanguage.googleapis.com/generate_content_free_tier_requests"
  quota_id: "GenerateRequestsPerDayPerProjectPerModel-FreeTier"
  quota_dimensions {
    key: "model"
    value: "gemini-2.5-flash"
  }
  quota_dimensions {
    key: "location"
    value: "global"
  }
  quota_value: 250
}
, retry_delay {
  seconds: 46
}
]
2025-11-09 10:10:12,770 - WARNING - root - LLMClient: quota/rate detected, sleeping 60 s then retrying
2025-11-09 10:11:12,771 - INFO - root - LLMClient: retry attempt 3 for generation
2025-11-09 10:11:14,264 - ERROR - root - LLMClient: generation error: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. 
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 250
Please retry in 44.666304166s. [links {
  description: "Learn more about Gemini API quotas"
  url: "https://ai.google.dev/gemini-api/docs/rate-limits"
}
, violations {
  quota_metric: "generativelanguage.googleapis.com/generate_content_free_tier_requests"
  quota_id: "GenerateRequestsPerDayPerProjectPerModel-FreeTier"
  quota_dimensions {
    key: "model"
    value: "gemini-2.5-flash"
  }
  quota_dimensions {
    key: "location"
    value: "global"
  }
  quota_value: 250
}
, retry_delay {
  seconds: 44
}
]
Traceback (most recent call last):
  File "D:\ChatPaper\llm_client.py", line 117, in generate
    resp = self.model.generate_content(prompt, safety_settings=self.safety_settings)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\google\generativeai\generative_models.py", line 331, in generate_content
    response = self._client.generate_content(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\google\ai\generativelanguage_v1beta\services\generative_service\client.py", line 835, in generate_content
    response = rpc(
               ^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\google\api_core\gapic_v1\method.py", line 131, in __call__
    return wrapped_func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 294, in retry_wrapped_func
    return retry_target(
           ^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 156, in retry_target
    next_sleep = _retry_error_helper(
                 ^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\google\api_core\retry\retry_base.py", line 214, in _retry_error_helper
    raise final_exc from source_exc
  File "D:\ChatPaper\.venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 147, in retry_target
    result = target()
             ^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\google\api_core\timeout.py", line 130, in func_with_timeout
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\google\api_core\grpc_helpers.py", line 77, in error_remapped_callable
    raise exceptions.from_grpc_error(exc) from exc
google.api_core.exceptions.ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. 
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 250
Please retry in 44.666304166s. [links {
  description: "Learn more about Gemini API quotas"
  url: "https://ai.google.dev/gemini-api/docs/rate-limits"
}
, violations {
  quota_metric: "generativelanguage.googleapis.com/generate_content_free_tier_requests"
  quota_id: "GenerateRequestsPerDayPerProjectPerModel-FreeTier"
  quota_dimensions {
    key: "model"
    value: "gemini-2.5-flash"
  }
  quota_dimensions {
    key: "location"
    value: "global"
  }
  quota_value: 250
}
, retry_delay {
  seconds: 44
}
]
2025-11-09 10:11:14,267 - INFO - root - 正在提取论文图片...
2025-11-09 10:11:14,617 - INFO - root - 已保存图片 1/10：./export\images_TwinLiteNet+_ An Enhanced Multi-Task Segmentation Model for Autonomous Driving\figure_1_page23.jpeg
2025-11-09 10:11:14,653 - INFO - root - 已保存图片 2/10：./export\images_TwinLiteNet+_ An Enhanced Multi-Task Segmentation Model for Autonomous Driving\figure_2_page6.jpeg
2025-11-09 10:11:14,696 - INFO - root - 已保存图片 3/10：./export\images_TwinLiteNet+_ An Enhanced Multi-Task Segmentation Model for Autonomous Driving\figure_3_page6.png
2025-11-09 10:11:14,750 - INFO - root - 已保存图片 4/10：./export\images_TwinLiteNet+_ An Enhanced Multi-Task Segmentation Model for Autonomous Driving\figure_4_page6.png
2025-11-09 10:11:14,794 - INFO - root - 已保存图片 5/10：./export\images_TwinLiteNet+_ An Enhanced Multi-Task Segmentation Model for Autonomous Driving\figure_5_page8.jpeg
2025-11-09 10:11:14,835 - INFO - root - 已保存图片 6/10：./export\images_TwinLiteNet+_ An Enhanced Multi-Task Segmentation Model for Autonomous Driving\figure_6_page17.jpeg
2025-11-09 10:11:14,883 - INFO - root - 已保存图片 7/10：./export\images_TwinLiteNet+_ An Enhanced Multi-Task Segmentation Model for Autonomous Driving\figure_7_page17.jpeg
2025-11-09 10:11:14,919 - INFO - root - 已保存图片 8/10：./export\images_TwinLiteNet+_ An Enhanced Multi-Task Segmentation Model for Autonomous Driving\figure_8_page17.jpeg
2025-11-09 10:11:14,961 - INFO - root - 已保存图片 9/10：./export\images_TwinLiteNet+_ An Enhanced Multi-Task Segmentation Model for Autonomous Driving\figure_9_page17.jpeg
2025-11-09 10:11:15,005 - INFO - root - 已保存图片 10/10：./export\images_TwinLiteNet+_ An Enhanced Multi-Task Segmentation Model for Autonomous Driving\figure_10_page17.jpeg
2025-11-09 10:11:15,011 - INFO - root - 成功添加图片 1：./export\images_TwinLiteNet+_ An Enhanced Multi-Task Segmentation Model for Autonomous Driving\figure_1_page23.jpeg
2025-11-09 10:11:15,011 - INFO - root - 成功添加图片 2：./export\images_TwinLiteNet+_ An Enhanced Multi-Task Segmentation Model for Autonomous Driving\figure_2_page6.jpeg
2025-11-09 10:11:15,011 - INFO - root - 成功添加图片 3：./export\images_TwinLiteNet+_ An Enhanced Multi-Task Segmentation Model for Autonomous Driving\figure_3_page6.png
2025-11-09 10:11:15,011 - INFO - root - 成功添加图片 4：./export\images_TwinLiteNet+_ An Enhanced Multi-Task Segmentation Model for Autonomous Driving\figure_4_page6.png
2025-11-09 10:11:15,011 - INFO - root - 成功添加图片 5：./export\images_TwinLiteNet+_ An Enhanced Multi-Task Segmentation Model for Autonomous Driving\figure_5_page8.jpeg
2025-11-09 10:11:15,011 - INFO - root - 成功添加图片 6：./export\images_TwinLiteNet+_ An Enhanced Multi-Task Segmentation Model for Autonomous Driving\figure_6_page17.jpeg
2025-11-09 10:11:15,017 - INFO - root - 成功添加图片 7：./export\images_TwinLiteNet+_ An Enhanced Multi-Task Segmentation Model for Autonomous Driving\figure_7_page17.jpeg
2025-11-09 10:11:15,017 - INFO - root - 成功添加图片 8：./export\images_TwinLiteNet+_ An Enhanced Multi-Task Segmentation Model for Autonomous Driving\figure_8_page17.jpeg
2025-11-09 10:11:15,017 - INFO - root - 成功添加图片 9：./export\images_TwinLiteNet+_ An Enhanced Multi-Task Segmentation Model for Autonomous Driving\figure_9_page17.jpeg
2025-11-09 10:11:15,017 - INFO - root - 成功添加图片 10：./export\images_TwinLiteNet+_ An Enhanced Multi-Task Segmentation Model for Autonomous Driving\figure_10_page17.jpeg
2025-11-09 10:11:15,028 - INFO - root - 论文《TwinLiteNet+: An Enhanced Multi-Task Segmentation Model for Autonomous Driving》的分析已保存到 ./export\TwinLiteNet+_ An Enhanced Multi-Task Segmentation Model for Autonomous Driving.md
2025-11-09 10:11:15,034 - INFO - root - summary time: 31076.43 seconds
2025-11-09 10:23:21,960 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-09 10:23:21,960 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-09 10:23:21,960 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-09 10:23:22,718 - INFO - root - LLMClient: trying model gemini-2.5-flash
2025-11-09 10:23:23,714 - INFO - root - LLMClient: trying model gemini-2.5-pro
2025-11-09 10:23:34,497 - INFO - root - LLMClient: initialized model gemini-2.5-pro
2025-11-09 10:23:34,497 - INFO - root - 使用 LLM 模型: gemini-2.5-pro
2025-11-09 10:23:34,498 - INFO - root - === 运行配置 ===
2025-11-09 10:23:34,498 - INFO - root - 处理模式: arxiv在线搜索
2025-11-09 10:23:34,499 - INFO - root - 关键词: Quant
2025-11-09 10:23:34,499 - INFO - root - 查询: block float point
2025-11-09 10:23:34,499 - INFO - root - 排序: None
2025-11-09 10:23:34,500 - INFO - root - 最近天数: 180
2025-11-09 10:23:34,500 - INFO - root - 最大处理数量: 50
2025-11-09 10:23:34,500 - INFO - root - 保存图片: 是
2025-11-09 10:23:34,501 - INFO - root - 输出语言: 中文
2025-11-09 10:23:34,501 - INFO - root - 强制重新处理: 否
2025-11-09 10:23:34,501 - INFO - root - ====================
2025-11-09 10:23:34,501 - INFO - root - 使用 arXiv 搜索模式（通过 chat_arxiv 模块获取）
2025-11-09 10:24:22,578 - INFO - root - 正在总结论文 1/30: From Uniform to Adaptive: General Skip-Block Mechanisms for Efficient PDE Neural Operators
2025-11-09 10:24:22,751 - ERROR - root - LLMClient: generation error: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. 
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 50
Please retry in 35.947403049s. [links {
  description: "Learn more about Gemini API quotas"
  url: "https://ai.google.dev/gemini-api/docs/rate-limits"
}
, violations {
  quota_metric: "generativelanguage.googleapis.com/generate_content_free_tier_requests"
  quota_id: "GenerateRequestsPerDayPerProjectPerModel-FreeTier"
  quota_dimensions {
    key: "model"
    value: "gemini-2.5-pro"
  }
  quota_dimensions {
    key: "location"
    value: "global"
  }
  quota_value: 50
}
, retry_delay {
  seconds: 35
}
]
Traceback (most recent call last):
  File "D:\ChatPaper\llm_client.py", line 117, in generate
    resp = self.model.generate_content(prompt, safety_settings=self.safety_settings)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\google\generativeai\generative_models.py", line 331, in generate_content
    response = self._client.generate_content(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\google\ai\generativelanguage_v1beta\services\generative_service\client.py", line 835, in generate_content
    response = rpc(
               ^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\google\api_core\gapic_v1\method.py", line 131, in __call__
    return wrapped_func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 294, in retry_wrapped_func
    return retry_target(
           ^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 156, in retry_target
    next_sleep = _retry_error_helper(
                 ^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\google\api_core\retry\retry_base.py", line 214, in _retry_error_helper
    raise final_exc from source_exc
  File "D:\ChatPaper\.venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 147, in retry_target
    result = target()
             ^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\google\api_core\timeout.py", line 130, in func_with_timeout
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\google\api_core\grpc_helpers.py", line 77, in error_remapped_callable
    raise exceptions.from_grpc_error(exc) from exc
google.api_core.exceptions.ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. 
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 50
Please retry in 35.947403049s. [links {
  description: "Learn more about Gemini API quotas"
  url: "https://ai.google.dev/gemini-api/docs/rate-limits"
}
, violations {
  quota_metric: "generativelanguage.googleapis.com/generate_content_free_tier_requests"
  quota_id: "GenerateRequestsPerDayPerProjectPerModel-FreeTier"
  quota_dimensions {
    key: "model"
    value: "gemini-2.5-pro"
  }
  quota_dimensions {
    key: "location"
    value: "global"
  }
  quota_value: 50
}
, retry_delay {
  seconds: 35
}
]
2025-11-09 10:24:22,758 - WARNING - root - LLMClient: quota/rate detected, sleeping 60 s then retrying
2025-11-09 10:25:22,762 - INFO - root - LLMClient: retry attempt 2 for generation
2025-11-09 10:25:23,508 - ERROR - root - LLMClient: generation error: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. 
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 50
Please retry in 35.205752668s. [links {
  description: "Learn more about Gemini API quotas"
  url: "https://ai.google.dev/gemini-api/docs/rate-limits"
}
, violations {
  quota_metric: "generativelanguage.googleapis.com/generate_content_free_tier_requests"
  quota_id: "GenerateRequestsPerDayPerProjectPerModel-FreeTier"
  quota_dimensions {
    key: "model"
    value: "gemini-2.5-pro"
  }
  quota_dimensions {
    key: "location"
    value: "global"
  }
  quota_value: 50
}
, retry_delay {
  seconds: 35
}
]
Traceback (most recent call last):
  File "D:\ChatPaper\llm_client.py", line 117, in generate
    resp = self.model.generate_content(prompt, safety_settings=self.safety_settings)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\google\generativeai\generative_models.py", line 331, in generate_content
    response = self._client.generate_content(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\google\ai\generativelanguage_v1beta\services\generative_service\client.py", line 835, in generate_content
    response = rpc(
               ^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\google\api_core\gapic_v1\method.py", line 131, in __call__
    return wrapped_func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 294, in retry_wrapped_func
    return retry_target(
           ^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 156, in retry_target
    next_sleep = _retry_error_helper(
                 ^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\google\api_core\retry\retry_base.py", line 214, in _retry_error_helper
    raise final_exc from source_exc
  File "D:\ChatPaper\.venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 147, in retry_target
    result = target()
             ^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\google\api_core\timeout.py", line 130, in func_with_timeout
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\google\api_core\grpc_helpers.py", line 77, in error_remapped_callable
    raise exceptions.from_grpc_error(exc) from exc
google.api_core.exceptions.ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. 
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 50
Please retry in 35.205752668s. [links {
  description: "Learn more about Gemini API quotas"
  url: "https://ai.google.dev/gemini-api/docs/rate-limits"
}
, violations {
  quota_metric: "generativelanguage.googleapis.com/generate_content_free_tier_requests"
  quota_id: "GenerateRequestsPerDayPerProjectPerModel-FreeTier"
  quota_dimensions {
    key: "model"
    value: "gemini-2.5-pro"
  }
  quota_dimensions {
    key: "location"
    value: "global"
  }
  quota_value: 50
}
, retry_delay {
  seconds: 35
}
]
2025-11-09 10:25:23,511 - WARNING - root - LLMClient: quota/rate detected, sleeping 60 s then retrying
2025-11-09 10:26:23,511 - INFO - root - LLMClient: retry attempt 3 for generation
2025-11-09 10:26:24,694 - ERROR - root - LLMClient: generation error: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. 
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 50
Please retry in 34.01837253s. [links {
  description: "Learn more about Gemini API quotas"
  url: "https://ai.google.dev/gemini-api/docs/rate-limits"
}
, violations {
  quota_metric: "generativelanguage.googleapis.com/generate_content_free_tier_requests"
  quota_id: "GenerateRequestsPerDayPerProjectPerModel-FreeTier"
  quota_dimensions {
    key: "model"
    value: "gemini-2.5-pro"
  }
  quota_dimensions {
    key: "location"
    value: "global"
  }
  quota_value: 50
}
, retry_delay {
  seconds: 34
}
]
Traceback (most recent call last):
  File "D:\ChatPaper\llm_client.py", line 117, in generate
    resp = self.model.generate_content(prompt, safety_settings=self.safety_settings)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\google\generativeai\generative_models.py", line 331, in generate_content
    response = self._client.generate_content(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\google\ai\generativelanguage_v1beta\services\generative_service\client.py", line 835, in generate_content
    response = rpc(
               ^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\google\api_core\gapic_v1\method.py", line 131, in __call__
    return wrapped_func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 294, in retry_wrapped_func
    return retry_target(
           ^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 156, in retry_target
    next_sleep = _retry_error_helper(
                 ^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\google\api_core\retry\retry_base.py", line 214, in _retry_error_helper
    raise final_exc from source_exc
  File "D:\ChatPaper\.venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 147, in retry_target
    result = target()
             ^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\google\api_core\timeout.py", line 130, in func_with_timeout
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\google\api_core\grpc_helpers.py", line 77, in error_remapped_callable
    raise exceptions.from_grpc_error(exc) from exc
google.api_core.exceptions.ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. 
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 50
Please retry in 34.01837253s. [links {
  description: "Learn more about Gemini API quotas"
  url: "https://ai.google.dev/gemini-api/docs/rate-limits"
}
, violations {
  quota_metric: "generativelanguage.googleapis.com/generate_content_free_tier_requests"
  quota_id: "GenerateRequestsPerDayPerProjectPerModel-FreeTier"
  quota_dimensions {
    key: "model"
    value: "gemini-2.5-pro"
  }
  quota_dimensions {
    key: "location"
    value: "global"
  }
  quota_value: 50
}
, retry_delay {
  seconds: 34
}
]
2025-11-09 10:26:24,828 - ERROR - root - LLMClient: generation error: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. 
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 50
Please retry in 33.879301367s. [links {
  description: "Learn more about Gemini API quotas"
  url: "https://ai.google.dev/gemini-api/docs/rate-limits"
}
, violations {
  quota_metric: "generativelanguage.googleapis.com/generate_content_free_tier_requests"
  quota_id: "GenerateRequestsPerDayPerProjectPerModel-FreeTier"
  quota_dimensions {
    key: "model"
    value: "gemini-2.5-pro"
  }
  quota_dimensions {
    key: "location"
    value: "global"
  }
  quota_value: 50
}
, retry_delay {
  seconds: 33
}
]
Traceback (most recent call last):
  File "D:\ChatPaper\llm_client.py", line 117, in generate
    resp = self.model.generate_content(prompt, safety_settings=self.safety_settings)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\google\generativeai\generative_models.py", line 331, in generate_content
    response = self._client.generate_content(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\google\ai\generativelanguage_v1beta\services\generative_service\client.py", line 835, in generate_content
    response = rpc(
               ^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\google\api_core\gapic_v1\method.py", line 131, in __call__
    return wrapped_func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 294, in retry_wrapped_func
    return retry_target(
           ^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 156, in retry_target
    next_sleep = _retry_error_helper(
                 ^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\google\api_core\retry\retry_base.py", line 214, in _retry_error_helper
    raise final_exc from source_exc
  File "D:\ChatPaper\.venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 147, in retry_target
    result = target()
             ^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\google\api_core\timeout.py", line 130, in func_with_timeout
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\google\api_core\grpc_helpers.py", line 77, in error_remapped_callable
    raise exceptions.from_grpc_error(exc) from exc
google.api_core.exceptions.ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. 
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 50
Please retry in 33.879301367s. [links {
  description: "Learn more about Gemini API quotas"
  url: "https://ai.google.dev/gemini-api/docs/rate-limits"
}
, violations {
  quota_metric: "generativelanguage.googleapis.com/generate_content_free_tier_requests"
  quota_id: "GenerateRequestsPerDayPerProjectPerModel-FreeTier"
  quota_dimensions {
    key: "model"
    value: "gemini-2.5-pro"
  }
  quota_dimensions {
    key: "location"
    value: "global"
  }
  quota_value: 50
}
, retry_delay {
  seconds: 33
}
]
2025-11-09 10:26:24,830 - WARNING - root - LLMClient: quota/rate detected, sleeping 60 s then retrying
2025-11-09 10:27:24,831 - INFO - root - LLMClient: retry attempt 2 for generation
2025-11-09 10:27:25,705 - ERROR - root - LLMClient: generation error: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. 
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 50
Please retry in 32.998956656s. [links {
  description: "Learn more about Gemini API quotas"
  url: "https://ai.google.dev/gemini-api/docs/rate-limits"
}
, violations {
  quota_metric: "generativelanguage.googleapis.com/generate_content_free_tier_requests"
  quota_id: "GenerateRequestsPerDayPerProjectPerModel-FreeTier"
  quota_dimensions {
    key: "model"
    value: "gemini-2.5-pro"
  }
  quota_dimensions {
    key: "location"
    value: "global"
  }
  quota_value: 50
}
, retry_delay {
  seconds: 32
}
]
Traceback (most recent call last):
  File "D:\ChatPaper\llm_client.py", line 117, in generate
    resp = self.model.generate_content(prompt, safety_settings=self.safety_settings)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\google\generativeai\generative_models.py", line 331, in generate_content
    response = self._client.generate_content(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\google\ai\generativelanguage_v1beta\services\generative_service\client.py", line 835, in generate_content
    response = rpc(
               ^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\google\api_core\gapic_v1\method.py", line 131, in __call__
    return wrapped_func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 294, in retry_wrapped_func
    return retry_target(
           ^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 156, in retry_target
    next_sleep = _retry_error_helper(
                 ^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\google\api_core\retry\retry_base.py", line 214, in _retry_error_helper
    raise final_exc from source_exc
  File "D:\ChatPaper\.venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 147, in retry_target
    result = target()
             ^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\google\api_core\timeout.py", line 130, in func_with_timeout
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\google\api_core\grpc_helpers.py", line 77, in error_remapped_callable
    raise exceptions.from_grpc_error(exc) from exc
google.api_core.exceptions.ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. 
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 50
Please retry in 32.998956656s. [links {
  description: "Learn more about Gemini API quotas"
  url: "https://ai.google.dev/gemini-api/docs/rate-limits"
}
, violations {
  quota_metric: "generativelanguage.googleapis.com/generate_content_free_tier_requests"
  quota_id: "GenerateRequestsPerDayPerProjectPerModel-FreeTier"
  quota_dimensions {
    key: "model"
    value: "gemini-2.5-pro"
  }
  quota_dimensions {
    key: "location"
    value: "global"
  }
  quota_value: 50
}
, retry_delay {
  seconds: 32
}
]
2025-11-09 10:27:25,707 - WARNING - root - LLMClient: quota/rate detected, sleeping 60 s then retrying
2025-11-09 10:28:25,708 - INFO - root - LLMClient: retry attempt 3 for generation
2025-11-09 10:28:26,444 - ERROR - root - LLMClient: generation error: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. 
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 50
Please retry in 32.258710193s. [links {
  description: "Learn more about Gemini API quotas"
  url: "https://ai.google.dev/gemini-api/docs/rate-limits"
}
, violations {
  quota_metric: "generativelanguage.googleapis.com/generate_content_free_tier_requests"
  quota_id: "GenerateRequestsPerDayPerProjectPerModel-FreeTier"
  quota_dimensions {
    key: "model"
    value: "gemini-2.5-pro"
  }
  quota_dimensions {
    key: "location"
    value: "global"
  }
  quota_value: 50
}
, retry_delay {
  seconds: 32
}
]
Traceback (most recent call last):
  File "D:\ChatPaper\llm_client.py", line 117, in generate
    resp = self.model.generate_content(prompt, safety_settings=self.safety_settings)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\google\generativeai\generative_models.py", line 331, in generate_content
    response = self._client.generate_content(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\google\ai\generativelanguage_v1beta\services\generative_service\client.py", line 835, in generate_content
    response = rpc(
               ^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\google\api_core\gapic_v1\method.py", line 131, in __call__
    return wrapped_func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 294, in retry_wrapped_func
    return retry_target(
           ^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 156, in retry_target
    next_sleep = _retry_error_helper(
                 ^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\google\api_core\retry\retry_base.py", line 214, in _retry_error_helper
    raise final_exc from source_exc
  File "D:\ChatPaper\.venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 147, in retry_target
    result = target()
             ^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\google\api_core\timeout.py", line 130, in func_with_timeout
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\google\api_core\grpc_helpers.py", line 77, in error_remapped_callable
    raise exceptions.from_grpc_error(exc) from exc
google.api_core.exceptions.ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. 
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 50
Please retry in 32.258710193s. [links {
  description: "Learn more about Gemini API quotas"
  url: "https://ai.google.dev/gemini-api/docs/rate-limits"
}
, violations {
  quota_metric: "generativelanguage.googleapis.com/generate_content_free_tier_requests"
  quota_id: "GenerateRequestsPerDayPerProjectPerModel-FreeTier"
  quota_dimensions {
    key: "model"
    value: "gemini-2.5-pro"
  }
  quota_dimensions {
    key: "location"
    value: "global"
  }
  quota_value: 50
}
, retry_delay {
  seconds: 32
}
]
2025-11-09 10:28:26,558 - ERROR - root - LLMClient: generation error: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. 
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 50
Please retry in 32.138240581s. [links {
  description: "Learn more about Gemini API quotas"
  url: "https://ai.google.dev/gemini-api/docs/rate-limits"
}
, violations {
  quota_metric: "generativelanguage.googleapis.com/generate_content_free_tier_requests"
  quota_id: "GenerateRequestsPerDayPerProjectPerModel-FreeTier"
  quota_dimensions {
    key: "model"
    value: "gemini-2.5-pro"
  }
  quota_dimensions {
    key: "location"
    value: "global"
  }
  quota_value: 50
}
, retry_delay {
  seconds: 32
}
]
Traceback (most recent call last):
  File "D:\ChatPaper\llm_client.py", line 117, in generate
    resp = self.model.generate_content(prompt, safety_settings=self.safety_settings)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\google\generativeai\generative_models.py", line 331, in generate_content
    response = self._client.generate_content(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\google\ai\generativelanguage_v1beta\services\generative_service\client.py", line 835, in generate_content
    response = rpc(
               ^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\google\api_core\gapic_v1\method.py", line 131, in __call__
    return wrapped_func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 294, in retry_wrapped_func
    return retry_target(
           ^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 156, in retry_target
    next_sleep = _retry_error_helper(
                 ^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\google\api_core\retry\retry_base.py", line 214, in _retry_error_helper
    raise final_exc from source_exc
  File "D:\ChatPaper\.venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 147, in retry_target
    result = target()
             ^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\google\api_core\timeout.py", line 130, in func_with_timeout
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\google\api_core\grpc_helpers.py", line 77, in error_remapped_callable
    raise exceptions.from_grpc_error(exc) from exc
google.api_core.exceptions.ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. 
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 50
Please retry in 32.138240581s. [links {
  description: "Learn more about Gemini API quotas"
  url: "https://ai.google.dev/gemini-api/docs/rate-limits"
}
, violations {
  quota_metric: "generativelanguage.googleapis.com/generate_content_free_tier_requests"
  quota_id: "GenerateRequestsPerDayPerProjectPerModel-FreeTier"
  quota_dimensions {
    key: "model"
    value: "gemini-2.5-pro"
  }
  quota_dimensions {
    key: "location"
    value: "global"
  }
  quota_value: 50
}
, retry_delay {
  seconds: 32
}
]
2025-11-09 10:28:26,561 - WARNING - root - LLMClient: quota/rate detected, sleeping 60 s then retrying
2025-11-09 10:34:14,529 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-09 10:34:14,529 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-09 10:34:14,529 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-09 10:34:15,175 - INFO - root - LLMClient: trying model gemini-2.5-flash
2025-11-09 10:34:16,017 - INFO - root - LLMClient: trying model gemini-2.5-pro
2025-11-09 10:34:16,375 - WARNING - root - LLMClient: no usable model found, LLM disabled
2025-11-09 10:34:16,375 - INFO - root - LLM 未初始化或不可用，后续生成将返回备用消息
2025-11-09 10:34:16,375 - INFO - root - === 运行配置 ===
2025-11-09 10:34:16,376 - INFO - root - 处理模式: arxiv在线搜索
2025-11-09 10:34:16,376 - INFO - root - 关键词: Quant
2025-11-09 10:34:16,376 - INFO - root - 查询: block float point
2025-11-09 10:34:16,376 - INFO - root - 排序: None
2025-11-09 10:34:16,377 - INFO - root - 最近天数: 180
2025-11-09 10:34:16,377 - INFO - root - 最大处理数量: 50
2025-11-09 10:34:16,377 - INFO - root - 保存图片: 是
2025-11-09 10:34:16,378 - INFO - root - 输出语言: 中文
2025-11-09 10:34:16,378 - INFO - root - 强制重新处理: 否
2025-11-09 10:34:16,379 - INFO - root - ====================
2025-11-09 10:34:16,379 - INFO - root - 使用 arXiv 搜索模式（通过 chat_arxiv 模块获取）
2025-11-09 10:34:16,380 - ERROR - root - 从 chat_arxiv 获取论文列表失败: name 'get_all_titles_from_web' is not defined
2025-11-09 10:34:16,384 - INFO - root - 没有找到要处理的论文，程序退出
2025-11-09 10:34:16,384 - INFO - root - summary time: 1.85 seconds
2025-11-09 10:40:38,168 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-09 10:40:38,176 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-09 10:40:38,176 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-09 10:40:38,993 - INFO - root - LLMClient: trying model gemini-2.5-flash
2025-11-09 10:40:39,838 - INFO - root - LLMClient: trying model gemini-2.5-pro
2025-11-09 10:40:40,189 - WARNING - root - LLMClient: no usable model found, LLM disabled
2025-11-09 10:40:40,190 - INFO - root - LLM 未初始化或不可用，后续生成将返回备用消息
2025-11-09 10:40:40,190 - INFO - root - === 运行配置 ===
2025-11-09 10:40:40,190 - INFO - root - 处理模式: arxiv在线搜索
2025-11-09 10:40:40,190 - INFO - root - 关键词: Quant
2025-11-09 10:40:40,191 - INFO - root - 查询: block float point
2025-11-09 10:40:40,191 - INFO - root - 排序: None
2025-11-09 10:40:40,191 - INFO - root - 最近天数: 180
2025-11-09 10:40:40,192 - INFO - root - 最大处理数量: 50
2025-11-09 10:40:40,192 - INFO - root - 保存图片: 是
2025-11-09 10:40:40,192 - INFO - root - 输出语言: 中文
2025-11-09 10:40:40,193 - INFO - root - 强制重新处理: 否
2025-11-09 10:40:40,193 - INFO - root - ====================
2025-11-09 10:40:40,193 - INFO - root - 使用 arXiv 搜索模式（通过 chat_arxiv 模块获取）
2025-11-09 10:40:40,193 - ERROR - root - 从 chat_arxiv 获取论文列表失败: get_all_titles_from_web() missing 1 required positional argument: 'keyword'
2025-11-09 10:40:40,195 - INFO - root - 没有找到要处理的论文，程序退出
2025-11-09 10:40:40,195 - INFO - root - summary time: 2.03 seconds
2025-11-09 10:43:10,381 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-09 10:43:10,381 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-09 10:43:10,381 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-09 10:43:10,983 - INFO - root - LLMClient: trying model gemini-2.5-flash
2025-11-09 10:43:11,896 - INFO - root - LLMClient: trying model gemini-2.5-pro
2025-11-09 10:43:12,334 - WARNING - root - LLMClient: no usable model found, LLM disabled
2025-11-09 10:43:12,335 - INFO - root - LLM 未初始化或不可用，后续生成将返回备用消息
2025-11-09 10:43:12,335 - INFO - root - === 运行配置 ===
2025-11-09 10:43:12,335 - INFO - root - 处理模式: arxiv在线搜索
2025-11-09 10:43:12,335 - INFO - root - 关键词: Quant
2025-11-09 10:43:12,336 - INFO - root - 查询: block float point
2025-11-09 10:43:12,336 - INFO - root - 排序: None
2025-11-09 10:43:12,336 - INFO - root - 最近天数: 180
2025-11-09 10:43:12,336 - INFO - root - 最大处理数量: 50
2025-11-09 10:43:12,337 - INFO - root - 保存图片: 是
2025-11-09 10:43:12,337 - INFO - root - 输出语言: 中文
2025-11-09 10:43:12,338 - INFO - root - 强制重新处理: 否
2025-11-09 10:43:12,338 - INFO - root - ====================
2025-11-09 10:43:12,338 - INFO - root - 使用 arXiv 搜索模式（通过 chat_arxiv 模块获取）
2025-11-09 10:43:12,338 - INFO - root - Fetching page 1 with URL: https://arxiv.org/search/?query=block+float+point&searchtype=all&abstracts=show&order=-announced_date_first&size=50
2025-11-09 10:43:14,471 - INFO - root - get_all_titles_from_web 
2025-11-09 10:43:14,471 - INFO - root - Page:0, Index:0, From Uniform to Adaptive: General Skip-Block Mechanisms for Efficient PDE Neural Operators, https://arxiv.org/pdf/2511.00032, 2025-11-04
2025-11-09 10:43:14,471 - INFO - root - Page:0, Index:1, INT v.s. FP: A Comprehensive Study of Fine-Grained Low-bit Quantization Formats, https://arxiv.org/pdf/2510.25602, 2025-10-29
2025-11-09 10:43:14,471 - INFO - root - Page:0, Index:2, MX+: Pushing the Limits of Microscaling Formats for Efficient Large Language Model Serving, https://arxiv.org/pdf/2510.14557, 2025-10-16
2025-11-09 10:43:14,471 - INFO - root - Page:0, Index:3, F-BFQ: Flexible Block Floating-Point Quantization Accelerator for LLMs, https://arxiv.org/pdf/2510.13401, 2025-10-15
2025-11-09 10:43:14,471 - INFO - root - Page:0, Index:4, Computationally Efficient Neural Receivers via Axial Self-Attention, https://arxiv.org/pdf/2510.12941, 2025-10-14
2025-11-09 10:43:14,471 - INFO - root - Page:0, Index:5, Efficient In-Memory Acceleration of Sparse Block Diagonal LLMs, https://arxiv.org/pdf/2510.11192, 2025-10-13
2025-11-09 10:43:14,471 - INFO - root - Page:0, Index:6, Dissecting Transformers: A CLEAR Perspective towards Green AI, https://arxiv.org/pdf/2510.02810, 2025-10-03
2025-11-09 10:43:14,471 - INFO - root - Page:0, Index:7, Microscaling Floating Point Formats for Large Language Models, https://arxiv.org/pdf/2510.01863, 2025-10-02
2025-11-09 10:43:14,471 - INFO - root - Page:0, Index:8, Automated and Scalable SEM Image Analysis of Perovskite Solar Cell Materials via a Deep Segmentation Framework, https://arxiv.org/pdf/2509.26548, 2025-09-30
2025-11-09 10:43:14,471 - INFO - root - Page:0, Index:9, AMLA: MUL by ADD in FlashAttention Rescaling, https://arxiv.org/pdf/2509.25224, 2025-09-24
2025-11-09 10:43:14,471 - INFO - root - Page:0, Index:10, Pretraining Large Language Models with NVFP4, https://arxiv.org/pdf/2509.25149, 2025-09-29
2025-11-09 10:43:14,471 - INFO - root - Page:0, Index:11, Bridging the Gap Between Promise and Performance for Microscaling FP4 Quantization, https://arxiv.org/pdf/2509.23202, 2025-10-16
2025-11-09 10:43:14,471 - INFO - root - Page:0, Index:12, Towards Verified Compilation of Floating-point Optimization in Scientific Computing Programs, https://arxiv.org/pdf/2509.09019, 2025-09-10
2025-11-09 10:43:14,471 - INFO - root - Page:0, Index:13, Green Learning for STAR-RIS mmWave Systems with Implicit CSI, https://arxiv.org/pdf/2509.06820, 2025-09-08
2025-11-09 10:43:14,476 - INFO - root - Page:0, Index:14, A Compute&Memory Efficient Model-Driven Neural 5G Receiver for Edge AI-assisted RAN, https://arxiv.org/pdf/2508.12892, 2025-10-22
2025-11-09 10:43:14,476 - INFO - root - Page:0, Index:15, SNNSIR: A Simple Spiking Neural Network for Stereo Image Restoration, https://arxiv.org/pdf/2508.12271, 2025-08-17
2025-11-09 10:43:14,476 - INFO - root - Page:0, Index:16, SpikeSTAG: Spatial-Temporal Forecasting via GNN-SNN Collaboration, https://arxiv.org/pdf/2508.02069, 2025-08-18
2025-11-09 10:43:14,476 - INFO - root - Page:0, Index:17, DGEMM without FP64 Arithmetic - Using FP64 Emulation and FP8 Tensor Cores with Ozaki Scheme, https://arxiv.org/pdf/2508.00441, 2025-09-25
2025-11-09 10:43:14,477 - INFO - root - Page:0, Index:18, Scaling Probabilistic Circuits via Monarch Matrices, https://arxiv.org/pdf/2506.12383, 2025-06-14
2025-11-09 10:43:14,477 - INFO - root - Page:0, Index:19, Starting Positions Matter: A Study on Better Weight Initialization for Neural Network Quantization, https://arxiv.org/pdf/2506.10463, 2025-06-12
2025-11-09 10:43:14,477 - INFO - root - Page:0, Index:20, Recipes for Pre-training LLMs with MXFP8, https://arxiv.org/pdf/2506.08027, 2025-08-18
2025-11-09 10:43:14,477 - INFO - root - Page:0, Index:21, FP4 All the Way: Fully Quantized Training of LLMs, https://arxiv.org/pdf/2505.19115, 2025-08-10
2025-11-09 10:43:14,478 - INFO - root - Page:0, Index:22, Automatic Verification of Floating-Point Accumulation Networks, https://arxiv.org/pdf/2505.18791, 2025-05-24
2025-11-09 10:43:14,478 - INFO - root - Page:0, Index:23, MXDOTP: A RISC-V ISA Extension for Enabling Microscaling (MX) Floating-Point Dot Products, https://arxiv.org/pdf/2505.13159, 2025-05-19
2025-11-09 10:43:14,478 - INFO - root - Page:0, Index:24, Parameter-Efficient Fine-Tuning with Circulant and Diagonal Vectors, https://arxiv.org/pdf/2505.00580, 2025-07-15
2025-11-09 10:43:14,480 - INFO - root - Page:0, Index:25, Silenzio: Secure Non-Interactive Outsourced MLP Training, https://arxiv.org/pdf/2504.17785, 2025-09-18
2025-11-09 10:43:14,480 - INFO - root - Page:0, Index:26, Involution and BSConv Multi-Depth Distillation Network for Lightweight Image Super-Resolution, https://arxiv.org/pdf/2503.14779, 2025-09-08
2025-11-09 10:43:14,480 - INFO - root - Page:0, Index:27, Flopping for FLOPs: Leveraging equivariance for computational efficiency, https://arxiv.org/pdf/2502.05169, 2025-06-24
2025-11-09 10:43:14,481 - INFO - root - Page:0, Index:28, An Effective UNet Using Feature Interaction and Fusion for Organ Segmentation in Medical Image, https://arxiv.org/pdf/2409.05324, 2025-07-26
2025-11-09 10:43:14,481 - INFO - root - Fetching page 2 with URL: https://arxiv.org/search/?query=block+float+point&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=50
2025-11-09 10:43:15,874 - INFO - root - get_all_titles_from_web 
2025-11-09 10:43:15,874 - INFO - root - Page:1, Index:0, TwinLiteNet+: An Enhanced Multi-Task Segmentation Model for Autonomous Driving, https://arxiv.org/pdf/2403.16958, 2025-08-30
2025-11-09 10:43:15,874 - INFO - root - Fetching page 3 with URL: https://arxiv.org/search/?query=block+float+point&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=100
2025-11-09 10:43:17,159 - INFO - root - ------------------------------------------------------------------------------------------------------------------------
2025-11-09 10:43:57,319 - INFO - root - 正在总结论文 1/30: From Uniform to Adaptive: General Skip-Block Mechanisms for Efficient PDE Neural Operators
2025-11-09 10:43:57,319 - INFO - root - 正在提取论文图片...
2025-11-09 10:43:57,752 - INFO - root - 已保存图片 1/10：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_1_page3.png
2025-11-09 10:43:57,814 - INFO - root - 已保存图片 2/10：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_2_page8.png
2025-11-09 10:43:57,914 - INFO - root - 已保存图片 3/10：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_3_page8.png
2025-11-09 10:43:57,978 - INFO - root - 已保存图片 4/10：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_4_page9.png
2025-11-09 10:43:58,046 - INFO - root - 已保存图片 5/10：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_5_page9.png
2025-11-09 10:43:58,121 - INFO - root - 已保存图片 6/10：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_6_page4.png
2025-11-09 10:43:58,206 - INFO - root - 已保存图片 7/10：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_7_page4.png
2025-11-09 10:43:58,277 - INFO - root - 已保存图片 8/10：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_8_page16.png
2025-11-09 10:43:58,296 - INFO - root - 已保存图片 9/10：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_9_page4.png
2025-11-09 10:43:58,307 - INFO - root - 已保存图片 10/10：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_10_page4.png
2025-11-09 10:43:58,313 - INFO - root - 成功添加图片 1：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_1_page3.png
2025-11-09 10:43:58,313 - INFO - root - 成功添加图片 2：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_2_page8.png
2025-11-09 10:43:58,313 - INFO - root - 成功添加图片 3：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_3_page8.png
2025-11-09 10:43:58,313 - INFO - root - 成功添加图片 4：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_4_page9.png
2025-11-09 10:43:58,315 - INFO - root - 成功添加图片 5：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_5_page9.png
2025-11-09 10:43:58,315 - INFO - root - 成功添加图片 6：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_6_page4.png
2025-11-09 10:43:58,315 - INFO - root - 成功添加图片 7：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_7_page4.png
2025-11-09 10:43:58,317 - INFO - root - 成功添加图片 8：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_8_page16.png
2025-11-09 10:43:58,317 - INFO - root - 成功添加图片 9：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_9_page4.png
2025-11-09 10:43:58,317 - INFO - root - 成功添加图片 10：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_10_page4.png
2025-11-09 10:43:58,321 - INFO - root - 论文《From Uniform to Adaptive: General Skip-Block Mechanisms for Efficient PDE Neural Operators》的分析已保存到 ./export\From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural-1.md
2025-11-09 10:43:58,335 - INFO - root - 正在总结论文 2/30: INT v.s. FP: A Comprehensive Study of Fine-Grained Low-bit Quantization Formats
2025-11-09 10:43:58,336 - INFO - root - 正在提取论文图片...
2025-11-09 10:43:58,817 - INFO - root - 已保存图片 1/10：./export\images_INT v.s. FP_ A Comprehensive Study of Fine-Grained Low-bit Quantization Formats\figure_1_page9.png
2025-11-09 10:43:58,884 - INFO - root - 已保存图片 2/10：./export\images_INT v.s. FP_ A Comprehensive Study of Fine-Grained Low-bit Quantization Formats\figure_2_page1.png
2025-11-09 10:43:58,918 - INFO - root - 已保存图片 3/10：./export\images_INT v.s. FP_ A Comprehensive Study of Fine-Grained Low-bit Quantization Formats\figure_3_page1.jpeg
2025-11-09 10:43:58,989 - INFO - root - 已保存图片 4/10：./export\images_INT v.s. FP_ A Comprehensive Study of Fine-Grained Low-bit Quantization Formats\figure_4_page9.png
2025-11-09 10:43:58,995 - INFO - root - 成功添加图片 1：./export\images_INT v.s. FP_ A Comprehensive Study of Fine-Grained Low-bit Quantization Formats\figure_1_page9.png
2025-11-09 10:43:58,995 - INFO - root - 成功添加图片 2：./export\images_INT v.s. FP_ A Comprehensive Study of Fine-Grained Low-bit Quantization Formats\figure_2_page1.png
2025-11-09 10:43:58,997 - INFO - root - 成功添加图片 3：./export\images_INT v.s. FP_ A Comprehensive Study of Fine-Grained Low-bit Quantization Formats\figure_3_page1.jpeg
2025-11-09 10:43:58,997 - INFO - root - 成功添加图片 4：./export\images_INT v.s. FP_ A Comprehensive Study of Fine-Grained Low-bit Quantization Formats\figure_4_page9.png
2025-11-09 10:43:59,009 - INFO - root - 论文《INT v.s. FP: A Comprehensive Study of Fine-Grained Low-bit Quantization Formats》的分析已保存到 ./export\INT v.s. FP_ A Comprehensive Study of Fine-Grained Low-bit Quantization Formats-1.md
2025-11-09 10:43:59,018 - INFO - root - 正在总结论文 3/30: MX+: Pushing the Limits of Microscaling Formats for Efficient Large Language Model Serving
2025-11-09 10:43:59,020 - INFO - root - 正在提取论文图片...
2025-11-09 10:43:59,133 - INFO - root - 已保存图片 1/10：./export\images_MX+_ Pushing the Limits of Microscaling Formats for Efficient Large Language Mod\figure_1_page3.png
2025-11-09 10:43:59,133 - INFO - root - 成功添加图片 1：./export\images_MX+_ Pushing the Limits of Microscaling Formats for Efficient Large Language Mod\figure_1_page3.png
2025-11-09 10:43:59,137 - INFO - root - 论文《MX+: Pushing the Limits of Microscaling Formats for Efficient Large Language Model Serving》的分析已保存到 ./export\MX+_ Pushing the Limits of Microscaling Formats for Efficient Large Language Mod-1.md
2025-11-09 10:43:59,150 - INFO - root - 正在总结论文 4/30: F-BFQ: Flexible Block Floating-Point Quantization Accelerator for LLMs
2025-11-09 10:43:59,151 - INFO - root - 正在提取论文图片...
2025-11-09 10:44:00,097 - INFO - root - 已保存图片 1/10：./export\images_F-BFQ_ Flexible Block Floating-Point Quantization Accelerator for LLMs\figure_1_page4.png
2025-11-09 10:44:00,242 - INFO - root - 已保存图片 2/10：./export\images_F-BFQ_ Flexible Block Floating-Point Quantization Accelerator for LLMs\figure_2_page3.png
2025-11-09 10:44:00,286 - INFO - root - 已保存图片 3/10：./export\images_F-BFQ_ Flexible Block Floating-Point Quantization Accelerator for LLMs\figure_3_page2.png
2025-11-09 10:44:00,298 - INFO - root - 成功添加图片 1：./export\images_F-BFQ_ Flexible Block Floating-Point Quantization Accelerator for LLMs\figure_1_page4.png
2025-11-09 10:44:00,298 - INFO - root - 成功添加图片 2：./export\images_F-BFQ_ Flexible Block Floating-Point Quantization Accelerator for LLMs\figure_2_page3.png
2025-11-09 10:44:00,299 - INFO - root - 成功添加图片 3：./export\images_F-BFQ_ Flexible Block Floating-Point Quantization Accelerator for LLMs\figure_3_page2.png
2025-11-09 10:44:00,304 - INFO - root - 论文《F-BFQ: Flexible Block Floating-Point Quantization Accelerator for LLMs》的分析已保存到 ./export\F-BFQ_ Flexible Block Floating-Point Quantization Accelerator for LLMs-1.md
2025-11-09 10:44:00,310 - INFO - root - 正在总结论文 5/30: Computationally Efficient Neural Receivers via Axial Self-Attention
2025-11-09 10:44:00,314 - INFO - root - 正在提取论文图片...
2025-11-09 10:44:01,593 - INFO - root - 已保存图片 1/10：./export\images_Computationally Efficient Neural Receivers via Axial Self-Attention\figure_1_page5.png
2025-11-09 10:44:01,601 - INFO - root - 成功添加图片 1：./export\images_Computationally Efficient Neural Receivers via Axial Self-Attention\figure_1_page5.png
2025-11-09 10:44:01,608 - INFO - root - 论文《Computationally Efficient Neural Receivers via Axial Self-Attention》的分析已保存到 ./export\Computationally Efficient Neural Receivers via Axial Self-Attention-1.md
2025-11-09 10:44:01,617 - INFO - root - 正在总结论文 6/30: Efficient In-Memory Acceleration of Sparse Block Diagonal LLMs
2025-11-09 10:44:01,619 - INFO - root - 正在提取论文图片...
2025-11-09 10:44:01,703 - INFO - root - 已保存图片 1/10：./export\images_Efficient In-Memory Acceleration of Sparse Block Diagonal LLMs\figure_1_page3.png
2025-11-09 10:44:01,769 - INFO - root - 已保存图片 2/10：./export\images_Efficient In-Memory Acceleration of Sparse Block Diagonal LLMs\figure_2_page3.png
2025-11-09 10:44:01,909 - INFO - root - 已保存图片 3/10：./export\images_Efficient In-Memory Acceleration of Sparse Block Diagonal LLMs\figure_3_page3.png
2025-11-09 10:44:01,910 - INFO - root - 成功添加图片 1：./export\images_Efficient In-Memory Acceleration of Sparse Block Diagonal LLMs\figure_1_page3.png
2025-11-09 10:44:01,910 - INFO - root - 成功添加图片 2：./export\images_Efficient In-Memory Acceleration of Sparse Block Diagonal LLMs\figure_2_page3.png
2025-11-09 10:44:01,912 - INFO - root - 成功添加图片 3：./export\images_Efficient In-Memory Acceleration of Sparse Block Diagonal LLMs\figure_3_page3.png
2025-11-09 10:44:01,921 - INFO - root - 论文《Efficient In-Memory Acceleration of Sparse Block Diagonal LLMs》的分析已保存到 ./export\Efficient In-Memory Acceleration of Sparse Block Diagonal LLMs-1.md
2025-11-09 10:44:01,932 - INFO - root - 正在总结论文 7/30: Dissecting Transformers: A CLEAR Perspective towards Green AI
2025-11-09 10:44:01,934 - INFO - root - 正在提取论文图片...
2025-11-09 10:44:02,051 - WARNING - root - 处理页面 19 的图片 1 时出错：Image size (360000000 pixels) exceeds limit of 178956970 pixels, could be decompression bomb DOS attack.
2025-11-09 10:44:02,223 - INFO - root - 已保存图片 1/10：./export\images_Dissecting Transformers_ A CLEAR Perspective towards Green AI\figure_1_page3.png
2025-11-09 10:44:02,317 - INFO - root - 已保存图片 2/10：./export\images_Dissecting Transformers_ A CLEAR Perspective towards Green AI\figure_2_page3.png
2025-11-09 10:44:02,443 - INFO - root - 已保存图片 3/10：./export\images_Dissecting Transformers_ A CLEAR Perspective towards Green AI\figure_3_page3.png
2025-11-09 10:44:02,555 - INFO - root - 已保存图片 4/10：./export\images_Dissecting Transformers_ A CLEAR Perspective towards Green AI\figure_4_page3.png
2025-11-09 10:44:02,691 - INFO - root - 已保存图片 5/10：./export\images_Dissecting Transformers_ A CLEAR Perspective towards Green AI\figure_5_page3.png
2025-11-09 10:44:02,691 - INFO - root - 成功添加图片 1：./export\images_Dissecting Transformers_ A CLEAR Perspective towards Green AI\figure_1_page3.png
2025-11-09 10:44:02,691 - INFO - root - 成功添加图片 2：./export\images_Dissecting Transformers_ A CLEAR Perspective towards Green AI\figure_2_page3.png
2025-11-09 10:44:02,691 - INFO - root - 成功添加图片 3：./export\images_Dissecting Transformers_ A CLEAR Perspective towards Green AI\figure_3_page3.png
2025-11-09 10:44:02,691 - INFO - root - 成功添加图片 4：./export\images_Dissecting Transformers_ A CLEAR Perspective towards Green AI\figure_4_page3.png
2025-11-09 10:44:02,691 - INFO - root - 成功添加图片 5：./export\images_Dissecting Transformers_ A CLEAR Perspective towards Green AI\figure_5_page3.png
2025-11-09 10:44:02,699 - INFO - root - 论文《Dissecting Transformers: A CLEAR Perspective towards Green AI》的分析已保存到 ./export\Dissecting Transformers_ A CLEAR Perspective towards Green AI-1.md
2025-11-09 10:44:02,711 - INFO - root - 正在总结论文 8/30: Microscaling Floating Point Formats for Large Language Models
2025-11-09 10:44:02,718 - INFO - root - 正在提取论文图片...
2025-11-09 10:44:02,737 - INFO - root - 论文《Microscaling Floating Point Formats for Large Language Models》的分析已保存到 ./export\Microscaling Floating Point Formats for Large Language Models-1.md
2025-11-09 10:44:02,760 - INFO - root - 正在总结论文 9/30: Automated and Scalable SEM Image Analysis of Perovskite Solar Cell Materials via a Deep Segmentation Framework
2025-11-09 10:44:02,762 - INFO - root - 正在提取论文图片...
2025-11-09 10:44:32,563 - INFO - root - 已保存图片 1/10：./export\images_Automated and Scalable SEM Image Analysis of Perovskite Solar Cell Materials via\figure_1_page8.jpeg
2025-11-09 10:44:32,843 - INFO - root - 已保存图片 2/10：./export\images_Automated and Scalable SEM Image Analysis of Perovskite Solar Cell Materials via\figure_2_page5.jpeg
2025-11-09 10:44:33,156 - INFO - root - 已保存图片 3/10：./export\images_Automated and Scalable SEM Image Analysis of Perovskite Solar Cell Materials via\figure_3_page9.jpeg
2025-11-09 10:44:33,411 - INFO - root - 已保存图片 4/10：./export\images_Automated and Scalable SEM Image Analysis of Perovskite Solar Cell Materials via\figure_4_page9.jpeg
2025-11-09 10:44:33,641 - INFO - root - 已保存图片 5/10：./export\images_Automated and Scalable SEM Image Analysis of Perovskite Solar Cell Materials via\figure_5_page9.jpeg
2025-11-09 10:44:33,837 - INFO - root - 已保存图片 6/10：./export\images_Automated and Scalable SEM Image Analysis of Perovskite Solar Cell Materials via\figure_6_page9.jpeg
2025-11-09 10:44:34,057 - INFO - root - 已保存图片 7/10：./export\images_Automated and Scalable SEM Image Analysis of Perovskite Solar Cell Materials via\figure_7_page9.jpeg
2025-11-09 10:44:34,251 - INFO - root - 已保存图片 8/10：./export\images_Automated and Scalable SEM Image Analysis of Perovskite Solar Cell Materials via\figure_8_page9.jpeg
2025-11-09 10:44:34,453 - INFO - root - 已保存图片 9/10：./export\images_Automated and Scalable SEM Image Analysis of Perovskite Solar Cell Materials via\figure_9_page9.jpeg
2025-11-09 10:44:34,645 - INFO - root - 已保存图片 10/10：./export\images_Automated and Scalable SEM Image Analysis of Perovskite Solar Cell Materials via\figure_10_page9.jpeg
2025-11-09 10:44:34,678 - INFO - root - 成功添加图片 1：./export\images_Automated and Scalable SEM Image Analysis of Perovskite Solar Cell Materials via\figure_1_page8.jpeg
2025-11-09 10:44:34,679 - INFO - root - 成功添加图片 2：./export\images_Automated and Scalable SEM Image Analysis of Perovskite Solar Cell Materials via\figure_2_page5.jpeg
2025-11-09 10:44:34,680 - INFO - root - 成功添加图片 3：./export\images_Automated and Scalable SEM Image Analysis of Perovskite Solar Cell Materials via\figure_3_page9.jpeg
2025-11-09 10:44:34,680 - INFO - root - 成功添加图片 4：./export\images_Automated and Scalable SEM Image Analysis of Perovskite Solar Cell Materials via\figure_4_page9.jpeg
2025-11-09 10:44:34,680 - INFO - root - 成功添加图片 5：./export\images_Automated and Scalable SEM Image Analysis of Perovskite Solar Cell Materials via\figure_5_page9.jpeg
2025-11-09 10:44:34,680 - INFO - root - 成功添加图片 6：./export\images_Automated and Scalable SEM Image Analysis of Perovskite Solar Cell Materials via\figure_6_page9.jpeg
2025-11-09 10:44:34,680 - INFO - root - 成功添加图片 7：./export\images_Automated and Scalable SEM Image Analysis of Perovskite Solar Cell Materials via\figure_7_page9.jpeg
2025-11-09 10:44:34,680 - INFO - root - 成功添加图片 8：./export\images_Automated and Scalable SEM Image Analysis of Perovskite Solar Cell Materials via\figure_8_page9.jpeg
2025-11-09 10:44:34,680 - INFO - root - 成功添加图片 9：./export\images_Automated and Scalable SEM Image Analysis of Perovskite Solar Cell Materials via\figure_9_page9.jpeg
2025-11-09 10:44:34,680 - INFO - root - 成功添加图片 10：./export\images_Automated and Scalable SEM Image Analysis of Perovskite Solar Cell Materials via\figure_10_page9.jpeg
2025-11-09 10:44:34,689 - INFO - root - 论文《Automated and Scalable SEM Image Analysis of Perovskite Solar Cell Materials via a Deep Segmentation Framework》的分析已保存到 ./export\Automated and Scalable SEM Image Analysis of Perovskite Solar Cell Materials via-1.md
2025-11-09 10:44:34,695 - INFO - root - 正在总结论文 10/30: AMLA: MUL by ADD in FlashAttention Rescaling
2025-11-09 10:44:34,698 - INFO - root - 正在提取论文图片...
2025-11-09 10:44:35,653 - INFO - root - 已保存图片 1/10：./export\images_AMLA_ MUL by ADD in FlashAttention Rescaling\figure_1_page15.png
2025-11-09 10:44:35,705 - INFO - root - 已保存图片 2/10：./export\images_AMLA_ MUL by ADD in FlashAttention Rescaling\figure_2_page4.jpeg
2025-11-09 10:44:35,752 - INFO - root - 已保存图片 3/10：./export\images_AMLA_ MUL by ADD in FlashAttention Rescaling\figure_3_page8.jpeg
2025-11-09 10:44:35,752 - INFO - root - 成功添加图片 1：./export\images_AMLA_ MUL by ADD in FlashAttention Rescaling\figure_1_page15.png
2025-11-09 10:44:35,752 - INFO - root - 成功添加图片 2：./export\images_AMLA_ MUL by ADD in FlashAttention Rescaling\figure_2_page4.jpeg
2025-11-09 10:44:35,752 - INFO - root - 成功添加图片 3：./export\images_AMLA_ MUL by ADD in FlashAttention Rescaling\figure_3_page8.jpeg
2025-11-09 10:44:35,766 - INFO - root - 论文《AMLA: MUL by ADD in FlashAttention Rescaling》的分析已保存到 ./export\AMLA_ MUL by ADD in FlashAttention Rescaling-1.md
2025-11-09 10:44:35,774 - INFO - root - 正在总结论文 11/30: Pretraining Large Language Models with NVFP4
2025-11-09 10:44:35,774 - INFO - root - 正在提取论文图片...
2025-11-09 10:44:35,975 - INFO - root - 已保存图片 1/10：./export\images_Pretraining Large Language Models with NVFP4\figure_1_page7.png
2025-11-09 10:44:36,036 - INFO - root - 已保存图片 2/10：./export\images_Pretraining Large Language Models with NVFP4\figure_2_page7.jpeg
2025-11-09 10:44:36,072 - INFO - root - 已保存图片 3/10：./export\images_Pretraining Large Language Models with NVFP4\figure_3_page1.png
2025-11-09 10:44:36,097 - INFO - root - 已保存图片 4/10：./export\images_Pretraining Large Language Models with NVFP4\figure_4_page7.jpeg
2025-11-09 10:44:36,128 - INFO - root - 已保存图片 5/10：./export\images_Pretraining Large Language Models with NVFP4\figure_5_page7.jpeg
2025-11-09 10:44:36,220 - INFO - root - 已保存图片 6/10：./export\images_Pretraining Large Language Models with NVFP4\figure_6_page7.jpeg
2025-11-09 10:44:36,277 - INFO - root - 已保存图片 7/10：./export\images_Pretraining Large Language Models with NVFP4\figure_7_page7.png
2025-11-09 10:44:36,307 - INFO - root - 已保存图片 8/10：./export\images_Pretraining Large Language Models with NVFP4\figure_8_page7.jpeg
2025-11-09 10:44:36,340 - INFO - root - 已保存图片 9/10：./export\images_Pretraining Large Language Models with NVFP4\figure_9_page7.jpeg
2025-11-09 10:44:36,387 - INFO - root - 已保存图片 10/10：./export\images_Pretraining Large Language Models with NVFP4\figure_10_page7.jpeg
2025-11-09 10:44:36,389 - INFO - root - 成功添加图片 1：./export\images_Pretraining Large Language Models with NVFP4\figure_1_page7.png
2025-11-09 10:44:36,389 - INFO - root - 成功添加图片 2：./export\images_Pretraining Large Language Models with NVFP4\figure_2_page7.jpeg
2025-11-09 10:44:36,389 - INFO - root - 成功添加图片 3：./export\images_Pretraining Large Language Models with NVFP4\figure_3_page1.png
2025-11-09 10:44:36,389 - INFO - root - 成功添加图片 4：./export\images_Pretraining Large Language Models with NVFP4\figure_4_page7.jpeg
2025-11-09 10:44:36,389 - INFO - root - 成功添加图片 5：./export\images_Pretraining Large Language Models with NVFP4\figure_5_page7.jpeg
2025-11-09 10:44:36,389 - INFO - root - 成功添加图片 6：./export\images_Pretraining Large Language Models with NVFP4\figure_6_page7.jpeg
2025-11-09 10:44:36,389 - INFO - root - 成功添加图片 7：./export\images_Pretraining Large Language Models with NVFP4\figure_7_page7.png
2025-11-09 10:44:36,389 - INFO - root - 成功添加图片 8：./export\images_Pretraining Large Language Models with NVFP4\figure_8_page7.jpeg
2025-11-09 10:44:36,397 - INFO - root - 成功添加图片 9：./export\images_Pretraining Large Language Models with NVFP4\figure_9_page7.jpeg
2025-11-09 10:44:36,397 - INFO - root - 成功添加图片 10：./export\images_Pretraining Large Language Models with NVFP4\figure_10_page7.jpeg
2025-11-09 10:44:36,406 - INFO - root - 论文《Pretraining Large Language Models with NVFP4》的分析已保存到 ./export\Pretraining Large Language Models with NVFP4-1.md
2025-11-09 10:44:36,416 - INFO - root - 正在总结论文 12/30: Bridging the Gap Between Promise and Performance for Microscaling FP4 Quantization
2025-11-09 10:44:36,418 - INFO - root - 正在提取论文图片...
2025-11-09 10:44:36,558 - INFO - root - 已保存图片 1/10：./export\images_Bridging the Gap Between Promise and Performance for Microscaling FP4 Quantizati\figure_1_page25.png
2025-11-09 10:44:36,559 - INFO - root - 成功添加图片 1：./export\images_Bridging the Gap Between Promise and Performance for Microscaling FP4 Quantizati\figure_1_page25.png
2025-11-09 10:44:36,577 - INFO - root - 论文《Bridging the Gap Between Promise and Performance for Microscaling FP4 Quantization》的分析已保存到 ./export\Bridging the Gap Between Promise and Performance for Microscaling FP4 Quantizati-1.md
2025-11-09 10:44:36,589 - INFO - root - 正在总结论文 13/30: Towards Verified Compilation of Floating-point Optimization in Scientific Computing Programs
2025-11-09 10:44:36,591 - INFO - root - 正在提取论文图片...
2025-11-09 10:44:36,597 - INFO - root - 论文《Towards Verified Compilation of Floating-point Optimization in Scientific Computing Programs》的分析已保存到 ./export\Towards Verified Compilation of Floating-point Optimization in Scientific Comput-1.md
2025-11-09 10:44:36,608 - INFO - root - 正在总结论文 14/30: Green Learning for STAR-RIS mmWave Systems with Implicit CSI
2025-11-09 10:44:36,609 - INFO - root - 正在提取论文图片...
2025-11-09 10:44:36,795 - INFO - root - 已保存图片 1/10：./export\images_Green Learning for STAR-RIS mmWave Systems with Implicit CSI\figure_1_page2.jpeg
2025-11-09 10:44:36,926 - INFO - root - 已保存图片 2/10：./export\images_Green Learning for STAR-RIS mmWave Systems with Implicit CSI\figure_2_page2.png
2025-11-09 10:44:36,977 - INFO - root - 已保存图片 3/10：./export\images_Green Learning for STAR-RIS mmWave Systems with Implicit CSI\figure_3_page2.png
2025-11-09 10:44:37,035 - INFO - root - 已保存图片 4/10：./export\images_Green Learning for STAR-RIS mmWave Systems with Implicit CSI\figure_4_page2.png
2025-11-09 10:44:37,037 - INFO - root - 成功添加图片 1：./export\images_Green Learning for STAR-RIS mmWave Systems with Implicit CSI\figure_1_page2.jpeg
2025-11-09 10:44:37,039 - INFO - root - 成功添加图片 2：./export\images_Green Learning for STAR-RIS mmWave Systems with Implicit CSI\figure_2_page2.png
2025-11-09 10:44:37,039 - INFO - root - 成功添加图片 3：./export\images_Green Learning for STAR-RIS mmWave Systems with Implicit CSI\figure_3_page2.png
2025-11-09 10:44:37,041 - INFO - root - 成功添加图片 4：./export\images_Green Learning for STAR-RIS mmWave Systems with Implicit CSI\figure_4_page2.png
2025-11-09 10:44:37,055 - INFO - root - 论文《Green Learning for STAR-RIS mmWave Systems with Implicit CSI》的分析已保存到 ./export\Green Learning for STAR-RIS mmWave Systems with Implicit CSI-1.md
2025-11-09 10:44:37,064 - INFO - root - 正在总结论文 15/30: A Compute&Memory Efficient Model-Driven Neural 5G Receiver for Edge AI-assisted RAN
2025-11-09 10:44:37,065 - INFO - root - 正在提取论文图片...
2025-11-09 10:44:37,775 - INFO - root - 已保存图片 1/10：./export\images_A Compute&Memory Efficient Model-Driven Neural 5G Receiver for Edge AI-assisted\figure_1_page6.png
2025-11-09 10:44:37,872 - INFO - root - 已保存图片 2/10：./export\images_A Compute&Memory Efficient Model-Driven Neural 5G Receiver for Edge AI-assisted\figure_2_page6.png
2025-11-09 10:44:37,969 - INFO - root - 已保存图片 3/10：./export\images_A Compute&Memory Efficient Model-Driven Neural 5G Receiver for Edge AI-assisted\figure_3_page2.png
2025-11-09 10:54:15,017 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-09 10:54:15,033 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-09 10:54:15,033 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-09 10:55:08,572 - ERROR - root - LLMClient: error during initialization: Timeout of 60.0s exceeded, last exception: 503 failed to connect to all addresses; last error: UNKNOWN: ipv4:142.251.34.202:443: socket is null
2025-11-09 10:55:08,574 - INFO - root - LLM 未初始化或不可用，后续生成将返回备用消息
2025-11-09 10:55:08,574 - INFO - root - === 运行配置 ===
2025-11-09 10:55:08,575 - INFO - root - 处理模式: arxiv在线搜索
2025-11-09 10:55:08,576 - INFO - root - 关键词: Quant
2025-11-09 10:55:08,576 - INFO - root - 查询: block float point
2025-11-09 10:55:08,578 - INFO - root - 排序: None
2025-11-09 10:55:08,578 - INFO - root - 最近天数: 180
2025-11-09 10:55:08,578 - INFO - root - 最大处理数量: 50
2025-11-09 10:55:08,578 - INFO - root - 保存图片: 是
2025-11-09 10:55:08,578 - INFO - root - 输出语言: 中文
2025-11-09 10:55:08,578 - INFO - root - 强制重新处理: 否
2025-11-09 10:55:08,578 - INFO - root - ====================
2025-11-09 10:55:08,590 - INFO - root - 使用 arXiv 搜索模式（通过 chat_arxiv 模块获取）
2025-11-09 10:55:08,590 - INFO - root - Fetching page 1 with URL: https://arxiv.org/search/?query=block+float+point&searchtype=all&abstracts=show&order=-announced_date_first&size=50
2025-11-09 10:55:39,943 - INFO - root - get_all_titles_from_web 
2025-11-09 10:55:39,943 - INFO - root - Page:0, Index:0, From Uniform to Adaptive: General Skip-Block Mechanisms for Efficient PDE Neural Operators, https://arxiv.org/pdf/2511.00032, 2025-11-04
2025-11-09 10:55:39,943 - INFO - root - Page:0, Index:1, INT v.s. FP: A Comprehensive Study of Fine-Grained Low-bit Quantization Formats, https://arxiv.org/pdf/2510.25602, 2025-10-29
2025-11-09 10:55:39,943 - INFO - root - Page:0, Index:2, MX+: Pushing the Limits of Microscaling Formats for Efficient Large Language Model Serving, https://arxiv.org/pdf/2510.14557, 2025-10-16
2025-11-09 10:55:39,943 - INFO - root - Page:0, Index:3, F-BFQ: Flexible Block Floating-Point Quantization Accelerator for LLMs, https://arxiv.org/pdf/2510.13401, 2025-10-15
2025-11-09 10:55:39,943 - INFO - root - Page:0, Index:4, Computationally Efficient Neural Receivers via Axial Self-Attention, https://arxiv.org/pdf/2510.12941, 2025-10-14
2025-11-09 10:55:39,943 - INFO - root - Page:0, Index:5, Efficient In-Memory Acceleration of Sparse Block Diagonal LLMs, https://arxiv.org/pdf/2510.11192, 2025-10-13
2025-11-09 10:55:39,943 - INFO - root - Page:0, Index:6, Dissecting Transformers: A CLEAR Perspective towards Green AI, https://arxiv.org/pdf/2510.02810, 2025-10-03
2025-11-09 10:55:39,943 - INFO - root - Page:0, Index:7, Microscaling Floating Point Formats for Large Language Models, https://arxiv.org/pdf/2510.01863, 2025-10-02
2025-11-09 10:55:39,943 - INFO - root - Page:0, Index:8, Automated and Scalable SEM Image Analysis of Perovskite Solar Cell Materials via a Deep Segmentation Framework, https://arxiv.org/pdf/2509.26548, 2025-09-30
2025-11-09 10:55:39,943 - INFO - root - Page:0, Index:9, AMLA: MUL by ADD in FlashAttention Rescaling, https://arxiv.org/pdf/2509.25224, 2025-09-24
2025-11-09 10:55:39,949 - INFO - root - Page:0, Index:10, Pretraining Large Language Models with NVFP4, https://arxiv.org/pdf/2509.25149, 2025-09-29
2025-11-09 10:55:39,949 - INFO - root - Page:0, Index:11, Bridging the Gap Between Promise and Performance for Microscaling FP4 Quantization, https://arxiv.org/pdf/2509.23202, 2025-10-16
2025-11-09 10:55:39,949 - INFO - root - Page:0, Index:12, Towards Verified Compilation of Floating-point Optimization in Scientific Computing Programs, https://arxiv.org/pdf/2509.09019, 2025-09-10
2025-11-09 10:55:39,949 - INFO - root - Page:0, Index:13, Green Learning for STAR-RIS mmWave Systems with Implicit CSI, https://arxiv.org/pdf/2509.06820, 2025-09-08
2025-11-09 10:55:39,949 - INFO - root - Page:0, Index:14, A Compute&Memory Efficient Model-Driven Neural 5G Receiver for Edge AI-assisted RAN, https://arxiv.org/pdf/2508.12892, 2025-10-22
2025-11-09 10:55:39,949 - INFO - root - Page:0, Index:15, SNNSIR: A Simple Spiking Neural Network for Stereo Image Restoration, https://arxiv.org/pdf/2508.12271, 2025-08-17
2025-11-09 10:55:39,949 - INFO - root - Page:0, Index:16, SpikeSTAG: Spatial-Temporal Forecasting via GNN-SNN Collaboration, https://arxiv.org/pdf/2508.02069, 2025-08-18
2025-11-09 10:55:39,949 - INFO - root - Page:0, Index:17, DGEMM without FP64 Arithmetic - Using FP64 Emulation and FP8 Tensor Cores with Ozaki Scheme, https://arxiv.org/pdf/2508.00441, 2025-09-25
2025-11-09 10:55:39,949 - INFO - root - Page:0, Index:18, Scaling Probabilistic Circuits via Monarch Matrices, https://arxiv.org/pdf/2506.12383, 2025-06-14
2025-11-09 10:55:39,949 - INFO - root - Page:0, Index:19, Starting Positions Matter: A Study on Better Weight Initialization for Neural Network Quantization, https://arxiv.org/pdf/2506.10463, 2025-06-12
2025-11-09 10:55:39,949 - INFO - root - Page:0, Index:20, Recipes for Pre-training LLMs with MXFP8, https://arxiv.org/pdf/2506.08027, 2025-08-18
2025-11-09 10:55:39,949 - INFO - root - Page:0, Index:21, FP4 All the Way: Fully Quantized Training of LLMs, https://arxiv.org/pdf/2505.19115, 2025-08-10
2025-11-09 10:55:39,949 - INFO - root - Page:0, Index:22, Automatic Verification of Floating-Point Accumulation Networks, https://arxiv.org/pdf/2505.18791, 2025-05-24
2025-11-09 10:55:39,949 - INFO - root - Page:0, Index:23, MXDOTP: A RISC-V ISA Extension for Enabling Microscaling (MX) Floating-Point Dot Products, https://arxiv.org/pdf/2505.13159, 2025-05-19
2025-11-09 10:55:39,949 - INFO - root - Page:0, Index:24, Parameter-Efficient Fine-Tuning with Circulant and Diagonal Vectors, https://arxiv.org/pdf/2505.00580, 2025-07-15
2025-11-09 10:55:39,949 - INFO - root - Page:0, Index:25, Silenzio: Secure Non-Interactive Outsourced MLP Training, https://arxiv.org/pdf/2504.17785, 2025-09-18
2025-11-09 10:55:39,949 - INFO - root - Page:0, Index:26, Involution and BSConv Multi-Depth Distillation Network for Lightweight Image Super-Resolution, https://arxiv.org/pdf/2503.14779, 2025-09-08
2025-11-09 10:55:39,949 - INFO - root - Page:0, Index:27, Flopping for FLOPs: Leveraging equivariance for computational efficiency, https://arxiv.org/pdf/2502.05169, 2025-06-24
2025-11-09 10:55:39,949 - INFO - root - Page:0, Index:28, An Effective UNet Using Feature Interaction and Fusion for Organ Segmentation in Medical Image, https://arxiv.org/pdf/2409.05324, 2025-07-26
2025-11-09 10:55:39,949 - INFO - root - Fetching page 2 with URL: https://arxiv.org/search/?query=block+float+point&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=50
2025-11-09 10:59:20,251 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-09 10:59:20,252 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-09 10:59:20,254 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-09 10:59:21,780 - INFO - root - LLMClient: trying model gemini-2.5-flash
2025-11-09 10:59:22,916 - INFO - root - LLMClient: trying model gemini-2.5-pro
2025-11-09 10:59:23,284 - WARNING - root - LLMClient: no usable model found, LLM disabled
2025-11-09 10:59:23,284 - INFO - root - LLM 未初始化或不可用，后续生成将返回备用消息
2025-11-09 10:59:23,285 - INFO - root - === 运行配置 ===
2025-11-09 10:59:23,285 - INFO - root - 处理模式: arxiv在线搜索
2025-11-09 10:59:23,286 - INFO - root - 关键词: Quant
2025-11-09 10:59:23,286 - INFO - root - 查询: block float point
2025-11-09 10:59:23,286 - INFO - root - 排序: None
2025-11-09 10:59:23,287 - INFO - root - 最近天数: 180
2025-11-09 10:59:23,287 - INFO - root - 最大处理数量: 50
2025-11-09 10:59:23,288 - INFO - root - 保存图片: 是
2025-11-09 10:59:23,288 - INFO - root - 输出语言: 中文
2025-11-09 10:59:23,288 - INFO - root - 强制重新处理: 否
2025-11-09 10:59:23,288 - INFO - root - ====================
2025-11-09 10:59:23,289 - INFO - root - 使用 arXiv 搜索模式（通过 chat_arxiv 模块获取）
2025-11-09 10:59:23,290 - INFO - root - Fetching page 1 with URL: https://arxiv.org/search/?query=block+float+point&searchtype=all&abstracts=show&order=-announced_date_first&size=50
2025-11-09 10:59:29,441 - INFO - root - get_all_titles_from_web 
2025-11-09 10:59:29,441 - INFO - root - Page:0, Index:0, From Uniform to Adaptive: General Skip-Block Mechanisms for Efficient PDE Neural Operators, https://arxiv.org/pdf/2511.00032, 2025-11-04
2025-11-09 10:59:29,442 - INFO - root - Page:0, Index:1, INT v.s. FP: A Comprehensive Study of Fine-Grained Low-bit Quantization Formats, https://arxiv.org/pdf/2510.25602, 2025-10-29
2025-11-09 10:59:29,442 - INFO - root - Page:0, Index:2, MX+: Pushing the Limits of Microscaling Formats for Efficient Large Language Model Serving, https://arxiv.org/pdf/2510.14557, 2025-10-16
2025-11-09 10:59:29,442 - INFO - root - Page:0, Index:3, F-BFQ: Flexible Block Floating-Point Quantization Accelerator for LLMs, https://arxiv.org/pdf/2510.13401, 2025-10-15
2025-11-09 10:59:29,442 - INFO - root - Page:0, Index:4, Computationally Efficient Neural Receivers via Axial Self-Attention, https://arxiv.org/pdf/2510.12941, 2025-10-14
2025-11-09 10:59:29,444 - INFO - root - Page:0, Index:5, Efficient In-Memory Acceleration of Sparse Block Diagonal LLMs, https://arxiv.org/pdf/2510.11192, 2025-10-13
2025-11-09 10:59:29,444 - INFO - root - Page:0, Index:6, Dissecting Transformers: A CLEAR Perspective towards Green AI, https://arxiv.org/pdf/2510.02810, 2025-10-03
2025-11-09 10:59:29,444 - INFO - root - Page:0, Index:7, Microscaling Floating Point Formats for Large Language Models, https://arxiv.org/pdf/2510.01863, 2025-10-02
2025-11-09 10:59:29,444 - INFO - root - Page:0, Index:8, Automated and Scalable SEM Image Analysis of Perovskite Solar Cell Materials via a Deep Segmentation Framework, https://arxiv.org/pdf/2509.26548, 2025-09-30
2025-11-09 10:59:29,445 - INFO - root - Page:0, Index:9, AMLA: MUL by ADD in FlashAttention Rescaling, https://arxiv.org/pdf/2509.25224, 2025-09-24
2025-11-09 10:59:29,445 - INFO - root - Page:0, Index:10, Pretraining Large Language Models with NVFP4, https://arxiv.org/pdf/2509.25149, 2025-09-29
2025-11-09 10:59:29,445 - INFO - root - Page:0, Index:11, Bridging the Gap Between Promise and Performance for Microscaling FP4 Quantization, https://arxiv.org/pdf/2509.23202, 2025-10-16
2025-11-09 10:59:29,446 - INFO - root - Page:0, Index:12, Towards Verified Compilation of Floating-point Optimization in Scientific Computing Programs, https://arxiv.org/pdf/2509.09019, 2025-09-10
2025-11-09 10:59:29,446 - INFO - root - Page:0, Index:13, Green Learning for STAR-RIS mmWave Systems with Implicit CSI, https://arxiv.org/pdf/2509.06820, 2025-09-08
2025-11-09 10:59:29,446 - INFO - root - Page:0, Index:14, A Compute&Memory Efficient Model-Driven Neural 5G Receiver for Edge AI-assisted RAN, https://arxiv.org/pdf/2508.12892, 2025-10-22
2025-11-09 10:59:29,447 - INFO - root - Page:0, Index:15, SNNSIR: A Simple Spiking Neural Network for Stereo Image Restoration, https://arxiv.org/pdf/2508.12271, 2025-08-17
2025-11-09 10:59:29,447 - INFO - root - Page:0, Index:16, SpikeSTAG: Spatial-Temporal Forecasting via GNN-SNN Collaboration, https://arxiv.org/pdf/2508.02069, 2025-08-18
2025-11-09 10:59:29,450 - INFO - root - Page:0, Index:17, DGEMM without FP64 Arithmetic - Using FP64 Emulation and FP8 Tensor Cores with Ozaki Scheme, https://arxiv.org/pdf/2508.00441, 2025-09-25
2025-11-09 10:59:29,451 - INFO - root - Page:0, Index:18, Scaling Probabilistic Circuits via Monarch Matrices, https://arxiv.org/pdf/2506.12383, 2025-06-14
2025-11-09 10:59:29,452 - INFO - root - Page:0, Index:19, Starting Positions Matter: A Study on Better Weight Initialization for Neural Network Quantization, https://arxiv.org/pdf/2506.10463, 2025-06-12
2025-11-09 10:59:29,452 - INFO - root - Page:0, Index:20, Recipes for Pre-training LLMs with MXFP8, https://arxiv.org/pdf/2506.08027, 2025-08-18
2025-11-09 10:59:29,452 - INFO - root - Page:0, Index:21, FP4 All the Way: Fully Quantized Training of LLMs, https://arxiv.org/pdf/2505.19115, 2025-08-10
2025-11-09 10:59:29,453 - INFO - root - Page:0, Index:22, Automatic Verification of Floating-Point Accumulation Networks, https://arxiv.org/pdf/2505.18791, 2025-05-24
2025-11-09 10:59:29,454 - INFO - root - Page:0, Index:23, MXDOTP: A RISC-V ISA Extension for Enabling Microscaling (MX) Floating-Point Dot Products, https://arxiv.org/pdf/2505.13159, 2025-05-19
2025-11-09 10:59:29,455 - INFO - root - Page:0, Index:24, Parameter-Efficient Fine-Tuning with Circulant and Diagonal Vectors, https://arxiv.org/pdf/2505.00580, 2025-07-15
2025-11-09 10:59:29,455 - INFO - root - Page:0, Index:25, Silenzio: Secure Non-Interactive Outsourced MLP Training, https://arxiv.org/pdf/2504.17785, 2025-09-18
2025-11-09 10:59:29,455 - INFO - root - Page:0, Index:26, Involution and BSConv Multi-Depth Distillation Network for Lightweight Image Super-Resolution, https://arxiv.org/pdf/2503.14779, 2025-09-08
2025-11-09 10:59:29,456 - INFO - root - Page:0, Index:27, Flopping for FLOPs: Leveraging equivariance for computational efficiency, https://arxiv.org/pdf/2502.05169, 2025-06-24
2025-11-09 10:59:29,457 - INFO - root - Page:0, Index:28, An Effective UNet Using Feature Interaction and Fusion for Organ Segmentation in Medical Image, https://arxiv.org/pdf/2409.05324, 2025-07-26
2025-11-09 10:59:29,458 - INFO - root - Fetching page 2 with URL: https://arxiv.org/search/?query=block+float+point&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=50
2025-11-09 10:59:35,891 - INFO - root - get_all_titles_from_web 
2025-11-09 10:59:35,892 - INFO - root - Page:1, Index:0, TwinLiteNet+: An Enhanced Multi-Task Segmentation Model for Autonomous Driving, https://arxiv.org/pdf/2403.16958, 2025-08-30
2025-11-09 10:59:35,892 - INFO - root - Fetching page 3 with URL: https://arxiv.org/search/?query=block+float+point&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=100
2025-11-09 10:59:42,083 - INFO - root - ------------------------------------------------------------------------------------------------------------------------
2025-11-09 11:02:42,840 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-09 11:02:42,841 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-09 11:02:42,846 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-09 11:02:43,393 - INFO - root - LLMClient: trying model gemini-2.5-flash
2025-11-09 11:02:44,233 - INFO - root - LLMClient: trying model gemini-2.5-pro
2025-11-09 11:02:44,596 - WARNING - root - LLMClient: no usable model found, LLM disabled
2025-11-09 11:02:44,596 - INFO - root - LLM 未初始化或不可用，后续生成将返回备用消息
2025-11-09 11:02:44,596 - INFO - root - === 运行配置 ===
2025-11-09 11:02:44,597 - INFO - root - 处理模式: arxiv在线搜索
2025-11-09 11:02:44,597 - INFO - root - 关键词: Quant
2025-11-09 11:02:44,598 - INFO - root - 查询: block float point
2025-11-09 11:02:44,598 - INFO - root - 排序: None
2025-11-09 11:02:44,598 - INFO - root - 最近天数: 180
2025-11-09 11:02:44,599 - INFO - root - 最大处理数量: 50
2025-11-09 11:02:44,599 - INFO - root - 保存图片: 是
2025-11-09 11:02:44,600 - INFO - root - 输出语言: 中文
2025-11-09 11:02:44,600 - INFO - root - 强制重新处理: 否
2025-11-09 11:02:44,600 - INFO - root - ====================
2025-11-09 11:02:44,600 - INFO - root - 使用 arXiv 搜索模式（通过 chat_arxiv 模块获取）
2025-11-09 11:02:44,601 - INFO - root - Fetching page 1 with URL: https://arxiv.org/search/?query=block+float+point&searchtype=all&abstracts=show&order=-announced_date_first&size=50
2025-11-09 11:02:50,748 - INFO - root - get_all_titles_from_web 
2025-11-09 11:02:50,750 - INFO - root - Page:0, Index:0, From Uniform to Adaptive: General Skip-Block Mechanisms for Efficient PDE Neural Operators, https://arxiv.org/pdf/2511.00032, 2025-11-04
2025-11-09 11:02:50,750 - INFO - root - Page:0, Index:1, INT v.s. FP: A Comprehensive Study of Fine-Grained Low-bit Quantization Formats, https://arxiv.org/pdf/2510.25602, 2025-10-29
2025-11-09 11:02:50,751 - INFO - root - Page:0, Index:2, MX+: Pushing the Limits of Microscaling Formats for Efficient Large Language Model Serving, https://arxiv.org/pdf/2510.14557, 2025-10-16
2025-11-09 11:02:50,751 - INFO - root - Page:0, Index:3, F-BFQ: Flexible Block Floating-Point Quantization Accelerator for LLMs, https://arxiv.org/pdf/2510.13401, 2025-10-15
2025-11-09 11:02:50,751 - INFO - root - Page:0, Index:4, Computationally Efficient Neural Receivers via Axial Self-Attention, https://arxiv.org/pdf/2510.12941, 2025-10-14
2025-11-09 11:02:50,751 - INFO - root - Page:0, Index:5, Efficient In-Memory Acceleration of Sparse Block Diagonal LLMs, https://arxiv.org/pdf/2510.11192, 2025-10-13
2025-11-09 11:02:50,751 - INFO - root - Page:0, Index:6, Dissecting Transformers: A CLEAR Perspective towards Green AI, https://arxiv.org/pdf/2510.02810, 2025-10-03
2025-11-09 11:02:50,751 - INFO - root - Page:0, Index:7, Microscaling Floating Point Formats for Large Language Models, https://arxiv.org/pdf/2510.01863, 2025-10-02
2025-11-09 11:02:50,751 - INFO - root - Page:0, Index:8, Automated and Scalable SEM Image Analysis of Perovskite Solar Cell Materials via a Deep Segmentation Framework, https://arxiv.org/pdf/2509.26548, 2025-09-30
2025-11-09 11:02:50,751 - INFO - root - Page:0, Index:9, AMLA: MUL by ADD in FlashAttention Rescaling, https://arxiv.org/pdf/2509.25224, 2025-09-24
2025-11-09 11:02:50,751 - INFO - root - Page:0, Index:10, Pretraining Large Language Models with NVFP4, https://arxiv.org/pdf/2509.25149, 2025-09-29
2025-11-09 11:02:50,751 - INFO - root - Page:0, Index:11, Bridging the Gap Between Promise and Performance for Microscaling FP4 Quantization, https://arxiv.org/pdf/2509.23202, 2025-10-16
2025-11-09 11:02:50,755 - INFO - root - Page:0, Index:12, Towards Verified Compilation of Floating-point Optimization in Scientific Computing Programs, https://arxiv.org/pdf/2509.09019, 2025-09-10
2025-11-09 11:02:50,755 - INFO - root - Page:0, Index:13, Green Learning for STAR-RIS mmWave Systems with Implicit CSI, https://arxiv.org/pdf/2509.06820, 2025-09-08
2025-11-09 11:02:50,755 - INFO - root - Page:0, Index:14, A Compute&Memory Efficient Model-Driven Neural 5G Receiver for Edge AI-assisted RAN, https://arxiv.org/pdf/2508.12892, 2025-10-22
2025-11-09 11:02:50,756 - INFO - root - Page:0, Index:15, SNNSIR: A Simple Spiking Neural Network for Stereo Image Restoration, https://arxiv.org/pdf/2508.12271, 2025-08-17
2025-11-09 11:02:50,758 - INFO - root - Page:0, Index:16, SpikeSTAG: Spatial-Temporal Forecasting via GNN-SNN Collaboration, https://arxiv.org/pdf/2508.02069, 2025-08-18
2025-11-09 11:02:50,758 - INFO - root - Page:0, Index:17, DGEMM without FP64 Arithmetic - Using FP64 Emulation and FP8 Tensor Cores with Ozaki Scheme, https://arxiv.org/pdf/2508.00441, 2025-09-25
2025-11-09 11:02:50,758 - INFO - root - Page:0, Index:18, Scaling Probabilistic Circuits via Monarch Matrices, https://arxiv.org/pdf/2506.12383, 2025-06-14
2025-11-09 11:02:50,758 - INFO - root - Page:0, Index:19, Starting Positions Matter: A Study on Better Weight Initialization for Neural Network Quantization, https://arxiv.org/pdf/2506.10463, 2025-06-12
2025-11-09 11:02:50,758 - INFO - root - Page:0, Index:20, Recipes for Pre-training LLMs with MXFP8, https://arxiv.org/pdf/2506.08027, 2025-08-18
2025-11-09 11:02:50,758 - INFO - root - Page:0, Index:21, FP4 All the Way: Fully Quantized Training of LLMs, https://arxiv.org/pdf/2505.19115, 2025-08-10
2025-11-09 11:02:50,759 - INFO - root - Page:0, Index:22, Automatic Verification of Floating-Point Accumulation Networks, https://arxiv.org/pdf/2505.18791, 2025-05-24
2025-11-09 11:02:50,759 - INFO - root - Page:0, Index:23, MXDOTP: A RISC-V ISA Extension for Enabling Microscaling (MX) Floating-Point Dot Products, https://arxiv.org/pdf/2505.13159, 2025-05-19
2025-11-09 11:02:50,760 - INFO - root - Page:0, Index:24, Parameter-Efficient Fine-Tuning with Circulant and Diagonal Vectors, https://arxiv.org/pdf/2505.00580, 2025-07-15
2025-11-09 11:02:50,760 - INFO - root - Page:0, Index:25, Silenzio: Secure Non-Interactive Outsourced MLP Training, https://arxiv.org/pdf/2504.17785, 2025-09-18
2025-11-09 11:02:50,760 - INFO - root - Page:0, Index:26, Involution and BSConv Multi-Depth Distillation Network for Lightweight Image Super-Resolution, https://arxiv.org/pdf/2503.14779, 2025-09-08
2025-11-09 11:02:50,762 - INFO - root - Page:0, Index:27, Flopping for FLOPs: Leveraging equivariance for computational efficiency, https://arxiv.org/pdf/2502.05169, 2025-06-24
2025-11-09 11:02:50,762 - INFO - root - Page:0, Index:28, An Effective UNet Using Feature Interaction and Fusion for Organ Segmentation in Medical Image, https://arxiv.org/pdf/2409.05324, 2025-07-26
2025-11-09 11:02:50,762 - INFO - root - Fetching page 2 with URL: https://arxiv.org/search/?query=block+float+point&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=50
2025-11-09 11:14:07,152 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-09 11:14:07,154 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-09 11:14:07,155 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-09 11:14:07,953 - INFO - root - LLMClient: trying model gemini-2.5-flash
2025-11-09 11:14:08,826 - INFO - root - LLMClient: trying model gemini-2.5-pro
2025-11-09 11:14:09,206 - WARNING - root - LLMClient: no usable model found, LLM disabled
2025-11-09 11:14:09,206 - INFO - root - LLM 未初始化或不可用，后续生成将返回备用消息
2025-11-09 11:14:09,207 - INFO - root - === 运行配置 ===
2025-11-09 11:14:09,207 - INFO - root - 处理模式: arxiv在线搜索
2025-11-09 11:14:09,207 - INFO - root - 关键词: Quant
2025-11-09 11:14:09,207 - INFO - root - 查询: block float point
2025-11-09 11:14:09,208 - INFO - root - 排序: None
2025-11-09 11:14:09,208 - INFO - root - 最近天数: 180
2025-11-09 11:14:09,208 - INFO - root - 最大处理数量: 50
2025-11-09 11:14:09,209 - INFO - root - 保存图片: 是
2025-11-09 11:14:09,209 - INFO - root - 输出语言: 中文
2025-11-09 11:14:09,209 - INFO - root - 强制重新处理: 否
2025-11-09 11:14:09,209 - INFO - root - ====================
2025-11-09 11:14:09,210 - INFO - root - 使用 arXiv 搜索模式（通过 chat_arxiv 模块获取）
2025-11-09 11:14:09,210 - INFO - root - Fetching page 1 with URL: https://arxiv.org/search/?query=block+float+point&searchtype=all&abstracts=show&order=-announced_date_first&size=50
2025-11-09 11:14:15,463 - INFO - root - get_all_titles_from_web 
2025-11-09 11:14:15,463 - INFO - root - Page:0, Index:0, From Uniform to Adaptive: General Skip-Block Mechanisms for Efficient PDE Neural Operators, https://arxiv.org/pdf/2511.00032, 2025-11-04
2025-11-09 11:14:15,463 - INFO - root - Page:0, Index:1, INT v.s. FP: A Comprehensive Study of Fine-Grained Low-bit Quantization Formats, https://arxiv.org/pdf/2510.25602, 2025-10-29
2025-11-09 11:14:15,463 - INFO - root - Page:0, Index:2, MX+: Pushing the Limits of Microscaling Formats for Efficient Large Language Model Serving, https://arxiv.org/pdf/2510.14557, 2025-10-16
2025-11-09 11:14:15,463 - INFO - root - Page:0, Index:3, F-BFQ: Flexible Block Floating-Point Quantization Accelerator for LLMs, https://arxiv.org/pdf/2510.13401, 2025-10-15
2025-11-09 11:14:15,463 - INFO - root - Page:0, Index:4, Computationally Efficient Neural Receivers via Axial Self-Attention, https://arxiv.org/pdf/2510.12941, 2025-10-14
2025-11-09 11:14:15,463 - INFO - root - Page:0, Index:5, Efficient In-Memory Acceleration of Sparse Block Diagonal LLMs, https://arxiv.org/pdf/2510.11192, 2025-10-13
2025-11-09 11:14:15,463 - INFO - root - Page:0, Index:6, Dissecting Transformers: A CLEAR Perspective towards Green AI, https://arxiv.org/pdf/2510.02810, 2025-10-03
2025-11-09 11:14:15,463 - INFO - root - Page:0, Index:7, Microscaling Floating Point Formats for Large Language Models, https://arxiv.org/pdf/2510.01863, 2025-10-02
2025-11-09 11:14:15,463 - INFO - root - Page:0, Index:8, Automated and Scalable SEM Image Analysis of Perovskite Solar Cell Materials via a Deep Segmentation Framework, https://arxiv.org/pdf/2509.26548, 2025-09-30
2025-11-09 11:14:15,463 - INFO - root - Page:0, Index:9, AMLA: MUL by ADD in FlashAttention Rescaling, https://arxiv.org/pdf/2509.25224, 2025-09-24
2025-11-09 11:14:15,463 - INFO - root - Page:0, Index:10, Pretraining Large Language Models with NVFP4, https://arxiv.org/pdf/2509.25149, 2025-09-29
2025-11-09 11:14:15,463 - INFO - root - Page:0, Index:11, Bridging the Gap Between Promise and Performance for Microscaling FP4 Quantization, https://arxiv.org/pdf/2509.23202, 2025-10-16
2025-11-09 11:14:15,463 - INFO - root - Page:0, Index:12, Towards Verified Compilation of Floating-point Optimization in Scientific Computing Programs, https://arxiv.org/pdf/2509.09019, 2025-09-10
2025-11-09 11:14:15,463 - INFO - root - Page:0, Index:13, Green Learning for STAR-RIS mmWave Systems with Implicit CSI, https://arxiv.org/pdf/2509.06820, 2025-09-08
2025-11-09 11:14:15,463 - INFO - root - Page:0, Index:14, A Compute&Memory Efficient Model-Driven Neural 5G Receiver for Edge AI-assisted RAN, https://arxiv.org/pdf/2508.12892, 2025-10-22
2025-11-09 11:14:15,463 - INFO - root - Page:0, Index:15, SNNSIR: A Simple Spiking Neural Network for Stereo Image Restoration, https://arxiv.org/pdf/2508.12271, 2025-08-17
2025-11-09 11:14:15,463 - INFO - root - Page:0, Index:16, SpikeSTAG: Spatial-Temporal Forecasting via GNN-SNN Collaboration, https://arxiv.org/pdf/2508.02069, 2025-08-18
2025-11-09 11:14:15,463 - INFO - root - Page:0, Index:17, DGEMM without FP64 Arithmetic - Using FP64 Emulation and FP8 Tensor Cores with Ozaki Scheme, https://arxiv.org/pdf/2508.00441, 2025-09-25
2025-11-09 11:14:15,463 - INFO - root - Page:0, Index:18, Scaling Probabilistic Circuits via Monarch Matrices, https://arxiv.org/pdf/2506.12383, 2025-06-14
2025-11-09 11:14:15,463 - INFO - root - Page:0, Index:19, Starting Positions Matter: A Study on Better Weight Initialization for Neural Network Quantization, https://arxiv.org/pdf/2506.10463, 2025-06-12
2025-11-09 11:14:15,463 - INFO - root - Page:0, Index:20, Recipes for Pre-training LLMs with MXFP8, https://arxiv.org/pdf/2506.08027, 2025-08-18
2025-11-09 11:14:15,463 - INFO - root - Page:0, Index:21, FP4 All the Way: Fully Quantized Training of LLMs, https://arxiv.org/pdf/2505.19115, 2025-08-10
2025-11-09 11:14:15,463 - INFO - root - Page:0, Index:22, Automatic Verification of Floating-Point Accumulation Networks, https://arxiv.org/pdf/2505.18791, 2025-05-24
2025-11-09 11:14:15,463 - INFO - root - Page:0, Index:23, MXDOTP: A RISC-V ISA Extension for Enabling Microscaling (MX) Floating-Point Dot Products, https://arxiv.org/pdf/2505.13159, 2025-05-19
2025-11-09 11:14:15,463 - INFO - root - Page:0, Index:24, Parameter-Efficient Fine-Tuning with Circulant and Diagonal Vectors, https://arxiv.org/pdf/2505.00580, 2025-07-15
2025-11-09 11:14:15,473 - INFO - root - Page:0, Index:25, Silenzio: Secure Non-Interactive Outsourced MLP Training, https://arxiv.org/pdf/2504.17785, 2025-09-18
2025-11-09 11:14:15,475 - INFO - root - Page:0, Index:26, Involution and BSConv Multi-Depth Distillation Network for Lightweight Image Super-Resolution, https://arxiv.org/pdf/2503.14779, 2025-09-08
2025-11-09 11:14:15,475 - INFO - root - Page:0, Index:27, Flopping for FLOPs: Leveraging equivariance for computational efficiency, https://arxiv.org/pdf/2502.05169, 2025-06-24
2025-11-09 11:14:15,477 - INFO - root - Page:0, Index:28, An Effective UNet Using Feature Interaction and Fusion for Organ Segmentation in Medical Image, https://arxiv.org/pdf/2409.05324, 2025-07-26
2025-11-09 11:14:15,477 - INFO - root - Fetching page 2 with URL: https://arxiv.org/search/?query=block+float+point&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=50
2025-11-09 11:14:21,869 - INFO - root - get_all_titles_from_web 
2025-11-09 11:14:21,869 - INFO - root - Page:1, Index:0, TwinLiteNet+: An Enhanced Multi-Task Segmentation Model for Autonomous Driving, https://arxiv.org/pdf/2403.16958, 2025-08-30
2025-11-09 11:14:21,869 - INFO - root - Fetching page 3 with URL: https://arxiv.org/search/?query=block+float+point&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=100
2025-11-09 11:14:28,257 - INFO - root - ------------------------------------------------------------------------------------------------------------------------
2025-11-09 11:18:03,978 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-09 11:18:03,979 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-09 11:18:03,981 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-09 11:18:04,669 - INFO - root - LLMClient: trying model gemini-2.5-flash
2025-11-09 11:18:05,549 - INFO - root - LLMClient: trying model gemini-2.5-pro
2025-11-09 11:18:05,899 - WARNING - root - LLMClient: no usable model found, LLM disabled
2025-11-09 11:18:05,899 - INFO - root - LLM 未初始化或不可用，后续生成将返回备用消息
2025-11-09 11:18:05,900 - INFO - root - === 运行配置 ===
2025-11-09 11:18:05,901 - INFO - root - 处理模式: arxiv在线搜索
2025-11-09 11:18:05,901 - INFO - root - 关键词: Quant
2025-11-09 11:18:05,901 - INFO - root - 查询: block float point
2025-11-09 11:18:05,901 - INFO - root - 排序: None
2025-11-09 11:18:05,902 - INFO - root - 最近天数: 180
2025-11-09 11:18:05,902 - INFO - root - 最大处理数量: 2
2025-11-09 11:18:05,903 - INFO - root - 保存图片: 是
2025-11-09 11:18:05,903 - INFO - root - 输出语言: 中文
2025-11-09 11:18:05,903 - INFO - root - 强制重新处理: 否
2025-11-09 11:18:05,903 - INFO - root - ====================
2025-11-09 11:18:05,904 - INFO - root - 使用 arXiv 搜索模式（通过 chat_arxiv 模块获取）
2025-11-09 11:18:05,904 - INFO - root - Fetching page 1 with URL: https://arxiv.org/search/?query=block+float+point&searchtype=all&abstracts=show&order=-announced_date_first&size=50
2025-11-09 11:18:12,193 - INFO - root - get_all_titles_from_web 
2025-11-09 11:18:12,193 - INFO - root - Page:0, Index:0, From Uniform to Adaptive: General Skip-Block Mechanisms for Efficient PDE Neural Operators, https://arxiv.org/pdf/2511.00032, 2025-11-04
2025-11-09 11:18:12,194 - INFO - root - Page:0, Index:1, INT v.s. FP: A Comprehensive Study of Fine-Grained Low-bit Quantization Formats, https://arxiv.org/pdf/2510.25602, 2025-10-29
2025-11-09 11:18:12,194 - INFO - root - Page:0, Index:2, MX+: Pushing the Limits of Microscaling Formats for Efficient Large Language Model Serving, https://arxiv.org/pdf/2510.14557, 2025-10-16
2025-11-09 11:18:12,194 - INFO - root - Page:0, Index:3, F-BFQ: Flexible Block Floating-Point Quantization Accelerator for LLMs, https://arxiv.org/pdf/2510.13401, 2025-10-15
2025-11-09 11:18:12,194 - INFO - root - Page:0, Index:4, Computationally Efficient Neural Receivers via Axial Self-Attention, https://arxiv.org/pdf/2510.12941, 2025-10-14
2025-11-09 11:18:12,196 - INFO - root - Page:0, Index:5, Efficient In-Memory Acceleration of Sparse Block Diagonal LLMs, https://arxiv.org/pdf/2510.11192, 2025-10-13
2025-11-09 11:18:12,196 - INFO - root - Page:0, Index:6, Dissecting Transformers: A CLEAR Perspective towards Green AI, https://arxiv.org/pdf/2510.02810, 2025-10-03
2025-11-09 11:18:12,196 - INFO - root - Page:0, Index:7, Microscaling Floating Point Formats for Large Language Models, https://arxiv.org/pdf/2510.01863, 2025-10-02
2025-11-09 11:18:12,196 - INFO - root - Page:0, Index:8, Automated and Scalable SEM Image Analysis of Perovskite Solar Cell Materials via a Deep Segmentation Framework, https://arxiv.org/pdf/2509.26548, 2025-09-30
2025-11-09 11:18:12,196 - INFO - root - Page:0, Index:9, AMLA: MUL by ADD in FlashAttention Rescaling, https://arxiv.org/pdf/2509.25224, 2025-09-24
2025-11-09 11:18:12,196 - INFO - root - Page:0, Index:10, Pretraining Large Language Models with NVFP4, https://arxiv.org/pdf/2509.25149, 2025-09-29
2025-11-09 11:18:12,196 - INFO - root - Page:0, Index:11, Bridging the Gap Between Promise and Performance for Microscaling FP4 Quantization, https://arxiv.org/pdf/2509.23202, 2025-10-16
2025-11-09 11:18:12,196 - INFO - root - Page:0, Index:12, Towards Verified Compilation of Floating-point Optimization in Scientific Computing Programs, https://arxiv.org/pdf/2509.09019, 2025-09-10
2025-11-09 11:18:12,196 - INFO - root - Page:0, Index:13, Green Learning for STAR-RIS mmWave Systems with Implicit CSI, https://arxiv.org/pdf/2509.06820, 2025-09-08
2025-11-09 11:18:12,196 - INFO - root - Page:0, Index:14, A Compute&Memory Efficient Model-Driven Neural 5G Receiver for Edge AI-assisted RAN, https://arxiv.org/pdf/2508.12892, 2025-10-22
2025-11-09 11:18:12,196 - INFO - root - Page:0, Index:15, SNNSIR: A Simple Spiking Neural Network for Stereo Image Restoration, https://arxiv.org/pdf/2508.12271, 2025-08-17
2025-11-09 11:18:12,196 - INFO - root - Page:0, Index:16, SpikeSTAG: Spatial-Temporal Forecasting via GNN-SNN Collaboration, https://arxiv.org/pdf/2508.02069, 2025-08-18
2025-11-09 11:18:12,196 - INFO - root - Page:0, Index:17, DGEMM without FP64 Arithmetic - Using FP64 Emulation and FP8 Tensor Cores with Ozaki Scheme, https://arxiv.org/pdf/2508.00441, 2025-09-25
2025-11-09 11:18:12,196 - INFO - root - Page:0, Index:18, Scaling Probabilistic Circuits via Monarch Matrices, https://arxiv.org/pdf/2506.12383, 2025-06-14
2025-11-09 11:18:12,196 - INFO - root - Page:0, Index:19, Starting Positions Matter: A Study on Better Weight Initialization for Neural Network Quantization, https://arxiv.org/pdf/2506.10463, 2025-06-12
2025-11-09 11:18:12,196 - INFO - root - Page:0, Index:20, Recipes for Pre-training LLMs with MXFP8, https://arxiv.org/pdf/2506.08027, 2025-08-18
2025-11-09 11:18:12,196 - INFO - root - Page:0, Index:21, FP4 All the Way: Fully Quantized Training of LLMs, https://arxiv.org/pdf/2505.19115, 2025-08-10
2025-11-09 11:18:12,196 - INFO - root - Page:0, Index:22, Automatic Verification of Floating-Point Accumulation Networks, https://arxiv.org/pdf/2505.18791, 2025-05-24
2025-11-09 11:18:12,196 - INFO - root - Page:0, Index:23, MXDOTP: A RISC-V ISA Extension for Enabling Microscaling (MX) Floating-Point Dot Products, https://arxiv.org/pdf/2505.13159, 2025-05-19
2025-11-09 11:18:12,196 - INFO - root - Page:0, Index:24, Parameter-Efficient Fine-Tuning with Circulant and Diagonal Vectors, https://arxiv.org/pdf/2505.00580, 2025-07-15
2025-11-09 11:18:12,196 - INFO - root - Page:0, Index:25, Silenzio: Secure Non-Interactive Outsourced MLP Training, https://arxiv.org/pdf/2504.17785, 2025-09-18
2025-11-09 11:18:12,196 - INFO - root - Page:0, Index:26, Involution and BSConv Multi-Depth Distillation Network for Lightweight Image Super-Resolution, https://arxiv.org/pdf/2503.14779, 2025-09-08
2025-11-09 11:18:12,196 - INFO - root - Page:0, Index:27, Flopping for FLOPs: Leveraging equivariance for computational efficiency, https://arxiv.org/pdf/2502.05169, 2025-06-24
2025-11-09 11:18:12,204 - INFO - root - Page:0, Index:28, An Effective UNet Using Feature Interaction and Fusion for Organ Segmentation in Medical Image, https://arxiv.org/pdf/2409.05324, 2025-07-26
2025-11-09 11:18:12,204 - INFO - root - Fetching page 2 with URL: https://arxiv.org/search/?query=block+float+point&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=50
2025-11-09 11:18:18,346 - INFO - root - get_all_titles_from_web 
2025-11-09 11:18:18,347 - INFO - root - Page:1, Index:0, TwinLiteNet+: An Enhanced Multi-Task Segmentation Model for Autonomous Driving, https://arxiv.org/pdf/2403.16958, 2025-08-30
2025-11-09 11:18:18,347 - INFO - root - Fetching page 3 with URL: https://arxiv.org/search/?query=block+float+point&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=100
2025-11-09 11:18:24,765 - INFO - root - ------------------------------------------------------------------------------------------------------------------------
2025-11-09 11:18:36,427 - INFO - root - 正在总结论文 1/2: From Uniform to Adaptive: General Skip-Block Mechanisms for Efficient PDE Neural Operators
2025-11-09 11:18:36,429 - INFO - root - 正在提取论文图片...
2025-11-09 11:18:36,905 - INFO - root - 已保存图片 1/10：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_1_page3.png
2025-11-09 11:18:36,981 - INFO - root - 已保存图片 2/10：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_2_page8.png
2025-11-09 11:18:37,084 - INFO - root - 已保存图片 3/10：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_3_page8.png
2025-11-09 11:18:37,161 - INFO - root - 已保存图片 4/10：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_4_page9.png
2025-11-09 11:18:37,262 - INFO - root - 已保存图片 5/10：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_5_page9.png
2025-11-09 11:18:37,350 - INFO - root - 已保存图片 6/10：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_6_page4.png
2025-11-09 11:18:37,428 - INFO - root - 已保存图片 7/10：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_7_page4.png
2025-11-09 11:18:37,564 - INFO - root - 已保存图片 8/10：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_8_page16.png
2025-11-09 11:18:37,585 - INFO - root - 已保存图片 9/10：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_9_page4.png
2025-11-09 11:18:37,612 - INFO - root - 已保存图片 10/10：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_10_page4.png
2025-11-09 11:18:37,619 - INFO - root - 成功添加图片 1：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_1_page3.png
2025-11-09 11:18:37,621 - INFO - root - 成功添加图片 2：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_2_page8.png
2025-11-09 11:18:37,625 - INFO - root - 成功添加图片 3：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_3_page8.png
2025-11-09 11:18:37,626 - INFO - root - 成功添加图片 4：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_4_page9.png
2025-11-09 11:18:37,627 - INFO - root - 成功添加图片 5：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_5_page9.png
2025-11-09 11:18:37,627 - INFO - root - 成功添加图片 6：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_6_page4.png
2025-11-09 11:18:37,628 - INFO - root - 成功添加图片 7：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_7_page4.png
2025-11-09 11:18:37,629 - INFO - root - 成功添加图片 8：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_8_page16.png
2025-11-09 11:18:37,630 - INFO - root - 成功添加图片 9：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_9_page4.png
2025-11-09 11:18:37,631 - INFO - root - 成功添加图片 10：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_10_page4.png
2025-11-09 11:18:37,634 - INFO - root - 论文《From Uniform to Adaptive: General Skip-Block Mechanisms for Efficient PDE Neural Operators》的分析已保存到 ./export\From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural-2.md
2025-11-09 11:18:37,645 - INFO - root - 正在总结论文 2/2: INT v.s. FP: A Comprehensive Study of Fine-Grained Low-bit Quantization Formats
2025-11-09 11:18:37,646 - INFO - root - 正在提取论文图片...
2025-11-09 11:18:38,452 - INFO - root - 已保存图片 1/10：./export\images_INT v.s. FP_ A Comprehensive Study of Fine-Grained Low-bit Quantization Formats\figure_1_page9.png
2025-11-09 11:18:38,533 - INFO - root - 已保存图片 2/10：./export\images_INT v.s. FP_ A Comprehensive Study of Fine-Grained Low-bit Quantization Formats\figure_2_page1.png
2025-11-09 11:18:38,563 - INFO - root - 已保存图片 3/10：./export\images_INT v.s. FP_ A Comprehensive Study of Fine-Grained Low-bit Quantization Formats\figure_3_page1.jpeg
2025-11-09 11:18:38,638 - INFO - root - 已保存图片 4/10：./export\images_INT v.s. FP_ A Comprehensive Study of Fine-Grained Low-bit Quantization Formats\figure_4_page9.png
2025-11-09 11:18:38,648 - INFO - root - 成功添加图片 1：./export\images_INT v.s. FP_ A Comprehensive Study of Fine-Grained Low-bit Quantization Formats\figure_1_page9.png
2025-11-09 11:18:38,648 - INFO - root - 成功添加图片 2：./export\images_INT v.s. FP_ A Comprehensive Study of Fine-Grained Low-bit Quantization Formats\figure_2_page1.png
2025-11-09 11:18:38,650 - INFO - root - 成功添加图片 3：./export\images_INT v.s. FP_ A Comprehensive Study of Fine-Grained Low-bit Quantization Formats\figure_3_page1.jpeg
2025-11-09 11:18:38,650 - INFO - root - 成功添加图片 4：./export\images_INT v.s. FP_ A Comprehensive Study of Fine-Grained Low-bit Quantization Formats\figure_4_page9.png
2025-11-09 11:18:38,652 - INFO - root - 论文《INT v.s. FP: A Comprehensive Study of Fine-Grained Low-bit Quantization Formats》的分析已保存到 ./export\INT v.s. FP_ A Comprehensive Study of Fine-Grained Low-bit Quantization Formats-2.md
2025-11-09 11:18:38,667 - INFO - root - summary time: 34.69 seconds
2025-11-09 11:29:36,716 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-09 11:29:36,721 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-09 11:29:36,737 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-09 11:30:37,916 - ERROR - root - LLMClient: error during initialization: Timeout of 60.0s exceeded, last exception: 503 failed to connect to all addresses; last error: UNKNOWN: ipv4:142.250.73.138:443: tcp handshaker shutdown
2025-11-09 11:30:37,917 - INFO - root - LLM 未初始化或不可用，后续生成将返回备用消息
2025-11-09 11:30:37,917 - INFO - root - === 运行配置 ===
2025-11-09 11:30:37,918 - INFO - root - 处理模式: arxiv在线搜索
2025-11-09 11:30:37,918 - INFO - root - 关键词: Quant
2025-11-09 11:30:37,918 - INFO - root - 查询: block float point
2025-11-09 11:30:37,919 - INFO - root - 排序: None
2025-11-09 11:30:37,919 - INFO - root - 最近天数: 180
2025-11-09 11:30:37,919 - INFO - root - 最大处理数量: 2
2025-11-09 11:30:37,919 - INFO - root - 保存图片: 是
2025-11-09 11:30:37,920 - INFO - root - 输出语言: 中文
2025-11-09 11:30:37,920 - INFO - root - 强制重新处理: 否
2025-11-09 11:30:37,920 - INFO - root - ====================
2025-11-09 11:30:37,921 - INFO - root - 使用 arXiv 搜索模式（通过 chat_arxiv 模块获取）
2025-11-09 11:30:37,921 - INFO - root - Fetching page 1 with URL: https://arxiv.org/search/?query=block+float+point&searchtype=all&abstracts=show&order=-announced_date_first&size=50
2025-11-09 11:31:05,549 - INFO - root - get_all_titles_from_web 
2025-11-09 11:31:05,549 - INFO - root - Page:0, Index:0, From Uniform to Adaptive: General Skip-Block Mechanisms for Efficient PDE Neural Operators, https://arxiv.org/pdf/2511.00032, 2025-11-04
2025-11-09 11:31:05,549 - INFO - root - Page:0, Index:1, INT v.s. FP: A Comprehensive Study of Fine-Grained Low-bit Quantization Formats, https://arxiv.org/pdf/2510.25602, 2025-10-29
2025-11-09 11:31:05,549 - INFO - root - Page:0, Index:2, MX+: Pushing the Limits of Microscaling Formats for Efficient Large Language Model Serving, https://arxiv.org/pdf/2510.14557, 2025-10-16
2025-11-09 11:31:05,549 - INFO - root - Page:0, Index:3, F-BFQ: Flexible Block Floating-Point Quantization Accelerator for LLMs, https://arxiv.org/pdf/2510.13401, 2025-10-15
2025-11-09 11:31:05,549 - INFO - root - Page:0, Index:4, Computationally Efficient Neural Receivers via Axial Self-Attention, https://arxiv.org/pdf/2510.12941, 2025-10-14
2025-11-09 11:31:05,549 - INFO - root - Page:0, Index:5, Efficient In-Memory Acceleration of Sparse Block Diagonal LLMs, https://arxiv.org/pdf/2510.11192, 2025-10-13
2025-11-09 11:31:05,549 - INFO - root - Page:0, Index:6, Dissecting Transformers: A CLEAR Perspective towards Green AI, https://arxiv.org/pdf/2510.02810, 2025-10-03
2025-11-09 11:31:05,549 - INFO - root - Page:0, Index:7, Microscaling Floating Point Formats for Large Language Models, https://arxiv.org/pdf/2510.01863, 2025-10-02
2025-11-09 11:31:05,549 - INFO - root - Page:0, Index:8, Automated and Scalable SEM Image Analysis of Perovskite Solar Cell Materials via a Deep Segmentation Framework, https://arxiv.org/pdf/2509.26548, 2025-09-30
2025-11-09 11:31:05,549 - INFO - root - Page:0, Index:9, AMLA: MUL by ADD in FlashAttention Rescaling, https://arxiv.org/pdf/2509.25224, 2025-09-24
2025-11-09 11:31:05,549 - INFO - root - Page:0, Index:10, Pretraining Large Language Models with NVFP4, https://arxiv.org/pdf/2509.25149, 2025-09-29
2025-11-09 11:31:05,549 - INFO - root - Page:0, Index:11, Bridging the Gap Between Promise and Performance for Microscaling FP4 Quantization, https://arxiv.org/pdf/2509.23202, 2025-10-16
2025-11-09 11:31:05,549 - INFO - root - Page:0, Index:12, Towards Verified Compilation of Floating-point Optimization in Scientific Computing Programs, https://arxiv.org/pdf/2509.09019, 2025-09-10
2025-11-09 11:31:05,549 - INFO - root - Page:0, Index:13, Green Learning for STAR-RIS mmWave Systems with Implicit CSI, https://arxiv.org/pdf/2509.06820, 2025-09-08
2025-11-09 11:31:05,549 - INFO - root - Page:0, Index:14, A Compute&Memory Efficient Model-Driven Neural 5G Receiver for Edge AI-assisted RAN, https://arxiv.org/pdf/2508.12892, 2025-10-22
2025-11-09 11:31:05,549 - INFO - root - Page:0, Index:15, SNNSIR: A Simple Spiking Neural Network for Stereo Image Restoration, https://arxiv.org/pdf/2508.12271, 2025-08-17
2025-11-09 11:31:05,549 - INFO - root - Page:0, Index:16, SpikeSTAG: Spatial-Temporal Forecasting via GNN-SNN Collaboration, https://arxiv.org/pdf/2508.02069, 2025-08-18
2025-11-09 11:31:05,549 - INFO - root - Page:0, Index:17, DGEMM without FP64 Arithmetic - Using FP64 Emulation and FP8 Tensor Cores with Ozaki Scheme, https://arxiv.org/pdf/2508.00441, 2025-09-25
2025-11-09 11:31:05,556 - INFO - root - Page:0, Index:18, Scaling Probabilistic Circuits via Monarch Matrices, https://arxiv.org/pdf/2506.12383, 2025-06-14
2025-11-09 11:31:05,557 - INFO - root - Page:0, Index:19, Starting Positions Matter: A Study on Better Weight Initialization for Neural Network Quantization, https://arxiv.org/pdf/2506.10463, 2025-06-12
2025-11-09 11:31:05,559 - INFO - root - Page:0, Index:20, Recipes for Pre-training LLMs with MXFP8, https://arxiv.org/pdf/2506.08027, 2025-08-18
2025-11-09 11:31:05,560 - INFO - root - Page:0, Index:21, FP4 All the Way: Fully Quantized Training of LLMs, https://arxiv.org/pdf/2505.19115, 2025-08-10
2025-11-09 11:31:05,560 - INFO - root - Page:0, Index:22, Automatic Verification of Floating-Point Accumulation Networks, https://arxiv.org/pdf/2505.18791, 2025-05-24
2025-11-09 11:31:05,560 - INFO - root - Page:0, Index:23, MXDOTP: A RISC-V ISA Extension for Enabling Microscaling (MX) Floating-Point Dot Products, https://arxiv.org/pdf/2505.13159, 2025-05-19
2025-11-09 11:31:05,561 - INFO - root - Page:0, Index:24, Parameter-Efficient Fine-Tuning with Circulant and Diagonal Vectors, https://arxiv.org/pdf/2505.00580, 2025-07-15
2025-11-09 11:31:05,561 - INFO - root - Page:0, Index:25, Silenzio: Secure Non-Interactive Outsourced MLP Training, https://arxiv.org/pdf/2504.17785, 2025-09-18
2025-11-09 11:31:05,561 - INFO - root - Page:0, Index:26, Involution and BSConv Multi-Depth Distillation Network for Lightweight Image Super-Resolution, https://arxiv.org/pdf/2503.14779, 2025-09-08
2025-11-09 11:31:05,562 - INFO - root - Page:0, Index:27, Flopping for FLOPs: Leveraging equivariance for computational efficiency, https://arxiv.org/pdf/2502.05169, 2025-06-24
2025-11-09 11:31:05,562 - INFO - root - Page:0, Index:28, An Effective UNet Using Feature Interaction and Fusion for Organ Segmentation in Medical Image, https://arxiv.org/pdf/2409.05324, 2025-07-26
2025-11-09 11:31:05,563 - INFO - root - Fetching page 2 with URL: https://arxiv.org/search/?query=block+float+point&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=50
2025-11-09 11:31:30,452 - INFO - root - get_all_titles_from_web 
2025-11-09 11:31:30,453 - INFO - root - Page:1, Index:0, TwinLiteNet+: An Enhanced Multi-Task Segmentation Model for Autonomous Driving, https://arxiv.org/pdf/2403.16958, 2025-08-30
2025-11-09 11:31:30,453 - INFO - root - Fetching page 3 with URL: https://arxiv.org/search/?query=block+float+point&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=100
2025-11-09 11:32:32,097 - INFO - root - ------------------------------------------------------------------------------------------------------------------------
2025-11-09 11:33:32,864 - INFO - root - 跳过已处理论文 From Uniform to Adaptive: General Skip-Block Mechanisms for Efficient PDE Neural Operators：D:\ChatPaper\academic Papers\block float point\From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural-1.pdf
2025-11-09 11:33:32,864 - INFO - root - 跳过已处理论文 INT v.s. FP: A Comprehensive Study of Fine-Grained Low-bit Quantization Formats：D:\ChatPaper\academic Papers\block float point\INT v.s. FP_ A Comprehensive Study of Fine-Grained Low-bit Quantization Formats-1.pdf
2025-11-09 11:33:32,864 - INFO - root - summary time: 236.15 seconds
2025-11-09 12:02:26,323 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-09 12:02:26,323 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-09 12:02:26,323 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-09 12:02:27,086 - INFO - root - GeminiClient: trying model gemini-2.5-flash
2025-11-09 12:02:27,922 - INFO - root - GeminiClient: trying model gemini-2.5-pro
2025-11-09 12:02:28,280 - WARNING - root - GeminiClient: no usable model found
2025-11-09 12:02:28,280 - WARNING - root - LLMClientManager: Gemini client initialization failed
2025-11-09 12:02:28,281 - WARNING - root - DeepSeekClient: API key not provided. LLM disabled.
2025-11-09 12:02:28,281 - WARNING - root - LLMClientManager: DeepSeek client initialization failed
2025-11-09 12:02:28,281 - WARNING - root - KimiClient: API key not provided. LLM disabled.
2025-11-09 12:02:28,281 - WARNING - root - LLMClientManager: Kimi client initialization failed
2025-11-09 12:02:28,282 - WARNING - root - QwenClient: API key not provided. LLM disabled.
2025-11-09 12:02:28,282 - WARNING - root - LLMClientManager: Qwen client initialization failed
2025-11-09 12:02:28,282 - WARNING - root - DoubaoClient: API key not provided. LLM disabled.
2025-11-09 12:02:28,282 - WARNING - root - LLMClientManager: Doubao client initialization failed
2025-11-09 12:02:28,283 - WARNING - root - LLMClientManager: no LLM client available
2025-11-09 12:02:28,283 - INFO - root - LLM 未初始化或不可用，后续生成将返回备用消息
2025-11-09 12:02:28,284 - INFO - root - === 运行配置 ===
2025-11-09 12:02:28,284 - INFO - root - 处理模式: arxiv在线搜索
2025-11-09 12:02:28,285 - INFO - root - 关键词: Quant
2025-11-09 12:02:28,285 - INFO - root - 查询: block float point
2025-11-09 12:02:28,287 - INFO - root - 排序: None
2025-11-09 12:02:28,287 - INFO - root - 最近天数: 180
2025-11-09 12:02:28,288 - INFO - root - 最大处理数量: 2
2025-11-09 12:02:28,289 - INFO - root - 保存图片: 是
2025-11-09 12:02:28,289 - INFO - root - 输出语言: 中文
2025-11-09 12:02:28,289 - INFO - root - 强制重新处理: 否
2025-11-09 12:02:28,290 - INFO - root - ====================
2025-11-09 12:02:28,290 - INFO - root - 使用 arXiv 搜索模式（通过 chat_arxiv 模块获取）
2025-11-09 12:02:28,290 - INFO - root - Fetching page 1 with URL: https://arxiv.org/search/?query=block+float+point&searchtype=all&abstracts=show&order=-announced_date_first&size=50
2025-11-09 12:02:34,854 - INFO - root - get_all_titles_from_web 
2025-11-09 12:02:34,854 - INFO - root - Page:0, Index:0, From Uniform to Adaptive: General Skip-Block Mechanisms for Efficient PDE Neural Operators, https://arxiv.org/pdf/2511.00032, 2025-11-04
2025-11-09 12:02:34,854 - INFO - root - Page:0, Index:1, INT v.s. FP: A Comprehensive Study of Fine-Grained Low-bit Quantization Formats, https://arxiv.org/pdf/2510.25602, 2025-10-29
2025-11-09 12:02:34,854 - INFO - root - Page:0, Index:2, MX+: Pushing the Limits of Microscaling Formats for Efficient Large Language Model Serving, https://arxiv.org/pdf/2510.14557, 2025-10-16
2025-11-09 12:02:34,854 - INFO - root - Page:0, Index:3, F-BFQ: Flexible Block Floating-Point Quantization Accelerator for LLMs, https://arxiv.org/pdf/2510.13401, 2025-10-15
2025-11-09 12:02:34,854 - INFO - root - Page:0, Index:4, Computationally Efficient Neural Receivers via Axial Self-Attention, https://arxiv.org/pdf/2510.12941, 2025-10-14
2025-11-09 12:02:34,854 - INFO - root - Page:0, Index:5, Efficient In-Memory Acceleration of Sparse Block Diagonal LLMs, https://arxiv.org/pdf/2510.11192, 2025-10-13
2025-11-09 12:02:34,854 - INFO - root - Page:0, Index:6, Dissecting Transformers: A CLEAR Perspective towards Green AI, https://arxiv.org/pdf/2510.02810, 2025-10-03
2025-11-09 12:02:34,857 - INFO - root - Page:0, Index:7, Microscaling Floating Point Formats for Large Language Models, https://arxiv.org/pdf/2510.01863, 2025-10-02
2025-11-09 12:02:34,857 - INFO - root - Page:0, Index:8, Automated and Scalable SEM Image Analysis of Perovskite Solar Cell Materials via a Deep Segmentation Framework, https://arxiv.org/pdf/2509.26548, 2025-09-30
2025-11-09 12:02:34,858 - INFO - root - Page:0, Index:9, AMLA: MUL by ADD in FlashAttention Rescaling, https://arxiv.org/pdf/2509.25224, 2025-09-24
2025-11-09 12:02:34,858 - INFO - root - Page:0, Index:10, Pretraining Large Language Models with NVFP4, https://arxiv.org/pdf/2509.25149, 2025-09-29
2025-11-09 12:02:34,858 - INFO - root - Page:0, Index:11, Bridging the Gap Between Promise and Performance for Microscaling FP4 Quantization, https://arxiv.org/pdf/2509.23202, 2025-10-16
2025-11-09 12:02:34,858 - INFO - root - Page:0, Index:12, Towards Verified Compilation of Floating-point Optimization in Scientific Computing Programs, https://arxiv.org/pdf/2509.09019, 2025-09-10
2025-11-09 12:02:34,859 - INFO - root - Page:0, Index:13, Green Learning for STAR-RIS mmWave Systems with Implicit CSI, https://arxiv.org/pdf/2509.06820, 2025-09-08
2025-11-09 12:02:34,859 - INFO - root - Page:0, Index:14, A Compute&Memory Efficient Model-Driven Neural 5G Receiver for Edge AI-assisted RAN, https://arxiv.org/pdf/2508.12892, 2025-10-22
2025-11-09 12:02:34,859 - INFO - root - Page:0, Index:15, SNNSIR: A Simple Spiking Neural Network for Stereo Image Restoration, https://arxiv.org/pdf/2508.12271, 2025-08-17
2025-11-09 12:02:34,860 - INFO - root - Page:0, Index:16, SpikeSTAG: Spatial-Temporal Forecasting via GNN-SNN Collaboration, https://arxiv.org/pdf/2508.02069, 2025-08-18
2025-11-09 12:02:34,860 - INFO - root - Page:0, Index:17, DGEMM without FP64 Arithmetic - Using FP64 Emulation and FP8 Tensor Cores with Ozaki Scheme, https://arxiv.org/pdf/2508.00441, 2025-09-25
2025-11-09 12:02:34,860 - INFO - root - Page:0, Index:18, Scaling Probabilistic Circuits via Monarch Matrices, https://arxiv.org/pdf/2506.12383, 2025-06-14
2025-11-09 12:02:34,861 - INFO - root - Page:0, Index:19, Starting Positions Matter: A Study on Better Weight Initialization for Neural Network Quantization, https://arxiv.org/pdf/2506.10463, 2025-06-12
2025-11-09 12:02:34,861 - INFO - root - Page:0, Index:20, Recipes for Pre-training LLMs with MXFP8, https://arxiv.org/pdf/2506.08027, 2025-08-18
2025-11-09 12:02:34,862 - INFO - root - Page:0, Index:21, FP4 All the Way: Fully Quantized Training of LLMs, https://arxiv.org/pdf/2505.19115, 2025-08-10
2025-11-09 12:02:34,862 - INFO - root - Page:0, Index:22, Automatic Verification of Floating-Point Accumulation Networks, https://arxiv.org/pdf/2505.18791, 2025-05-24
2025-11-09 12:02:34,862 - INFO - root - Page:0, Index:23, MXDOTP: A RISC-V ISA Extension for Enabling Microscaling (MX) Floating-Point Dot Products, https://arxiv.org/pdf/2505.13159, 2025-05-19
2025-11-09 12:02:34,862 - INFO - root - Page:0, Index:24, Parameter-Efficient Fine-Tuning with Circulant and Diagonal Vectors, https://arxiv.org/pdf/2505.00580, 2025-07-15
2025-11-09 12:02:34,863 - INFO - root - Page:0, Index:25, Silenzio: Secure Non-Interactive Outsourced MLP Training, https://arxiv.org/pdf/2504.17785, 2025-09-18
2025-11-09 12:02:34,863 - INFO - root - Page:0, Index:26, Involution and BSConv Multi-Depth Distillation Network for Lightweight Image Super-Resolution, https://arxiv.org/pdf/2503.14779, 2025-09-08
2025-11-09 12:02:34,863 - INFO - root - Page:0, Index:27, Flopping for FLOPs: Leveraging equivariance for computational efficiency, https://arxiv.org/pdf/2502.05169, 2025-06-24
2025-11-09 12:02:34,863 - INFO - root - Page:0, Index:28, An Effective UNet Using Feature Interaction and Fusion for Organ Segmentation in Medical Image, https://arxiv.org/pdf/2409.05324, 2025-07-26
2025-11-09 12:02:34,864 - INFO - root - Fetching page 2 with URL: https://arxiv.org/search/?query=block+float+point&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=50
2025-11-09 12:02:41,042 - INFO - root - get_all_titles_from_web 
2025-11-09 12:02:41,042 - INFO - root - Page:1, Index:0, TwinLiteNet+: An Enhanced Multi-Task Segmentation Model for Autonomous Driving, https://arxiv.org/pdf/2403.16958, 2025-08-30
2025-11-09 12:02:41,043 - INFO - root - Fetching page 3 with URL: https://arxiv.org/search/?query=block+float+point&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=100
2025-11-09 12:02:47,533 - INFO - root - ------------------------------------------------------------------------------------------------------------------------
2025-11-09 12:02:59,831 - INFO - root - 正在总结论文 1/2: From Uniform to Adaptive: General Skip-Block Mechanisms for Efficient PDE Neural Operators
2025-11-09 12:02:59,835 - INFO - root - 正在提取论文图片...
2025-11-09 12:03:00,382 - INFO - root - 已保存图片 1/10：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_1_page3.png
2025-11-09 12:03:00,553 - INFO - root - 已保存图片 2/10：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_2_page8.png
2025-11-09 12:03:00,645 - INFO - root - 已保存图片 3/10：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_3_page8.png
2025-11-09 12:03:00,721 - INFO - root - 已保存图片 4/10：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_4_page9.png
2025-11-09 12:03:00,827 - INFO - root - 已保存图片 5/10：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_5_page9.png
2025-11-09 12:03:00,943 - INFO - root - 已保存图片 6/10：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_6_page4.png
2025-11-09 12:03:01,103 - INFO - root - 已保存图片 7/10：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_7_page4.png
2025-11-09 12:03:01,219 - INFO - root - 已保存图片 8/10：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_8_page16.png
2025-11-09 12:03:01,246 - INFO - root - 已保存图片 9/10：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_9_page4.png
2025-11-09 12:03:01,272 - INFO - root - 已保存图片 10/10：./export\images_From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural\figure_10_page4.png
2025-11-09 12:03:01,284 - INFO - root - 输出文件已存在，跳过论文 From Uniform to Adaptive: General Skip-Block Mechanisms for Efficient PDE Neural Operators 的处理
2025-11-09 12:03:01,286 - INFO - root - 正在总结论文 2/2: INT v.s. FP: A Comprehensive Study of Fine-Grained Low-bit Quantization Formats
2025-11-09 12:03:01,287 - INFO - root - 正在提取论文图片...
2025-11-09 12:03:02,061 - INFO - root - 已保存图片 1/10：./export\images_INT v.s. FP_ A Comprehensive Study of Fine-Grained Low-bit Quantization Formats\figure_1_page9.png
2025-11-09 12:03:02,238 - INFO - root - 已保存图片 2/10：./export\images_INT v.s. FP_ A Comprehensive Study of Fine-Grained Low-bit Quantization Formats\figure_2_page1.png
2025-11-09 12:03:02,291 - INFO - root - 已保存图片 3/10：./export\images_INT v.s. FP_ A Comprehensive Study of Fine-Grained Low-bit Quantization Formats\figure_3_page1.jpeg
2025-11-09 12:03:02,361 - INFO - root - 已保存图片 4/10：./export\images_INT v.s. FP_ A Comprehensive Study of Fine-Grained Low-bit Quantization Formats\figure_4_page9.png
2025-11-09 12:03:02,364 - INFO - root - 输出文件已存在，跳过论文 INT v.s. FP: A Comprehensive Study of Fine-Grained Low-bit Quantization Formats 的处理
2025-11-09 12:03:02,364 - INFO - root - summary time: 36.04 seconds
2025-11-09 12:40:27,534 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-09 12:40:27,541 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-09 12:40:27,546 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-09 12:40:28,502 - INFO - root - GeminiClient: trying model gemini-2.5-flash
2025-11-09 12:40:29,436 - INFO - root - GeminiClient: trying model gemini-2.5-pro
2025-11-09 12:40:29,790 - WARNING - root - GeminiClient: no usable model found
2025-11-09 12:40:29,791 - WARNING - root - LLMClientManager: Gemini client initialization failed
2025-11-09 12:40:29,791 - WARNING - root - DeepSeekClient: API key not provided. LLM disabled.
2025-11-09 12:40:29,791 - WARNING - root - LLMClientManager: DeepSeek client initialization failed
2025-11-09 12:40:29,791 - WARNING - root - KimiClient: API key not provided. LLM disabled.
2025-11-09 12:40:29,792 - WARNING - root - LLMClientManager: Kimi client initialization failed
2025-11-09 12:40:29,792 - WARNING - root - QwenClient: API key not provided. LLM disabled.
2025-11-09 12:40:29,792 - WARNING - root - LLMClientManager: Qwen client initialization failed
2025-11-09 12:40:29,792 - WARNING - root - DoubaoClient: API key not provided. LLM disabled.
2025-11-09 12:40:29,793 - WARNING - root - LLMClientManager: Doubao client initialization failed
2025-11-09 12:40:29,793 - WARNING - root - LLMClientManager: no LLM client available
2025-11-09 12:40:29,793 - WARNING - root - LLMClientManager: client Gemini not available
2025-11-09 12:40:29,794 - WARNING - root - 无法切换到指定的客户端 Gemini，将使用默认客户端
2025-11-09 12:40:29,794 - INFO - root - 可用客户端: []
2025-11-09 12:40:29,795 - INFO - root - LLM 未初始化或不可用，后续生成将返回备用消息
2025-11-09 12:40:29,795 - INFO - root - === 运行配置 ===
2025-11-09 12:40:29,795 - INFO - root - 处理模式: 本地PDF文件
2025-11-09 12:40:29,796 - INFO - root - PDF目录: ./myPapers
2025-11-09 12:40:29,796 - INFO - root - 最大处理数量: 2
2025-11-09 12:40:29,797 - INFO - root - 保存图片: 是
2025-11-09 12:40:29,799 - INFO - root - 输出语言: 中文
2025-11-09 12:40:29,799 - INFO - root - 强制重新处理: 否
2025-11-09 12:40:29,800 - INFO - root - ====================
2025-11-09 12:40:29,800 - INFO - root - 从本地目录读取PDF文件：./myPapers
2025-11-09 12:40:32,678 - INFO - root - 成功加载PDF文件：A Compute&Memory Efficient Model-Driven Neural 5G Receiver for Edge AI-assisted.pdf
2025-11-09 12:40:35,064 - INFO - root - 成功加载PDF文件：AMLA_ MUL by ADD in FlashAttention Rescaling.pdf
2025-11-09 12:40:35,890 - INFO - root - 成功加载PDF文件：An Effective UNet Using Feature Interaction and Fusion for Organ Segmentation in.pdf
2025-11-09 12:42:15,377 - INFO - root - 成功加载PDF文件：Automated and Scalable SEM Image Analysis of Perovskite Solar Cell Materials via.pdf
2025-11-09 12:42:16,352 - INFO - root - 成功加载PDF文件：Automatic Verification of Floating-Point Accumulation Networks.pdf
2025-11-09 12:42:17,772 - INFO - root - 成功加载PDF文件：Bridging the Gap Between Promise and Performance for Microscaling FP4 Quantizati.pdf
2025-11-09 12:42:20,130 - INFO - root - 成功加载PDF文件：Computationally Efficient Neural Receivers via Axial Self-Attention.pdf
2025-11-09 12:42:21,023 - INFO - root - 成功加载PDF文件：DGEMM without FP64 Arithmetic - Using FP64 Emulation and FP8 Tensor Cores with O.pdf
2025-11-09 12:42:23,369 - INFO - root - 成功加载PDF文件：Dissecting Transformers_ A CLEAR Perspective towards Green AI.pdf
2025-11-09 12:42:23,819 - INFO - root - 成功加载PDF文件：Efficient In-Memory Acceleration of Sparse Block Diagonal LLMs.pdf
2025-11-09 12:42:26,826 - INFO - root - 成功加载PDF文件：F-BFQ_ Flexible Block Floating-Point Quantization Accelerator for LLMs.pdf
2025-11-09 12:42:28,662 - INFO - root - 成功加载PDF文件：Flopping for FLOPs_ Leveraging equivariance for computational efficiency.pdf
2025-11-09 12:42:29,354 - INFO - root - 成功加载PDF文件：FP4 All the Way_ Fully Quantized Training of LLMs.pdf
2025-11-09 12:42:30,794 - INFO - root - 成功加载PDF文件：From Uniform to Adaptive_ General Skip-Block Mechanisms for Efficient PDE Neural.pdf
2025-11-09 12:42:31,478 - INFO - root - 成功加载PDF文件：Green Learning for STAR-RIS mmWave Systems with Implicit CSI.pdf
2025-11-09 12:42:38,123 - INFO - root - 成功加载PDF文件：INT v.s. FP_ A Comprehensive Study of Fine-Grained Low-bit Quantization Formats.pdf
2025-11-09 12:42:38,686 - INFO - root - 成功加载PDF文件：Involution and BSConv Multi-Depth Distillation Network for Lightweight Image Sup.pdf
2025-11-09 12:42:39,128 - INFO - root - 成功加载PDF文件：Microscaling Floating Point Formats for Large Language Models.pdf
2025-11-09 12:42:39,967 - INFO - root - 成功加载PDF文件：MX+_ Pushing the Limits of Microscaling Formats for Efficient Large Language Mod.pdf
2025-11-09 12:42:40,332 - INFO - root - 成功加载PDF文件：MXDOTP_ A RISC-V ISA Extension for Enabling Microscaling (MX) Floating-Point Dot.pdf
2025-11-09 12:42:40,665 - INFO - root - 成功加载PDF文件：Parameter-Efficient Fine-Tuning with Circulant and Diagonal Vectors.pdf
2025-11-09 12:42:42,370 - INFO - root - 成功加载PDF文件：Pretraining Large Language Models with NVFP4.pdf
2025-11-09 12:42:42,773 - INFO - root - 成功加载PDF文件：Recipes for Pre-training LLMs with MXFP8.pdf
2025-11-09 12:42:44,763 - INFO - root - 成功加载PDF文件：Scaling Probabilistic Circuits via Monarch Matrices.pdf
2025-11-09 12:42:44,776 - ERROR - root - 处理PDF文件 Silenzio_ Secure Non-Interactive Outsourced MLP Training.pdf 时出错：no such file: './myPapers\Silenzio_ Secure Non-Interactive Outsourced MLP Training.pdf'
2025-11-09 12:42:44,778 - ERROR - root - 处理PDF文件 SNNSIR_ A Simple Spiking Neural Network for Stereo Image Restoration.pdf 时出错：no such file: './myPapers\SNNSIR_ A Simple Spiking Neural Network for Stereo Image Restoration.pdf'
2025-11-09 12:42:44,909 - ERROR - root - 处理PDF文件 SpikeSTAG_ Spatial-Temporal Forecasting via GNN-SNN Collaboration.pdf 时出错：no such file: './myPapers\SpikeSTAG_ Spatial-Temporal Forecasting via GNN-SNN Collaboration.pdf'
2025-11-09 12:42:44,940 - ERROR - root - 处理PDF文件 Starting Positions Matter_ A Study on Better Weight Initialization for Neural Ne.pdf 时出错：no such file: './myPapers\Starting Positions Matter_ A Study on Better Weight Initialization for Neural Ne.pdf'
2025-11-09 12:42:44,984 - ERROR - root - 处理PDF文件 Towards Verified Compilation of Floating-point Optimization in Scientific Comput.pdf 时出错：no such file: './myPapers\Towards Verified Compilation of Floating-point Optimization in Scientific Comput.pdf'
2025-11-09 12:42:44,994 - ERROR - root - 处理PDF文件 TwinLiteNet+_ An Enhanced Multi-Task Segmentation Model for Autonomous Driving.pdf 时出错：no such file: './myPapers\TwinLiteNet+_ An Enhanced Multi-Task Segmentation Model for Autonomous Driving.pdf'
2025-11-09 12:42:45,008 - INFO - root - 正在总结论文 1/24: A Compute&Memory Efficient Model-Driven Neural
2025-11-09 12:42:45,010 - INFO - root - 正在提取论文图片...
2025-11-09 12:42:46,858 - INFO - root - 已保存图片 1/10：./export\images_A Compute&Memory Efficient Model-Driven Neural\figure_1_page6.png
2025-11-09 12:42:47,327 - INFO - root - 已保存图片 2/10：./export\images_A Compute&Memory Efficient Model-Driven Neural\figure_2_page6.png
2025-11-09 12:42:47,562 - INFO - root - 已保存图片 3/10：./export\images_A Compute&Memory Efficient Model-Driven Neural\figure_3_page2.png
2025-11-09 12:42:47,639 - INFO - root - 已保存图片 4/10：./export\images_A Compute&Memory Efficient Model-Driven Neural\figure_4_page2.png
2025-11-09 12:42:47,689 - INFO - root - 已保存图片 5/10：./export\images_A Compute&Memory Efficient Model-Driven Neural\figure_5_page3.png
2025-11-09 12:42:47,702 - INFO - root - 成功添加图片 1：./export\images_A Compute&Memory Efficient Model-Driven Neural\figure_1_page6.png
2025-11-09 12:42:47,702 - INFO - root - 成功添加图片 2：./export\images_A Compute&Memory Efficient Model-Driven Neural\figure_2_page6.png
2025-11-09 12:42:47,703 - INFO - root - 成功添加图片 3：./export\images_A Compute&Memory Efficient Model-Driven Neural\figure_3_page2.png
2025-11-09 12:42:47,703 - INFO - root - 成功添加图片 4：./export\images_A Compute&Memory Efficient Model-Driven Neural\figure_4_page2.png
2025-11-09 12:42:47,703 - INFO - root - 成功添加图片 5：./export\images_A Compute&Memory Efficient Model-Driven Neural\figure_5_page3.png
2025-11-09 12:42:47,711 - INFO - root - 论文《A Compute&Memory Efficient Model-Driven Neural》的分析已保存到 ./export\A Compute&Memory Efficient Model-Driven Neural.md
2025-11-09 12:42:47,729 - INFO - root - 跳过已处理论文 AMLA: MUL by ADD in FlashAttention Rescaling：./myPapers\AMLA_ MUL by ADD in FlashAttention Rescaling.pdf
2025-11-09 12:42:47,730 - INFO - root - 正在总结论文 3/24: An Effective UNet Using Feature Interaction and Fusion for Organ
2025-11-09 12:42:47,737 - INFO - root - 正在提取论文图片...
2025-11-09 12:42:48,558 - INFO - root - 已保存图片 1/10：./export\images_An Effective UNet Using Feature Interaction and Fusion for Organ\figure_1_page14.png
2025-11-09 12:42:48,712 - INFO - root - 已保存图片 2/10：./export\images_An Effective UNet Using Feature Interaction and Fusion for Organ\figure_2_page19.jpeg
2025-11-09 12:42:48,812 - INFO - root - 已保存图片 3/10：./export\images_An Effective UNet Using Feature Interaction and Fusion for Organ\figure_3_page19.jpeg
2025-11-09 12:42:48,931 - INFO - root - 已保存图片 4/10：./export\images_An Effective UNet Using Feature Interaction and Fusion for Organ\figure_4_page19.jpeg
2025-11-09 12:42:49,105 - INFO - root - 已保存图片 5/10：./export\images_An Effective UNet Using Feature Interaction and Fusion for Organ\figure_5_page19.jpeg
2025-11-09 12:42:49,209 - INFO - root - 已保存图片 6/10：./export\images_An Effective UNet Using Feature Interaction and Fusion for Organ\figure_6_page19.jpeg
2025-11-09 12:42:49,478 - INFO - root - 已保存图片 7/10：./export\images_An Effective UNet Using Feature Interaction and Fusion for Organ\figure_7_page19.jpeg
2025-11-09 12:42:49,706 - INFO - root - 已保存图片 8/10：./export\images_An Effective UNet Using Feature Interaction and Fusion for Organ\figure_8_page19.jpeg
2025-11-09 12:42:49,794 - INFO - root - 已保存图片 9/10：./export\images_An Effective UNet Using Feature Interaction and Fusion for Organ\figure_9_page19.jpeg
2025-11-09 12:42:49,961 - INFO - root - 已保存图片 10/10：./export\images_An Effective UNet Using Feature Interaction and Fusion for Organ\figure_10_page19.jpeg
2025-11-09 12:42:49,966 - INFO - root - 成功添加图片 1：./export\images_An Effective UNet Using Feature Interaction and Fusion for Organ\figure_1_page14.png
2025-11-09 12:42:49,967 - INFO - root - 成功添加图片 2：./export\images_An Effective UNet Using Feature Interaction and Fusion for Organ\figure_2_page19.jpeg
2025-11-09 12:42:49,969 - INFO - root - 成功添加图片 3：./export\images_An Effective UNet Using Feature Interaction and Fusion for Organ\figure_3_page19.jpeg
2025-11-09 12:42:49,977 - INFO - root - 成功添加图片 4：./export\images_An Effective UNet Using Feature Interaction and Fusion for Organ\figure_4_page19.jpeg
2025-11-09 12:42:49,979 - INFO - root - 成功添加图片 5：./export\images_An Effective UNet Using Feature Interaction and Fusion for Organ\figure_5_page19.jpeg
2025-11-09 12:42:49,982 - INFO - root - 成功添加图片 6：./export\images_An Effective UNet Using Feature Interaction and Fusion for Organ\figure_6_page19.jpeg
2025-11-09 12:42:49,985 - INFO - root - 成功添加图片 7：./export\images_An Effective UNet Using Feature Interaction and Fusion for Organ\figure_7_page19.jpeg
2025-11-09 12:42:49,993 - INFO - root - 成功添加图片 8：./export\images_An Effective UNet Using Feature Interaction and Fusion for Organ\figure_8_page19.jpeg
2025-11-09 12:42:49,996 - INFO - root - 成功添加图片 9：./export\images_An Effective UNet Using Feature Interaction and Fusion for Organ\figure_9_page19.jpeg
2025-11-09 12:42:50,011 - INFO - root - 成功添加图片 10：./export\images_An Effective UNet Using Feature Interaction and Fusion for Organ\figure_10_page19.jpeg
2025-11-09 12:42:50,030 - INFO - root - 论文《An Effective UNet Using Feature Interaction and Fusion for Organ》的分析已保存到 ./export\An Effective UNet Using Feature Interaction and Fusion for Organ.md
2025-11-09 12:42:50,076 - INFO - root - 正在总结论文 4/24: Automated and Scalable SEM Image Analysis of Perovskite Solar Cell
2025-11-09 12:42:50,095 - INFO - root - 正在提取论文图片...
2025-11-09 12:43:28,803 - INFO - root - 已保存图片 1/10：./export\images_Automated and Scalable SEM Image Analysis of Perovskite Solar Cell\figure_1_page8.jpeg
2025-11-09 12:43:29,124 - INFO - root - 已保存图片 2/10：./export\images_Automated and Scalable SEM Image Analysis of Perovskite Solar Cell\figure_2_page5.jpeg
2025-11-09 12:43:29,434 - INFO - root - 已保存图片 3/10：./export\images_Automated and Scalable SEM Image Analysis of Perovskite Solar Cell\figure_3_page9.jpeg
2025-11-09 12:43:29,639 - INFO - root - 已保存图片 4/10：./export\images_Automated and Scalable SEM Image Analysis of Perovskite Solar Cell\figure_4_page9.jpeg
2025-11-09 12:43:29,842 - INFO - root - 已保存图片 5/10：./export\images_Automated and Scalable SEM Image Analysis of Perovskite Solar Cell\figure_5_page9.jpeg
2025-11-09 12:43:30,072 - INFO - root - 已保存图片 6/10：./export\images_Automated and Scalable SEM Image Analysis of Perovskite Solar Cell\figure_6_page9.jpeg
2025-11-09 12:43:30,284 - INFO - root - 已保存图片 7/10：./export\images_Automated and Scalable SEM Image Analysis of Perovskite Solar Cell\figure_7_page9.jpeg
2025-11-09 12:43:30,485 - INFO - root - 已保存图片 8/10：./export\images_Automated and Scalable SEM Image Analysis of Perovskite Solar Cell\figure_8_page9.jpeg
2025-11-09 12:43:30,688 - INFO - root - 已保存图片 9/10：./export\images_Automated and Scalable SEM Image Analysis of Perovskite Solar Cell\figure_9_page9.jpeg
2025-11-09 12:43:30,896 - INFO - root - 已保存图片 10/10：./export\images_Automated and Scalable SEM Image Analysis of Perovskite Solar Cell\figure_10_page9.jpeg
2025-11-09 12:43:30,919 - INFO - root - 成功添加图片 1：./export\images_Automated and Scalable SEM Image Analysis of Perovskite Solar Cell\figure_1_page8.jpeg
2025-11-09 12:43:30,920 - INFO - root - 成功添加图片 2：./export\images_Automated and Scalable SEM Image Analysis of Perovskite Solar Cell\figure_2_page5.jpeg
2025-11-09 12:43:30,921 - INFO - root - 成功添加图片 3：./export\images_Automated and Scalable SEM Image Analysis of Perovskite Solar Cell\figure_3_page9.jpeg
2025-11-09 12:43:30,921 - INFO - root - 成功添加图片 4：./export\images_Automated and Scalable SEM Image Analysis of Perovskite Solar Cell\figure_4_page9.jpeg
2025-11-09 12:43:30,922 - INFO - root - 成功添加图片 5：./export\images_Automated and Scalable SEM Image Analysis of Perovskite Solar Cell\figure_5_page9.jpeg
2025-11-09 12:43:30,922 - INFO - root - 成功添加图片 6：./export\images_Automated and Scalable SEM Image Analysis of Perovskite Solar Cell\figure_6_page9.jpeg
2025-11-09 12:43:30,922 - INFO - root - 成功添加图片 7：./export\images_Automated and Scalable SEM Image Analysis of Perovskite Solar Cell\figure_7_page9.jpeg
2025-11-09 12:43:30,923 - INFO - root - 成功添加图片 8：./export\images_Automated and Scalable SEM Image Analysis of Perovskite Solar Cell\figure_8_page9.jpeg
2025-11-09 12:43:30,923 - INFO - root - 成功添加图片 9：./export\images_Automated and Scalable SEM Image Analysis of Perovskite Solar Cell\figure_9_page9.jpeg
2025-11-09 12:43:30,925 - INFO - root - 成功添加图片 10：./export\images_Automated and Scalable SEM Image Analysis of Perovskite Solar Cell\figure_10_page9.jpeg
2025-11-09 12:43:30,932 - INFO - root - 论文《Automated and Scalable SEM Image Analysis of Perovskite Solar Cell》的分析已保存到 ./export\Automated and Scalable SEM Image Analysis of Perovskite Solar Cell.md
2025-11-09 12:43:30,948 - INFO - root - 正在总结论文 5/24: Automatic Verification of
2025-11-09 12:43:30,950 - INFO - root - 正在提取论文图片...
2025-11-09 12:43:30,989 - INFO - root - 论文《Automatic Verification of》的分析已保存到 ./export\Automatic Verification of.md
2025-11-09 12:43:31,005 - INFO - root - 正在总结论文 6/24: 
2025-11-09 12:43:31,014 - INFO - root - 正在提取论文图片...
2025-11-09 12:43:31,371 - INFO - root - 已保存图片 1/10：./export\images_untitled\figure_1_page25.png
2025-11-09 12:43:31,371 - INFO - root - 成功添加图片 1：./export\images_untitled\figure_1_page25.png
2025-11-09 12:43:31,386 - INFO - root - 论文《》的分析已保存到 ./export\traffic flow prediction.md
2025-11-09 12:43:31,402 - INFO - root - 正在总结论文 7/24: Computationally Efficient Neural Receivers via
2025-11-09 12:43:31,409 - INFO - root - 正在提取论文图片...
2025-11-09 12:43:32,644 - INFO - root - 已保存图片 1/10：./export\images_Computationally Efficient Neural Receivers via\figure_1_page5.png
2025-11-09 12:43:32,650 - INFO - root - 成功添加图片 1：./export\images_Computationally Efficient Neural Receivers via\figure_1_page5.png
2025-11-09 12:43:32,655 - INFO - root - 论文《Computationally Efficient Neural Receivers via》的分析已保存到 ./export\Computationally Efficient Neural Receivers via.md
2025-11-09 12:43:32,660 - INFO - root - 正在总结论文 8/24: DGEMM without FP64 Arithmetic – Using FP64 Emulation and
2025-11-09 12:43:32,666 - INFO - root - 正在提取论文图片...
2025-11-09 12:45:56,822 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-09 12:45:56,824 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-09 12:45:56,826 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-09 12:45:57,544 - INFO - root - GeminiClient: trying model gemini-2.5-flash
2025-11-09 12:45:58,503 - INFO - root - GeminiClient: trying model gemini-2.5-pro
2025-11-09 12:45:58,863 - WARNING - root - GeminiClient: no usable model found
2025-11-09 12:45:58,863 - WARNING - root - LLMClientManager: Gemini client initialization failed
2025-11-09 12:45:58,864 - WARNING - root - DeepSeekClient: API key not provided. LLM disabled.
2025-11-09 12:45:58,864 - WARNING - root - LLMClientManager: DeepSeek client initialization failed
2025-11-09 12:45:58,864 - WARNING - root - KimiClient: API key not provided. LLM disabled.
2025-11-09 12:45:58,865 - WARNING - root - LLMClientManager: Kimi client initialization failed
2025-11-09 12:45:58,865 - WARNING - root - QwenClient: API key not provided. LLM disabled.
2025-11-09 12:45:58,866 - WARNING - root - LLMClientManager: Qwen client initialization failed
2025-11-09 12:45:58,866 - WARNING - root - DoubaoClient: API key not provided. LLM disabled.
2025-11-09 12:45:58,866 - WARNING - root - LLMClientManager: Doubao client initialization failed
2025-11-09 12:45:58,867 - WARNING - root - LLMClientManager: no LLM client available
2025-11-09 12:45:58,867 - INFO - root - LLM 未初始化或不可用，后续生成将返回备用消息
2025-11-09 12:45:58,867 - INFO - root - === 运行配置 ===
2025-11-09 12:45:58,867 - INFO - root - 处理模式: 本地PDF文件
2025-11-09 12:45:58,868 - INFO - root - PDF目录: ./myPapers
2025-11-09 12:45:58,869 - INFO - root - 最大处理数量: 2
2025-11-09 12:45:58,869 - INFO - root - 保存图片: 是
2025-11-09 12:45:58,869 - INFO - root - 输出语言: 中文
2025-11-09 12:45:58,870 - INFO - root - 强制重新处理: 否
2025-11-09 12:45:58,870 - INFO - root - ====================
2025-11-09 12:45:58,870 - INFO - root - 从本地目录读取PDF文件：./myPapers
2025-11-09 12:46:00,328 - INFO - root - 成功加载PDF文件：A Compute&Memory Efficient Model-Driven Neural 5G Receiver for Edge AI-assisted.pdf
2025-11-09 12:46:02,886 - INFO - root - 成功加载PDF文件：AMLA_ MUL by ADD in FlashAttention Rescaling.pdf
2025-11-09 12:46:02,886 - INFO - root - 已达到最大处理数量限制 (2)，停止加载更多PDF文件
2025-11-09 12:46:02,887 - INFO - root - 跳过已处理论文 A Compute&Memory Efficient Model-Driven Neural：./myPapers\A Compute&Memory Efficient Model-Driven Neural 5G Receiver for Edge AI-assisted.pdf
2025-11-09 12:46:02,889 - INFO - root - 跳过已处理论文 AMLA: MUL by ADD in FlashAttention Rescaling：./myPapers\AMLA_ MUL by ADD in FlashAttention Rescaling.pdf
2025-11-09 12:46:02,890 - INFO - root - summary time: 6.07 seconds
2025-11-09 12:46:38,191 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-09 12:46:38,192 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-09 12:46:38,194 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-09 12:46:38,778 - INFO - root - GeminiClient: trying model gemini-2.5-flash
2025-11-09 12:46:39,436 - INFO - root - GeminiClient: trying model gemini-2.5-pro
2025-11-09 12:46:39,558 - WARNING - root - GeminiClient: no usable model found
2025-11-09 12:46:39,560 - WARNING - root - LLMClientManager: Gemini client initialization failed
2025-11-09 12:46:39,560 - WARNING - root - DeepSeekClient: API key not provided. LLM disabled.
2025-11-09 12:46:39,561 - WARNING - root - LLMClientManager: DeepSeek client initialization failed
2025-11-09 12:46:39,562 - WARNING - root - KimiClient: API key not provided. LLM disabled.
2025-11-09 12:46:39,562 - WARNING - root - LLMClientManager: Kimi client initialization failed
2025-11-09 12:46:39,563 - WARNING - root - QwenClient: API key not provided. LLM disabled.
2025-11-09 12:46:39,563 - WARNING - root - LLMClientManager: Qwen client initialization failed
2025-11-09 12:46:40,213 - ERROR - root - DoubaoClient: API test failed with status 404
2025-11-09 12:46:40,215 - WARNING - root - LLMClientManager: Doubao client initialization failed
2025-11-09 12:46:40,215 - WARNING - root - LLMClientManager: no LLM client available
2025-11-09 12:46:40,215 - WARNING - root - LLMClientManager: client Doubao not available
2025-11-09 12:46:40,215 - WARNING - root - 无法切换到指定的客户端 Doubao，将使用默认客户端
2025-11-09 12:46:40,217 - INFO - root - 可用客户端: []
2025-11-09 12:46:40,217 - INFO - root - LLM 未初始化或不可用，后续生成将返回备用消息
2025-11-09 12:46:40,218 - INFO - root - === 运行配置 ===
2025-11-09 12:46:40,218 - INFO - root - 处理模式: 本地PDF文件
2025-11-09 12:46:40,221 - INFO - root - PDF目录: ./myPapers
2025-11-09 12:46:40,222 - INFO - root - 最大处理数量: 2
2025-11-09 12:46:40,223 - INFO - root - 保存图片: 是
2025-11-09 12:46:40,224 - INFO - root - 输出语言: 中文
2025-11-09 12:46:40,224 - INFO - root - 强制重新处理: 否
2025-11-09 12:46:40,224 - INFO - root - ====================
2025-11-09 12:46:40,226 - INFO - root - 从本地目录读取PDF文件：./myPapers
2025-11-09 12:46:41,906 - INFO - root - 成功加载PDF文件：A Compute&Memory Efficient Model-Driven Neural 5G Receiver for Edge AI-assisted.pdf
2025-11-09 12:46:45,400 - INFO - root - 成功加载PDF文件：AMLA_ MUL by ADD in FlashAttention Rescaling.pdf
2025-11-09 12:46:45,400 - INFO - root - 已达到最大处理数量限制 (2)，停止加载更多PDF文件
2025-11-09 12:46:45,401 - INFO - root - 跳过已处理论文 A Compute&Memory Efficient Model-Driven Neural：./myPapers\A Compute&Memory Efficient Model-Driven Neural 5G Receiver for Edge AI-assisted.pdf
2025-11-09 12:46:45,402 - INFO - root - 跳过已处理论文 AMLA: MUL by ADD in FlashAttention Rescaling：./myPapers\AMLA_ MUL by ADD in FlashAttention Rescaling.pdf
2025-11-09 12:46:45,402 - INFO - root - summary time: 7.21 seconds
2025-11-09 12:49:23,218 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-09 12:49:23,219 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-09 12:49:23,221 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-09 12:49:23,805 - INFO - root - GeminiClient: trying model gemini-2.5-flash
2025-11-09 12:49:24,666 - INFO - root - GeminiClient: trying model gemini-2.5-pro
2025-11-09 12:49:25,022 - WARNING - root - GeminiClient: no usable model found
2025-11-09 12:49:25,022 - WARNING - root - LLMClientManager: Gemini client initialization failed
2025-11-09 12:49:25,022 - WARNING - root - DeepSeekClient: API key not provided. LLM disabled.
2025-11-09 12:49:25,022 - WARNING - root - LLMClientManager: DeepSeek client initialization failed
2025-11-09 12:49:25,023 - WARNING - root - KimiClient: API key not provided. LLM disabled.
2025-11-09 12:49:25,023 - WARNING - root - LLMClientManager: Kimi client initialization failed
2025-11-09 12:49:25,023 - WARNING - root - QwenClient: API key not provided. LLM disabled.
2025-11-09 12:49:25,024 - WARNING - root - LLMClientManager: Qwen client initialization failed
2025-11-09 12:49:25,491 - ERROR - root - DoubaoClient: API test failed with status 404
2025-11-09 12:49:25,493 - WARNING - root - LLMClientManager: Doubao client initialization failed
2025-11-09 12:49:25,493 - WARNING - root - LLMClientManager: no LLM client available
2025-11-09 12:49:25,494 - WARNING - root - LLMClientManager: client Doubao not available
2025-11-09 12:49:25,494 - WARNING - root - 无法切换到指定的客户端 Doubao，将使用默认客户端
2025-11-09 12:49:25,494 - INFO - root - 可用客户端: []
2025-11-09 12:49:25,495 - INFO - root - LLM 未初始化或不可用，后续生成将返回备用消息
2025-11-09 12:49:25,495 - INFO - root - === 运行配置 ===
2025-11-09 12:49:25,495 - INFO - root - 处理模式: 本地PDF文件
2025-11-09 12:49:25,495 - INFO - root - PDF目录: ./myPapers
2025-11-09 12:49:25,495 - INFO - root - 最大处理数量: 2
2025-11-09 12:49:25,496 - INFO - root - 保存图片: 是
2025-11-09 12:49:25,497 - INFO - root - 输出语言: 中文
2025-11-09 12:49:25,497 - INFO - root - 强制重新处理: 否
2025-11-09 12:49:25,497 - INFO - root - ====================
2025-11-09 12:49:25,497 - INFO - root - 从本地目录读取PDF文件：./myPapers
2025-11-09 12:49:26,935 - INFO - root - 成功加载PDF文件：A Compute&Memory Efficient Model-Driven Neural 5G Receiver for Edge AI-assisted.pdf
2025-11-09 12:49:28,995 - INFO - root - 成功加载PDF文件：AMLA_ MUL by ADD in FlashAttention Rescaling.pdf
2025-11-09 12:49:28,996 - INFO - root - 已达到最大处理数量限制 (2)，停止加载更多PDF文件
2025-11-09 12:49:28,997 - INFO - root - 跳过已处理论文 A Compute&Memory Efficient Model-Driven Neural：./myPapers\A Compute&Memory Efficient Model-Driven Neural 5G Receiver for Edge AI-assisted.pdf
2025-11-09 12:49:28,997 - INFO - root - 跳过已处理论文 AMLA: MUL by ADD in FlashAttention Rescaling：./myPapers\AMLA_ MUL by ADD in FlashAttention Rescaling.pdf
2025-11-09 12:49:28,999 - INFO - root - summary time: 5.78 seconds
2025-11-09 12:58:12,607 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-09 12:58:12,611 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-09 12:58:12,613 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-09 12:58:13,285 - INFO - root - GeminiClient: trying model gemini-2.5-flash
2025-11-09 12:58:14,129 - INFO - root - GeminiClient: trying model gemini-2.5-pro
2025-11-09 12:58:14,477 - WARNING - root - GeminiClient: no usable model found
2025-11-09 12:58:14,478 - WARNING - root - LLMClientManager: Gemini client initialization failed
2025-11-09 12:58:14,478 - WARNING - root - DeepSeekClient: API key not provided. LLM disabled.
2025-11-09 12:58:14,478 - WARNING - root - LLMClientManager: DeepSeek client initialization failed
2025-11-09 12:58:14,479 - WARNING - root - KimiClient: API key not provided. LLM disabled.
2025-11-09 12:58:14,479 - WARNING - root - LLMClientManager: Kimi client initialization failed
2025-11-09 12:58:14,480 - WARNING - root - QwenClient: API key not provided. LLM disabled.
2025-11-09 12:58:14,480 - WARNING - root - LLMClientManager: Qwen client initialization failed
2025-11-09 12:58:15,026 - ERROR - root - DoubaoClient: API test failed with status 404
2025-11-09 12:58:15,030 - WARNING - root - LLMClientManager: Doubao client initialization failed
2025-11-09 12:58:15,031 - WARNING - root - LLMClientManager: no LLM client available
2025-11-09 12:58:15,031 - WARNING - root - LLMClientManager: client Doubao not available
2025-11-09 12:58:15,031 - WARNING - root - 无法切换到指定的客户端 Doubao，将使用默认客户端
2025-11-09 12:58:15,033 - INFO - root - 可用客户端: []
2025-11-09 12:58:15,033 - INFO - root - LLM 未初始化或不可用，后续生成将返回备用消息
2025-11-09 12:58:15,034 - INFO - root - === 运行配置 ===
2025-11-09 12:58:15,034 - INFO - root - 处理模式: 本地PDF文件
2025-11-09 12:58:15,034 - INFO - root - PDF目录: ./myPapers
2025-11-09 12:58:15,035 - INFO - root - 最大处理数量: 2
2025-11-09 12:58:15,035 - INFO - root - 保存图片: 是
2025-11-09 12:58:15,035 - INFO - root - 输出语言: 中文
2025-11-09 12:58:15,036 - INFO - root - 强制重新处理: 否
2025-11-09 12:58:15,036 - INFO - root - ====================
2025-11-09 12:58:15,036 - INFO - root - 从本地目录读取PDF文件：./myPapers
2025-11-09 12:58:16,829 - INFO - root - 成功加载PDF文件：A Compute&Memory Efficient Model-Driven Neural 5G Receiver for Edge AI-assisted.pdf
2025-11-09 12:58:19,740 - INFO - root - 成功加载PDF文件：AMLA_ MUL by ADD in FlashAttention Rescaling.pdf
2025-11-09 12:58:19,741 - INFO - root - 已达到最大处理数量限制 (2)，停止加载更多PDF文件
2025-11-09 12:58:19,747 - INFO - root - 跳过已处理论文 A Compute&Memory Efficient Model-Driven Neural：./myPapers\A Compute&Memory Efficient Model-Driven Neural 5G Receiver for Edge AI-assisted.pdf
2025-11-09 12:58:19,747 - INFO - root - 跳过已处理论文 AMLA: MUL by ADD in FlashAttention Rescaling：./myPapers\AMLA_ MUL by ADD in FlashAttention Rescaling.pdf
2025-11-09 12:58:19,748 - INFO - root - summary time: 7.14 seconds
2025-11-09 13:05:28,941 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-09 13:05:28,942 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-09 13:05:28,944 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-09 13:05:28,970 - INFO - root - LLMClientManager: 指定使用客户端: Doubao
2025-11-09 13:05:29,528 - ERROR - root - DoubaoClient: API test failed with status 404
2025-11-09 13:05:29,529 - ERROR - root - LLMClientManager: 指定的客户端 Doubao 初始化失败
2025-11-09 13:05:29,529 - WARNING - root - LLMClientManager: 指定的客户端 Doubao 不可用，将尝试其他客户端
2025-11-09 13:05:30,291 - INFO - root - GeminiClient: trying model gemini-2.5-flash
2025-11-09 13:05:31,203 - INFO - root - GeminiClient: trying model gemini-2.5-pro
2025-11-09 13:05:31,564 - WARNING - root - GeminiClient: no usable model found
2025-11-09 13:05:31,565 - WARNING - root - LLMClientManager: Gemini client initialization failed
2025-11-09 13:05:31,565 - WARNING - root - DeepSeekClient: API key not provided. LLM disabled.
2025-11-09 13:05:31,565 - WARNING - root - LLMClientManager: DeepSeek client initialization failed
2025-11-09 13:05:31,566 - WARNING - root - KimiClient: API key not provided. LLM disabled.
2025-11-09 13:05:31,566 - WARNING - root - LLMClientManager: Kimi client initialization failed
2025-11-09 13:05:31,566 - WARNING - root - QwenClient: API key not provided. LLM disabled.
2025-11-09 13:05:31,566 - WARNING - root - LLMClientManager: Qwen client initialization failed
2025-11-09 13:05:31,567 - WARNING - root - LLMClientManager: no LLM client available
2025-11-09 13:05:31,567 - WARNING - root - LLMClientManager: client Doubao not available
2025-11-09 13:05:31,568 - WARNING - root - 无法切换到指定的客户端 Doubao，将使用默认客户端
2025-11-09 13:05:31,568 - INFO - root - 可用客户端: []
2025-11-09 13:05:31,568 - INFO - root - LLM 未初始化或不可用，后续生成将返回备用消息
2025-11-09 13:05:31,568 - INFO - root - === 运行配置 ===
2025-11-09 13:05:31,569 - INFO - root - 处理模式: 本地PDF文件
2025-11-09 13:05:31,569 - INFO - root - PDF目录: ./myPapers
2025-11-09 13:05:31,569 - INFO - root - 最大处理数量: 2
2025-11-09 13:05:31,569 - INFO - root - 保存图片: 是
2025-11-09 13:05:31,570 - INFO - root - 输出语言: 中文
2025-11-09 13:05:31,570 - INFO - root - 强制重新处理: 否
2025-11-09 13:05:31,571 - INFO - root - ====================
2025-11-09 13:05:31,572 - INFO - root - 从本地目录读取PDF文件：./myPapers
2025-11-09 13:05:33,240 - INFO - root - 成功加载PDF文件：A Compute&Memory Efficient Model-Driven Neural 5G Receiver for Edge AI-assisted.pdf
2025-11-09 13:05:35,435 - INFO - root - 成功加载PDF文件：AMLA_ MUL by ADD in FlashAttention Rescaling.pdf
2025-11-09 13:05:35,435 - INFO - root - 已达到最大处理数量限制 (2)，停止加载更多PDF文件
2025-11-09 13:05:35,436 - INFO - root - 跳过已处理论文 A Compute&Memory Efficient Model-Driven Neural：./myPapers\A Compute&Memory Efficient Model-Driven Neural 5G Receiver for Edge AI-assisted.pdf
2025-11-09 13:05:35,437 - INFO - root - 跳过已处理论文 AMLA: MUL by ADD in FlashAttention Rescaling：./myPapers\AMLA_ MUL by ADD in FlashAttention Rescaling.pdf
2025-11-09 13:05:35,438 - INFO - root - summary time: 6.50 seconds
2025-11-09 13:09:04,133 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-09 13:09:04,152 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-09 13:09:04,154 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-09 13:09:04,321 - INFO - root - LLMClientManager: 指定使用客户端: Doubao
2025-11-09 13:09:06,618 - ERROR - root - DoubaoClient: API test failed with status 404
2025-11-09 13:09:06,631 - ERROR - root - LLMClientManager: 指定的客户端 Doubao 初始化失败
2025-11-09 13:09:06,644 - WARNING - root - LLMClientManager: 指定的客户端 Doubao 不可用，将尝试其他客户端
2025-11-09 13:09:08,688 - INFO - root - GeminiClient: trying model gemini-2.5-flash
2025-11-09 13:09:09,712 - INFO - root - GeminiClient: trying model gemini-2.5-pro
2025-11-09 13:09:10,067 - WARNING - root - GeminiClient: no usable model found
2025-11-09 13:09:10,075 - WARNING - root - LLMClientManager: Gemini client initialization failed
2025-11-09 13:09:10,076 - WARNING - root - DeepSeekClient: API key not provided. LLM disabled.
2025-11-09 13:09:10,077 - WARNING - root - LLMClientManager: DeepSeek client initialization failed
2025-11-09 13:09:10,079 - WARNING - root - KimiClient: API key not provided. LLM disabled.
2025-11-09 13:09:10,080 - WARNING - root - LLMClientManager: Kimi client initialization failed
2025-11-09 13:09:10,080 - WARNING - root - QwenClient: API key not provided. LLM disabled.
2025-11-09 13:09:10,081 - WARNING - root - LLMClientManager: Qwen client initialization failed
2025-11-09 13:09:10,082 - WARNING - root - LLMClientManager: no LLM client available
2025-11-09 13:09:10,082 - WARNING - root - LLMClientManager: client Doubao not available
2025-11-09 13:09:10,098 - WARNING - root - 无法切换到指定的客户端 Doubao，将使用默认客户端
2025-11-09 13:09:10,101 - INFO - root - 可用客户端: []
2025-11-09 13:09:10,107 - INFO - root - LLM 未初始化或不可用，后续生成将返回备用消息
2025-11-09 13:09:10,117 - INFO - root - === 运行配置 ===
2025-11-09 13:09:10,123 - INFO - root - 处理模式: 本地PDF文件
2025-11-09 13:09:10,126 - INFO - root - PDF目录: ./myPapers
2025-11-09 13:09:10,135 - INFO - root - 最大处理数量: 2
2025-11-09 13:09:10,143 - INFO - root - 保存图片: 是
2025-11-09 13:09:10,146 - INFO - root - 输出语言: 中文
2025-11-09 13:09:10,149 - INFO - root - 强制重新处理: 否
2025-11-09 13:09:10,151 - INFO - root - ====================
2025-11-09 13:09:10,158 - INFO - root - 从本地目录读取PDF文件：./myPapers
2025-11-09 13:09:15,684 - INFO - root - 成功加载PDF文件：A Compute&Memory Efficient Model-Driven Neural 5G Receiver for Edge AI-assisted.pdf
2025-11-09 13:09:19,567 - INFO - root - 成功加载PDF文件：AMLA_ MUL by ADD in FlashAttention Rescaling.pdf
2025-11-09 13:09:19,568 - INFO - root - 已达到最大处理数量限制 (2)，停止加载更多PDF文件
2025-11-09 13:09:19,572 - INFO - root - 跳过已处理论文 A Compute&Memory Efficient Model-Driven Neural：./myPapers\A Compute&Memory Efficient Model-Driven Neural 5G Receiver for Edge AI-assisted.pdf
2025-11-09 13:09:19,573 - INFO - root - 跳过已处理论文 AMLA: MUL by ADD in FlashAttention Rescaling：./myPapers\AMLA_ MUL by ADD in FlashAttention Rescaling.pdf
2025-11-09 13:09:19,574 - INFO - root - summary time: 15.44 seconds
2025-11-09 13:14:46,332 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-09 13:14:46,334 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-09 13:14:46,337 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-09 13:14:49,446 - INFO - root - LLMClientManager: 指定使用客户端: Doubao
2025-11-09 13:14:49,446 - WARNING - root - DoubaoClient: API key not provided. LLM disabled.
2025-11-09 13:14:49,446 - ERROR - root - LLMClientManager: 指定的客户端 Doubao 初始化失败
2025-11-09 13:14:49,446 - WARNING - root - LLMClientManager: 指定的客户端 Doubao 不可用，将尝试其他客户端
2025-11-09 13:14:50,249 - INFO - root - GeminiClient: trying model gemini-2.5-flash
2025-11-09 13:14:51,097 - INFO - root - GeminiClient: trying model gemini-2.5-pro
2025-11-09 13:14:51,453 - WARNING - root - GeminiClient: no usable model found
2025-11-09 13:14:51,454 - WARNING - root - LLMClientManager: Gemini client initialization failed
2025-11-09 13:14:51,455 - WARNING - root - DeepSeekClient: API key not provided. LLM disabled.
2025-11-09 13:14:51,455 - WARNING - root - LLMClientManager: DeepSeek client initialization failed
2025-11-09 13:14:51,456 - WARNING - root - KimiClient: API key not provided. LLM disabled.
2025-11-09 13:14:51,456 - WARNING - root - LLMClientManager: Kimi client initialization failed
2025-11-09 13:14:51,456 - WARNING - root - QwenClient: API key not provided. LLM disabled.
2025-11-09 13:14:51,457 - WARNING - root - LLMClientManager: Qwen client initialization failed
2025-11-09 13:14:51,457 - WARNING - root - LLMClientManager: no LLM client available
2025-11-09 13:14:51,458 - WARNING - root - LLMClientManager: client Doubao not available
2025-11-09 13:14:51,458 - WARNING - root - 无法切换到指定的客户端 Doubao，将使用默认客户端
2025-11-09 13:14:51,458 - INFO - root - 可用客户端: []
2025-11-09 13:14:51,459 - INFO - root - LLM 未初始化或不可用，后续生成将返回备用消息
2025-11-09 13:14:51,459 - INFO - root - === 运行配置 ===
2025-11-09 13:14:51,460 - INFO - root - 处理模式: 本地PDF文件
2025-11-09 13:14:51,461 - INFO - root - PDF目录: ./myPapers
2025-11-09 13:14:51,461 - INFO - root - 最大处理数量: 2
2025-11-09 13:14:51,463 - INFO - root - 保存图片: 是
2025-11-09 13:14:51,463 - INFO - root - 输出语言: 中文
2025-11-09 13:14:51,464 - INFO - root - 强制重新处理: 否
2025-11-09 13:14:51,465 - INFO - root - ====================
2025-11-09 13:14:51,466 - INFO - root - 从本地目录读取PDF文件：./myPapers
2025-11-09 13:14:53,801 - INFO - root - 成功加载PDF文件：A Compute&Memory Efficient Model-Driven Neural 5G Receiver for Edge AI-assisted.pdf
2025-11-09 13:14:57,267 - INFO - root - 成功加载PDF文件：AMLA_ MUL by ADD in FlashAttention Rescaling.pdf
2025-11-09 13:14:57,268 - INFO - root - 已达到最大处理数量限制 (2)，停止加载更多PDF文件
2025-11-09 13:14:57,277 - INFO - root - 跳过已处理论文 A Compute&Memory Efficient Model-Driven Neural：./myPapers\A Compute&Memory Efficient Model-Driven Neural 5G Receiver for Edge AI-assisted.pdf
2025-11-09 13:14:57,279 - INFO - root - 跳过已处理论文 AMLA: MUL by ADD in FlashAttention Rescaling：./myPapers\AMLA_ MUL by ADD in FlashAttention Rescaling.pdf
2025-11-09 13:14:57,279 - INFO - root - summary time: 10.95 seconds
2025-11-09 13:15:29,541 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-09 13:15:29,543 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-09 13:15:29,543 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-09 13:15:30,631 - INFO - root - LLMClientManager: 指定使用客户端: Doubao
2025-11-09 13:15:30,636 - WARNING - root - DoubaoClient: API key not provided. LLM disabled.
2025-11-09 13:15:30,636 - ERROR - root - LLMClientManager: 指定的客户端 Doubao 初始化失败
2025-11-09 13:15:30,636 - WARNING - root - LLMClientManager: 指定的客户端 Doubao 不可用，将尝试其他客户端
2025-11-09 13:15:31,714 - INFO - root - GeminiClient: trying model gemini-2.5-flash
2025-11-09 13:15:32,394 - INFO - root - GeminiClient: trying model gemini-2.5-pro
2025-11-09 13:15:32,518 - WARNING - root - GeminiClient: no usable model found
2025-11-09 13:15:32,519 - WARNING - root - LLMClientManager: Gemini client initialization failed
2025-11-09 13:15:32,520 - WARNING - root - DeepSeekClient: API key not provided. LLM disabled.
2025-11-09 13:15:32,521 - WARNING - root - LLMClientManager: DeepSeek client initialization failed
2025-11-09 13:15:32,522 - WARNING - root - KimiClient: API key not provided. LLM disabled.
2025-11-09 13:15:32,522 - WARNING - root - LLMClientManager: Kimi client initialization failed
2025-11-09 13:15:32,523 - WARNING - root - QwenClient: API key not provided. LLM disabled.
2025-11-09 13:15:32,523 - WARNING - root - LLMClientManager: Qwen client initialization failed
2025-11-09 13:15:32,523 - WARNING - root - LLMClientManager: no LLM client available
2025-11-09 13:15:32,524 - WARNING - root - LLMClientManager: client Doubao not available
2025-11-09 13:15:32,524 - WARNING - root - 无法切换到指定的客户端 Doubao，将使用默认客户端
2025-11-09 13:15:32,524 - INFO - root - 可用客户端: []
2025-11-09 13:15:32,525 - INFO - root - LLM 未初始化或不可用，后续生成将返回备用消息
2025-11-09 13:15:32,525 - INFO - root - === 运行配置 ===
2025-11-09 13:15:32,525 - INFO - root - 处理模式: 本地PDF文件
2025-11-09 13:15:32,526 - INFO - root - PDF目录: ./myPapers
2025-11-09 13:15:32,526 - INFO - root - 最大处理数量: 2
2025-11-09 13:15:32,527 - INFO - root - 保存图片: 是
2025-11-09 13:15:32,527 - INFO - root - 输出语言: 中文
2025-11-09 13:15:32,528 - INFO - root - 强制重新处理: 否
2025-11-09 13:15:32,528 - INFO - root - ====================
2025-11-09 13:15:32,529 - INFO - root - 从本地目录读取PDF文件：./myPapers
2025-11-09 13:15:34,692 - INFO - root - 成功加载PDF文件：A Compute&Memory Efficient Model-Driven Neural 5G Receiver for Edge AI-assisted.pdf
2025-11-09 13:15:37,219 - INFO - root - 成功加载PDF文件：AMLA_ MUL by ADD in FlashAttention Rescaling.pdf
2025-11-09 13:15:37,219 - INFO - root - 已达到最大处理数量限制 (2)，停止加载更多PDF文件
2025-11-09 13:15:37,220 - INFO - root - 跳过已处理论文 A Compute&Memory Efficient Model-Driven Neural：./myPapers\A Compute&Memory Efficient Model-Driven Neural 5G Receiver for Edge AI-assisted.pdf
2025-11-09 13:15:37,220 - INFO - root - 跳过已处理论文 AMLA: MUL by ADD in FlashAttention Rescaling：./myPapers\AMLA_ MUL by ADD in FlashAttention Rescaling.pdf
2025-11-09 13:15:37,222 - INFO - root - summary time: 7.68 seconds
2025-11-09 13:17:34,011 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-09 13:17:34,012 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-09 13:17:34,014 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-09 13:17:35,164 - INFO - root - LLMClientManager: 指定使用客户端: Doubao
2025-11-09 13:17:35,164 - ERROR - root - DoubaoClient: error reading config: RawConfigParser.get() takes 3 positional arguments but 4 were given
2025-11-09 13:17:35,165 - WARNING - root - DoubaoClient: API key not provided or using placeholder. LLM disabled.
2025-11-09 13:17:35,165 - ERROR - root - LLMClientManager: 指定的客户端 Doubao 初始化失败
2025-11-09 13:17:35,165 - WARNING - root - LLMClientManager: 指定的客户端 Doubao 不可用，将尝试其他客户端
2025-11-09 13:17:35,805 - INFO - root - GeminiClient: trying model gemini-2.5-flash
2025-11-09 13:17:36,828 - INFO - root - GeminiClient: trying model gemini-2.5-pro
2025-11-09 13:17:37,191 - WARNING - root - GeminiClient: no usable model found
2025-11-09 13:17:37,191 - WARNING - root - LLMClientManager: Gemini client initialization failed
2025-11-09 13:17:37,192 - WARNING - root - DeepSeekClient: API key not provided. LLM disabled.
2025-11-09 13:17:37,192 - WARNING - root - LLMClientManager: DeepSeek client initialization failed
2025-11-09 13:17:37,193 - WARNING - root - KimiClient: API key not provided. LLM disabled.
2025-11-09 13:17:37,193 - WARNING - root - LLMClientManager: Kimi client initialization failed
2025-11-09 13:17:37,193 - WARNING - root - QwenClient: API key not provided. LLM disabled.
2025-11-09 13:17:37,194 - WARNING - root - LLMClientManager: Qwen client initialization failed
2025-11-09 13:17:37,194 - WARNING - root - LLMClientManager: no LLM client available
2025-11-09 13:17:37,194 - WARNING - root - LLMClientManager: client Doubao not available
2025-11-09 13:17:37,195 - WARNING - root - 无法切换到指定的客户端 Doubao，将使用默认客户端
2025-11-09 13:17:37,195 - INFO - root - 可用客户端: []
2025-11-09 13:17:37,196 - INFO - root - LLM 未初始化或不可用，后续生成将返回备用消息
2025-11-09 13:17:37,196 - INFO - root - === 运行配置 ===
2025-11-09 13:17:37,203 - INFO - root - 处理模式: 本地PDF文件
2025-11-09 13:17:37,213 - INFO - root - PDF目录: ./myPapers
2025-11-09 13:17:37,219 - INFO - root - 最大处理数量: 2
2025-11-09 13:17:37,220 - INFO - root - 保存图片: 是
2025-11-09 13:17:37,224 - INFO - root - 输出语言: 中文
2025-11-09 13:17:37,225 - INFO - root - 强制重新处理: 否
2025-11-09 13:17:37,228 - INFO - root - ====================
2025-11-09 13:17:37,230 - INFO - root - 从本地目录读取PDF文件：./myPapers
2025-11-09 13:17:39,662 - INFO - root - 成功加载PDF文件：A Compute&Memory Efficient Model-Driven Neural 5G Receiver for Edge AI-assisted.pdf
2025-11-09 13:17:42,426 - INFO - root - 成功加载PDF文件：AMLA_ MUL by ADD in FlashAttention Rescaling.pdf
2025-11-09 13:17:42,426 - INFO - root - 已达到最大处理数量限制 (2)，停止加载更多PDF文件
2025-11-09 13:17:42,426 - INFO - root - 跳过已处理论文 A Compute&Memory Efficient Model-Driven Neural：./myPapers\A Compute&Memory Efficient Model-Driven Neural 5G Receiver for Edge AI-assisted.pdf
2025-11-09 13:17:42,426 - INFO - root - 跳过已处理论文 AMLA: MUL by ADD in FlashAttention Rescaling：./myPapers\AMLA_ MUL by ADD in FlashAttention Rescaling.pdf
2025-11-09 13:17:42,426 - INFO - root - summary time: 8.42 seconds
2025-11-09 13:19:00,129 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-09 13:19:00,131 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-09 13:19:00,135 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-09 13:19:01,214 - INFO - root - LLMClientManager: 指定使用客户端: Doubao
2025-11-09 13:19:01,214 - INFO - root - DoubaoClient: API key found: 9f9e270e-b...
2025-11-09 13:19:07,220 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 13:19:07,240 - INFO - root - DoubaoClient: initialized successfully with model doubao-seed-1-6-lite-251015
2025-11-09 13:19:07,241 - INFO - root - LLMClientManager: Doubao 客户端初始化成功
2025-11-09 13:19:07,241 - INFO - root - LLMClientManager: switched to Doubao client
2025-11-09 13:19:07,241 - INFO - root - 已手动切换到 LLM 客户端: Doubao
2025-11-09 13:19:07,242 - INFO - root - 使用 LLM 模型: doubao-seed-1-6-lite-251015
2025-11-09 13:19:07,242 - INFO - root - 可用客户端: ['Doubao']
2025-11-09 13:19:07,242 - INFO - root - === 运行配置 ===
2025-11-09 13:19:07,243 - INFO - root - 处理模式: 本地PDF文件
2025-11-09 13:19:07,245 - INFO - root - PDF目录: ./myPapers
2025-11-09 13:19:07,246 - INFO - root - 最大处理数量: 2
2025-11-09 13:19:07,249 - INFO - root - 保存图片: 是
2025-11-09 13:19:07,252 - INFO - root - 输出语言: 中文
2025-11-09 13:19:07,253 - INFO - root - 强制重新处理: 否
2025-11-09 13:19:07,260 - INFO - root - ====================
2025-11-09 13:19:07,263 - INFO - root - 从本地目录读取PDF文件：./myPapers
2025-11-09 13:19:09,141 - INFO - root - 成功加载PDF文件：A Compute&Memory Efficient Model-Driven Neural 5G Receiver for Edge AI-assisted.pdf
2025-11-09 13:19:11,769 - INFO - root - 成功加载PDF文件：AMLA_ MUL by ADD in FlashAttention Rescaling.pdf
2025-11-09 13:19:11,769 - INFO - root - 已达到最大处理数量限制 (2)，停止加载更多PDF文件
2025-11-09 13:19:11,772 - INFO - root - 跳过已处理论文 A Compute&Memory Efficient Model-Driven Neural：./myPapers\A Compute&Memory Efficient Model-Driven Neural 5G Receiver for Edge AI-assisted.pdf
2025-11-09 13:19:11,772 - INFO - root - 跳过已处理论文 AMLA: MUL by ADD in FlashAttention Rescaling：./myPapers\AMLA_ MUL by ADD in FlashAttention Rescaling.pdf
2025-11-09 13:19:11,773 - INFO - root - summary time: 11.65 seconds
2025-11-09 13:21:37,150 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-09 13:21:37,176 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-09 13:21:37,179 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-09 13:21:38,652 - INFO - root - LLMClientManager: 指定使用客户端: Doubao
2025-11-09 13:21:38,653 - INFO - root - DoubaoClient: API key found: 9f9e270e-b...
2025-11-09 13:21:43,494 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 13:21:43,681 - INFO - root - DoubaoClient: initialized successfully with model doubao-seed-1-6-lite-251015
2025-11-09 13:21:43,821 - INFO - root - LLMClientManager: Doubao 客户端初始化成功
2025-11-09 13:21:43,871 - INFO - root - LLMClientManager: switched to Doubao client
2025-11-09 13:21:43,897 - INFO - root - 已手动切换到 LLM 客户端: Doubao
2025-11-09 13:21:43,971 - INFO - root - 使用 LLM 模型: doubao-seed-1-6-lite-251015
2025-11-09 13:21:43,993 - INFO - root - 可用客户端: ['Doubao']
2025-11-09 13:21:44,032 - INFO - root - === 运行配置 ===
2025-11-09 13:21:44,100 - INFO - root - 处理模式: 本地PDF文件
2025-11-09 13:21:44,117 - INFO - root - PDF目录: ./myPapers
2025-11-09 13:21:44,147 - INFO - root - 最大处理数量: 2
2025-11-09 13:21:44,186 - INFO - root - 保存图片: 是
2025-11-09 13:21:44,233 - INFO - root - 输出语言: 中文
2025-11-09 13:21:44,238 - INFO - root - 强制重新处理: 否
2025-11-09 13:21:44,244 - INFO - root - ====================
2025-11-09 13:21:44,250 - INFO - root - 从本地目录读取PDF文件：./myPapers
2025-11-09 13:21:46,096 - INFO - root - 成功加载PDF文件：A Compute&Memory Efficient Model-Driven Neural 5G Receiver for Edge AI-assisted.pdf
2025-11-09 13:21:49,176 - INFO - root - 成功加载PDF文件：AMLA_ MUL by ADD in FlashAttention Rescaling.pdf
2025-11-09 13:21:49,178 - INFO - root - 已达到最大处理数量限制 (2)，停止加载更多PDF文件
2025-11-09 13:21:49,179 - INFO - root - 跳过已处理论文 A Compute&Memory Efficient Model-Driven Neural：./myPapers\A Compute&Memory Efficient Model-Driven Neural 5G Receiver for Edge AI-assisted.pdf
2025-11-09 13:21:49,179 - INFO - root - 跳过已处理论文 AMLA: MUL by ADD in FlashAttention Rescaling：./myPapers\AMLA_ MUL by ADD in FlashAttention Rescaling.pdf
2025-11-09 13:21:49,179 - INFO - root - summary time: 12.03 seconds
2025-11-09 13:22:41,686 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-09 13:22:41,687 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-09 13:22:41,688 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-09 13:22:43,552 - INFO - root - LLMClientManager: 指定使用客户端: Doubao
2025-11-09 13:22:43,552 - INFO - root - DoubaoClient: API key found: 9f9e270e-b...
2025-11-09 13:22:48,878 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 13:22:48,886 - INFO - root - DoubaoClient: initialized successfully with model doubao-seed-1-6-lite-251015
2025-11-09 13:22:48,886 - INFO - root - LLMClientManager: Doubao 客户端初始化成功
2025-11-09 13:22:48,887 - INFO - root - LLMClientManager: switched to Doubao client
2025-11-09 13:22:48,887 - INFO - root - 已手动切换到 LLM 客户端: Doubao
2025-11-09 13:22:48,888 - INFO - root - 使用 LLM 模型: doubao-seed-1-6-lite-251015
2025-11-09 13:22:48,889 - INFO - root - 可用客户端: ['Doubao']
2025-11-09 13:22:48,889 - INFO - root - === 运行配置 ===
2025-11-09 13:22:48,890 - INFO - root - 处理模式: 本地PDF文件
2025-11-09 13:22:48,891 - INFO - root - PDF目录: ./myPapers
2025-11-09 13:22:48,891 - INFO - root - 最大处理数量: 2
2025-11-09 13:22:48,892 - INFO - root - 保存图片: 是
2025-11-09 13:22:48,892 - INFO - root - 输出语言: 中文
2025-11-09 13:22:48,892 - INFO - root - 强制重新处理: 否
2025-11-09 13:22:48,892 - INFO - root - ====================
2025-11-09 13:22:48,894 - INFO - root - 从本地目录读取PDF文件：./myPapers
2025-11-09 13:22:50,256 - INFO - root - 成功加载PDF文件：A Compute&Memory Efficient Model-Driven Neural 5G Receiver for Edge AI-assisted.pdf
2025-11-09 13:22:52,443 - INFO - root - 成功加载PDF文件：AMLA_ MUL by ADD in FlashAttention Rescaling.pdf
2025-11-09 13:22:52,443 - INFO - root - 已达到最大处理数量限制 (2)，停止加载更多PDF文件
2025-11-09 13:22:52,443 - INFO - root - 正在总结论文 1/2: A Compute&Memory Efficient Model-Driven Neural
2025-11-09 13:23:18,467 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 13:24:47,003 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 13:25:29,784 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 13:25:29,788 - INFO - root - 正在提取论文图片...
2025-11-09 13:25:31,327 - INFO - root - 已保存图片 1/10：./export\images_A Compute&Memory Efficient Model-Driven Neural\figure_1_page6.png
2025-11-09 13:25:31,422 - INFO - root - 已保存图片 2/10：./export\images_A Compute&Memory Efficient Model-Driven Neural\figure_2_page6.png
2025-11-09 13:25:31,518 - INFO - root - 已保存图片 3/10：./export\images_A Compute&Memory Efficient Model-Driven Neural\figure_3_page2.png
2025-11-09 13:25:31,575 - INFO - root - 已保存图片 4/10：./export\images_A Compute&Memory Efficient Model-Driven Neural\figure_4_page2.png
2025-11-09 13:25:31,625 - INFO - root - 已保存图片 5/10：./export\images_A Compute&Memory Efficient Model-Driven Neural\figure_5_page3.png
2025-11-09 13:25:31,628 - INFO - root - 成功添加图片 1：./export\images_A Compute&Memory Efficient Model-Driven Neural\figure_1_page6.png
2025-11-09 13:25:31,628 - INFO - root - 成功添加图片 2：./export\images_A Compute&Memory Efficient Model-Driven Neural\figure_2_page6.png
2025-11-09 13:25:31,628 - INFO - root - 成功添加图片 3：./export\images_A Compute&Memory Efficient Model-Driven Neural\figure_3_page2.png
2025-11-09 13:25:31,629 - INFO - root - 成功添加图片 4：./export\images_A Compute&Memory Efficient Model-Driven Neural\figure_4_page2.png
2025-11-09 13:25:31,629 - INFO - root - 成功添加图片 5：./export\images_A Compute&Memory Efficient Model-Driven Neural\figure_5_page3.png
2025-11-09 13:25:31,631 - INFO - root - 论文《A Compute&Memory Efficient Model-Driven Neural》的分析已保存到 ./export\A Compute&Memory Efficient Model-Driven Neural.md
2025-11-09 13:25:31,639 - INFO - root - 跳过已处理论文 AMLA: MUL by ADD in FlashAttention Rescaling：./myPapers\AMLA_ MUL by ADD in FlashAttention Rescaling.pdf
2025-11-09 13:25:31,644 - INFO - root - summary time: 169.96 seconds
2025-11-09 13:41:09,766 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-09 13:41:09,768 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-09 13:41:09,770 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-09 13:41:10,997 - INFO - root - LLMClientManager: 指定使用客户端: Doubao
2025-11-09 13:41:10,998 - INFO - root - DoubaoClient: API key found: 9f9e270e-b...
2025-11-09 13:41:16,132 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 13:41:16,144 - INFO - root - DoubaoClient: initialized successfully with model doubao-seed-1-6-lite-251015
2025-11-09 13:41:16,144 - INFO - root - LLMClientManager: Doubao 客户端初始化成功
2025-11-09 13:41:16,144 - INFO - root - LLMClientManager: switched to Doubao client
2025-11-09 13:41:16,145 - INFO - root - 已手动切换到 LLM 客户端: Doubao
2025-11-09 13:41:16,145 - INFO - root - 使用 LLM 模型: doubao-seed-1-6-lite-251015
2025-11-09 13:41:16,146 - INFO - root - 可用客户端: ['Doubao']
2025-11-09 13:41:16,146 - INFO - root - === 运行配置 ===
2025-11-09 13:41:16,147 - INFO - root - 处理模式: 本地PDF文件
2025-11-09 13:41:16,147 - INFO - root - PDF目录: ./myPapers
2025-11-09 13:41:16,147 - INFO - root - 最大处理数量: 2
2025-11-09 13:41:16,148 - INFO - root - 保存图片: 是
2025-11-09 13:41:16,150 - INFO - root - 输出语言: 中文
2025-11-09 13:41:16,151 - INFO - root - 强制重新处理: 否
2025-11-09 13:41:16,152 - INFO - root - ====================
2025-11-09 13:41:16,153 - INFO - root - 从本地目录读取PDF文件：./myPapers
2025-11-09 13:41:18,769 - INFO - root - 成功加载PDF文件：A Compute&Memory Efficient Model-Driven Neural 5G Receiver for Edge AI-assisted.pdf
2025-11-09 13:41:22,435 - INFO - root - 成功加载PDF文件：AMLA_ MUL by ADD in FlashAttention Rescaling.pdf
2025-11-09 13:41:22,435 - INFO - root - 已达到最大处理数量限制 (2)，停止加载更多PDF文件
2025-11-09 13:41:22,437 - INFO - root - 跳过已处理论文 A Compute&Memory Efficient Model-Driven Neural：./myPapers\A Compute&Memory Efficient Model-Driven Neural 5G Receiver for Edge AI-assisted.pdf
2025-11-09 13:41:22,437 - INFO - root - 跳过已处理论文 AMLA: MUL by ADD in FlashAttention Rescaling：./myPapers\AMLA_ MUL by ADD in FlashAttention Rescaling.pdf
2025-11-09 13:41:22,437 - INFO - root - summary time: 12.67 seconds
2025-11-09 13:42:09,313 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-09 13:42:09,314 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-09 13:42:09,317 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-09 13:42:10,708 - INFO - root - LLMClientManager: 指定使用客户端: Doubao
2025-11-09 13:42:10,709 - INFO - root - DoubaoClient: API key found: 9f9e270e-b...
2025-11-09 13:42:15,602 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 13:42:15,620 - INFO - root - DoubaoClient: initialized successfully with model doubao-seed-1-6-lite-251015
2025-11-09 13:42:15,620 - INFO - root - LLMClientManager: Doubao 客户端初始化成功
2025-11-09 13:42:15,621 - INFO - root - LLMClientManager: switched to Doubao client
2025-11-09 13:42:15,623 - INFO - root - 已手动切换到 LLM 客户端: Doubao
2025-11-09 13:42:15,624 - INFO - root - 使用 LLM 模型: doubao-seed-1-6-lite-251015
2025-11-09 13:42:15,625 - INFO - root - 可用客户端: ['Doubao']
2025-11-09 13:42:15,627 - INFO - root - === 运行配置 ===
2025-11-09 13:42:15,628 - INFO - root - 处理模式: 本地PDF文件
2025-11-09 13:42:15,629 - INFO - root - PDF目录: ./myPapers
2025-11-09 13:42:15,629 - INFO - root - 最大处理数量: 2
2025-11-09 13:42:15,630 - INFO - root - 保存图片: 是
2025-11-09 13:42:15,630 - INFO - root - 输出语言: 中文
2025-11-09 13:42:15,631 - INFO - root - 强制重新处理: 否
2025-11-09 13:42:15,631 - INFO - root - ====================
2025-11-09 13:42:15,631 - INFO - root - 从本地目录读取PDF文件：./myPapers
2025-11-09 13:42:17,181 - INFO - root - 成功加载PDF文件：A Compute&Memory Efficient Model-Driven Neural 5G Receiver for Edge AI-assisted.pdf
2025-11-09 13:42:19,842 - INFO - root - 成功加载PDF文件：AMLA_ MUL by ADD in FlashAttention Rescaling.pdf
2025-11-09 13:42:19,843 - INFO - root - 已达到最大处理数量限制 (2)，停止加载更多PDF文件
2025-11-09 13:42:19,844 - INFO - root - 正在总结论文 1/2: A Compute&Memory Efficient Model-Driven Neural
2025-11-09 13:42:52,518 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 13:44:31,832 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 13:45:09,321 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 13:45:09,322 - INFO - root - 正在提取论文图片...
2025-11-09 13:45:10,094 - INFO - root - 已保存图片 1/10：./export\images_A Compute&Memory Efficient Model-Driven Neural\figure_1_page6.png
2025-11-09 13:45:10,255 - INFO - root - 已保存图片 2/10：./export\images_A Compute&Memory Efficient Model-Driven Neural\figure_2_page6.png
2025-11-09 13:45:10,346 - INFO - root - 已保存图片 3/10：./export\images_A Compute&Memory Efficient Model-Driven Neural\figure_3_page2.png
2025-11-09 13:45:10,394 - INFO - root - 已保存图片 4/10：./export\images_A Compute&Memory Efficient Model-Driven Neural\figure_4_page2.png
2025-11-09 13:45:10,451 - INFO - root - 已保存图片 5/10：./export\images_A Compute&Memory Efficient Model-Driven Neural\figure_5_page3.png
2025-11-09 13:45:10,457 - INFO - root - 成功添加图片 1：./export\images_A Compute&Memory Efficient Model-Driven Neural\figure_1_page6.png
2025-11-09 13:45:10,457 - INFO - root - 成功添加图片 2：./export\images_A Compute&Memory Efficient Model-Driven Neural\figure_2_page6.png
2025-11-09 13:45:10,458 - INFO - root - 成功添加图片 3：./export\images_A Compute&Memory Efficient Model-Driven Neural\figure_3_page2.png
2025-11-09 13:45:10,458 - INFO - root - 成功添加图片 4：./export\images_A Compute&Memory Efficient Model-Driven Neural\figure_4_page2.png
2025-11-09 13:45:10,458 - INFO - root - 成功添加图片 5：./export\images_A Compute&Memory Efficient Model-Driven Neural\figure_5_page3.png
2025-11-09 13:45:10,460 - INFO - root - 论文《A Compute&Memory Efficient Model-Driven Neural》的分析已保存到 ./export\A Compute&Memory Efficient Model-Driven Neural.md
2025-11-09 13:45:10,473 - INFO - root - 跳过已处理论文 AMLA: MUL by ADD in FlashAttention Rescaling：./myPapers\AMLA_ MUL by ADD in FlashAttention Rescaling.pdf
2025-11-09 13:45:10,479 - INFO - root - summary time: 181.17 seconds
2025-11-09 14:04:17,111 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-09 14:04:17,111 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-09 14:04:17,111 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-09 14:04:19,141 - INFO - root - GeminiClient: trying model gemini-2.5-flash
2025-11-09 14:04:20,107 - INFO - root - GeminiClient: trying model gemini-2.5-pro
2025-11-09 14:04:20,489 - WARNING - root - GeminiClient: no usable model found
2025-11-09 14:04:20,491 - WARNING - root - LLMClientManager: Gemini client initialization failed
2025-11-09 14:04:20,492 - WARNING - root - DeepSeekClient: API key not provided. LLM disabled.
2025-11-09 14:04:20,492 - WARNING - root - LLMClientManager: DeepSeek client initialization failed
2025-11-09 14:04:20,493 - WARNING - root - KimiClient: API key not provided. LLM disabled.
2025-11-09 14:04:20,493 - WARNING - root - LLMClientManager: Kimi client initialization failed
2025-11-09 14:04:20,493 - WARNING - root - QwenClient: API key not provided. LLM disabled.
2025-11-09 14:04:20,494 - WARNING - root - LLMClientManager: Qwen client initialization failed
2025-11-09 14:04:20,494 - INFO - root - DoubaoClient: API key found: 9f9e270e-b...
2025-11-09 14:04:26,872 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 14:04:26,893 - INFO - root - DoubaoClient: initialized successfully with model doubao-seed-1-6-lite-251015
2025-11-09 14:04:26,894 - INFO - root - LLMClientManager: Doubao client initialized successfully
2025-11-09 14:04:26,894 - INFO - root - LLMClientManager: using Doubao as default client
2025-11-09 14:04:26,895 - INFO - root - 使用 LLM 模型: doubao-seed-1-6-lite-251015
2025-11-09 14:04:26,896 - INFO - root - 可用客户端: ['Doubao']
2025-11-09 14:04:26,896 - INFO - root - === 运行配置 ===
2025-11-09 14:04:26,896 - INFO - root - 处理模式: 本地PDF文件
2025-11-09 14:04:26,897 - INFO - root - PDF目录: ./myPapers
2025-11-09 14:04:26,897 - INFO - root - 最大处理数量: 2
2025-11-09 14:04:26,897 - INFO - root - 保存图片: 是
2025-11-09 14:04:26,898 - INFO - root - 输出语言: 中文
2025-11-09 14:04:26,898 - INFO - root - 强制重新处理: 否
2025-11-09 14:04:26,899 - INFO - root - ====================
2025-11-09 14:04:26,900 - INFO - root - 从本地目录读取PDF文件：./myPapers
2025-11-09 14:04:28,787 - INFO - root - 成功加载PDF文件：A Compute&Memory Efficient Model-Driven Neural 5G Receiver for Edge AI-assisted.pdf
2025-11-09 14:04:31,792 - INFO - root - 成功加载PDF文件：AMLA_ MUL by ADD in FlashAttention Rescaling.pdf
2025-11-09 14:04:31,794 - INFO - root - 已达到最大处理数量限制 (2)，停止加载更多PDF文件
2025-11-09 14:04:31,795 - INFO - root - 跳过已处理论文 A Compute&Memory Efficient Model-Driven Neural：./myPapers\A Compute&Memory Efficient Model-Driven Neural 5G Receiver for Edge AI-assisted.pdf
2025-11-09 14:04:31,796 - INFO - root - 跳过已处理论文 AMLA: MUL by ADD in FlashAttention Rescaling：./myPapers\AMLA_ MUL by ADD in FlashAttention Rescaling.pdf
2025-11-09 14:04:31,796 - INFO - root - summary time: 14.68 seconds
2025-11-09 14:12:56,035 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-09 14:12:56,035 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-09 14:12:56,049 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-09 14:12:57,528 - INFO - root - GeminiClient: trying model gemini-2.5-flash
2025-11-09 14:12:58,374 - INFO - root - GeminiClient: trying model gemini-2.5-pro
2025-11-09 14:12:58,745 - WARNING - root - GeminiClient: no usable model found
2025-11-09 14:12:58,746 - WARNING - root - LLMClientManager: Gemini client initialization failed
2025-11-09 14:12:58,746 - WARNING - root - DeepSeekClient: API key not provided. LLM disabled.
2025-11-09 14:12:58,746 - WARNING - root - LLMClientManager: DeepSeek client initialization failed
2025-11-09 14:12:58,747 - WARNING - root - KimiClient: API key not provided. LLM disabled.
2025-11-09 14:12:58,748 - WARNING - root - LLMClientManager: Kimi client initialization failed
2025-11-09 14:12:58,748 - WARNING - root - QwenClient: API key not provided. LLM disabled.
2025-11-09 14:12:58,748 - WARNING - root - LLMClientManager: Qwen client initialization failed
2025-11-09 14:12:58,748 - INFO - root - DoubaoClient: API key found: 9f9e270e-b...
2025-11-09 14:13:02,872 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 14:13:02,877 - INFO - root - DoubaoClient: initialized successfully with model doubao-seed-1-6-lite-251015
2025-11-09 14:13:02,877 - INFO - root - LLMClientManager: Doubao client initialized successfully
2025-11-09 14:13:02,877 - INFO - root - LLMClientManager: using Doubao as default client
2025-11-09 14:13:02,885 - INFO - root - 使用 LLM 模型: doubao-seed-1-6-lite-251015
2025-11-09 14:13:02,885 - INFO - root - 可用客户端: ['Doubao']
2025-11-09 14:13:02,886 - INFO - root - === 运行配置 ===
2025-11-09 14:13:02,886 - INFO - root - 处理模式: 本地PDF文件
2025-11-09 14:13:02,887 - INFO - root - PDF目录: ./myPapers
2025-11-09 14:13:02,887 - INFO - root - 最大处理数量: 2
2025-11-09 14:13:02,890 - INFO - root - 保存图片: 是
2025-11-09 14:13:02,890 - INFO - root - 输出语言: 中文
2025-11-09 14:13:02,891 - INFO - root - 强制重新处理: 否
2025-11-09 14:13:02,891 - INFO - root - ====================
2025-11-09 14:13:02,891 - INFO - root - 从本地目录读取PDF文件：./myPapers
2025-11-09 14:13:04,457 - INFO - root - 成功加载PDF文件：A Compute&Memory Efficient Model-Driven Neural 5G Receiver for Edge AI-assisted.pdf
2025-11-09 14:13:06,450 - INFO - root - 成功加载PDF文件：AMLA_ MUL by ADD in FlashAttention Rescaling.pdf
2025-11-09 14:13:06,450 - INFO - root - 已达到最大处理数量限制 (2)，停止加载更多PDF文件
2025-11-09 14:13:06,450 - INFO - root - 跳过已处理论文 A Compute&Memory Efficient Model-Driven Neural：./myPapers\A Compute&Memory Efficient Model-Driven Neural 5G Receiver for Edge AI-assisted.pdf
2025-11-09 14:13:06,450 - INFO - root - 跳过已处理论文 AMLA: MUL by ADD in FlashAttention Rescaling：./myPapers\AMLA_ MUL by ADD in FlashAttention Rescaling.pdf
2025-11-09 14:13:06,450 - INFO - root - summary time: 10.42 seconds
2025-11-09 14:13:27,922 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-09 14:13:27,924 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-09 14:13:27,926 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-09 14:13:29,624 - INFO - root - GeminiClient: trying model gemini-2.5-flash
2025-11-09 14:13:30,568 - INFO - root - GeminiClient: trying model gemini-2.5-pro
2025-11-09 14:13:30,695 - WARNING - root - GeminiClient: no usable model found
2025-11-09 14:13:30,696 - WARNING - root - LLMClientManager: Gemini client initialization failed
2025-11-09 14:13:30,696 - WARNING - root - DeepSeekClient: API key not provided. LLM disabled.
2025-11-09 14:13:30,696 - WARNING - root - LLMClientManager: DeepSeek client initialization failed
2025-11-09 14:13:30,697 - WARNING - root - KimiClient: API key not provided. LLM disabled.
2025-11-09 14:13:30,697 - WARNING - root - LLMClientManager: Kimi client initialization failed
2025-11-09 14:13:30,697 - WARNING - root - QwenClient: API key not provided. LLM disabled.
2025-11-09 14:13:30,697 - WARNING - root - LLMClientManager: Qwen client initialization failed
2025-11-09 14:13:30,698 - INFO - root - DoubaoClient: API key found: 9f9e270e-b...
2025-11-09 14:13:35,993 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 14:13:36,003 - INFO - root - DoubaoClient: initialized successfully with model doubao-seed-1-6-lite-251015
2025-11-09 14:13:36,003 - INFO - root - LLMClientManager: Doubao client initialized successfully
2025-11-09 14:13:36,003 - INFO - root - LLMClientManager: using Doubao as default client
2025-11-09 14:13:36,003 - INFO - root - 使用 LLM 模型: doubao-seed-1-6-lite-251015
2025-11-09 14:13:36,004 - INFO - root - 可用客户端: ['Doubao']
2025-11-09 14:13:36,006 - INFO - root - === 运行配置 ===
2025-11-09 14:13:36,008 - INFO - root - 处理模式: 本地PDF文件
2025-11-09 14:13:36,009 - INFO - root - PDF目录: ./myPapers
2025-11-09 14:13:36,010 - INFO - root - 最大处理数量: 2
2025-11-09 14:13:36,010 - INFO - root - 保存图片: 是
2025-11-09 14:13:36,011 - INFO - root - 输出语言: 中文
2025-11-09 14:13:36,011 - INFO - root - 强制重新处理: 否
2025-11-09 14:13:36,011 - INFO - root - ====================
2025-11-09 14:13:36,011 - INFO - root - 从本地目录读取PDF文件：./myPapers
2025-11-09 14:13:37,419 - INFO - root - 成功加载PDF文件：A Compute&Memory Efficient Model-Driven Neural 5G Receiver for Edge AI-assisted.pdf
2025-11-09 14:13:39,410 - INFO - root - 成功加载PDF文件：AMLA_ MUL by ADD in FlashAttention Rescaling.pdf
2025-11-09 14:13:39,410 - INFO - root - 已达到最大处理数量限制 (2)，停止加载更多PDF文件
2025-11-09 14:13:39,410 - INFO - root - 跳过已处理论文 A Compute&Memory Efficient Model-Driven Neural：./myPapers\A Compute&Memory Efficient Model-Driven Neural 5G Receiver for Edge AI-assisted.pdf
2025-11-09 14:13:39,410 - INFO - root - 跳过已处理论文 AMLA: MUL by ADD in FlashAttention Rescaling：./myPapers\AMLA_ MUL by ADD in FlashAttention Rescaling.pdf
2025-11-09 14:13:39,410 - INFO - root - summary time: 11.49 seconds
2025-11-09 14:14:39,048 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-09 14:14:39,052 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-09 14:14:39,054 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-09 14:14:40,444 - INFO - root - GeminiClient: trying model gemini-2.5-flash
2025-11-09 14:14:41,291 - INFO - root - GeminiClient: trying model gemini-2.5-pro
2025-11-09 14:14:41,648 - WARNING - root - GeminiClient: no usable model found
2025-11-09 14:14:41,648 - WARNING - root - LLMClientManager: Gemini client initialization failed
2025-11-09 14:14:41,648 - WARNING - root - DeepSeekClient: API key not provided. LLM disabled.
2025-11-09 14:14:41,649 - WARNING - root - LLMClientManager: DeepSeek client initialization failed
2025-11-09 14:14:41,649 - WARNING - root - KimiClient: API key not provided. LLM disabled.
2025-11-09 14:14:41,649 - WARNING - root - LLMClientManager: Kimi client initialization failed
2025-11-09 14:14:41,650 - WARNING - root - QwenClient: API key not provided. LLM disabled.
2025-11-09 14:14:41,650 - WARNING - root - LLMClientManager: Qwen client initialization failed
2025-11-09 14:14:41,650 - INFO - root - DoubaoClient: API key found: 9f9e270e-b...
2025-11-09 14:14:46,605 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 14:14:46,616 - INFO - root - DoubaoClient: initialized successfully with model doubao-seed-1-6-lite-251015
2025-11-09 14:14:46,616 - INFO - root - LLMClientManager: Doubao client initialized successfully
2025-11-09 14:14:46,616 - INFO - root - LLMClientManager: using Doubao as default client
2025-11-09 14:14:46,616 - INFO - root - 使用 LLM 模型: doubao-seed-1-6-lite-251015
2025-11-09 14:14:46,616 - INFO - root - 可用客户端: ['Doubao']
2025-11-09 14:14:46,619 - INFO - root - === 运行配置 ===
2025-11-09 14:14:46,619 - INFO - root - 处理模式: 本地PDF文件
2025-11-09 14:14:46,620 - INFO - root - PDF目录: ./myPapers
2025-11-09 14:14:46,620 - INFO - root - 最大处理数量: 2
2025-11-09 14:14:46,620 - INFO - root - 保存图片: 是
2025-11-09 14:14:46,620 - INFO - root - 输出语言: 中文
2025-11-09 14:14:46,621 - INFO - root - 强制重新处理: 否
2025-11-09 14:14:46,622 - INFO - root - ====================
2025-11-09 14:14:46,622 - INFO - root - 从本地目录读取PDF文件：./myPapers
2025-11-09 14:14:47,983 - INFO - root - 成功加载PDF文件：A Compute&Memory Efficient Model-Driven Neural 5G Receiver for Edge AI-assisted.pdf
2025-11-09 14:14:49,898 - INFO - root - 成功加载PDF文件：AMLA_ MUL by ADD in FlashAttention Rescaling.pdf
2025-11-09 14:14:49,898 - INFO - root - 已达到最大处理数量限制 (2)，停止加载更多PDF文件
2025-11-09 14:14:49,898 - INFO - root - 正在总结论文 1/2: A Compute&Memory Efficient Model-Driven Neural
2025-11-09 14:15:32,728 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 14:16:45,454 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 14:17:33,055 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 14:17:33,058 - INFO - root - 正在提取论文图片...
2025-11-09 14:17:33,812 - INFO - root - 已保存图片 1/10：./export\images_A Compute&Memory Efficient Model-Driven Neural\figure_1_page6.png
2025-11-09 14:17:33,915 - INFO - root - 已保存图片 2/10：./export\images_A Compute&Memory Efficient Model-Driven Neural\figure_2_page6.png
2025-11-09 14:17:34,007 - INFO - root - 已保存图片 3/10：./export\images_A Compute&Memory Efficient Model-Driven Neural\figure_3_page2.png
2025-11-09 14:17:34,056 - INFO - root - 已保存图片 4/10：./export\images_A Compute&Memory Efficient Model-Driven Neural\figure_4_page2.png
2025-11-09 14:17:34,127 - INFO - root - 已保存图片 5/10：./export\images_A Compute&Memory Efficient Model-Driven Neural\figure_5_page3.png
2025-11-09 14:17:34,132 - INFO - root - 成功添加图片 1：./export\images_A Compute&Memory Efficient Model-Driven Neural\figure_1_page6.png
2025-11-09 14:17:34,132 - INFO - root - 成功添加图片 2：./export\images_A Compute&Memory Efficient Model-Driven Neural\figure_2_page6.png
2025-11-09 14:17:34,132 - INFO - root - 成功添加图片 3：./export\images_A Compute&Memory Efficient Model-Driven Neural\figure_3_page2.png
2025-11-09 14:17:34,133 - INFO - root - 成功添加图片 4：./export\images_A Compute&Memory Efficient Model-Driven Neural\figure_4_page2.png
2025-11-09 14:17:34,133 - INFO - root - 成功添加图片 5：./export\images_A Compute&Memory Efficient Model-Driven Neural\figure_5_page3.png
2025-11-09 14:17:34,138 - INFO - root - 论文《A Compute&Memory Efficient Model-Driven Neural》的分析已保存到 ./export\A Compute&Memory Efficient Model-Driven Neural.md
2025-11-09 14:17:34,145 - INFO - root - 跳过已处理论文 AMLA: MUL by ADD in FlashAttention Rescaling：./myPapers\AMLA_ MUL by ADD in FlashAttention Rescaling.pdf
2025-11-09 14:17:34,153 - INFO - root - summary time: 175.10 seconds
2025-11-09 16:42:33,744 - INFO - root - Fetching page 1 with URL: https://arxiv.org/search/?query=traffic+flow+prediction&searchtype=all&abstracts=show&order=-announced_date_first&size=50
2025-11-09 16:42:35,196 - INFO - root - get_all_titles_from_web 
2025-11-09 16:42:35,196 - INFO - root - Page:0, Index:0, A Theoretical Framework for Environmental Similarity and Vessel Mobility as Coupled Predictors of Marine Invasive Species Pathways, https://arxiv.org/pdf/2511.03499, 2025-11-06
2025-11-09 16:42:35,196 - INFO - root - Page:0, Index:1, Towards Sub-millisecond Latency and Guaranteed Bit Rates in 5G User Plane, https://arxiv.org/pdf/2511.00196, 2025-10-31
2025-11-09 16:42:35,196 - INFO - root - Page:0, Index:2, A Cloud-Based Spatio-Temporal GNN-Transformer Hybrid Model for Traffic Flow Forecasting with External Feature Integration, https://arxiv.org/pdf/2510.27039, 2025-10-30
2025-11-09 16:42:35,196 - INFO - root - Page:0, Index:3, Research on Expressway Congestion Warning Technology Based on YOLOv11-DIoU and GRU-Attention, https://arxiv.org/pdf/2509.13361, 2025-11-04
2025-11-09 16:42:35,196 - INFO - root - Fetching page 2 with URL: https://arxiv.org/search/?query=traffic+flow+prediction&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=50
2025-11-09 16:42:36,837 - INFO - root - ------------------------------------------------------------------------------------------------------------------------
2025-11-09 16:42:46,124 - INFO - root - Downloaded 3 papers in 12.4s
2025-11-09 16:43:48,497 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-09 16:43:48,502 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-09 16:43:48,502 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-09 16:47:07,981 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-09 16:47:07,981 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-09 16:47:07,985 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-09 16:47:09,033 - INFO - root - LLMClientManager: 指定使用客户端: Deepseek
2025-11-09 16:47:09,034 - INFO - root - DeepSeekClient: API key found: your_deeps...
2025-11-09 16:47:09,034 - WARNING - root - DeepSeekClient: API key not provided or using placeholder. LLM disabled.
2025-11-09 16:47:09,034 - ERROR - root - LLMClientManager: 指定的客户端 DeepSeek 初始化失败
2025-11-09 16:47:09,034 - WARNING - root - LLMClientManager: 指定的客户端 Deepseek 不可用，将尝试其他客户端
2025-11-09 16:51:57,471 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-09 16:51:57,472 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-09 16:51:57,477 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-09 16:51:59,021 - INFO - root - LLMClientManager: 指定使用客户端: Deepseek
2025-11-09 16:51:59,021 - INFO - root - DeepSeekClient: API key found: 9f9e270e-b...
2025-11-09 16:52:01,342 - INFO - httpx - HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 401 Unauthorized"
2025-11-09 16:52:01,345 - ERROR - root - DeepSeekClient: error during initialization: Error code: 401 - {'error': {'message': 'Authentication Fails, Your api key: ****24c9 is invalid', 'type': 'authentication_error', 'param': None, 'code': 'invalid_request_error'}}
2025-11-09 16:52:01,346 - ERROR - root - LLMClientManager: 指定的客户端 DeepSeek 初始化失败
2025-11-09 16:52:01,347 - WARNING - root - LLMClientManager: 指定的客户端 Deepseek 不可用，将尝试其他客户端
2025-11-09 16:53:00,258 - ERROR - root - GeminiClient: error during initialization: Timeout of 60.0s exceeded, last exception: 503 failed to connect to all addresses; last error: UNKNOWN: ipv4:142.250.73.138:443: socket is null
2025-11-09 16:53:00,260 - WARNING - root - LLMClientManager: Gemini client initialization failed
2025-11-09 16:53:00,261 - WARNING - root - KimiClient: API key not provided. LLM disabled.
2025-11-09 16:53:00,261 - WARNING - root - LLMClientManager: Kimi client initialization failed
2025-11-09 16:53:00,261 - WARNING - root - QwenClient: API key not provided. LLM disabled.
2025-11-09 16:53:00,263 - WARNING - root - LLMClientManager: Qwen client initialization failed
2025-11-09 16:53:00,263 - INFO - root - DoubaoClient: API key found: 9f9e270e-b...
2025-11-09 16:53:04,463 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 16:53:04,488 - INFO - root - DoubaoClient: initialized successfully with model doubao-seed-1-6-lite-251015
2025-11-09 16:53:04,489 - INFO - root - LLMClientManager: Doubao client initialized successfully
2025-11-09 16:53:04,491 - INFO - root - LLMClientManager: using Doubao as default client
2025-11-09 16:53:04,492 - WARNING - root - LLMClientManager: client Deepseek not available
2025-11-09 16:53:04,493 - WARNING - root - 无法切换到指定的客户端 Deepseek，将使用默认客户端
2025-11-09 16:53:04,497 - INFO - root - 可用客户端: ['Doubao']
2025-11-09 16:53:04,497 - INFO - root - 使用 LLM 模型: doubao-seed-1-6-lite-251015
2025-11-09 16:53:04,498 - INFO - root - 可用客户端: ['Doubao']
2025-11-09 16:53:04,501 - INFO - root - === 运行配置 ===
2025-11-09 16:53:04,502 - INFO - root - 处理模式: arxiv在线搜索
2025-11-09 16:53:04,503 - INFO - root - 关键词: Quant
2025-11-09 16:53:04,506 - INFO - root - 查询: Quantization-Aware-Training
2025-11-09 16:53:04,507 - INFO - root - 排序: None
2025-11-09 16:53:04,507 - INFO - root - 最近天数: 180
2025-11-09 16:53:04,544 - INFO - root - 最大处理数量: 10
2025-11-09 16:53:04,544 - INFO - root - 保存图片: 是
2025-11-09 16:53:04,546 - INFO - root - 输出语言: 中文
2025-11-09 16:53:04,547 - INFO - root - 强制重新处理: 否
2025-11-09 16:53:04,551 - INFO - root - ====================
2025-11-09 16:53:04,557 - INFO - root - 使用 arXiv 搜索模式（通过 chat_arxiv 模块获取）
2025-11-09 16:53:04,557 - INFO - root - Fetching page 1 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50
2025-11-09 16:53:06,532 - INFO - root - get_all_titles_from_web 
2025-11-09 16:53:06,533 - INFO - root - Page:0, Index:0, A Quantized VAE-MLP Botnet Detection Model: A Systematic Evaluation of Quantization-Aware Training and Post-Training Quantization Strategies, https://arxiv.org/pdf/2511.03201, 2025-11-05
2025-11-09 16:53:06,533 - INFO - root - Page:0, Index:1, FP8-Flow-MoE: A Casting-Free FP8 Recipe without Double Quantization Error, https://arxiv.org/pdf/2511.02302, 2025-11-04
2025-11-09 16:53:06,533 - INFO - root - Page:0, Index:2, Outlier-Aware Post-Training Quantization for Image Super-Resolution, https://arxiv.org/pdf/2511.00682, 2025-11-01
2025-11-09 16:53:06,534 - INFO - root - Page:0, Index:3, Evaluation of Wafer-Scale SOT-MRAM for Analog Crossbar Array Applications, https://arxiv.org/pdf/2510.25853, 2025-11-03
2025-11-09 16:53:06,534 - INFO - root - Page:0, Index:4, Improving the Straight-Through Estimator with Zeroth-Order Information, https://arxiv.org/pdf/2510.23926, 2025-10-27
2025-11-09 16:53:06,534 - INFO - root - Page:0, Index:5, Real-Time Semantic Segmentation on FPGA for Autonomous Vehicles Using LMIINet with the CGRA4ML Framework, https://arxiv.org/pdf/2510.22243, 2025-10-25
2025-11-09 16:53:06,534 - INFO - root - Page:0, Index:6, TernaryCLIP: Efficiently Compressing Vision-Language Models with Ternary Weights and Distilled Knowledge, https://arxiv.org/pdf/2510.21879, 2025-10-23
2025-11-09 16:53:06,535 - INFO - root - Page:0, Index:7, KARIPAP: Quantum-Inspired Tensor Network Compression of Large Language Models Using Infinite Projected Entangled Pair States and Tensor Renormalization Group, https://arxiv.org/pdf/2510.21844, 2025-10-22
2025-11-09 16:53:06,535 - INFO - root - Page:0, Index:8, A Convergence Analysis of Adaptive Optimizers under Floating-point Quantization, https://arxiv.org/pdf/2510.21314, 2025-10-24
2025-11-09 16:53:06,535 - INFO - root - Page:0, Index:9, Adaptive Distribution-aware Quantization for Mixed-Precision Neural Networks, https://arxiv.org/pdf/2510.19760, 2025-10-22
2025-11-09 16:53:06,536 - INFO - root - Page:0, Index:10, CAGE: Curvature-Aware Gradient Estimation For Accurate Quantization-Aware Training, https://arxiv.org/pdf/2510.18784, 2025-10-21
2025-11-09 16:53:06,536 - INFO - root - Page:0, Index:11, Mixed-Precision Quantization for Language Models: Techniques and Prospects, https://arxiv.org/pdf/2510.16805, 2025-10-19
2025-11-09 16:53:06,536 - INFO - root - Page:0, Index:12, SPLite Hand: Sparsity-Aware Lightweight 3D Hand Pose Estimation, https://arxiv.org/pdf/2510.16396, 2025-10-30
2025-11-09 16:53:06,536 - INFO - root - Page:0, Index:13, CTR-LoRA: Curvature-Aware and Trust-Region Guided Low-Rank Adaptation for Large Language Models, https://arxiv.org/pdf/2510.15962, 2025-10-11
2025-11-09 16:53:06,537 - INFO - root - Page:0, Index:14, SANR: Scene-Aware Neural Representation for Light Field Image Compression with Rate-Distortion Optimization, https://arxiv.org/pdf/2510.15775, 2025-10-17
2025-11-09 16:53:06,537 - INFO - root - Page:0, Index:15, SpikeFit: Towards Optimal Deployment of Spiking Networks on Neuromorphic Hardware, https://arxiv.org/pdf/2510.15542, 2025-10-31
2025-11-09 16:53:06,537 - INFO - root - Page:0, Index:16, GRank: Towards Target-Aware and Streamlined Industrial Retrieval with a Generate-Rank Framework, https://arxiv.org/pdf/2510.15299, 2025-10-17
2025-11-09 16:53:06,538 - INFO - root - Page:0, Index:17, SaLon3R: Structure-aware Long-term Generalizable 3D Reconstruction from Unposed Images, https://arxiv.org/pdf/2510.15072, 2025-10-16
2025-11-09 16:53:06,538 - INFO - root - Page:0, Index:18, FraQAT: Quantization Aware Training with Fractional bits, https://arxiv.org/pdf/2510.14823, 2025-10-16
2025-11-09 16:53:06,540 - INFO - root - Page:0, Index:19, Computing-In-Memory Aware Model Adaption For Edge Devices, https://arxiv.org/pdf/2510.14379, 2025-10-16
2025-11-09 16:53:06,540 - INFO - root - Page:0, Index:20, Invited Paper: BitMedViT: Ternary-Quantized Vision Transformer for Medical AI Assistants on the Edge, https://arxiv.org/pdf/2510.13760, 2025-11-04
2025-11-09 16:53:06,540 - INFO - root - Page:0, Index:21, NeuroRVQ: Multi-Scale EEG Tokenization for Generative Large Brainwave Models, https://arxiv.org/pdf/2510.13068, 2025-10-14
2025-11-09 16:53:06,543 - INFO - root - Page:0, Index:22, Detect Anything via Next Point Prediction, https://arxiv.org/pdf/2510.12798, 2025-10-14
2025-11-09 16:53:06,546 - INFO - root - Page:0, Index:23, AndesVL Technical Report: An Efficient Mobile-side Multimodal Large Language Model, https://arxiv.org/pdf/2510.11496, 2025-10-14
2025-11-09 16:53:06,548 - INFO - root - Page:0, Index:24, Rescaling-Aware Training for Efficient Deployment of Deep Learning Models on Full-Integer Hardware, https://arxiv.org/pdf/2510.11484, 2025-10-13
2025-11-09 16:53:06,549 - INFO - root - Page:0, Index:25, SASER: Stego attacks on open-source LLMs, https://arxiv.org/pdf/2510.10486, 2025-10-12
2025-11-09 16:53:06,550 - INFO - root - Page:0, Index:26, Ultralytics YOLO Evolution: An Overview of YOLO26, YOLO11, YOLOv8 and YOLOv5 Object Detectors for Computer Vision and Pattern Recognition, https://arxiv.org/pdf/2510.09653, 2025-10-15
2025-11-09 16:53:06,550 - INFO - root - Page:0, Index:27, A Theoretically-Grounded Codebook for Digital Semantic Communications, https://arxiv.org/pdf/2510.07108, 2025-10-14
2025-11-09 16:53:06,551 - INFO - root - Page:0, Index:28, QuantDemoire: Quantization with Outlier Aware for Image Demoiréing, https://arxiv.org/pdf/2510.04066, 2025-10-05
2025-11-09 16:53:06,552 - INFO - root - Page:0, Index:29, Adaptively Sampling-Reusing-Mixing Decomposed Gradients to Speed Up Sharpness Aware Minimization, https://arxiv.org/pdf/2510.03763, 2025-10-04
2025-11-09 16:53:06,552 - INFO - root - Page:0, Index:30, Quant-dLLM: Post-Training Extreme Low-Bit Quantization for Diffusion Large Language Models, https://arxiv.org/pdf/2510.03274, 2025-09-27
2025-11-09 16:53:06,554 - INFO - root - Page:0, Index:31, PT$^2$-LLM: Post-Training Ternarization for Large Language Models, https://arxiv.org/pdf/2510.03267, 2025-09-26
2025-11-09 16:53:06,554 - INFO - root - Page:0, Index:32, Purrception: Variational Flow Matching for Vector-Quantized Image Generation, https://arxiv.org/pdf/2510.01478, 2025-10-01
2025-11-09 16:53:06,555 - INFO - root - Page:0, Index:33, Post-Training Quantization for Audio Diffusion Transformers, https://arxiv.org/pdf/2510.00313, 2025-09-30
2025-11-09 16:53:06,556 - INFO - root - Page:0, Index:34, Rethinking RoPE Scaling in Quantized LLM: Theory, Outlier, and Channel-Band Analysis with Weight Rescaling, https://arxiv.org/pdf/2510.00028, 2025-09-25
2025-11-09 16:53:06,557 - INFO - root - Page:0, Index:35, Post-Training Quantization via Residual Truncation and Zero Suppression for Diffusion Models, https://arxiv.org/pdf/2509.26436, 2025-09-30
2025-11-09 16:53:06,558 - INFO - root - Page:0, Index:36, Cat: Post-Training Quantization Error Reduction via Cluster-based Affine Transformation, https://arxiv.org/pdf/2509.26277, 2025-10-07
2025-11-09 16:53:06,558 - INFO - root - Page:0, Index:37, CAST: Continuous and Differentiable Semi-Structured Sparsity-Aware Training for Large Language Models, https://arxiv.org/pdf/2509.25996, 2025-09-30
2025-11-09 16:53:06,559 - INFO - root - Page:0, Index:38, Norm-Q: Effective Compression Method for Hidden Markov Models in Neuro-Symbolic Applications, https://arxiv.org/pdf/2509.25439, 2025-09-29
2025-11-09 16:53:06,561 - INFO - root - Page:0, Index:39, On-the-Fly Adaptation to Quantization: Configuration-Aware LoRA for Efficient Fine-Tuning of Quantized LLMs, https://arxiv.org/pdf/2509.25214, 2025-09-22
2025-11-09 16:53:06,566 - INFO - root - Page:0, Index:40, VoxCPM: Tokenizer-Free TTS for Context-Aware Speech Generation and True-to-Life Voice Cloning, https://arxiv.org/pdf/2509.24650, 2025-09-29
2025-11-09 16:53:06,567 - INFO - root - Page:0, Index:41, S$^2$NN: Sub-bit Spiking Neural Networks, https://arxiv.org/pdf/2509.24266, 2025-10-24
2025-11-09 16:53:06,568 - INFO - root - Page:0, Index:42, Tequila: Trapping-free Ternary Quantization for Large Language Models, https://arxiv.org/pdf/2509.23809, 2025-10-17
2025-11-09 16:53:06,568 - INFO - root - Page:0, Index:43, Texture Vector-Quantization and Reconstruction Aware Prediction for Generative Super-Resolution, https://arxiv.org/pdf/2509.23774, 2025-09-30
2025-11-09 16:53:06,568 - INFO - root - Page:0, Index:44, RobuQ: Pushing DiTs to W1.58A2 via Robust Activation Quantization, https://arxiv.org/pdf/2509.23582, 2025-09-27
2025-11-09 16:53:06,568 - INFO - root - Page:0, Index:45, Beyond Outliers: A Study of Optimizers Under Quantization, https://arxiv.org/pdf/2509.23500, 2025-10-02
2025-11-09 16:53:06,569 - INFO - root - Page:0, Index:46, Compute-Optimal Quantization-Aware Training, https://arxiv.org/pdf/2509.22935, 2025-09-26
2025-11-09 16:53:06,569 - INFO - root - Page:0, Index:47, COSPADI: Compressing LLMs via Calibration-Guided Sparse Dictionary Learning, https://arxiv.org/pdf/2509.22075, 2025-10-06
2025-11-09 16:53:06,569 - INFO - root - Page:0, Index:48, SlimDiff: Training-Free, Activation-Guided Hands-free Slimming of Diffusion Models, https://arxiv.org/pdf/2509.21498, 2025-09-25
2025-11-09 16:53:06,571 - INFO - root - Page:0, Index:49, Quantized Visual Geometry Grounded Transformer, https://arxiv.org/pdf/2509.21302, 2025-09-29
2025-11-09 16:53:06,584 - INFO - root - Fetching page 2 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=50
2025-11-09 16:53:08,300 - INFO - root - get_all_titles_from_web 
2025-11-09 16:53:08,300 - INFO - root - Page:1, Index:0, Can Less Precise Be More Reliable? A Systematic Evaluation of Quantization's Impact on CLIP Beyond Accuracy, https://arxiv.org/pdf/2509.21173, 2025-10-27
2025-11-09 16:53:08,300 - INFO - root - Page:1, Index:1, Punching Above Precision: Small Quantized Model Distillation with Learnable Regularizer, https://arxiv.org/pdf/2509.20854, 2025-09-25
2025-11-09 16:53:08,301 - INFO - root - Page:1, Index:2, TinyEcoWeedNet: Edge Efficient Real-Time Aerial Agricultural Weed Detection, https://arxiv.org/pdf/2509.18193, 2025-09-19
2025-11-09 16:53:08,301 - INFO - root - Page:1, Index:3, SBVR: Summation of BitVector Representation for Efficient LLM Quantization, https://arxiv.org/pdf/2509.18172, 2025-09-17
2025-11-09 16:53:08,301 - INFO - root - Page:1, Index:4, QWHA: Quantization-Aware Walsh-Hadamard Adaptation for Parameter-Efficient Fine-Tuning on Large Language Models, https://arxiv.org/pdf/2509.17428, 2025-09-26
2025-11-09 16:53:08,302 - INFO - root - Page:1, Index:5, PTQTP: Post-Training Quantization to Trit-Planes for Large Language Models, https://arxiv.org/pdf/2509.16989, 2025-10-28
2025-11-09 16:53:08,302 - INFO - root - Page:1, Index:6, MEC-Quant: Maximum Entropy Coding for Extremely Low Bit Quantization-Aware Training, https://arxiv.org/pdf/2509.15514, 2025-09-18
2025-11-09 16:53:08,302 - INFO - root - Page:1, Index:7, Q-ROAR: Outlier-Aware Rescaling for RoPE Position Interpolation in Quantized Long-Context LLMs, https://arxiv.org/pdf/2509.14391, 2025-09-17
2025-11-09 16:53:08,303 - INFO - root - Page:1, Index:8, Efficient Quantization-Aware Neural Receivers: Beyond Post-Training Quantization, https://arxiv.org/pdf/2509.13786, 2025-09-19
2025-11-09 16:53:08,303 - INFO - root - Page:1, Index:9, Rate-Distortion Limits for Multimodal Retrieval: Theory, Optimal Codes, and Finite-Sample Guarantees, https://arxiv.org/pdf/2509.11054, 2025-09-13
2025-11-09 16:53:08,303 - INFO - root - Page:1, Index:10, SQAP-VLA: A Synergistic Quantization-Aware Pruning Framework for High-Performance Vision-Language-Action Models, https://arxiv.org/pdf/2509.09090, 2025-09-10
2025-11-09 16:53:08,304 - INFO - root - Page:1, Index:11, CSI Compression Beyond Latents: End-to-End Hybrid Attention-CNN Networks with Entropy Regularization, https://arxiv.org/pdf/2509.08776, 2025-09-10
2025-11-09 16:53:08,304 - INFO - root - Page:1, Index:12, Explaining How Quantization Disparately Skews a Model, https://arxiv.org/pdf/2509.07222, 2025-09-08
2025-11-09 16:53:08,304 - INFO - root - Page:1, Index:13, LoaQ: Layer-wise Output Approximation Quantization, https://arxiv.org/pdf/2509.06297, 2025-09-07
2025-11-09 16:53:08,304 - INFO - root - Page:1, Index:14, FineServe: Precision-Aware KV Slab and Two-Level Scheduling for Heterogeneous Precision LLM Serving, https://arxiv.org/pdf/2509.06261, 2025-09-14
2025-11-09 16:53:08,305 - INFO - root - Page:1, Index:15, Sensitivity-Aware Post-Training Quantization for Deep Neural Networks, https://arxiv.org/pdf/2509.05576, 2025-09-05
2025-11-09 16:53:08,306 - INFO - root - Page:1, Index:16, SuperSNN: A Hardware-Aware Framework for Physically Realizable, High-Performance Superconducting Spiking Neural Network Chips, https://arxiv.org/pdf/2509.05532, 2025-09-05
2025-11-09 16:53:08,306 - INFO - root - Page:1, Index:17, Data-Augmented Quantization-Aware Knowledge Distillation, https://arxiv.org/pdf/2509.03850, 2025-09-03
2025-11-09 16:53:08,308 - INFO - root - Page:1, Index:18, DPQuant: Efficient and Differentially-Private Model Training via Dynamic Quantization Scheduling, https://arxiv.org/pdf/2509.03472, 2025-09-03
2025-11-09 16:53:08,309 - INFO - root - Page:1, Index:19, Empowering Large Language Model for Sequential Recommendation via Multimodal Embeddings and Semantic IDs, https://arxiv.org/pdf/2509.02017, 2025-09-02
2025-11-09 16:53:08,309 - INFO - root - Page:1, Index:20, Q-Sched: Pushing the Boundaries of Few-Step Diffusion Models with Quantization-Aware Scheduling, https://arxiv.org/pdf/2509.01624, 2025-09-01
2025-11-09 16:53:08,310 - INFO - root - Page:1, Index:21, Quantization Meets OOD: Generalizable Quantization-aware Training from a Flatness Perspective, https://arxiv.org/pdf/2509.00859, 2025-08-31
2025-11-09 16:53:08,311 - INFO - root - Page:1, Index:22, Progressive Element-wise Gradient Estimation for Neural Network Quantization, https://arxiv.org/pdf/2509.00097, 2025-08-27
2025-11-09 16:53:08,312 - INFO - root - Page:1, Index:23, End-to-End On-Device Quantization-Aware Training for LLMs at Inference Cost, https://arxiv.org/pdf/2509.00031, 2025-09-29
2025-11-09 16:53:08,318 - INFO - root - Page:1, Index:24, Quantization Robustness to Input Degradations for Object Detection, https://arxiv.org/pdf/2508.19600, 2025-08-27
2025-11-09 16:53:08,322 - INFO - root - Page:1, Index:25, Scaling Laws for Task-Stratified Knowledge in Post-Training Quantized Large Language Models, https://arxiv.org/pdf/2508.18609, 2025-08-27
2025-11-09 16:53:08,323 - INFO - root - Page:1, Index:26, AQ-PCDSys: An Adaptive Quantized Planetary Crater Detection System for Autonomous Space Exploration, https://arxiv.org/pdf/2508.18025, 2025-08-25
2025-11-09 16:53:08,323 - INFO - root - Page:1, Index:27, TaDiCodec: Text-aware Diffusion Speech Tokenizer for Speech Language Modeling, https://arxiv.org/pdf/2508.16790, 2025-08-22
2025-11-09 16:53:08,323 - INFO - root - Page:1, Index:28, A Node-Aware Dynamic Quantization Approach for Graph Collaborative Filtering, https://arxiv.org/pdf/2508.16516, 2025-08-22
2025-11-09 16:53:08,325 - INFO - root - Page:1, Index:29, JEDI-linear: Fast and Efficient Graph Neural Networks for Jet Tagging on FPGAs, https://arxiv.org/pdf/2508.15468, 2025-08-21
2025-11-09 16:53:08,325 - INFO - root - Page:1, Index:30, MMQ: Multimodal Mixture-of-Quantization Tokenization for Semantic ID Generation and User Behavioral Adaptation, https://arxiv.org/pdf/2508.15281, 2025-08-21
2025-11-09 16:53:08,325 - INFO - root - Page:1, Index:31, DLLMQuant: Quantizing Diffusion-based Large Language Models, https://arxiv.org/pdf/2508.14090, 2025-08-25
2025-11-09 16:53:08,326 - INFO - root - Page:1, Index:32, Automated Energy-Aware Time-Series Model Deployment on Embedded FPGAs for Resilient Combined Sewer Overflow Management, https://arxiv.org/pdf/2508.13905, 2025-08-19
2025-11-09 16:53:08,333 - INFO - root - Page:1, Index:33, XR-NPE: High-Throughput Mixed-precision SIMD Neural Processing Engine for Extended Reality Perception Workloads, https://arxiv.org/pdf/2508.13049, 2025-08-18
2025-11-09 16:53:08,334 - INFO - root - Page:1, Index:34, Exploring Self-Supervised Audio Models for Generalized Anomalous Sound Detection, https://arxiv.org/pdf/2508.12230, 2025-08-17
2025-11-09 16:53:08,336 - INFO - root - Page:1, Index:35, TriQDef: Disrupting Semantic and Gradient Alignment to Prevent Adversarial Patch Transferability in Quantized Neural Networks, https://arxiv.org/pdf/2508.12132, 2025-08-16
2025-11-09 16:53:08,336 - INFO - root - Page:1, Index:36, Error Propagation Mechanisms and Compensation Strategies for Quantized Diffusion, https://arxiv.org/pdf/2508.12094, 2025-10-13
2025-11-09 16:53:08,338 - INFO - root - Page:1, Index:37, Extending Straight-Through Estimation for Robust Neural Networks on Analog CIM Hardware, https://arxiv.org/pdf/2508.11940, 2025-08-16
2025-11-09 16:53:08,339 - INFO - root - Page:1, Index:38, PTQAT: A Hybrid Parameter-Efficient Quantization Algorithm for 3D Perception Tasks, https://arxiv.org/pdf/2508.10557, 2025-08-15
2025-11-09 16:53:08,356 - INFO - root - Page:1, Index:39, MiCo: End-to-End Mixed Precision Neural Network Co-Exploration Framework for Edge AI, https://arxiv.org/pdf/2508.09500, 2025-08-13
2025-11-09 16:53:08,356 - INFO - root - Page:1, Index:40, SPARC: Soft Probabilistic Adaptive multi-interest Retrieval Model via Codebooks for recommender system, https://arxiv.org/pdf/2508.09090, 2025-08-12
2025-11-09 16:53:08,357 - INFO - root - Page:1, Index:41, Rethinking 1-bit Optimization Leveraging Pre-trained Large Language Models, https://arxiv.org/pdf/2508.06974, 2025-08-09
2025-11-09 16:53:08,357 - INFO - root - Page:1, Index:42, Efficient Deep Neural Receiver with Post-Training Quantization, https://arxiv.org/pdf/2508.06275, 2025-08-08
2025-11-09 16:53:08,357 - INFO - root - Page:1, Index:43, iFairy: the First 2-bit Complex LLM with All Parameters in $\{\pm1, \pm i\}$, https://arxiv.org/pdf/2508.05571, 2025-08-16
2025-11-09 16:53:08,358 - INFO - root - Page:1, Index:44, S$^2$Q-VDiT: Accurate Quantized Video Diffusion Transformer with Salient Data and Sparse Token Distillation, https://arxiv.org/pdf/2508.04016, 2025-10-27
2025-11-09 16:53:08,360 - INFO - root - Page:1, Index:45, LRQ-DiT: Log-Rotation Post-Training Quantization of Diffusion Transformers for Image and Video Generation, https://arxiv.org/pdf/2508.03485, 2025-09-23
2025-11-09 16:53:08,361 - INFO - root - Page:1, Index:46, VLMQ: Efficient Post-Training Quantization for Large Vision-Language Models via Hessian Augmentation, https://arxiv.org/pdf/2508.03351, 2025-08-05
2025-11-09 16:53:08,361 - INFO - root - Page:1, Index:47, TF-MLPNet: Tiny Real-Time Neural Speech Separation, https://arxiv.org/pdf/2508.03047, 2025-08-04
2025-11-09 16:53:08,361 - INFO - root - Page:1, Index:48, SaviorRec: Semantic-Behavior Alignment for Cold-Start Recommendation, https://arxiv.org/pdf/2508.01375, 2025-08-02
2025-11-09 16:53:08,363 - INFO - root - Page:1, Index:49, MixA-Q: Revisiting Activation Sparsity for Vision Transformers from a Mixed-Precision Quantization Perspective, https://arxiv.org/pdf/2507.19131, 2025-07-25
2025-11-09 16:53:08,363 - INFO - root - Fetching page 3 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=100
2025-11-09 16:53:10,328 - INFO - root - get_all_titles_from_web 
2025-11-09 16:53:10,329 - INFO - root - Page:2, Index:0, Enhancing Quantization-Aware Training on Edge Devices via Relative Entropy Coreset Selection and Cascaded Layer Correction, https://arxiv.org/pdf/2507.17768, 2025-07-16
2025-11-09 16:53:10,329 - INFO - root - Page:2, Index:1, SiLQ: Simple Large Language Model Quantization-Aware Training, https://arxiv.org/pdf/2507.16933, 2025-07-22
2025-11-09 16:53:10,330 - INFO - root - Page:2, Index:2, Task-Specific Zero-shot Quantization-Aware Training for Object Detection, https://arxiv.org/pdf/2507.16782, 2025-07-22
2025-11-09 16:53:10,330 - INFO - root - Page:2, Index:3, TorchAO: PyTorch-Native Training-to-Serving Model Optimization, https://arxiv.org/pdf/2507.16099, 2025-07-21
2025-11-09 16:53:10,331 - INFO - root - Page:2, Index:4, SegQuant: A Semantics-Aware and Generalizable Quantization Framework for Diffusion Models, https://arxiv.org/pdf/2507.14811, 2025-08-27
2025-11-09 16:53:10,332 - INFO - root - Page:2, Index:5, Apple Intelligence Foundation Language Models: Tech Report 2025, https://arxiv.org/pdf/2507.13575, 2025-08-27
2025-11-09 16:53:10,333 - INFO - root - Page:2, Index:6, Generative Multi-Target Cross-Domain Recommendation, https://arxiv.org/pdf/2507.12871, 2025-08-07
2025-11-09 16:53:10,334 - INFO - root - Page:2, Index:7, DAF: An Efficient End-to-End Dynamic Activation Framework for on-Device DNN Training, https://arxiv.org/pdf/2507.07149, 2025-07-09
2025-11-09 16:53:10,335 - INFO - root - Page:2, Index:8, Opto-ViT: Architecting a Near-Sensor Region of Interest-Aware Vision Transformer Accelerator with Silicon Photonics, https://arxiv.org/pdf/2507.07044, 2025-07-15
2025-11-09 16:53:10,336 - INFO - root - Page:2, Index:9, QS4D: Quantization-aware training for efficient hardware deployment of structured state-space sequential models, https://arxiv.org/pdf/2507.06079, 2025-07-08
2025-11-09 16:53:10,336 - INFO - root - Page:2, Index:10, GSVR: 2D Gaussian-based Video Representation for 800+ FPS with Hybrid Deformation Field, https://arxiv.org/pdf/2507.05594, 2025-07-07
2025-11-09 16:53:10,340 - INFO - root - Page:2, Index:11, Hita: Holistic Tokenizer for Autoregressive Image Generation, https://arxiv.org/pdf/2507.02358, 2025-07-11
2025-11-09 16:53:10,341 - INFO - root - Page:2, Index:12, QPART: Adaptive Model Quantization and Dynamic Workload Balancing for Accuracy-aware Edge Inference, https://arxiv.org/pdf/2506.23934, 2025-06-30
2025-11-09 16:53:10,342 - INFO - root - Page:2, Index:13, FedWSQ: Efficient Federated Learning with Weight Standardization and Distribution-Aware Non-Uniform Quantization, https://arxiv.org/pdf/2506.23516, 2025-07-21
2025-11-09 16:53:10,347 - INFO - root - Page:2, Index:14, Spectra 1.1: Scaling Laws and Efficient Inference for Ternary Language Models, https://arxiv.org/pdf/2506.23025, 2025-06-28
2025-11-09 16:53:10,349 - INFO - root - Page:2, Index:15, Joint Quantization and Pruning Neural Networks Approach: A Case Study on FSO Receivers, https://arxiv.org/pdf/2506.20084, 2025-06-24
2025-11-09 16:53:10,374 - INFO - root - Page:2, Index:16, Single-step Diffusion for Image Compression at Ultra-Low Bitrates, https://arxiv.org/pdf/2506.16572, 2025-09-22
2025-11-09 16:53:10,389 - INFO - root - Page:2, Index:17, LittleBit: Ultra Low-Bit Quantization via Latent Factorization, https://arxiv.org/pdf/2506.13771, 2025-10-28
2025-11-09 16:53:10,394 - INFO - root - Page:2, Index:18, MARCO: Hardware-Aware Neural Architecture Search for Edge Devices with Multi-Agent Reinforcement Learning and Conformal Prediction Filtering, https://arxiv.org/pdf/2506.13755, 2025-06-16
2025-11-09 16:53:10,396 - INFO - root - Page:2, Index:19, EAQuant: Enhancing Post-Training Quantization for MoE Models via Expert-Aware Optimization, https://arxiv.org/pdf/2506.13329, 2025-07-04
2025-11-09 16:53:10,397 - INFO - root - Page:2, Index:20, Towards Neural Audio Codec Source Parsing, https://arxiv.org/pdf/2506.12627, 2025-06-14
2025-11-09 16:53:10,397 - INFO - root - Page:2, Index:21, Quantizing Small-Scale State-Space Models for Edge AI, https://arxiv.org/pdf/2506.12480, 2025-06-14
2025-11-09 16:53:10,398 - INFO - root - Page:2, Index:22, EMLoC: Emulator-based Memory-efficient Fine-tuning with LoRA Correction, https://arxiv.org/pdf/2506.12015, 2025-06-13
2025-11-09 16:53:10,399 - INFO - root - Page:2, Index:23, Compression Aware Certified Training, https://arxiv.org/pdf/2506.11992, 2025-06-13
2025-11-09 16:53:10,404 - INFO - root - Page:2, Index:24, GPLQ: A General, Practical, and Lightning QAT Method for Vision Transformers, https://arxiv.org/pdf/2506.11784, 2025-06-13
2025-11-09 16:53:10,414 - INFO - root - Page:2, Index:25, TruncQuant: Truncation-Ready Quantization for DNNs with Flexible Weight Bit Precision, https://arxiv.org/pdf/2506.11431, 2025-06-12
2025-11-09 16:53:10,415 - INFO - root - Page:2, Index:26, EfficientQuant: An Efficient Post-Training Quantization for CNN-Transformer Hybrid Models on Edge Devices, https://arxiv.org/pdf/2506.11093, 2025-06-05
2025-11-09 16:53:10,415 - INFO - root - Page:2, Index:27, Starting Positions Matter: A Study on Better Weight Initialization for Neural Network Quantization, https://arxiv.org/pdf/2506.10463, 2025-06-12
2025-11-09 16:53:10,419 - INFO - root - Page:2, Index:28, AWP: Activation-Aware Weight Pruning and Quantization with Projected Gradient Descent, https://arxiv.org/pdf/2506.10205, 2025-06-11
2025-11-09 16:53:10,420 - INFO - root - Page:2, Index:29, Q-SAM2: Accurate Quantization for Segment Anything Model 2, https://arxiv.org/pdf/2506.09782, 2025-06-11
2025-11-09 16:53:10,421 - INFO - root - Page:2, Index:30, Unifying Block-wise PTQ and Distillation-based QAT for Progressive Quantization toward 2-bit Instruction-Tuned LLMs, https://arxiv.org/pdf/2506.09104, 2025-06-10
2025-11-09 16:53:10,422 - INFO - root - Page:2, Index:31, Implementing Keyword Spotting on the MCUX947 Microcontroller with Integrated NPU, https://arxiv.org/pdf/2506.08911, 2025-06-10
2025-11-09 16:53:10,422 - INFO - root - Page:2, Index:32, POLARON: Precision-aware On-device Learning and Adaptive Runtime-cONfigurable AI acceleration, https://arxiv.org/pdf/2506.08785, 2025-06-10
2025-11-09 16:53:10,424 - INFO - root - Page:2, Index:33, MoQAE: Mixed-Precision Quantization for Long-Context LLM Inference via Mixture of Quantization-Aware Experts, https://arxiv.org/pdf/2506.07533, 2025-06-09
2025-11-09 16:53:10,425 - INFO - root - Page:2, Index:34, BitVLA: 1-bit Vision-Language-Action Models for Robotics Manipulation, https://arxiv.org/pdf/2506.07530, 2025-06-09
2025-11-09 16:53:10,425 - INFO - root - Page:2, Index:35, RecGPT: A Foundation Model for Sequential Recommendation, https://arxiv.org/pdf/2506.06270, 2025-06-12
2025-11-09 16:53:10,428 - INFO - root - Page:2, Index:36, FPSAttention: Training-Aware FP8 and Sparsity Co-Design for Fast Video Diffusion, https://arxiv.org/pdf/2506.04648, 2025-06-05
2025-11-09 16:53:10,429 - INFO - root - Page:2, Index:37, BitTTS: Highly Compact Text-to-Speech Using 1.58-bit Quantization and Weight Indexing, https://arxiv.org/pdf/2506.03515, 2025-06-03
2025-11-09 16:53:10,438 - INFO - root - Page:2, Index:38, ShapeLLM-Omni: A Native Multimodal LLM for 3D Generation and Understanding, https://arxiv.org/pdf/2506.01853, 2025-06-02
2025-11-09 16:53:10,440 - INFO - root - Page:2, Index:39, Movable Antenna Enhanced Federated Fine-Tuning of Large Language Models via Hybrid Client Selection Optimization, https://arxiv.org/pdf/2506.00011, 2025-10-26
2025-11-09 16:53:10,441 - INFO - root - Page:2, Index:40, Running Conventional Automatic Speech Recognition on Memristor Hardware: A Simulated Approach, https://arxiv.org/pdf/2505.24721, 2025-05-30
2025-11-09 16:53:10,441 - INFO - root - Page:2, Index:41, GARLIC: GAussian Representation LearnIng for spaCe partitioning, https://arxiv.org/pdf/2505.24608, 2025-10-02
2025-11-09 16:53:10,442 - INFO - root - Page:2, Index:42, AutoChemSchematic AI: Agentic Physics-Aware Automation for Chemical Manufacturing Scale-Up, https://arxiv.org/pdf/2505.24584, 2025-08-18
2025-11-09 16:53:10,446 - INFO - root - Page:2, Index:43, Model-Preserving Adaptive Rounding, https://arxiv.org/pdf/2505.22988, 2025-09-25
2025-11-09 16:53:10,452 - INFO - root - Page:2, Index:44, Highly Efficient and Effective LLMs with Multi-Boolean Architectures, https://arxiv.org/pdf/2505.22811, 2025-10-03
2025-11-09 16:53:10,458 - INFO - root - Page:2, Index:45, Pioneering 4-Bit FP Quantization for Diffusion Models: Mixup-Sign Quantization and Timestep-Aware Fine-Tuning, https://arxiv.org/pdf/2505.21591, 2025-05-27
2025-11-09 16:53:10,460 - INFO - root - Page:2, Index:46, Frequency Composition for Compressed and Domain-Adaptive Neural Networks, https://arxiv.org/pdf/2505.20890, 2025-05-27
2025-11-09 16:53:10,475 - INFO - root - Page:2, Index:47, MoPFormer: Motion-Primitive Transformer for Wearable-Sensor Activity Recognition, https://arxiv.org/pdf/2505.20744, 2025-10-27
2025-11-09 16:53:10,476 - INFO - root - Page:2, Index:48, Optimizing edge AI models on HPC systems with the edge in the loop, https://arxiv.org/pdf/2505.19995, 2025-05-26
2025-11-09 16:53:10,480 - INFO - root - Fetching page 4 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=150
2025-11-09 16:53:12,568 - INFO - root - get_all_titles_from_web 
2025-11-09 16:53:12,569 - INFO - root - Page:3, Index:0, DPASyn: Mechanism-Aware Drug Synergy Prediction via Dual Attention and Precision-Aware Quantization, https://arxiv.org/pdf/2505.19144, 2025-09-20
2025-11-09 16:53:12,569 - INFO - root - Page:3, Index:1, Reducing Storage of Pretrained Neural Networks by Rate-Constrained Quantization and Entropy Coding, https://arxiv.org/pdf/2505.18758, 2025-05-24
2025-11-09 16:53:12,570 - INFO - root - Page:3, Index:2, Beyond Discreteness: Finite-Sample Analysis of Straight-Through Estimator for Quantization, https://arxiv.org/pdf/2505.18113, 2025-05-23
2025-11-09 16:53:12,570 - INFO - root - Page:3, Index:3, Automating Versatile Time-Series Analysis with Tiny Transformers on Embedded FPGAs, https://arxiv.org/pdf/2505.17662, 2025-09-19
2025-11-09 16:53:12,571 - INFO - root - Page:3, Index:4, FPQVAR: Floating Point Quantization for Visual Autoregressive Model with FPGA Hardware Co-design, https://arxiv.org/pdf/2505.16335, 2025-05-22
2025-11-09 16:53:12,573 - INFO - root - Page:3, Index:5, Saliency-Aware Quantized Imitation Learning for Efficient Robotic Control, https://arxiv.org/pdf/2505.15304, 2025-05-30
2025-11-09 16:53:12,575 - INFO - root - Page:3, Index:6, Scaling Law for Quantization-Aware Training, https://arxiv.org/pdf/2505.14302, 2025-05-20
2025-11-09 16:53:12,579 - INFO - root - Page:3, Index:7, Automatic mixed precision for optimizing gained time with constrained loss mean-squared-error based on model partition to sequential sub-graphs, https://arxiv.org/pdf/2505.13060, 2025-05-19
2025-11-09 16:53:12,580 - INFO - root - Page:3, Index:8, Deep Unfolding with Kernel-based Quantization in MIMO Detection, https://arxiv.org/pdf/2505.12736, 2025-05-19
2025-11-09 16:53:12,580 - INFO - root - Page:3, Index:9, FedHQ: Hybrid Runtime Quantization for Federated Learning, https://arxiv.org/pdf/2505.11982, 2025-05-17
2025-11-09 16:53:12,581 - INFO - root - Page:3, Index:10, QVGen: Pushing the Limit of Quantized Video Generative Models, https://arxiv.org/pdf/2505.11497, 2025-09-27
2025-11-09 16:53:12,582 - INFO - root - Page:3, Index:11, EA-3DGS: Efficient and Adaptive 3D Gaussians with Highly Enhanced Quality for outdoor scenes, https://arxiv.org/pdf/2505.10787, 2025-05-15
2025-11-09 16:53:12,583 - INFO - root - Page:3, Index:12, ITERA-LLM: Boosting Sub-8-Bit Large Language Model Inference via Iterative Tensor Decomposition, https://arxiv.org/pdf/2505.08981, 2025-05-13
2025-11-09 16:53:12,595 - INFO - root - Page:3, Index:13, PROM: Prioritize Reduction of Multiplications Over Lower Bit-Widths for Efficient CNNs, https://arxiv.org/pdf/2505.03254, 2025-08-06
2025-11-09 16:53:12,599 - INFO - root - Page:3, Index:14, ICQuant: Index Coding enables Low-bit LLM Quantization, https://arxiv.org/pdf/2505.00850, 2025-08-24
2025-11-09 16:53:12,606 - INFO - root - Page:3, Index:15, Enhancing Ultra-Low-Bit Quantization of Large Language Models Through Saliency-Aware Partial Retraining, https://arxiv.org/pdf/2504.13932, 2025-07-30
2025-11-09 16:53:12,609 - INFO - root - Page:3, Index:16, Achieving binary weight and activation for LLMs using Post-Training Quantization, https://arxiv.org/pdf/2504.05352, 2025-06-30
2025-11-09 16:53:12,610 - INFO - root - Page:3, Index:17, Wireless Hearables With Programmable Speech AI Accelerators, https://arxiv.org/pdf/2503.18698, 2025-10-21
2025-11-09 16:53:12,611 - INFO - root - Page:3, Index:18, GranQ: Efficient Channel-wise Quantization via Vectorized Pre-Scaling for Zero-Shot QAT, https://arxiv.org/pdf/2503.18339, 2025-10-15
2025-11-09 16:53:12,611 - INFO - root - Page:3, Index:19, CompMarkGS: Robust Watermarking for Compressed 3D Gaussian Splatting, https://arxiv.org/pdf/2503.12836, 2025-09-29
2025-11-09 16:53:12,612 - INFO - root - Page:3, Index:20, AHCPTQ: Accurate and Hardware-Compatible Post-Training Quantization for Segment Anything Model, https://arxiv.org/pdf/2503.03088, 2025-07-11
2025-11-09 16:53:12,612 - INFO - root - Page:3, Index:21, Teaching Metric Distance to Discrete Autoregressive Language Models, https://arxiv.org/pdf/2503.02379, 2025-10-07
2025-11-09 16:53:12,615 - INFO - root - Page:3, Index:22, Regularization-based Framework for Quantization-, Fault- and Variability-Aware Training, https://arxiv.org/pdf/2503.01297, 2025-07-12
2025-11-09 16:53:12,616 - INFO - root - Fetching page 5 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=200
2025-11-09 16:53:14,317 - INFO - root - get_all_titles_from_web 
2025-11-09 16:53:14,317 - INFO - root - Page:4, Index:0, Investigating the Impact of Quantization Methods on the Safety and Reliability of Large Language Models, https://arxiv.org/pdf/2502.15799, 2025-06-29
2025-11-09 16:53:14,318 - INFO - root - Page:4, Index:1, Rotate, Clip, and Partition: Towards W2A4KV4 Quantization by Integrating Rotation and Learnable Non-uniform Quantizer, https://arxiv.org/pdf/2502.15779, 2025-09-01
2025-11-09 16:53:14,318 - INFO - root - Page:4, Index:2, RoSTE: An Efficient Quantization-Aware Supervised Fine-Tuning Approach for Large Language Models, https://arxiv.org/pdf/2502.09003, 2025-06-05
2025-11-09 16:53:14,318 - INFO - root - Page:4, Index:3, Spatial Degradation-Aware and Temporal Consistent Diffusion Model for Compressed Video Super-Resolution, https://arxiv.org/pdf/2502.07381, 2025-06-27
2025-11-09 16:53:14,319 - INFO - root - Page:4, Index:4, QuEST: Stable Training of LLMs with 1-Bit Weights and Activations, https://arxiv.org/pdf/2502.05003, 2025-06-10
2025-11-09 16:53:14,319 - INFO - root - Page:4, Index:5, HALO: Hadamard-Assisted Lower-Precision Optimization for LLMs, https://arxiv.org/pdf/2501.02625, 2025-11-05
2025-11-09 16:53:14,320 - INFO - root - Page:4, Index:6, TAR3D: Creating High-Quality 3D Assets via Next-Part Prediction, https://arxiv.org/pdf/2412.16919, 2025-08-08
2025-11-09 16:53:14,321 - INFO - root - Page:4, Index:7, Training Multi-Layer Binary Neural Networks With Local Binary Error Signals, https://arxiv.org/pdf/2412.00119, 2025-08-05
2025-11-09 16:53:14,321 - INFO - root - Page:4, Index:8, Scaling Large-scale GNN Training to Thousands of Processors on CPU-based Supercomputers, https://arxiv.org/pdf/2411.16025, 2025-05-26
2025-11-09 16:53:14,321 - INFO - root - Page:4, Index:9, HAFLQ: Heterogeneous Adaptive Federated LoRA Fine-tuned LLM with Quantization, https://arxiv.org/pdf/2411.06581, 2025-05-16
2025-11-09 16:53:14,322 - INFO - root - Fetching page 6 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=250
2025-11-09 16:53:16,346 - INFO - root - get_all_titles_from_web 
2025-11-09 16:53:16,346 - INFO - root - Page:5, Index:0, Gradient-Free Training of Quantized Neural Networks, https://arxiv.org/pdf/2410.09734, 2025-09-29
2025-11-09 16:53:16,347 - INFO - root - Page:5, Index:1, QT-DoG: Quantization-aware Training for Domain Generalization, https://arxiv.org/pdf/2410.06020, 2025-06-26
2025-11-09 16:53:16,347 - INFO - root - Page:5, Index:2, Constraint Guided Model Quantization of Neural Networks, https://arxiv.org/pdf/2409.20138, 2025-09-12
2025-11-09 16:53:16,347 - INFO - root - Page:5, Index:3, Accumulator-Aware Post-Training Quantization for Large Language Models, https://arxiv.org/pdf/2409.17092, 2025-07-30
2025-11-09 16:53:16,348 - INFO - root - Page:5, Index:4, DilateQuant: Accurate and Efficient Diffusion Quantization via Weight Dilation, https://arxiv.org/pdf/2409.14307, 2025-07-09
2025-11-09 16:53:16,348 - INFO - root - Page:5, Index:5, Robust Training of Neural Networks at Arbitrary Precision and Sparsity, https://arxiv.org/pdf/2409.09245, 2025-09-23
2025-11-09 16:53:16,348 - INFO - root - Page:5, Index:6, VQ-CTAP: Cross-Modal Fine-Grained Sequence Representation Learning for Speech Processing, https://arxiv.org/pdf/2408.05758, 2025-05-27
2025-11-09 16:53:16,349 - INFO - root - Page:5, Index:7, DopQ-ViT: Towards Distribution-Friendly and Outlier-Aware Post-Training Quantization for Vision Transformers, https://arxiv.org/pdf/2408.03291, 2025-06-19
2025-11-09 16:53:16,349 - INFO - root - Page:5, Index:8, Temporal Feature Matters: A Framework for Diffusion Model Quantization, https://arxiv.org/pdf/2407.19547, 2025-07-11
2025-11-09 16:53:16,349 - INFO - root - Page:5, Index:9, EfficientQAT: Efficient Quantization-Aware Training for Large Language Models, https://arxiv.org/pdf/2407.11062, 2025-05-19
2025-11-09 16:53:16,350 - INFO - root - Page:5, Index:10, Integer-only Quantized Transformers for Embedded FPGA-based Time-series Forecasting in AIoT, https://arxiv.org/pdf/2407.11041, 2025-10-31
2025-11-09 16:53:16,350 - INFO - root - Fetching page 7 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=300
2025-11-09 16:53:18,928 - INFO - root - get_all_titles_from_web 
2025-11-09 16:53:18,929 - INFO - root - Page:6, Index:0, BoA: Attention-aware Post-training Quantization without Backpropagation, https://arxiv.org/pdf/2406.13474, 2025-06-06
2025-11-09 16:53:18,929 - INFO - root - Page:6, Index:1, A Rescaling-Invariant Lipschitz Bound Based on Path-Metrics for Modern ReLU Network Parameterizations, https://arxiv.org/pdf/2405.15006, 2025-06-13
2025-11-09 16:53:18,930 - INFO - root - Page:6, Index:2, Scheduling Weight Transitions for Quantization-Aware Training, https://arxiv.org/pdf/2404.19248, 2025-10-01
2025-11-09 16:53:18,930 - INFO - root - Page:6, Index:3, GPTVQ: The Blessing of Dimensionality for LLM Quantization, https://arxiv.org/pdf/2402.15319, 2025-06-03
2025-11-09 16:53:18,930 - INFO - root - Fetching page 8 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=350
2025-11-09 16:53:21,281 - INFO - root - get_all_titles_from_web 
2025-11-09 16:53:21,281 - INFO - root - Page:7, Index:0, Squat: Quant Small Language Models on the Edge, https://arxiv.org/pdf/2402.10787, 2025-07-01
2025-11-09 16:53:21,281 - INFO - root - Page:7, Index:1, L4Q: Parameter Efficient Quantization-Aware Fine-Tuning on Large Language Models, https://arxiv.org/pdf/2402.04902, 2025-07-21
2025-11-09 16:53:21,282 - INFO - root - Fetching page 9 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=400
2025-11-09 16:53:23,427 - INFO - root - ------------------------------------------------------------------------------------------------------------------------
2025-11-09 16:53:50,568 - INFO - root - 正在总结论文 1/10: A Quantized VAE-MLP Botnet Detection Model: A Systematic Evaluation of Quantization-Aware Training and Post-Training Quantization Strategies
2025-11-09 16:54:10,990 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 16:55:27,773 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 16:56:14,124 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 16:56:14,128 - INFO - root - 正在提取论文图片...
2025-11-09 16:56:18,215 - INFO - root - 已保存图片 1/10：./export\images_A Quantized VAE-MLP Botnet Detection Model_ A Systematic Evaluation of Quantizat\figure_1_page4.png
2025-11-09 16:56:18,531 - INFO - root - 已保存图片 2/10：./export\images_A Quantized VAE-MLP Botnet Detection Model_ A Systematic Evaluation of Quantizat\figure_2_page4.png
2025-11-09 16:56:18,874 - INFO - root - 已保存图片 3/10：./export\images_A Quantized VAE-MLP Botnet Detection Model_ A Systematic Evaluation of Quantizat\figure_3_page4.png
2025-11-09 16:56:19,094 - INFO - root - 已保存图片 4/10：./export\images_A Quantized VAE-MLP Botnet Detection Model_ A Systematic Evaluation of Quantizat\figure_4_page5.png
2025-11-09 16:56:19,201 - INFO - root - 已保存图片 5/10：./export\images_A Quantized VAE-MLP Botnet Detection Model_ A Systematic Evaluation of Quantizat\figure_5_page3.png
2025-11-09 16:56:19,379 - INFO - root - 已保存图片 6/10：./export\images_A Quantized VAE-MLP Botnet Detection Model_ A Systematic Evaluation of Quantizat\figure_6_page4.png
2025-11-09 16:56:19,381 - INFO - root - 成功添加图片 1：./export\images_A Quantized VAE-MLP Botnet Detection Model_ A Systematic Evaluation of Quantizat\figure_1_page4.png
2025-11-09 16:56:19,382 - INFO - root - 成功添加图片 2：./export\images_A Quantized VAE-MLP Botnet Detection Model_ A Systematic Evaluation of Quantizat\figure_2_page4.png
2025-11-09 16:56:19,382 - INFO - root - 成功添加图片 3：./export\images_A Quantized VAE-MLP Botnet Detection Model_ A Systematic Evaluation of Quantizat\figure_3_page4.png
2025-11-09 16:56:19,383 - INFO - root - 成功添加图片 4：./export\images_A Quantized VAE-MLP Botnet Detection Model_ A Systematic Evaluation of Quantizat\figure_4_page5.png
2025-11-09 16:56:19,383 - INFO - root - 成功添加图片 5：./export\images_A Quantized VAE-MLP Botnet Detection Model_ A Systematic Evaluation of Quantizat\figure_5_page3.png
2025-11-09 16:56:19,384 - INFO - root - 成功添加图片 6：./export\images_A Quantized VAE-MLP Botnet Detection Model_ A Systematic Evaluation of Quantizat\figure_6_page4.png
2025-11-09 16:56:19,393 - INFO - root - 论文《A Quantized VAE-MLP Botnet Detection Model: A Systematic Evaluation of Quantization-Aware Training and Post-Training Quantization Strategies》的分析已保存到 ./export\A Quantized VAE-MLP Botnet Detection Model_ A Systematic Evaluation of Quantizat.md
2025-11-09 16:56:19,415 - INFO - root - 正在总结论文 2/10: FP8-Flow-MoE: A Casting-Free FP8 Recipe without Double Quantization Error
2025-11-09 16:56:42,330 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 16:56:57,262 - INFO - openai._base_client - Retrying request to /chat/completions in 0.390960 seconds
2025-11-09 16:56:59,684 - INFO - openai._base_client - Retrying request to /chat/completions in 0.900756 seconds
2025-11-09 16:57:02,610 - ERROR - root - DoubaoClient: generation error: Connection error.
Traceback (most recent call last):
  File "D:\ChatPaper\.venv\Lib\site-packages\httpx\_transports\default.py", line 101, in map_httpcore_exceptions
    yield
  File "D:\ChatPaper\.venv\Lib\site-packages\httpx\_transports\default.py", line 250, in handle_request
    resp = self._pool.handle_request(req)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\httpcore\_sync\connection_pool.py", line 256, in handle_request
    raise exc from None
  File "D:\ChatPaper\.venv\Lib\site-packages\httpcore\_sync\connection_pool.py", line 236, in handle_request
    response = connection.handle_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\httpcore\_sync\http_proxy.py", line 288, in handle_request
    connect_response = self._connection.handle_request(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\httpcore\_sync\connection.py", line 101, in handle_request
    raise exc
  File "D:\ChatPaper\.venv\Lib\site-packages\httpcore\_sync\connection.py", line 78, in handle_request
    stream = self._connect(request)
             ^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\httpcore\_sync\connection.py", line 124, in _connect
    stream = self._network_backend.connect_tcp(**kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\httpcore\_backends\sync.py", line 207, in connect_tcp
    with map_exceptions(exc_map):
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(value)
  File "D:\ChatPaper\.venv\Lib\site-packages\httpcore\_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ConnectError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "D:\ChatPaper\.venv\Lib\site-packages\openai\_base_client.py", line 982, in request
    response = self._client.send(
               ^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\httpx\_client.py", line 914, in send
    response = self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\httpx\_client.py", line 942, in _send_handling_auth
    response = self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\httpx\_client.py", line 979, in _send_handling_redirects
    response = self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\httpx\_client.py", line 1014, in _send_single_request
    response = transport.handle_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\httpx\_transports\default.py", line 249, in handle_request
    with map_httpcore_exceptions():
         ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(value)
  File "D:\ChatPaper\.venv\Lib\site-packages\httpx\_transports\default.py", line 118, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "D:\ChatPaper\llm_client_merged.py", line 632, in generate
    completion = self.client.chat.completions.create(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\openai\_utils\_utils.py", line 286, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\openai\resources\chat\completions\completions.py", line 1156, in create
    return self._post(
           ^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\openai\_base_client.py", line 1259, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\openai\_base_client.py", line 1014, in request
    raise APIConnectionError(request=request) from err
openai.APIConnectionError: Connection error.
2025-11-09 16:57:02,650 - WARNING - root - DoubaoClient: 网络连接问题 检测到，等待 60 秒后重试
2025-11-09 16:58:02,653 - INFO - root - DoubaoClient: retry attempt 2 for generation
2025-11-09 16:58:04,699 - INFO - openai._base_client - Retrying request to /chat/completions in 0.449534 seconds
2025-11-09 16:58:07,192 - INFO - openai._base_client - Retrying request to /chat/completions in 0.840435 seconds
2025-11-09 16:58:10,065 - ERROR - root - DoubaoClient: generation error: Connection error.
Traceback (most recent call last):
  File "D:\ChatPaper\.venv\Lib\site-packages\httpx\_transports\default.py", line 101, in map_httpcore_exceptions
    yield
  File "D:\ChatPaper\.venv\Lib\site-packages\httpx\_transports\default.py", line 250, in handle_request
    resp = self._pool.handle_request(req)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\httpcore\_sync\connection_pool.py", line 256, in handle_request
    raise exc from None
  File "D:\ChatPaper\.venv\Lib\site-packages\httpcore\_sync\connection_pool.py", line 236, in handle_request
    response = connection.handle_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\httpcore\_sync\http_proxy.py", line 288, in handle_request
    connect_response = self._connection.handle_request(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\httpcore\_sync\connection.py", line 101, in handle_request
    raise exc
  File "D:\ChatPaper\.venv\Lib\site-packages\httpcore\_sync\connection.py", line 78, in handle_request
    stream = self._connect(request)
             ^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\httpcore\_sync\connection.py", line 124, in _connect
    stream = self._network_backend.connect_tcp(**kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\httpcore\_backends\sync.py", line 207, in connect_tcp
    with map_exceptions(exc_map):
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(value)
  File "D:\ChatPaper\.venv\Lib\site-packages\httpcore\_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ConnectError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "D:\ChatPaper\.venv\Lib\site-packages\openai\_base_client.py", line 982, in request
    response = self._client.send(
               ^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\httpx\_client.py", line 914, in send
    response = self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\httpx\_client.py", line 942, in _send_handling_auth
    response = self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\httpx\_client.py", line 979, in _send_handling_redirects
    response = self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\httpx\_client.py", line 1014, in _send_single_request
    response = transport.handle_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\httpx\_transports\default.py", line 249, in handle_request
    with map_httpcore_exceptions():
         ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(value)
  File "D:\ChatPaper\.venv\Lib\site-packages\httpx\_transports\default.py", line 118, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "D:\ChatPaper\llm_client_merged.py", line 632, in generate
    completion = self.client.chat.completions.create(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\openai\_utils\_utils.py", line 286, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\openai\resources\chat\completions\completions.py", line 1156, in create
    return self._post(
           ^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\openai\_base_client.py", line 1259, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\openai\_base_client.py", line 1014, in request
    raise APIConnectionError(request=request) from err
openai.APIConnectionError: Connection error.
2025-11-09 16:58:10,074 - WARNING - root - DoubaoClient: 网络连接问题 检测到，等待 60 秒后重试
2025-11-09 16:59:10,077 - INFO - root - DoubaoClient: retry attempt 3 for generation
2025-11-09 16:59:12,128 - INFO - openai._base_client - Retrying request to /chat/completions in 0.419260 seconds
2025-11-09 16:59:14,569 - INFO - openai._base_client - Retrying request to /chat/completions in 0.863384 seconds
2025-11-09 16:59:17,468 - ERROR - root - DoubaoClient: generation error: Connection error.
Traceback (most recent call last):
  File "D:\ChatPaper\.venv\Lib\site-packages\httpx\_transports\default.py", line 101, in map_httpcore_exceptions
    yield
  File "D:\ChatPaper\.venv\Lib\site-packages\httpx\_transports\default.py", line 250, in handle_request
    resp = self._pool.handle_request(req)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\httpcore\_sync\connection_pool.py", line 256, in handle_request
    raise exc from None
  File "D:\ChatPaper\.venv\Lib\site-packages\httpcore\_sync\connection_pool.py", line 236, in handle_request
    response = connection.handle_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\httpcore\_sync\http_proxy.py", line 288, in handle_request
    connect_response = self._connection.handle_request(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\httpcore\_sync\connection.py", line 101, in handle_request
    raise exc
  File "D:\ChatPaper\.venv\Lib\site-packages\httpcore\_sync\connection.py", line 78, in handle_request
    stream = self._connect(request)
             ^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\httpcore\_sync\connection.py", line 124, in _connect
    stream = self._network_backend.connect_tcp(**kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\httpcore\_backends\sync.py", line 207, in connect_tcp
    with map_exceptions(exc_map):
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(value)
  File "D:\ChatPaper\.venv\Lib\site-packages\httpcore\_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ConnectError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "D:\ChatPaper\.venv\Lib\site-packages\openai\_base_client.py", line 982, in request
    response = self._client.send(
               ^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\httpx\_client.py", line 914, in send
    response = self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\httpx\_client.py", line 942, in _send_handling_auth
    response = self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\httpx\_client.py", line 979, in _send_handling_redirects
    response = self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\httpx\_client.py", line 1014, in _send_single_request
    response = transport.handle_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\httpx\_transports\default.py", line 249, in handle_request
    with map_httpcore_exceptions():
         ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(value)
  File "D:\ChatPaper\.venv\Lib\site-packages\httpx\_transports\default.py", line 118, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "D:\ChatPaper\llm_client_merged.py", line 632, in generate
    completion = self.client.chat.completions.create(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\openai\_utils\_utils.py", line 286, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\openai\resources\chat\completions\completions.py", line 1156, in create
    return self._post(
           ^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\openai\_base_client.py", line 1259, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\openai\_base_client.py", line 1014, in request
    raise APIConnectionError(request=request) from err
openai.APIConnectionError: Connection error.
2025-11-09 16:59:17,480 - ERROR - root - DoubaoClient: 最终失败 - 抱歉，豆包生成内容时遇到问题：Connection error.
2025-11-09 16:59:19,520 - INFO - openai._base_client - Retrying request to /chat/completions in 0.457668 seconds
2025-11-09 16:59:22,010 - INFO - openai._base_client - Retrying request to /chat/completions in 0.784081 seconds
2025-11-09 16:59:24,810 - ERROR - root - DoubaoClient: generation error: Connection error.
Traceback (most recent call last):
  File "D:\ChatPaper\.venv\Lib\site-packages\httpx\_transports\default.py", line 101, in map_httpcore_exceptions
    yield
  File "D:\ChatPaper\.venv\Lib\site-packages\httpx\_transports\default.py", line 250, in handle_request
    resp = self._pool.handle_request(req)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\httpcore\_sync\connection_pool.py", line 256, in handle_request
    raise exc from None
  File "D:\ChatPaper\.venv\Lib\site-packages\httpcore\_sync\connection_pool.py", line 236, in handle_request
    response = connection.handle_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\httpcore\_sync\http_proxy.py", line 288, in handle_request
    connect_response = self._connection.handle_request(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\httpcore\_sync\connection.py", line 101, in handle_request
    raise exc
  File "D:\ChatPaper\.venv\Lib\site-packages\httpcore\_sync\connection.py", line 78, in handle_request
    stream = self._connect(request)
             ^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\httpcore\_sync\connection.py", line 124, in _connect
    stream = self._network_backend.connect_tcp(**kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\httpcore\_backends\sync.py", line 207, in connect_tcp
    with map_exceptions(exc_map):
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(value)
  File "D:\ChatPaper\.venv\Lib\site-packages\httpcore\_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ConnectError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "D:\ChatPaper\.venv\Lib\site-packages\openai\_base_client.py", line 982, in request
    response = self._client.send(
               ^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\httpx\_client.py", line 914, in send
    response = self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\httpx\_client.py", line 942, in _send_handling_auth
    response = self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\httpx\_client.py", line 979, in _send_handling_redirects
    response = self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\httpx\_client.py", line 1014, in _send_single_request
    response = transport.handle_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\httpx\_transports\default.py", line 249, in handle_request
    with map_httpcore_exceptions():
         ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python312\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(value)
  File "D:\ChatPaper\.venv\Lib\site-packages\httpx\_transports\default.py", line 118, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "D:\ChatPaper\llm_client_merged.py", line 632, in generate
    completion = self.client.chat.completions.create(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\openai\_utils\_utils.py", line 286, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\openai\resources\chat\completions\completions.py", line 1156, in create
    return self._post(
           ^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\openai\_base_client.py", line 1259, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ChatPaper\.venv\Lib\site-packages\openai\_base_client.py", line 1014, in request
    raise APIConnectionError(request=request) from err
openai.APIConnectionError: Connection error.
2025-11-09 16:59:24,818 - WARNING - root - DoubaoClient: 网络连接问题 检测到，等待 60 秒后重试
2025-11-09 17:12:12,059 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-09 17:12:12,062 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-09 17:12:12,065 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-09 17:25:58,418 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-09 17:25:58,423 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-09 17:25:58,426 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-09 17:36:52,097 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-09 17:36:52,104 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-09 17:36:52,110 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-09 17:36:54,026 - INFO - root - LLMClientManager: 指定使用客户端: Doubao
2025-11-09 17:36:54,028 - INFO - root - DoubaoClient: API key found: 9f9e270e-b...
2025-11-09 17:36:58,431 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 17:36:58,453 - INFO - root - DoubaoClient: initialized successfully with model doubao-seed-1-6-lite-251015
2025-11-09 17:36:58,454 - INFO - root - LLMClientManager: Doubao 客户端初始化成功
2025-11-09 17:36:58,454 - INFO - root - LLMClientManager: switched to Doubao client
2025-11-09 17:36:58,454 - INFO - root - 已手动切换到 LLM 客户端: Doubao
2025-11-09 17:36:58,454 - INFO - root - 使用 LLM 模型: doubao-seed-1-6-lite-251015
2025-11-09 17:36:58,454 - INFO - root - 可用客户端: ['Doubao']
2025-11-09 17:36:58,455 - INFO - root - === 运行配置 ===
2025-11-09 17:36:58,455 - INFO - root - 处理模式: arxiv在线搜索
2025-11-09 17:36:58,455 - INFO - root - 关键词: QAT
2025-11-09 17:36:58,456 - INFO - root - 查询: Quantization-Aware-Training
2025-11-09 17:36:58,456 - INFO - root - 排序: None
2025-11-09 17:36:58,456 - INFO - root - 最近天数: 180
2025-11-09 17:36:58,457 - INFO - root - 最大处理数量: 20
2025-11-09 17:36:58,457 - INFO - root - 保存图片: 是
2025-11-09 17:36:58,457 - INFO - root - 输出语言: 中文
2025-11-09 17:36:58,457 - INFO - root - 强制重新处理: 否
2025-11-09 17:36:58,457 - INFO - root - ====================
2025-11-09 17:36:58,457 - INFO - root - 使用 arXiv 搜索模式（通过 chat_arxiv 模块获取）
2025-11-09 17:36:58,459 - INFO - root - Fetching page 1 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50
2025-11-09 17:37:16,996 - INFO - root - get_all_titles_from_web 
2025-11-09 17:37:16,997 - INFO - root - Page:0, Index:0, A Quantized VAE-MLP Botnet Detection Model: A Systematic Evaluation of Quantization-Aware Training and Post-Training Quantization Strategies, https://arxiv.org/pdf/2511.03201, 2025-11-05
2025-11-09 17:37:16,997 - INFO - root - Page:0, Index:1, FP8-Flow-MoE: A Casting-Free FP8 Recipe without Double Quantization Error, https://arxiv.org/pdf/2511.02302, 2025-11-04
2025-11-09 17:37:16,997 - INFO - root - Page:0, Index:2, Outlier-Aware Post-Training Quantization for Image Super-Resolution, https://arxiv.org/pdf/2511.00682, 2025-11-01
2025-11-09 17:37:16,998 - INFO - root - Page:0, Index:3, Evaluation of Wafer-Scale SOT-MRAM for Analog Crossbar Array Applications, https://arxiv.org/pdf/2510.25853, 2025-11-03
2025-11-09 17:37:16,999 - INFO - root - Page:0, Index:4, Improving the Straight-Through Estimator with Zeroth-Order Information, https://arxiv.org/pdf/2510.23926, 2025-10-27
2025-11-09 17:37:16,999 - INFO - root - Page:0, Index:5, Real-Time Semantic Segmentation on FPGA for Autonomous Vehicles Using LMIINet with the CGRA4ML Framework, https://arxiv.org/pdf/2510.22243, 2025-10-25
2025-11-09 17:37:17,000 - INFO - root - Page:0, Index:6, TernaryCLIP: Efficiently Compressing Vision-Language Models with Ternary Weights and Distilled Knowledge, https://arxiv.org/pdf/2510.21879, 2025-10-23
2025-11-09 17:37:17,000 - INFO - root - Page:0, Index:7, KARIPAP: Quantum-Inspired Tensor Network Compression of Large Language Models Using Infinite Projected Entangled Pair States and Tensor Renormalization Group, https://arxiv.org/pdf/2510.21844, 2025-10-22
2025-11-09 17:37:17,001 - INFO - root - Page:0, Index:8, A Convergence Analysis of Adaptive Optimizers under Floating-point Quantization, https://arxiv.org/pdf/2510.21314, 2025-10-24
2025-11-09 17:37:17,001 - INFO - root - Page:0, Index:9, Adaptive Distribution-aware Quantization for Mixed-Precision Neural Networks, https://arxiv.org/pdf/2510.19760, 2025-10-22
2025-11-09 17:37:17,001 - INFO - root - Page:0, Index:10, CAGE: Curvature-Aware Gradient Estimation For Accurate Quantization-Aware Training, https://arxiv.org/pdf/2510.18784, 2025-10-21
2025-11-09 17:37:17,002 - INFO - root - Page:0, Index:11, Mixed-Precision Quantization for Language Models: Techniques and Prospects, https://arxiv.org/pdf/2510.16805, 2025-10-19
2025-11-09 17:37:17,002 - INFO - root - Page:0, Index:12, SPLite Hand: Sparsity-Aware Lightweight 3D Hand Pose Estimation, https://arxiv.org/pdf/2510.16396, 2025-10-30
2025-11-09 17:37:17,002 - INFO - root - Page:0, Index:13, CTR-LoRA: Curvature-Aware and Trust-Region Guided Low-Rank Adaptation for Large Language Models, https://arxiv.org/pdf/2510.15962, 2025-10-11
2025-11-09 17:37:17,003 - INFO - root - Page:0, Index:14, SANR: Scene-Aware Neural Representation for Light Field Image Compression with Rate-Distortion Optimization, https://arxiv.org/pdf/2510.15775, 2025-10-17
2025-11-09 17:37:17,004 - INFO - root - Page:0, Index:15, SpikeFit: Towards Optimal Deployment of Spiking Networks on Neuromorphic Hardware, https://arxiv.org/pdf/2510.15542, 2025-10-31
2025-11-09 17:37:17,006 - INFO - root - Page:0, Index:16, GRank: Towards Target-Aware and Streamlined Industrial Retrieval with a Generate-Rank Framework, https://arxiv.org/pdf/2510.15299, 2025-10-17
2025-11-09 17:37:17,007 - INFO - root - Page:0, Index:17, SaLon3R: Structure-aware Long-term Generalizable 3D Reconstruction from Unposed Images, https://arxiv.org/pdf/2510.15072, 2025-10-16
2025-11-09 17:37:17,007 - INFO - root - Page:0, Index:18, FraQAT: Quantization Aware Training with Fractional bits, https://arxiv.org/pdf/2510.14823, 2025-10-16
2025-11-09 17:37:17,007 - INFO - root - Page:0, Index:19, Computing-In-Memory Aware Model Adaption For Edge Devices, https://arxiv.org/pdf/2510.14379, 2025-10-16
2025-11-09 17:37:17,007 - INFO - root - Page:0, Index:20, Invited Paper: BitMedViT: Ternary-Quantized Vision Transformer for Medical AI Assistants on the Edge, https://arxiv.org/pdf/2510.13760, 2025-11-04
2025-11-09 17:37:17,009 - INFO - root - Page:0, Index:21, NeuroRVQ: Multi-Scale EEG Tokenization for Generative Large Brainwave Models, https://arxiv.org/pdf/2510.13068, 2025-10-14
2025-11-09 17:37:17,009 - INFO - root - Page:0, Index:22, Detect Anything via Next Point Prediction, https://arxiv.org/pdf/2510.12798, 2025-10-14
2025-11-09 17:37:17,013 - INFO - root - Page:0, Index:23, AndesVL Technical Report: An Efficient Mobile-side Multimodal Large Language Model, https://arxiv.org/pdf/2510.11496, 2025-10-14
2025-11-09 17:37:17,042 - INFO - root - Page:0, Index:24, Rescaling-Aware Training for Efficient Deployment of Deep Learning Models on Full-Integer Hardware, https://arxiv.org/pdf/2510.11484, 2025-10-13
2025-11-09 17:37:17,044 - INFO - root - Page:0, Index:25, SASER: Stego attacks on open-source LLMs, https://arxiv.org/pdf/2510.10486, 2025-10-12
2025-11-09 17:37:17,046 - INFO - root - Page:0, Index:26, Ultralytics YOLO Evolution: An Overview of YOLO26, YOLO11, YOLOv8 and YOLOv5 Object Detectors for Computer Vision and Pattern Recognition, https://arxiv.org/pdf/2510.09653, 2025-10-15
2025-11-09 17:37:17,047 - INFO - root - Page:0, Index:27, A Theoretically-Grounded Codebook for Digital Semantic Communications, https://arxiv.org/pdf/2510.07108, 2025-10-14
2025-11-09 17:37:17,047 - INFO - root - Page:0, Index:28, QuantDemoire: Quantization with Outlier Aware for Image Demoiréing, https://arxiv.org/pdf/2510.04066, 2025-10-05
2025-11-09 17:37:17,047 - INFO - root - Page:0, Index:29, Adaptively Sampling-Reusing-Mixing Decomposed Gradients to Speed Up Sharpness Aware Minimization, https://arxiv.org/pdf/2510.03763, 2025-10-04
2025-11-09 17:37:17,047 - INFO - root - Page:0, Index:30, Quant-dLLM: Post-Training Extreme Low-Bit Quantization for Diffusion Large Language Models, https://arxiv.org/pdf/2510.03274, 2025-09-27
2025-11-09 17:37:17,049 - INFO - root - Page:0, Index:31, PT$^2$-LLM: Post-Training Ternarization for Large Language Models, https://arxiv.org/pdf/2510.03267, 2025-09-26
2025-11-09 17:37:17,053 - INFO - root - Page:0, Index:32, Purrception: Variational Flow Matching for Vector-Quantized Image Generation, https://arxiv.org/pdf/2510.01478, 2025-10-01
2025-11-09 17:37:17,054 - INFO - root - Page:0, Index:33, Post-Training Quantization for Audio Diffusion Transformers, https://arxiv.org/pdf/2510.00313, 2025-09-30
2025-11-09 17:37:17,055 - INFO - root - Page:0, Index:34, Rethinking RoPE Scaling in Quantized LLM: Theory, Outlier, and Channel-Band Analysis with Weight Rescaling, https://arxiv.org/pdf/2510.00028, 2025-09-25
2025-11-09 17:37:17,056 - INFO - root - Page:0, Index:35, Post-Training Quantization via Residual Truncation and Zero Suppression for Diffusion Models, https://arxiv.org/pdf/2509.26436, 2025-09-30
2025-11-09 17:37:17,056 - INFO - root - Page:0, Index:36, Cat: Post-Training Quantization Error Reduction via Cluster-based Affine Transformation, https://arxiv.org/pdf/2509.26277, 2025-10-07
2025-11-09 17:37:17,057 - INFO - root - Page:0, Index:37, CAST: Continuous and Differentiable Semi-Structured Sparsity-Aware Training for Large Language Models, https://arxiv.org/pdf/2509.25996, 2025-09-30
2025-11-09 17:37:17,057 - INFO - root - Page:0, Index:38, Norm-Q: Effective Compression Method for Hidden Markov Models in Neuro-Symbolic Applications, https://arxiv.org/pdf/2509.25439, 2025-09-29
2025-11-09 17:37:17,072 - INFO - root - Page:0, Index:39, On-the-Fly Adaptation to Quantization: Configuration-Aware LoRA for Efficient Fine-Tuning of Quantized LLMs, https://arxiv.org/pdf/2509.25214, 2025-09-22
2025-11-09 17:37:17,076 - INFO - root - Page:0, Index:40, VoxCPM: Tokenizer-Free TTS for Context-Aware Speech Generation and True-to-Life Voice Cloning, https://arxiv.org/pdf/2509.24650, 2025-09-29
2025-11-09 17:37:17,076 - INFO - root - Page:0, Index:41, S$^2$NN: Sub-bit Spiking Neural Networks, https://arxiv.org/pdf/2509.24266, 2025-10-24
2025-11-09 17:37:17,077 - INFO - root - Page:0, Index:42, Tequila: Trapping-free Ternary Quantization for Large Language Models, https://arxiv.org/pdf/2509.23809, 2025-10-17
2025-11-09 17:37:17,077 - INFO - root - Page:0, Index:43, Texture Vector-Quantization and Reconstruction Aware Prediction for Generative Super-Resolution, https://arxiv.org/pdf/2509.23774, 2025-09-30
2025-11-09 17:37:17,077 - INFO - root - Page:0, Index:44, RobuQ: Pushing DiTs to W1.58A2 via Robust Activation Quantization, https://arxiv.org/pdf/2509.23582, 2025-09-27
2025-11-09 17:37:17,078 - INFO - root - Page:0, Index:45, Beyond Outliers: A Study of Optimizers Under Quantization, https://arxiv.org/pdf/2509.23500, 2025-10-02
2025-11-09 17:37:17,078 - INFO - root - Page:0, Index:46, Compute-Optimal Quantization-Aware Training, https://arxiv.org/pdf/2509.22935, 2025-09-26
2025-11-09 17:37:17,079 - INFO - root - Page:0, Index:47, COSPADI: Compressing LLMs via Calibration-Guided Sparse Dictionary Learning, https://arxiv.org/pdf/2509.22075, 2025-10-06
2025-11-09 17:37:17,079 - INFO - root - Page:0, Index:48, SlimDiff: Training-Free, Activation-Guided Hands-free Slimming of Diffusion Models, https://arxiv.org/pdf/2509.21498, 2025-09-25
2025-11-09 17:37:17,086 - INFO - root - Page:0, Index:49, Quantized Visual Geometry Grounded Transformer, https://arxiv.org/pdf/2509.21302, 2025-09-29
2025-11-09 17:37:17,089 - INFO - root - Fetching page 2 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=50
2025-11-09 17:37:39,510 - INFO - root - get_all_titles_from_web 
2025-11-09 17:37:39,510 - INFO - root - Page:1, Index:0, Can Less Precise Be More Reliable? A Systematic Evaluation of Quantization's Impact on CLIP Beyond Accuracy, https://arxiv.org/pdf/2509.21173, 2025-10-27
2025-11-09 17:37:39,510 - INFO - root - Page:1, Index:1, Punching Above Precision: Small Quantized Model Distillation with Learnable Regularizer, https://arxiv.org/pdf/2509.20854, 2025-09-25
2025-11-09 17:37:39,512 - INFO - root - Page:1, Index:2, TinyEcoWeedNet: Edge Efficient Real-Time Aerial Agricultural Weed Detection, https://arxiv.org/pdf/2509.18193, 2025-09-19
2025-11-09 17:37:39,512 - INFO - root - Page:1, Index:3, SBVR: Summation of BitVector Representation for Efficient LLM Quantization, https://arxiv.org/pdf/2509.18172, 2025-09-17
2025-11-09 17:37:39,512 - INFO - root - Page:1, Index:4, QWHA: Quantization-Aware Walsh-Hadamard Adaptation for Parameter-Efficient Fine-Tuning on Large Language Models, https://arxiv.org/pdf/2509.17428, 2025-09-26
2025-11-09 17:37:39,512 - INFO - root - Page:1, Index:5, PTQTP: Post-Training Quantization to Trit-Planes for Large Language Models, https://arxiv.org/pdf/2509.16989, 2025-10-28
2025-11-09 17:37:39,513 - INFO - root - Page:1, Index:6, MEC-Quant: Maximum Entropy Coding for Extremely Low Bit Quantization-Aware Training, https://arxiv.org/pdf/2509.15514, 2025-09-18
2025-11-09 17:37:39,513 - INFO - root - Page:1, Index:7, Q-ROAR: Outlier-Aware Rescaling for RoPE Position Interpolation in Quantized Long-Context LLMs, https://arxiv.org/pdf/2509.14391, 2025-09-17
2025-11-09 17:37:39,513 - INFO - root - Page:1, Index:8, Efficient Quantization-Aware Neural Receivers: Beyond Post-Training Quantization, https://arxiv.org/pdf/2509.13786, 2025-09-19
2025-11-09 17:37:39,514 - INFO - root - Page:1, Index:9, Rate-Distortion Limits for Multimodal Retrieval: Theory, Optimal Codes, and Finite-Sample Guarantees, https://arxiv.org/pdf/2509.11054, 2025-09-13
2025-11-09 17:37:39,514 - INFO - root - Page:1, Index:10, SQAP-VLA: A Synergistic Quantization-Aware Pruning Framework for High-Performance Vision-Language-Action Models, https://arxiv.org/pdf/2509.09090, 2025-09-10
2025-11-09 17:37:39,514 - INFO - root - Page:1, Index:11, CSI Compression Beyond Latents: End-to-End Hybrid Attention-CNN Networks with Entropy Regularization, https://arxiv.org/pdf/2509.08776, 2025-09-10
2025-11-09 17:37:39,514 - INFO - root - Page:1, Index:12, Explaining How Quantization Disparately Skews a Model, https://arxiv.org/pdf/2509.07222, 2025-09-08
2025-11-09 17:37:39,515 - INFO - root - Page:1, Index:13, LoaQ: Layer-wise Output Approximation Quantization, https://arxiv.org/pdf/2509.06297, 2025-09-07
2025-11-09 17:37:39,515 - INFO - root - Page:1, Index:14, FineServe: Precision-Aware KV Slab and Two-Level Scheduling for Heterogeneous Precision LLM Serving, https://arxiv.org/pdf/2509.06261, 2025-09-14
2025-11-09 17:37:39,515 - INFO - root - Page:1, Index:15, Sensitivity-Aware Post-Training Quantization for Deep Neural Networks, https://arxiv.org/pdf/2509.05576, 2025-09-05
2025-11-09 17:37:39,515 - INFO - root - Page:1, Index:16, SuperSNN: A Hardware-Aware Framework for Physically Realizable, High-Performance Superconducting Spiking Neural Network Chips, https://arxiv.org/pdf/2509.05532, 2025-09-05
2025-11-09 17:37:39,517 - INFO - root - Page:1, Index:17, Data-Augmented Quantization-Aware Knowledge Distillation, https://arxiv.org/pdf/2509.03850, 2025-09-03
2025-11-09 17:37:39,517 - INFO - root - Page:1, Index:18, DPQuant: Efficient and Differentially-Private Model Training via Dynamic Quantization Scheduling, https://arxiv.org/pdf/2509.03472, 2025-09-03
2025-11-09 17:37:39,517 - INFO - root - Page:1, Index:19, Empowering Large Language Model for Sequential Recommendation via Multimodal Embeddings and Semantic IDs, https://arxiv.org/pdf/2509.02017, 2025-09-02
2025-11-09 17:37:39,518 - INFO - root - Page:1, Index:20, Q-Sched: Pushing the Boundaries of Few-Step Diffusion Models with Quantization-Aware Scheduling, https://arxiv.org/pdf/2509.01624, 2025-09-01
2025-11-09 17:37:39,518 - INFO - root - Page:1, Index:21, Quantization Meets OOD: Generalizable Quantization-aware Training from a Flatness Perspective, https://arxiv.org/pdf/2509.00859, 2025-08-31
2025-11-09 17:37:39,519 - INFO - root - Page:1, Index:22, Progressive Element-wise Gradient Estimation for Neural Network Quantization, https://arxiv.org/pdf/2509.00097, 2025-08-27
2025-11-09 17:37:39,519 - INFO - root - Page:1, Index:23, End-to-End On-Device Quantization-Aware Training for LLMs at Inference Cost, https://arxiv.org/pdf/2509.00031, 2025-09-29
2025-11-09 17:37:39,519 - INFO - root - Page:1, Index:24, Quantization Robustness to Input Degradations for Object Detection, https://arxiv.org/pdf/2508.19600, 2025-08-27
2025-11-09 17:37:39,520 - INFO - root - Page:1, Index:25, Scaling Laws for Task-Stratified Knowledge in Post-Training Quantized Large Language Models, https://arxiv.org/pdf/2508.18609, 2025-08-27
2025-11-09 17:37:39,521 - INFO - root - Page:1, Index:26, AQ-PCDSys: An Adaptive Quantized Planetary Crater Detection System for Autonomous Space Exploration, https://arxiv.org/pdf/2508.18025, 2025-08-25
2025-11-09 17:37:39,522 - INFO - root - Page:1, Index:27, TaDiCodec: Text-aware Diffusion Speech Tokenizer for Speech Language Modeling, https://arxiv.org/pdf/2508.16790, 2025-08-22
2025-11-09 17:37:39,522 - INFO - root - Page:1, Index:28, A Node-Aware Dynamic Quantization Approach for Graph Collaborative Filtering, https://arxiv.org/pdf/2508.16516, 2025-08-22
2025-11-09 17:37:39,523 - INFO - root - Page:1, Index:29, JEDI-linear: Fast and Efficient Graph Neural Networks for Jet Tagging on FPGAs, https://arxiv.org/pdf/2508.15468, 2025-08-21
2025-11-09 17:37:39,523 - INFO - root - Page:1, Index:30, MMQ: Multimodal Mixture-of-Quantization Tokenization for Semantic ID Generation and User Behavioral Adaptation, https://arxiv.org/pdf/2508.15281, 2025-08-21
2025-11-09 17:37:39,524 - INFO - root - Page:1, Index:31, DLLMQuant: Quantizing Diffusion-based Large Language Models, https://arxiv.org/pdf/2508.14090, 2025-08-25
2025-11-09 17:37:39,524 - INFO - root - Page:1, Index:32, Automated Energy-Aware Time-Series Model Deployment on Embedded FPGAs for Resilient Combined Sewer Overflow Management, https://arxiv.org/pdf/2508.13905, 2025-08-19
2025-11-09 17:37:39,525 - INFO - root - Page:1, Index:33, XR-NPE: High-Throughput Mixed-precision SIMD Neural Processing Engine for Extended Reality Perception Workloads, https://arxiv.org/pdf/2508.13049, 2025-08-18
2025-11-09 17:37:39,526 - INFO - root - Page:1, Index:34, Exploring Self-Supervised Audio Models for Generalized Anomalous Sound Detection, https://arxiv.org/pdf/2508.12230, 2025-08-17
2025-11-09 17:37:39,530 - INFO - root - Page:1, Index:35, TriQDef: Disrupting Semantic and Gradient Alignment to Prevent Adversarial Patch Transferability in Quantized Neural Networks, https://arxiv.org/pdf/2508.12132, 2025-08-16
2025-11-09 17:37:39,534 - INFO - root - Page:1, Index:36, Error Propagation Mechanisms and Compensation Strategies for Quantized Diffusion, https://arxiv.org/pdf/2508.12094, 2025-10-13
2025-11-09 17:37:39,534 - INFO - root - Page:1, Index:37, Extending Straight-Through Estimation for Robust Neural Networks on Analog CIM Hardware, https://arxiv.org/pdf/2508.11940, 2025-08-16
2025-11-09 17:37:39,535 - INFO - root - Page:1, Index:38, PTQAT: A Hybrid Parameter-Efficient Quantization Algorithm for 3D Perception Tasks, https://arxiv.org/pdf/2508.10557, 2025-08-15
2025-11-09 17:37:39,536 - INFO - root - Page:1, Index:39, MiCo: End-to-End Mixed Precision Neural Network Co-Exploration Framework for Edge AI, https://arxiv.org/pdf/2508.09500, 2025-08-13
2025-11-09 17:37:39,537 - INFO - root - Page:1, Index:40, SPARC: Soft Probabilistic Adaptive multi-interest Retrieval Model via Codebooks for recommender system, https://arxiv.org/pdf/2508.09090, 2025-08-12
2025-11-09 17:37:39,537 - INFO - root - Page:1, Index:41, Rethinking 1-bit Optimization Leveraging Pre-trained Large Language Models, https://arxiv.org/pdf/2508.06974, 2025-08-09
2025-11-09 17:37:39,542 - INFO - root - Page:1, Index:42, Efficient Deep Neural Receiver with Post-Training Quantization, https://arxiv.org/pdf/2508.06275, 2025-08-08
2025-11-09 17:37:39,545 - INFO - root - Page:1, Index:43, iFairy: the First 2-bit Complex LLM with All Parameters in $\{\pm1, \pm i\}$, https://arxiv.org/pdf/2508.05571, 2025-08-16
2025-11-09 17:37:39,546 - INFO - root - Page:1, Index:44, S$^2$Q-VDiT: Accurate Quantized Video Diffusion Transformer with Salient Data and Sparse Token Distillation, https://arxiv.org/pdf/2508.04016, 2025-10-27
2025-11-09 17:37:39,547 - INFO - root - Page:1, Index:45, LRQ-DiT: Log-Rotation Post-Training Quantization of Diffusion Transformers for Image and Video Generation, https://arxiv.org/pdf/2508.03485, 2025-09-23
2025-11-09 17:37:39,547 - INFO - root - Page:1, Index:46, VLMQ: Efficient Post-Training Quantization for Large Vision-Language Models via Hessian Augmentation, https://arxiv.org/pdf/2508.03351, 2025-08-05
2025-11-09 17:37:39,547 - INFO - root - Page:1, Index:47, TF-MLPNet: Tiny Real-Time Neural Speech Separation, https://arxiv.org/pdf/2508.03047, 2025-08-04
2025-11-09 17:37:39,548 - INFO - root - Page:1, Index:48, SaviorRec: Semantic-Behavior Alignment for Cold-Start Recommendation, https://arxiv.org/pdf/2508.01375, 2025-08-02
2025-11-09 17:37:39,548 - INFO - root - Page:1, Index:49, MixA-Q: Revisiting Activation Sparsity for Vision Transformers from a Mixed-Precision Quantization Perspective, https://arxiv.org/pdf/2507.19131, 2025-07-25
2025-11-09 17:37:39,549 - INFO - root - Fetching page 3 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=100
2025-11-09 17:37:50,057 - INFO - root - get_all_titles_from_web 
2025-11-09 17:37:50,058 - INFO - root - Page:2, Index:0, Enhancing Quantization-Aware Training on Edge Devices via Relative Entropy Coreset Selection and Cascaded Layer Correction, https://arxiv.org/pdf/2507.17768, 2025-07-16
2025-11-09 17:37:50,058 - INFO - root - Page:2, Index:1, SiLQ: Simple Large Language Model Quantization-Aware Training, https://arxiv.org/pdf/2507.16933, 2025-07-22
2025-11-09 17:37:50,059 - INFO - root - Page:2, Index:2, Task-Specific Zero-shot Quantization-Aware Training for Object Detection, https://arxiv.org/pdf/2507.16782, 2025-07-22
2025-11-09 17:37:50,059 - INFO - root - Page:2, Index:3, TorchAO: PyTorch-Native Training-to-Serving Model Optimization, https://arxiv.org/pdf/2507.16099, 2025-07-21
2025-11-09 17:37:50,059 - INFO - root - Page:2, Index:4, SegQuant: A Semantics-Aware and Generalizable Quantization Framework for Diffusion Models, https://arxiv.org/pdf/2507.14811, 2025-08-27
2025-11-09 17:37:50,059 - INFO - root - Page:2, Index:5, Apple Intelligence Foundation Language Models: Tech Report 2025, https://arxiv.org/pdf/2507.13575, 2025-08-27
2025-11-09 17:37:50,060 - INFO - root - Page:2, Index:6, Generative Multi-Target Cross-Domain Recommendation, https://arxiv.org/pdf/2507.12871, 2025-08-07
2025-11-09 17:37:50,060 - INFO - root - Page:2, Index:7, DAF: An Efficient End-to-End Dynamic Activation Framework for on-Device DNN Training, https://arxiv.org/pdf/2507.07149, 2025-07-09
2025-11-09 17:37:50,060 - INFO - root - Page:2, Index:8, Opto-ViT: Architecting a Near-Sensor Region of Interest-Aware Vision Transformer Accelerator with Silicon Photonics, https://arxiv.org/pdf/2507.07044, 2025-07-15
2025-11-09 17:37:50,060 - INFO - root - Page:2, Index:9, QS4D: Quantization-aware training for efficient hardware deployment of structured state-space sequential models, https://arxiv.org/pdf/2507.06079, 2025-07-08
2025-11-09 17:37:50,062 - INFO - root - Page:2, Index:10, GSVR: 2D Gaussian-based Video Representation for 800+ FPS with Hybrid Deformation Field, https://arxiv.org/pdf/2507.05594, 2025-07-07
2025-11-09 17:37:50,062 - INFO - root - Page:2, Index:11, Hita: Holistic Tokenizer for Autoregressive Image Generation, https://arxiv.org/pdf/2507.02358, 2025-07-11
2025-11-09 17:37:50,062 - INFO - root - Page:2, Index:12, QPART: Adaptive Model Quantization and Dynamic Workload Balancing for Accuracy-aware Edge Inference, https://arxiv.org/pdf/2506.23934, 2025-06-30
2025-11-09 17:37:50,063 - INFO - root - Page:2, Index:13, FedWSQ: Efficient Federated Learning with Weight Standardization and Distribution-Aware Non-Uniform Quantization, https://arxiv.org/pdf/2506.23516, 2025-07-21
2025-11-09 17:37:50,064 - INFO - root - Page:2, Index:14, Spectra 1.1: Scaling Laws and Efficient Inference for Ternary Language Models, https://arxiv.org/pdf/2506.23025, 2025-06-28
2025-11-09 17:37:50,064 - INFO - root - Page:2, Index:15, Joint Quantization and Pruning Neural Networks Approach: A Case Study on FSO Receivers, https://arxiv.org/pdf/2506.20084, 2025-06-24
2025-11-09 17:37:50,066 - INFO - root - Page:2, Index:16, Single-step Diffusion for Image Compression at Ultra-Low Bitrates, https://arxiv.org/pdf/2506.16572, 2025-09-22
2025-11-09 17:37:50,066 - INFO - root - Page:2, Index:17, LittleBit: Ultra Low-Bit Quantization via Latent Factorization, https://arxiv.org/pdf/2506.13771, 2025-10-28
2025-11-09 17:37:50,067 - INFO - root - Page:2, Index:18, MARCO: Hardware-Aware Neural Architecture Search for Edge Devices with Multi-Agent Reinforcement Learning and Conformal Prediction Filtering, https://arxiv.org/pdf/2506.13755, 2025-06-16
2025-11-09 17:37:50,067 - INFO - root - Page:2, Index:19, EAQuant: Enhancing Post-Training Quantization for MoE Models via Expert-Aware Optimization, https://arxiv.org/pdf/2506.13329, 2025-07-04
2025-11-09 17:37:50,068 - INFO - root - Page:2, Index:20, Towards Neural Audio Codec Source Parsing, https://arxiv.org/pdf/2506.12627, 2025-06-14
2025-11-09 17:37:50,068 - INFO - root - Page:2, Index:21, Quantizing Small-Scale State-Space Models for Edge AI, https://arxiv.org/pdf/2506.12480, 2025-06-14
2025-11-09 17:37:50,069 - INFO - root - Page:2, Index:22, EMLoC: Emulator-based Memory-efficient Fine-tuning with LoRA Correction, https://arxiv.org/pdf/2506.12015, 2025-06-13
2025-11-09 17:37:50,069 - INFO - root - Page:2, Index:23, Compression Aware Certified Training, https://arxiv.org/pdf/2506.11992, 2025-06-13
2025-11-09 17:37:50,069 - INFO - root - Page:2, Index:24, GPLQ: A General, Practical, and Lightning QAT Method for Vision Transformers, https://arxiv.org/pdf/2506.11784, 2025-06-13
2025-11-09 17:37:50,070 - INFO - root - Page:2, Index:25, TruncQuant: Truncation-Ready Quantization for DNNs with Flexible Weight Bit Precision, https://arxiv.org/pdf/2506.11431, 2025-06-12
2025-11-09 17:37:50,071 - INFO - root - Page:2, Index:26, EfficientQuant: An Efficient Post-Training Quantization for CNN-Transformer Hybrid Models on Edge Devices, https://arxiv.org/pdf/2506.11093, 2025-06-05
2025-11-09 17:37:50,072 - INFO - root - Page:2, Index:27, Starting Positions Matter: A Study on Better Weight Initialization for Neural Network Quantization, https://arxiv.org/pdf/2506.10463, 2025-06-12
2025-11-09 17:37:50,072 - INFO - root - Page:2, Index:28, AWP: Activation-Aware Weight Pruning and Quantization with Projected Gradient Descent, https://arxiv.org/pdf/2506.10205, 2025-06-11
2025-11-09 17:37:50,072 - INFO - root - Page:2, Index:29, Q-SAM2: Accurate Quantization for Segment Anything Model 2, https://arxiv.org/pdf/2506.09782, 2025-06-11
2025-11-09 17:37:50,074 - INFO - root - Page:2, Index:30, Unifying Block-wise PTQ and Distillation-based QAT for Progressive Quantization toward 2-bit Instruction-Tuned LLMs, https://arxiv.org/pdf/2506.09104, 2025-06-10
2025-11-09 17:37:50,078 - INFO - root - Page:2, Index:31, Implementing Keyword Spotting on the MCUX947 Microcontroller with Integrated NPU, https://arxiv.org/pdf/2506.08911, 2025-06-10
2025-11-09 17:37:50,081 - INFO - root - Page:2, Index:32, POLARON: Precision-aware On-device Learning and Adaptive Runtime-cONfigurable AI acceleration, https://arxiv.org/pdf/2506.08785, 2025-06-10
2025-11-09 17:37:50,084 - INFO - root - Page:2, Index:33, MoQAE: Mixed-Precision Quantization for Long-Context LLM Inference via Mixture of Quantization-Aware Experts, https://arxiv.org/pdf/2506.07533, 2025-06-09
2025-11-09 17:37:50,088 - INFO - root - Page:2, Index:34, BitVLA: 1-bit Vision-Language-Action Models for Robotics Manipulation, https://arxiv.org/pdf/2506.07530, 2025-06-09
2025-11-09 17:37:50,094 - INFO - root - Page:2, Index:35, RecGPT: A Foundation Model for Sequential Recommendation, https://arxiv.org/pdf/2506.06270, 2025-06-12
2025-11-09 17:37:50,096 - INFO - root - Page:2, Index:36, FPSAttention: Training-Aware FP8 and Sparsity Co-Design for Fast Video Diffusion, https://arxiv.org/pdf/2506.04648, 2025-06-05
2025-11-09 17:37:50,097 - INFO - root - Page:2, Index:37, BitTTS: Highly Compact Text-to-Speech Using 1.58-bit Quantization and Weight Indexing, https://arxiv.org/pdf/2506.03515, 2025-06-03
2025-11-09 17:37:50,098 - INFO - root - Page:2, Index:38, ShapeLLM-Omni: A Native Multimodal LLM for 3D Generation and Understanding, https://arxiv.org/pdf/2506.01853, 2025-06-02
2025-11-09 17:37:50,098 - INFO - root - Page:2, Index:39, Movable Antenna Enhanced Federated Fine-Tuning of Large Language Models via Hybrid Client Selection Optimization, https://arxiv.org/pdf/2506.00011, 2025-10-26
2025-11-09 17:37:50,114 - INFO - root - Page:2, Index:40, Running Conventional Automatic Speech Recognition on Memristor Hardware: A Simulated Approach, https://arxiv.org/pdf/2505.24721, 2025-05-30
2025-11-09 17:37:50,119 - INFO - root - Page:2, Index:41, GARLIC: GAussian Representation LearnIng for spaCe partitioning, https://arxiv.org/pdf/2505.24608, 2025-10-02
2025-11-09 17:37:50,121 - INFO - root - Page:2, Index:42, AutoChemSchematic AI: Agentic Physics-Aware Automation for Chemical Manufacturing Scale-Up, https://arxiv.org/pdf/2505.24584, 2025-08-18
2025-11-09 17:37:50,122 - INFO - root - Page:2, Index:43, Model-Preserving Adaptive Rounding, https://arxiv.org/pdf/2505.22988, 2025-09-25
2025-11-09 17:37:50,123 - INFO - root - Page:2, Index:44, Highly Efficient and Effective LLMs with Multi-Boolean Architectures, https://arxiv.org/pdf/2505.22811, 2025-10-03
2025-11-09 17:37:50,123 - INFO - root - Page:2, Index:45, Pioneering 4-Bit FP Quantization for Diffusion Models: Mixup-Sign Quantization and Timestep-Aware Fine-Tuning, https://arxiv.org/pdf/2505.21591, 2025-05-27
2025-11-09 17:37:50,123 - INFO - root - Page:2, Index:46, Frequency Composition for Compressed and Domain-Adaptive Neural Networks, https://arxiv.org/pdf/2505.20890, 2025-05-27
2025-11-09 17:37:50,124 - INFO - root - Page:2, Index:47, MoPFormer: Motion-Primitive Transformer for Wearable-Sensor Activity Recognition, https://arxiv.org/pdf/2505.20744, 2025-10-27
2025-11-09 17:37:50,125 - INFO - root - Page:2, Index:48, Optimizing edge AI models on HPC systems with the edge in the loop, https://arxiv.org/pdf/2505.19995, 2025-05-26
2025-11-09 17:37:50,126 - INFO - root - Fetching page 4 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=150
2025-11-09 17:38:07,293 - INFO - root - get_all_titles_from_web 
2025-11-09 17:38:07,294 - INFO - root - Page:3, Index:0, DPASyn: Mechanism-Aware Drug Synergy Prediction via Dual Attention and Precision-Aware Quantization, https://arxiv.org/pdf/2505.19144, 2025-09-20
2025-11-09 17:38:07,294 - INFO - root - Page:3, Index:1, Reducing Storage of Pretrained Neural Networks by Rate-Constrained Quantization and Entropy Coding, https://arxiv.org/pdf/2505.18758, 2025-05-24
2025-11-09 17:38:07,294 - INFO - root - Page:3, Index:2, Beyond Discreteness: Finite-Sample Analysis of Straight-Through Estimator for Quantization, https://arxiv.org/pdf/2505.18113, 2025-05-23
2025-11-09 17:38:07,295 - INFO - root - Page:3, Index:3, Automating Versatile Time-Series Analysis with Tiny Transformers on Embedded FPGAs, https://arxiv.org/pdf/2505.17662, 2025-09-19
2025-11-09 17:38:07,295 - INFO - root - Page:3, Index:4, FPQVAR: Floating Point Quantization for Visual Autoregressive Model with FPGA Hardware Co-design, https://arxiv.org/pdf/2505.16335, 2025-05-22
2025-11-09 17:38:07,295 - INFO - root - Page:3, Index:5, Saliency-Aware Quantized Imitation Learning for Efficient Robotic Control, https://arxiv.org/pdf/2505.15304, 2025-05-30
2025-11-09 17:38:07,296 - INFO - root - Page:3, Index:6, Scaling Law for Quantization-Aware Training, https://arxiv.org/pdf/2505.14302, 2025-05-20
2025-11-09 17:38:07,296 - INFO - root - Page:3, Index:7, Automatic mixed precision for optimizing gained time with constrained loss mean-squared-error based on model partition to sequential sub-graphs, https://arxiv.org/pdf/2505.13060, 2025-05-19
2025-11-09 17:38:07,296 - INFO - root - Page:3, Index:8, Deep Unfolding with Kernel-based Quantization in MIMO Detection, https://arxiv.org/pdf/2505.12736, 2025-05-19
2025-11-09 17:38:07,297 - INFO - root - Page:3, Index:9, FedHQ: Hybrid Runtime Quantization for Federated Learning, https://arxiv.org/pdf/2505.11982, 2025-05-17
2025-11-09 17:38:07,297 - INFO - root - Page:3, Index:10, QVGen: Pushing the Limit of Quantized Video Generative Models, https://arxiv.org/pdf/2505.11497, 2025-09-27
2025-11-09 17:38:07,297 - INFO - root - Page:3, Index:11, EA-3DGS: Efficient and Adaptive 3D Gaussians with Highly Enhanced Quality for outdoor scenes, https://arxiv.org/pdf/2505.10787, 2025-05-15
2025-11-09 17:38:07,297 - INFO - root - Page:3, Index:12, ITERA-LLM: Boosting Sub-8-Bit Large Language Model Inference via Iterative Tensor Decomposition, https://arxiv.org/pdf/2505.08981, 2025-05-13
2025-11-09 17:38:07,298 - INFO - root - Page:3, Index:13, PROM: Prioritize Reduction of Multiplications Over Lower Bit-Widths for Efficient CNNs, https://arxiv.org/pdf/2505.03254, 2025-08-06
2025-11-09 17:38:07,298 - INFO - root - Page:3, Index:14, ICQuant: Index Coding enables Low-bit LLM Quantization, https://arxiv.org/pdf/2505.00850, 2025-08-24
2025-11-09 17:38:07,298 - INFO - root - Page:3, Index:15, Enhancing Ultra-Low-Bit Quantization of Large Language Models Through Saliency-Aware Partial Retraining, https://arxiv.org/pdf/2504.13932, 2025-07-30
2025-11-09 17:38:07,298 - INFO - root - Page:3, Index:16, Achieving binary weight and activation for LLMs using Post-Training Quantization, https://arxiv.org/pdf/2504.05352, 2025-06-30
2025-11-09 17:38:07,299 - INFO - root - Page:3, Index:17, Wireless Hearables With Programmable Speech AI Accelerators, https://arxiv.org/pdf/2503.18698, 2025-10-21
2025-11-09 17:38:07,299 - INFO - root - Page:3, Index:18, GranQ: Efficient Channel-wise Quantization via Vectorized Pre-Scaling for Zero-Shot QAT, https://arxiv.org/pdf/2503.18339, 2025-10-15
2025-11-09 17:38:07,300 - INFO - root - Page:3, Index:19, CompMarkGS: Robust Watermarking for Compressed 3D Gaussian Splatting, https://arxiv.org/pdf/2503.12836, 2025-09-29
2025-11-09 17:38:07,300 - INFO - root - Page:3, Index:20, AHCPTQ: Accurate and Hardware-Compatible Post-Training Quantization for Segment Anything Model, https://arxiv.org/pdf/2503.03088, 2025-07-11
2025-11-09 17:38:07,302 - INFO - root - Page:3, Index:21, Teaching Metric Distance to Discrete Autoregressive Language Models, https://arxiv.org/pdf/2503.02379, 2025-10-07
2025-11-09 17:38:07,303 - INFO - root - Page:3, Index:22, Regularization-based Framework for Quantization-, Fault- and Variability-Aware Training, https://arxiv.org/pdf/2503.01297, 2025-07-12
2025-11-09 17:38:07,303 - INFO - root - Fetching page 5 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=200
2025-11-09 17:38:12,599 - INFO - root - get_all_titles_from_web 
2025-11-09 17:38:12,600 - INFO - root - Page:4, Index:0, Investigating the Impact of Quantization Methods on the Safety and Reliability of Large Language Models, https://arxiv.org/pdf/2502.15799, 2025-06-29
2025-11-09 17:38:12,600 - INFO - root - Page:4, Index:1, Rotate, Clip, and Partition: Towards W2A4KV4 Quantization by Integrating Rotation and Learnable Non-uniform Quantizer, https://arxiv.org/pdf/2502.15779, 2025-09-01
2025-11-09 17:38:12,601 - INFO - root - Page:4, Index:2, RoSTE: An Efficient Quantization-Aware Supervised Fine-Tuning Approach for Large Language Models, https://arxiv.org/pdf/2502.09003, 2025-06-05
2025-11-09 17:38:12,601 - INFO - root - Page:4, Index:3, Spatial Degradation-Aware and Temporal Consistent Diffusion Model for Compressed Video Super-Resolution, https://arxiv.org/pdf/2502.07381, 2025-06-27
2025-11-09 17:38:12,601 - INFO - root - Page:4, Index:4, QuEST: Stable Training of LLMs with 1-Bit Weights and Activations, https://arxiv.org/pdf/2502.05003, 2025-06-10
2025-11-09 17:38:12,601 - INFO - root - Page:4, Index:5, HALO: Hadamard-Assisted Lower-Precision Optimization for LLMs, https://arxiv.org/pdf/2501.02625, 2025-11-05
2025-11-09 17:38:12,602 - INFO - root - Page:4, Index:6, TAR3D: Creating High-Quality 3D Assets via Next-Part Prediction, https://arxiv.org/pdf/2412.16919, 2025-08-08
2025-11-09 17:38:12,602 - INFO - root - Page:4, Index:7, Training Multi-Layer Binary Neural Networks With Local Binary Error Signals, https://arxiv.org/pdf/2412.00119, 2025-08-05
2025-11-09 17:38:12,602 - INFO - root - Page:4, Index:8, Scaling Large-scale GNN Training to Thousands of Processors on CPU-based Supercomputers, https://arxiv.org/pdf/2411.16025, 2025-05-26
2025-11-09 17:38:12,602 - INFO - root - Page:4, Index:9, HAFLQ: Heterogeneous Adaptive Federated LoRA Fine-tuned LLM with Quantization, https://arxiv.org/pdf/2411.06581, 2025-05-16
2025-11-09 17:38:12,604 - INFO - root - Fetching page 6 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=250
2025-11-09 17:38:25,080 - INFO - root - get_all_titles_from_web 
2025-11-09 17:38:25,082 - INFO - root - Page:5, Index:0, Gradient-Free Training of Quantized Neural Networks, https://arxiv.org/pdf/2410.09734, 2025-09-29
2025-11-09 17:38:25,082 - INFO - root - Page:5, Index:1, QT-DoG: Quantization-aware Training for Domain Generalization, https://arxiv.org/pdf/2410.06020, 2025-06-26
2025-11-09 17:38:25,083 - INFO - root - Page:5, Index:2, Constraint Guided Model Quantization of Neural Networks, https://arxiv.org/pdf/2409.20138, 2025-09-12
2025-11-09 17:38:25,083 - INFO - root - Page:5, Index:3, Accumulator-Aware Post-Training Quantization for Large Language Models, https://arxiv.org/pdf/2409.17092, 2025-07-30
2025-11-09 17:38:25,084 - INFO - root - Page:5, Index:4, DilateQuant: Accurate and Efficient Diffusion Quantization via Weight Dilation, https://arxiv.org/pdf/2409.14307, 2025-07-09
2025-11-09 17:38:25,086 - INFO - root - Page:5, Index:5, Robust Training of Neural Networks at Arbitrary Precision and Sparsity, https://arxiv.org/pdf/2409.09245, 2025-09-23
2025-11-09 17:38:25,116 - INFO - root - Page:5, Index:6, VQ-CTAP: Cross-Modal Fine-Grained Sequence Representation Learning for Speech Processing, https://arxiv.org/pdf/2408.05758, 2025-05-27
2025-11-09 17:38:25,140 - INFO - root - Page:5, Index:7, DopQ-ViT: Towards Distribution-Friendly and Outlier-Aware Post-Training Quantization for Vision Transformers, https://arxiv.org/pdf/2408.03291, 2025-06-19
2025-11-09 17:38:25,174 - INFO - root - Page:5, Index:8, Temporal Feature Matters: A Framework for Diffusion Model Quantization, https://arxiv.org/pdf/2407.19547, 2025-07-11
2025-11-09 17:38:25,208 - INFO - root - Page:5, Index:9, EfficientQAT: Efficient Quantization-Aware Training for Large Language Models, https://arxiv.org/pdf/2407.11062, 2025-05-19
2025-11-09 17:38:25,260 - INFO - root - Page:5, Index:10, Integer-only Quantized Transformers for Embedded FPGA-based Time-series Forecasting in AIoT, https://arxiv.org/pdf/2407.11041, 2025-10-31
2025-11-09 17:38:25,361 - INFO - root - Fetching page 7 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=300
2025-11-09 17:39:04,384 - INFO - root - get_all_titles_from_web 
2025-11-09 17:39:04,385 - INFO - root - Page:6, Index:0, BoA: Attention-aware Post-training Quantization without Backpropagation, https://arxiv.org/pdf/2406.13474, 2025-06-06
2025-11-09 17:39:04,386 - INFO - root - Page:6, Index:1, A Rescaling-Invariant Lipschitz Bound Based on Path-Metrics for Modern ReLU Network Parameterizations, https://arxiv.org/pdf/2405.15006, 2025-06-13
2025-11-09 17:39:04,386 - INFO - root - Page:6, Index:2, Scheduling Weight Transitions for Quantization-Aware Training, https://arxiv.org/pdf/2404.19248, 2025-10-01
2025-11-09 17:39:04,387 - INFO - root - Page:6, Index:3, GPTVQ: The Blessing of Dimensionality for LLM Quantization, https://arxiv.org/pdf/2402.15319, 2025-06-03
2025-11-09 17:39:04,392 - INFO - root - Fetching page 8 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=350
2025-11-09 17:39:32,163 - INFO - root - get_all_titles_from_web 
2025-11-09 17:39:32,163 - INFO - root - Page:7, Index:0, Squat: Quant Small Language Models on the Edge, https://arxiv.org/pdf/2402.10787, 2025-07-01
2025-11-09 17:39:32,163 - INFO - root - Page:7, Index:1, L4Q: Parameter Efficient Quantization-Aware Fine-Tuning on Large Language Models, https://arxiv.org/pdf/2402.04902, 2025-07-21
2025-11-09 17:39:32,164 - INFO - root - Fetching page 9 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=400
2025-11-09 17:39:50,822 - INFO - root - ------------------------------------------------------------------------------------------------------------------------
2025-11-09 19:30:28,901 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-09 19:30:28,903 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-09 19:30:28,907 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-09 19:31:20,197 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-09 19:31:20,198 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-09 19:31:20,204 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-09 19:31:21,363 - INFO - root - LLMClientManager: 指定使用客户端: Doubao
2025-11-09 19:31:21,366 - INFO - root - DoubaoClient: API key found: 9f9e270e-b...
2025-11-09 19:31:25,824 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 19:31:25,870 - INFO - root - DoubaoClient: initialized successfully with model doubao-seed-1-6-lite-251015
2025-11-09 19:31:25,871 - INFO - root - LLMClientManager: Doubao 客户端初始化成功
2025-11-09 19:31:25,871 - INFO - root - LLMClientManager: switched to Doubao client
2025-11-09 19:31:25,871 - INFO - root - 已手动切换到 LLM 客户端: Doubao
2025-11-09 19:31:25,873 - INFO - root - 使用 LLM 模型: doubao-seed-1-6-lite-251015
2025-11-09 19:31:25,876 - INFO - root - 可用客户端: ['Doubao']
2025-11-09 19:31:25,877 - INFO - root - === 运行配置 ===
2025-11-09 19:31:25,877 - INFO - root - 处理模式: arxiv在线搜索
2025-11-09 19:31:25,877 - INFO - root - 关键词: hp
2025-11-09 19:31:25,877 - INFO - root - 查询: high pressure selenium
2025-11-09 19:31:25,877 - INFO - root - 排序: None
2025-11-09 19:31:25,879 - INFO - root - 最近天数: 180
2025-11-09 19:31:25,879 - INFO - root - 最大处理数量: 2
2025-11-09 19:31:25,881 - INFO - root - 保存图片: 是
2025-11-09 19:31:25,882 - INFO - root - 输出语言: 中文
2025-11-09 19:31:25,882 - INFO - root - 强制重新处理: 否
2025-11-09 19:31:25,882 - INFO - root - ====================
2025-11-09 19:31:25,883 - INFO - root - 使用 arXiv 搜索模式（通过 chat_arxiv 模块获取）
2025-11-09 19:31:25,883 - INFO - root - Fetching page 1 with URL: https://arxiv.org/search/?query=high+pressure+selenium&searchtype=all&abstracts=show&order=-announced_date_first&size=50
2025-11-09 19:31:31,884 - INFO - root - ------------------------------------------------------------------------------------------------------------------------
2025-11-09 19:31:31,884 - INFO - root - 没有找到要处理的论文，程序退出
2025-11-09 19:31:31,885 - INFO - root - summary time: 11.69 seconds
2025-11-09 19:42:52,555 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-09 19:42:52,558 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-09 19:42:52,559 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-09 19:42:53,724 - INFO - root - LLMClientManager: 指定使用客户端: Deepseek
2025-11-09 19:42:53,725 - INFO - root - DeepSeekClient: API key found: your_deeps...
2025-11-09 19:42:53,726 - INFO - root - DeepSeekClient: 使用模式: 直接API
2025-11-09 19:42:53,727 - WARNING - root - DeepSeekClient: API key not provided or using placeholder. LLM disabled.
2025-11-09 19:42:53,727 - ERROR - root - LLMClientManager: 指定的客户端 DeepSeek 初始化失败
2025-11-09 19:42:53,728 - WARNING - root - LLMClientManager: 指定的客户端 Deepseek 不可用，将尝试其他客户端
2025-11-09 19:42:54,520 - INFO - root - GeminiClient: trying model gemini-2.5-flash
2025-11-09 19:44:04,414 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-09 19:44:04,416 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-09 19:44:04,419 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-09 19:44:07,571 - INFO - root - LLMClientManager: 指定使用客户端: Deepseek
2025-11-09 19:44:07,572 - INFO - root - DeepSeekClient: API key found: your_deeps...
2025-11-09 19:44:07,573 - INFO - root - DeepSeekClient: 使用模式: 直接API
2025-11-09 19:44:07,573 - WARNING - root - DeepSeekClient: API key not provided or using placeholder. LLM disabled.
2025-11-09 19:44:07,574 - ERROR - root - LLMClientManager: 指定的客户端 DeepSeek 初始化失败
2025-11-09 19:44:07,574 - WARNING - root - LLMClientManager: 指定的客户端 Deepseek 不可用，将尝试其他客户端
2025-11-09 19:44:08,406 - INFO - root - GeminiClient: trying model gemini-2.5-flash
2025-11-09 19:44:11,267 - INFO - root - GeminiClient: initialized model gemini-2.5-flash
2025-11-09 19:44:11,269 - INFO - root - LLMClientManager: Gemini client initialized successfully
2025-11-09 19:44:11,269 - INFO - root - LLMClientManager: using Gemini as default client
2025-11-09 19:44:11,270 - WARNING - root - KimiClient: API key not provided. LLM disabled.
2025-11-09 19:44:11,271 - WARNING - root - LLMClientManager: Kimi client initialization failed
2025-11-09 19:44:11,272 - WARNING - root - QwenClient: API key not provided. LLM disabled.
2025-11-09 19:44:11,272 - WARNING - root - LLMClientManager: Qwen client initialization failed
2025-11-09 19:44:11,282 - INFO - root - DoubaoClient: API key found: 9f9e270e-b...
2025-11-09 19:44:19,859 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 19:44:19,910 - INFO - root - DoubaoClient: initialized successfully with model doubao-seed-1-6-lite-251015
2025-11-09 19:44:19,910 - INFO - root - LLMClientManager: Doubao client initialized successfully
2025-11-09 19:44:19,910 - WARNING - root - LLMClientManager: client Deepseek not available
2025-11-09 19:44:19,911 - WARNING - root - 无法切换到指定的客户端 Deepseek，将使用默认客户端
2025-11-09 19:44:19,911 - INFO - root - 可用客户端: ['Gemini', 'Doubao']
2025-11-09 19:44:19,912 - INFO - root - 使用 LLM 模型: gemini-2.5-flash
2025-11-09 19:44:19,912 - INFO - root - 可用客户端: ['Gemini', 'Doubao']
2025-11-09 19:44:19,913 - INFO - root - === 运行配置 ===
2025-11-09 19:44:19,914 - INFO - root - 处理模式: arxiv在线搜索
2025-11-09 19:44:19,914 - INFO - root - 关键词: QAT
2025-11-09 19:44:19,914 - INFO - root - 查询: Quantization-Aware-Training
2025-11-09 19:44:19,915 - INFO - root - 排序: None
2025-11-09 19:44:19,917 - INFO - root - 最近天数: 180
2025-11-09 19:44:19,919 - INFO - root - 最大处理数量: 2
2025-11-09 19:44:19,922 - INFO - root - 保存图片: 是
2025-11-09 19:44:19,924 - INFO - root - 输出语言: 中文
2025-11-09 19:44:19,925 - INFO - root - 强制重新处理: 否
2025-11-09 19:44:19,925 - INFO - root - ====================
2025-11-09 19:44:19,927 - INFO - root - 使用 arXiv 搜索模式（通过 chat_arxiv 模块获取）
2025-11-09 19:44:19,928 - INFO - root - Fetching page 1 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50
2025-11-09 19:44:26,277 - INFO - root - get_all_titles_from_web 
2025-11-09 19:44:26,277 - INFO - root - Page:0, Index:0, A Quantized VAE-MLP Botnet Detection Model: A Systematic Evaluation of Quantization-Aware Training and Post-Training Quantization Strategies, https://arxiv.org/pdf/2511.03201, 2025-11-05
2025-11-09 19:44:26,279 - INFO - root - Page:0, Index:1, FP8-Flow-MoE: A Casting-Free FP8 Recipe without Double Quantization Error, https://arxiv.org/pdf/2511.02302, 2025-11-04
2025-11-09 19:44:26,280 - INFO - root - Page:0, Index:2, Outlier-Aware Post-Training Quantization for Image Super-Resolution, https://arxiv.org/pdf/2511.00682, 2025-11-01
2025-11-09 19:44:26,281 - INFO - root - Page:0, Index:3, Evaluation of Wafer-Scale SOT-MRAM for Analog Crossbar Array Applications, https://arxiv.org/pdf/2510.25853, 2025-11-03
2025-11-09 19:44:26,281 - INFO - root - Page:0, Index:4, Improving the Straight-Through Estimator with Zeroth-Order Information, https://arxiv.org/pdf/2510.23926, 2025-10-27
2025-11-09 19:44:26,281 - INFO - root - Page:0, Index:5, Real-Time Semantic Segmentation on FPGA for Autonomous Vehicles Using LMIINet with the CGRA4ML Framework, https://arxiv.org/pdf/2510.22243, 2025-10-25
2025-11-09 19:44:26,282 - INFO - root - Page:0, Index:6, TernaryCLIP: Efficiently Compressing Vision-Language Models with Ternary Weights and Distilled Knowledge, https://arxiv.org/pdf/2510.21879, 2025-10-23
2025-11-09 19:44:26,282 - INFO - root - Page:0, Index:7, KARIPAP: Quantum-Inspired Tensor Network Compression of Large Language Models Using Infinite Projected Entangled Pair States and Tensor Renormalization Group, https://arxiv.org/pdf/2510.21844, 2025-10-22
2025-11-09 19:44:26,283 - INFO - root - Page:0, Index:8, A Convergence Analysis of Adaptive Optimizers under Floating-point Quantization, https://arxiv.org/pdf/2510.21314, 2025-10-24
2025-11-09 19:44:26,283 - INFO - root - Page:0, Index:9, Adaptive Distribution-aware Quantization for Mixed-Precision Neural Networks, https://arxiv.org/pdf/2510.19760, 2025-10-22
2025-11-09 19:44:26,283 - INFO - root - Page:0, Index:10, CAGE: Curvature-Aware Gradient Estimation For Accurate Quantization-Aware Training, https://arxiv.org/pdf/2510.18784, 2025-10-21
2025-11-09 19:44:26,284 - INFO - root - Page:0, Index:11, Mixed-Precision Quantization for Language Models: Techniques and Prospects, https://arxiv.org/pdf/2510.16805, 2025-10-19
2025-11-09 19:44:26,284 - INFO - root - Page:0, Index:12, SPLite Hand: Sparsity-Aware Lightweight 3D Hand Pose Estimation, https://arxiv.org/pdf/2510.16396, 2025-10-30
2025-11-09 19:44:26,285 - INFO - root - Page:0, Index:13, CTR-LoRA: Curvature-Aware and Trust-Region Guided Low-Rank Adaptation for Large Language Models, https://arxiv.org/pdf/2510.15962, 2025-10-11
2025-11-09 19:44:26,285 - INFO - root - Page:0, Index:14, SANR: Scene-Aware Neural Representation for Light Field Image Compression with Rate-Distortion Optimization, https://arxiv.org/pdf/2510.15775, 2025-10-17
2025-11-09 19:44:26,286 - INFO - root - Page:0, Index:15, SpikeFit: Towards Optimal Deployment of Spiking Networks on Neuromorphic Hardware, https://arxiv.org/pdf/2510.15542, 2025-10-31
2025-11-09 19:44:26,286 - INFO - root - Page:0, Index:16, GRank: Towards Target-Aware and Streamlined Industrial Retrieval with a Generate-Rank Framework, https://arxiv.org/pdf/2510.15299, 2025-10-17
2025-11-09 19:44:26,287 - INFO - root - Page:0, Index:17, SaLon3R: Structure-aware Long-term Generalizable 3D Reconstruction from Unposed Images, https://arxiv.org/pdf/2510.15072, 2025-10-16
2025-11-09 19:44:26,288 - INFO - root - Page:0, Index:18, FraQAT: Quantization Aware Training with Fractional bits, https://arxiv.org/pdf/2510.14823, 2025-10-16
2025-11-09 19:44:26,290 - INFO - root - Page:0, Index:19, Computing-In-Memory Aware Model Adaption For Edge Devices, https://arxiv.org/pdf/2510.14379, 2025-10-16
2025-11-09 19:44:26,292 - INFO - root - Page:0, Index:20, Invited Paper: BitMedViT: Ternary-Quantized Vision Transformer for Medical AI Assistants on the Edge, https://arxiv.org/pdf/2510.13760, 2025-11-04
2025-11-09 19:44:26,292 - INFO - root - Page:0, Index:21, NeuroRVQ: Multi-Scale EEG Tokenization for Generative Large Brainwave Models, https://arxiv.org/pdf/2510.13068, 2025-10-14
2025-11-09 19:44:26,293 - INFO - root - Page:0, Index:22, Detect Anything via Next Point Prediction, https://arxiv.org/pdf/2510.12798, 2025-10-14
2025-11-09 19:44:26,294 - INFO - root - Page:0, Index:23, AndesVL Technical Report: An Efficient Mobile-side Multimodal Large Language Model, https://arxiv.org/pdf/2510.11496, 2025-10-14
2025-11-09 19:44:26,294 - INFO - root - Page:0, Index:24, Rescaling-Aware Training for Efficient Deployment of Deep Learning Models on Full-Integer Hardware, https://arxiv.org/pdf/2510.11484, 2025-10-13
2025-11-09 19:44:26,295 - INFO - root - Page:0, Index:25, SASER: Stego attacks on open-source LLMs, https://arxiv.org/pdf/2510.10486, 2025-10-12
2025-11-09 19:44:26,295 - INFO - root - Page:0, Index:26, Ultralytics YOLO Evolution: An Overview of YOLO26, YOLO11, YOLOv8 and YOLOv5 Object Detectors for Computer Vision and Pattern Recognition, https://arxiv.org/pdf/2510.09653, 2025-10-15
2025-11-09 19:44:26,296 - INFO - root - Page:0, Index:27, A Theoretically-Grounded Codebook for Digital Semantic Communications, https://arxiv.org/pdf/2510.07108, 2025-10-14
2025-11-09 19:44:26,297 - INFO - root - Page:0, Index:28, QuantDemoire: Quantization with Outlier Aware for Image Demoiréing, https://arxiv.org/pdf/2510.04066, 2025-10-05
2025-11-09 19:44:26,300 - INFO - root - Page:0, Index:29, Adaptively Sampling-Reusing-Mixing Decomposed Gradients to Speed Up Sharpness Aware Minimization, https://arxiv.org/pdf/2510.03763, 2025-10-04
2025-11-09 19:44:26,301 - INFO - root - Page:0, Index:30, Quant-dLLM: Post-Training Extreme Low-Bit Quantization for Diffusion Large Language Models, https://arxiv.org/pdf/2510.03274, 2025-09-27
2025-11-09 19:44:26,302 - INFO - root - Page:0, Index:31, PT$^2$-LLM: Post-Training Ternarization for Large Language Models, https://arxiv.org/pdf/2510.03267, 2025-09-26
2025-11-09 19:44:26,302 - INFO - root - Page:0, Index:32, Purrception: Variational Flow Matching for Vector-Quantized Image Generation, https://arxiv.org/pdf/2510.01478, 2025-10-01
2025-11-09 19:44:26,302 - INFO - root - Page:0, Index:33, Post-Training Quantization for Audio Diffusion Transformers, https://arxiv.org/pdf/2510.00313, 2025-09-30
2025-11-09 19:44:26,305 - INFO - root - Page:0, Index:34, Rethinking RoPE Scaling in Quantized LLM: Theory, Outlier, and Channel-Band Analysis with Weight Rescaling, https://arxiv.org/pdf/2510.00028, 2025-09-25
2025-11-09 19:44:26,306 - INFO - root - Page:0, Index:35, Post-Training Quantization via Residual Truncation and Zero Suppression for Diffusion Models, https://arxiv.org/pdf/2509.26436, 2025-09-30
2025-11-09 19:44:26,307 - INFO - root - Page:0, Index:36, Cat: Post-Training Quantization Error Reduction via Cluster-based Affine Transformation, https://arxiv.org/pdf/2509.26277, 2025-10-07
2025-11-09 19:44:26,308 - INFO - root - Page:0, Index:37, CAST: Continuous and Differentiable Semi-Structured Sparsity-Aware Training for Large Language Models, https://arxiv.org/pdf/2509.25996, 2025-09-30
2025-11-09 19:44:26,309 - INFO - root - Page:0, Index:38, Norm-Q: Effective Compression Method for Hidden Markov Models in Neuro-Symbolic Applications, https://arxiv.org/pdf/2509.25439, 2025-09-29
2025-11-09 19:44:26,310 - INFO - root - Page:0, Index:39, On-the-Fly Adaptation to Quantization: Configuration-Aware LoRA for Efficient Fine-Tuning of Quantized LLMs, https://arxiv.org/pdf/2509.25214, 2025-09-22
2025-11-09 19:44:26,310 - INFO - root - Page:0, Index:40, VoxCPM: Tokenizer-Free TTS for Context-Aware Speech Generation and True-to-Life Voice Cloning, https://arxiv.org/pdf/2509.24650, 2025-09-29
2025-11-09 19:44:26,311 - INFO - root - Page:0, Index:41, S$^2$NN: Sub-bit Spiking Neural Networks, https://arxiv.org/pdf/2509.24266, 2025-10-24
2025-11-09 19:44:26,311 - INFO - root - Page:0, Index:42, Tequila: Trapping-free Ternary Quantization for Large Language Models, https://arxiv.org/pdf/2509.23809, 2025-10-17
2025-11-09 19:44:26,312 - INFO - root - Page:0, Index:43, Texture Vector-Quantization and Reconstruction Aware Prediction for Generative Super-Resolution, https://arxiv.org/pdf/2509.23774, 2025-09-30
2025-11-09 19:44:26,312 - INFO - root - Page:0, Index:44, RobuQ: Pushing DiTs to W1.58A2 via Robust Activation Quantization, https://arxiv.org/pdf/2509.23582, 2025-09-27
2025-11-09 19:44:26,313 - INFO - root - Page:0, Index:45, Beyond Outliers: A Study of Optimizers Under Quantization, https://arxiv.org/pdf/2509.23500, 2025-10-02
2025-11-09 19:44:26,313 - INFO - root - Page:0, Index:46, Compute-Optimal Quantization-Aware Training, https://arxiv.org/pdf/2509.22935, 2025-09-26
2025-11-09 19:44:26,314 - INFO - root - Page:0, Index:47, COSPADI: Compressing LLMs via Calibration-Guided Sparse Dictionary Learning, https://arxiv.org/pdf/2509.22075, 2025-10-06
2025-11-09 19:44:26,314 - INFO - root - Page:0, Index:48, SlimDiff: Training-Free, Activation-Guided Hands-free Slimming of Diffusion Models, https://arxiv.org/pdf/2509.21498, 2025-09-25
2025-11-09 19:44:26,314 - INFO - root - Page:0, Index:49, Quantized Visual Geometry Grounded Transformer, https://arxiv.org/pdf/2509.21302, 2025-09-29
2025-11-09 19:44:26,316 - INFO - root - Fetching page 2 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=50
2025-11-09 19:44:36,067 - INFO - root - get_all_titles_from_web 
2025-11-09 19:44:36,068 - INFO - root - Page:1, Index:0, Can Less Precise Be More Reliable? A Systematic Evaluation of Quantization's Impact on CLIP Beyond Accuracy, https://arxiv.org/pdf/2509.21173, 2025-10-27
2025-11-09 19:44:36,069 - INFO - root - Page:1, Index:1, Punching Above Precision: Small Quantized Model Distillation with Learnable Regularizer, https://arxiv.org/pdf/2509.20854, 2025-09-25
2025-11-09 19:44:36,069 - INFO - root - Page:1, Index:2, TinyEcoWeedNet: Edge Efficient Real-Time Aerial Agricultural Weed Detection, https://arxiv.org/pdf/2509.18193, 2025-09-19
2025-11-09 19:44:36,070 - INFO - root - Page:1, Index:3, SBVR: Summation of BitVector Representation for Efficient LLM Quantization, https://arxiv.org/pdf/2509.18172, 2025-09-17
2025-11-09 19:44:36,070 - INFO - root - Page:1, Index:4, QWHA: Quantization-Aware Walsh-Hadamard Adaptation for Parameter-Efficient Fine-Tuning on Large Language Models, https://arxiv.org/pdf/2509.17428, 2025-09-26
2025-11-09 19:44:36,071 - INFO - root - Page:1, Index:5, PTQTP: Post-Training Quantization to Trit-Planes for Large Language Models, https://arxiv.org/pdf/2509.16989, 2025-10-28
2025-11-09 19:44:36,071 - INFO - root - Page:1, Index:6, MEC-Quant: Maximum Entropy Coding for Extremely Low Bit Quantization-Aware Training, https://arxiv.org/pdf/2509.15514, 2025-09-18
2025-11-09 19:44:36,071 - INFO - root - Page:1, Index:7, Q-ROAR: Outlier-Aware Rescaling for RoPE Position Interpolation in Quantized Long-Context LLMs, https://arxiv.org/pdf/2509.14391, 2025-09-17
2025-11-09 19:44:36,076 - INFO - root - Page:1, Index:8, Efficient Quantization-Aware Neural Receivers: Beyond Post-Training Quantization, https://arxiv.org/pdf/2509.13786, 2025-09-19
2025-11-09 19:44:36,077 - INFO - root - Page:1, Index:9, Rate-Distortion Limits for Multimodal Retrieval: Theory, Optimal Codes, and Finite-Sample Guarantees, https://arxiv.org/pdf/2509.11054, 2025-09-13
2025-11-09 19:44:36,078 - INFO - root - Page:1, Index:10, SQAP-VLA: A Synergistic Quantization-Aware Pruning Framework for High-Performance Vision-Language-Action Models, https://arxiv.org/pdf/2509.09090, 2025-09-10
2025-11-09 19:44:36,078 - INFO - root - Page:1, Index:11, CSI Compression Beyond Latents: End-to-End Hybrid Attention-CNN Networks with Entropy Regularization, https://arxiv.org/pdf/2509.08776, 2025-09-10
2025-11-09 19:44:36,079 - INFO - root - Page:1, Index:12, Explaining How Quantization Disparately Skews a Model, https://arxiv.org/pdf/2509.07222, 2025-09-08
2025-11-09 19:44:36,079 - INFO - root - Page:1, Index:13, LoaQ: Layer-wise Output Approximation Quantization, https://arxiv.org/pdf/2509.06297, 2025-09-07
2025-11-09 19:44:36,080 - INFO - root - Page:1, Index:14, FineServe: Precision-Aware KV Slab and Two-Level Scheduling for Heterogeneous Precision LLM Serving, https://arxiv.org/pdf/2509.06261, 2025-09-14
2025-11-09 19:44:36,081 - INFO - root - Page:1, Index:15, Sensitivity-Aware Post-Training Quantization for Deep Neural Networks, https://arxiv.org/pdf/2509.05576, 2025-09-05
2025-11-09 19:44:36,082 - INFO - root - Page:1, Index:16, SuperSNN: A Hardware-Aware Framework for Physically Realizable, High-Performance Superconducting Spiking Neural Network Chips, https://arxiv.org/pdf/2509.05532, 2025-09-05
2025-11-09 19:44:36,084 - INFO - root - Page:1, Index:17, Data-Augmented Quantization-Aware Knowledge Distillation, https://arxiv.org/pdf/2509.03850, 2025-09-03
2025-11-09 19:44:36,085 - INFO - root - Page:1, Index:18, DPQuant: Efficient and Differentially-Private Model Training via Dynamic Quantization Scheduling, https://arxiv.org/pdf/2509.03472, 2025-09-03
2025-11-09 19:44:36,086 - INFO - root - Page:1, Index:19, Empowering Large Language Model for Sequential Recommendation via Multimodal Embeddings and Semantic IDs, https://arxiv.org/pdf/2509.02017, 2025-09-02
2025-11-09 19:44:36,086 - INFO - root - Page:1, Index:20, Q-Sched: Pushing the Boundaries of Few-Step Diffusion Models with Quantization-Aware Scheduling, https://arxiv.org/pdf/2509.01624, 2025-09-01
2025-11-09 19:44:36,087 - INFO - root - Page:1, Index:21, Quantization Meets OOD: Generalizable Quantization-aware Training from a Flatness Perspective, https://arxiv.org/pdf/2509.00859, 2025-08-31
2025-11-09 19:44:36,087 - INFO - root - Page:1, Index:22, Progressive Element-wise Gradient Estimation for Neural Network Quantization, https://arxiv.org/pdf/2509.00097, 2025-08-27
2025-11-09 19:44:36,088 - INFO - root - Page:1, Index:23, End-to-End On-Device Quantization-Aware Training for LLMs at Inference Cost, https://arxiv.org/pdf/2509.00031, 2025-09-29
2025-11-09 19:44:36,089 - INFO - root - Page:1, Index:24, Quantization Robustness to Input Degradations for Object Detection, https://arxiv.org/pdf/2508.19600, 2025-08-27
2025-11-09 19:44:36,090 - INFO - root - Page:1, Index:25, Scaling Laws for Task-Stratified Knowledge in Post-Training Quantized Large Language Models, https://arxiv.org/pdf/2508.18609, 2025-08-27
2025-11-09 19:44:36,091 - INFO - root - Page:1, Index:26, AQ-PCDSys: An Adaptive Quantized Planetary Crater Detection System for Autonomous Space Exploration, https://arxiv.org/pdf/2508.18025, 2025-08-25
2025-11-09 19:44:36,091 - INFO - root - Page:1, Index:27, TaDiCodec: Text-aware Diffusion Speech Tokenizer for Speech Language Modeling, https://arxiv.org/pdf/2508.16790, 2025-08-22
2025-11-09 19:44:36,092 - INFO - root - Page:1, Index:28, A Node-Aware Dynamic Quantization Approach for Graph Collaborative Filtering, https://arxiv.org/pdf/2508.16516, 2025-08-22
2025-11-09 19:44:36,093 - INFO - root - Page:1, Index:29, JEDI-linear: Fast and Efficient Graph Neural Networks for Jet Tagging on FPGAs, https://arxiv.org/pdf/2508.15468, 2025-08-21
2025-11-09 19:44:36,094 - INFO - root - Page:1, Index:30, MMQ: Multimodal Mixture-of-Quantization Tokenization for Semantic ID Generation and User Behavioral Adaptation, https://arxiv.org/pdf/2508.15281, 2025-08-21
2025-11-09 19:44:36,094 - INFO - root - Page:1, Index:31, DLLMQuant: Quantizing Diffusion-based Large Language Models, https://arxiv.org/pdf/2508.14090, 2025-08-25
2025-11-09 19:44:36,096 - INFO - root - Page:1, Index:32, Automated Energy-Aware Time-Series Model Deployment on Embedded FPGAs for Resilient Combined Sewer Overflow Management, https://arxiv.org/pdf/2508.13905, 2025-08-19
2025-11-09 19:44:36,106 - INFO - root - Page:1, Index:33, XR-NPE: High-Throughput Mixed-precision SIMD Neural Processing Engine for Extended Reality Perception Workloads, https://arxiv.org/pdf/2508.13049, 2025-08-18
2025-11-09 19:44:36,107 - INFO - root - Page:1, Index:34, Exploring Self-Supervised Audio Models for Generalized Anomalous Sound Detection, https://arxiv.org/pdf/2508.12230, 2025-08-17
2025-11-09 19:44:36,107 - INFO - root - Page:1, Index:35, TriQDef: Disrupting Semantic and Gradient Alignment to Prevent Adversarial Patch Transferability in Quantized Neural Networks, https://arxiv.org/pdf/2508.12132, 2025-08-16
2025-11-09 19:44:36,107 - INFO - root - Page:1, Index:36, Error Propagation Mechanisms and Compensation Strategies for Quantized Diffusion, https://arxiv.org/pdf/2508.12094, 2025-10-13
2025-11-09 19:44:36,108 - INFO - root - Page:1, Index:37, Extending Straight-Through Estimation for Robust Neural Networks on Analog CIM Hardware, https://arxiv.org/pdf/2508.11940, 2025-08-16
2025-11-09 19:44:36,108 - INFO - root - Page:1, Index:38, PTQAT: A Hybrid Parameter-Efficient Quantization Algorithm for 3D Perception Tasks, https://arxiv.org/pdf/2508.10557, 2025-08-15
2025-11-09 19:44:36,108 - INFO - root - Page:1, Index:39, MiCo: End-to-End Mixed Precision Neural Network Co-Exploration Framework for Edge AI, https://arxiv.org/pdf/2508.09500, 2025-08-13
2025-11-09 19:44:36,109 - INFO - root - Page:1, Index:40, SPARC: Soft Probabilistic Adaptive multi-interest Retrieval Model via Codebooks for recommender system, https://arxiv.org/pdf/2508.09090, 2025-08-12
2025-11-09 19:44:36,109 - INFO - root - Page:1, Index:41, Rethinking 1-bit Optimization Leveraging Pre-trained Large Language Models, https://arxiv.org/pdf/2508.06974, 2025-08-09
2025-11-09 19:44:36,110 - INFO - root - Page:1, Index:42, Efficient Deep Neural Receiver with Post-Training Quantization, https://arxiv.org/pdf/2508.06275, 2025-08-08
2025-11-09 19:44:36,110 - INFO - root - Page:1, Index:43, iFairy: the First 2-bit Complex LLM with All Parameters in $\{\pm1, \pm i\}$, https://arxiv.org/pdf/2508.05571, 2025-08-16
2025-11-09 19:44:36,111 - INFO - root - Page:1, Index:44, S$^2$Q-VDiT: Accurate Quantized Video Diffusion Transformer with Salient Data and Sparse Token Distillation, https://arxiv.org/pdf/2508.04016, 2025-10-27
2025-11-09 19:44:36,111 - INFO - root - Page:1, Index:45, LRQ-DiT: Log-Rotation Post-Training Quantization of Diffusion Transformers for Image and Video Generation, https://arxiv.org/pdf/2508.03485, 2025-09-23
2025-11-09 19:44:36,112 - INFO - root - Page:1, Index:46, VLMQ: Efficient Post-Training Quantization for Large Vision-Language Models via Hessian Augmentation, https://arxiv.org/pdf/2508.03351, 2025-08-05
2025-11-09 19:44:36,113 - INFO - root - Page:1, Index:47, TF-MLPNet: Tiny Real-Time Neural Speech Separation, https://arxiv.org/pdf/2508.03047, 2025-08-04
2025-11-09 19:44:36,113 - INFO - root - Page:1, Index:48, SaviorRec: Semantic-Behavior Alignment for Cold-Start Recommendation, https://arxiv.org/pdf/2508.01375, 2025-08-02
2025-11-09 19:44:36,114 - INFO - root - Page:1, Index:49, MixA-Q: Revisiting Activation Sparsity for Vision Transformers from a Mixed-Precision Quantization Perspective, https://arxiv.org/pdf/2507.19131, 2025-07-25
2025-11-09 19:44:36,114 - INFO - root - Fetching page 3 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=100
2025-11-09 19:44:42,546 - INFO - root - get_all_titles_from_web 
2025-11-09 19:44:42,546 - INFO - root - Page:2, Index:0, Enhancing Quantization-Aware Training on Edge Devices via Relative Entropy Coreset Selection and Cascaded Layer Correction, https://arxiv.org/pdf/2507.17768, 2025-07-16
2025-11-09 19:44:42,547 - INFO - root - Page:2, Index:1, SiLQ: Simple Large Language Model Quantization-Aware Training, https://arxiv.org/pdf/2507.16933, 2025-07-22
2025-11-09 19:44:42,547 - INFO - root - Page:2, Index:2, Task-Specific Zero-shot Quantization-Aware Training for Object Detection, https://arxiv.org/pdf/2507.16782, 2025-07-22
2025-11-09 19:44:42,548 - INFO - root - Page:2, Index:3, TorchAO: PyTorch-Native Training-to-Serving Model Optimization, https://arxiv.org/pdf/2507.16099, 2025-07-21
2025-11-09 19:44:42,548 - INFO - root - Page:2, Index:4, SegQuant: A Semantics-Aware and Generalizable Quantization Framework for Diffusion Models, https://arxiv.org/pdf/2507.14811, 2025-08-27
2025-11-09 19:44:42,549 - INFO - root - Page:2, Index:5, Apple Intelligence Foundation Language Models: Tech Report 2025, https://arxiv.org/pdf/2507.13575, 2025-08-27
2025-11-09 19:44:42,549 - INFO - root - Page:2, Index:6, Generative Multi-Target Cross-Domain Recommendation, https://arxiv.org/pdf/2507.12871, 2025-08-07
2025-11-09 19:44:42,550 - INFO - root - Page:2, Index:7, DAF: An Efficient End-to-End Dynamic Activation Framework for on-Device DNN Training, https://arxiv.org/pdf/2507.07149, 2025-07-09
2025-11-09 19:44:42,550 - INFO - root - Page:2, Index:8, Opto-ViT: Architecting a Near-Sensor Region of Interest-Aware Vision Transformer Accelerator with Silicon Photonics, https://arxiv.org/pdf/2507.07044, 2025-07-15
2025-11-09 19:44:42,550 - INFO - root - Page:2, Index:9, QS4D: Quantization-aware training for efficient hardware deployment of structured state-space sequential models, https://arxiv.org/pdf/2507.06079, 2025-07-08
2025-11-09 19:44:42,551 - INFO - root - Page:2, Index:10, GSVR: 2D Gaussian-based Video Representation for 800+ FPS with Hybrid Deformation Field, https://arxiv.org/pdf/2507.05594, 2025-07-07
2025-11-09 19:44:42,551 - INFO - root - Page:2, Index:11, Hita: Holistic Tokenizer for Autoregressive Image Generation, https://arxiv.org/pdf/2507.02358, 2025-07-11
2025-11-09 19:44:42,552 - INFO - root - Page:2, Index:12, QPART: Adaptive Model Quantization and Dynamic Workload Balancing for Accuracy-aware Edge Inference, https://arxiv.org/pdf/2506.23934, 2025-06-30
2025-11-09 19:44:42,552 - INFO - root - Page:2, Index:13, FedWSQ: Efficient Federated Learning with Weight Standardization and Distribution-Aware Non-Uniform Quantization, https://arxiv.org/pdf/2506.23516, 2025-07-21
2025-11-09 19:44:42,553 - INFO - root - Page:2, Index:14, Spectra 1.1: Scaling Laws and Efficient Inference for Ternary Language Models, https://arxiv.org/pdf/2506.23025, 2025-06-28
2025-11-09 19:44:42,554 - INFO - root - Page:2, Index:15, Joint Quantization and Pruning Neural Networks Approach: A Case Study on FSO Receivers, https://arxiv.org/pdf/2506.20084, 2025-06-24
2025-11-09 19:44:42,555 - INFO - root - Page:2, Index:16, Single-step Diffusion for Image Compression at Ultra-Low Bitrates, https://arxiv.org/pdf/2506.16572, 2025-09-22
2025-11-09 19:44:42,561 - INFO - root - Page:2, Index:17, LittleBit: Ultra Low-Bit Quantization via Latent Factorization, https://arxiv.org/pdf/2506.13771, 2025-10-28
2025-11-09 19:44:42,562 - INFO - root - Page:2, Index:18, MARCO: Hardware-Aware Neural Architecture Search for Edge Devices with Multi-Agent Reinforcement Learning and Conformal Prediction Filtering, https://arxiv.org/pdf/2506.13755, 2025-06-16
2025-11-09 19:44:42,562 - INFO - root - Page:2, Index:19, EAQuant: Enhancing Post-Training Quantization for MoE Models via Expert-Aware Optimization, https://arxiv.org/pdf/2506.13329, 2025-07-04
2025-11-09 19:44:42,562 - INFO - root - Page:2, Index:20, Towards Neural Audio Codec Source Parsing, https://arxiv.org/pdf/2506.12627, 2025-06-14
2025-11-09 19:44:42,563 - INFO - root - Page:2, Index:21, Quantizing Small-Scale State-Space Models for Edge AI, https://arxiv.org/pdf/2506.12480, 2025-06-14
2025-11-09 19:44:42,563 - INFO - root - Page:2, Index:22, EMLoC: Emulator-based Memory-efficient Fine-tuning with LoRA Correction, https://arxiv.org/pdf/2506.12015, 2025-06-13
2025-11-09 19:44:42,564 - INFO - root - Page:2, Index:23, Compression Aware Certified Training, https://arxiv.org/pdf/2506.11992, 2025-06-13
2025-11-09 19:44:42,565 - INFO - root - Page:2, Index:24, GPLQ: A General, Practical, and Lightning QAT Method for Vision Transformers, https://arxiv.org/pdf/2506.11784, 2025-06-13
2025-11-09 19:44:42,566 - INFO - root - Page:2, Index:25, TruncQuant: Truncation-Ready Quantization for DNNs with Flexible Weight Bit Precision, https://arxiv.org/pdf/2506.11431, 2025-06-12
2025-11-09 19:44:42,568 - INFO - root - Page:2, Index:26, EfficientQuant: An Efficient Post-Training Quantization for CNN-Transformer Hybrid Models on Edge Devices, https://arxiv.org/pdf/2506.11093, 2025-06-05
2025-11-09 19:44:42,569 - INFO - root - Page:2, Index:27, Starting Positions Matter: A Study on Better Weight Initialization for Neural Network Quantization, https://arxiv.org/pdf/2506.10463, 2025-06-12
2025-11-09 19:44:42,570 - INFO - root - Page:2, Index:28, AWP: Activation-Aware Weight Pruning and Quantization with Projected Gradient Descent, https://arxiv.org/pdf/2506.10205, 2025-06-11
2025-11-09 19:44:42,571 - INFO - root - Page:2, Index:29, Q-SAM2: Accurate Quantization for Segment Anything Model 2, https://arxiv.org/pdf/2506.09782, 2025-06-11
2025-11-09 19:44:42,571 - INFO - root - Page:2, Index:30, Unifying Block-wise PTQ and Distillation-based QAT for Progressive Quantization toward 2-bit Instruction-Tuned LLMs, https://arxiv.org/pdf/2506.09104, 2025-06-10
2025-11-09 19:44:42,571 - INFO - root - Page:2, Index:31, Implementing Keyword Spotting on the MCUX947 Microcontroller with Integrated NPU, https://arxiv.org/pdf/2506.08911, 2025-06-10
2025-11-09 19:44:42,572 - INFO - root - Page:2, Index:32, POLARON: Precision-aware On-device Learning and Adaptive Runtime-cONfigurable AI acceleration, https://arxiv.org/pdf/2506.08785, 2025-06-10
2025-11-09 19:44:42,574 - INFO - root - Page:2, Index:33, MoQAE: Mixed-Precision Quantization for Long-Context LLM Inference via Mixture of Quantization-Aware Experts, https://arxiv.org/pdf/2506.07533, 2025-06-09
2025-11-09 19:44:42,575 - INFO - root - Page:2, Index:34, BitVLA: 1-bit Vision-Language-Action Models for Robotics Manipulation, https://arxiv.org/pdf/2506.07530, 2025-06-09
2025-11-09 19:44:42,577 - INFO - root - Page:2, Index:35, RecGPT: A Foundation Model for Sequential Recommendation, https://arxiv.org/pdf/2506.06270, 2025-06-12
2025-11-09 19:44:42,577 - INFO - root - Page:2, Index:36, FPSAttention: Training-Aware FP8 and Sparsity Co-Design for Fast Video Diffusion, https://arxiv.org/pdf/2506.04648, 2025-06-05
2025-11-09 19:44:42,577 - INFO - root - Page:2, Index:37, BitTTS: Highly Compact Text-to-Speech Using 1.58-bit Quantization and Weight Indexing, https://arxiv.org/pdf/2506.03515, 2025-06-03
2025-11-09 19:44:42,579 - INFO - root - Page:2, Index:38, ShapeLLM-Omni: A Native Multimodal LLM for 3D Generation and Understanding, https://arxiv.org/pdf/2506.01853, 2025-06-02
2025-11-09 19:44:42,579 - INFO - root - Page:2, Index:39, Movable Antenna Enhanced Federated Fine-Tuning of Large Language Models via Hybrid Client Selection Optimization, https://arxiv.org/pdf/2506.00011, 2025-10-26
2025-11-09 19:44:42,580 - INFO - root - Page:2, Index:40, Running Conventional Automatic Speech Recognition on Memristor Hardware: A Simulated Approach, https://arxiv.org/pdf/2505.24721, 2025-05-30
2025-11-09 19:44:42,580 - INFO - root - Page:2, Index:41, GARLIC: GAussian Representation LearnIng for spaCe partitioning, https://arxiv.org/pdf/2505.24608, 2025-10-02
2025-11-09 19:44:42,582 - INFO - root - Page:2, Index:42, AutoChemSchematic AI: Agentic Physics-Aware Automation for Chemical Manufacturing Scale-Up, https://arxiv.org/pdf/2505.24584, 2025-08-18
2025-11-09 19:44:42,582 - INFO - root - Page:2, Index:43, Model-Preserving Adaptive Rounding, https://arxiv.org/pdf/2505.22988, 2025-09-25
2025-11-09 19:44:42,584 - INFO - root - Page:2, Index:44, Highly Efficient and Effective LLMs with Multi-Boolean Architectures, https://arxiv.org/pdf/2505.22811, 2025-10-03
2025-11-09 19:44:42,587 - INFO - root - Page:2, Index:45, Pioneering 4-Bit FP Quantization for Diffusion Models: Mixup-Sign Quantization and Timestep-Aware Fine-Tuning, https://arxiv.org/pdf/2505.21591, 2025-05-27
2025-11-09 19:44:42,592 - INFO - root - Page:2, Index:46, Frequency Composition for Compressed and Domain-Adaptive Neural Networks, https://arxiv.org/pdf/2505.20890, 2025-05-27
2025-11-09 19:44:42,596 - INFO - root - Page:2, Index:47, MoPFormer: Motion-Primitive Transformer for Wearable-Sensor Activity Recognition, https://arxiv.org/pdf/2505.20744, 2025-10-27
2025-11-09 19:44:42,597 - INFO - root - Page:2, Index:48, Optimizing edge AI models on HPC systems with the edge in the loop, https://arxiv.org/pdf/2505.19995, 2025-05-26
2025-11-09 19:44:42,597 - INFO - root - Fetching page 4 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=150
2025-11-09 19:44:49,700 - INFO - root - get_all_titles_from_web 
2025-11-09 19:44:49,701 - INFO - root - Page:3, Index:0, DPASyn: Mechanism-Aware Drug Synergy Prediction via Dual Attention and Precision-Aware Quantization, https://arxiv.org/pdf/2505.19144, 2025-09-20
2025-11-09 19:44:49,701 - INFO - root - Page:3, Index:1, Reducing Storage of Pretrained Neural Networks by Rate-Constrained Quantization and Entropy Coding, https://arxiv.org/pdf/2505.18758, 2025-05-24
2025-11-09 19:44:49,701 - INFO - root - Page:3, Index:2, Beyond Discreteness: Finite-Sample Analysis of Straight-Through Estimator for Quantization, https://arxiv.org/pdf/2505.18113, 2025-05-23
2025-11-09 19:44:49,702 - INFO - root - Page:3, Index:3, Automating Versatile Time-Series Analysis with Tiny Transformers on Embedded FPGAs, https://arxiv.org/pdf/2505.17662, 2025-09-19
2025-11-09 19:44:49,702 - INFO - root - Page:3, Index:4, FPQVAR: Floating Point Quantization for Visual Autoregressive Model with FPGA Hardware Co-design, https://arxiv.org/pdf/2505.16335, 2025-05-22
2025-11-09 19:44:49,702 - INFO - root - Page:3, Index:5, Saliency-Aware Quantized Imitation Learning for Efficient Robotic Control, https://arxiv.org/pdf/2505.15304, 2025-05-30
2025-11-09 19:44:49,703 - INFO - root - Page:3, Index:6, Scaling Law for Quantization-Aware Training, https://arxiv.org/pdf/2505.14302, 2025-05-20
2025-11-09 19:44:49,703 - INFO - root - Page:3, Index:7, Automatic mixed precision for optimizing gained time with constrained loss mean-squared-error based on model partition to sequential sub-graphs, https://arxiv.org/pdf/2505.13060, 2025-05-19
2025-11-09 19:44:49,703 - INFO - root - Page:3, Index:8, Deep Unfolding with Kernel-based Quantization in MIMO Detection, https://arxiv.org/pdf/2505.12736, 2025-05-19
2025-11-09 19:44:49,703 - INFO - root - Page:3, Index:9, FedHQ: Hybrid Runtime Quantization for Federated Learning, https://arxiv.org/pdf/2505.11982, 2025-05-17
2025-11-09 19:44:49,704 - INFO - root - Page:3, Index:10, QVGen: Pushing the Limit of Quantized Video Generative Models, https://arxiv.org/pdf/2505.11497, 2025-09-27
2025-11-09 19:44:49,704 - INFO - root - Page:3, Index:11, EA-3DGS: Efficient and Adaptive 3D Gaussians with Highly Enhanced Quality for outdoor scenes, https://arxiv.org/pdf/2505.10787, 2025-05-15
2025-11-09 19:44:49,704 - INFO - root - Page:3, Index:12, ITERA-LLM: Boosting Sub-8-Bit Large Language Model Inference via Iterative Tensor Decomposition, https://arxiv.org/pdf/2505.08981, 2025-05-13
2025-11-09 19:44:49,705 - INFO - root - Page:3, Index:13, PROM: Prioritize Reduction of Multiplications Over Lower Bit-Widths for Efficient CNNs, https://arxiv.org/pdf/2505.03254, 2025-08-06
2025-11-09 19:44:49,705 - INFO - root - Page:3, Index:14, ICQuant: Index Coding enables Low-bit LLM Quantization, https://arxiv.org/pdf/2505.00850, 2025-08-24
2025-11-09 19:44:49,705 - INFO - root - Page:3, Index:15, Enhancing Ultra-Low-Bit Quantization of Large Language Models Through Saliency-Aware Partial Retraining, https://arxiv.org/pdf/2504.13932, 2025-07-30
2025-11-09 19:44:49,706 - INFO - root - Page:3, Index:16, Achieving binary weight and activation for LLMs using Post-Training Quantization, https://arxiv.org/pdf/2504.05352, 2025-06-30
2025-11-09 19:44:49,706 - INFO - root - Page:3, Index:17, Wireless Hearables With Programmable Speech AI Accelerators, https://arxiv.org/pdf/2503.18698, 2025-10-21
2025-11-09 19:44:49,707 - INFO - root - Page:3, Index:18, GranQ: Efficient Channel-wise Quantization via Vectorized Pre-Scaling for Zero-Shot QAT, https://arxiv.org/pdf/2503.18339, 2025-10-15
2025-11-09 19:44:49,707 - INFO - root - Page:3, Index:19, CompMarkGS: Robust Watermarking for Compressed 3D Gaussian Splatting, https://arxiv.org/pdf/2503.12836, 2025-09-29
2025-11-09 19:44:49,707 - INFO - root - Page:3, Index:20, AHCPTQ: Accurate and Hardware-Compatible Post-Training Quantization for Segment Anything Model, https://arxiv.org/pdf/2503.03088, 2025-07-11
2025-11-09 19:44:49,708 - INFO - root - Page:3, Index:21, Teaching Metric Distance to Discrete Autoregressive Language Models, https://arxiv.org/pdf/2503.02379, 2025-10-07
2025-11-09 19:44:49,708 - INFO - root - Page:3, Index:22, Regularization-based Framework for Quantization-, Fault- and Variability-Aware Training, https://arxiv.org/pdf/2503.01297, 2025-07-12
2025-11-09 19:44:49,709 - INFO - root - Fetching page 5 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=200
2025-11-09 19:44:54,374 - INFO - root - get_all_titles_from_web 
2025-11-09 19:44:54,374 - INFO - root - Page:4, Index:0, Investigating the Impact of Quantization Methods on the Safety and Reliability of Large Language Models, https://arxiv.org/pdf/2502.15799, 2025-06-29
2025-11-09 19:44:54,374 - INFO - root - Page:4, Index:1, Rotate, Clip, and Partition: Towards W2A4KV4 Quantization by Integrating Rotation and Learnable Non-uniform Quantizer, https://arxiv.org/pdf/2502.15779, 2025-09-01
2025-11-09 19:44:54,375 - INFO - root - Page:4, Index:2, RoSTE: An Efficient Quantization-Aware Supervised Fine-Tuning Approach for Large Language Models, https://arxiv.org/pdf/2502.09003, 2025-06-05
2025-11-09 19:44:54,375 - INFO - root - Page:4, Index:3, Spatial Degradation-Aware and Temporal Consistent Diffusion Model for Compressed Video Super-Resolution, https://arxiv.org/pdf/2502.07381, 2025-06-27
2025-11-09 19:44:54,375 - INFO - root - Page:4, Index:4, QuEST: Stable Training of LLMs with 1-Bit Weights and Activations, https://arxiv.org/pdf/2502.05003, 2025-06-10
2025-11-09 19:44:54,376 - INFO - root - Page:4, Index:5, HALO: Hadamard-Assisted Lower-Precision Optimization for LLMs, https://arxiv.org/pdf/2501.02625, 2025-11-05
2025-11-09 19:44:54,376 - INFO - root - Page:4, Index:6, TAR3D: Creating High-Quality 3D Assets via Next-Part Prediction, https://arxiv.org/pdf/2412.16919, 2025-08-08
2025-11-09 19:44:54,376 - INFO - root - Page:4, Index:7, Training Multi-Layer Binary Neural Networks With Local Binary Error Signals, https://arxiv.org/pdf/2412.00119, 2025-08-05
2025-11-09 19:44:54,376 - INFO - root - Page:4, Index:8, Scaling Large-scale GNN Training to Thousands of Processors on CPU-based Supercomputers, https://arxiv.org/pdf/2411.16025, 2025-05-26
2025-11-09 19:44:54,377 - INFO - root - Page:4, Index:9, HAFLQ: Heterogeneous Adaptive Federated LoRA Fine-tuned LLM with Quantization, https://arxiv.org/pdf/2411.06581, 2025-05-16
2025-11-09 19:44:54,377 - INFO - root - Fetching page 6 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=250
2025-11-09 19:45:00,926 - INFO - root - get_all_titles_from_web 
2025-11-09 19:45:00,927 - INFO - root - Page:5, Index:0, Gradient-Free Training of Quantized Neural Networks, https://arxiv.org/pdf/2410.09734, 2025-09-29
2025-11-09 19:45:00,927 - INFO - root - Page:5, Index:1, QT-DoG: Quantization-aware Training for Domain Generalization, https://arxiv.org/pdf/2410.06020, 2025-06-26
2025-11-09 19:45:00,928 - INFO - root - Page:5, Index:2, Constraint Guided Model Quantization of Neural Networks, https://arxiv.org/pdf/2409.20138, 2025-09-12
2025-11-09 19:45:00,928 - INFO - root - Page:5, Index:3, Accumulator-Aware Post-Training Quantization for Large Language Models, https://arxiv.org/pdf/2409.17092, 2025-07-30
2025-11-09 19:45:00,928 - INFO - root - Page:5, Index:4, DilateQuant: Accurate and Efficient Diffusion Quantization via Weight Dilation, https://arxiv.org/pdf/2409.14307, 2025-07-09
2025-11-09 19:45:00,928 - INFO - root - Page:5, Index:5, Robust Training of Neural Networks at Arbitrary Precision and Sparsity, https://arxiv.org/pdf/2409.09245, 2025-09-23
2025-11-09 19:45:00,929 - INFO - root - Page:5, Index:6, VQ-CTAP: Cross-Modal Fine-Grained Sequence Representation Learning for Speech Processing, https://arxiv.org/pdf/2408.05758, 2025-05-27
2025-11-09 19:45:00,929 - INFO - root - Page:5, Index:7, DopQ-ViT: Towards Distribution-Friendly and Outlier-Aware Post-Training Quantization for Vision Transformers, https://arxiv.org/pdf/2408.03291, 2025-06-19
2025-11-09 19:45:00,929 - INFO - root - Page:5, Index:8, Temporal Feature Matters: A Framework for Diffusion Model Quantization, https://arxiv.org/pdf/2407.19547, 2025-07-11
2025-11-09 19:45:00,930 - INFO - root - Page:5, Index:9, EfficientQAT: Efficient Quantization-Aware Training for Large Language Models, https://arxiv.org/pdf/2407.11062, 2025-05-19
2025-11-09 19:45:00,930 - INFO - root - Page:5, Index:10, Integer-only Quantized Transformers for Embedded FPGA-based Time-series Forecasting in AIoT, https://arxiv.org/pdf/2407.11041, 2025-10-31
2025-11-09 19:45:00,930 - INFO - root - Fetching page 7 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=300
2025-11-09 19:45:07,602 - INFO - root - get_all_titles_from_web 
2025-11-09 19:45:07,603 - INFO - root - Page:6, Index:0, BoA: Attention-aware Post-training Quantization without Backpropagation, https://arxiv.org/pdf/2406.13474, 2025-06-06
2025-11-09 19:45:07,603 - INFO - root - Page:6, Index:1, A Rescaling-Invariant Lipschitz Bound Based on Path-Metrics for Modern ReLU Network Parameterizations, https://arxiv.org/pdf/2405.15006, 2025-06-13
2025-11-09 19:45:07,604 - INFO - root - Page:6, Index:2, Scheduling Weight Transitions for Quantization-Aware Training, https://arxiv.org/pdf/2404.19248, 2025-10-01
2025-11-09 19:45:07,604 - INFO - root - Page:6, Index:3, GPTVQ: The Blessing of Dimensionality for LLM Quantization, https://arxiv.org/pdf/2402.15319, 2025-06-03
2025-11-09 19:45:07,604 - INFO - root - Fetching page 8 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=350
2025-11-09 19:45:13,986 - INFO - root - get_all_titles_from_web 
2025-11-09 19:45:13,989 - INFO - root - Page:7, Index:0, Squat: Quant Small Language Models on the Edge, https://arxiv.org/pdf/2402.10787, 2025-07-01
2025-11-09 19:45:13,990 - INFO - root - Page:7, Index:1, L4Q: Parameter Efficient Quantization-Aware Fine-Tuning on Large Language Models, https://arxiv.org/pdf/2402.04902, 2025-07-21
2025-11-09 19:45:13,990 - INFO - root - Fetching page 9 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=400
2025-11-09 19:45:21,043 - INFO - root - ------------------------------------------------------------------------------------------------------------------------
2025-11-09 19:45:33,772 - INFO - root - 跳过已处理论文 A Quantized VAE-MLP Botnet Detection Model: A Systematic Evaluation of Quantization-Aware Training and Post-Training Quantization Strategies：D:\ChatPaper\academic Papers\Quantization-Aware-Training\A Quantized VAE-MLP Botnet Detection Model_ A Systematic Evaluation of Quantizat-2.pdf
2025-11-09 19:45:33,773 - INFO - root - 正在总结论文 2/2: FP8-Flow-MoE: A Casting-Free FP8 Recipe without Double Quantization Error
2025-11-09 19:46:16,637 - INFO - root - LLMClient: rate limit reached, sleeping 17.1s
2025-11-09 19:46:52,812 - INFO - root - 正在提取论文图片...
2025-11-09 19:47:00,391 - INFO - root - 已保存图片 1/10：./export\images_FP8-Flow-MoE_ A Casting-Free FP8 Recipe without Double Quantization Error\figure_1_page6.png
2025-11-09 19:47:01,367 - INFO - root - 已保存图片 2/10：./export\images_FP8-Flow-MoE_ A Casting-Free FP8 Recipe without Double Quantization Error\figure_2_page6.png
2025-11-09 19:47:01,725 - INFO - root - 已保存图片 3/10：./export\images_FP8-Flow-MoE_ A Casting-Free FP8 Recipe without Double Quantization Error\figure_3_page6.png
2025-11-09 19:47:02,103 - INFO - root - 已保存图片 4/10：./export\images_FP8-Flow-MoE_ A Casting-Free FP8 Recipe without Double Quantization Error\figure_4_page6.png
2025-11-09 19:47:02,152 - INFO - root - 成功添加图片 1：./export\images_FP8-Flow-MoE_ A Casting-Free FP8 Recipe without Double Quantization Error\figure_1_page6.png
2025-11-09 19:47:02,153 - INFO - root - 成功添加图片 2：./export\images_FP8-Flow-MoE_ A Casting-Free FP8 Recipe without Double Quantization Error\figure_2_page6.png
2025-11-09 19:47:02,153 - INFO - root - 成功添加图片 3：./export\images_FP8-Flow-MoE_ A Casting-Free FP8 Recipe without Double Quantization Error\figure_3_page6.png
2025-11-09 19:47:02,153 - INFO - root - 成功添加图片 4：./export\images_FP8-Flow-MoE_ A Casting-Free FP8 Recipe without Double Quantization Error\figure_4_page6.png
2025-11-09 19:47:02,178 - INFO - root - 论文《FP8-Flow-MoE: A Casting-Free FP8 Recipe without Double Quantization Error》的分析已保存到 ./export\FP8-Flow-MoE_ A Casting-Free FP8 Recipe without Double Quantization Error.md
2025-11-09 19:47:02,276 - INFO - root - summary time: 177.86 seconds
2025-11-09 20:00:55,741 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-09 20:00:55,743 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-09 20:00:55,745 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-09 20:00:57,021 - INFO - root - LLMClientManager: 指定使用客户端: Deepseek
2025-11-09 20:00:57,021 - INFO - root - DeepSeekClient: API key found: 9f9e270e-b...
2025-11-09 20:00:57,023 - INFO - root - DeepSeekClient: 使用模式: 火山引擎
2025-11-09 20:01:00,188 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 404 Not Found"
2025-11-09 20:01:00,190 - ERROR - root - DeepSeekClient: error during initialization: Error code: 404 - {'error': {'code': 'InvalidEndpointOrModel.NotFound', 'message': 'The model or endpoint deepseek-chat does not exist or you do not have access to it. Request id: 021762689659689f83b1f853f59e3d47d2ccd8cfd02b65a46c588', 'param': '', 'type': 'Not Found'}}
2025-11-09 20:01:00,190 - ERROR - root - LLMClientManager: 指定的客户端 DeepSeek 初始化失败
2025-11-09 20:01:00,190 - WARNING - root - LLMClientManager: 指定的客户端 Deepseek 不可用，将尝试其他客户端
2025-11-09 20:01:01,087 - INFO - root - GeminiClient: trying model gemini-2.5-flash
2025-11-09 20:01:03,306 - INFO - root - GeminiClient: initialized model gemini-2.5-flash
2025-11-09 20:01:03,307 - INFO - root - LLMClientManager: Gemini client initialized successfully
2025-11-09 20:01:03,307 - INFO - root - LLMClientManager: using Gemini as default client
2025-11-09 20:01:03,307 - WARNING - root - KimiClient: API key not provided. LLM disabled.
2025-11-09 20:01:03,308 - WARNING - root - LLMClientManager: Kimi client initialization failed
2025-11-09 20:01:03,308 - WARNING - root - QwenClient: API key not provided. LLM disabled.
2025-11-09 20:01:03,309 - WARNING - root - LLMClientManager: Qwen client initialization failed
2025-11-09 20:01:03,309 - INFO - root - DoubaoClient: API key found: 9f9e270e-b...
2025-11-09 20:01:07,975 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 20:01:07,985 - INFO - root - DoubaoClient: initialized successfully with model doubao-seed-1-6-lite-251015
2025-11-09 20:01:07,986 - INFO - root - LLMClientManager: Doubao client initialized successfully
2025-11-09 20:01:07,986 - WARNING - root - LLMClientManager: client Deepseek not available
2025-11-09 20:01:07,987 - WARNING - root - 无法切换到指定的客户端 Deepseek，将使用默认客户端
2025-11-09 20:01:07,987 - INFO - root - 可用客户端: ['Gemini', 'Doubao']
2025-11-09 20:01:07,987 - INFO - root - 使用 LLM 模型: gemini-2.5-flash
2025-11-09 20:01:07,988 - INFO - root - 可用客户端: ['Gemini', 'Doubao']
2025-11-09 20:01:07,988 - INFO - root - === 运行配置 ===
2025-11-09 20:01:07,988 - INFO - root - 处理模式: arxiv在线搜索
2025-11-09 20:01:07,989 - INFO - root - 关键词: QAT
2025-11-09 20:01:07,989 - INFO - root - 查询: Quantization-Aware-Training
2025-11-09 20:01:07,989 - INFO - root - 排序: None
2025-11-09 20:01:07,989 - INFO - root - 最近天数: 180
2025-11-09 20:01:07,990 - INFO - root - 最大处理数量: 2
2025-11-09 20:01:07,990 - INFO - root - 保存图片: 是
2025-11-09 20:01:07,991 - INFO - root - 输出语言: 中文
2025-11-09 20:01:07,991 - INFO - root - 强制重新处理: 否
2025-11-09 20:01:07,991 - INFO - root - ====================
2025-11-09 20:01:07,992 - INFO - root - 使用 arXiv 搜索模式（通过 chat_arxiv 模块获取）
2025-11-09 20:01:07,994 - INFO - root - Fetching page 1 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50
2025-11-09 20:01:14,406 - INFO - root - get_all_titles_from_web 
2025-11-09 20:01:14,407 - INFO - root - Page:0, Index:0, A Quantized VAE-MLP Botnet Detection Model: A Systematic Evaluation of Quantization-Aware Training and Post-Training Quantization Strategies, https://arxiv.org/pdf/2511.03201, 2025-11-05
2025-11-09 20:01:14,407 - INFO - root - Page:0, Index:1, FP8-Flow-MoE: A Casting-Free FP8 Recipe without Double Quantization Error, https://arxiv.org/pdf/2511.02302, 2025-11-04
2025-11-09 20:01:14,407 - INFO - root - Page:0, Index:2, Outlier-Aware Post-Training Quantization for Image Super-Resolution, https://arxiv.org/pdf/2511.00682, 2025-11-01
2025-11-09 20:01:14,407 - INFO - root - Page:0, Index:3, Evaluation of Wafer-Scale SOT-MRAM for Analog Crossbar Array Applications, https://arxiv.org/pdf/2510.25853, 2025-11-03
2025-11-09 20:01:14,408 - INFO - root - Page:0, Index:4, Improving the Straight-Through Estimator with Zeroth-Order Information, https://arxiv.org/pdf/2510.23926, 2025-10-27
2025-11-09 20:01:14,408 - INFO - root - Page:0, Index:5, Real-Time Semantic Segmentation on FPGA for Autonomous Vehicles Using LMIINet with the CGRA4ML Framework, https://arxiv.org/pdf/2510.22243, 2025-10-25
2025-11-09 20:01:14,408 - INFO - root - Page:0, Index:6, TernaryCLIP: Efficiently Compressing Vision-Language Models with Ternary Weights and Distilled Knowledge, https://arxiv.org/pdf/2510.21879, 2025-10-23
2025-11-09 20:01:14,409 - INFO - root - Page:0, Index:7, KARIPAP: Quantum-Inspired Tensor Network Compression of Large Language Models Using Infinite Projected Entangled Pair States and Tensor Renormalization Group, https://arxiv.org/pdf/2510.21844, 2025-10-22
2025-11-09 20:01:14,409 - INFO - root - Page:0, Index:8, A Convergence Analysis of Adaptive Optimizers under Floating-point Quantization, https://arxiv.org/pdf/2510.21314, 2025-10-24
2025-11-09 20:01:14,409 - INFO - root - Page:0, Index:9, Adaptive Distribution-aware Quantization for Mixed-Precision Neural Networks, https://arxiv.org/pdf/2510.19760, 2025-10-22
2025-11-09 20:01:14,409 - INFO - root - Page:0, Index:10, CAGE: Curvature-Aware Gradient Estimation For Accurate Quantization-Aware Training, https://arxiv.org/pdf/2510.18784, 2025-10-21
2025-11-09 20:01:14,409 - INFO - root - Page:0, Index:11, Mixed-Precision Quantization for Language Models: Techniques and Prospects, https://arxiv.org/pdf/2510.16805, 2025-10-19
2025-11-09 20:01:14,410 - INFO - root - Page:0, Index:12, SPLite Hand: Sparsity-Aware Lightweight 3D Hand Pose Estimation, https://arxiv.org/pdf/2510.16396, 2025-10-30
2025-11-09 20:01:14,411 - INFO - root - Page:0, Index:13, CTR-LoRA: Curvature-Aware and Trust-Region Guided Low-Rank Adaptation for Large Language Models, https://arxiv.org/pdf/2510.15962, 2025-10-11
2025-11-09 20:01:14,412 - INFO - root - Page:0, Index:14, SANR: Scene-Aware Neural Representation for Light Field Image Compression with Rate-Distortion Optimization, https://arxiv.org/pdf/2510.15775, 2025-10-17
2025-11-09 20:01:14,412 - INFO - root - Page:0, Index:15, SpikeFit: Towards Optimal Deployment of Spiking Networks on Neuromorphic Hardware, https://arxiv.org/pdf/2510.15542, 2025-10-31
2025-11-09 20:01:14,413 - INFO - root - Page:0, Index:16, GRank: Towards Target-Aware and Streamlined Industrial Retrieval with a Generate-Rank Framework, https://arxiv.org/pdf/2510.15299, 2025-10-17
2025-11-09 20:01:14,413 - INFO - root - Page:0, Index:17, SaLon3R: Structure-aware Long-term Generalizable 3D Reconstruction from Unposed Images, https://arxiv.org/pdf/2510.15072, 2025-10-16
2025-11-09 20:01:14,414 - INFO - root - Page:0, Index:18, FraQAT: Quantization Aware Training with Fractional bits, https://arxiv.org/pdf/2510.14823, 2025-10-16
2025-11-09 20:01:14,414 - INFO - root - Page:0, Index:19, Computing-In-Memory Aware Model Adaption For Edge Devices, https://arxiv.org/pdf/2510.14379, 2025-10-16
2025-11-09 20:01:14,414 - INFO - root - Page:0, Index:20, Invited Paper: BitMedViT: Ternary-Quantized Vision Transformer for Medical AI Assistants on the Edge, https://arxiv.org/pdf/2510.13760, 2025-11-04
2025-11-09 20:01:14,419 - INFO - root - Page:0, Index:21, NeuroRVQ: Multi-Scale EEG Tokenization for Generative Large Brainwave Models, https://arxiv.org/pdf/2510.13068, 2025-10-14
2025-11-09 20:01:14,425 - INFO - root - Page:0, Index:22, Detect Anything via Next Point Prediction, https://arxiv.org/pdf/2510.12798, 2025-10-14
2025-11-09 20:01:14,426 - INFO - root - Page:0, Index:23, AndesVL Technical Report: An Efficient Mobile-side Multimodal Large Language Model, https://arxiv.org/pdf/2510.11496, 2025-10-14
2025-11-09 20:01:14,426 - INFO - root - Page:0, Index:24, Rescaling-Aware Training for Efficient Deployment of Deep Learning Models on Full-Integer Hardware, https://arxiv.org/pdf/2510.11484, 2025-10-13
2025-11-09 20:01:14,427 - INFO - root - Page:0, Index:25, SASER: Stego attacks on open-source LLMs, https://arxiv.org/pdf/2510.10486, 2025-10-12
2025-11-09 20:01:14,427 - INFO - root - Page:0, Index:26, Ultralytics YOLO Evolution: An Overview of YOLO26, YOLO11, YOLOv8 and YOLOv5 Object Detectors for Computer Vision and Pattern Recognition, https://arxiv.org/pdf/2510.09653, 2025-10-15
2025-11-09 20:01:14,428 - INFO - root - Page:0, Index:27, A Theoretically-Grounded Codebook for Digital Semantic Communications, https://arxiv.org/pdf/2510.07108, 2025-10-14
2025-11-09 20:01:14,428 - INFO - root - Page:0, Index:28, QuantDemoire: Quantization with Outlier Aware for Image Demoiréing, https://arxiv.org/pdf/2510.04066, 2025-10-05
2025-11-09 20:01:14,429 - INFO - root - Page:0, Index:29, Adaptively Sampling-Reusing-Mixing Decomposed Gradients to Speed Up Sharpness Aware Minimization, https://arxiv.org/pdf/2510.03763, 2025-10-04
2025-11-09 20:01:14,429 - INFO - root - Page:0, Index:30, Quant-dLLM: Post-Training Extreme Low-Bit Quantization for Diffusion Large Language Models, https://arxiv.org/pdf/2510.03274, 2025-09-27
2025-11-09 20:01:14,430 - INFO - root - Page:0, Index:31, PT$^2$-LLM: Post-Training Ternarization for Large Language Models, https://arxiv.org/pdf/2510.03267, 2025-09-26
2025-11-09 20:01:14,430 - INFO - root - Page:0, Index:32, Purrception: Variational Flow Matching for Vector-Quantized Image Generation, https://arxiv.org/pdf/2510.01478, 2025-10-01
2025-11-09 20:01:14,431 - INFO - root - Page:0, Index:33, Post-Training Quantization for Audio Diffusion Transformers, https://arxiv.org/pdf/2510.00313, 2025-09-30
2025-11-09 20:01:14,431 - INFO - root - Page:0, Index:34, Rethinking RoPE Scaling in Quantized LLM: Theory, Outlier, and Channel-Band Analysis with Weight Rescaling, https://arxiv.org/pdf/2510.00028, 2025-09-25
2025-11-09 20:01:14,443 - INFO - root - Page:0, Index:35, Post-Training Quantization via Residual Truncation and Zero Suppression for Diffusion Models, https://arxiv.org/pdf/2509.26436, 2025-09-30
2025-11-09 20:01:14,450 - INFO - root - Page:0, Index:36, Cat: Post-Training Quantization Error Reduction via Cluster-based Affine Transformation, https://arxiv.org/pdf/2509.26277, 2025-10-07
2025-11-09 20:01:14,452 - INFO - root - Page:0, Index:37, CAST: Continuous and Differentiable Semi-Structured Sparsity-Aware Training for Large Language Models, https://arxiv.org/pdf/2509.25996, 2025-09-30
2025-11-09 20:01:14,452 - INFO - root - Page:0, Index:38, Norm-Q: Effective Compression Method for Hidden Markov Models in Neuro-Symbolic Applications, https://arxiv.org/pdf/2509.25439, 2025-09-29
2025-11-09 20:01:14,453 - INFO - root - Page:0, Index:39, On-the-Fly Adaptation to Quantization: Configuration-Aware LoRA for Efficient Fine-Tuning of Quantized LLMs, https://arxiv.org/pdf/2509.25214, 2025-09-22
2025-11-09 20:01:14,453 - INFO - root - Page:0, Index:40, VoxCPM: Tokenizer-Free TTS for Context-Aware Speech Generation and True-to-Life Voice Cloning, https://arxiv.org/pdf/2509.24650, 2025-09-29
2025-11-09 20:01:14,454 - INFO - root - Page:0, Index:41, S$^2$NN: Sub-bit Spiking Neural Networks, https://arxiv.org/pdf/2509.24266, 2025-10-24
2025-11-09 20:01:14,454 - INFO - root - Page:0, Index:42, Tequila: Trapping-free Ternary Quantization for Large Language Models, https://arxiv.org/pdf/2509.23809, 2025-10-17
2025-11-09 20:01:14,454 - INFO - root - Page:0, Index:43, Texture Vector-Quantization and Reconstruction Aware Prediction for Generative Super-Resolution, https://arxiv.org/pdf/2509.23774, 2025-09-30
2025-11-09 20:01:14,454 - INFO - root - Page:0, Index:44, RobuQ: Pushing DiTs to W1.58A2 via Robust Activation Quantization, https://arxiv.org/pdf/2509.23582, 2025-09-27
2025-11-09 20:01:14,455 - INFO - root - Page:0, Index:45, Beyond Outliers: A Study of Optimizers Under Quantization, https://arxiv.org/pdf/2509.23500, 2025-10-02
2025-11-09 20:01:14,455 - INFO - root - Page:0, Index:46, Compute-Optimal Quantization-Aware Training, https://arxiv.org/pdf/2509.22935, 2025-09-26
2025-11-09 20:01:14,456 - INFO - root - Page:0, Index:47, COSPADI: Compressing LLMs via Calibration-Guided Sparse Dictionary Learning, https://arxiv.org/pdf/2509.22075, 2025-10-06
2025-11-09 20:01:14,457 - INFO - root - Page:0, Index:48, SlimDiff: Training-Free, Activation-Guided Hands-free Slimming of Diffusion Models, https://arxiv.org/pdf/2509.21498, 2025-09-25
2025-11-09 20:01:14,459 - INFO - root - Page:0, Index:49, Quantized Visual Geometry Grounded Transformer, https://arxiv.org/pdf/2509.21302, 2025-09-29
2025-11-09 20:01:14,459 - INFO - root - Fetching page 2 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=50
2025-11-09 20:01:20,927 - INFO - root - get_all_titles_from_web 
2025-11-09 20:01:20,927 - INFO - root - Page:1, Index:0, Can Less Precise Be More Reliable? A Systematic Evaluation of Quantization's Impact on CLIP Beyond Accuracy, https://arxiv.org/pdf/2509.21173, 2025-10-27
2025-11-09 20:01:20,927 - INFO - root - Page:1, Index:1, Punching Above Precision: Small Quantized Model Distillation with Learnable Regularizer, https://arxiv.org/pdf/2509.20854, 2025-09-25
2025-11-09 20:01:20,928 - INFO - root - Page:1, Index:2, TinyEcoWeedNet: Edge Efficient Real-Time Aerial Agricultural Weed Detection, https://arxiv.org/pdf/2509.18193, 2025-09-19
2025-11-09 20:01:20,928 - INFO - root - Page:1, Index:3, SBVR: Summation of BitVector Representation for Efficient LLM Quantization, https://arxiv.org/pdf/2509.18172, 2025-09-17
2025-11-09 20:01:20,929 - INFO - root - Page:1, Index:4, QWHA: Quantization-Aware Walsh-Hadamard Adaptation for Parameter-Efficient Fine-Tuning on Large Language Models, https://arxiv.org/pdf/2509.17428, 2025-09-26
2025-11-09 20:01:20,929 - INFO - root - Page:1, Index:5, PTQTP: Post-Training Quantization to Trit-Planes for Large Language Models, https://arxiv.org/pdf/2509.16989, 2025-10-28
2025-11-09 20:01:20,929 - INFO - root - Page:1, Index:6, MEC-Quant: Maximum Entropy Coding for Extremely Low Bit Quantization-Aware Training, https://arxiv.org/pdf/2509.15514, 2025-09-18
2025-11-09 20:01:20,929 - INFO - root - Page:1, Index:7, Q-ROAR: Outlier-Aware Rescaling for RoPE Position Interpolation in Quantized Long-Context LLMs, https://arxiv.org/pdf/2509.14391, 2025-09-17
2025-11-09 20:01:20,930 - INFO - root - Page:1, Index:8, Efficient Quantization-Aware Neural Receivers: Beyond Post-Training Quantization, https://arxiv.org/pdf/2509.13786, 2025-09-19
2025-11-09 20:01:20,930 - INFO - root - Page:1, Index:9, Rate-Distortion Limits for Multimodal Retrieval: Theory, Optimal Codes, and Finite-Sample Guarantees, https://arxiv.org/pdf/2509.11054, 2025-09-13
2025-11-09 20:01:20,930 - INFO - root - Page:1, Index:10, SQAP-VLA: A Synergistic Quantization-Aware Pruning Framework for High-Performance Vision-Language-Action Models, https://arxiv.org/pdf/2509.09090, 2025-09-10
2025-11-09 20:01:20,931 - INFO - root - Page:1, Index:11, CSI Compression Beyond Latents: End-to-End Hybrid Attention-CNN Networks with Entropy Regularization, https://arxiv.org/pdf/2509.08776, 2025-09-10
2025-11-09 20:01:20,931 - INFO - root - Page:1, Index:12, Explaining How Quantization Disparately Skews a Model, https://arxiv.org/pdf/2509.07222, 2025-09-08
2025-11-09 20:01:20,932 - INFO - root - Page:1, Index:13, LoaQ: Layer-wise Output Approximation Quantization, https://arxiv.org/pdf/2509.06297, 2025-09-07
2025-11-09 20:01:20,932 - INFO - root - Page:1, Index:14, FineServe: Precision-Aware KV Slab and Two-Level Scheduling for Heterogeneous Precision LLM Serving, https://arxiv.org/pdf/2509.06261, 2025-09-14
2025-11-09 20:01:20,933 - INFO - root - Page:1, Index:15, Sensitivity-Aware Post-Training Quantization for Deep Neural Networks, https://arxiv.org/pdf/2509.05576, 2025-09-05
2025-11-09 20:01:20,933 - INFO - root - Page:1, Index:16, SuperSNN: A Hardware-Aware Framework for Physically Realizable, High-Performance Superconducting Spiking Neural Network Chips, https://arxiv.org/pdf/2509.05532, 2025-09-05
2025-11-09 20:01:20,934 - INFO - root - Page:1, Index:17, Data-Augmented Quantization-Aware Knowledge Distillation, https://arxiv.org/pdf/2509.03850, 2025-09-03
2025-11-09 20:01:20,934 - INFO - root - Page:1, Index:18, DPQuant: Efficient and Differentially-Private Model Training via Dynamic Quantization Scheduling, https://arxiv.org/pdf/2509.03472, 2025-09-03
2025-11-09 20:01:20,934 - INFO - root - Page:1, Index:19, Empowering Large Language Model for Sequential Recommendation via Multimodal Embeddings and Semantic IDs, https://arxiv.org/pdf/2509.02017, 2025-09-02
2025-11-09 20:01:20,935 - INFO - root - Page:1, Index:20, Q-Sched: Pushing the Boundaries of Few-Step Diffusion Models with Quantization-Aware Scheduling, https://arxiv.org/pdf/2509.01624, 2025-09-01
2025-11-09 20:01:20,935 - INFO - root - Page:1, Index:21, Quantization Meets OOD: Generalizable Quantization-aware Training from a Flatness Perspective, https://arxiv.org/pdf/2509.00859, 2025-08-31
2025-11-09 20:01:20,936 - INFO - root - Page:1, Index:22, Progressive Element-wise Gradient Estimation for Neural Network Quantization, https://arxiv.org/pdf/2509.00097, 2025-08-27
2025-11-09 20:01:20,936 - INFO - root - Page:1, Index:23, End-to-End On-Device Quantization-Aware Training for LLMs at Inference Cost, https://arxiv.org/pdf/2509.00031, 2025-09-29
2025-11-09 20:01:20,936 - INFO - root - Page:1, Index:24, Quantization Robustness to Input Degradations for Object Detection, https://arxiv.org/pdf/2508.19600, 2025-08-27
2025-11-09 20:01:20,937 - INFO - root - Page:1, Index:25, Scaling Laws for Task-Stratified Knowledge in Post-Training Quantized Large Language Models, https://arxiv.org/pdf/2508.18609, 2025-08-27
2025-11-09 20:01:20,937 - INFO - root - Page:1, Index:26, AQ-PCDSys: An Adaptive Quantized Planetary Crater Detection System for Autonomous Space Exploration, https://arxiv.org/pdf/2508.18025, 2025-08-25
2025-11-09 20:01:20,937 - INFO - root - Page:1, Index:27, TaDiCodec: Text-aware Diffusion Speech Tokenizer for Speech Language Modeling, https://arxiv.org/pdf/2508.16790, 2025-08-22
2025-11-09 20:01:20,937 - INFO - root - Page:1, Index:28, A Node-Aware Dynamic Quantization Approach for Graph Collaborative Filtering, https://arxiv.org/pdf/2508.16516, 2025-08-22
2025-11-09 20:01:20,939 - INFO - root - Page:1, Index:29, JEDI-linear: Fast and Efficient Graph Neural Networks for Jet Tagging on FPGAs, https://arxiv.org/pdf/2508.15468, 2025-08-21
2025-11-09 20:01:20,944 - INFO - root - Page:1, Index:30, MMQ: Multimodal Mixture-of-Quantization Tokenization for Semantic ID Generation and User Behavioral Adaptation, https://arxiv.org/pdf/2508.15281, 2025-08-21
2025-11-09 20:01:20,945 - INFO - root - Page:1, Index:31, DLLMQuant: Quantizing Diffusion-based Large Language Models, https://arxiv.org/pdf/2508.14090, 2025-08-25
2025-11-09 20:01:20,946 - INFO - root - Page:1, Index:32, Automated Energy-Aware Time-Series Model Deployment on Embedded FPGAs for Resilient Combined Sewer Overflow Management, https://arxiv.org/pdf/2508.13905, 2025-08-19
2025-11-09 20:01:20,946 - INFO - root - Page:1, Index:33, XR-NPE: High-Throughput Mixed-precision SIMD Neural Processing Engine for Extended Reality Perception Workloads, https://arxiv.org/pdf/2508.13049, 2025-08-18
2025-11-09 20:01:20,946 - INFO - root - Page:1, Index:34, Exploring Self-Supervised Audio Models for Generalized Anomalous Sound Detection, https://arxiv.org/pdf/2508.12230, 2025-08-17
2025-11-09 20:01:20,947 - INFO - root - Page:1, Index:35, TriQDef: Disrupting Semantic and Gradient Alignment to Prevent Adversarial Patch Transferability in Quantized Neural Networks, https://arxiv.org/pdf/2508.12132, 2025-08-16
2025-11-09 20:01:20,947 - INFO - root - Page:1, Index:36, Error Propagation Mechanisms and Compensation Strategies for Quantized Diffusion, https://arxiv.org/pdf/2508.12094, 2025-10-13
2025-11-09 20:01:20,948 - INFO - root - Page:1, Index:37, Extending Straight-Through Estimation for Robust Neural Networks on Analog CIM Hardware, https://arxiv.org/pdf/2508.11940, 2025-08-16
2025-11-09 20:01:20,948 - INFO - root - Page:1, Index:38, PTQAT: A Hybrid Parameter-Efficient Quantization Algorithm for 3D Perception Tasks, https://arxiv.org/pdf/2508.10557, 2025-08-15
2025-11-09 20:01:20,948 - INFO - root - Page:1, Index:39, MiCo: End-to-End Mixed Precision Neural Network Co-Exploration Framework for Edge AI, https://arxiv.org/pdf/2508.09500, 2025-08-13
2025-11-09 20:01:20,949 - INFO - root - Page:1, Index:40, SPARC: Soft Probabilistic Adaptive multi-interest Retrieval Model via Codebooks for recommender system, https://arxiv.org/pdf/2508.09090, 2025-08-12
2025-11-09 20:01:20,949 - INFO - root - Page:1, Index:41, Rethinking 1-bit Optimization Leveraging Pre-trained Large Language Models, https://arxiv.org/pdf/2508.06974, 2025-08-09
2025-11-09 20:01:20,949 - INFO - root - Page:1, Index:42, Efficient Deep Neural Receiver with Post-Training Quantization, https://arxiv.org/pdf/2508.06275, 2025-08-08
2025-11-09 20:01:20,950 - INFO - root - Page:1, Index:43, iFairy: the First 2-bit Complex LLM with All Parameters in $\{\pm1, \pm i\}$, https://arxiv.org/pdf/2508.05571, 2025-08-16
2025-11-09 20:01:20,950 - INFO - root - Page:1, Index:44, S$^2$Q-VDiT: Accurate Quantized Video Diffusion Transformer with Salient Data and Sparse Token Distillation, https://arxiv.org/pdf/2508.04016, 2025-10-27
2025-11-09 20:01:20,950 - INFO - root - Page:1, Index:45, LRQ-DiT: Log-Rotation Post-Training Quantization of Diffusion Transformers for Image and Video Generation, https://arxiv.org/pdf/2508.03485, 2025-09-23
2025-11-09 20:01:20,951 - INFO - root - Page:1, Index:46, VLMQ: Efficient Post-Training Quantization for Large Vision-Language Models via Hessian Augmentation, https://arxiv.org/pdf/2508.03351, 2025-08-05
2025-11-09 20:01:20,951 - INFO - root - Page:1, Index:47, TF-MLPNet: Tiny Real-Time Neural Speech Separation, https://arxiv.org/pdf/2508.03047, 2025-08-04
2025-11-09 20:01:20,951 - INFO - root - Page:1, Index:48, SaviorRec: Semantic-Behavior Alignment for Cold-Start Recommendation, https://arxiv.org/pdf/2508.01375, 2025-08-02
2025-11-09 20:01:20,952 - INFO - root - Page:1, Index:49, MixA-Q: Revisiting Activation Sparsity for Vision Transformers from a Mixed-Precision Quantization Perspective, https://arxiv.org/pdf/2507.19131, 2025-07-25
2025-11-09 20:01:20,952 - INFO - root - Fetching page 3 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=100
2025-11-09 20:01:27,192 - INFO - root - get_all_titles_from_web 
2025-11-09 20:01:27,192 - INFO - root - Page:2, Index:0, Enhancing Quantization-Aware Training on Edge Devices via Relative Entropy Coreset Selection and Cascaded Layer Correction, https://arxiv.org/pdf/2507.17768, 2025-07-16
2025-11-09 20:01:27,193 - INFO - root - Page:2, Index:1, SiLQ: Simple Large Language Model Quantization-Aware Training, https://arxiv.org/pdf/2507.16933, 2025-07-22
2025-11-09 20:01:27,193 - INFO - root - Page:2, Index:2, Task-Specific Zero-shot Quantization-Aware Training for Object Detection, https://arxiv.org/pdf/2507.16782, 2025-07-22
2025-11-09 20:01:27,193 - INFO - root - Page:2, Index:3, TorchAO: PyTorch-Native Training-to-Serving Model Optimization, https://arxiv.org/pdf/2507.16099, 2025-07-21
2025-11-09 20:01:27,193 - INFO - root - Page:2, Index:4, SegQuant: A Semantics-Aware and Generalizable Quantization Framework for Diffusion Models, https://arxiv.org/pdf/2507.14811, 2025-08-27
2025-11-09 20:01:27,193 - INFO - root - Page:2, Index:5, Apple Intelligence Foundation Language Models: Tech Report 2025, https://arxiv.org/pdf/2507.13575, 2025-08-27
2025-11-09 20:01:27,193 - INFO - root - Page:2, Index:6, Generative Multi-Target Cross-Domain Recommendation, https://arxiv.org/pdf/2507.12871, 2025-08-07
2025-11-09 20:01:27,195 - INFO - root - Page:2, Index:7, DAF: An Efficient End-to-End Dynamic Activation Framework for on-Device DNN Training, https://arxiv.org/pdf/2507.07149, 2025-07-09
2025-11-09 20:01:27,195 - INFO - root - Page:2, Index:8, Opto-ViT: Architecting a Near-Sensor Region of Interest-Aware Vision Transformer Accelerator with Silicon Photonics, https://arxiv.org/pdf/2507.07044, 2025-07-15
2025-11-09 20:01:27,196 - INFO - root - Page:2, Index:9, QS4D: Quantization-aware training for efficient hardware deployment of structured state-space sequential models, https://arxiv.org/pdf/2507.06079, 2025-07-08
2025-11-09 20:01:27,196 - INFO - root - Page:2, Index:10, GSVR: 2D Gaussian-based Video Representation for 800+ FPS with Hybrid Deformation Field, https://arxiv.org/pdf/2507.05594, 2025-07-07
2025-11-09 20:01:27,196 - INFO - root - Page:2, Index:11, Hita: Holistic Tokenizer for Autoregressive Image Generation, https://arxiv.org/pdf/2507.02358, 2025-07-11
2025-11-09 20:01:27,196 - INFO - root - Page:2, Index:12, QPART: Adaptive Model Quantization and Dynamic Workload Balancing for Accuracy-aware Edge Inference, https://arxiv.org/pdf/2506.23934, 2025-06-30
2025-11-09 20:01:27,197 - INFO - root - Page:2, Index:13, FedWSQ: Efficient Federated Learning with Weight Standardization and Distribution-Aware Non-Uniform Quantization, https://arxiv.org/pdf/2506.23516, 2025-07-21
2025-11-09 20:01:27,197 - INFO - root - Page:2, Index:14, Spectra 1.1: Scaling Laws and Efficient Inference for Ternary Language Models, https://arxiv.org/pdf/2506.23025, 2025-06-28
2025-11-09 20:01:27,198 - INFO - root - Page:2, Index:15, Joint Quantization and Pruning Neural Networks Approach: A Case Study on FSO Receivers, https://arxiv.org/pdf/2506.20084, 2025-06-24
2025-11-09 20:01:27,198 - INFO - root - Page:2, Index:16, Single-step Diffusion for Image Compression at Ultra-Low Bitrates, https://arxiv.org/pdf/2506.16572, 2025-09-22
2025-11-09 20:01:27,199 - INFO - root - Page:2, Index:17, LittleBit: Ultra Low-Bit Quantization via Latent Factorization, https://arxiv.org/pdf/2506.13771, 2025-10-28
2025-11-09 20:01:27,199 - INFO - root - Page:2, Index:18, MARCO: Hardware-Aware Neural Architecture Search for Edge Devices with Multi-Agent Reinforcement Learning and Conformal Prediction Filtering, https://arxiv.org/pdf/2506.13755, 2025-06-16
2025-11-09 20:01:27,200 - INFO - root - Page:2, Index:19, EAQuant: Enhancing Post-Training Quantization for MoE Models via Expert-Aware Optimization, https://arxiv.org/pdf/2506.13329, 2025-07-04
2025-11-09 20:01:27,200 - INFO - root - Page:2, Index:20, Towards Neural Audio Codec Source Parsing, https://arxiv.org/pdf/2506.12627, 2025-06-14
2025-11-09 20:01:27,200 - INFO - root - Page:2, Index:21, Quantizing Small-Scale State-Space Models for Edge AI, https://arxiv.org/pdf/2506.12480, 2025-06-14
2025-11-09 20:01:27,200 - INFO - root - Page:2, Index:22, EMLoC: Emulator-based Memory-efficient Fine-tuning with LoRA Correction, https://arxiv.org/pdf/2506.12015, 2025-06-13
2025-11-09 20:01:27,200 - INFO - root - Page:2, Index:23, Compression Aware Certified Training, https://arxiv.org/pdf/2506.11992, 2025-06-13
2025-11-09 20:01:27,203 - INFO - root - Page:2, Index:24, GPLQ: A General, Practical, and Lightning QAT Method for Vision Transformers, https://arxiv.org/pdf/2506.11784, 2025-06-13
2025-11-09 20:01:27,203 - INFO - root - Page:2, Index:25, TruncQuant: Truncation-Ready Quantization for DNNs with Flexible Weight Bit Precision, https://arxiv.org/pdf/2506.11431, 2025-06-12
2025-11-09 20:01:27,203 - INFO - root - Page:2, Index:26, EfficientQuant: An Efficient Post-Training Quantization for CNN-Transformer Hybrid Models on Edge Devices, https://arxiv.org/pdf/2506.11093, 2025-06-05
2025-11-09 20:01:27,204 - INFO - root - Page:2, Index:27, Starting Positions Matter: A Study on Better Weight Initialization for Neural Network Quantization, https://arxiv.org/pdf/2506.10463, 2025-06-12
2025-11-09 20:01:27,204 - INFO - root - Page:2, Index:28, AWP: Activation-Aware Weight Pruning and Quantization with Projected Gradient Descent, https://arxiv.org/pdf/2506.10205, 2025-06-11
2025-11-09 20:01:27,204 - INFO - root - Page:2, Index:29, Q-SAM2: Accurate Quantization for Segment Anything Model 2, https://arxiv.org/pdf/2506.09782, 2025-06-11
2025-11-09 20:01:27,204 - INFO - root - Page:2, Index:30, Unifying Block-wise PTQ and Distillation-based QAT for Progressive Quantization toward 2-bit Instruction-Tuned LLMs, https://arxiv.org/pdf/2506.09104, 2025-06-10
2025-11-09 20:01:27,205 - INFO - root - Page:2, Index:31, Implementing Keyword Spotting on the MCUX947 Microcontroller with Integrated NPU, https://arxiv.org/pdf/2506.08911, 2025-06-10
2025-11-09 20:01:27,207 - INFO - root - Page:2, Index:32, POLARON: Precision-aware On-device Learning and Adaptive Runtime-cONfigurable AI acceleration, https://arxiv.org/pdf/2506.08785, 2025-06-10
2025-11-09 20:01:27,207 - INFO - root - Page:2, Index:33, MoQAE: Mixed-Precision Quantization for Long-Context LLM Inference via Mixture of Quantization-Aware Experts, https://arxiv.org/pdf/2506.07533, 2025-06-09
2025-11-09 20:01:27,209 - INFO - root - Page:2, Index:34, BitVLA: 1-bit Vision-Language-Action Models for Robotics Manipulation, https://arxiv.org/pdf/2506.07530, 2025-06-09
2025-11-09 20:01:27,209 - INFO - root - Page:2, Index:35, RecGPT: A Foundation Model for Sequential Recommendation, https://arxiv.org/pdf/2506.06270, 2025-06-12
2025-11-09 20:01:27,209 - INFO - root - Page:2, Index:36, FPSAttention: Training-Aware FP8 and Sparsity Co-Design for Fast Video Diffusion, https://arxiv.org/pdf/2506.04648, 2025-06-05
2025-11-09 20:01:27,211 - INFO - root - Page:2, Index:37, BitTTS: Highly Compact Text-to-Speech Using 1.58-bit Quantization and Weight Indexing, https://arxiv.org/pdf/2506.03515, 2025-06-03
2025-11-09 20:01:27,212 - INFO - root - Page:2, Index:38, ShapeLLM-Omni: A Native Multimodal LLM for 3D Generation and Understanding, https://arxiv.org/pdf/2506.01853, 2025-06-02
2025-11-09 20:01:27,213 - INFO - root - Page:2, Index:39, Movable Antenna Enhanced Federated Fine-Tuning of Large Language Models via Hybrid Client Selection Optimization, https://arxiv.org/pdf/2506.00011, 2025-10-26
2025-11-09 20:01:27,215 - INFO - root - Page:2, Index:40, Running Conventional Automatic Speech Recognition on Memristor Hardware: A Simulated Approach, https://arxiv.org/pdf/2505.24721, 2025-05-30
2025-11-09 20:01:27,215 - INFO - root - Page:2, Index:41, GARLIC: GAussian Representation LearnIng for spaCe partitioning, https://arxiv.org/pdf/2505.24608, 2025-10-02
2025-11-09 20:01:27,216 - INFO - root - Page:2, Index:42, AutoChemSchematic AI: Agentic Physics-Aware Automation for Chemical Manufacturing Scale-Up, https://arxiv.org/pdf/2505.24584, 2025-08-18
2025-11-09 20:01:27,217 - INFO - root - Page:2, Index:43, Model-Preserving Adaptive Rounding, https://arxiv.org/pdf/2505.22988, 2025-09-25
2025-11-09 20:01:27,217 - INFO - root - Page:2, Index:44, Highly Efficient and Effective LLMs with Multi-Boolean Architectures, https://arxiv.org/pdf/2505.22811, 2025-10-03
2025-11-09 20:01:27,217 - INFO - root - Page:2, Index:45, Pioneering 4-Bit FP Quantization for Diffusion Models: Mixup-Sign Quantization and Timestep-Aware Fine-Tuning, https://arxiv.org/pdf/2505.21591, 2025-05-27
2025-11-09 20:01:27,217 - INFO - root - Page:2, Index:46, Frequency Composition for Compressed and Domain-Adaptive Neural Networks, https://arxiv.org/pdf/2505.20890, 2025-05-27
2025-11-09 20:01:27,218 - INFO - root - Page:2, Index:47, MoPFormer: Motion-Primitive Transformer for Wearable-Sensor Activity Recognition, https://arxiv.org/pdf/2505.20744, 2025-10-27
2025-11-09 20:01:27,218 - INFO - root - Page:2, Index:48, Optimizing edge AI models on HPC systems with the edge in the loop, https://arxiv.org/pdf/2505.19995, 2025-05-26
2025-11-09 20:01:27,223 - INFO - root - Fetching page 4 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=150
2025-11-09 20:01:33,695 - INFO - root - get_all_titles_from_web 
2025-11-09 20:01:33,696 - INFO - root - Page:3, Index:0, DPASyn: Mechanism-Aware Drug Synergy Prediction via Dual Attention and Precision-Aware Quantization, https://arxiv.org/pdf/2505.19144, 2025-09-20
2025-11-09 20:01:33,697 - INFO - root - Page:3, Index:1, Reducing Storage of Pretrained Neural Networks by Rate-Constrained Quantization and Entropy Coding, https://arxiv.org/pdf/2505.18758, 2025-05-24
2025-11-09 20:01:33,697 - INFO - root - Page:3, Index:2, Beyond Discreteness: Finite-Sample Analysis of Straight-Through Estimator for Quantization, https://arxiv.org/pdf/2505.18113, 2025-05-23
2025-11-09 20:01:33,698 - INFO - root - Page:3, Index:3, Automating Versatile Time-Series Analysis with Tiny Transformers on Embedded FPGAs, https://arxiv.org/pdf/2505.17662, 2025-09-19
2025-11-09 20:01:33,698 - INFO - root - Page:3, Index:4, FPQVAR: Floating Point Quantization for Visual Autoregressive Model with FPGA Hardware Co-design, https://arxiv.org/pdf/2505.16335, 2025-05-22
2025-11-09 20:01:33,698 - INFO - root - Page:3, Index:5, Saliency-Aware Quantized Imitation Learning for Efficient Robotic Control, https://arxiv.org/pdf/2505.15304, 2025-05-30
2025-11-09 20:01:33,700 - INFO - root - Page:3, Index:6, Scaling Law for Quantization-Aware Training, https://arxiv.org/pdf/2505.14302, 2025-05-20
2025-11-09 20:01:33,701 - INFO - root - Page:3, Index:7, Automatic mixed precision for optimizing gained time with constrained loss mean-squared-error based on model partition to sequential sub-graphs, https://arxiv.org/pdf/2505.13060, 2025-05-19
2025-11-09 20:01:33,706 - INFO - root - Page:3, Index:8, Deep Unfolding with Kernel-based Quantization in MIMO Detection, https://arxiv.org/pdf/2505.12736, 2025-05-19
2025-11-09 20:01:33,707 - INFO - root - Page:3, Index:9, FedHQ: Hybrid Runtime Quantization for Federated Learning, https://arxiv.org/pdf/2505.11982, 2025-05-17
2025-11-09 20:01:33,709 - INFO - root - Page:3, Index:10, QVGen: Pushing the Limit of Quantized Video Generative Models, https://arxiv.org/pdf/2505.11497, 2025-09-27
2025-11-09 20:01:33,711 - INFO - root - Page:3, Index:11, EA-3DGS: Efficient and Adaptive 3D Gaussians with Highly Enhanced Quality for outdoor scenes, https://arxiv.org/pdf/2505.10787, 2025-05-15
2025-11-09 20:01:33,713 - INFO - root - Page:3, Index:12, ITERA-LLM: Boosting Sub-8-Bit Large Language Model Inference via Iterative Tensor Decomposition, https://arxiv.org/pdf/2505.08981, 2025-05-13
2025-11-09 20:01:33,714 - INFO - root - Page:3, Index:13, PROM: Prioritize Reduction of Multiplications Over Lower Bit-Widths for Efficient CNNs, https://arxiv.org/pdf/2505.03254, 2025-08-06
2025-11-09 20:01:33,714 - INFO - root - Page:3, Index:14, ICQuant: Index Coding enables Low-bit LLM Quantization, https://arxiv.org/pdf/2505.00850, 2025-08-24
2025-11-09 20:01:33,714 - INFO - root - Page:3, Index:15, Enhancing Ultra-Low-Bit Quantization of Large Language Models Through Saliency-Aware Partial Retraining, https://arxiv.org/pdf/2504.13932, 2025-07-30
2025-11-09 20:01:33,715 - INFO - root - Page:3, Index:16, Achieving binary weight and activation for LLMs using Post-Training Quantization, https://arxiv.org/pdf/2504.05352, 2025-06-30
2025-11-09 20:01:33,715 - INFO - root - Page:3, Index:17, Wireless Hearables With Programmable Speech AI Accelerators, https://arxiv.org/pdf/2503.18698, 2025-10-21
2025-11-09 20:01:33,715 - INFO - root - Page:3, Index:18, GranQ: Efficient Channel-wise Quantization via Vectorized Pre-Scaling for Zero-Shot QAT, https://arxiv.org/pdf/2503.18339, 2025-10-15
2025-11-09 20:01:33,716 - INFO - root - Page:3, Index:19, CompMarkGS: Robust Watermarking for Compressed 3D Gaussian Splatting, https://arxiv.org/pdf/2503.12836, 2025-09-29
2025-11-09 20:01:33,716 - INFO - root - Page:3, Index:20, AHCPTQ: Accurate and Hardware-Compatible Post-Training Quantization for Segment Anything Model, https://arxiv.org/pdf/2503.03088, 2025-07-11
2025-11-09 20:01:33,717 - INFO - root - Page:3, Index:21, Teaching Metric Distance to Discrete Autoregressive Language Models, https://arxiv.org/pdf/2503.02379, 2025-10-07
2025-11-09 20:01:33,718 - INFO - root - Page:3, Index:22, Regularization-based Framework for Quantization-, Fault- and Variability-Aware Training, https://arxiv.org/pdf/2503.01297, 2025-07-12
2025-11-09 20:01:33,721 - INFO - root - Fetching page 5 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=200
2025-11-09 20:01:41,539 - INFO - root - get_all_titles_from_web 
2025-11-09 20:01:41,539 - INFO - root - Page:4, Index:0, Investigating the Impact of Quantization Methods on the Safety and Reliability of Large Language Models, https://arxiv.org/pdf/2502.15799, 2025-06-29
2025-11-09 20:01:41,540 - INFO - root - Page:4, Index:1, Rotate, Clip, and Partition: Towards W2A4KV4 Quantization by Integrating Rotation and Learnable Non-uniform Quantizer, https://arxiv.org/pdf/2502.15779, 2025-09-01
2025-11-09 20:01:41,540 - INFO - root - Page:4, Index:2, RoSTE: An Efficient Quantization-Aware Supervised Fine-Tuning Approach for Large Language Models, https://arxiv.org/pdf/2502.09003, 2025-06-05
2025-11-09 20:01:41,540 - INFO - root - Page:4, Index:3, Spatial Degradation-Aware and Temporal Consistent Diffusion Model for Compressed Video Super-Resolution, https://arxiv.org/pdf/2502.07381, 2025-06-27
2025-11-09 20:01:41,540 - INFO - root - Page:4, Index:4, QuEST: Stable Training of LLMs with 1-Bit Weights and Activations, https://arxiv.org/pdf/2502.05003, 2025-06-10
2025-11-09 20:01:41,540 - INFO - root - Page:4, Index:5, HALO: Hadamard-Assisted Lower-Precision Optimization for LLMs, https://arxiv.org/pdf/2501.02625, 2025-11-05
2025-11-09 20:01:41,540 - INFO - root - Page:4, Index:6, TAR3D: Creating High-Quality 3D Assets via Next-Part Prediction, https://arxiv.org/pdf/2412.16919, 2025-08-08
2025-11-09 20:01:41,542 - INFO - root - Page:4, Index:7, Training Multi-Layer Binary Neural Networks With Local Binary Error Signals, https://arxiv.org/pdf/2412.00119, 2025-08-05
2025-11-09 20:01:41,542 - INFO - root - Page:4, Index:8, Scaling Large-scale GNN Training to Thousands of Processors on CPU-based Supercomputers, https://arxiv.org/pdf/2411.16025, 2025-05-26
2025-11-09 20:01:41,542 - INFO - root - Page:4, Index:9, HAFLQ: Heterogeneous Adaptive Federated LoRA Fine-tuned LLM with Quantization, https://arxiv.org/pdf/2411.06581, 2025-05-16
2025-11-09 20:01:41,544 - INFO - root - Fetching page 6 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=250
2025-11-09 20:01:51,894 - INFO - root - get_all_titles_from_web 
2025-11-09 20:01:51,895 - INFO - root - Page:5, Index:0, Gradient-Free Training of Quantized Neural Networks, https://arxiv.org/pdf/2410.09734, 2025-09-29
2025-11-09 20:01:51,895 - INFO - root - Page:5, Index:1, QT-DoG: Quantization-aware Training for Domain Generalization, https://arxiv.org/pdf/2410.06020, 2025-06-26
2025-11-09 20:01:51,897 - INFO - root - Page:5, Index:2, Constraint Guided Model Quantization of Neural Networks, https://arxiv.org/pdf/2409.20138, 2025-09-12
2025-11-09 20:01:51,899 - INFO - root - Page:5, Index:3, Accumulator-Aware Post-Training Quantization for Large Language Models, https://arxiv.org/pdf/2409.17092, 2025-07-30
2025-11-09 20:01:51,899 - INFO - root - Page:5, Index:4, DilateQuant: Accurate and Efficient Diffusion Quantization via Weight Dilation, https://arxiv.org/pdf/2409.14307, 2025-07-09
2025-11-09 20:01:51,901 - INFO - root - Page:5, Index:5, Robust Training of Neural Networks at Arbitrary Precision and Sparsity, https://arxiv.org/pdf/2409.09245, 2025-09-23
2025-11-09 20:01:51,931 - INFO - root - Page:5, Index:6, VQ-CTAP: Cross-Modal Fine-Grained Sequence Representation Learning for Speech Processing, https://arxiv.org/pdf/2408.05758, 2025-05-27
2025-11-09 20:01:51,934 - INFO - root - Page:5, Index:7, DopQ-ViT: Towards Distribution-Friendly and Outlier-Aware Post-Training Quantization for Vision Transformers, https://arxiv.org/pdf/2408.03291, 2025-06-19
2025-11-09 20:01:51,935 - INFO - root - Page:5, Index:8, Temporal Feature Matters: A Framework for Diffusion Model Quantization, https://arxiv.org/pdf/2407.19547, 2025-07-11
2025-11-09 20:01:51,953 - INFO - root - Page:5, Index:9, EfficientQAT: Efficient Quantization-Aware Training for Large Language Models, https://arxiv.org/pdf/2407.11062, 2025-05-19
2025-11-09 20:01:51,977 - INFO - root - Page:5, Index:10, Integer-only Quantized Transformers for Embedded FPGA-based Time-series Forecasting in AIoT, https://arxiv.org/pdf/2407.11041, 2025-10-31
2025-11-09 20:01:51,979 - INFO - root - Fetching page 7 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=300
2025-11-09 20:01:58,534 - INFO - root - get_all_titles_from_web 
2025-11-09 20:01:58,534 - INFO - root - Page:6, Index:0, BoA: Attention-aware Post-training Quantization without Backpropagation, https://arxiv.org/pdf/2406.13474, 2025-06-06
2025-11-09 20:01:58,534 - INFO - root - Page:6, Index:1, A Rescaling-Invariant Lipschitz Bound Based on Path-Metrics for Modern ReLU Network Parameterizations, https://arxiv.org/pdf/2405.15006, 2025-06-13
2025-11-09 20:01:58,535 - INFO - root - Page:6, Index:2, Scheduling Weight Transitions for Quantization-Aware Training, https://arxiv.org/pdf/2404.19248, 2025-10-01
2025-11-09 20:01:58,535 - INFO - root - Page:6, Index:3, GPTVQ: The Blessing of Dimensionality for LLM Quantization, https://arxiv.org/pdf/2402.15319, 2025-06-03
2025-11-09 20:01:58,535 - INFO - root - Fetching page 8 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=350
2025-11-09 20:02:06,126 - INFO - root - get_all_titles_from_web 
2025-11-09 20:02:06,126 - INFO - root - Page:7, Index:0, Squat: Quant Small Language Models on the Edge, https://arxiv.org/pdf/2402.10787, 2025-07-01
2025-11-09 20:02:06,127 - INFO - root - Page:7, Index:1, L4Q: Parameter Efficient Quantization-Aware Fine-Tuning on Large Language Models, https://arxiv.org/pdf/2402.04902, 2025-07-21
2025-11-09 20:02:06,127 - INFO - root - Fetching page 9 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=400
2025-11-09 20:02:12,933 - INFO - root - ------------------------------------------------------------------------------------------------------------------------
2025-11-09 20:02:25,773 - INFO - root - 跳过已处理论文 A Quantized VAE-MLP Botnet Detection Model: A Systematic Evaluation of Quantization-Aware Training and Post-Training Quantization Strategies：D:\ChatPaper\academic Papers\Quantization-Aware-Training\A Quantized VAE-MLP Botnet Detection Model_ A Systematic Evaluation of Quantizat-3.pdf
2025-11-09 20:02:25,779 - INFO - root - 跳过已处理论文 FP8-Flow-MoE: A Casting-Free FP8 Recipe without Double Quantization Error：D:\ChatPaper\academic Papers\Quantization-Aware-Training\FP8-Flow-MoE_ A Casting-Free FP8 Recipe without Double Quantization Error-3.pdf
2025-11-09 20:02:25,832 - INFO - root - summary time: 90.09 seconds
2025-11-09 20:12:00,720 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-09 20:12:00,723 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-09 20:12:00,726 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-09 20:12:02,579 - INFO - root - LLMClientManager: 指定使用客户端: Deepseek
2025-11-09 20:12:02,580 - INFO - root - DeepSeekClient: API key found: 9f9e270e-b...
2025-11-09 20:12:02,582 - INFO - root - DeepSeekClient: 使用模式: 火山引擎
2025-11-09 20:12:02,583 - INFO - root - DeepSeekClient: 模型名称: deepseek-v3-1-terminus
2025-11-09 20:12:06,717 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 20:12:06,745 - INFO - root - DeepSeekClient: initialized successfully with model deepseek-v3-1-terminus
2025-11-09 20:12:06,745 - INFO - root - LLMClientManager: DeepSeek 客户端初始化成功
2025-11-09 20:12:06,745 - WARNING - root - LLMClientManager: client Deepseek not available
2025-11-09 20:12:06,746 - WARNING - root - 无法切换到指定的客户端 Deepseek，将使用默认客户端
2025-11-09 20:12:06,746 - INFO - root - 可用客户端: ['DeepSeek']
2025-11-09 20:12:06,746 - INFO - root - 使用 LLM 模型: deepseek-v3-1-terminus
2025-11-09 20:12:06,747 - INFO - root - 可用客户端: ['DeepSeek']
2025-11-09 20:12:06,748 - INFO - root - === 运行配置 ===
2025-11-09 20:12:06,749 - INFO - root - 处理模式: arxiv在线搜索
2025-11-09 20:12:06,750 - INFO - root - 关键词: QAT
2025-11-09 20:12:06,760 - INFO - root - 查询: Quantization-Aware-Training
2025-11-09 20:12:06,776 - INFO - root - 排序: None
2025-11-09 20:12:06,793 - INFO - root - 最近天数: 180
2025-11-09 20:12:06,794 - INFO - root - 最大处理数量: 2
2025-11-09 20:12:06,794 - INFO - root - 保存图片: 是
2025-11-09 20:12:06,794 - INFO - root - 输出语言: 中文
2025-11-09 20:12:06,795 - INFO - root - 强制重新处理: 否
2025-11-09 20:12:06,795 - INFO - root - ====================
2025-11-09 20:12:06,796 - INFO - root - 使用 arXiv 搜索模式（通过 chat_arxiv 模块获取）
2025-11-09 20:12:06,797 - INFO - root - Fetching page 1 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50
2025-11-09 20:12:13,586 - INFO - root - get_all_titles_from_web 
2025-11-09 20:12:13,587 - INFO - root - Page:0, Index:0, A Quantized VAE-MLP Botnet Detection Model: A Systematic Evaluation of Quantization-Aware Training and Post-Training Quantization Strategies, https://arxiv.org/pdf/2511.03201, 2025-11-05
2025-11-09 20:12:13,587 - INFO - root - Page:0, Index:1, FP8-Flow-MoE: A Casting-Free FP8 Recipe without Double Quantization Error, https://arxiv.org/pdf/2511.02302, 2025-11-04
2025-11-09 20:12:13,587 - INFO - root - Page:0, Index:2, Outlier-Aware Post-Training Quantization for Image Super-Resolution, https://arxiv.org/pdf/2511.00682, 2025-11-01
2025-11-09 20:12:13,587 - INFO - root - Page:0, Index:3, Evaluation of Wafer-Scale SOT-MRAM for Analog Crossbar Array Applications, https://arxiv.org/pdf/2510.25853, 2025-11-03
2025-11-09 20:12:13,588 - INFO - root - Page:0, Index:4, Improving the Straight-Through Estimator with Zeroth-Order Information, https://arxiv.org/pdf/2510.23926, 2025-10-27
2025-11-09 20:12:13,588 - INFO - root - Page:0, Index:5, Real-Time Semantic Segmentation on FPGA for Autonomous Vehicles Using LMIINet with the CGRA4ML Framework, https://arxiv.org/pdf/2510.22243, 2025-10-25
2025-11-09 20:12:13,588 - INFO - root - Page:0, Index:6, TernaryCLIP: Efficiently Compressing Vision-Language Models with Ternary Weights and Distilled Knowledge, https://arxiv.org/pdf/2510.21879, 2025-10-23
2025-11-09 20:12:13,588 - INFO - root - Page:0, Index:7, KARIPAP: Quantum-Inspired Tensor Network Compression of Large Language Models Using Infinite Projected Entangled Pair States and Tensor Renormalization Group, https://arxiv.org/pdf/2510.21844, 2025-10-22
2025-11-09 20:12:13,590 - INFO - root - Page:0, Index:8, A Convergence Analysis of Adaptive Optimizers under Floating-point Quantization, https://arxiv.org/pdf/2510.21314, 2025-10-24
2025-11-09 20:12:13,590 - INFO - root - Page:0, Index:9, Adaptive Distribution-aware Quantization for Mixed-Precision Neural Networks, https://arxiv.org/pdf/2510.19760, 2025-10-22
2025-11-09 20:12:13,590 - INFO - root - Page:0, Index:10, CAGE: Curvature-Aware Gradient Estimation For Accurate Quantization-Aware Training, https://arxiv.org/pdf/2510.18784, 2025-10-21
2025-11-09 20:12:13,590 - INFO - root - Page:0, Index:11, Mixed-Precision Quantization for Language Models: Techniques and Prospects, https://arxiv.org/pdf/2510.16805, 2025-10-19
2025-11-09 20:12:13,591 - INFO - root - Page:0, Index:12, SPLite Hand: Sparsity-Aware Lightweight 3D Hand Pose Estimation, https://arxiv.org/pdf/2510.16396, 2025-10-30
2025-11-09 20:12:13,591 - INFO - root - Page:0, Index:13, CTR-LoRA: Curvature-Aware and Trust-Region Guided Low-Rank Adaptation for Large Language Models, https://arxiv.org/pdf/2510.15962, 2025-10-11
2025-11-09 20:12:13,592 - INFO - root - Page:0, Index:14, SANR: Scene-Aware Neural Representation for Light Field Image Compression with Rate-Distortion Optimization, https://arxiv.org/pdf/2510.15775, 2025-10-17
2025-11-09 20:12:13,592 - INFO - root - Page:0, Index:15, SpikeFit: Towards Optimal Deployment of Spiking Networks on Neuromorphic Hardware, https://arxiv.org/pdf/2510.15542, 2025-10-31
2025-11-09 20:12:13,592 - INFO - root - Page:0, Index:16, GRank: Towards Target-Aware and Streamlined Industrial Retrieval with a Generate-Rank Framework, https://arxiv.org/pdf/2510.15299, 2025-10-17
2025-11-09 20:12:13,593 - INFO - root - Page:0, Index:17, SaLon3R: Structure-aware Long-term Generalizable 3D Reconstruction from Unposed Images, https://arxiv.org/pdf/2510.15072, 2025-10-16
2025-11-09 20:12:13,593 - INFO - root - Page:0, Index:18, FraQAT: Quantization Aware Training with Fractional bits, https://arxiv.org/pdf/2510.14823, 2025-10-16
2025-11-09 20:12:13,594 - INFO - root - Page:0, Index:19, Computing-In-Memory Aware Model Adaption For Edge Devices, https://arxiv.org/pdf/2510.14379, 2025-10-16
2025-11-09 20:12:13,594 - INFO - root - Page:0, Index:20, Invited Paper: BitMedViT: Ternary-Quantized Vision Transformer for Medical AI Assistants on the Edge, https://arxiv.org/pdf/2510.13760, 2025-11-04
2025-11-09 20:12:13,594 - INFO - root - Page:0, Index:21, NeuroRVQ: Multi-Scale EEG Tokenization for Generative Large Brainwave Models, https://arxiv.org/pdf/2510.13068, 2025-10-14
2025-11-09 20:12:13,595 - INFO - root - Page:0, Index:22, Detect Anything via Next Point Prediction, https://arxiv.org/pdf/2510.12798, 2025-10-14
2025-11-09 20:12:13,595 - INFO - root - Page:0, Index:23, AndesVL Technical Report: An Efficient Mobile-side Multimodal Large Language Model, https://arxiv.org/pdf/2510.11496, 2025-10-14
2025-11-09 20:12:13,595 - INFO - root - Page:0, Index:24, Rescaling-Aware Training for Efficient Deployment of Deep Learning Models on Full-Integer Hardware, https://arxiv.org/pdf/2510.11484, 2025-10-13
2025-11-09 20:12:13,595 - INFO - root - Page:0, Index:25, SASER: Stego attacks on open-source LLMs, https://arxiv.org/pdf/2510.10486, 2025-10-12
2025-11-09 20:12:13,597 - INFO - root - Page:0, Index:26, Ultralytics YOLO Evolution: An Overview of YOLO26, YOLO11, YOLOv8 and YOLOv5 Object Detectors for Computer Vision and Pattern Recognition, https://arxiv.org/pdf/2510.09653, 2025-10-15
2025-11-09 20:12:13,597 - INFO - root - Page:0, Index:27, A Theoretically-Grounded Codebook for Digital Semantic Communications, https://arxiv.org/pdf/2510.07108, 2025-10-14
2025-11-09 20:12:13,597 - INFO - root - Page:0, Index:28, QuantDemoire: Quantization with Outlier Aware for Image Demoiréing, https://arxiv.org/pdf/2510.04066, 2025-10-05
2025-11-09 20:12:13,598 - INFO - root - Page:0, Index:29, Adaptively Sampling-Reusing-Mixing Decomposed Gradients to Speed Up Sharpness Aware Minimization, https://arxiv.org/pdf/2510.03763, 2025-10-04
2025-11-09 20:12:13,598 - INFO - root - Page:0, Index:30, Quant-dLLM: Post-Training Extreme Low-Bit Quantization for Diffusion Large Language Models, https://arxiv.org/pdf/2510.03274, 2025-09-27
2025-11-09 20:12:13,598 - INFO - root - Page:0, Index:31, PT$^2$-LLM: Post-Training Ternarization for Large Language Models, https://arxiv.org/pdf/2510.03267, 2025-09-26
2025-11-09 20:12:13,602 - INFO - root - Page:0, Index:32, Purrception: Variational Flow Matching for Vector-Quantized Image Generation, https://arxiv.org/pdf/2510.01478, 2025-10-01
2025-11-09 20:12:13,602 - INFO - root - Page:0, Index:33, Post-Training Quantization for Audio Diffusion Transformers, https://arxiv.org/pdf/2510.00313, 2025-09-30
2025-11-09 20:12:13,603 - INFO - root - Page:0, Index:34, Rethinking RoPE Scaling in Quantized LLM: Theory, Outlier, and Channel-Band Analysis with Weight Rescaling, https://arxiv.org/pdf/2510.00028, 2025-09-25
2025-11-09 20:12:13,603 - INFO - root - Page:0, Index:35, Post-Training Quantization via Residual Truncation and Zero Suppression for Diffusion Models, https://arxiv.org/pdf/2509.26436, 2025-09-30
2025-11-09 20:12:13,604 - INFO - root - Page:0, Index:36, Cat: Post-Training Quantization Error Reduction via Cluster-based Affine Transformation, https://arxiv.org/pdf/2509.26277, 2025-10-07
2025-11-09 20:12:13,604 - INFO - root - Page:0, Index:37, CAST: Continuous and Differentiable Semi-Structured Sparsity-Aware Training for Large Language Models, https://arxiv.org/pdf/2509.25996, 2025-09-30
2025-11-09 20:12:13,604 - INFO - root - Page:0, Index:38, Norm-Q: Effective Compression Method for Hidden Markov Models in Neuro-Symbolic Applications, https://arxiv.org/pdf/2509.25439, 2025-09-29
2025-11-09 20:12:13,606 - INFO - root - Page:0, Index:39, On-the-Fly Adaptation to Quantization: Configuration-Aware LoRA for Efficient Fine-Tuning of Quantized LLMs, https://arxiv.org/pdf/2509.25214, 2025-09-22
2025-11-09 20:12:13,606 - INFO - root - Page:0, Index:40, VoxCPM: Tokenizer-Free TTS for Context-Aware Speech Generation and True-to-Life Voice Cloning, https://arxiv.org/pdf/2509.24650, 2025-09-29
2025-11-09 20:12:13,606 - INFO - root - Page:0, Index:41, S$^2$NN: Sub-bit Spiking Neural Networks, https://arxiv.org/pdf/2509.24266, 2025-10-24
2025-11-09 20:12:13,606 - INFO - root - Page:0, Index:42, Tequila: Trapping-free Ternary Quantization for Large Language Models, https://arxiv.org/pdf/2509.23809, 2025-10-17
2025-11-09 20:12:13,607 - INFO - root - Page:0, Index:43, Texture Vector-Quantization and Reconstruction Aware Prediction for Generative Super-Resolution, https://arxiv.org/pdf/2509.23774, 2025-09-30
2025-11-09 20:12:13,607 - INFO - root - Page:0, Index:44, RobuQ: Pushing DiTs to W1.58A2 via Robust Activation Quantization, https://arxiv.org/pdf/2509.23582, 2025-09-27
2025-11-09 20:12:13,612 - INFO - root - Page:0, Index:45, Beyond Outliers: A Study of Optimizers Under Quantization, https://arxiv.org/pdf/2509.23500, 2025-10-02
2025-11-09 20:12:13,613 - INFO - root - Page:0, Index:46, Compute-Optimal Quantization-Aware Training, https://arxiv.org/pdf/2509.22935, 2025-09-26
2025-11-09 20:12:13,613 - INFO - root - Page:0, Index:47, COSPADI: Compressing LLMs via Calibration-Guided Sparse Dictionary Learning, https://arxiv.org/pdf/2509.22075, 2025-10-06
2025-11-09 20:12:13,614 - INFO - root - Page:0, Index:48, SlimDiff: Training-Free, Activation-Guided Hands-free Slimming of Diffusion Models, https://arxiv.org/pdf/2509.21498, 2025-09-25
2025-11-09 20:12:13,614 - INFO - root - Page:0, Index:49, Quantized Visual Geometry Grounded Transformer, https://arxiv.org/pdf/2509.21302, 2025-09-29
2025-11-09 20:12:13,615 - INFO - root - Fetching page 2 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=50
2025-11-09 20:12:20,154 - INFO - root - get_all_titles_from_web 
2025-11-09 20:12:20,155 - INFO - root - Page:1, Index:0, Can Less Precise Be More Reliable? A Systematic Evaluation of Quantization's Impact on CLIP Beyond Accuracy, https://arxiv.org/pdf/2509.21173, 2025-10-27
2025-11-09 20:12:20,156 - INFO - root - Page:1, Index:1, Punching Above Precision: Small Quantized Model Distillation with Learnable Regularizer, https://arxiv.org/pdf/2509.20854, 2025-09-25
2025-11-09 20:12:20,156 - INFO - root - Page:1, Index:2, TinyEcoWeedNet: Edge Efficient Real-Time Aerial Agricultural Weed Detection, https://arxiv.org/pdf/2509.18193, 2025-09-19
2025-11-09 20:12:20,156 - INFO - root - Page:1, Index:3, SBVR: Summation of BitVector Representation for Efficient LLM Quantization, https://arxiv.org/pdf/2509.18172, 2025-09-17
2025-11-09 20:12:20,156 - INFO - root - Page:1, Index:4, QWHA: Quantization-Aware Walsh-Hadamard Adaptation for Parameter-Efficient Fine-Tuning on Large Language Models, https://arxiv.org/pdf/2509.17428, 2025-09-26
2025-11-09 20:12:20,156 - INFO - root - Page:1, Index:5, PTQTP: Post-Training Quantization to Trit-Planes for Large Language Models, https://arxiv.org/pdf/2509.16989, 2025-10-28
2025-11-09 20:12:20,156 - INFO - root - Page:1, Index:6, MEC-Quant: Maximum Entropy Coding for Extremely Low Bit Quantization-Aware Training, https://arxiv.org/pdf/2509.15514, 2025-09-18
2025-11-09 20:12:20,157 - INFO - root - Page:1, Index:7, Q-ROAR: Outlier-Aware Rescaling for RoPE Position Interpolation in Quantized Long-Context LLMs, https://arxiv.org/pdf/2509.14391, 2025-09-17
2025-11-09 20:12:20,157 - INFO - root - Page:1, Index:8, Efficient Quantization-Aware Neural Receivers: Beyond Post-Training Quantization, https://arxiv.org/pdf/2509.13786, 2025-09-19
2025-11-09 20:12:20,157 - INFO - root - Page:1, Index:9, Rate-Distortion Limits for Multimodal Retrieval: Theory, Optimal Codes, and Finite-Sample Guarantees, https://arxiv.org/pdf/2509.11054, 2025-09-13
2025-11-09 20:12:20,157 - INFO - root - Page:1, Index:10, SQAP-VLA: A Synergistic Quantization-Aware Pruning Framework for High-Performance Vision-Language-Action Models, https://arxiv.org/pdf/2509.09090, 2025-09-10
2025-11-09 20:12:20,158 - INFO - root - Page:1, Index:11, CSI Compression Beyond Latents: End-to-End Hybrid Attention-CNN Networks with Entropy Regularization, https://arxiv.org/pdf/2509.08776, 2025-09-10
2025-11-09 20:12:20,158 - INFO - root - Page:1, Index:12, Explaining How Quantization Disparately Skews a Model, https://arxiv.org/pdf/2509.07222, 2025-09-08
2025-11-09 20:12:20,158 - INFO - root - Page:1, Index:13, LoaQ: Layer-wise Output Approximation Quantization, https://arxiv.org/pdf/2509.06297, 2025-09-07
2025-11-09 20:12:20,159 - INFO - root - Page:1, Index:14, FineServe: Precision-Aware KV Slab and Two-Level Scheduling for Heterogeneous Precision LLM Serving, https://arxiv.org/pdf/2509.06261, 2025-09-14
2025-11-09 20:12:20,159 - INFO - root - Page:1, Index:15, Sensitivity-Aware Post-Training Quantization for Deep Neural Networks, https://arxiv.org/pdf/2509.05576, 2025-09-05
2025-11-09 20:12:20,159 - INFO - root - Page:1, Index:16, SuperSNN: A Hardware-Aware Framework for Physically Realizable, High-Performance Superconducting Spiking Neural Network Chips, https://arxiv.org/pdf/2509.05532, 2025-09-05
2025-11-09 20:12:20,160 - INFO - root - Page:1, Index:17, Data-Augmented Quantization-Aware Knowledge Distillation, https://arxiv.org/pdf/2509.03850, 2025-09-03
2025-11-09 20:12:20,161 - INFO - root - Page:1, Index:18, DPQuant: Efficient and Differentially-Private Model Training via Dynamic Quantization Scheduling, https://arxiv.org/pdf/2509.03472, 2025-09-03
2025-11-09 20:12:20,161 - INFO - root - Page:1, Index:19, Empowering Large Language Model for Sequential Recommendation via Multimodal Embeddings and Semantic IDs, https://arxiv.org/pdf/2509.02017, 2025-09-02
2025-11-09 20:12:20,162 - INFO - root - Page:1, Index:20, Q-Sched: Pushing the Boundaries of Few-Step Diffusion Models with Quantization-Aware Scheduling, https://arxiv.org/pdf/2509.01624, 2025-09-01
2025-11-09 20:12:20,162 - INFO - root - Page:1, Index:21, Quantization Meets OOD: Generalizable Quantization-aware Training from a Flatness Perspective, https://arxiv.org/pdf/2509.00859, 2025-08-31
2025-11-09 20:12:20,163 - INFO - root - Page:1, Index:22, Progressive Element-wise Gradient Estimation for Neural Network Quantization, https://arxiv.org/pdf/2509.00097, 2025-08-27
2025-11-09 20:12:20,163 - INFO - root - Page:1, Index:23, End-to-End On-Device Quantization-Aware Training for LLMs at Inference Cost, https://arxiv.org/pdf/2509.00031, 2025-09-29
2025-11-09 20:12:20,163 - INFO - root - Page:1, Index:24, Quantization Robustness to Input Degradations for Object Detection, https://arxiv.org/pdf/2508.19600, 2025-08-27
2025-11-09 20:12:20,163 - INFO - root - Page:1, Index:25, Scaling Laws for Task-Stratified Knowledge in Post-Training Quantized Large Language Models, https://arxiv.org/pdf/2508.18609, 2025-08-27
2025-11-09 20:12:20,164 - INFO - root - Page:1, Index:26, AQ-PCDSys: An Adaptive Quantized Planetary Crater Detection System for Autonomous Space Exploration, https://arxiv.org/pdf/2508.18025, 2025-08-25
2025-11-09 20:12:20,166 - INFO - root - Page:1, Index:27, TaDiCodec: Text-aware Diffusion Speech Tokenizer for Speech Language Modeling, https://arxiv.org/pdf/2508.16790, 2025-08-22
2025-11-09 20:12:20,166 - INFO - root - Page:1, Index:28, A Node-Aware Dynamic Quantization Approach for Graph Collaborative Filtering, https://arxiv.org/pdf/2508.16516, 2025-08-22
2025-11-09 20:12:20,166 - INFO - root - Page:1, Index:29, JEDI-linear: Fast and Efficient Graph Neural Networks for Jet Tagging on FPGAs, https://arxiv.org/pdf/2508.15468, 2025-08-21
2025-11-09 20:12:20,166 - INFO - root - Page:1, Index:30, MMQ: Multimodal Mixture-of-Quantization Tokenization for Semantic ID Generation and User Behavioral Adaptation, https://arxiv.org/pdf/2508.15281, 2025-08-21
2025-11-09 20:12:20,167 - INFO - root - Page:1, Index:31, DLLMQuant: Quantizing Diffusion-based Large Language Models, https://arxiv.org/pdf/2508.14090, 2025-08-25
2025-11-09 20:12:20,168 - INFO - root - Page:1, Index:32, Automated Energy-Aware Time-Series Model Deployment on Embedded FPGAs for Resilient Combined Sewer Overflow Management, https://arxiv.org/pdf/2508.13905, 2025-08-19
2025-11-09 20:12:20,172 - INFO - root - Page:1, Index:33, XR-NPE: High-Throughput Mixed-precision SIMD Neural Processing Engine for Extended Reality Perception Workloads, https://arxiv.org/pdf/2508.13049, 2025-08-18
2025-11-09 20:12:20,172 - INFO - root - Page:1, Index:34, Exploring Self-Supervised Audio Models for Generalized Anomalous Sound Detection, https://arxiv.org/pdf/2508.12230, 2025-08-17
2025-11-09 20:12:20,172 - INFO - root - Page:1, Index:35, TriQDef: Disrupting Semantic and Gradient Alignment to Prevent Adversarial Patch Transferability in Quantized Neural Networks, https://arxiv.org/pdf/2508.12132, 2025-08-16
2025-11-09 20:12:20,173 - INFO - root - Page:1, Index:36, Error Propagation Mechanisms and Compensation Strategies for Quantized Diffusion, https://arxiv.org/pdf/2508.12094, 2025-10-13
2025-11-09 20:12:20,173 - INFO - root - Page:1, Index:37, Extending Straight-Through Estimation for Robust Neural Networks on Analog CIM Hardware, https://arxiv.org/pdf/2508.11940, 2025-08-16
2025-11-09 20:12:20,173 - INFO - root - Page:1, Index:38, PTQAT: A Hybrid Parameter-Efficient Quantization Algorithm for 3D Perception Tasks, https://arxiv.org/pdf/2508.10557, 2025-08-15
2025-11-09 20:12:20,173 - INFO - root - Page:1, Index:39, MiCo: End-to-End Mixed Precision Neural Network Co-Exploration Framework for Edge AI, https://arxiv.org/pdf/2508.09500, 2025-08-13
2025-11-09 20:12:20,174 - INFO - root - Page:1, Index:40, SPARC: Soft Probabilistic Adaptive multi-interest Retrieval Model via Codebooks for recommender system, https://arxiv.org/pdf/2508.09090, 2025-08-12
2025-11-09 20:12:20,174 - INFO - root - Page:1, Index:41, Rethinking 1-bit Optimization Leveraging Pre-trained Large Language Models, https://arxiv.org/pdf/2508.06974, 2025-08-09
2025-11-09 20:12:20,174 - INFO - root - Page:1, Index:42, Efficient Deep Neural Receiver with Post-Training Quantization, https://arxiv.org/pdf/2508.06275, 2025-08-08
2025-11-09 20:12:20,175 - INFO - root - Page:1, Index:43, iFairy: the First 2-bit Complex LLM with All Parameters in $\{\pm1, \pm i\}$, https://arxiv.org/pdf/2508.05571, 2025-08-16
2025-11-09 20:12:20,175 - INFO - root - Page:1, Index:44, S$^2$Q-VDiT: Accurate Quantized Video Diffusion Transformer with Salient Data and Sparse Token Distillation, https://arxiv.org/pdf/2508.04016, 2025-10-27
2025-11-09 20:12:20,175 - INFO - root - Page:1, Index:45, LRQ-DiT: Log-Rotation Post-Training Quantization of Diffusion Transformers for Image and Video Generation, https://arxiv.org/pdf/2508.03485, 2025-09-23
2025-11-09 20:12:20,176 - INFO - root - Page:1, Index:46, VLMQ: Efficient Post-Training Quantization for Large Vision-Language Models via Hessian Augmentation, https://arxiv.org/pdf/2508.03351, 2025-08-05
2025-11-09 20:12:20,176 - INFO - root - Page:1, Index:47, TF-MLPNet: Tiny Real-Time Neural Speech Separation, https://arxiv.org/pdf/2508.03047, 2025-08-04
2025-11-09 20:12:20,177 - INFO - root - Page:1, Index:48, SaviorRec: Semantic-Behavior Alignment for Cold-Start Recommendation, https://arxiv.org/pdf/2508.01375, 2025-08-02
2025-11-09 20:12:20,177 - INFO - root - Page:1, Index:49, MixA-Q: Revisiting Activation Sparsity for Vision Transformers from a Mixed-Precision Quantization Perspective, https://arxiv.org/pdf/2507.19131, 2025-07-25
2025-11-09 20:12:20,177 - INFO - root - Fetching page 3 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=100
2025-11-09 20:12:26,765 - INFO - root - get_all_titles_from_web 
2025-11-09 20:12:26,765 - INFO - root - Page:2, Index:0, Enhancing Quantization-Aware Training on Edge Devices via Relative Entropy Coreset Selection and Cascaded Layer Correction, https://arxiv.org/pdf/2507.17768, 2025-07-16
2025-11-09 20:12:26,766 - INFO - root - Page:2, Index:1, SiLQ: Simple Large Language Model Quantization-Aware Training, https://arxiv.org/pdf/2507.16933, 2025-07-22
2025-11-09 20:12:26,770 - INFO - root - Page:2, Index:2, Task-Specific Zero-shot Quantization-Aware Training for Object Detection, https://arxiv.org/pdf/2507.16782, 2025-07-22
2025-11-09 20:12:26,779 - INFO - root - Page:2, Index:3, TorchAO: PyTorch-Native Training-to-Serving Model Optimization, https://arxiv.org/pdf/2507.16099, 2025-07-21
2025-11-09 20:12:26,783 - INFO - root - Page:2, Index:4, SegQuant: A Semantics-Aware and Generalizable Quantization Framework for Diffusion Models, https://arxiv.org/pdf/2507.14811, 2025-08-27
2025-11-09 20:12:26,799 - INFO - root - Page:2, Index:5, Apple Intelligence Foundation Language Models: Tech Report 2025, https://arxiv.org/pdf/2507.13575, 2025-08-27
2025-11-09 20:12:26,813 - INFO - root - Page:2, Index:6, Generative Multi-Target Cross-Domain Recommendation, https://arxiv.org/pdf/2507.12871, 2025-08-07
2025-11-09 20:12:26,816 - INFO - root - Page:2, Index:7, DAF: An Efficient End-to-End Dynamic Activation Framework for on-Device DNN Training, https://arxiv.org/pdf/2507.07149, 2025-07-09
2025-11-09 20:12:26,828 - INFO - root - Page:2, Index:8, Opto-ViT: Architecting a Near-Sensor Region of Interest-Aware Vision Transformer Accelerator with Silicon Photonics, https://arxiv.org/pdf/2507.07044, 2025-07-15
2025-11-09 20:12:26,832 - INFO - root - Page:2, Index:9, QS4D: Quantization-aware training for efficient hardware deployment of structured state-space sequential models, https://arxiv.org/pdf/2507.06079, 2025-07-08
2025-11-09 20:12:26,836 - INFO - root - Page:2, Index:10, GSVR: 2D Gaussian-based Video Representation for 800+ FPS with Hybrid Deformation Field, https://arxiv.org/pdf/2507.05594, 2025-07-07
2025-11-09 20:12:26,840 - INFO - root - Page:2, Index:11, Hita: Holistic Tokenizer for Autoregressive Image Generation, https://arxiv.org/pdf/2507.02358, 2025-07-11
2025-11-09 20:12:26,845 - INFO - root - Page:2, Index:12, QPART: Adaptive Model Quantization and Dynamic Workload Balancing for Accuracy-aware Edge Inference, https://arxiv.org/pdf/2506.23934, 2025-06-30
2025-11-09 20:12:26,849 - INFO - root - Page:2, Index:13, FedWSQ: Efficient Federated Learning with Weight Standardization and Distribution-Aware Non-Uniform Quantization, https://arxiv.org/pdf/2506.23516, 2025-07-21
2025-11-09 20:12:26,857 - INFO - root - Page:2, Index:14, Spectra 1.1: Scaling Laws and Efficient Inference for Ternary Language Models, https://arxiv.org/pdf/2506.23025, 2025-06-28
2025-11-09 20:12:26,860 - INFO - root - Page:2, Index:15, Joint Quantization and Pruning Neural Networks Approach: A Case Study on FSO Receivers, https://arxiv.org/pdf/2506.20084, 2025-06-24
2025-11-09 20:12:26,866 - INFO - root - Page:2, Index:16, Single-step Diffusion for Image Compression at Ultra-Low Bitrates, https://arxiv.org/pdf/2506.16572, 2025-09-22
2025-11-09 20:12:26,871 - INFO - root - Page:2, Index:17, LittleBit: Ultra Low-Bit Quantization via Latent Factorization, https://arxiv.org/pdf/2506.13771, 2025-10-28
2025-11-09 20:12:26,876 - INFO - root - Page:2, Index:18, MARCO: Hardware-Aware Neural Architecture Search for Edge Devices with Multi-Agent Reinforcement Learning and Conformal Prediction Filtering, https://arxiv.org/pdf/2506.13755, 2025-06-16
2025-11-09 20:12:26,879 - INFO - root - Page:2, Index:19, EAQuant: Enhancing Post-Training Quantization for MoE Models via Expert-Aware Optimization, https://arxiv.org/pdf/2506.13329, 2025-07-04
2025-11-09 20:12:26,885 - INFO - root - Page:2, Index:20, Towards Neural Audio Codec Source Parsing, https://arxiv.org/pdf/2506.12627, 2025-06-14
2025-11-09 20:12:26,886 - INFO - root - Page:2, Index:21, Quantizing Small-Scale State-Space Models for Edge AI, https://arxiv.org/pdf/2506.12480, 2025-06-14
2025-11-09 20:12:26,892 - INFO - root - Page:2, Index:22, EMLoC: Emulator-based Memory-efficient Fine-tuning with LoRA Correction, https://arxiv.org/pdf/2506.12015, 2025-06-13
2025-11-09 20:12:26,898 - INFO - root - Page:2, Index:23, Compression Aware Certified Training, https://arxiv.org/pdf/2506.11992, 2025-06-13
2025-11-09 20:12:26,902 - INFO - root - Page:2, Index:24, GPLQ: A General, Practical, and Lightning QAT Method for Vision Transformers, https://arxiv.org/pdf/2506.11784, 2025-06-13
2025-11-09 20:12:26,907 - INFO - root - Page:2, Index:25, TruncQuant: Truncation-Ready Quantization for DNNs with Flexible Weight Bit Precision, https://arxiv.org/pdf/2506.11431, 2025-06-12
2025-11-09 20:12:26,911 - INFO - root - Page:2, Index:26, EfficientQuant: An Efficient Post-Training Quantization for CNN-Transformer Hybrid Models on Edge Devices, https://arxiv.org/pdf/2506.11093, 2025-06-05
2025-11-09 20:12:26,916 - INFO - root - Page:2, Index:27, Starting Positions Matter: A Study on Better Weight Initialization for Neural Network Quantization, https://arxiv.org/pdf/2506.10463, 2025-06-12
2025-11-09 20:12:26,918 - INFO - root - Page:2, Index:28, AWP: Activation-Aware Weight Pruning and Quantization with Projected Gradient Descent, https://arxiv.org/pdf/2506.10205, 2025-06-11
2025-11-09 20:12:26,924 - INFO - root - Page:2, Index:29, Q-SAM2: Accurate Quantization for Segment Anything Model 2, https://arxiv.org/pdf/2506.09782, 2025-06-11
2025-11-09 20:12:26,926 - INFO - root - Page:2, Index:30, Unifying Block-wise PTQ and Distillation-based QAT for Progressive Quantization toward 2-bit Instruction-Tuned LLMs, https://arxiv.org/pdf/2506.09104, 2025-06-10
2025-11-09 20:12:26,934 - INFO - root - Page:2, Index:31, Implementing Keyword Spotting on the MCUX947 Microcontroller with Integrated NPU, https://arxiv.org/pdf/2506.08911, 2025-06-10
2025-11-09 20:12:26,945 - INFO - root - Page:2, Index:32, POLARON: Precision-aware On-device Learning and Adaptive Runtime-cONfigurable AI acceleration, https://arxiv.org/pdf/2506.08785, 2025-06-10
2025-11-09 20:12:26,987 - INFO - root - Page:2, Index:33, MoQAE: Mixed-Precision Quantization for Long-Context LLM Inference via Mixture of Quantization-Aware Experts, https://arxiv.org/pdf/2506.07533, 2025-06-09
2025-11-09 20:12:27,010 - INFO - root - Page:2, Index:34, BitVLA: 1-bit Vision-Language-Action Models for Robotics Manipulation, https://arxiv.org/pdf/2506.07530, 2025-06-09
2025-11-09 20:12:27,033 - INFO - root - Page:2, Index:35, RecGPT: A Foundation Model for Sequential Recommendation, https://arxiv.org/pdf/2506.06270, 2025-06-12
2025-11-09 20:12:27,045 - INFO - root - Page:2, Index:36, FPSAttention: Training-Aware FP8 and Sparsity Co-Design for Fast Video Diffusion, https://arxiv.org/pdf/2506.04648, 2025-06-05
2025-11-09 20:12:27,052 - INFO - root - Page:2, Index:37, BitTTS: Highly Compact Text-to-Speech Using 1.58-bit Quantization and Weight Indexing, https://arxiv.org/pdf/2506.03515, 2025-06-03
2025-11-09 20:12:27,060 - INFO - root - Page:2, Index:38, ShapeLLM-Omni: A Native Multimodal LLM for 3D Generation and Understanding, https://arxiv.org/pdf/2506.01853, 2025-06-02
2025-11-09 20:12:27,062 - INFO - root - Page:2, Index:39, Movable Antenna Enhanced Federated Fine-Tuning of Large Language Models via Hybrid Client Selection Optimization, https://arxiv.org/pdf/2506.00011, 2025-10-26
2025-11-09 20:12:27,063 - INFO - root - Page:2, Index:40, Running Conventional Automatic Speech Recognition on Memristor Hardware: A Simulated Approach, https://arxiv.org/pdf/2505.24721, 2025-05-30
2025-11-09 20:12:27,063 - INFO - root - Page:2, Index:41, GARLIC: GAussian Representation LearnIng for spaCe partitioning, https://arxiv.org/pdf/2505.24608, 2025-10-02
2025-11-09 20:12:27,064 - INFO - root - Page:2, Index:42, AutoChemSchematic AI: Agentic Physics-Aware Automation for Chemical Manufacturing Scale-Up, https://arxiv.org/pdf/2505.24584, 2025-08-18
2025-11-09 20:12:27,065 - INFO - root - Page:2, Index:43, Model-Preserving Adaptive Rounding, https://arxiv.org/pdf/2505.22988, 2025-09-25
2025-11-09 20:12:27,066 - INFO - root - Page:2, Index:44, Highly Efficient and Effective LLMs with Multi-Boolean Architectures, https://arxiv.org/pdf/2505.22811, 2025-10-03
2025-11-09 20:12:27,066 - INFO - root - Page:2, Index:45, Pioneering 4-Bit FP Quantization for Diffusion Models: Mixup-Sign Quantization and Timestep-Aware Fine-Tuning, https://arxiv.org/pdf/2505.21591, 2025-05-27
2025-11-09 20:12:27,066 - INFO - root - Page:2, Index:46, Frequency Composition for Compressed and Domain-Adaptive Neural Networks, https://arxiv.org/pdf/2505.20890, 2025-05-27
2025-11-09 20:12:27,067 - INFO - root - Page:2, Index:47, MoPFormer: Motion-Primitive Transformer for Wearable-Sensor Activity Recognition, https://arxiv.org/pdf/2505.20744, 2025-10-27
2025-11-09 20:12:27,067 - INFO - root - Page:2, Index:48, Optimizing edge AI models on HPC systems with the edge in the loop, https://arxiv.org/pdf/2505.19995, 2025-05-26
2025-11-09 20:12:27,067 - INFO - root - Fetching page 4 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=150
2025-11-09 20:12:34,212 - INFO - root - get_all_titles_from_web 
2025-11-09 20:12:34,213 - INFO - root - Page:3, Index:0, DPASyn: Mechanism-Aware Drug Synergy Prediction via Dual Attention and Precision-Aware Quantization, https://arxiv.org/pdf/2505.19144, 2025-09-20
2025-11-09 20:12:34,214 - INFO - root - Page:3, Index:1, Reducing Storage of Pretrained Neural Networks by Rate-Constrained Quantization and Entropy Coding, https://arxiv.org/pdf/2505.18758, 2025-05-24
2025-11-09 20:12:34,215 - INFO - root - Page:3, Index:2, Beyond Discreteness: Finite-Sample Analysis of Straight-Through Estimator for Quantization, https://arxiv.org/pdf/2505.18113, 2025-05-23
2025-11-09 20:12:34,215 - INFO - root - Page:3, Index:3, Automating Versatile Time-Series Analysis with Tiny Transformers on Embedded FPGAs, https://arxiv.org/pdf/2505.17662, 2025-09-19
2025-11-09 20:12:34,215 - INFO - root - Page:3, Index:4, FPQVAR: Floating Point Quantization for Visual Autoregressive Model with FPGA Hardware Co-design, https://arxiv.org/pdf/2505.16335, 2025-05-22
2025-11-09 20:12:34,216 - INFO - root - Page:3, Index:5, Saliency-Aware Quantized Imitation Learning for Efficient Robotic Control, https://arxiv.org/pdf/2505.15304, 2025-05-30
2025-11-09 20:12:34,216 - INFO - root - Page:3, Index:6, Scaling Law for Quantization-Aware Training, https://arxiv.org/pdf/2505.14302, 2025-05-20
2025-11-09 20:12:34,216 - INFO - root - Page:3, Index:7, Automatic mixed precision for optimizing gained time with constrained loss mean-squared-error based on model partition to sequential sub-graphs, https://arxiv.org/pdf/2505.13060, 2025-05-19
2025-11-09 20:12:34,216 - INFO - root - Page:3, Index:8, Deep Unfolding with Kernel-based Quantization in MIMO Detection, https://arxiv.org/pdf/2505.12736, 2025-05-19
2025-11-09 20:12:34,217 - INFO - root - Page:3, Index:9, FedHQ: Hybrid Runtime Quantization for Federated Learning, https://arxiv.org/pdf/2505.11982, 2025-05-17
2025-11-09 20:12:34,217 - INFO - root - Page:3, Index:10, QVGen: Pushing the Limit of Quantized Video Generative Models, https://arxiv.org/pdf/2505.11497, 2025-09-27
2025-11-09 20:12:34,218 - INFO - root - Page:3, Index:11, EA-3DGS: Efficient and Adaptive 3D Gaussians with Highly Enhanced Quality for outdoor scenes, https://arxiv.org/pdf/2505.10787, 2025-05-15
2025-11-09 20:12:34,219 - INFO - root - Page:3, Index:12, ITERA-LLM: Boosting Sub-8-Bit Large Language Model Inference via Iterative Tensor Decomposition, https://arxiv.org/pdf/2505.08981, 2025-05-13
2025-11-09 20:12:34,220 - INFO - root - Page:3, Index:13, PROM: Prioritize Reduction of Multiplications Over Lower Bit-Widths for Efficient CNNs, https://arxiv.org/pdf/2505.03254, 2025-08-06
2025-11-09 20:12:34,220 - INFO - root - Page:3, Index:14, ICQuant: Index Coding enables Low-bit LLM Quantization, https://arxiv.org/pdf/2505.00850, 2025-08-24
2025-11-09 20:12:34,222 - INFO - root - Page:3, Index:15, Enhancing Ultra-Low-Bit Quantization of Large Language Models Through Saliency-Aware Partial Retraining, https://arxiv.org/pdf/2504.13932, 2025-07-30
2025-11-09 20:12:34,223 - INFO - root - Page:3, Index:16, Achieving binary weight and activation for LLMs using Post-Training Quantization, https://arxiv.org/pdf/2504.05352, 2025-06-30
2025-11-09 20:12:34,223 - INFO - root - Page:3, Index:17, Wireless Hearables With Programmable Speech AI Accelerators, https://arxiv.org/pdf/2503.18698, 2025-10-21
2025-11-09 20:12:34,224 - INFO - root - Page:3, Index:18, GranQ: Efficient Channel-wise Quantization via Vectorized Pre-Scaling for Zero-Shot QAT, https://arxiv.org/pdf/2503.18339, 2025-10-15
2025-11-09 20:12:34,224 - INFO - root - Page:3, Index:19, CompMarkGS: Robust Watermarking for Compressed 3D Gaussian Splatting, https://arxiv.org/pdf/2503.12836, 2025-09-29
2025-11-09 20:12:34,226 - INFO - root - Page:3, Index:20, AHCPTQ: Accurate and Hardware-Compatible Post-Training Quantization for Segment Anything Model, https://arxiv.org/pdf/2503.03088, 2025-07-11
2025-11-09 20:12:34,226 - INFO - root - Page:3, Index:21, Teaching Metric Distance to Discrete Autoregressive Language Models, https://arxiv.org/pdf/2503.02379, 2025-10-07
2025-11-09 20:12:34,227 - INFO - root - Page:3, Index:22, Regularization-based Framework for Quantization-, Fault- and Variability-Aware Training, https://arxiv.org/pdf/2503.01297, 2025-07-12
2025-11-09 20:12:34,228 - INFO - root - Fetching page 5 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=200
2025-11-09 20:12:40,773 - INFO - root - get_all_titles_from_web 
2025-11-09 20:12:40,773 - INFO - root - Page:4, Index:0, Investigating the Impact of Quantization Methods on the Safety and Reliability of Large Language Models, https://arxiv.org/pdf/2502.15799, 2025-06-29
2025-11-09 20:12:40,774 - INFO - root - Page:4, Index:1, Rotate, Clip, and Partition: Towards W2A4KV4 Quantization by Integrating Rotation and Learnable Non-uniform Quantizer, https://arxiv.org/pdf/2502.15779, 2025-09-01
2025-11-09 20:12:40,774 - INFO - root - Page:4, Index:2, RoSTE: An Efficient Quantization-Aware Supervised Fine-Tuning Approach for Large Language Models, https://arxiv.org/pdf/2502.09003, 2025-06-05
2025-11-09 20:12:40,774 - INFO - root - Page:4, Index:3, Spatial Degradation-Aware and Temporal Consistent Diffusion Model for Compressed Video Super-Resolution, https://arxiv.org/pdf/2502.07381, 2025-06-27
2025-11-09 20:12:40,774 - INFO - root - Page:4, Index:4, QuEST: Stable Training of LLMs with 1-Bit Weights and Activations, https://arxiv.org/pdf/2502.05003, 2025-06-10
2025-11-09 20:12:40,774 - INFO - root - Page:4, Index:5, HALO: Hadamard-Assisted Lower-Precision Optimization for LLMs, https://arxiv.org/pdf/2501.02625, 2025-11-05
2025-11-09 20:12:40,775 - INFO - root - Page:4, Index:6, TAR3D: Creating High-Quality 3D Assets via Next-Part Prediction, https://arxiv.org/pdf/2412.16919, 2025-08-08
2025-11-09 20:12:40,775 - INFO - root - Page:4, Index:7, Training Multi-Layer Binary Neural Networks With Local Binary Error Signals, https://arxiv.org/pdf/2412.00119, 2025-08-05
2025-11-09 20:12:40,775 - INFO - root - Page:4, Index:8, Scaling Large-scale GNN Training to Thousands of Processors on CPU-based Supercomputers, https://arxiv.org/pdf/2411.16025, 2025-05-26
2025-11-09 20:12:40,775 - INFO - root - Page:4, Index:9, HAFLQ: Heterogeneous Adaptive Federated LoRA Fine-tuned LLM with Quantization, https://arxiv.org/pdf/2411.06581, 2025-05-16
2025-11-09 20:12:40,776 - INFO - root - Fetching page 6 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=250
2025-11-09 20:12:47,553 - INFO - root - get_all_titles_from_web 
2025-11-09 20:12:47,553 - INFO - root - Page:5, Index:0, Gradient-Free Training of Quantized Neural Networks, https://arxiv.org/pdf/2410.09734, 2025-09-29
2025-11-09 20:12:47,554 - INFO - root - Page:5, Index:1, QT-DoG: Quantization-aware Training for Domain Generalization, https://arxiv.org/pdf/2410.06020, 2025-06-26
2025-11-09 20:12:47,554 - INFO - root - Page:5, Index:2, Constraint Guided Model Quantization of Neural Networks, https://arxiv.org/pdf/2409.20138, 2025-09-12
2025-11-09 20:12:47,556 - INFO - root - Page:5, Index:3, Accumulator-Aware Post-Training Quantization for Large Language Models, https://arxiv.org/pdf/2409.17092, 2025-07-30
2025-11-09 20:12:47,556 - INFO - root - Page:5, Index:4, DilateQuant: Accurate and Efficient Diffusion Quantization via Weight Dilation, https://arxiv.org/pdf/2409.14307, 2025-07-09
2025-11-09 20:12:47,556 - INFO - root - Page:5, Index:5, Robust Training of Neural Networks at Arbitrary Precision and Sparsity, https://arxiv.org/pdf/2409.09245, 2025-09-23
2025-11-09 20:12:47,557 - INFO - root - Page:5, Index:6, VQ-CTAP: Cross-Modal Fine-Grained Sequence Representation Learning for Speech Processing, https://arxiv.org/pdf/2408.05758, 2025-05-27
2025-11-09 20:12:47,557 - INFO - root - Page:5, Index:7, DopQ-ViT: Towards Distribution-Friendly and Outlier-Aware Post-Training Quantization for Vision Transformers, https://arxiv.org/pdf/2408.03291, 2025-06-19
2025-11-09 20:12:47,558 - INFO - root - Page:5, Index:8, Temporal Feature Matters: A Framework for Diffusion Model Quantization, https://arxiv.org/pdf/2407.19547, 2025-07-11
2025-11-09 20:12:47,560 - INFO - root - Page:5, Index:9, EfficientQAT: Efficient Quantization-Aware Training for Large Language Models, https://arxiv.org/pdf/2407.11062, 2025-05-19
2025-11-09 20:12:47,563 - INFO - root - Page:5, Index:10, Integer-only Quantized Transformers for Embedded FPGA-based Time-series Forecasting in AIoT, https://arxiv.org/pdf/2407.11041, 2025-10-31
2025-11-09 20:12:47,566 - INFO - root - Fetching page 7 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=300
2025-11-09 20:12:54,121 - INFO - root - get_all_titles_from_web 
2025-11-09 20:12:54,122 - INFO - root - Page:6, Index:0, BoA: Attention-aware Post-training Quantization without Backpropagation, https://arxiv.org/pdf/2406.13474, 2025-06-06
2025-11-09 20:12:54,123 - INFO - root - Page:6, Index:1, A Rescaling-Invariant Lipschitz Bound Based on Path-Metrics for Modern ReLU Network Parameterizations, https://arxiv.org/pdf/2405.15006, 2025-06-13
2025-11-09 20:12:54,123 - INFO - root - Page:6, Index:2, Scheduling Weight Transitions for Quantization-Aware Training, https://arxiv.org/pdf/2404.19248, 2025-10-01
2025-11-09 20:12:54,123 - INFO - root - Page:6, Index:3, GPTVQ: The Blessing of Dimensionality for LLM Quantization, https://arxiv.org/pdf/2402.15319, 2025-06-03
2025-11-09 20:12:54,123 - INFO - root - Fetching page 8 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=350
2025-11-09 20:13:00,649 - INFO - root - get_all_titles_from_web 
2025-11-09 20:13:00,649 - INFO - root - Page:7, Index:0, Squat: Quant Small Language Models on the Edge, https://arxiv.org/pdf/2402.10787, 2025-07-01
2025-11-09 20:13:00,649 - INFO - root - Page:7, Index:1, L4Q: Parameter Efficient Quantization-Aware Fine-Tuning on Large Language Models, https://arxiv.org/pdf/2402.04902, 2025-07-21
2025-11-09 20:13:00,650 - INFO - root - Fetching page 9 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=400
2025-11-09 20:13:07,499 - INFO - root - ------------------------------------------------------------------------------------------------------------------------
2025-11-09 20:13:21,213 - INFO - root - 跳过已处理论文 A Quantized VAE-MLP Botnet Detection Model: A Systematic Evaluation of Quantization-Aware Training and Post-Training Quantization Strategies：D:\ChatPaper\academic Papers\Quantization-Aware-Training\A Quantized VAE-MLP Botnet Detection Model_ A Systematic Evaluation of Quantizat-4.pdf
2025-11-09 20:13:21,214 - INFO - root - 跳过已处理论文 FP8-Flow-MoE: A Casting-Free FP8 Recipe without Double Quantization Error：D:\ChatPaper\academic Papers\Quantization-Aware-Training\FP8-Flow-MoE_ A Casting-Free FP8 Recipe without Double Quantization Error-4.pdf
2025-11-09 20:13:21,215 - INFO - root - summary time: 80.50 seconds
2025-11-09 20:14:13,113 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-09 20:14:13,114 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-09 20:14:13,116 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-09 20:14:14,181 - INFO - root - LLMClientManager: 指定使用客户端: Gemini
2025-11-09 20:14:15,286 - INFO - root - GeminiClient: trying model gemini-2.5-flash
2025-11-09 20:14:18,313 - INFO - root - GeminiClient: initialized model gemini-2.5-flash
2025-11-09 20:14:18,313 - INFO - root - LLMClientManager: Gemini 客户端初始化成功
2025-11-09 20:14:18,314 - INFO - root - LLMClientManager: switched to Gemini client
2025-11-09 20:14:18,315 - INFO - root - 已手动切换到 LLM 客户端: Gemini
2025-11-09 20:14:18,315 - INFO - root - 使用 LLM 模型: gemini-2.5-flash
2025-11-09 20:14:18,315 - INFO - root - 可用客户端: ['Gemini']
2025-11-09 20:14:18,316 - INFO - root - === 运行配置 ===
2025-11-09 20:14:18,317 - INFO - root - 处理模式: arxiv在线搜索
2025-11-09 20:14:18,317 - INFO - root - 关键词: QAT
2025-11-09 20:14:18,318 - INFO - root - 查询: Quantization-Aware-Training
2025-11-09 20:14:18,318 - INFO - root - 排序: None
2025-11-09 20:14:18,319 - INFO - root - 最近天数: 180
2025-11-09 20:14:18,320 - INFO - root - 最大处理数量: 2
2025-11-09 20:14:18,320 - INFO - root - 保存图片: 是
2025-11-09 20:14:18,321 - INFO - root - 输出语言: 中文
2025-11-09 20:14:18,321 - INFO - root - 强制重新处理: 否
2025-11-09 20:14:18,321 - INFO - root - ====================
2025-11-09 20:14:18,321 - INFO - root - 使用 arXiv 搜索模式（通过 chat_arxiv 模块获取）
2025-11-09 20:14:18,321 - INFO - root - Fetching page 1 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50
2025-11-09 20:14:25,132 - INFO - root - get_all_titles_from_web 
2025-11-09 20:14:25,133 - INFO - root - Page:0, Index:0, A Quantized VAE-MLP Botnet Detection Model: A Systematic Evaluation of Quantization-Aware Training and Post-Training Quantization Strategies, https://arxiv.org/pdf/2511.03201, 2025-11-05
2025-11-09 20:14:25,133 - INFO - root - Page:0, Index:1, FP8-Flow-MoE: A Casting-Free FP8 Recipe without Double Quantization Error, https://arxiv.org/pdf/2511.02302, 2025-11-04
2025-11-09 20:14:25,133 - INFO - root - Page:0, Index:2, Outlier-Aware Post-Training Quantization for Image Super-Resolution, https://arxiv.org/pdf/2511.00682, 2025-11-01
2025-11-09 20:14:25,133 - INFO - root - Page:0, Index:3, Evaluation of Wafer-Scale SOT-MRAM for Analog Crossbar Array Applications, https://arxiv.org/pdf/2510.25853, 2025-11-03
2025-11-09 20:14:25,134 - INFO - root - Page:0, Index:4, Improving the Straight-Through Estimator with Zeroth-Order Information, https://arxiv.org/pdf/2510.23926, 2025-10-27
2025-11-09 20:14:25,134 - INFO - root - Page:0, Index:5, Real-Time Semantic Segmentation on FPGA for Autonomous Vehicles Using LMIINet with the CGRA4ML Framework, https://arxiv.org/pdf/2510.22243, 2025-10-25
2025-11-09 20:14:25,134 - INFO - root - Page:0, Index:6, TernaryCLIP: Efficiently Compressing Vision-Language Models with Ternary Weights and Distilled Knowledge, https://arxiv.org/pdf/2510.21879, 2025-10-23
2025-11-09 20:14:25,134 - INFO - root - Page:0, Index:7, KARIPAP: Quantum-Inspired Tensor Network Compression of Large Language Models Using Infinite Projected Entangled Pair States and Tensor Renormalization Group, https://arxiv.org/pdf/2510.21844, 2025-10-22
2025-11-09 20:14:25,136 - INFO - root - Page:0, Index:8, A Convergence Analysis of Adaptive Optimizers under Floating-point Quantization, https://arxiv.org/pdf/2510.21314, 2025-10-24
2025-11-09 20:14:25,136 - INFO - root - Page:0, Index:9, Adaptive Distribution-aware Quantization for Mixed-Precision Neural Networks, https://arxiv.org/pdf/2510.19760, 2025-10-22
2025-11-09 20:14:25,136 - INFO - root - Page:0, Index:10, CAGE: Curvature-Aware Gradient Estimation For Accurate Quantization-Aware Training, https://arxiv.org/pdf/2510.18784, 2025-10-21
2025-11-09 20:14:25,136 - INFO - root - Page:0, Index:11, Mixed-Precision Quantization for Language Models: Techniques and Prospects, https://arxiv.org/pdf/2510.16805, 2025-10-19
2025-11-09 20:14:25,136 - INFO - root - Page:0, Index:12, SPLite Hand: Sparsity-Aware Lightweight 3D Hand Pose Estimation, https://arxiv.org/pdf/2510.16396, 2025-10-30
2025-11-09 20:14:25,136 - INFO - root - Page:0, Index:13, CTR-LoRA: Curvature-Aware and Trust-Region Guided Low-Rank Adaptation for Large Language Models, https://arxiv.org/pdf/2510.15962, 2025-10-11
2025-11-09 20:14:25,136 - INFO - root - Page:0, Index:14, SANR: Scene-Aware Neural Representation for Light Field Image Compression with Rate-Distortion Optimization, https://arxiv.org/pdf/2510.15775, 2025-10-17
2025-11-09 20:14:25,138 - INFO - root - Page:0, Index:15, SpikeFit: Towards Optimal Deployment of Spiking Networks on Neuromorphic Hardware, https://arxiv.org/pdf/2510.15542, 2025-10-31
2025-11-09 20:14:25,138 - INFO - root - Page:0, Index:16, GRank: Towards Target-Aware and Streamlined Industrial Retrieval with a Generate-Rank Framework, https://arxiv.org/pdf/2510.15299, 2025-10-17
2025-11-09 20:14:25,142 - INFO - root - Page:0, Index:17, SaLon3R: Structure-aware Long-term Generalizable 3D Reconstruction from Unposed Images, https://arxiv.org/pdf/2510.15072, 2025-10-16
2025-11-09 20:14:25,144 - INFO - root - Page:0, Index:18, FraQAT: Quantization Aware Training with Fractional bits, https://arxiv.org/pdf/2510.14823, 2025-10-16
2025-11-09 20:14:25,144 - INFO - root - Page:0, Index:19, Computing-In-Memory Aware Model Adaption For Edge Devices, https://arxiv.org/pdf/2510.14379, 2025-10-16
2025-11-09 20:14:25,144 - INFO - root - Page:0, Index:20, Invited Paper: BitMedViT: Ternary-Quantized Vision Transformer for Medical AI Assistants on the Edge, https://arxiv.org/pdf/2510.13760, 2025-11-04
2025-11-09 20:14:25,145 - INFO - root - Page:0, Index:21, NeuroRVQ: Multi-Scale EEG Tokenization for Generative Large Brainwave Models, https://arxiv.org/pdf/2510.13068, 2025-10-14
2025-11-09 20:14:25,145 - INFO - root - Page:0, Index:22, Detect Anything via Next Point Prediction, https://arxiv.org/pdf/2510.12798, 2025-10-14
2025-11-09 20:14:25,146 - INFO - root - Page:0, Index:23, AndesVL Technical Report: An Efficient Mobile-side Multimodal Large Language Model, https://arxiv.org/pdf/2510.11496, 2025-10-14
2025-11-09 20:14:25,146 - INFO - root - Page:0, Index:24, Rescaling-Aware Training for Efficient Deployment of Deep Learning Models on Full-Integer Hardware, https://arxiv.org/pdf/2510.11484, 2025-10-13
2025-11-09 20:14:25,146 - INFO - root - Page:0, Index:25, SASER: Stego attacks on open-source LLMs, https://arxiv.org/pdf/2510.10486, 2025-10-12
2025-11-09 20:14:25,146 - INFO - root - Page:0, Index:26, Ultralytics YOLO Evolution: An Overview of YOLO26, YOLO11, YOLOv8 and YOLOv5 Object Detectors for Computer Vision and Pattern Recognition, https://arxiv.org/pdf/2510.09653, 2025-10-15
2025-11-09 20:14:25,147 - INFO - root - Page:0, Index:27, A Theoretically-Grounded Codebook for Digital Semantic Communications, https://arxiv.org/pdf/2510.07108, 2025-10-14
2025-11-09 20:14:25,147 - INFO - root - Page:0, Index:28, QuantDemoire: Quantization with Outlier Aware for Image Demoiréing, https://arxiv.org/pdf/2510.04066, 2025-10-05
2025-11-09 20:14:25,147 - INFO - root - Page:0, Index:29, Adaptively Sampling-Reusing-Mixing Decomposed Gradients to Speed Up Sharpness Aware Minimization, https://arxiv.org/pdf/2510.03763, 2025-10-04
2025-11-09 20:14:25,148 - INFO - root - Page:0, Index:30, Quant-dLLM: Post-Training Extreme Low-Bit Quantization for Diffusion Large Language Models, https://arxiv.org/pdf/2510.03274, 2025-09-27
2025-11-09 20:14:25,148 - INFO - root - Page:0, Index:31, PT$^2$-LLM: Post-Training Ternarization for Large Language Models, https://arxiv.org/pdf/2510.03267, 2025-09-26
2025-11-09 20:14:25,148 - INFO - root - Page:0, Index:32, Purrception: Variational Flow Matching for Vector-Quantized Image Generation, https://arxiv.org/pdf/2510.01478, 2025-10-01
2025-11-09 20:14:25,148 - INFO - root - Page:0, Index:33, Post-Training Quantization for Audio Diffusion Transformers, https://arxiv.org/pdf/2510.00313, 2025-09-30
2025-11-09 20:14:25,148 - INFO - root - Page:0, Index:34, Rethinking RoPE Scaling in Quantized LLM: Theory, Outlier, and Channel-Band Analysis with Weight Rescaling, https://arxiv.org/pdf/2510.00028, 2025-09-25
2025-11-09 20:14:25,148 - INFO - root - Page:0, Index:35, Post-Training Quantization via Residual Truncation and Zero Suppression for Diffusion Models, https://arxiv.org/pdf/2509.26436, 2025-09-30
2025-11-09 20:14:25,149 - INFO - root - Page:0, Index:36, Cat: Post-Training Quantization Error Reduction via Cluster-based Affine Transformation, https://arxiv.org/pdf/2509.26277, 2025-10-07
2025-11-09 20:14:25,149 - INFO - root - Page:0, Index:37, CAST: Continuous and Differentiable Semi-Structured Sparsity-Aware Training for Large Language Models, https://arxiv.org/pdf/2509.25996, 2025-09-30
2025-11-09 20:14:25,149 - INFO - root - Page:0, Index:38, Norm-Q: Effective Compression Method for Hidden Markov Models in Neuro-Symbolic Applications, https://arxiv.org/pdf/2509.25439, 2025-09-29
2025-11-09 20:14:25,149 - INFO - root - Page:0, Index:39, On-the-Fly Adaptation to Quantization: Configuration-Aware LoRA for Efficient Fine-Tuning of Quantized LLMs, https://arxiv.org/pdf/2509.25214, 2025-09-22
2025-11-09 20:14:25,149 - INFO - root - Page:0, Index:40, VoxCPM: Tokenizer-Free TTS for Context-Aware Speech Generation and True-to-Life Voice Cloning, https://arxiv.org/pdf/2509.24650, 2025-09-29
2025-11-09 20:14:25,150 - INFO - root - Page:0, Index:41, S$^2$NN: Sub-bit Spiking Neural Networks, https://arxiv.org/pdf/2509.24266, 2025-10-24
2025-11-09 20:14:25,150 - INFO - root - Page:0, Index:42, Tequila: Trapping-free Ternary Quantization for Large Language Models, https://arxiv.org/pdf/2509.23809, 2025-10-17
2025-11-09 20:14:25,150 - INFO - root - Page:0, Index:43, Texture Vector-Quantization and Reconstruction Aware Prediction for Generative Super-Resolution, https://arxiv.org/pdf/2509.23774, 2025-09-30
2025-11-09 20:14:25,150 - INFO - root - Page:0, Index:44, RobuQ: Pushing DiTs to W1.58A2 via Robust Activation Quantization, https://arxiv.org/pdf/2509.23582, 2025-09-27
2025-11-09 20:14:25,150 - INFO - root - Page:0, Index:45, Beyond Outliers: A Study of Optimizers Under Quantization, https://arxiv.org/pdf/2509.23500, 2025-10-02
2025-11-09 20:14:25,150 - INFO - root - Page:0, Index:46, Compute-Optimal Quantization-Aware Training, https://arxiv.org/pdf/2509.22935, 2025-09-26
2025-11-09 20:14:25,151 - INFO - root - Page:0, Index:47, COSPADI: Compressing LLMs via Calibration-Guided Sparse Dictionary Learning, https://arxiv.org/pdf/2509.22075, 2025-10-06
2025-11-09 20:14:25,151 - INFO - root - Page:0, Index:48, SlimDiff: Training-Free, Activation-Guided Hands-free Slimming of Diffusion Models, https://arxiv.org/pdf/2509.21498, 2025-09-25
2025-11-09 20:14:25,151 - INFO - root - Page:0, Index:49, Quantized Visual Geometry Grounded Transformer, https://arxiv.org/pdf/2509.21302, 2025-09-29
2025-11-09 20:14:25,151 - INFO - root - Fetching page 2 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=50
2025-11-09 20:14:31,601 - INFO - root - get_all_titles_from_web 
2025-11-09 20:14:31,601 - INFO - root - Page:1, Index:0, Can Less Precise Be More Reliable? A Systematic Evaluation of Quantization's Impact on CLIP Beyond Accuracy, https://arxiv.org/pdf/2509.21173, 2025-10-27
2025-11-09 20:14:31,601 - INFO - root - Page:1, Index:1, Punching Above Precision: Small Quantized Model Distillation with Learnable Regularizer, https://arxiv.org/pdf/2509.20854, 2025-09-25
2025-11-09 20:14:31,603 - INFO - root - Page:1, Index:2, TinyEcoWeedNet: Edge Efficient Real-Time Aerial Agricultural Weed Detection, https://arxiv.org/pdf/2509.18193, 2025-09-19
2025-11-09 20:14:31,603 - INFO - root - Page:1, Index:3, SBVR: Summation of BitVector Representation for Efficient LLM Quantization, https://arxiv.org/pdf/2509.18172, 2025-09-17
2025-11-09 20:14:31,603 - INFO - root - Page:1, Index:4, QWHA: Quantization-Aware Walsh-Hadamard Adaptation for Parameter-Efficient Fine-Tuning on Large Language Models, https://arxiv.org/pdf/2509.17428, 2025-09-26
2025-11-09 20:14:31,603 - INFO - root - Page:1, Index:5, PTQTP: Post-Training Quantization to Trit-Planes for Large Language Models, https://arxiv.org/pdf/2509.16989, 2025-10-28
2025-11-09 20:14:31,604 - INFO - root - Page:1, Index:6, MEC-Quant: Maximum Entropy Coding for Extremely Low Bit Quantization-Aware Training, https://arxiv.org/pdf/2509.15514, 2025-09-18
2025-11-09 20:14:31,604 - INFO - root - Page:1, Index:7, Q-ROAR: Outlier-Aware Rescaling for RoPE Position Interpolation in Quantized Long-Context LLMs, https://arxiv.org/pdf/2509.14391, 2025-09-17
2025-11-09 20:14:31,604 - INFO - root - Page:1, Index:8, Efficient Quantization-Aware Neural Receivers: Beyond Post-Training Quantization, https://arxiv.org/pdf/2509.13786, 2025-09-19
2025-11-09 20:14:31,605 - INFO - root - Page:1, Index:9, Rate-Distortion Limits for Multimodal Retrieval: Theory, Optimal Codes, and Finite-Sample Guarantees, https://arxiv.org/pdf/2509.11054, 2025-09-13
2025-11-09 20:14:31,605 - INFO - root - Page:1, Index:10, SQAP-VLA: A Synergistic Quantization-Aware Pruning Framework for High-Performance Vision-Language-Action Models, https://arxiv.org/pdf/2509.09090, 2025-09-10
2025-11-09 20:14:31,605 - INFO - root - Page:1, Index:11, CSI Compression Beyond Latents: End-to-End Hybrid Attention-CNN Networks with Entropy Regularization, https://arxiv.org/pdf/2509.08776, 2025-09-10
2025-11-09 20:14:31,606 - INFO - root - Page:1, Index:12, Explaining How Quantization Disparately Skews a Model, https://arxiv.org/pdf/2509.07222, 2025-09-08
2025-11-09 20:14:31,606 - INFO - root - Page:1, Index:13, LoaQ: Layer-wise Output Approximation Quantization, https://arxiv.org/pdf/2509.06297, 2025-09-07
2025-11-09 20:14:31,606 - INFO - root - Page:1, Index:14, FineServe: Precision-Aware KV Slab and Two-Level Scheduling for Heterogeneous Precision LLM Serving, https://arxiv.org/pdf/2509.06261, 2025-09-14
2025-11-09 20:14:31,606 - INFO - root - Page:1, Index:15, Sensitivity-Aware Post-Training Quantization for Deep Neural Networks, https://arxiv.org/pdf/2509.05576, 2025-09-05
2025-11-09 20:14:31,607 - INFO - root - Page:1, Index:16, SuperSNN: A Hardware-Aware Framework for Physically Realizable, High-Performance Superconducting Spiking Neural Network Chips, https://arxiv.org/pdf/2509.05532, 2025-09-05
2025-11-09 20:14:31,607 - INFO - root - Page:1, Index:17, Data-Augmented Quantization-Aware Knowledge Distillation, https://arxiv.org/pdf/2509.03850, 2025-09-03
2025-11-09 20:14:31,608 - INFO - root - Page:1, Index:18, DPQuant: Efficient and Differentially-Private Model Training via Dynamic Quantization Scheduling, https://arxiv.org/pdf/2509.03472, 2025-09-03
2025-11-09 20:14:31,608 - INFO - root - Page:1, Index:19, Empowering Large Language Model for Sequential Recommendation via Multimodal Embeddings and Semantic IDs, https://arxiv.org/pdf/2509.02017, 2025-09-02
2025-11-09 20:14:31,608 - INFO - root - Page:1, Index:20, Q-Sched: Pushing the Boundaries of Few-Step Diffusion Models with Quantization-Aware Scheduling, https://arxiv.org/pdf/2509.01624, 2025-09-01
2025-11-09 20:14:31,608 - INFO - root - Page:1, Index:21, Quantization Meets OOD: Generalizable Quantization-aware Training from a Flatness Perspective, https://arxiv.org/pdf/2509.00859, 2025-08-31
2025-11-09 20:14:31,609 - INFO - root - Page:1, Index:22, Progressive Element-wise Gradient Estimation for Neural Network Quantization, https://arxiv.org/pdf/2509.00097, 2025-08-27
2025-11-09 20:14:31,609 - INFO - root - Page:1, Index:23, End-to-End On-Device Quantization-Aware Training for LLMs at Inference Cost, https://arxiv.org/pdf/2509.00031, 2025-09-29
2025-11-09 20:14:31,609 - INFO - root - Page:1, Index:24, Quantization Robustness to Input Degradations for Object Detection, https://arxiv.org/pdf/2508.19600, 2025-08-27
2025-11-09 20:14:31,610 - INFO - root - Page:1, Index:25, Scaling Laws for Task-Stratified Knowledge in Post-Training Quantized Large Language Models, https://arxiv.org/pdf/2508.18609, 2025-08-27
2025-11-09 20:14:31,610 - INFO - root - Page:1, Index:26, AQ-PCDSys: An Adaptive Quantized Planetary Crater Detection System for Autonomous Space Exploration, https://arxiv.org/pdf/2508.18025, 2025-08-25
2025-11-09 20:14:31,610 - INFO - root - Page:1, Index:27, TaDiCodec: Text-aware Diffusion Speech Tokenizer for Speech Language Modeling, https://arxiv.org/pdf/2508.16790, 2025-08-22
2025-11-09 20:14:31,611 - INFO - root - Page:1, Index:28, A Node-Aware Dynamic Quantization Approach for Graph Collaborative Filtering, https://arxiv.org/pdf/2508.16516, 2025-08-22
2025-11-09 20:14:31,611 - INFO - root - Page:1, Index:29, JEDI-linear: Fast and Efficient Graph Neural Networks for Jet Tagging on FPGAs, https://arxiv.org/pdf/2508.15468, 2025-08-21
2025-11-09 20:14:31,611 - INFO - root - Page:1, Index:30, MMQ: Multimodal Mixture-of-Quantization Tokenization for Semantic ID Generation and User Behavioral Adaptation, https://arxiv.org/pdf/2508.15281, 2025-08-21
2025-11-09 20:14:31,611 - INFO - root - Page:1, Index:31, DLLMQuant: Quantizing Diffusion-based Large Language Models, https://arxiv.org/pdf/2508.14090, 2025-08-25
2025-11-09 20:14:31,613 - INFO - root - Page:1, Index:32, Automated Energy-Aware Time-Series Model Deployment on Embedded FPGAs for Resilient Combined Sewer Overflow Management, https://arxiv.org/pdf/2508.13905, 2025-08-19
2025-11-09 20:14:31,614 - INFO - root - Page:1, Index:33, XR-NPE: High-Throughput Mixed-precision SIMD Neural Processing Engine for Extended Reality Perception Workloads, https://arxiv.org/pdf/2508.13049, 2025-08-18
2025-11-09 20:14:31,616 - INFO - root - Page:1, Index:34, Exploring Self-Supervised Audio Models for Generalized Anomalous Sound Detection, https://arxiv.org/pdf/2508.12230, 2025-08-17
2025-11-09 20:14:31,618 - INFO - root - Page:1, Index:35, TriQDef: Disrupting Semantic and Gradient Alignment to Prevent Adversarial Patch Transferability in Quantized Neural Networks, https://arxiv.org/pdf/2508.12132, 2025-08-16
2025-11-09 20:14:31,620 - INFO - root - Page:1, Index:36, Error Propagation Mechanisms and Compensation Strategies for Quantized Diffusion, https://arxiv.org/pdf/2508.12094, 2025-10-13
2025-11-09 20:14:31,620 - INFO - root - Page:1, Index:37, Extending Straight-Through Estimation for Robust Neural Networks on Analog CIM Hardware, https://arxiv.org/pdf/2508.11940, 2025-08-16
2025-11-09 20:14:31,620 - INFO - root - Page:1, Index:38, PTQAT: A Hybrid Parameter-Efficient Quantization Algorithm for 3D Perception Tasks, https://arxiv.org/pdf/2508.10557, 2025-08-15
2025-11-09 20:14:31,620 - INFO - root - Page:1, Index:39, MiCo: End-to-End Mixed Precision Neural Network Co-Exploration Framework for Edge AI, https://arxiv.org/pdf/2508.09500, 2025-08-13
2025-11-09 20:14:31,622 - INFO - root - Page:1, Index:40, SPARC: Soft Probabilistic Adaptive multi-interest Retrieval Model via Codebooks for recommender system, https://arxiv.org/pdf/2508.09090, 2025-08-12
2025-11-09 20:14:31,622 - INFO - root - Page:1, Index:41, Rethinking 1-bit Optimization Leveraging Pre-trained Large Language Models, https://arxiv.org/pdf/2508.06974, 2025-08-09
2025-11-09 20:14:31,622 - INFO - root - Page:1, Index:42, Efficient Deep Neural Receiver with Post-Training Quantization, https://arxiv.org/pdf/2508.06275, 2025-08-08
2025-11-09 20:14:31,623 - INFO - root - Page:1, Index:43, iFairy: the First 2-bit Complex LLM with All Parameters in $\{\pm1, \pm i\}$, https://arxiv.org/pdf/2508.05571, 2025-08-16
2025-11-09 20:14:31,623 - INFO - root - Page:1, Index:44, S$^2$Q-VDiT: Accurate Quantized Video Diffusion Transformer with Salient Data and Sparse Token Distillation, https://arxiv.org/pdf/2508.04016, 2025-10-27
2025-11-09 20:14:31,623 - INFO - root - Page:1, Index:45, LRQ-DiT: Log-Rotation Post-Training Quantization of Diffusion Transformers for Image and Video Generation, https://arxiv.org/pdf/2508.03485, 2025-09-23
2025-11-09 20:14:31,624 - INFO - root - Page:1, Index:46, VLMQ: Efficient Post-Training Quantization for Large Vision-Language Models via Hessian Augmentation, https://arxiv.org/pdf/2508.03351, 2025-08-05
2025-11-09 20:14:31,624 - INFO - root - Page:1, Index:47, TF-MLPNet: Tiny Real-Time Neural Speech Separation, https://arxiv.org/pdf/2508.03047, 2025-08-04
2025-11-09 20:14:31,624 - INFO - root - Page:1, Index:48, SaviorRec: Semantic-Behavior Alignment for Cold-Start Recommendation, https://arxiv.org/pdf/2508.01375, 2025-08-02
2025-11-09 20:14:31,624 - INFO - root - Page:1, Index:49, MixA-Q: Revisiting Activation Sparsity for Vision Transformers from a Mixed-Precision Quantization Perspective, https://arxiv.org/pdf/2507.19131, 2025-07-25
2025-11-09 20:14:31,625 - INFO - root - Fetching page 3 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=100
2025-11-09 20:14:38,390 - INFO - root - get_all_titles_from_web 
2025-11-09 20:14:38,390 - INFO - root - Page:2, Index:0, Enhancing Quantization-Aware Training on Edge Devices via Relative Entropy Coreset Selection and Cascaded Layer Correction, https://arxiv.org/pdf/2507.17768, 2025-07-16
2025-11-09 20:14:38,390 - INFO - root - Page:2, Index:1, SiLQ: Simple Large Language Model Quantization-Aware Training, https://arxiv.org/pdf/2507.16933, 2025-07-22
2025-11-09 20:14:38,390 - INFO - root - Page:2, Index:2, Task-Specific Zero-shot Quantization-Aware Training for Object Detection, https://arxiv.org/pdf/2507.16782, 2025-07-22
2025-11-09 20:14:38,391 - INFO - root - Page:2, Index:3, TorchAO: PyTorch-Native Training-to-Serving Model Optimization, https://arxiv.org/pdf/2507.16099, 2025-07-21
2025-11-09 20:14:38,391 - INFO - root - Page:2, Index:4, SegQuant: A Semantics-Aware and Generalizable Quantization Framework for Diffusion Models, https://arxiv.org/pdf/2507.14811, 2025-08-27
2025-11-09 20:14:38,391 - INFO - root - Page:2, Index:5, Apple Intelligence Foundation Language Models: Tech Report 2025, https://arxiv.org/pdf/2507.13575, 2025-08-27
2025-11-09 20:14:38,391 - INFO - root - Page:2, Index:6, Generative Multi-Target Cross-Domain Recommendation, https://arxiv.org/pdf/2507.12871, 2025-08-07
2025-11-09 20:14:38,391 - INFO - root - Page:2, Index:7, DAF: An Efficient End-to-End Dynamic Activation Framework for on-Device DNN Training, https://arxiv.org/pdf/2507.07149, 2025-07-09
2025-11-09 20:14:38,391 - INFO - root - Page:2, Index:8, Opto-ViT: Architecting a Near-Sensor Region of Interest-Aware Vision Transformer Accelerator with Silicon Photonics, https://arxiv.org/pdf/2507.07044, 2025-07-15
2025-11-09 20:14:38,392 - INFO - root - Page:2, Index:9, QS4D: Quantization-aware training for efficient hardware deployment of structured state-space sequential models, https://arxiv.org/pdf/2507.06079, 2025-07-08
2025-11-09 20:14:38,392 - INFO - root - Page:2, Index:10, GSVR: 2D Gaussian-based Video Representation for 800+ FPS with Hybrid Deformation Field, https://arxiv.org/pdf/2507.05594, 2025-07-07
2025-11-09 20:14:38,392 - INFO - root - Page:2, Index:11, Hita: Holistic Tokenizer for Autoregressive Image Generation, https://arxiv.org/pdf/2507.02358, 2025-07-11
2025-11-09 20:14:38,392 - INFO - root - Page:2, Index:12, QPART: Adaptive Model Quantization and Dynamic Workload Balancing for Accuracy-aware Edge Inference, https://arxiv.org/pdf/2506.23934, 2025-06-30
2025-11-09 20:14:38,392 - INFO - root - Page:2, Index:13, FedWSQ: Efficient Federated Learning with Weight Standardization and Distribution-Aware Non-Uniform Quantization, https://arxiv.org/pdf/2506.23516, 2025-07-21
2025-11-09 20:14:38,393 - INFO - root - Page:2, Index:14, Spectra 1.1: Scaling Laws and Efficient Inference for Ternary Language Models, https://arxiv.org/pdf/2506.23025, 2025-06-28
2025-11-09 20:14:38,393 - INFO - root - Page:2, Index:15, Joint Quantization and Pruning Neural Networks Approach: A Case Study on FSO Receivers, https://arxiv.org/pdf/2506.20084, 2025-06-24
2025-11-09 20:14:38,393 - INFO - root - Page:2, Index:16, Single-step Diffusion for Image Compression at Ultra-Low Bitrates, https://arxiv.org/pdf/2506.16572, 2025-09-22
2025-11-09 20:14:38,394 - INFO - root - Page:2, Index:17, LittleBit: Ultra Low-Bit Quantization via Latent Factorization, https://arxiv.org/pdf/2506.13771, 2025-10-28
2025-11-09 20:14:38,394 - INFO - root - Page:2, Index:18, MARCO: Hardware-Aware Neural Architecture Search for Edge Devices with Multi-Agent Reinforcement Learning and Conformal Prediction Filtering, https://arxiv.org/pdf/2506.13755, 2025-06-16
2025-11-09 20:14:38,395 - INFO - root - Page:2, Index:19, EAQuant: Enhancing Post-Training Quantization for MoE Models via Expert-Aware Optimization, https://arxiv.org/pdf/2506.13329, 2025-07-04
2025-11-09 20:14:38,395 - INFO - root - Page:2, Index:20, Towards Neural Audio Codec Source Parsing, https://arxiv.org/pdf/2506.12627, 2025-06-14
2025-11-09 20:14:38,396 - INFO - root - Page:2, Index:21, Quantizing Small-Scale State-Space Models for Edge AI, https://arxiv.org/pdf/2506.12480, 2025-06-14
2025-11-09 20:14:38,396 - INFO - root - Page:2, Index:22, EMLoC: Emulator-based Memory-efficient Fine-tuning with LoRA Correction, https://arxiv.org/pdf/2506.12015, 2025-06-13
2025-11-09 20:14:38,397 - INFO - root - Page:2, Index:23, Compression Aware Certified Training, https://arxiv.org/pdf/2506.11992, 2025-06-13
2025-11-09 20:14:38,397 - INFO - root - Page:2, Index:24, GPLQ: A General, Practical, and Lightning QAT Method for Vision Transformers, https://arxiv.org/pdf/2506.11784, 2025-06-13
2025-11-09 20:14:38,397 - INFO - root - Page:2, Index:25, TruncQuant: Truncation-Ready Quantization for DNNs with Flexible Weight Bit Precision, https://arxiv.org/pdf/2506.11431, 2025-06-12
2025-11-09 20:14:38,398 - INFO - root - Page:2, Index:26, EfficientQuant: An Efficient Post-Training Quantization for CNN-Transformer Hybrid Models on Edge Devices, https://arxiv.org/pdf/2506.11093, 2025-06-05
2025-11-09 20:14:38,399 - INFO - root - Page:2, Index:27, Starting Positions Matter: A Study on Better Weight Initialization for Neural Network Quantization, https://arxiv.org/pdf/2506.10463, 2025-06-12
2025-11-09 20:14:38,402 - INFO - root - Page:2, Index:28, AWP: Activation-Aware Weight Pruning and Quantization with Projected Gradient Descent, https://arxiv.org/pdf/2506.10205, 2025-06-11
2025-11-09 20:14:38,403 - INFO - root - Page:2, Index:29, Q-SAM2: Accurate Quantization for Segment Anything Model 2, https://arxiv.org/pdf/2506.09782, 2025-06-11
2025-11-09 20:14:38,405 - INFO - root - Page:2, Index:30, Unifying Block-wise PTQ and Distillation-based QAT for Progressive Quantization toward 2-bit Instruction-Tuned LLMs, https://arxiv.org/pdf/2506.09104, 2025-06-10
2025-11-09 20:14:38,406 - INFO - root - Page:2, Index:31, Implementing Keyword Spotting on the MCUX947 Microcontroller with Integrated NPU, https://arxiv.org/pdf/2506.08911, 2025-06-10
2025-11-09 20:14:38,406 - INFO - root - Page:2, Index:32, POLARON: Precision-aware On-device Learning and Adaptive Runtime-cONfigurable AI acceleration, https://arxiv.org/pdf/2506.08785, 2025-06-10
2025-11-09 20:14:38,407 - INFO - root - Page:2, Index:33, MoQAE: Mixed-Precision Quantization for Long-Context LLM Inference via Mixture of Quantization-Aware Experts, https://arxiv.org/pdf/2506.07533, 2025-06-09
2025-11-09 20:14:38,407 - INFO - root - Page:2, Index:34, BitVLA: 1-bit Vision-Language-Action Models for Robotics Manipulation, https://arxiv.org/pdf/2506.07530, 2025-06-09
2025-11-09 20:14:38,407 - INFO - root - Page:2, Index:35, RecGPT: A Foundation Model for Sequential Recommendation, https://arxiv.org/pdf/2506.06270, 2025-06-12
2025-11-09 20:14:38,408 - INFO - root - Page:2, Index:36, FPSAttention: Training-Aware FP8 and Sparsity Co-Design for Fast Video Diffusion, https://arxiv.org/pdf/2506.04648, 2025-06-05
2025-11-09 20:14:38,408 - INFO - root - Page:2, Index:37, BitTTS: Highly Compact Text-to-Speech Using 1.58-bit Quantization and Weight Indexing, https://arxiv.org/pdf/2506.03515, 2025-06-03
2025-11-09 20:14:38,408 - INFO - root - Page:2, Index:38, ShapeLLM-Omni: A Native Multimodal LLM for 3D Generation and Understanding, https://arxiv.org/pdf/2506.01853, 2025-06-02
2025-11-09 20:14:38,408 - INFO - root - Page:2, Index:39, Movable Antenna Enhanced Federated Fine-Tuning of Large Language Models via Hybrid Client Selection Optimization, https://arxiv.org/pdf/2506.00011, 2025-10-26
2025-11-09 20:14:38,409 - INFO - root - Page:2, Index:40, Running Conventional Automatic Speech Recognition on Memristor Hardware: A Simulated Approach, https://arxiv.org/pdf/2505.24721, 2025-05-30
2025-11-09 20:14:38,411 - INFO - root - Page:2, Index:41, GARLIC: GAussian Representation LearnIng for spaCe partitioning, https://arxiv.org/pdf/2505.24608, 2025-10-02
2025-11-09 20:14:38,411 - INFO - root - Page:2, Index:42, AutoChemSchematic AI: Agentic Physics-Aware Automation for Chemical Manufacturing Scale-Up, https://arxiv.org/pdf/2505.24584, 2025-08-18
2025-11-09 20:14:38,414 - INFO - root - Page:2, Index:43, Model-Preserving Adaptive Rounding, https://arxiv.org/pdf/2505.22988, 2025-09-25
2025-11-09 20:14:38,414 - INFO - root - Page:2, Index:44, Highly Efficient and Effective LLMs with Multi-Boolean Architectures, https://arxiv.org/pdf/2505.22811, 2025-10-03
2025-11-09 20:14:38,414 - INFO - root - Page:2, Index:45, Pioneering 4-Bit FP Quantization for Diffusion Models: Mixup-Sign Quantization and Timestep-Aware Fine-Tuning, https://arxiv.org/pdf/2505.21591, 2025-05-27
2025-11-09 20:14:38,414 - INFO - root - Page:2, Index:46, Frequency Composition for Compressed and Domain-Adaptive Neural Networks, https://arxiv.org/pdf/2505.20890, 2025-05-27
2025-11-09 20:14:38,416 - INFO - root - Page:2, Index:47, MoPFormer: Motion-Primitive Transformer for Wearable-Sensor Activity Recognition, https://arxiv.org/pdf/2505.20744, 2025-10-27
2025-11-09 20:14:38,416 - INFO - root - Page:2, Index:48, Optimizing edge AI models on HPC systems with the edge in the loop, https://arxiv.org/pdf/2505.19995, 2025-05-26
2025-11-09 20:14:38,416 - INFO - root - Fetching page 4 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=150
2025-11-09 20:14:45,563 - INFO - root - get_all_titles_from_web 
2025-11-09 20:14:45,564 - INFO - root - Page:3, Index:0, DPASyn: Mechanism-Aware Drug Synergy Prediction via Dual Attention and Precision-Aware Quantization, https://arxiv.org/pdf/2505.19144, 2025-09-20
2025-11-09 20:14:45,564 - INFO - root - Page:3, Index:1, Reducing Storage of Pretrained Neural Networks by Rate-Constrained Quantization and Entropy Coding, https://arxiv.org/pdf/2505.18758, 2025-05-24
2025-11-09 20:14:45,564 - INFO - root - Page:3, Index:2, Beyond Discreteness: Finite-Sample Analysis of Straight-Through Estimator for Quantization, https://arxiv.org/pdf/2505.18113, 2025-05-23
2025-11-09 20:14:45,564 - INFO - root - Page:3, Index:3, Automating Versatile Time-Series Analysis with Tiny Transformers on Embedded FPGAs, https://arxiv.org/pdf/2505.17662, 2025-09-19
2025-11-09 20:14:45,565 - INFO - root - Page:3, Index:4, FPQVAR: Floating Point Quantization for Visual Autoregressive Model with FPGA Hardware Co-design, https://arxiv.org/pdf/2505.16335, 2025-05-22
2025-11-09 20:14:45,565 - INFO - root - Page:3, Index:5, Saliency-Aware Quantized Imitation Learning for Efficient Robotic Control, https://arxiv.org/pdf/2505.15304, 2025-05-30
2025-11-09 20:14:45,565 - INFO - root - Page:3, Index:6, Scaling Law for Quantization-Aware Training, https://arxiv.org/pdf/2505.14302, 2025-05-20
2025-11-09 20:14:45,565 - INFO - root - Page:3, Index:7, Automatic mixed precision for optimizing gained time with constrained loss mean-squared-error based on model partition to sequential sub-graphs, https://arxiv.org/pdf/2505.13060, 2025-05-19
2025-11-09 20:14:45,566 - INFO - root - Page:3, Index:8, Deep Unfolding with Kernel-based Quantization in MIMO Detection, https://arxiv.org/pdf/2505.12736, 2025-05-19
2025-11-09 20:14:45,566 - INFO - root - Page:3, Index:9, FedHQ: Hybrid Runtime Quantization for Federated Learning, https://arxiv.org/pdf/2505.11982, 2025-05-17
2025-11-09 20:14:45,567 - INFO - root - Page:3, Index:10, QVGen: Pushing the Limit of Quantized Video Generative Models, https://arxiv.org/pdf/2505.11497, 2025-09-27
2025-11-09 20:14:45,567 - INFO - root - Page:3, Index:11, EA-3DGS: Efficient and Adaptive 3D Gaussians with Highly Enhanced Quality for outdoor scenes, https://arxiv.org/pdf/2505.10787, 2025-05-15
2025-11-09 20:14:45,567 - INFO - root - Page:3, Index:12, ITERA-LLM: Boosting Sub-8-Bit Large Language Model Inference via Iterative Tensor Decomposition, https://arxiv.org/pdf/2505.08981, 2025-05-13
2025-11-09 20:14:45,567 - INFO - root - Page:3, Index:13, PROM: Prioritize Reduction of Multiplications Over Lower Bit-Widths for Efficient CNNs, https://arxiv.org/pdf/2505.03254, 2025-08-06
2025-11-09 20:14:45,568 - INFO - root - Page:3, Index:14, ICQuant: Index Coding enables Low-bit LLM Quantization, https://arxiv.org/pdf/2505.00850, 2025-08-24
2025-11-09 20:14:45,568 - INFO - root - Page:3, Index:15, Enhancing Ultra-Low-Bit Quantization of Large Language Models Through Saliency-Aware Partial Retraining, https://arxiv.org/pdf/2504.13932, 2025-07-30
2025-11-09 20:14:45,568 - INFO - root - Page:3, Index:16, Achieving binary weight and activation for LLMs using Post-Training Quantization, https://arxiv.org/pdf/2504.05352, 2025-06-30
2025-11-09 20:14:45,568 - INFO - root - Page:3, Index:17, Wireless Hearables With Programmable Speech AI Accelerators, https://arxiv.org/pdf/2503.18698, 2025-10-21
2025-11-09 20:14:45,568 - INFO - root - Page:3, Index:18, GranQ: Efficient Channel-wise Quantization via Vectorized Pre-Scaling for Zero-Shot QAT, https://arxiv.org/pdf/2503.18339, 2025-10-15
2025-11-09 20:14:45,569 - INFO - root - Page:3, Index:19, CompMarkGS: Robust Watermarking for Compressed 3D Gaussian Splatting, https://arxiv.org/pdf/2503.12836, 2025-09-29
2025-11-09 20:14:45,569 - INFO - root - Page:3, Index:20, AHCPTQ: Accurate and Hardware-Compatible Post-Training Quantization for Segment Anything Model, https://arxiv.org/pdf/2503.03088, 2025-07-11
2025-11-09 20:14:45,569 - INFO - root - Page:3, Index:21, Teaching Metric Distance to Discrete Autoregressive Language Models, https://arxiv.org/pdf/2503.02379, 2025-10-07
2025-11-09 20:14:45,570 - INFO - root - Page:3, Index:22, Regularization-based Framework for Quantization-, Fault- and Variability-Aware Training, https://arxiv.org/pdf/2503.01297, 2025-07-12
2025-11-09 20:14:45,570 - INFO - root - Fetching page 5 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=200
2025-11-09 20:14:52,400 - INFO - root - get_all_titles_from_web 
2025-11-09 20:14:52,400 - INFO - root - Page:4, Index:0, Investigating the Impact of Quantization Methods on the Safety and Reliability of Large Language Models, https://arxiv.org/pdf/2502.15799, 2025-06-29
2025-11-09 20:14:52,401 - INFO - root - Page:4, Index:1, Rotate, Clip, and Partition: Towards W2A4KV4 Quantization by Integrating Rotation and Learnable Non-uniform Quantizer, https://arxiv.org/pdf/2502.15779, 2025-09-01
2025-11-09 20:14:52,401 - INFO - root - Page:4, Index:2, RoSTE: An Efficient Quantization-Aware Supervised Fine-Tuning Approach for Large Language Models, https://arxiv.org/pdf/2502.09003, 2025-06-05
2025-11-09 20:14:52,401 - INFO - root - Page:4, Index:3, Spatial Degradation-Aware and Temporal Consistent Diffusion Model for Compressed Video Super-Resolution, https://arxiv.org/pdf/2502.07381, 2025-06-27
2025-11-09 20:14:52,402 - INFO - root - Page:4, Index:4, QuEST: Stable Training of LLMs with 1-Bit Weights and Activations, https://arxiv.org/pdf/2502.05003, 2025-06-10
2025-11-09 20:14:52,402 - INFO - root - Page:4, Index:5, HALO: Hadamard-Assisted Lower-Precision Optimization for LLMs, https://arxiv.org/pdf/2501.02625, 2025-11-05
2025-11-09 20:14:52,402 - INFO - root - Page:4, Index:6, TAR3D: Creating High-Quality 3D Assets via Next-Part Prediction, https://arxiv.org/pdf/2412.16919, 2025-08-08
2025-11-09 20:14:52,402 - INFO - root - Page:4, Index:7, Training Multi-Layer Binary Neural Networks With Local Binary Error Signals, https://arxiv.org/pdf/2412.00119, 2025-08-05
2025-11-09 20:14:52,404 - INFO - root - Page:4, Index:8, Scaling Large-scale GNN Training to Thousands of Processors on CPU-based Supercomputers, https://arxiv.org/pdf/2411.16025, 2025-05-26
2025-11-09 20:14:52,404 - INFO - root - Page:4, Index:9, HAFLQ: Heterogeneous Adaptive Federated LoRA Fine-tuned LLM with Quantization, https://arxiv.org/pdf/2411.06581, 2025-05-16
2025-11-09 20:14:52,404 - INFO - root - Fetching page 6 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=250
2025-11-09 20:14:59,509 - INFO - root - get_all_titles_from_web 
2025-11-09 20:14:59,509 - INFO - root - Page:5, Index:0, Gradient-Free Training of Quantized Neural Networks, https://arxiv.org/pdf/2410.09734, 2025-09-29
2025-11-09 20:14:59,510 - INFO - root - Page:5, Index:1, QT-DoG: Quantization-aware Training for Domain Generalization, https://arxiv.org/pdf/2410.06020, 2025-06-26
2025-11-09 20:14:59,510 - INFO - root - Page:5, Index:2, Constraint Guided Model Quantization of Neural Networks, https://arxiv.org/pdf/2409.20138, 2025-09-12
2025-11-09 20:14:59,510 - INFO - root - Page:5, Index:3, Accumulator-Aware Post-Training Quantization for Large Language Models, https://arxiv.org/pdf/2409.17092, 2025-07-30
2025-11-09 20:14:59,511 - INFO - root - Page:5, Index:4, DilateQuant: Accurate and Efficient Diffusion Quantization via Weight Dilation, https://arxiv.org/pdf/2409.14307, 2025-07-09
2025-11-09 20:14:59,511 - INFO - root - Page:5, Index:5, Robust Training of Neural Networks at Arbitrary Precision and Sparsity, https://arxiv.org/pdf/2409.09245, 2025-09-23
2025-11-09 20:14:59,511 - INFO - root - Page:5, Index:6, VQ-CTAP: Cross-Modal Fine-Grained Sequence Representation Learning for Speech Processing, https://arxiv.org/pdf/2408.05758, 2025-05-27
2025-11-09 20:14:59,511 - INFO - root - Page:5, Index:7, DopQ-ViT: Towards Distribution-Friendly and Outlier-Aware Post-Training Quantization for Vision Transformers, https://arxiv.org/pdf/2408.03291, 2025-06-19
2025-11-09 20:14:59,513 - INFO - root - Page:5, Index:8, Temporal Feature Matters: A Framework for Diffusion Model Quantization, https://arxiv.org/pdf/2407.19547, 2025-07-11
2025-11-09 20:14:59,513 - INFO - root - Page:5, Index:9, EfficientQAT: Efficient Quantization-Aware Training for Large Language Models, https://arxiv.org/pdf/2407.11062, 2025-05-19
2025-11-09 20:14:59,513 - INFO - root - Page:5, Index:10, Integer-only Quantized Transformers for Embedded FPGA-based Time-series Forecasting in AIoT, https://arxiv.org/pdf/2407.11041, 2025-10-31
2025-11-09 20:14:59,514 - INFO - root - Fetching page 7 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=300
2025-11-09 20:15:06,532 - INFO - root - get_all_titles_from_web 
2025-11-09 20:15:06,534 - INFO - root - Page:6, Index:0, BoA: Attention-aware Post-training Quantization without Backpropagation, https://arxiv.org/pdf/2406.13474, 2025-06-06
2025-11-09 20:15:06,535 - INFO - root - Page:6, Index:1, A Rescaling-Invariant Lipschitz Bound Based on Path-Metrics for Modern ReLU Network Parameterizations, https://arxiv.org/pdf/2405.15006, 2025-06-13
2025-11-09 20:15:06,536 - INFO - root - Page:6, Index:2, Scheduling Weight Transitions for Quantization-Aware Training, https://arxiv.org/pdf/2404.19248, 2025-10-01
2025-11-09 20:15:06,536 - INFO - root - Page:6, Index:3, GPTVQ: The Blessing of Dimensionality for LLM Quantization, https://arxiv.org/pdf/2402.15319, 2025-06-03
2025-11-09 20:15:06,537 - INFO - root - Fetching page 8 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=350
2025-11-09 20:15:13,032 - INFO - root - get_all_titles_from_web 
2025-11-09 20:15:13,032 - INFO - root - Page:7, Index:0, Squat: Quant Small Language Models on the Edge, https://arxiv.org/pdf/2402.10787, 2025-07-01
2025-11-09 20:15:13,032 - INFO - root - Page:7, Index:1, L4Q: Parameter Efficient Quantization-Aware Fine-Tuning on Large Language Models, https://arxiv.org/pdf/2402.04902, 2025-07-21
2025-11-09 20:15:13,034 - INFO - root - Fetching page 9 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=400
2025-11-09 20:15:19,488 - INFO - root - ------------------------------------------------------------------------------------------------------------------------
2025-11-09 20:15:33,034 - INFO - root - 跳过已处理论文 A Quantized VAE-MLP Botnet Detection Model: A Systematic Evaluation of Quantization-Aware Training and Post-Training Quantization Strategies：D:\ChatPaper\academic Papers\Quantization-Aware-Training\A Quantized VAE-MLP Botnet Detection Model_ A Systematic Evaluation of Quantizat-5.pdf
2025-11-09 20:15:33,035 - INFO - root - 跳过已处理论文 FP8-Flow-MoE: A Casting-Free FP8 Recipe without Double Quantization Error：D:\ChatPaper\academic Papers\Quantization-Aware-Training\FP8-Flow-MoE_ A Casting-Free FP8 Recipe without Double Quantization Error-5.pdf
2025-11-09 20:15:33,035 - INFO - root - summary time: 79.92 seconds
2025-11-09 20:28:53,722 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-09 20:28:53,728 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-09 20:28:53,751 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-09 20:28:57,059 - INFO - root - LLMClientManager: 指定使用客户端: Deepseek
2025-11-09 20:28:57,069 - INFO - root - DeepSeekClient: API key found: 9f9e270e-b...
2025-11-09 20:28:57,110 - INFO - root - DeepSeekClient: 使用模式: 火山引擎
2025-11-09 20:28:57,126 - INFO - root - DeepSeekClient: 模型名称: deepseek-v3-1-terminus
2025-11-09 20:29:04,506 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 20:29:04,566 - INFO - root - DeepSeekClient: initialized successfully with model deepseek-v3-1-terminus
2025-11-09 20:29:04,566 - INFO - root - LLMClientManager: DeepSeek 客户端初始化成功
2025-11-09 20:29:04,567 - WARNING - root - LLMClientManager: client Deepseek not available
2025-11-09 20:29:04,568 - WARNING - root - 无法切换到指定的客户端 Deepseek，将使用默认客户端
2025-11-09 20:29:04,568 - INFO - root - 可用客户端: ['DeepSeek']
2025-11-09 20:29:04,568 - INFO - root - 使用 LLM 模型: deepseek-v3-1-terminus
2025-11-09 20:29:04,569 - INFO - root - 可用客户端: ['DeepSeek']
2025-11-09 20:29:04,574 - INFO - root - === 运行配置 ===
2025-11-09 20:29:04,575 - INFO - root - 处理模式: arxiv在线搜索
2025-11-09 20:29:04,575 - INFO - root - 关键词: QAT
2025-11-09 20:29:04,577 - INFO - root - 查询: Quantization-Aware-Training
2025-11-09 20:29:04,577 - INFO - root - 排序: None
2025-11-09 20:29:04,577 - INFO - root - 最近天数: 180
2025-11-09 20:29:04,578 - INFO - root - 最大处理数量: 2
2025-11-09 20:29:04,578 - INFO - root - 保存图片: 是
2025-11-09 20:29:04,578 - INFO - root - 输出语言: 中文
2025-11-09 20:29:04,581 - INFO - root - 强制重新处理: 否
2025-11-09 20:29:04,581 - INFO - root - ====================
2025-11-09 20:29:04,582 - INFO - root - 使用 arXiv 搜索模式（通过 chat_arxiv 模块获取）
2025-11-09 20:29:04,582 - INFO - root - Fetching page 1 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50
2025-11-09 20:29:11,959 - INFO - root - get_all_titles_from_web 
2025-11-09 20:29:11,965 - INFO - root - Page:0, Index:0, A Quantized VAE-MLP Botnet Detection Model: A Systematic Evaluation of Quantization-Aware Training and Post-Training Quantization Strategies, https://arxiv.org/pdf/2511.03201, 2025-11-05
2025-11-09 20:29:11,966 - INFO - root - Page:0, Index:1, FP8-Flow-MoE: A Casting-Free FP8 Recipe without Double Quantization Error, https://arxiv.org/pdf/2511.02302, 2025-11-04
2025-11-09 20:29:11,967 - INFO - root - Page:0, Index:2, Outlier-Aware Post-Training Quantization for Image Super-Resolution, https://arxiv.org/pdf/2511.00682, 2025-11-01
2025-11-09 20:29:11,975 - INFO - root - Page:0, Index:3, Evaluation of Wafer-Scale SOT-MRAM for Analog Crossbar Array Applications, https://arxiv.org/pdf/2510.25853, 2025-11-03
2025-11-09 20:29:11,991 - INFO - root - Page:0, Index:4, Improving the Straight-Through Estimator with Zeroth-Order Information, https://arxiv.org/pdf/2510.23926, 2025-10-27
2025-11-09 20:29:12,007 - INFO - root - Page:0, Index:5, Real-Time Semantic Segmentation on FPGA for Autonomous Vehicles Using LMIINet with the CGRA4ML Framework, https://arxiv.org/pdf/2510.22243, 2025-10-25
2025-11-09 20:29:12,015 - INFO - root - Page:0, Index:6, TernaryCLIP: Efficiently Compressing Vision-Language Models with Ternary Weights and Distilled Knowledge, https://arxiv.org/pdf/2510.21879, 2025-10-23
2025-11-09 20:29:12,016 - INFO - root - Page:0, Index:7, KARIPAP: Quantum-Inspired Tensor Network Compression of Large Language Models Using Infinite Projected Entangled Pair States and Tensor Renormalization Group, https://arxiv.org/pdf/2510.21844, 2025-10-22
2025-11-09 20:29:12,016 - INFO - root - Page:0, Index:8, A Convergence Analysis of Adaptive Optimizers under Floating-point Quantization, https://arxiv.org/pdf/2510.21314, 2025-10-24
2025-11-09 20:29:12,018 - INFO - root - Page:0, Index:9, Adaptive Distribution-aware Quantization for Mixed-Precision Neural Networks, https://arxiv.org/pdf/2510.19760, 2025-10-22
2025-11-09 20:29:12,019 - INFO - root - Page:0, Index:10, CAGE: Curvature-Aware Gradient Estimation For Accurate Quantization-Aware Training, https://arxiv.org/pdf/2510.18784, 2025-10-21
2025-11-09 20:29:12,021 - INFO - root - Page:0, Index:11, Mixed-Precision Quantization for Language Models: Techniques and Prospects, https://arxiv.org/pdf/2510.16805, 2025-10-19
2025-11-09 20:29:12,021 - INFO - root - Page:0, Index:12, SPLite Hand: Sparsity-Aware Lightweight 3D Hand Pose Estimation, https://arxiv.org/pdf/2510.16396, 2025-10-30
2025-11-09 20:29:12,022 - INFO - root - Page:0, Index:13, CTR-LoRA: Curvature-Aware and Trust-Region Guided Low-Rank Adaptation for Large Language Models, https://arxiv.org/pdf/2510.15962, 2025-10-11
2025-11-09 20:29:12,022 - INFO - root - Page:0, Index:14, SANR: Scene-Aware Neural Representation for Light Field Image Compression with Rate-Distortion Optimization, https://arxiv.org/pdf/2510.15775, 2025-10-17
2025-11-09 20:29:12,023 - INFO - root - Page:0, Index:15, SpikeFit: Towards Optimal Deployment of Spiking Networks on Neuromorphic Hardware, https://arxiv.org/pdf/2510.15542, 2025-10-31
2025-11-09 20:29:12,023 - INFO - root - Page:0, Index:16, GRank: Towards Target-Aware and Streamlined Industrial Retrieval with a Generate-Rank Framework, https://arxiv.org/pdf/2510.15299, 2025-10-17
2025-11-09 20:29:12,023 - INFO - root - Page:0, Index:17, SaLon3R: Structure-aware Long-term Generalizable 3D Reconstruction from Unposed Images, https://arxiv.org/pdf/2510.15072, 2025-10-16
2025-11-09 20:29:12,023 - INFO - root - Page:0, Index:18, FraQAT: Quantization Aware Training with Fractional bits, https://arxiv.org/pdf/2510.14823, 2025-10-16
2025-11-09 20:29:12,024 - INFO - root - Page:0, Index:19, Computing-In-Memory Aware Model Adaption For Edge Devices, https://arxiv.org/pdf/2510.14379, 2025-10-16
2025-11-09 20:29:12,024 - INFO - root - Page:0, Index:20, Invited Paper: BitMedViT: Ternary-Quantized Vision Transformer for Medical AI Assistants on the Edge, https://arxiv.org/pdf/2510.13760, 2025-11-04
2025-11-09 20:29:12,024 - INFO - root - Page:0, Index:21, NeuroRVQ: Multi-Scale EEG Tokenization for Generative Large Brainwave Models, https://arxiv.org/pdf/2510.13068, 2025-10-14
2025-11-09 20:29:12,025 - INFO - root - Page:0, Index:22, Detect Anything via Next Point Prediction, https://arxiv.org/pdf/2510.12798, 2025-10-14
2025-11-09 20:29:12,025 - INFO - root - Page:0, Index:23, AndesVL Technical Report: An Efficient Mobile-side Multimodal Large Language Model, https://arxiv.org/pdf/2510.11496, 2025-10-14
2025-11-09 20:29:12,026 - INFO - root - Page:0, Index:24, Rescaling-Aware Training for Efficient Deployment of Deep Learning Models on Full-Integer Hardware, https://arxiv.org/pdf/2510.11484, 2025-10-13
2025-11-09 20:29:12,035 - INFO - root - Page:0, Index:25, SASER: Stego attacks on open-source LLMs, https://arxiv.org/pdf/2510.10486, 2025-10-12
2025-11-09 20:29:12,036 - INFO - root - Page:0, Index:26, Ultralytics YOLO Evolution: An Overview of YOLO26, YOLO11, YOLOv8 and YOLOv5 Object Detectors for Computer Vision and Pattern Recognition, https://arxiv.org/pdf/2510.09653, 2025-10-15
2025-11-09 20:29:12,040 - INFO - root - Page:0, Index:27, A Theoretically-Grounded Codebook for Digital Semantic Communications, https://arxiv.org/pdf/2510.07108, 2025-10-14
2025-11-09 20:29:12,056 - INFO - root - Page:0, Index:28, QuantDemoire: Quantization with Outlier Aware for Image Demoiréing, https://arxiv.org/pdf/2510.04066, 2025-10-05
2025-11-09 20:29:12,066 - INFO - root - Page:0, Index:29, Adaptively Sampling-Reusing-Mixing Decomposed Gradients to Speed Up Sharpness Aware Minimization, https://arxiv.org/pdf/2510.03763, 2025-10-04
2025-11-09 20:29:12,067 - INFO - root - Page:0, Index:30, Quant-dLLM: Post-Training Extreme Low-Bit Quantization for Diffusion Large Language Models, https://arxiv.org/pdf/2510.03274, 2025-09-27
2025-11-09 20:29:12,068 - INFO - root - Page:0, Index:31, PT$^2$-LLM: Post-Training Ternarization for Large Language Models, https://arxiv.org/pdf/2510.03267, 2025-09-26
2025-11-09 20:29:12,071 - INFO - root - Page:0, Index:32, Purrception: Variational Flow Matching for Vector-Quantized Image Generation, https://arxiv.org/pdf/2510.01478, 2025-10-01
2025-11-09 20:29:12,072 - INFO - root - Page:0, Index:33, Post-Training Quantization for Audio Diffusion Transformers, https://arxiv.org/pdf/2510.00313, 2025-09-30
2025-11-09 20:29:12,074 - INFO - root - Page:0, Index:34, Rethinking RoPE Scaling in Quantized LLM: Theory, Outlier, and Channel-Band Analysis with Weight Rescaling, https://arxiv.org/pdf/2510.00028, 2025-09-25
2025-11-09 20:29:12,074 - INFO - root - Page:0, Index:35, Post-Training Quantization via Residual Truncation and Zero Suppression for Diffusion Models, https://arxiv.org/pdf/2509.26436, 2025-09-30
2025-11-09 20:29:12,076 - INFO - root - Page:0, Index:36, Cat: Post-Training Quantization Error Reduction via Cluster-based Affine Transformation, https://arxiv.org/pdf/2509.26277, 2025-10-07
2025-11-09 20:29:12,088 - INFO - root - Page:0, Index:37, CAST: Continuous and Differentiable Semi-Structured Sparsity-Aware Training for Large Language Models, https://arxiv.org/pdf/2509.25996, 2025-09-30
2025-11-09 20:29:12,107 - INFO - root - Page:0, Index:38, Norm-Q: Effective Compression Method for Hidden Markov Models in Neuro-Symbolic Applications, https://arxiv.org/pdf/2509.25439, 2025-09-29
2025-11-09 20:29:12,114 - INFO - root - Page:0, Index:39, On-the-Fly Adaptation to Quantization: Configuration-Aware LoRA for Efficient Fine-Tuning of Quantized LLMs, https://arxiv.org/pdf/2509.25214, 2025-09-22
2025-11-09 20:29:12,117 - INFO - root - Page:0, Index:40, VoxCPM: Tokenizer-Free TTS for Context-Aware Speech Generation and True-to-Life Voice Cloning, https://arxiv.org/pdf/2509.24650, 2025-09-29
2025-11-09 20:29:12,123 - INFO - root - Page:0, Index:41, S$^2$NN: Sub-bit Spiking Neural Networks, https://arxiv.org/pdf/2509.24266, 2025-10-24
2025-11-09 20:29:12,125 - INFO - root - Page:0, Index:42, Tequila: Trapping-free Ternary Quantization for Large Language Models, https://arxiv.org/pdf/2509.23809, 2025-10-17
2025-11-09 20:29:12,125 - INFO - root - Page:0, Index:43, Texture Vector-Quantization and Reconstruction Aware Prediction for Generative Super-Resolution, https://arxiv.org/pdf/2509.23774, 2025-09-30
2025-11-09 20:29:12,125 - INFO - root - Page:0, Index:44, RobuQ: Pushing DiTs to W1.58A2 via Robust Activation Quantization, https://arxiv.org/pdf/2509.23582, 2025-09-27
2025-11-09 20:29:12,133 - INFO - root - Page:0, Index:45, Beyond Outliers: A Study of Optimizers Under Quantization, https://arxiv.org/pdf/2509.23500, 2025-10-02
2025-11-09 20:29:12,134 - INFO - root - Page:0, Index:46, Compute-Optimal Quantization-Aware Training, https://arxiv.org/pdf/2509.22935, 2025-09-26
2025-11-09 20:29:12,136 - INFO - root - Page:0, Index:47, COSPADI: Compressing LLMs via Calibration-Guided Sparse Dictionary Learning, https://arxiv.org/pdf/2509.22075, 2025-10-06
2025-11-09 20:29:12,142 - INFO - root - Page:0, Index:48, SlimDiff: Training-Free, Activation-Guided Hands-free Slimming of Diffusion Models, https://arxiv.org/pdf/2509.21498, 2025-09-25
2025-11-09 20:29:12,159 - INFO - root - Page:0, Index:49, Quantized Visual Geometry Grounded Transformer, https://arxiv.org/pdf/2509.21302, 2025-09-29
2025-11-09 20:29:12,185 - INFO - root - Fetching page 2 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=50
2025-11-09 20:29:19,926 - INFO - root - get_all_titles_from_web 
2025-11-09 20:29:19,932 - INFO - root - Page:1, Index:0, Can Less Precise Be More Reliable? A Systematic Evaluation of Quantization's Impact on CLIP Beyond Accuracy, https://arxiv.org/pdf/2509.21173, 2025-10-27
2025-11-09 20:29:19,960 - INFO - root - Page:1, Index:1, Punching Above Precision: Small Quantized Model Distillation with Learnable Regularizer, https://arxiv.org/pdf/2509.20854, 2025-09-25
2025-11-09 20:29:19,976 - INFO - root - Page:1, Index:2, TinyEcoWeedNet: Edge Efficient Real-Time Aerial Agricultural Weed Detection, https://arxiv.org/pdf/2509.18193, 2025-09-19
2025-11-09 20:29:19,978 - INFO - root - Page:1, Index:3, SBVR: Summation of BitVector Representation for Efficient LLM Quantization, https://arxiv.org/pdf/2509.18172, 2025-09-17
2025-11-09 20:29:19,983 - INFO - root - Page:1, Index:4, QWHA: Quantization-Aware Walsh-Hadamard Adaptation for Parameter-Efficient Fine-Tuning on Large Language Models, https://arxiv.org/pdf/2509.17428, 2025-09-26
2025-11-09 20:29:20,008 - INFO - root - Page:1, Index:5, PTQTP: Post-Training Quantization to Trit-Planes for Large Language Models, https://arxiv.org/pdf/2509.16989, 2025-10-28
2025-11-09 20:29:20,030 - INFO - root - Page:1, Index:6, MEC-Quant: Maximum Entropy Coding for Extremely Low Bit Quantization-Aware Training, https://arxiv.org/pdf/2509.15514, 2025-09-18
2025-11-09 20:29:20,045 - INFO - root - Page:1, Index:7, Q-ROAR: Outlier-Aware Rescaling for RoPE Position Interpolation in Quantized Long-Context LLMs, https://arxiv.org/pdf/2509.14391, 2025-09-17
2025-11-09 20:29:20,078 - INFO - root - Page:1, Index:8, Efficient Quantization-Aware Neural Receivers: Beyond Post-Training Quantization, https://arxiv.org/pdf/2509.13786, 2025-09-19
2025-11-09 20:29:20,093 - INFO - root - Page:1, Index:9, Rate-Distortion Limits for Multimodal Retrieval: Theory, Optimal Codes, and Finite-Sample Guarantees, https://arxiv.org/pdf/2509.11054, 2025-09-13
2025-11-09 20:29:20,156 - INFO - root - Page:1, Index:10, SQAP-VLA: A Synergistic Quantization-Aware Pruning Framework for High-Performance Vision-Language-Action Models, https://arxiv.org/pdf/2509.09090, 2025-09-10
2025-11-09 20:29:20,280 - INFO - root - Page:1, Index:11, CSI Compression Beyond Latents: End-to-End Hybrid Attention-CNN Networks with Entropy Regularization, https://arxiv.org/pdf/2509.08776, 2025-09-10
2025-11-09 20:29:20,397 - INFO - root - Page:1, Index:12, Explaining How Quantization Disparately Skews a Model, https://arxiv.org/pdf/2509.07222, 2025-09-08
2025-11-09 20:29:20,433 - INFO - root - Page:1, Index:13, LoaQ: Layer-wise Output Approximation Quantization, https://arxiv.org/pdf/2509.06297, 2025-09-07
2025-11-09 20:29:20,501 - INFO - root - Page:1, Index:14, FineServe: Precision-Aware KV Slab and Two-Level Scheduling for Heterogeneous Precision LLM Serving, https://arxiv.org/pdf/2509.06261, 2025-09-14
2025-11-09 20:29:20,513 - INFO - root - Page:1, Index:15, Sensitivity-Aware Post-Training Quantization for Deep Neural Networks, https://arxiv.org/pdf/2509.05576, 2025-09-05
2025-11-09 20:29:20,529 - INFO - root - Page:1, Index:16, SuperSNN: A Hardware-Aware Framework for Physically Realizable, High-Performance Superconducting Spiking Neural Network Chips, https://arxiv.org/pdf/2509.05532, 2025-09-05
2025-11-09 20:29:20,533 - INFO - root - Page:1, Index:17, Data-Augmented Quantization-Aware Knowledge Distillation, https://arxiv.org/pdf/2509.03850, 2025-09-03
2025-11-09 20:29:20,540 - INFO - root - Page:1, Index:18, DPQuant: Efficient and Differentially-Private Model Training via Dynamic Quantization Scheduling, https://arxiv.org/pdf/2509.03472, 2025-09-03
2025-11-09 20:29:20,590 - INFO - root - Page:1, Index:19, Empowering Large Language Model for Sequential Recommendation via Multimodal Embeddings and Semantic IDs, https://arxiv.org/pdf/2509.02017, 2025-09-02
2025-11-09 20:29:20,597 - INFO - root - Page:1, Index:20, Q-Sched: Pushing the Boundaries of Few-Step Diffusion Models with Quantization-Aware Scheduling, https://arxiv.org/pdf/2509.01624, 2025-09-01
2025-11-09 20:29:20,616 - INFO - root - Page:1, Index:21, Quantization Meets OOD: Generalizable Quantization-aware Training from a Flatness Perspective, https://arxiv.org/pdf/2509.00859, 2025-08-31
2025-11-09 20:29:20,627 - INFO - root - Page:1, Index:22, Progressive Element-wise Gradient Estimation for Neural Network Quantization, https://arxiv.org/pdf/2509.00097, 2025-08-27
2025-11-09 20:29:20,645 - INFO - root - Page:1, Index:23, End-to-End On-Device Quantization-Aware Training for LLMs at Inference Cost, https://arxiv.org/pdf/2509.00031, 2025-09-29
2025-11-09 20:29:20,646 - INFO - root - Page:1, Index:24, Quantization Robustness to Input Degradations for Object Detection, https://arxiv.org/pdf/2508.19600, 2025-08-27
2025-11-09 20:29:20,647 - INFO - root - Page:1, Index:25, Scaling Laws for Task-Stratified Knowledge in Post-Training Quantized Large Language Models, https://arxiv.org/pdf/2508.18609, 2025-08-27
2025-11-09 20:29:20,648 - INFO - root - Page:1, Index:26, AQ-PCDSys: An Adaptive Quantized Planetary Crater Detection System for Autonomous Space Exploration, https://arxiv.org/pdf/2508.18025, 2025-08-25
2025-11-09 20:29:20,649 - INFO - root - Page:1, Index:27, TaDiCodec: Text-aware Diffusion Speech Tokenizer for Speech Language Modeling, https://arxiv.org/pdf/2508.16790, 2025-08-22
2025-11-09 20:29:20,649 - INFO - root - Page:1, Index:28, A Node-Aware Dynamic Quantization Approach for Graph Collaborative Filtering, https://arxiv.org/pdf/2508.16516, 2025-08-22
2025-11-09 20:29:20,697 - INFO - root - Page:1, Index:29, JEDI-linear: Fast and Efficient Graph Neural Networks for Jet Tagging on FPGAs, https://arxiv.org/pdf/2508.15468, 2025-08-21
2025-11-09 20:29:20,698 - INFO - root - Page:1, Index:30, MMQ: Multimodal Mixture-of-Quantization Tokenization for Semantic ID Generation and User Behavioral Adaptation, https://arxiv.org/pdf/2508.15281, 2025-08-21
2025-11-09 20:29:20,700 - INFO - root - Page:1, Index:31, DLLMQuant: Quantizing Diffusion-based Large Language Models, https://arxiv.org/pdf/2508.14090, 2025-08-25
2025-11-09 20:29:20,700 - INFO - root - Page:1, Index:32, Automated Energy-Aware Time-Series Model Deployment on Embedded FPGAs for Resilient Combined Sewer Overflow Management, https://arxiv.org/pdf/2508.13905, 2025-08-19
2025-11-09 20:29:20,707 - INFO - root - Page:1, Index:33, XR-NPE: High-Throughput Mixed-precision SIMD Neural Processing Engine for Extended Reality Perception Workloads, https://arxiv.org/pdf/2508.13049, 2025-08-18
2025-11-09 20:29:20,708 - INFO - root - Page:1, Index:34, Exploring Self-Supervised Audio Models for Generalized Anomalous Sound Detection, https://arxiv.org/pdf/2508.12230, 2025-08-17
2025-11-09 20:29:20,712 - INFO - root - Page:1, Index:35, TriQDef: Disrupting Semantic and Gradient Alignment to Prevent Adversarial Patch Transferability in Quantized Neural Networks, https://arxiv.org/pdf/2508.12132, 2025-08-16
2025-11-09 20:29:20,715 - INFO - root - Page:1, Index:36, Error Propagation Mechanisms and Compensation Strategies for Quantized Diffusion, https://arxiv.org/pdf/2508.12094, 2025-10-13
2025-11-09 20:29:20,724 - INFO - root - Page:1, Index:37, Extending Straight-Through Estimation for Robust Neural Networks on Analog CIM Hardware, https://arxiv.org/pdf/2508.11940, 2025-08-16
2025-11-09 20:29:20,730 - INFO - root - Page:1, Index:38, PTQAT: A Hybrid Parameter-Efficient Quantization Algorithm for 3D Perception Tasks, https://arxiv.org/pdf/2508.10557, 2025-08-15
2025-11-09 20:29:20,731 - INFO - root - Page:1, Index:39, MiCo: End-to-End Mixed Precision Neural Network Co-Exploration Framework for Edge AI, https://arxiv.org/pdf/2508.09500, 2025-08-13
2025-11-09 20:29:20,731 - INFO - root - Page:1, Index:40, SPARC: Soft Probabilistic Adaptive multi-interest Retrieval Model via Codebooks for recommender system, https://arxiv.org/pdf/2508.09090, 2025-08-12
2025-11-09 20:29:20,734 - INFO - root - Page:1, Index:41, Rethinking 1-bit Optimization Leveraging Pre-trained Large Language Models, https://arxiv.org/pdf/2508.06974, 2025-08-09
2025-11-09 20:29:20,734 - INFO - root - Page:1, Index:42, Efficient Deep Neural Receiver with Post-Training Quantization, https://arxiv.org/pdf/2508.06275, 2025-08-08
2025-11-09 20:29:20,735 - INFO - root - Page:1, Index:43, iFairy: the First 2-bit Complex LLM with All Parameters in $\{\pm1, \pm i\}$, https://arxiv.org/pdf/2508.05571, 2025-08-16
2025-11-09 20:29:20,767 - INFO - root - Page:1, Index:44, S$^2$Q-VDiT: Accurate Quantized Video Diffusion Transformer with Salient Data and Sparse Token Distillation, https://arxiv.org/pdf/2508.04016, 2025-10-27
2025-11-09 20:29:20,780 - INFO - root - Page:1, Index:45, LRQ-DiT: Log-Rotation Post-Training Quantization of Diffusion Transformers for Image and Video Generation, https://arxiv.org/pdf/2508.03485, 2025-09-23
2025-11-09 20:29:20,795 - INFO - root - Page:1, Index:46, VLMQ: Efficient Post-Training Quantization for Large Vision-Language Models via Hessian Augmentation, https://arxiv.org/pdf/2508.03351, 2025-08-05
2025-11-09 20:29:20,798 - INFO - root - Page:1, Index:47, TF-MLPNet: Tiny Real-Time Neural Speech Separation, https://arxiv.org/pdf/2508.03047, 2025-08-04
2025-11-09 20:29:20,811 - INFO - root - Page:1, Index:48, SaviorRec: Semantic-Behavior Alignment for Cold-Start Recommendation, https://arxiv.org/pdf/2508.01375, 2025-08-02
2025-11-09 20:29:20,860 - INFO - root - Page:1, Index:49, MixA-Q: Revisiting Activation Sparsity for Vision Transformers from a Mixed-Precision Quantization Perspective, https://arxiv.org/pdf/2507.19131, 2025-07-25
2025-11-09 20:29:20,893 - INFO - root - Fetching page 3 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=100
2025-11-09 20:29:28,070 - INFO - root - get_all_titles_from_web 
2025-11-09 20:29:28,071 - INFO - root - Page:2, Index:0, Enhancing Quantization-Aware Training on Edge Devices via Relative Entropy Coreset Selection and Cascaded Layer Correction, https://arxiv.org/pdf/2507.17768, 2025-07-16
2025-11-09 20:29:28,072 - INFO - root - Page:2, Index:1, SiLQ: Simple Large Language Model Quantization-Aware Training, https://arxiv.org/pdf/2507.16933, 2025-07-22
2025-11-09 20:29:28,072 - INFO - root - Page:2, Index:2, Task-Specific Zero-shot Quantization-Aware Training for Object Detection, https://arxiv.org/pdf/2507.16782, 2025-07-22
2025-11-09 20:29:28,072 - INFO - root - Page:2, Index:3, TorchAO: PyTorch-Native Training-to-Serving Model Optimization, https://arxiv.org/pdf/2507.16099, 2025-07-21
2025-11-09 20:29:28,072 - INFO - root - Page:2, Index:4, SegQuant: A Semantics-Aware and Generalizable Quantization Framework for Diffusion Models, https://arxiv.org/pdf/2507.14811, 2025-08-27
2025-11-09 20:29:28,072 - INFO - root - Page:2, Index:5, Apple Intelligence Foundation Language Models: Tech Report 2025, https://arxiv.org/pdf/2507.13575, 2025-08-27
2025-11-09 20:29:28,073 - INFO - root - Page:2, Index:6, Generative Multi-Target Cross-Domain Recommendation, https://arxiv.org/pdf/2507.12871, 2025-08-07
2025-11-09 20:29:28,073 - INFO - root - Page:2, Index:7, DAF: An Efficient End-to-End Dynamic Activation Framework for on-Device DNN Training, https://arxiv.org/pdf/2507.07149, 2025-07-09
2025-11-09 20:29:28,073 - INFO - root - Page:2, Index:8, Opto-ViT: Architecting a Near-Sensor Region of Interest-Aware Vision Transformer Accelerator with Silicon Photonics, https://arxiv.org/pdf/2507.07044, 2025-07-15
2025-11-09 20:29:28,073 - INFO - root - Page:2, Index:9, QS4D: Quantization-aware training for efficient hardware deployment of structured state-space sequential models, https://arxiv.org/pdf/2507.06079, 2025-07-08
2025-11-09 20:29:28,073 - INFO - root - Page:2, Index:10, GSVR: 2D Gaussian-based Video Representation for 800+ FPS with Hybrid Deformation Field, https://arxiv.org/pdf/2507.05594, 2025-07-07
2025-11-09 20:29:28,074 - INFO - root - Page:2, Index:11, Hita: Holistic Tokenizer for Autoregressive Image Generation, https://arxiv.org/pdf/2507.02358, 2025-07-11
2025-11-09 20:29:28,074 - INFO - root - Page:2, Index:12, QPART: Adaptive Model Quantization and Dynamic Workload Balancing for Accuracy-aware Edge Inference, https://arxiv.org/pdf/2506.23934, 2025-06-30
2025-11-09 20:29:28,074 - INFO - root - Page:2, Index:13, FedWSQ: Efficient Federated Learning with Weight Standardization and Distribution-Aware Non-Uniform Quantization, https://arxiv.org/pdf/2506.23516, 2025-07-21
2025-11-09 20:29:28,074 - INFO - root - Page:2, Index:14, Spectra 1.1: Scaling Laws and Efficient Inference for Ternary Language Models, https://arxiv.org/pdf/2506.23025, 2025-06-28
2025-11-09 20:29:28,074 - INFO - root - Page:2, Index:15, Joint Quantization and Pruning Neural Networks Approach: A Case Study on FSO Receivers, https://arxiv.org/pdf/2506.20084, 2025-06-24
2025-11-09 20:29:28,074 - INFO - root - Page:2, Index:16, Single-step Diffusion for Image Compression at Ultra-Low Bitrates, https://arxiv.org/pdf/2506.16572, 2025-09-22
2025-11-09 20:29:28,075 - INFO - root - Page:2, Index:17, LittleBit: Ultra Low-Bit Quantization via Latent Factorization, https://arxiv.org/pdf/2506.13771, 2025-10-28
2025-11-09 20:29:28,075 - INFO - root - Page:2, Index:18, MARCO: Hardware-Aware Neural Architecture Search for Edge Devices with Multi-Agent Reinforcement Learning and Conformal Prediction Filtering, https://arxiv.org/pdf/2506.13755, 2025-06-16
2025-11-09 20:29:28,075 - INFO - root - Page:2, Index:19, EAQuant: Enhancing Post-Training Quantization for MoE Models via Expert-Aware Optimization, https://arxiv.org/pdf/2506.13329, 2025-07-04
2025-11-09 20:29:28,075 - INFO - root - Page:2, Index:20, Towards Neural Audio Codec Source Parsing, https://arxiv.org/pdf/2506.12627, 2025-06-14
2025-11-09 20:29:28,077 - INFO - root - Page:2, Index:21, Quantizing Small-Scale State-Space Models for Edge AI, https://arxiv.org/pdf/2506.12480, 2025-06-14
2025-11-09 20:29:28,078 - INFO - root - Page:2, Index:22, EMLoC: Emulator-based Memory-efficient Fine-tuning with LoRA Correction, https://arxiv.org/pdf/2506.12015, 2025-06-13
2025-11-09 20:29:28,078 - INFO - root - Page:2, Index:23, Compression Aware Certified Training, https://arxiv.org/pdf/2506.11992, 2025-06-13
2025-11-09 20:29:28,078 - INFO - root - Page:2, Index:24, GPLQ: A General, Practical, and Lightning QAT Method for Vision Transformers, https://arxiv.org/pdf/2506.11784, 2025-06-13
2025-11-09 20:29:28,078 - INFO - root - Page:2, Index:25, TruncQuant: Truncation-Ready Quantization for DNNs with Flexible Weight Bit Precision, https://arxiv.org/pdf/2506.11431, 2025-06-12
2025-11-09 20:29:28,080 - INFO - root - Page:2, Index:26, EfficientQuant: An Efficient Post-Training Quantization for CNN-Transformer Hybrid Models on Edge Devices, https://arxiv.org/pdf/2506.11093, 2025-06-05
2025-11-09 20:29:28,081 - INFO - root - Page:2, Index:27, Starting Positions Matter: A Study on Better Weight Initialization for Neural Network Quantization, https://arxiv.org/pdf/2506.10463, 2025-06-12
2025-11-09 20:29:28,081 - INFO - root - Page:2, Index:28, AWP: Activation-Aware Weight Pruning and Quantization with Projected Gradient Descent, https://arxiv.org/pdf/2506.10205, 2025-06-11
2025-11-09 20:29:28,081 - INFO - root - Page:2, Index:29, Q-SAM2: Accurate Quantization for Segment Anything Model 2, https://arxiv.org/pdf/2506.09782, 2025-06-11
2025-11-09 20:29:28,081 - INFO - root - Page:2, Index:30, Unifying Block-wise PTQ and Distillation-based QAT for Progressive Quantization toward 2-bit Instruction-Tuned LLMs, https://arxiv.org/pdf/2506.09104, 2025-06-10
2025-11-09 20:29:28,081 - INFO - root - Page:2, Index:31, Implementing Keyword Spotting on the MCUX947 Microcontroller with Integrated NPU, https://arxiv.org/pdf/2506.08911, 2025-06-10
2025-11-09 20:29:28,081 - INFO - root - Page:2, Index:32, POLARON: Precision-aware On-device Learning and Adaptive Runtime-cONfigurable AI acceleration, https://arxiv.org/pdf/2506.08785, 2025-06-10
2025-11-09 20:29:28,083 - INFO - root - Page:2, Index:33, MoQAE: Mixed-Precision Quantization for Long-Context LLM Inference via Mixture of Quantization-Aware Experts, https://arxiv.org/pdf/2506.07533, 2025-06-09
2025-11-09 20:29:28,084 - INFO - root - Page:2, Index:34, BitVLA: 1-bit Vision-Language-Action Models for Robotics Manipulation, https://arxiv.org/pdf/2506.07530, 2025-06-09
2025-11-09 20:29:28,084 - INFO - root - Page:2, Index:35, RecGPT: A Foundation Model for Sequential Recommendation, https://arxiv.org/pdf/2506.06270, 2025-06-12
2025-11-09 20:29:28,086 - INFO - root - Page:2, Index:36, FPSAttention: Training-Aware FP8 and Sparsity Co-Design for Fast Video Diffusion, https://arxiv.org/pdf/2506.04648, 2025-06-05
2025-11-09 20:29:28,086 - INFO - root - Page:2, Index:37, BitTTS: Highly Compact Text-to-Speech Using 1.58-bit Quantization and Weight Indexing, https://arxiv.org/pdf/2506.03515, 2025-06-03
2025-11-09 20:29:28,087 - INFO - root - Page:2, Index:38, ShapeLLM-Omni: A Native Multimodal LLM for 3D Generation and Understanding, https://arxiv.org/pdf/2506.01853, 2025-06-02
2025-11-09 20:29:28,087 - INFO - root - Page:2, Index:39, Movable Antenna Enhanced Federated Fine-Tuning of Large Language Models via Hybrid Client Selection Optimization, https://arxiv.org/pdf/2506.00011, 2025-10-26
2025-11-09 20:29:28,088 - INFO - root - Page:2, Index:40, Running Conventional Automatic Speech Recognition on Memristor Hardware: A Simulated Approach, https://arxiv.org/pdf/2505.24721, 2025-05-30
2025-11-09 20:29:28,088 - INFO - root - Page:2, Index:41, GARLIC: GAussian Representation LearnIng for spaCe partitioning, https://arxiv.org/pdf/2505.24608, 2025-10-02
2025-11-09 20:29:28,088 - INFO - root - Page:2, Index:42, AutoChemSchematic AI: Agentic Physics-Aware Automation for Chemical Manufacturing Scale-Up, https://arxiv.org/pdf/2505.24584, 2025-08-18
2025-11-09 20:29:28,089 - INFO - root - Page:2, Index:43, Model-Preserving Adaptive Rounding, https://arxiv.org/pdf/2505.22988, 2025-09-25
2025-11-09 20:29:28,089 - INFO - root - Page:2, Index:44, Highly Efficient and Effective LLMs with Multi-Boolean Architectures, https://arxiv.org/pdf/2505.22811, 2025-10-03
2025-11-09 20:29:28,089 - INFO - root - Page:2, Index:45, Pioneering 4-Bit FP Quantization for Diffusion Models: Mixup-Sign Quantization and Timestep-Aware Fine-Tuning, https://arxiv.org/pdf/2505.21591, 2025-05-27
2025-11-09 20:29:28,089 - INFO - root - Page:2, Index:46, Frequency Composition for Compressed and Domain-Adaptive Neural Networks, https://arxiv.org/pdf/2505.20890, 2025-05-27
2025-11-09 20:29:28,090 - INFO - root - Page:2, Index:47, MoPFormer: Motion-Primitive Transformer for Wearable-Sensor Activity Recognition, https://arxiv.org/pdf/2505.20744, 2025-10-27
2025-11-09 20:29:28,091 - INFO - root - Page:2, Index:48, Optimizing edge AI models on HPC systems with the edge in the loop, https://arxiv.org/pdf/2505.19995, 2025-05-26
2025-11-09 20:29:28,091 - INFO - root - Fetching page 4 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=150
2025-11-09 20:29:36,313 - INFO - root - get_all_titles_from_web 
2025-11-09 20:29:36,313 - INFO - root - Page:3, Index:0, DPASyn: Mechanism-Aware Drug Synergy Prediction via Dual Attention and Precision-Aware Quantization, https://arxiv.org/pdf/2505.19144, 2025-09-20
2025-11-09 20:29:36,314 - INFO - root - Page:3, Index:1, Reducing Storage of Pretrained Neural Networks by Rate-Constrained Quantization and Entropy Coding, https://arxiv.org/pdf/2505.18758, 2025-05-24
2025-11-09 20:29:36,315 - INFO - root - Page:3, Index:2, Beyond Discreteness: Finite-Sample Analysis of Straight-Through Estimator for Quantization, https://arxiv.org/pdf/2505.18113, 2025-05-23
2025-11-09 20:29:36,315 - INFO - root - Page:3, Index:3, Automating Versatile Time-Series Analysis with Tiny Transformers on Embedded FPGAs, https://arxiv.org/pdf/2505.17662, 2025-09-19
2025-11-09 20:29:36,317 - INFO - root - Page:3, Index:4, FPQVAR: Floating Point Quantization for Visual Autoregressive Model with FPGA Hardware Co-design, https://arxiv.org/pdf/2505.16335, 2025-05-22
2025-11-09 20:29:36,325 - INFO - root - Page:3, Index:5, Saliency-Aware Quantized Imitation Learning for Efficient Robotic Control, https://arxiv.org/pdf/2505.15304, 2025-05-30
2025-11-09 20:29:36,330 - INFO - root - Page:3, Index:6, Scaling Law for Quantization-Aware Training, https://arxiv.org/pdf/2505.14302, 2025-05-20
2025-11-09 20:29:36,341 - INFO - root - Page:3, Index:7, Automatic mixed precision for optimizing gained time with constrained loss mean-squared-error based on model partition to sequential sub-graphs, https://arxiv.org/pdf/2505.13060, 2025-05-19
2025-11-09 20:29:36,344 - INFO - root - Page:3, Index:8, Deep Unfolding with Kernel-based Quantization in MIMO Detection, https://arxiv.org/pdf/2505.12736, 2025-05-19
2025-11-09 20:29:36,344 - INFO - root - Page:3, Index:9, FedHQ: Hybrid Runtime Quantization for Federated Learning, https://arxiv.org/pdf/2505.11982, 2025-05-17
2025-11-09 20:29:36,346 - INFO - root - Page:3, Index:10, QVGen: Pushing the Limit of Quantized Video Generative Models, https://arxiv.org/pdf/2505.11497, 2025-09-27
2025-11-09 20:29:36,347 - INFO - root - Page:3, Index:11, EA-3DGS: Efficient and Adaptive 3D Gaussians with Highly Enhanced Quality for outdoor scenes, https://arxiv.org/pdf/2505.10787, 2025-05-15
2025-11-09 20:29:36,350 - INFO - root - Page:3, Index:12, ITERA-LLM: Boosting Sub-8-Bit Large Language Model Inference via Iterative Tensor Decomposition, https://arxiv.org/pdf/2505.08981, 2025-05-13
2025-11-09 20:29:36,356 - INFO - root - Page:3, Index:13, PROM: Prioritize Reduction of Multiplications Over Lower Bit-Widths for Efficient CNNs, https://arxiv.org/pdf/2505.03254, 2025-08-06
2025-11-09 20:29:36,357 - INFO - root - Page:3, Index:14, ICQuant: Index Coding enables Low-bit LLM Quantization, https://arxiv.org/pdf/2505.00850, 2025-08-24
2025-11-09 20:29:36,360 - INFO - root - Page:3, Index:15, Enhancing Ultra-Low-Bit Quantization of Large Language Models Through Saliency-Aware Partial Retraining, https://arxiv.org/pdf/2504.13932, 2025-07-30
2025-11-09 20:29:36,362 - INFO - root - Page:3, Index:16, Achieving binary weight and activation for LLMs using Post-Training Quantization, https://arxiv.org/pdf/2504.05352, 2025-06-30
2025-11-09 20:29:36,362 - INFO - root - Page:3, Index:17, Wireless Hearables With Programmable Speech AI Accelerators, https://arxiv.org/pdf/2503.18698, 2025-10-21
2025-11-09 20:29:36,373 - INFO - root - Page:3, Index:18, GranQ: Efficient Channel-wise Quantization via Vectorized Pre-Scaling for Zero-Shot QAT, https://arxiv.org/pdf/2503.18339, 2025-10-15
2025-11-09 20:29:36,376 - INFO - root - Page:3, Index:19, CompMarkGS: Robust Watermarking for Compressed 3D Gaussian Splatting, https://arxiv.org/pdf/2503.12836, 2025-09-29
2025-11-09 20:29:36,377 - INFO - root - Page:3, Index:20, AHCPTQ: Accurate and Hardware-Compatible Post-Training Quantization for Segment Anything Model, https://arxiv.org/pdf/2503.03088, 2025-07-11
2025-11-09 20:29:36,379 - INFO - root - Page:3, Index:21, Teaching Metric Distance to Discrete Autoregressive Language Models, https://arxiv.org/pdf/2503.02379, 2025-10-07
2025-11-09 20:29:36,398 - INFO - root - Page:3, Index:22, Regularization-based Framework for Quantization-, Fault- and Variability-Aware Training, https://arxiv.org/pdf/2503.01297, 2025-07-12
2025-11-09 20:29:36,416 - INFO - root - Fetching page 5 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=200
2025-11-09 20:29:43,978 - INFO - root - get_all_titles_from_web 
2025-11-09 20:29:43,978 - INFO - root - Page:4, Index:0, Investigating the Impact of Quantization Methods on the Safety and Reliability of Large Language Models, https://arxiv.org/pdf/2502.15799, 2025-06-29
2025-11-09 20:29:43,979 - INFO - root - Page:4, Index:1, Rotate, Clip, and Partition: Towards W2A4KV4 Quantization by Integrating Rotation and Learnable Non-uniform Quantizer, https://arxiv.org/pdf/2502.15779, 2025-09-01
2025-11-09 20:29:43,979 - INFO - root - Page:4, Index:2, RoSTE: An Efficient Quantization-Aware Supervised Fine-Tuning Approach for Large Language Models, https://arxiv.org/pdf/2502.09003, 2025-06-05
2025-11-09 20:29:43,979 - INFO - root - Page:4, Index:3, Spatial Degradation-Aware and Temporal Consistent Diffusion Model for Compressed Video Super-Resolution, https://arxiv.org/pdf/2502.07381, 2025-06-27
2025-11-09 20:29:43,979 - INFO - root - Page:4, Index:4, QuEST: Stable Training of LLMs with 1-Bit Weights and Activations, https://arxiv.org/pdf/2502.05003, 2025-06-10
2025-11-09 20:29:43,979 - INFO - root - Page:4, Index:5, HALO: Hadamard-Assisted Lower-Precision Optimization for LLMs, https://arxiv.org/pdf/2501.02625, 2025-11-05
2025-11-09 20:29:43,981 - INFO - root - Page:4, Index:6, TAR3D: Creating High-Quality 3D Assets via Next-Part Prediction, https://arxiv.org/pdf/2412.16919, 2025-08-08
2025-11-09 20:29:43,981 - INFO - root - Page:4, Index:7, Training Multi-Layer Binary Neural Networks With Local Binary Error Signals, https://arxiv.org/pdf/2412.00119, 2025-08-05
2025-11-09 20:29:43,981 - INFO - root - Page:4, Index:8, Scaling Large-scale GNN Training to Thousands of Processors on CPU-based Supercomputers, https://arxiv.org/pdf/2411.16025, 2025-05-26
2025-11-09 20:29:43,981 - INFO - root - Page:4, Index:9, HAFLQ: Heterogeneous Adaptive Federated LoRA Fine-tuned LLM with Quantization, https://arxiv.org/pdf/2411.06581, 2025-05-16
2025-11-09 20:29:43,982 - INFO - root - Fetching page 6 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=250
2025-11-09 20:29:50,445 - INFO - root - get_all_titles_from_web 
2025-11-09 20:29:50,446 - INFO - root - Page:5, Index:0, Gradient-Free Training of Quantized Neural Networks, https://arxiv.org/pdf/2410.09734, 2025-09-29
2025-11-09 20:29:50,446 - INFO - root - Page:5, Index:1, QT-DoG: Quantization-aware Training for Domain Generalization, https://arxiv.org/pdf/2410.06020, 2025-06-26
2025-11-09 20:29:50,447 - INFO - root - Page:5, Index:2, Constraint Guided Model Quantization of Neural Networks, https://arxiv.org/pdf/2409.20138, 2025-09-12
2025-11-09 20:29:50,447 - INFO - root - Page:5, Index:3, Accumulator-Aware Post-Training Quantization for Large Language Models, https://arxiv.org/pdf/2409.17092, 2025-07-30
2025-11-09 20:29:50,447 - INFO - root - Page:5, Index:4, DilateQuant: Accurate and Efficient Diffusion Quantization via Weight Dilation, https://arxiv.org/pdf/2409.14307, 2025-07-09
2025-11-09 20:29:50,448 - INFO - root - Page:5, Index:5, Robust Training of Neural Networks at Arbitrary Precision and Sparsity, https://arxiv.org/pdf/2409.09245, 2025-09-23
2025-11-09 20:29:50,448 - INFO - root - Page:5, Index:6, VQ-CTAP: Cross-Modal Fine-Grained Sequence Representation Learning for Speech Processing, https://arxiv.org/pdf/2408.05758, 2025-05-27
2025-11-09 20:29:50,449 - INFO - root - Page:5, Index:7, DopQ-ViT: Towards Distribution-Friendly and Outlier-Aware Post-Training Quantization for Vision Transformers, https://arxiv.org/pdf/2408.03291, 2025-06-19
2025-11-09 20:29:50,451 - INFO - root - Page:5, Index:8, Temporal Feature Matters: A Framework for Diffusion Model Quantization, https://arxiv.org/pdf/2407.19547, 2025-07-11
2025-11-09 20:29:50,451 - INFO - root - Page:5, Index:9, EfficientQAT: Efficient Quantization-Aware Training for Large Language Models, https://arxiv.org/pdf/2407.11062, 2025-05-19
2025-11-09 20:29:50,452 - INFO - root - Page:5, Index:10, Integer-only Quantized Transformers for Embedded FPGA-based Time-series Forecasting in AIoT, https://arxiv.org/pdf/2407.11041, 2025-10-31
2025-11-09 20:29:50,452 - INFO - root - Fetching page 7 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=300
2025-11-09 20:29:57,714 - INFO - root - get_all_titles_from_web 
2025-11-09 20:29:57,715 - INFO - root - Page:6, Index:0, BoA: Attention-aware Post-training Quantization without Backpropagation, https://arxiv.org/pdf/2406.13474, 2025-06-06
2025-11-09 20:29:57,716 - INFO - root - Page:6, Index:1, A Rescaling-Invariant Lipschitz Bound Based on Path-Metrics for Modern ReLU Network Parameterizations, https://arxiv.org/pdf/2405.15006, 2025-06-13
2025-11-09 20:29:57,716 - INFO - root - Page:6, Index:2, Scheduling Weight Transitions for Quantization-Aware Training, https://arxiv.org/pdf/2404.19248, 2025-10-01
2025-11-09 20:29:57,716 - INFO - root - Page:6, Index:3, GPTVQ: The Blessing of Dimensionality for LLM Quantization, https://arxiv.org/pdf/2402.15319, 2025-06-03
2025-11-09 20:29:57,717 - INFO - root - Fetching page 8 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=350
2025-11-09 20:30:06,889 - INFO - root - get_all_titles_from_web 
2025-11-09 20:30:06,891 - INFO - root - Page:7, Index:0, Squat: Quant Small Language Models on the Edge, https://arxiv.org/pdf/2402.10787, 2025-07-01
2025-11-09 20:30:06,892 - INFO - root - Page:7, Index:1, L4Q: Parameter Efficient Quantization-Aware Fine-Tuning on Large Language Models, https://arxiv.org/pdf/2402.04902, 2025-07-21
2025-11-09 20:30:06,893 - INFO - root - Fetching page 9 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=400
2025-11-09 20:30:18,691 - INFO - root - ------------------------------------------------------------------------------------------------------------------------
2025-11-09 20:30:33,568 - INFO - root - 跳过已处理论文 A Quantized VAE-MLP Botnet Detection Model: A Systematic Evaluation of Quantization-Aware Training and Post-Training Quantization Strategies：D:\ChatPaper\academic Papers\Quantization-Aware-Training\A Quantized VAE-MLP Botnet Detection Model_ A Systematic Evaluation of Quantizat-6.pdf
2025-11-09 20:30:33,570 - INFO - root - 跳过已处理论文 FP8-Flow-MoE: A Casting-Free FP8 Recipe without Double Quantization Error：D:\ChatPaper\academic Papers\Quantization-Aware-Training\FP8-Flow-MoE_ A Casting-Free FP8 Recipe without Double Quantization Error-6.pdf
2025-11-09 20:30:33,570 - INFO - root - summary time: 99.85 seconds
2025-11-09 20:41:51,546 - INFO - root - Fetching page 1 with URL: https://arxiv.org/search/?query=traffic+flow+prediction&searchtype=all&abstracts=show&order=-announced_date_first&size=50
2025-11-09 20:41:57,937 - INFO - root - get_all_titles_from_web 
2025-11-09 20:41:57,937 - INFO - root - Page:0, Index:0, A Theoretical Framework for Environmental Similarity and Vessel Mobility as Coupled Predictors of Marine Invasive Species Pathways, https://arxiv.org/pdf/2511.03499, 2025-11-06
2025-11-09 20:41:57,939 - INFO - root - Page:0, Index:1, Towards Sub-millisecond Latency and Guaranteed Bit Rates in 5G User Plane, https://arxiv.org/pdf/2511.00196, 2025-10-31
2025-11-09 20:41:57,939 - INFO - root - Page:0, Index:2, A Cloud-Based Spatio-Temporal GNN-Transformer Hybrid Model for Traffic Flow Forecasting with External Feature Integration, https://arxiv.org/pdf/2510.27039, 2025-10-30
2025-11-09 20:41:57,939 - INFO - root - Page:0, Index:3, Research on Expressway Congestion Warning Technology Based on YOLOv11-DIoU and GRU-Attention, https://arxiv.org/pdf/2509.13361, 2025-11-04
2025-11-09 20:41:57,939 - INFO - root - Fetching page 2 with URL: https://arxiv.org/search/?query=traffic+flow+prediction&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=50
2025-11-09 20:45:14,569 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-09 20:45:14,571 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-09 20:45:14,572 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-09 20:45:15,662 - INFO - root - LLMClientManager: 指定使用客户端: DeepSeek
2025-11-09 20:45:15,663 - WARNING - root - DeepSeekClient: API key not provided. LLM disabled.
2025-11-09 20:45:15,663 - ERROR - root - LLMClientManager: 指定的客户端 DeepSeek 初始化失败
2025-11-09 20:45:15,663 - WARNING - root - LLMClientManager: 指定的客户端 DeepSeek 不可用，将尝试其他客户端
2025-11-09 20:45:16,564 - INFO - root - GeminiClient: trying model gemini-2.5-flash
2025-11-09 20:45:19,999 - INFO - root - GeminiClient: initialized model gemini-2.5-flash
2025-11-09 20:45:20,000 - INFO - root - LLMClientManager: Gemini client initialized successfully
2025-11-09 20:45:20,000 - INFO - root - LLMClientManager: using Gemini as default client
2025-11-09 20:45:20,000 - WARNING - root - KimiClient: API key not provided. LLM disabled.
2025-11-09 20:45:20,001 - WARNING - root - LLMClientManager: Kimi client initialization failed
2025-11-09 20:45:20,001 - WARNING - root - QwenClient: API key not provided. LLM disabled.
2025-11-09 20:45:20,001 - WARNING - root - LLMClientManager: Qwen client initialization failed
2025-11-09 20:45:20,001 - INFO - root - DoubaoClient: API key found: 9f9e270e-b...
2025-11-09 20:45:24,845 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 20:45:24,863 - INFO - root - DoubaoClient: initialized successfully with model doubao-seed-1-6-lite-251015
2025-11-09 20:45:24,863 - INFO - root - LLMClientManager: Doubao client initialized successfully
2025-11-09 20:45:24,864 - WARNING - root - LLMClientManager: client DeepSeek not available
2025-11-09 20:45:24,864 - WARNING - root - 无法切换到指定的客户端 DeepSeek，将使用默认客户端
2025-11-09 20:45:24,864 - INFO - root - 可用客户端: ['Gemini', 'Doubao']
2025-11-09 20:45:24,864 - INFO - root - 使用 LLM 模型: gemini-2.5-flash
2025-11-09 20:45:24,865 - INFO - root - 可用客户端: ['Gemini', 'Doubao']
2025-11-09 20:45:24,866 - INFO - root - === 运行配置 ===
2025-11-09 20:45:24,866 - INFO - root - 处理模式: arxiv在线搜索
2025-11-09 20:45:24,866 - INFO - root - 关键词: QAT
2025-11-09 20:45:24,866 - INFO - root - 查询: Quantization-Aware-Training
2025-11-09 20:45:24,867 - INFO - root - 排序: None
2025-11-09 20:45:24,870 - INFO - root - 最近天数: 180
2025-11-09 20:45:24,871 - INFO - root - 最大处理数量: 2
2025-11-09 20:45:24,872 - INFO - root - 保存图片: 是
2025-11-09 20:45:24,872 - INFO - root - 输出语言: 中文
2025-11-09 20:45:24,872 - INFO - root - 强制重新处理: 否
2025-11-09 20:45:24,873 - INFO - root - ====================
2025-11-09 20:45:24,873 - INFO - root - 使用 arXiv 搜索模式（通过 chat_arxiv 模块获取）
2025-11-09 20:45:24,874 - INFO - root - Fetching page 1 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50
2025-11-09 20:45:32,073 - INFO - root - get_all_titles_from_web 
2025-11-09 20:45:32,074 - INFO - root - Page:0, Index:0, A Quantized VAE-MLP Botnet Detection Model: A Systematic Evaluation of Quantization-Aware Training and Post-Training Quantization Strategies, https://arxiv.org/pdf/2511.03201, 2025-11-05
2025-11-09 20:45:32,074 - INFO - root - Page:0, Index:1, FP8-Flow-MoE: A Casting-Free FP8 Recipe without Double Quantization Error, https://arxiv.org/pdf/2511.02302, 2025-11-04
2025-11-09 20:45:32,074 - INFO - root - Page:0, Index:2, Outlier-Aware Post-Training Quantization for Image Super-Resolution, https://arxiv.org/pdf/2511.00682, 2025-11-01
2025-11-09 20:45:32,074 - INFO - root - Page:0, Index:3, Evaluation of Wafer-Scale SOT-MRAM for Analog Crossbar Array Applications, https://arxiv.org/pdf/2510.25853, 2025-11-03
2025-11-09 20:45:32,074 - INFO - root - Page:0, Index:4, Improving the Straight-Through Estimator with Zeroth-Order Information, https://arxiv.org/pdf/2510.23926, 2025-10-27
2025-11-09 20:45:32,075 - INFO - root - Page:0, Index:5, Real-Time Semantic Segmentation on FPGA for Autonomous Vehicles Using LMIINet with the CGRA4ML Framework, https://arxiv.org/pdf/2510.22243, 2025-10-25
2025-11-09 20:45:32,075 - INFO - root - Page:0, Index:6, TernaryCLIP: Efficiently Compressing Vision-Language Models with Ternary Weights and Distilled Knowledge, https://arxiv.org/pdf/2510.21879, 2025-10-23
2025-11-09 20:45:32,076 - INFO - root - Page:0, Index:7, KARIPAP: Quantum-Inspired Tensor Network Compression of Large Language Models Using Infinite Projected Entangled Pair States and Tensor Renormalization Group, https://arxiv.org/pdf/2510.21844, 2025-10-22
2025-11-09 20:45:32,076 - INFO - root - Page:0, Index:8, A Convergence Analysis of Adaptive Optimizers under Floating-point Quantization, https://arxiv.org/pdf/2510.21314, 2025-10-24
2025-11-09 20:45:32,076 - INFO - root - Page:0, Index:9, Adaptive Distribution-aware Quantization for Mixed-Precision Neural Networks, https://arxiv.org/pdf/2510.19760, 2025-10-22
2025-11-09 20:45:32,076 - INFO - root - Page:0, Index:10, CAGE: Curvature-Aware Gradient Estimation For Accurate Quantization-Aware Training, https://arxiv.org/pdf/2510.18784, 2025-10-21
2025-11-09 20:45:32,078 - INFO - root - Page:0, Index:11, Mixed-Precision Quantization for Language Models: Techniques and Prospects, https://arxiv.org/pdf/2510.16805, 2025-10-19
2025-11-09 20:45:32,078 - INFO - root - Page:0, Index:12, SPLite Hand: Sparsity-Aware Lightweight 3D Hand Pose Estimation, https://arxiv.org/pdf/2510.16396, 2025-10-30
2025-11-09 20:45:32,078 - INFO - root - Page:0, Index:13, CTR-LoRA: Curvature-Aware and Trust-Region Guided Low-Rank Adaptation for Large Language Models, https://arxiv.org/pdf/2510.15962, 2025-10-11
2025-11-09 20:45:32,078 - INFO - root - Page:0, Index:14, SANR: Scene-Aware Neural Representation for Light Field Image Compression with Rate-Distortion Optimization, https://arxiv.org/pdf/2510.15775, 2025-10-17
2025-11-09 20:45:32,079 - INFO - root - Page:0, Index:15, SpikeFit: Towards Optimal Deployment of Spiking Networks on Neuromorphic Hardware, https://arxiv.org/pdf/2510.15542, 2025-10-31
2025-11-09 20:45:32,079 - INFO - root - Page:0, Index:16, GRank: Towards Target-Aware and Streamlined Industrial Retrieval with a Generate-Rank Framework, https://arxiv.org/pdf/2510.15299, 2025-10-17
2025-11-09 20:45:32,080 - INFO - root - Page:0, Index:17, SaLon3R: Structure-aware Long-term Generalizable 3D Reconstruction from Unposed Images, https://arxiv.org/pdf/2510.15072, 2025-10-16
2025-11-09 20:45:32,080 - INFO - root - Page:0, Index:18, FraQAT: Quantization Aware Training with Fractional bits, https://arxiv.org/pdf/2510.14823, 2025-10-16
2025-11-09 20:45:32,080 - INFO - root - Page:0, Index:19, Computing-In-Memory Aware Model Adaption For Edge Devices, https://arxiv.org/pdf/2510.14379, 2025-10-16
2025-11-09 20:45:32,080 - INFO - root - Page:0, Index:20, Invited Paper: BitMedViT: Ternary-Quantized Vision Transformer for Medical AI Assistants on the Edge, https://arxiv.org/pdf/2510.13760, 2025-11-04
2025-11-09 20:45:32,082 - INFO - root - Page:0, Index:21, NeuroRVQ: Multi-Scale EEG Tokenization for Generative Large Brainwave Models, https://arxiv.org/pdf/2510.13068, 2025-10-14
2025-11-09 20:45:32,082 - INFO - root - Page:0, Index:22, Detect Anything via Next Point Prediction, https://arxiv.org/pdf/2510.12798, 2025-10-14
2025-11-09 20:45:32,082 - INFO - root - Page:0, Index:23, AndesVL Technical Report: An Efficient Mobile-side Multimodal Large Language Model, https://arxiv.org/pdf/2510.11496, 2025-10-14
2025-11-09 20:45:32,085 - INFO - root - Page:0, Index:24, Rescaling-Aware Training for Efficient Deployment of Deep Learning Models on Full-Integer Hardware, https://arxiv.org/pdf/2510.11484, 2025-10-13
2025-11-09 20:45:32,085 - INFO - root - Page:0, Index:25, SASER: Stego attacks on open-source LLMs, https://arxiv.org/pdf/2510.10486, 2025-10-12
2025-11-09 20:45:32,085 - INFO - root - Page:0, Index:26, Ultralytics YOLO Evolution: An Overview of YOLO26, YOLO11, YOLOv8 and YOLOv5 Object Detectors for Computer Vision and Pattern Recognition, https://arxiv.org/pdf/2510.09653, 2025-10-15
2025-11-09 20:45:32,086 - INFO - root - Page:0, Index:27, A Theoretically-Grounded Codebook for Digital Semantic Communications, https://arxiv.org/pdf/2510.07108, 2025-10-14
2025-11-09 20:45:32,086 - INFO - root - Page:0, Index:28, QuantDemoire: Quantization with Outlier Aware for Image Demoiréing, https://arxiv.org/pdf/2510.04066, 2025-10-05
2025-11-09 20:45:32,087 - INFO - root - Page:0, Index:29, Adaptively Sampling-Reusing-Mixing Decomposed Gradients to Speed Up Sharpness Aware Minimization, https://arxiv.org/pdf/2510.03763, 2025-10-04
2025-11-09 20:45:32,088 - INFO - root - Page:0, Index:30, Quant-dLLM: Post-Training Extreme Low-Bit Quantization for Diffusion Large Language Models, https://arxiv.org/pdf/2510.03274, 2025-09-27
2025-11-09 20:45:32,090 - INFO - root - Page:0, Index:31, PT$^2$-LLM: Post-Training Ternarization for Large Language Models, https://arxiv.org/pdf/2510.03267, 2025-09-26
2025-11-09 20:45:32,095 - INFO - root - Page:0, Index:32, Purrception: Variational Flow Matching for Vector-Quantized Image Generation, https://arxiv.org/pdf/2510.01478, 2025-10-01
2025-11-09 20:45:32,095 - INFO - root - Page:0, Index:33, Post-Training Quantization for Audio Diffusion Transformers, https://arxiv.org/pdf/2510.00313, 2025-09-30
2025-11-09 20:45:32,096 - INFO - root - Page:0, Index:34, Rethinking RoPE Scaling in Quantized LLM: Theory, Outlier, and Channel-Band Analysis with Weight Rescaling, https://arxiv.org/pdf/2510.00028, 2025-09-25
2025-11-09 20:45:32,096 - INFO - root - Page:0, Index:35, Post-Training Quantization via Residual Truncation and Zero Suppression for Diffusion Models, https://arxiv.org/pdf/2509.26436, 2025-09-30
2025-11-09 20:45:32,096 - INFO - root - Page:0, Index:36, Cat: Post-Training Quantization Error Reduction via Cluster-based Affine Transformation, https://arxiv.org/pdf/2509.26277, 2025-10-07
2025-11-09 20:45:32,097 - INFO - root - Page:0, Index:37, CAST: Continuous and Differentiable Semi-Structured Sparsity-Aware Training for Large Language Models, https://arxiv.org/pdf/2509.25996, 2025-09-30
2025-11-09 20:45:32,097 - INFO - root - Page:0, Index:38, Norm-Q: Effective Compression Method for Hidden Markov Models in Neuro-Symbolic Applications, https://arxiv.org/pdf/2509.25439, 2025-09-29
2025-11-09 20:45:32,097 - INFO - root - Page:0, Index:39, On-the-Fly Adaptation to Quantization: Configuration-Aware LoRA for Efficient Fine-Tuning of Quantized LLMs, https://arxiv.org/pdf/2509.25214, 2025-09-22
2025-11-09 20:45:32,098 - INFO - root - Page:0, Index:40, VoxCPM: Tokenizer-Free TTS for Context-Aware Speech Generation and True-to-Life Voice Cloning, https://arxiv.org/pdf/2509.24650, 2025-09-29
2025-11-09 20:45:32,098 - INFO - root - Page:0, Index:41, S$^2$NN: Sub-bit Spiking Neural Networks, https://arxiv.org/pdf/2509.24266, 2025-10-24
2025-11-09 20:45:32,101 - INFO - root - Page:0, Index:42, Tequila: Trapping-free Ternary Quantization for Large Language Models, https://arxiv.org/pdf/2509.23809, 2025-10-17
2025-11-09 20:45:32,103 - INFO - root - Page:0, Index:43, Texture Vector-Quantization and Reconstruction Aware Prediction for Generative Super-Resolution, https://arxiv.org/pdf/2509.23774, 2025-09-30
2025-11-09 20:45:32,103 - INFO - root - Page:0, Index:44, RobuQ: Pushing DiTs to W1.58A2 via Robust Activation Quantization, https://arxiv.org/pdf/2509.23582, 2025-09-27
2025-11-09 20:45:32,103 - INFO - root - Page:0, Index:45, Beyond Outliers: A Study of Optimizers Under Quantization, https://arxiv.org/pdf/2509.23500, 2025-10-02
2025-11-09 20:45:32,104 - INFO - root - Page:0, Index:46, Compute-Optimal Quantization-Aware Training, https://arxiv.org/pdf/2509.22935, 2025-09-26
2025-11-09 20:45:32,104 - INFO - root - Page:0, Index:47, COSPADI: Compressing LLMs via Calibration-Guided Sparse Dictionary Learning, https://arxiv.org/pdf/2509.22075, 2025-10-06
2025-11-09 20:45:32,105 - INFO - root - Page:0, Index:48, SlimDiff: Training-Free, Activation-Guided Hands-free Slimming of Diffusion Models, https://arxiv.org/pdf/2509.21498, 2025-09-25
2025-11-09 20:45:32,105 - INFO - root - Page:0, Index:49, Quantized Visual Geometry Grounded Transformer, https://arxiv.org/pdf/2509.21302, 2025-09-29
2025-11-09 20:45:32,105 - INFO - root - Fetching page 2 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=50
2025-11-09 20:45:39,008 - INFO - root - get_all_titles_from_web 
2025-11-09 20:45:39,009 - INFO - root - Page:1, Index:0, Can Less Precise Be More Reliable? A Systematic Evaluation of Quantization's Impact on CLIP Beyond Accuracy, https://arxiv.org/pdf/2509.21173, 2025-10-27
2025-11-09 20:45:39,009 - INFO - root - Page:1, Index:1, Punching Above Precision: Small Quantized Model Distillation with Learnable Regularizer, https://arxiv.org/pdf/2509.20854, 2025-09-25
2025-11-09 20:45:39,009 - INFO - root - Page:1, Index:2, TinyEcoWeedNet: Edge Efficient Real-Time Aerial Agricultural Weed Detection, https://arxiv.org/pdf/2509.18193, 2025-09-19
2025-11-09 20:45:39,009 - INFO - root - Page:1, Index:3, SBVR: Summation of BitVector Representation for Efficient LLM Quantization, https://arxiv.org/pdf/2509.18172, 2025-09-17
2025-11-09 20:45:39,010 - INFO - root - Page:1, Index:4, QWHA: Quantization-Aware Walsh-Hadamard Adaptation for Parameter-Efficient Fine-Tuning on Large Language Models, https://arxiv.org/pdf/2509.17428, 2025-09-26
2025-11-09 20:45:39,010 - INFO - root - Page:1, Index:5, PTQTP: Post-Training Quantization to Trit-Planes for Large Language Models, https://arxiv.org/pdf/2509.16989, 2025-10-28
2025-11-09 20:45:39,010 - INFO - root - Page:1, Index:6, MEC-Quant: Maximum Entropy Coding for Extremely Low Bit Quantization-Aware Training, https://arxiv.org/pdf/2509.15514, 2025-09-18
2025-11-09 20:45:39,011 - INFO - root - Page:1, Index:7, Q-ROAR: Outlier-Aware Rescaling for RoPE Position Interpolation in Quantized Long-Context LLMs, https://arxiv.org/pdf/2509.14391, 2025-09-17
2025-11-09 20:45:39,011 - INFO - root - Page:1, Index:8, Efficient Quantization-Aware Neural Receivers: Beyond Post-Training Quantization, https://arxiv.org/pdf/2509.13786, 2025-09-19
2025-11-09 20:45:39,011 - INFO - root - Page:1, Index:9, Rate-Distortion Limits for Multimodal Retrieval: Theory, Optimal Codes, and Finite-Sample Guarantees, https://arxiv.org/pdf/2509.11054, 2025-09-13
2025-11-09 20:45:39,012 - INFO - root - Page:1, Index:10, SQAP-VLA: A Synergistic Quantization-Aware Pruning Framework for High-Performance Vision-Language-Action Models, https://arxiv.org/pdf/2509.09090, 2025-09-10
2025-11-09 20:45:39,012 - INFO - root - Page:1, Index:11, CSI Compression Beyond Latents: End-to-End Hybrid Attention-CNN Networks with Entropy Regularization, https://arxiv.org/pdf/2509.08776, 2025-09-10
2025-11-09 20:45:39,012 - INFO - root - Page:1, Index:12, Explaining How Quantization Disparately Skews a Model, https://arxiv.org/pdf/2509.07222, 2025-09-08
2025-11-09 20:45:39,012 - INFO - root - Page:1, Index:13, LoaQ: Layer-wise Output Approximation Quantization, https://arxiv.org/pdf/2509.06297, 2025-09-07
2025-11-09 20:45:39,012 - INFO - root - Page:1, Index:14, FineServe: Precision-Aware KV Slab and Two-Level Scheduling for Heterogeneous Precision LLM Serving, https://arxiv.org/pdf/2509.06261, 2025-09-14
2025-11-09 20:45:39,014 - INFO - root - Page:1, Index:15, Sensitivity-Aware Post-Training Quantization for Deep Neural Networks, https://arxiv.org/pdf/2509.05576, 2025-09-05
2025-11-09 20:45:39,014 - INFO - root - Page:1, Index:16, SuperSNN: A Hardware-Aware Framework for Physically Realizable, High-Performance Superconducting Spiking Neural Network Chips, https://arxiv.org/pdf/2509.05532, 2025-09-05
2025-11-09 20:45:39,014 - INFO - root - Page:1, Index:17, Data-Augmented Quantization-Aware Knowledge Distillation, https://arxiv.org/pdf/2509.03850, 2025-09-03
2025-11-09 20:45:39,015 - INFO - root - Page:1, Index:18, DPQuant: Efficient and Differentially-Private Model Training via Dynamic Quantization Scheduling, https://arxiv.org/pdf/2509.03472, 2025-09-03
2025-11-09 20:45:39,015 - INFO - root - Page:1, Index:19, Empowering Large Language Model for Sequential Recommendation via Multimodal Embeddings and Semantic IDs, https://arxiv.org/pdf/2509.02017, 2025-09-02
2025-11-09 20:45:39,016 - INFO - root - Page:1, Index:20, Q-Sched: Pushing the Boundaries of Few-Step Diffusion Models with Quantization-Aware Scheduling, https://arxiv.org/pdf/2509.01624, 2025-09-01
2025-11-09 20:45:39,016 - INFO - root - Page:1, Index:21, Quantization Meets OOD: Generalizable Quantization-aware Training from a Flatness Perspective, https://arxiv.org/pdf/2509.00859, 2025-08-31
2025-11-09 20:45:39,017 - INFO - root - Page:1, Index:22, Progressive Element-wise Gradient Estimation for Neural Network Quantization, https://arxiv.org/pdf/2509.00097, 2025-08-27
2025-11-09 20:45:39,017 - INFO - root - Page:1, Index:23, End-to-End On-Device Quantization-Aware Training for LLMs at Inference Cost, https://arxiv.org/pdf/2509.00031, 2025-09-29
2025-11-09 20:45:39,018 - INFO - root - Page:1, Index:24, Quantization Robustness to Input Degradations for Object Detection, https://arxiv.org/pdf/2508.19600, 2025-08-27
2025-11-09 20:45:39,019 - INFO - root - Page:1, Index:25, Scaling Laws for Task-Stratified Knowledge in Post-Training Quantized Large Language Models, https://arxiv.org/pdf/2508.18609, 2025-08-27
2025-11-09 20:45:39,019 - INFO - root - Page:1, Index:26, AQ-PCDSys: An Adaptive Quantized Planetary Crater Detection System for Autonomous Space Exploration, https://arxiv.org/pdf/2508.18025, 2025-08-25
2025-11-09 20:45:39,019 - INFO - root - Page:1, Index:27, TaDiCodec: Text-aware Diffusion Speech Tokenizer for Speech Language Modeling, https://arxiv.org/pdf/2508.16790, 2025-08-22
2025-11-09 20:45:39,020 - INFO - root - Page:1, Index:28, A Node-Aware Dynamic Quantization Approach for Graph Collaborative Filtering, https://arxiv.org/pdf/2508.16516, 2025-08-22
2025-11-09 20:45:39,020 - INFO - root - Page:1, Index:29, JEDI-linear: Fast and Efficient Graph Neural Networks for Jet Tagging on FPGAs, https://arxiv.org/pdf/2508.15468, 2025-08-21
2025-11-09 20:45:39,020 - INFO - root - Page:1, Index:30, MMQ: Multimodal Mixture-of-Quantization Tokenization for Semantic ID Generation and User Behavioral Adaptation, https://arxiv.org/pdf/2508.15281, 2025-08-21
2025-11-09 20:45:39,020 - INFO - root - Page:1, Index:31, DLLMQuant: Quantizing Diffusion-based Large Language Models, https://arxiv.org/pdf/2508.14090, 2025-08-25
2025-11-09 20:45:39,021 - INFO - root - Page:1, Index:32, Automated Energy-Aware Time-Series Model Deployment on Embedded FPGAs for Resilient Combined Sewer Overflow Management, https://arxiv.org/pdf/2508.13905, 2025-08-19
2025-11-09 20:45:39,021 - INFO - root - Page:1, Index:33, XR-NPE: High-Throughput Mixed-precision SIMD Neural Processing Engine for Extended Reality Perception Workloads, https://arxiv.org/pdf/2508.13049, 2025-08-18
2025-11-09 20:45:39,023 - INFO - root - Page:1, Index:34, Exploring Self-Supervised Audio Models for Generalized Anomalous Sound Detection, https://arxiv.org/pdf/2508.12230, 2025-08-17
2025-11-09 20:45:39,025 - INFO - root - Page:1, Index:35, TriQDef: Disrupting Semantic and Gradient Alignment to Prevent Adversarial Patch Transferability in Quantized Neural Networks, https://arxiv.org/pdf/2508.12132, 2025-08-16
2025-11-09 20:45:39,026 - INFO - root - Page:1, Index:36, Error Propagation Mechanisms and Compensation Strategies for Quantized Diffusion, https://arxiv.org/pdf/2508.12094, 2025-10-13
2025-11-09 20:45:39,026 - INFO - root - Page:1, Index:37, Extending Straight-Through Estimation for Robust Neural Networks on Analog CIM Hardware, https://arxiv.org/pdf/2508.11940, 2025-08-16
2025-11-09 20:45:39,026 - INFO - root - Page:1, Index:38, PTQAT: A Hybrid Parameter-Efficient Quantization Algorithm for 3D Perception Tasks, https://arxiv.org/pdf/2508.10557, 2025-08-15
2025-11-09 20:45:39,027 - INFO - root - Page:1, Index:39, MiCo: End-to-End Mixed Precision Neural Network Co-Exploration Framework for Edge AI, https://arxiv.org/pdf/2508.09500, 2025-08-13
2025-11-09 20:45:39,027 - INFO - root - Page:1, Index:40, SPARC: Soft Probabilistic Adaptive multi-interest Retrieval Model via Codebooks for recommender system, https://arxiv.org/pdf/2508.09090, 2025-08-12
2025-11-09 20:45:39,027 - INFO - root - Page:1, Index:41, Rethinking 1-bit Optimization Leveraging Pre-trained Large Language Models, https://arxiv.org/pdf/2508.06974, 2025-08-09
2025-11-09 20:45:39,027 - INFO - root - Page:1, Index:42, Efficient Deep Neural Receiver with Post-Training Quantization, https://arxiv.org/pdf/2508.06275, 2025-08-08
2025-11-09 20:45:39,028 - INFO - root - Page:1, Index:43, iFairy: the First 2-bit Complex LLM with All Parameters in $\{\pm1, \pm i\}$, https://arxiv.org/pdf/2508.05571, 2025-08-16
2025-11-09 20:45:39,028 - INFO - root - Page:1, Index:44, S$^2$Q-VDiT: Accurate Quantized Video Diffusion Transformer with Salient Data and Sparse Token Distillation, https://arxiv.org/pdf/2508.04016, 2025-10-27
2025-11-09 20:45:39,028 - INFO - root - Page:1, Index:45, LRQ-DiT: Log-Rotation Post-Training Quantization of Diffusion Transformers for Image and Video Generation, https://arxiv.org/pdf/2508.03485, 2025-09-23
2025-11-09 20:45:39,030 - INFO - root - Page:1, Index:46, VLMQ: Efficient Post-Training Quantization for Large Vision-Language Models via Hessian Augmentation, https://arxiv.org/pdf/2508.03351, 2025-08-05
2025-11-09 20:45:39,030 - INFO - root - Page:1, Index:47, TF-MLPNet: Tiny Real-Time Neural Speech Separation, https://arxiv.org/pdf/2508.03047, 2025-08-04
2025-11-09 20:45:39,030 - INFO - root - Page:1, Index:48, SaviorRec: Semantic-Behavior Alignment for Cold-Start Recommendation, https://arxiv.org/pdf/2508.01375, 2025-08-02
2025-11-09 20:45:39,031 - INFO - root - Page:1, Index:49, MixA-Q: Revisiting Activation Sparsity for Vision Transformers from a Mixed-Precision Quantization Perspective, https://arxiv.org/pdf/2507.19131, 2025-07-25
2025-11-09 20:45:39,031 - INFO - root - Fetching page 3 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=100
2025-11-09 20:45:46,283 - INFO - root - get_all_titles_from_web 
2025-11-09 20:45:46,283 - INFO - root - Page:2, Index:0, Enhancing Quantization-Aware Training on Edge Devices via Relative Entropy Coreset Selection and Cascaded Layer Correction, https://arxiv.org/pdf/2507.17768, 2025-07-16
2025-11-09 20:45:46,284 - INFO - root - Page:2, Index:1, SiLQ: Simple Large Language Model Quantization-Aware Training, https://arxiv.org/pdf/2507.16933, 2025-07-22
2025-11-09 20:45:46,284 - INFO - root - Page:2, Index:2, Task-Specific Zero-shot Quantization-Aware Training for Object Detection, https://arxiv.org/pdf/2507.16782, 2025-07-22
2025-11-09 20:45:46,284 - INFO - root - Page:2, Index:3, TorchAO: PyTorch-Native Training-to-Serving Model Optimization, https://arxiv.org/pdf/2507.16099, 2025-07-21
2025-11-09 20:45:46,284 - INFO - root - Page:2, Index:4, SegQuant: A Semantics-Aware and Generalizable Quantization Framework for Diffusion Models, https://arxiv.org/pdf/2507.14811, 2025-08-27
2025-11-09 20:45:46,285 - INFO - root - Page:2, Index:5, Apple Intelligence Foundation Language Models: Tech Report 2025, https://arxiv.org/pdf/2507.13575, 2025-08-27
2025-11-09 20:45:46,285 - INFO - root - Page:2, Index:6, Generative Multi-Target Cross-Domain Recommendation, https://arxiv.org/pdf/2507.12871, 2025-08-07
2025-11-09 20:45:46,285 - INFO - root - Page:2, Index:7, DAF: An Efficient End-to-End Dynamic Activation Framework for on-Device DNN Training, https://arxiv.org/pdf/2507.07149, 2025-07-09
2025-11-09 20:45:46,285 - INFO - root - Page:2, Index:8, Opto-ViT: Architecting a Near-Sensor Region of Interest-Aware Vision Transformer Accelerator with Silicon Photonics, https://arxiv.org/pdf/2507.07044, 2025-07-15
2025-11-09 20:45:46,285 - INFO - root - Page:2, Index:9, QS4D: Quantization-aware training for efficient hardware deployment of structured state-space sequential models, https://arxiv.org/pdf/2507.06079, 2025-07-08
2025-11-09 20:45:46,286 - INFO - root - Page:2, Index:10, GSVR: 2D Gaussian-based Video Representation for 800+ FPS with Hybrid Deformation Field, https://arxiv.org/pdf/2507.05594, 2025-07-07
2025-11-09 20:45:46,290 - INFO - root - Page:2, Index:11, Hita: Holistic Tokenizer for Autoregressive Image Generation, https://arxiv.org/pdf/2507.02358, 2025-07-11
2025-11-09 20:45:46,291 - INFO - root - Page:2, Index:12, QPART: Adaptive Model Quantization and Dynamic Workload Balancing for Accuracy-aware Edge Inference, https://arxiv.org/pdf/2506.23934, 2025-06-30
2025-11-09 20:45:46,291 - INFO - root - Page:2, Index:13, FedWSQ: Efficient Federated Learning with Weight Standardization and Distribution-Aware Non-Uniform Quantization, https://arxiv.org/pdf/2506.23516, 2025-07-21
2025-11-09 20:45:46,292 - INFO - root - Page:2, Index:14, Spectra 1.1: Scaling Laws and Efficient Inference for Ternary Language Models, https://arxiv.org/pdf/2506.23025, 2025-06-28
2025-11-09 20:45:46,296 - INFO - root - Page:2, Index:15, Joint Quantization and Pruning Neural Networks Approach: A Case Study on FSO Receivers, https://arxiv.org/pdf/2506.20084, 2025-06-24
2025-11-09 20:45:46,297 - INFO - root - Page:2, Index:16, Single-step Diffusion for Image Compression at Ultra-Low Bitrates, https://arxiv.org/pdf/2506.16572, 2025-09-22
2025-11-09 20:45:46,298 - INFO - root - Page:2, Index:17, LittleBit: Ultra Low-Bit Quantization via Latent Factorization, https://arxiv.org/pdf/2506.13771, 2025-10-28
2025-11-09 20:45:46,298 - INFO - root - Page:2, Index:18, MARCO: Hardware-Aware Neural Architecture Search for Edge Devices with Multi-Agent Reinforcement Learning and Conformal Prediction Filtering, https://arxiv.org/pdf/2506.13755, 2025-06-16
2025-11-09 20:45:46,298 - INFO - root - Page:2, Index:19, EAQuant: Enhancing Post-Training Quantization for MoE Models via Expert-Aware Optimization, https://arxiv.org/pdf/2506.13329, 2025-07-04
2025-11-09 20:45:46,299 - INFO - root - Page:2, Index:20, Towards Neural Audio Codec Source Parsing, https://arxiv.org/pdf/2506.12627, 2025-06-14
2025-11-09 20:45:46,299 - INFO - root - Page:2, Index:21, Quantizing Small-Scale State-Space Models for Edge AI, https://arxiv.org/pdf/2506.12480, 2025-06-14
2025-11-09 20:45:46,299 - INFO - root - Page:2, Index:22, EMLoC: Emulator-based Memory-efficient Fine-tuning with LoRA Correction, https://arxiv.org/pdf/2506.12015, 2025-06-13
2025-11-09 20:45:46,300 - INFO - root - Page:2, Index:23, Compression Aware Certified Training, https://arxiv.org/pdf/2506.11992, 2025-06-13
2025-11-09 20:45:46,300 - INFO - root - Page:2, Index:24, GPLQ: A General, Practical, and Lightning QAT Method for Vision Transformers, https://arxiv.org/pdf/2506.11784, 2025-06-13
2025-11-09 20:45:46,300 - INFO - root - Page:2, Index:25, TruncQuant: Truncation-Ready Quantization for DNNs with Flexible Weight Bit Precision, https://arxiv.org/pdf/2506.11431, 2025-06-12
2025-11-09 20:45:46,300 - INFO - root - Page:2, Index:26, EfficientQuant: An Efficient Post-Training Quantization for CNN-Transformer Hybrid Models on Edge Devices, https://arxiv.org/pdf/2506.11093, 2025-06-05
2025-11-09 20:45:46,302 - INFO - root - Page:2, Index:27, Starting Positions Matter: A Study on Better Weight Initialization for Neural Network Quantization, https://arxiv.org/pdf/2506.10463, 2025-06-12
2025-11-09 20:45:46,303 - INFO - root - Page:2, Index:28, AWP: Activation-Aware Weight Pruning and Quantization with Projected Gradient Descent, https://arxiv.org/pdf/2506.10205, 2025-06-11
2025-11-09 20:45:46,304 - INFO - root - Page:2, Index:29, Q-SAM2: Accurate Quantization for Segment Anything Model 2, https://arxiv.org/pdf/2506.09782, 2025-06-11
2025-11-09 20:45:46,304 - INFO - root - Page:2, Index:30, Unifying Block-wise PTQ and Distillation-based QAT for Progressive Quantization toward 2-bit Instruction-Tuned LLMs, https://arxiv.org/pdf/2506.09104, 2025-06-10
2025-11-09 20:45:46,304 - INFO - root - Page:2, Index:31, Implementing Keyword Spotting on the MCUX947 Microcontroller with Integrated NPU, https://arxiv.org/pdf/2506.08911, 2025-06-10
2025-11-09 20:45:46,304 - INFO - root - Page:2, Index:32, POLARON: Precision-aware On-device Learning and Adaptive Runtime-cONfigurable AI acceleration, https://arxiv.org/pdf/2506.08785, 2025-06-10
2025-11-09 20:45:46,306 - INFO - root - Page:2, Index:33, MoQAE: Mixed-Precision Quantization for Long-Context LLM Inference via Mixture of Quantization-Aware Experts, https://arxiv.org/pdf/2506.07533, 2025-06-09
2025-11-09 20:45:46,306 - INFO - root - Page:2, Index:34, BitVLA: 1-bit Vision-Language-Action Models for Robotics Manipulation, https://arxiv.org/pdf/2506.07530, 2025-06-09
2025-11-09 20:45:46,308 - INFO - root - Page:2, Index:35, RecGPT: A Foundation Model for Sequential Recommendation, https://arxiv.org/pdf/2506.06270, 2025-06-12
2025-11-09 20:45:46,309 - INFO - root - Page:2, Index:36, FPSAttention: Training-Aware FP8 and Sparsity Co-Design for Fast Video Diffusion, https://arxiv.org/pdf/2506.04648, 2025-06-05
2025-11-09 20:45:46,309 - INFO - root - Page:2, Index:37, BitTTS: Highly Compact Text-to-Speech Using 1.58-bit Quantization and Weight Indexing, https://arxiv.org/pdf/2506.03515, 2025-06-03
2025-11-09 20:45:46,311 - INFO - root - Page:2, Index:38, ShapeLLM-Omni: A Native Multimodal LLM for 3D Generation and Understanding, https://arxiv.org/pdf/2506.01853, 2025-06-02
2025-11-09 20:45:46,311 - INFO - root - Page:2, Index:39, Movable Antenna Enhanced Federated Fine-Tuning of Large Language Models via Hybrid Client Selection Optimization, https://arxiv.org/pdf/2506.00011, 2025-10-26
2025-11-09 20:45:46,311 - INFO - root - Page:2, Index:40, Running Conventional Automatic Speech Recognition on Memristor Hardware: A Simulated Approach, https://arxiv.org/pdf/2505.24721, 2025-05-30
2025-11-09 20:45:46,312 - INFO - root - Page:2, Index:41, GARLIC: GAussian Representation LearnIng for spaCe partitioning, https://arxiv.org/pdf/2505.24608, 2025-10-02
2025-11-09 20:45:46,312 - INFO - root - Page:2, Index:42, AutoChemSchematic AI: Agentic Physics-Aware Automation for Chemical Manufacturing Scale-Up, https://arxiv.org/pdf/2505.24584, 2025-08-18
2025-11-09 20:45:46,312 - INFO - root - Page:2, Index:43, Model-Preserving Adaptive Rounding, https://arxiv.org/pdf/2505.22988, 2025-09-25
2025-11-09 20:45:46,312 - INFO - root - Page:2, Index:44, Highly Efficient and Effective LLMs with Multi-Boolean Architectures, https://arxiv.org/pdf/2505.22811, 2025-10-03
2025-11-09 20:45:46,314 - INFO - root - Page:2, Index:45, Pioneering 4-Bit FP Quantization for Diffusion Models: Mixup-Sign Quantization and Timestep-Aware Fine-Tuning, https://arxiv.org/pdf/2505.21591, 2025-05-27
2025-11-09 20:45:46,317 - INFO - root - Page:2, Index:46, Frequency Composition for Compressed and Domain-Adaptive Neural Networks, https://arxiv.org/pdf/2505.20890, 2025-05-27
2025-11-09 20:45:46,319 - INFO - root - Page:2, Index:47, MoPFormer: Motion-Primitive Transformer for Wearable-Sensor Activity Recognition, https://arxiv.org/pdf/2505.20744, 2025-10-27
2025-11-09 20:45:46,320 - INFO - root - Page:2, Index:48, Optimizing edge AI models on HPC systems with the edge in the loop, https://arxiv.org/pdf/2505.19995, 2025-05-26
2025-11-09 20:45:46,320 - INFO - root - Fetching page 4 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=150
2025-11-09 20:45:53,377 - INFO - root - get_all_titles_from_web 
2025-11-09 20:45:53,377 - INFO - root - Page:3, Index:0, DPASyn: Mechanism-Aware Drug Synergy Prediction via Dual Attention and Precision-Aware Quantization, https://arxiv.org/pdf/2505.19144, 2025-09-20
2025-11-09 20:45:53,377 - INFO - root - Page:3, Index:1, Reducing Storage of Pretrained Neural Networks by Rate-Constrained Quantization and Entropy Coding, https://arxiv.org/pdf/2505.18758, 2025-05-24
2025-11-09 20:45:53,380 - INFO - root - Page:3, Index:2, Beyond Discreteness: Finite-Sample Analysis of Straight-Through Estimator for Quantization, https://arxiv.org/pdf/2505.18113, 2025-05-23
2025-11-09 20:45:53,381 - INFO - root - Page:3, Index:3, Automating Versatile Time-Series Analysis with Tiny Transformers on Embedded FPGAs, https://arxiv.org/pdf/2505.17662, 2025-09-19
2025-11-09 20:45:53,382 - INFO - root - Page:3, Index:4, FPQVAR: Floating Point Quantization for Visual Autoregressive Model with FPGA Hardware Co-design, https://arxiv.org/pdf/2505.16335, 2025-05-22
2025-11-09 20:45:53,383 - INFO - root - Page:3, Index:5, Saliency-Aware Quantized Imitation Learning for Efficient Robotic Control, https://arxiv.org/pdf/2505.15304, 2025-05-30
2025-11-09 20:45:53,383 - INFO - root - Page:3, Index:6, Scaling Law for Quantization-Aware Training, https://arxiv.org/pdf/2505.14302, 2025-05-20
2025-11-09 20:45:53,387 - INFO - root - Page:3, Index:7, Automatic mixed precision for optimizing gained time with constrained loss mean-squared-error based on model partition to sequential sub-graphs, https://arxiv.org/pdf/2505.13060, 2025-05-19
2025-11-09 20:45:53,393 - INFO - root - Page:3, Index:8, Deep Unfolding with Kernel-based Quantization in MIMO Detection, https://arxiv.org/pdf/2505.12736, 2025-05-19
2025-11-09 20:45:53,396 - INFO - root - Page:3, Index:9, FedHQ: Hybrid Runtime Quantization for Federated Learning, https://arxiv.org/pdf/2505.11982, 2025-05-17
2025-11-09 20:45:53,396 - INFO - root - Page:3, Index:10, QVGen: Pushing the Limit of Quantized Video Generative Models, https://arxiv.org/pdf/2505.11497, 2025-09-27
2025-11-09 20:45:53,401 - INFO - root - Page:3, Index:11, EA-3DGS: Efficient and Adaptive 3D Gaussians with Highly Enhanced Quality for outdoor scenes, https://arxiv.org/pdf/2505.10787, 2025-05-15
2025-11-09 20:45:53,402 - INFO - root - Page:3, Index:12, ITERA-LLM: Boosting Sub-8-Bit Large Language Model Inference via Iterative Tensor Decomposition, https://arxiv.org/pdf/2505.08981, 2025-05-13
2025-11-09 20:45:53,403 - INFO - root - Page:3, Index:13, PROM: Prioritize Reduction of Multiplications Over Lower Bit-Widths for Efficient CNNs, https://arxiv.org/pdf/2505.03254, 2025-08-06
2025-11-09 20:45:53,404 - INFO - root - Page:3, Index:14, ICQuant: Index Coding enables Low-bit LLM Quantization, https://arxiv.org/pdf/2505.00850, 2025-08-24
2025-11-09 20:45:53,404 - INFO - root - Page:3, Index:15, Enhancing Ultra-Low-Bit Quantization of Large Language Models Through Saliency-Aware Partial Retraining, https://arxiv.org/pdf/2504.13932, 2025-07-30
2025-11-09 20:45:53,405 - INFO - root - Page:3, Index:16, Achieving binary weight and activation for LLMs using Post-Training Quantization, https://arxiv.org/pdf/2504.05352, 2025-06-30
2025-11-09 20:45:53,423 - INFO - root - Page:3, Index:17, Wireless Hearables With Programmable Speech AI Accelerators, https://arxiv.org/pdf/2503.18698, 2025-10-21
2025-11-09 20:45:53,424 - INFO - root - Page:3, Index:18, GranQ: Efficient Channel-wise Quantization via Vectorized Pre-Scaling for Zero-Shot QAT, https://arxiv.org/pdf/2503.18339, 2025-10-15
2025-11-09 20:45:53,425 - INFO - root - Page:3, Index:19, CompMarkGS: Robust Watermarking for Compressed 3D Gaussian Splatting, https://arxiv.org/pdf/2503.12836, 2025-09-29
2025-11-09 20:45:53,426 - INFO - root - Page:3, Index:20, AHCPTQ: Accurate and Hardware-Compatible Post-Training Quantization for Segment Anything Model, https://arxiv.org/pdf/2503.03088, 2025-07-11
2025-11-09 20:45:53,427 - INFO - root - Page:3, Index:21, Teaching Metric Distance to Discrete Autoregressive Language Models, https://arxiv.org/pdf/2503.02379, 2025-10-07
2025-11-09 20:45:53,428 - INFO - root - Page:3, Index:22, Regularization-based Framework for Quantization-, Fault- and Variability-Aware Training, https://arxiv.org/pdf/2503.01297, 2025-07-12
2025-11-09 20:45:53,428 - INFO - root - Fetching page 5 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=200
2025-11-09 20:45:59,869 - INFO - root - get_all_titles_from_web 
2025-11-09 20:45:59,869 - INFO - root - Page:4, Index:0, Investigating the Impact of Quantization Methods on the Safety and Reliability of Large Language Models, https://arxiv.org/pdf/2502.15799, 2025-06-29
2025-11-09 20:45:59,872 - INFO - root - Page:4, Index:1, Rotate, Clip, and Partition: Towards W2A4KV4 Quantization by Integrating Rotation and Learnable Non-uniform Quantizer, https://arxiv.org/pdf/2502.15779, 2025-09-01
2025-11-09 20:45:59,872 - INFO - root - Page:4, Index:2, RoSTE: An Efficient Quantization-Aware Supervised Fine-Tuning Approach for Large Language Models, https://arxiv.org/pdf/2502.09003, 2025-06-05
2025-11-09 20:45:59,873 - INFO - root - Page:4, Index:3, Spatial Degradation-Aware and Temporal Consistent Diffusion Model for Compressed Video Super-Resolution, https://arxiv.org/pdf/2502.07381, 2025-06-27
2025-11-09 20:45:59,873 - INFO - root - Page:4, Index:4, QuEST: Stable Training of LLMs with 1-Bit Weights and Activations, https://arxiv.org/pdf/2502.05003, 2025-06-10
2025-11-09 20:45:59,873 - INFO - root - Page:4, Index:5, HALO: Hadamard-Assisted Lower-Precision Optimization for LLMs, https://arxiv.org/pdf/2501.02625, 2025-11-05
2025-11-09 20:45:59,874 - INFO - root - Page:4, Index:6, TAR3D: Creating High-Quality 3D Assets via Next-Part Prediction, https://arxiv.org/pdf/2412.16919, 2025-08-08
2025-11-09 20:45:59,875 - INFO - root - Page:4, Index:7, Training Multi-Layer Binary Neural Networks With Local Binary Error Signals, https://arxiv.org/pdf/2412.00119, 2025-08-05
2025-11-09 20:45:59,876 - INFO - root - Page:4, Index:8, Scaling Large-scale GNN Training to Thousands of Processors on CPU-based Supercomputers, https://arxiv.org/pdf/2411.16025, 2025-05-26
2025-11-09 20:45:59,877 - INFO - root - Page:4, Index:9, HAFLQ: Heterogeneous Adaptive Federated LoRA Fine-tuned LLM with Quantization, https://arxiv.org/pdf/2411.06581, 2025-05-16
2025-11-09 20:45:59,877 - INFO - root - Fetching page 6 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=250
2025-11-09 20:46:06,656 - INFO - root - get_all_titles_from_web 
2025-11-09 20:46:06,657 - INFO - root - Page:5, Index:0, Gradient-Free Training of Quantized Neural Networks, https://arxiv.org/pdf/2410.09734, 2025-09-29
2025-11-09 20:46:06,657 - INFO - root - Page:5, Index:1, QT-DoG: Quantization-aware Training for Domain Generalization, https://arxiv.org/pdf/2410.06020, 2025-06-26
2025-11-09 20:46:06,657 - INFO - root - Page:5, Index:2, Constraint Guided Model Quantization of Neural Networks, https://arxiv.org/pdf/2409.20138, 2025-09-12
2025-11-09 20:46:06,657 - INFO - root - Page:5, Index:3, Accumulator-Aware Post-Training Quantization for Large Language Models, https://arxiv.org/pdf/2409.17092, 2025-07-30
2025-11-09 20:46:06,658 - INFO - root - Page:5, Index:4, DilateQuant: Accurate and Efficient Diffusion Quantization via Weight Dilation, https://arxiv.org/pdf/2409.14307, 2025-07-09
2025-11-09 20:46:06,658 - INFO - root - Page:5, Index:5, Robust Training of Neural Networks at Arbitrary Precision and Sparsity, https://arxiv.org/pdf/2409.09245, 2025-09-23
2025-11-09 20:46:06,658 - INFO - root - Page:5, Index:6, VQ-CTAP: Cross-Modal Fine-Grained Sequence Representation Learning for Speech Processing, https://arxiv.org/pdf/2408.05758, 2025-05-27
2025-11-09 20:46:06,659 - INFO - root - Page:5, Index:7, DopQ-ViT: Towards Distribution-Friendly and Outlier-Aware Post-Training Quantization for Vision Transformers, https://arxiv.org/pdf/2408.03291, 2025-06-19
2025-11-09 20:46:06,659 - INFO - root - Page:5, Index:8, Temporal Feature Matters: A Framework for Diffusion Model Quantization, https://arxiv.org/pdf/2407.19547, 2025-07-11
2025-11-09 20:46:06,659 - INFO - root - Page:5, Index:9, EfficientQAT: Efficient Quantization-Aware Training for Large Language Models, https://arxiv.org/pdf/2407.11062, 2025-05-19
2025-11-09 20:46:06,660 - INFO - root - Page:5, Index:10, Integer-only Quantized Transformers for Embedded FPGA-based Time-series Forecasting in AIoT, https://arxiv.org/pdf/2407.11041, 2025-10-31
2025-11-09 20:46:06,661 - INFO - root - Fetching page 7 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=300
2025-11-09 20:46:14,365 - INFO - root - get_all_titles_from_web 
2025-11-09 20:46:14,365 - INFO - root - Page:6, Index:0, BoA: Attention-aware Post-training Quantization without Backpropagation, https://arxiv.org/pdf/2406.13474, 2025-06-06
2025-11-09 20:46:14,366 - INFO - root - Page:6, Index:1, A Rescaling-Invariant Lipschitz Bound Based on Path-Metrics for Modern ReLU Network Parameterizations, https://arxiv.org/pdf/2405.15006, 2025-06-13
2025-11-09 20:46:14,366 - INFO - root - Page:6, Index:2, Scheduling Weight Transitions for Quantization-Aware Training, https://arxiv.org/pdf/2404.19248, 2025-10-01
2025-11-09 20:46:14,366 - INFO - root - Page:6, Index:3, GPTVQ: The Blessing of Dimensionality for LLM Quantization, https://arxiv.org/pdf/2402.15319, 2025-06-03
2025-11-09 20:46:14,367 - INFO - root - Fetching page 8 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=350
2025-11-09 20:46:20,769 - INFO - root - get_all_titles_from_web 
2025-11-09 20:46:20,769 - INFO - root - Page:7, Index:0, Squat: Quant Small Language Models on the Edge, https://arxiv.org/pdf/2402.10787, 2025-07-01
2025-11-09 20:46:20,770 - INFO - root - Page:7, Index:1, L4Q: Parameter Efficient Quantization-Aware Fine-Tuning on Large Language Models, https://arxiv.org/pdf/2402.04902, 2025-07-21
2025-11-09 20:46:20,770 - INFO - root - Fetching page 9 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=400
2025-11-09 20:46:27,236 - INFO - root - ------------------------------------------------------------------------------------------------------------------------
2025-11-09 20:46:27,237 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\A Quantized VAE-MLP Botnet Detection Model_ A Systematic Evaluation of Quantizat.pdf
2025-11-09 20:46:27,244 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\FP8-Flow-MoE_ A Casting-Free FP8 Recipe without Double Quantization Error.pdf
2025-11-09 20:46:27,245 - INFO - root - 跳过已处理论文 A Quantized VAE-MLP Botnet Detection Model: A Systematic Evaluation of Quantization-Aware Training and Post-Training Quantization Strategies：d:\ChatPaper\academic Papers\Quantization-Aware-Training\A Quantized VAE-MLP Botnet Detection Model_ A Systematic Evaluation of Quantizat.pdf
2025-11-09 20:46:27,246 - INFO - root - 跳过已处理论文 FP8-Flow-MoE: A Casting-Free FP8 Recipe without Double Quantization Error：d:\ChatPaper\academic Papers\Quantization-Aware-Training\FP8-Flow-MoE_ A Casting-Free FP8 Recipe without Double Quantization Error.pdf
2025-11-09 20:46:27,247 - INFO - root - summary time: 72.68 seconds
2025-11-09 20:46:45,952 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-09 20:46:45,953 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-09 20:46:45,954 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-09 20:46:46,795 - INFO - root - LLMClientManager: 指定使用客户端: DeepSeek
2025-11-09 20:46:46,796 - WARNING - root - DeepSeekClient: API key not provided. LLM disabled.
2025-11-09 20:46:46,796 - ERROR - root - LLMClientManager: 指定的客户端 DeepSeek 初始化失败
2025-11-09 20:46:46,796 - WARNING - root - LLMClientManager: 指定的客户端 DeepSeek 不可用，将尝试其他客户端
2025-11-09 20:46:47,623 - INFO - root - GeminiClient: trying model gemini-2.5-flash
2025-11-09 20:46:49,542 - INFO - root - GeminiClient: initialized model gemini-2.5-flash
2025-11-09 20:46:49,542 - INFO - root - LLMClientManager: Gemini client initialized successfully
2025-11-09 20:46:49,543 - INFO - root - LLMClientManager: using Gemini as default client
2025-11-09 20:46:49,543 - WARNING - root - KimiClient: API key not provided. LLM disabled.
2025-11-09 20:46:49,543 - WARNING - root - LLMClientManager: Kimi client initialization failed
2025-11-09 20:46:49,543 - WARNING - root - QwenClient: API key not provided. LLM disabled.
2025-11-09 20:46:49,544 - WARNING - root - LLMClientManager: Qwen client initialization failed
2025-11-09 20:46:49,544 - INFO - root - DoubaoClient: API key found: 9f9e270e-b...
2025-11-09 20:46:54,056 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 20:46:54,066 - INFO - root - DoubaoClient: initialized successfully with model doubao-seed-1-6-lite-251015
2025-11-09 20:46:54,066 - INFO - root - LLMClientManager: Doubao client initialized successfully
2025-11-09 20:46:54,068 - WARNING - root - LLMClientManager: client DeepSeek not available
2025-11-09 20:46:54,068 - WARNING - root - 无法切换到指定的客户端 DeepSeek，将使用默认客户端
2025-11-09 20:46:54,068 - INFO - root - 可用客户端: ['Gemini', 'Doubao']
2025-11-09 20:46:54,069 - INFO - root - 使用 LLM 模型: gemini-2.5-flash
2025-11-09 20:46:54,069 - INFO - root - 可用客户端: ['Gemini', 'Doubao']
2025-11-09 20:46:54,069 - INFO - root - === 运行配置 ===
2025-11-09 20:46:54,070 - INFO - root - 处理模式: arxiv在线搜索
2025-11-09 20:46:54,070 - INFO - root - 关键词: QAT
2025-11-09 20:46:54,070 - INFO - root - 查询: Quantization-Aware-Training
2025-11-09 20:46:54,070 - INFO - root - 排序: None
2025-11-09 20:46:54,071 - INFO - root - 最近天数: 180
2025-11-09 20:46:54,071 - INFO - root - 最大处理数量: 2
2025-11-09 20:46:54,071 - INFO - root - 保存图片: 是
2025-11-09 20:46:54,072 - INFO - root - 输出语言: 中文
2025-11-09 20:46:54,072 - INFO - root - 强制重新处理: 否
2025-11-09 20:46:54,072 - INFO - root - ====================
2025-11-09 20:46:54,072 - INFO - root - 使用 arXiv 搜索模式（通过 chat_arxiv 模块获取）
2025-11-09 20:46:54,073 - INFO - root - Fetching page 1 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50
2025-11-09 20:47:01,095 - INFO - root - get_all_titles_from_web 
2025-11-09 20:47:01,095 - INFO - root - Page:0, Index:0, A Quantized VAE-MLP Botnet Detection Model: A Systematic Evaluation of Quantization-Aware Training and Post-Training Quantization Strategies, https://arxiv.org/pdf/2511.03201, 2025-11-05
2025-11-09 20:47:01,096 - INFO - root - Page:0, Index:1, FP8-Flow-MoE: A Casting-Free FP8 Recipe without Double Quantization Error, https://arxiv.org/pdf/2511.02302, 2025-11-04
2025-11-09 20:47:01,096 - INFO - root - Page:0, Index:2, Outlier-Aware Post-Training Quantization for Image Super-Resolution, https://arxiv.org/pdf/2511.00682, 2025-11-01
2025-11-09 20:47:01,096 - INFO - root - Page:0, Index:3, Evaluation of Wafer-Scale SOT-MRAM for Analog Crossbar Array Applications, https://arxiv.org/pdf/2510.25853, 2025-11-03
2025-11-09 20:47:01,097 - INFO - root - Page:0, Index:4, Improving the Straight-Through Estimator with Zeroth-Order Information, https://arxiv.org/pdf/2510.23926, 2025-10-27
2025-11-09 20:47:01,097 - INFO - root - Page:0, Index:5, Real-Time Semantic Segmentation on FPGA for Autonomous Vehicles Using LMIINet with the CGRA4ML Framework, https://arxiv.org/pdf/2510.22243, 2025-10-25
2025-11-09 20:47:01,097 - INFO - root - Page:0, Index:6, TernaryCLIP: Efficiently Compressing Vision-Language Models with Ternary Weights and Distilled Knowledge, https://arxiv.org/pdf/2510.21879, 2025-10-23
2025-11-09 20:47:01,097 - INFO - root - Page:0, Index:7, KARIPAP: Quantum-Inspired Tensor Network Compression of Large Language Models Using Infinite Projected Entangled Pair States and Tensor Renormalization Group, https://arxiv.org/pdf/2510.21844, 2025-10-22
2025-11-09 20:47:01,098 - INFO - root - Page:0, Index:8, A Convergence Analysis of Adaptive Optimizers under Floating-point Quantization, https://arxiv.org/pdf/2510.21314, 2025-10-24
2025-11-09 20:47:01,099 - INFO - root - Page:0, Index:9, Adaptive Distribution-aware Quantization for Mixed-Precision Neural Networks, https://arxiv.org/pdf/2510.19760, 2025-10-22
2025-11-09 20:47:01,099 - INFO - root - Page:0, Index:10, CAGE: Curvature-Aware Gradient Estimation For Accurate Quantization-Aware Training, https://arxiv.org/pdf/2510.18784, 2025-10-21
2025-11-09 20:47:01,099 - INFO - root - Page:0, Index:11, Mixed-Precision Quantization for Language Models: Techniques and Prospects, https://arxiv.org/pdf/2510.16805, 2025-10-19
2025-11-09 20:47:01,101 - INFO - root - Page:0, Index:12, SPLite Hand: Sparsity-Aware Lightweight 3D Hand Pose Estimation, https://arxiv.org/pdf/2510.16396, 2025-10-30
2025-11-09 20:47:01,102 - INFO - root - Page:0, Index:13, CTR-LoRA: Curvature-Aware and Trust-Region Guided Low-Rank Adaptation for Large Language Models, https://arxiv.org/pdf/2510.15962, 2025-10-11
2025-11-09 20:47:01,102 - INFO - root - Page:0, Index:14, SANR: Scene-Aware Neural Representation for Light Field Image Compression with Rate-Distortion Optimization, https://arxiv.org/pdf/2510.15775, 2025-10-17
2025-11-09 20:47:01,102 - INFO - root - Page:0, Index:15, SpikeFit: Towards Optimal Deployment of Spiking Networks on Neuromorphic Hardware, https://arxiv.org/pdf/2510.15542, 2025-10-31
2025-11-09 20:47:01,103 - INFO - root - Page:0, Index:16, GRank: Towards Target-Aware and Streamlined Industrial Retrieval with a Generate-Rank Framework, https://arxiv.org/pdf/2510.15299, 2025-10-17
2025-11-09 20:47:01,103 - INFO - root - Page:0, Index:17, SaLon3R: Structure-aware Long-term Generalizable 3D Reconstruction from Unposed Images, https://arxiv.org/pdf/2510.15072, 2025-10-16
2025-11-09 20:47:01,103 - INFO - root - Page:0, Index:18, FraQAT: Quantization Aware Training with Fractional bits, https://arxiv.org/pdf/2510.14823, 2025-10-16
2025-11-09 20:47:01,104 - INFO - root - Page:0, Index:19, Computing-In-Memory Aware Model Adaption For Edge Devices, https://arxiv.org/pdf/2510.14379, 2025-10-16
2025-11-09 20:47:01,104 - INFO - root - Page:0, Index:20, Invited Paper: BitMedViT: Ternary-Quantized Vision Transformer for Medical AI Assistants on the Edge, https://arxiv.org/pdf/2510.13760, 2025-11-04
2025-11-09 20:47:01,104 - INFO - root - Page:0, Index:21, NeuroRVQ: Multi-Scale EEG Tokenization for Generative Large Brainwave Models, https://arxiv.org/pdf/2510.13068, 2025-10-14
2025-11-09 20:47:01,105 - INFO - root - Page:0, Index:22, Detect Anything via Next Point Prediction, https://arxiv.org/pdf/2510.12798, 2025-10-14
2025-11-09 20:47:01,105 - INFO - root - Page:0, Index:23, AndesVL Technical Report: An Efficient Mobile-side Multimodal Large Language Model, https://arxiv.org/pdf/2510.11496, 2025-10-14
2025-11-09 20:47:01,105 - INFO - root - Page:0, Index:24, Rescaling-Aware Training for Efficient Deployment of Deep Learning Models on Full-Integer Hardware, https://arxiv.org/pdf/2510.11484, 2025-10-13
2025-11-09 20:47:01,106 - INFO - root - Page:0, Index:25, SASER: Stego attacks on open-source LLMs, https://arxiv.org/pdf/2510.10486, 2025-10-12
2025-11-09 20:47:01,106 - INFO - root - Page:0, Index:26, Ultralytics YOLO Evolution: An Overview of YOLO26, YOLO11, YOLOv8 and YOLOv5 Object Detectors for Computer Vision and Pattern Recognition, https://arxiv.org/pdf/2510.09653, 2025-10-15
2025-11-09 20:47:01,106 - INFO - root - Page:0, Index:27, A Theoretically-Grounded Codebook for Digital Semantic Communications, https://arxiv.org/pdf/2510.07108, 2025-10-14
2025-11-09 20:47:01,107 - INFO - root - Page:0, Index:28, QuantDemoire: Quantization with Outlier Aware for Image Demoiréing, https://arxiv.org/pdf/2510.04066, 2025-10-05
2025-11-09 20:47:01,108 - INFO - root - Page:0, Index:29, Adaptively Sampling-Reusing-Mixing Decomposed Gradients to Speed Up Sharpness Aware Minimization, https://arxiv.org/pdf/2510.03763, 2025-10-04
2025-11-09 20:47:01,109 - INFO - root - Page:0, Index:30, Quant-dLLM: Post-Training Extreme Low-Bit Quantization for Diffusion Large Language Models, https://arxiv.org/pdf/2510.03274, 2025-09-27
2025-11-09 20:47:01,110 - INFO - root - Page:0, Index:31, PT$^2$-LLM: Post-Training Ternarization for Large Language Models, https://arxiv.org/pdf/2510.03267, 2025-09-26
2025-11-09 20:47:01,110 - INFO - root - Page:0, Index:32, Purrception: Variational Flow Matching for Vector-Quantized Image Generation, https://arxiv.org/pdf/2510.01478, 2025-10-01
2025-11-09 20:47:01,110 - INFO - root - Page:0, Index:33, Post-Training Quantization for Audio Diffusion Transformers, https://arxiv.org/pdf/2510.00313, 2025-09-30
2025-11-09 20:47:01,111 - INFO - root - Page:0, Index:34, Rethinking RoPE Scaling in Quantized LLM: Theory, Outlier, and Channel-Band Analysis with Weight Rescaling, https://arxiv.org/pdf/2510.00028, 2025-09-25
2025-11-09 20:47:01,111 - INFO - root - Page:0, Index:35, Post-Training Quantization via Residual Truncation and Zero Suppression for Diffusion Models, https://arxiv.org/pdf/2509.26436, 2025-09-30
2025-11-09 20:47:01,111 - INFO - root - Page:0, Index:36, Cat: Post-Training Quantization Error Reduction via Cluster-based Affine Transformation, https://arxiv.org/pdf/2509.26277, 2025-10-07
2025-11-09 20:47:01,112 - INFO - root - Page:0, Index:37, CAST: Continuous and Differentiable Semi-Structured Sparsity-Aware Training for Large Language Models, https://arxiv.org/pdf/2509.25996, 2025-09-30
2025-11-09 20:47:01,112 - INFO - root - Page:0, Index:38, Norm-Q: Effective Compression Method for Hidden Markov Models in Neuro-Symbolic Applications, https://arxiv.org/pdf/2509.25439, 2025-09-29
2025-11-09 20:47:01,112 - INFO - root - Page:0, Index:39, On-the-Fly Adaptation to Quantization: Configuration-Aware LoRA for Efficient Fine-Tuning of Quantized LLMs, https://arxiv.org/pdf/2509.25214, 2025-09-22
2025-11-09 20:47:01,114 - INFO - root - Page:0, Index:40, VoxCPM: Tokenizer-Free TTS for Context-Aware Speech Generation and True-to-Life Voice Cloning, https://arxiv.org/pdf/2509.24650, 2025-09-29
2025-11-09 20:47:01,114 - INFO - root - Page:0, Index:41, S$^2$NN: Sub-bit Spiking Neural Networks, https://arxiv.org/pdf/2509.24266, 2025-10-24
2025-11-09 20:47:01,114 - INFO - root - Page:0, Index:42, Tequila: Trapping-free Ternary Quantization for Large Language Models, https://arxiv.org/pdf/2509.23809, 2025-10-17
2025-11-09 20:47:01,114 - INFO - root - Page:0, Index:43, Texture Vector-Quantization and Reconstruction Aware Prediction for Generative Super-Resolution, https://arxiv.org/pdf/2509.23774, 2025-09-30
2025-11-09 20:47:01,116 - INFO - root - Page:0, Index:44, RobuQ: Pushing DiTs to W1.58A2 via Robust Activation Quantization, https://arxiv.org/pdf/2509.23582, 2025-09-27
2025-11-09 20:47:01,117 - INFO - root - Page:0, Index:45, Beyond Outliers: A Study of Optimizers Under Quantization, https://arxiv.org/pdf/2509.23500, 2025-10-02
2025-11-09 20:47:01,117 - INFO - root - Page:0, Index:46, Compute-Optimal Quantization-Aware Training, https://arxiv.org/pdf/2509.22935, 2025-09-26
2025-11-09 20:47:01,117 - INFO - root - Page:0, Index:47, COSPADI: Compressing LLMs via Calibration-Guided Sparse Dictionary Learning, https://arxiv.org/pdf/2509.22075, 2025-10-06
2025-11-09 20:47:01,117 - INFO - root - Page:0, Index:48, SlimDiff: Training-Free, Activation-Guided Hands-free Slimming of Diffusion Models, https://arxiv.org/pdf/2509.21498, 2025-09-25
2025-11-09 20:47:01,119 - INFO - root - Page:0, Index:49, Quantized Visual Geometry Grounded Transformer, https://arxiv.org/pdf/2509.21302, 2025-09-29
2025-11-09 20:47:01,119 - INFO - root - Fetching page 2 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=50
2025-11-09 20:47:07,965 - INFO - root - get_all_titles_from_web 
2025-11-09 20:47:07,965 - INFO - root - Page:1, Index:0, Can Less Precise Be More Reliable? A Systematic Evaluation of Quantization's Impact on CLIP Beyond Accuracy, https://arxiv.org/pdf/2509.21173, 2025-10-27
2025-11-09 20:47:07,967 - INFO - root - Page:1, Index:1, Punching Above Precision: Small Quantized Model Distillation with Learnable Regularizer, https://arxiv.org/pdf/2509.20854, 2025-09-25
2025-11-09 20:47:07,967 - INFO - root - Page:1, Index:2, TinyEcoWeedNet: Edge Efficient Real-Time Aerial Agricultural Weed Detection, https://arxiv.org/pdf/2509.18193, 2025-09-19
2025-11-09 20:47:07,967 - INFO - root - Page:1, Index:3, SBVR: Summation of BitVector Representation for Efficient LLM Quantization, https://arxiv.org/pdf/2509.18172, 2025-09-17
2025-11-09 20:47:07,967 - INFO - root - Page:1, Index:4, QWHA: Quantization-Aware Walsh-Hadamard Adaptation for Parameter-Efficient Fine-Tuning on Large Language Models, https://arxiv.org/pdf/2509.17428, 2025-09-26
2025-11-09 20:47:07,968 - INFO - root - Page:1, Index:5, PTQTP: Post-Training Quantization to Trit-Planes for Large Language Models, https://arxiv.org/pdf/2509.16989, 2025-10-28
2025-11-09 20:47:07,968 - INFO - root - Page:1, Index:6, MEC-Quant: Maximum Entropy Coding for Extremely Low Bit Quantization-Aware Training, https://arxiv.org/pdf/2509.15514, 2025-09-18
2025-11-09 20:47:07,968 - INFO - root - Page:1, Index:7, Q-ROAR: Outlier-Aware Rescaling for RoPE Position Interpolation in Quantized Long-Context LLMs, https://arxiv.org/pdf/2509.14391, 2025-09-17
2025-11-09 20:47:07,969 - INFO - root - Page:1, Index:8, Efficient Quantization-Aware Neural Receivers: Beyond Post-Training Quantization, https://arxiv.org/pdf/2509.13786, 2025-09-19
2025-11-09 20:47:07,969 - INFO - root - Page:1, Index:9, Rate-Distortion Limits for Multimodal Retrieval: Theory, Optimal Codes, and Finite-Sample Guarantees, https://arxiv.org/pdf/2509.11054, 2025-09-13
2025-11-09 20:47:07,969 - INFO - root - Page:1, Index:10, SQAP-VLA: A Synergistic Quantization-Aware Pruning Framework for High-Performance Vision-Language-Action Models, https://arxiv.org/pdf/2509.09090, 2025-09-10
2025-11-09 20:47:07,970 - INFO - root - Page:1, Index:11, CSI Compression Beyond Latents: End-to-End Hybrid Attention-CNN Networks with Entropy Regularization, https://arxiv.org/pdf/2509.08776, 2025-09-10
2025-11-09 20:47:07,970 - INFO - root - Page:1, Index:12, Explaining How Quantization Disparately Skews a Model, https://arxiv.org/pdf/2509.07222, 2025-09-08
2025-11-09 20:47:07,970 - INFO - root - Page:1, Index:13, LoaQ: Layer-wise Output Approximation Quantization, https://arxiv.org/pdf/2509.06297, 2025-09-07
2025-11-09 20:47:07,970 - INFO - root - Page:1, Index:14, FineServe: Precision-Aware KV Slab and Two-Level Scheduling for Heterogeneous Precision LLM Serving, https://arxiv.org/pdf/2509.06261, 2025-09-14
2025-11-09 20:47:07,971 - INFO - root - Page:1, Index:15, Sensitivity-Aware Post-Training Quantization for Deep Neural Networks, https://arxiv.org/pdf/2509.05576, 2025-09-05
2025-11-09 20:47:07,971 - INFO - root - Page:1, Index:16, SuperSNN: A Hardware-Aware Framework for Physically Realizable, High-Performance Superconducting Spiking Neural Network Chips, https://arxiv.org/pdf/2509.05532, 2025-09-05
2025-11-09 20:47:07,973 - INFO - root - Page:1, Index:17, Data-Augmented Quantization-Aware Knowledge Distillation, https://arxiv.org/pdf/2509.03850, 2025-09-03
2025-11-09 20:47:07,975 - INFO - root - Page:1, Index:18, DPQuant: Efficient and Differentially-Private Model Training via Dynamic Quantization Scheduling, https://arxiv.org/pdf/2509.03472, 2025-09-03
2025-11-09 20:47:07,976 - INFO - root - Page:1, Index:19, Empowering Large Language Model for Sequential Recommendation via Multimodal Embeddings and Semantic IDs, https://arxiv.org/pdf/2509.02017, 2025-09-02
2025-11-09 20:47:07,977 - INFO - root - Page:1, Index:20, Q-Sched: Pushing the Boundaries of Few-Step Diffusion Models with Quantization-Aware Scheduling, https://arxiv.org/pdf/2509.01624, 2025-09-01
2025-11-09 20:47:07,977 - INFO - root - Page:1, Index:21, Quantization Meets OOD: Generalizable Quantization-aware Training from a Flatness Perspective, https://arxiv.org/pdf/2509.00859, 2025-08-31
2025-11-09 20:47:07,978 - INFO - root - Page:1, Index:22, Progressive Element-wise Gradient Estimation for Neural Network Quantization, https://arxiv.org/pdf/2509.00097, 2025-08-27
2025-11-09 20:47:07,978 - INFO - root - Page:1, Index:23, End-to-End On-Device Quantization-Aware Training for LLMs at Inference Cost, https://arxiv.org/pdf/2509.00031, 2025-09-29
2025-11-09 20:47:07,978 - INFO - root - Page:1, Index:24, Quantization Robustness to Input Degradations for Object Detection, https://arxiv.org/pdf/2508.19600, 2025-08-27
2025-11-09 20:47:07,978 - INFO - root - Page:1, Index:25, Scaling Laws for Task-Stratified Knowledge in Post-Training Quantized Large Language Models, https://arxiv.org/pdf/2508.18609, 2025-08-27
2025-11-09 20:47:07,979 - INFO - root - Page:1, Index:26, AQ-PCDSys: An Adaptive Quantized Planetary Crater Detection System for Autonomous Space Exploration, https://arxiv.org/pdf/2508.18025, 2025-08-25
2025-11-09 20:47:07,979 - INFO - root - Page:1, Index:27, TaDiCodec: Text-aware Diffusion Speech Tokenizer for Speech Language Modeling, https://arxiv.org/pdf/2508.16790, 2025-08-22
2025-11-09 20:47:07,979 - INFO - root - Page:1, Index:28, A Node-Aware Dynamic Quantization Approach for Graph Collaborative Filtering, https://arxiv.org/pdf/2508.16516, 2025-08-22
2025-11-09 20:47:07,979 - INFO - root - Page:1, Index:29, JEDI-linear: Fast and Efficient Graph Neural Networks for Jet Tagging on FPGAs, https://arxiv.org/pdf/2508.15468, 2025-08-21
2025-11-09 20:47:07,980 - INFO - root - Page:1, Index:30, MMQ: Multimodal Mixture-of-Quantization Tokenization for Semantic ID Generation and User Behavioral Adaptation, https://arxiv.org/pdf/2508.15281, 2025-08-21
2025-11-09 20:47:07,980 - INFO - root - Page:1, Index:31, DLLMQuant: Quantizing Diffusion-based Large Language Models, https://arxiv.org/pdf/2508.14090, 2025-08-25
2025-11-09 20:47:07,980 - INFO - root - Page:1, Index:32, Automated Energy-Aware Time-Series Model Deployment on Embedded FPGAs for Resilient Combined Sewer Overflow Management, https://arxiv.org/pdf/2508.13905, 2025-08-19
2025-11-09 20:47:07,980 - INFO - root - Page:1, Index:33, XR-NPE: High-Throughput Mixed-precision SIMD Neural Processing Engine for Extended Reality Perception Workloads, https://arxiv.org/pdf/2508.13049, 2025-08-18
2025-11-09 20:47:07,981 - INFO - root - Page:1, Index:34, Exploring Self-Supervised Audio Models for Generalized Anomalous Sound Detection, https://arxiv.org/pdf/2508.12230, 2025-08-17
2025-11-09 20:47:07,981 - INFO - root - Page:1, Index:35, TriQDef: Disrupting Semantic and Gradient Alignment to Prevent Adversarial Patch Transferability in Quantized Neural Networks, https://arxiv.org/pdf/2508.12132, 2025-08-16
2025-11-09 20:47:07,981 - INFO - root - Page:1, Index:36, Error Propagation Mechanisms and Compensation Strategies for Quantized Diffusion, https://arxiv.org/pdf/2508.12094, 2025-10-13
2025-11-09 20:47:07,983 - INFO - root - Page:1, Index:37, Extending Straight-Through Estimation for Robust Neural Networks on Analog CIM Hardware, https://arxiv.org/pdf/2508.11940, 2025-08-16
2025-11-09 20:47:07,983 - INFO - root - Page:1, Index:38, PTQAT: A Hybrid Parameter-Efficient Quantization Algorithm for 3D Perception Tasks, https://arxiv.org/pdf/2508.10557, 2025-08-15
2025-11-09 20:47:07,983 - INFO - root - Page:1, Index:39, MiCo: End-to-End Mixed Precision Neural Network Co-Exploration Framework for Edge AI, https://arxiv.org/pdf/2508.09500, 2025-08-13
2025-11-09 20:47:07,985 - INFO - root - Page:1, Index:40, SPARC: Soft Probabilistic Adaptive multi-interest Retrieval Model via Codebooks for recommender system, https://arxiv.org/pdf/2508.09090, 2025-08-12
2025-11-09 20:47:07,985 - INFO - root - Page:1, Index:41, Rethinking 1-bit Optimization Leveraging Pre-trained Large Language Models, https://arxiv.org/pdf/2508.06974, 2025-08-09
2025-11-09 20:47:07,985 - INFO - root - Page:1, Index:42, Efficient Deep Neural Receiver with Post-Training Quantization, https://arxiv.org/pdf/2508.06275, 2025-08-08
2025-11-09 20:47:07,985 - INFO - root - Page:1, Index:43, iFairy: the First 2-bit Complex LLM with All Parameters in $\{\pm1, \pm i\}$, https://arxiv.org/pdf/2508.05571, 2025-08-16
2025-11-09 20:47:07,986 - INFO - root - Page:1, Index:44, S$^2$Q-VDiT: Accurate Quantized Video Diffusion Transformer with Salient Data and Sparse Token Distillation, https://arxiv.org/pdf/2508.04016, 2025-10-27
2025-11-09 20:47:07,986 - INFO - root - Page:1, Index:45, LRQ-DiT: Log-Rotation Post-Training Quantization of Diffusion Transformers for Image and Video Generation, https://arxiv.org/pdf/2508.03485, 2025-09-23
2025-11-09 20:47:07,986 - INFO - root - Page:1, Index:46, VLMQ: Efficient Post-Training Quantization for Large Vision-Language Models via Hessian Augmentation, https://arxiv.org/pdf/2508.03351, 2025-08-05
2025-11-09 20:47:07,986 - INFO - root - Page:1, Index:47, TF-MLPNet: Tiny Real-Time Neural Speech Separation, https://arxiv.org/pdf/2508.03047, 2025-08-04
2025-11-09 20:47:07,987 - INFO - root - Page:1, Index:48, SaviorRec: Semantic-Behavior Alignment for Cold-Start Recommendation, https://arxiv.org/pdf/2508.01375, 2025-08-02
2025-11-09 20:47:07,987 - INFO - root - Page:1, Index:49, MixA-Q: Revisiting Activation Sparsity for Vision Transformers from a Mixed-Precision Quantization Perspective, https://arxiv.org/pdf/2507.19131, 2025-07-25
2025-11-09 20:47:07,989 - INFO - root - Fetching page 3 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=100
2025-11-09 20:47:14,670 - INFO - root - get_all_titles_from_web 
2025-11-09 20:47:14,670 - INFO - root - Page:2, Index:0, Enhancing Quantization-Aware Training on Edge Devices via Relative Entropy Coreset Selection and Cascaded Layer Correction, https://arxiv.org/pdf/2507.17768, 2025-07-16
2025-11-09 20:47:14,671 - INFO - root - Page:2, Index:1, SiLQ: Simple Large Language Model Quantization-Aware Training, https://arxiv.org/pdf/2507.16933, 2025-07-22
2025-11-09 20:47:14,671 - INFO - root - Page:2, Index:2, Task-Specific Zero-shot Quantization-Aware Training for Object Detection, https://arxiv.org/pdf/2507.16782, 2025-07-22
2025-11-09 20:47:14,671 - INFO - root - Page:2, Index:3, TorchAO: PyTorch-Native Training-to-Serving Model Optimization, https://arxiv.org/pdf/2507.16099, 2025-07-21
2025-11-09 20:47:14,672 - INFO - root - Page:2, Index:4, SegQuant: A Semantics-Aware and Generalizable Quantization Framework for Diffusion Models, https://arxiv.org/pdf/2507.14811, 2025-08-27
2025-11-09 20:47:14,672 - INFO - root - Page:2, Index:5, Apple Intelligence Foundation Language Models: Tech Report 2025, https://arxiv.org/pdf/2507.13575, 2025-08-27
2025-11-09 20:47:14,672 - INFO - root - Page:2, Index:6, Generative Multi-Target Cross-Domain Recommendation, https://arxiv.org/pdf/2507.12871, 2025-08-07
2025-11-09 20:47:14,672 - INFO - root - Page:2, Index:7, DAF: An Efficient End-to-End Dynamic Activation Framework for on-Device DNN Training, https://arxiv.org/pdf/2507.07149, 2025-07-09
2025-11-09 20:47:14,673 - INFO - root - Page:2, Index:8, Opto-ViT: Architecting a Near-Sensor Region of Interest-Aware Vision Transformer Accelerator with Silicon Photonics, https://arxiv.org/pdf/2507.07044, 2025-07-15
2025-11-09 20:47:14,673 - INFO - root - Page:2, Index:9, QS4D: Quantization-aware training for efficient hardware deployment of structured state-space sequential models, https://arxiv.org/pdf/2507.06079, 2025-07-08
2025-11-09 20:47:14,673 - INFO - root - Page:2, Index:10, GSVR: 2D Gaussian-based Video Representation for 800+ FPS with Hybrid Deformation Field, https://arxiv.org/pdf/2507.05594, 2025-07-07
2025-11-09 20:47:14,674 - INFO - root - Page:2, Index:11, Hita: Holistic Tokenizer for Autoregressive Image Generation, https://arxiv.org/pdf/2507.02358, 2025-07-11
2025-11-09 20:47:14,674 - INFO - root - Page:2, Index:12, QPART: Adaptive Model Quantization and Dynamic Workload Balancing for Accuracy-aware Edge Inference, https://arxiv.org/pdf/2506.23934, 2025-06-30
2025-11-09 20:47:14,674 - INFO - root - Page:2, Index:13, FedWSQ: Efficient Federated Learning with Weight Standardization and Distribution-Aware Non-Uniform Quantization, https://arxiv.org/pdf/2506.23516, 2025-07-21
2025-11-09 20:47:14,674 - INFO - root - Page:2, Index:14, Spectra 1.1: Scaling Laws and Efficient Inference for Ternary Language Models, https://arxiv.org/pdf/2506.23025, 2025-06-28
2025-11-09 20:47:14,675 - INFO - root - Page:2, Index:15, Joint Quantization and Pruning Neural Networks Approach: A Case Study on FSO Receivers, https://arxiv.org/pdf/2506.20084, 2025-06-24
2025-11-09 20:47:14,675 - INFO - root - Page:2, Index:16, Single-step Diffusion for Image Compression at Ultra-Low Bitrates, https://arxiv.org/pdf/2506.16572, 2025-09-22
2025-11-09 20:47:14,675 - INFO - root - Page:2, Index:17, LittleBit: Ultra Low-Bit Quantization via Latent Factorization, https://arxiv.org/pdf/2506.13771, 2025-10-28
2025-11-09 20:47:14,676 - INFO - root - Page:2, Index:18, MARCO: Hardware-Aware Neural Architecture Search for Edge Devices with Multi-Agent Reinforcement Learning and Conformal Prediction Filtering, https://arxiv.org/pdf/2506.13755, 2025-06-16
2025-11-09 20:47:14,676 - INFO - root - Page:2, Index:19, EAQuant: Enhancing Post-Training Quantization for MoE Models via Expert-Aware Optimization, https://arxiv.org/pdf/2506.13329, 2025-07-04
2025-11-09 20:47:14,677 - INFO - root - Page:2, Index:20, Towards Neural Audio Codec Source Parsing, https://arxiv.org/pdf/2506.12627, 2025-06-14
2025-11-09 20:47:14,677 - INFO - root - Page:2, Index:21, Quantizing Small-Scale State-Space Models for Edge AI, https://arxiv.org/pdf/2506.12480, 2025-06-14
2025-11-09 20:47:14,677 - INFO - root - Page:2, Index:22, EMLoC: Emulator-based Memory-efficient Fine-tuning with LoRA Correction, https://arxiv.org/pdf/2506.12015, 2025-06-13
2025-11-09 20:47:14,678 - INFO - root - Page:2, Index:23, Compression Aware Certified Training, https://arxiv.org/pdf/2506.11992, 2025-06-13
2025-11-09 20:47:14,678 - INFO - root - Page:2, Index:24, GPLQ: A General, Practical, and Lightning QAT Method for Vision Transformers, https://arxiv.org/pdf/2506.11784, 2025-06-13
2025-11-09 20:47:14,680 - INFO - root - Page:2, Index:25, TruncQuant: Truncation-Ready Quantization for DNNs with Flexible Weight Bit Precision, https://arxiv.org/pdf/2506.11431, 2025-06-12
2025-11-09 20:47:14,680 - INFO - root - Page:2, Index:26, EfficientQuant: An Efficient Post-Training Quantization for CNN-Transformer Hybrid Models on Edge Devices, https://arxiv.org/pdf/2506.11093, 2025-06-05
2025-11-09 20:47:14,681 - INFO - root - Page:2, Index:27, Starting Positions Matter: A Study on Better Weight Initialization for Neural Network Quantization, https://arxiv.org/pdf/2506.10463, 2025-06-12
2025-11-09 20:47:14,682 - INFO - root - Page:2, Index:28, AWP: Activation-Aware Weight Pruning and Quantization with Projected Gradient Descent, https://arxiv.org/pdf/2506.10205, 2025-06-11
2025-11-09 20:47:14,682 - INFO - root - Page:2, Index:29, Q-SAM2: Accurate Quantization for Segment Anything Model 2, https://arxiv.org/pdf/2506.09782, 2025-06-11
2025-11-09 20:47:14,682 - INFO - root - Page:2, Index:30, Unifying Block-wise PTQ and Distillation-based QAT for Progressive Quantization toward 2-bit Instruction-Tuned LLMs, https://arxiv.org/pdf/2506.09104, 2025-06-10
2025-11-09 20:47:14,683 - INFO - root - Page:2, Index:31, Implementing Keyword Spotting on the MCUX947 Microcontroller with Integrated NPU, https://arxiv.org/pdf/2506.08911, 2025-06-10
2025-11-09 20:47:14,683 - INFO - root - Page:2, Index:32, POLARON: Precision-aware On-device Learning and Adaptive Runtime-cONfigurable AI acceleration, https://arxiv.org/pdf/2506.08785, 2025-06-10
2025-11-09 20:47:14,683 - INFO - root - Page:2, Index:33, MoQAE: Mixed-Precision Quantization for Long-Context LLM Inference via Mixture of Quantization-Aware Experts, https://arxiv.org/pdf/2506.07533, 2025-06-09
2025-11-09 20:47:14,683 - INFO - root - Page:2, Index:34, BitVLA: 1-bit Vision-Language-Action Models for Robotics Manipulation, https://arxiv.org/pdf/2506.07530, 2025-06-09
2025-11-09 20:47:14,684 - INFO - root - Page:2, Index:35, RecGPT: A Foundation Model for Sequential Recommendation, https://arxiv.org/pdf/2506.06270, 2025-06-12
2025-11-09 20:47:14,687 - INFO - root - Page:2, Index:36, FPSAttention: Training-Aware FP8 and Sparsity Co-Design for Fast Video Diffusion, https://arxiv.org/pdf/2506.04648, 2025-06-05
2025-11-09 20:47:14,688 - INFO - root - Page:2, Index:37, BitTTS: Highly Compact Text-to-Speech Using 1.58-bit Quantization and Weight Indexing, https://arxiv.org/pdf/2506.03515, 2025-06-03
2025-11-09 20:47:14,689 - INFO - root - Page:2, Index:38, ShapeLLM-Omni: A Native Multimodal LLM for 3D Generation and Understanding, https://arxiv.org/pdf/2506.01853, 2025-06-02
2025-11-09 20:47:14,689 - INFO - root - Page:2, Index:39, Movable Antenna Enhanced Federated Fine-Tuning of Large Language Models via Hybrid Client Selection Optimization, https://arxiv.org/pdf/2506.00011, 2025-10-26
2025-11-09 20:47:14,690 - INFO - root - Page:2, Index:40, Running Conventional Automatic Speech Recognition on Memristor Hardware: A Simulated Approach, https://arxiv.org/pdf/2505.24721, 2025-05-30
2025-11-09 20:47:14,690 - INFO - root - Page:2, Index:41, GARLIC: GAussian Representation LearnIng for spaCe partitioning, https://arxiv.org/pdf/2505.24608, 2025-10-02
2025-11-09 20:47:14,690 - INFO - root - Page:2, Index:42, AutoChemSchematic AI: Agentic Physics-Aware Automation for Chemical Manufacturing Scale-Up, https://arxiv.org/pdf/2505.24584, 2025-08-18
2025-11-09 20:47:14,691 - INFO - root - Page:2, Index:43, Model-Preserving Adaptive Rounding, https://arxiv.org/pdf/2505.22988, 2025-09-25
2025-11-09 20:47:14,691 - INFO - root - Page:2, Index:44, Highly Efficient and Effective LLMs with Multi-Boolean Architectures, https://arxiv.org/pdf/2505.22811, 2025-10-03
2025-11-09 20:47:14,691 - INFO - root - Page:2, Index:45, Pioneering 4-Bit FP Quantization for Diffusion Models: Mixup-Sign Quantization and Timestep-Aware Fine-Tuning, https://arxiv.org/pdf/2505.21591, 2025-05-27
2025-11-09 20:47:14,692 - INFO - root - Page:2, Index:46, Frequency Composition for Compressed and Domain-Adaptive Neural Networks, https://arxiv.org/pdf/2505.20890, 2025-05-27
2025-11-09 20:47:14,693 - INFO - root - Page:2, Index:47, MoPFormer: Motion-Primitive Transformer for Wearable-Sensor Activity Recognition, https://arxiv.org/pdf/2505.20744, 2025-10-27
2025-11-09 20:47:14,693 - INFO - root - Page:2, Index:48, Optimizing edge AI models on HPC systems with the edge in the loop, https://arxiv.org/pdf/2505.19995, 2025-05-26
2025-11-09 20:47:14,694 - INFO - root - Fetching page 4 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=150
2025-11-09 20:47:21,165 - INFO - root - get_all_titles_from_web 
2025-11-09 20:47:21,165 - INFO - root - Page:3, Index:0, DPASyn: Mechanism-Aware Drug Synergy Prediction via Dual Attention and Precision-Aware Quantization, https://arxiv.org/pdf/2505.19144, 2025-09-20
2025-11-09 20:47:21,166 - INFO - root - Page:3, Index:1, Reducing Storage of Pretrained Neural Networks by Rate-Constrained Quantization and Entropy Coding, https://arxiv.org/pdf/2505.18758, 2025-05-24
2025-11-09 20:47:21,166 - INFO - root - Page:3, Index:2, Beyond Discreteness: Finite-Sample Analysis of Straight-Through Estimator for Quantization, https://arxiv.org/pdf/2505.18113, 2025-05-23
2025-11-09 20:47:21,166 - INFO - root - Page:3, Index:3, Automating Versatile Time-Series Analysis with Tiny Transformers on Embedded FPGAs, https://arxiv.org/pdf/2505.17662, 2025-09-19
2025-11-09 20:47:21,167 - INFO - root - Page:3, Index:4, FPQVAR: Floating Point Quantization for Visual Autoregressive Model with FPGA Hardware Co-design, https://arxiv.org/pdf/2505.16335, 2025-05-22
2025-11-09 20:47:21,167 - INFO - root - Page:3, Index:5, Saliency-Aware Quantized Imitation Learning for Efficient Robotic Control, https://arxiv.org/pdf/2505.15304, 2025-05-30
2025-11-09 20:47:21,167 - INFO - root - Page:3, Index:6, Scaling Law for Quantization-Aware Training, https://arxiv.org/pdf/2505.14302, 2025-05-20
2025-11-09 20:47:21,167 - INFO - root - Page:3, Index:7, Automatic mixed precision for optimizing gained time with constrained loss mean-squared-error based on model partition to sequential sub-graphs, https://arxiv.org/pdf/2505.13060, 2025-05-19
2025-11-09 20:47:21,168 - INFO - root - Page:3, Index:8, Deep Unfolding with Kernel-based Quantization in MIMO Detection, https://arxiv.org/pdf/2505.12736, 2025-05-19
2025-11-09 20:47:21,168 - INFO - root - Page:3, Index:9, FedHQ: Hybrid Runtime Quantization for Federated Learning, https://arxiv.org/pdf/2505.11982, 2025-05-17
2025-11-09 20:47:21,169 - INFO - root - Page:3, Index:10, QVGen: Pushing the Limit of Quantized Video Generative Models, https://arxiv.org/pdf/2505.11497, 2025-09-27
2025-11-09 20:47:21,169 - INFO - root - Page:3, Index:11, EA-3DGS: Efficient and Adaptive 3D Gaussians with Highly Enhanced Quality for outdoor scenes, https://arxiv.org/pdf/2505.10787, 2025-05-15
2025-11-09 20:47:21,169 - INFO - root - Page:3, Index:12, ITERA-LLM: Boosting Sub-8-Bit Large Language Model Inference via Iterative Tensor Decomposition, https://arxiv.org/pdf/2505.08981, 2025-05-13
2025-11-09 20:47:21,170 - INFO - root - Page:3, Index:13, PROM: Prioritize Reduction of Multiplications Over Lower Bit-Widths for Efficient CNNs, https://arxiv.org/pdf/2505.03254, 2025-08-06
2025-11-09 20:47:21,170 - INFO - root - Page:3, Index:14, ICQuant: Index Coding enables Low-bit LLM Quantization, https://arxiv.org/pdf/2505.00850, 2025-08-24
2025-11-09 20:47:21,170 - INFO - root - Page:3, Index:15, Enhancing Ultra-Low-Bit Quantization of Large Language Models Through Saliency-Aware Partial Retraining, https://arxiv.org/pdf/2504.13932, 2025-07-30
2025-11-09 20:47:21,171 - INFO - root - Page:3, Index:16, Achieving binary weight and activation for LLMs using Post-Training Quantization, https://arxiv.org/pdf/2504.05352, 2025-06-30
2025-11-09 20:47:21,171 - INFO - root - Page:3, Index:17, Wireless Hearables With Programmable Speech AI Accelerators, https://arxiv.org/pdf/2503.18698, 2025-10-21
2025-11-09 20:47:21,171 - INFO - root - Page:3, Index:18, GranQ: Efficient Channel-wise Quantization via Vectorized Pre-Scaling for Zero-Shot QAT, https://arxiv.org/pdf/2503.18339, 2025-10-15
2025-11-09 20:47:21,173 - INFO - root - Page:3, Index:19, CompMarkGS: Robust Watermarking for Compressed 3D Gaussian Splatting, https://arxiv.org/pdf/2503.12836, 2025-09-29
2025-11-09 20:47:21,173 - INFO - root - Page:3, Index:20, AHCPTQ: Accurate and Hardware-Compatible Post-Training Quantization for Segment Anything Model, https://arxiv.org/pdf/2503.03088, 2025-07-11
2025-11-09 20:47:21,173 - INFO - root - Page:3, Index:21, Teaching Metric Distance to Discrete Autoregressive Language Models, https://arxiv.org/pdf/2503.02379, 2025-10-07
2025-11-09 20:47:21,173 - INFO - root - Page:3, Index:22, Regularization-based Framework for Quantization-, Fault- and Variability-Aware Training, https://arxiv.org/pdf/2503.01297, 2025-07-12
2025-11-09 20:47:21,174 - INFO - root - Fetching page 5 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=200
2025-11-09 20:47:28,424 - INFO - root - get_all_titles_from_web 
2025-11-09 20:47:28,424 - INFO - root - Page:4, Index:0, Investigating the Impact of Quantization Methods on the Safety and Reliability of Large Language Models, https://arxiv.org/pdf/2502.15799, 2025-06-29
2025-11-09 20:47:28,425 - INFO - root - Page:4, Index:1, Rotate, Clip, and Partition: Towards W2A4KV4 Quantization by Integrating Rotation and Learnable Non-uniform Quantizer, https://arxiv.org/pdf/2502.15779, 2025-09-01
2025-11-09 20:47:28,425 - INFO - root - Page:4, Index:2, RoSTE: An Efficient Quantization-Aware Supervised Fine-Tuning Approach for Large Language Models, https://arxiv.org/pdf/2502.09003, 2025-06-05
2025-11-09 20:47:28,425 - INFO - root - Page:4, Index:3, Spatial Degradation-Aware and Temporal Consistent Diffusion Model for Compressed Video Super-Resolution, https://arxiv.org/pdf/2502.07381, 2025-06-27
2025-11-09 20:47:28,426 - INFO - root - Page:4, Index:4, QuEST: Stable Training of LLMs with 1-Bit Weights and Activations, https://arxiv.org/pdf/2502.05003, 2025-06-10
2025-11-09 20:47:28,426 - INFO - root - Page:4, Index:5, HALO: Hadamard-Assisted Lower-Precision Optimization for LLMs, https://arxiv.org/pdf/2501.02625, 2025-11-05
2025-11-09 20:47:28,427 - INFO - root - Page:4, Index:6, TAR3D: Creating High-Quality 3D Assets via Next-Part Prediction, https://arxiv.org/pdf/2412.16919, 2025-08-08
2025-11-09 20:47:28,427 - INFO - root - Page:4, Index:7, Training Multi-Layer Binary Neural Networks With Local Binary Error Signals, https://arxiv.org/pdf/2412.00119, 2025-08-05
2025-11-09 20:47:28,428 - INFO - root - Page:4, Index:8, Scaling Large-scale GNN Training to Thousands of Processors on CPU-based Supercomputers, https://arxiv.org/pdf/2411.16025, 2025-05-26
2025-11-09 20:47:28,428 - INFO - root - Page:4, Index:9, HAFLQ: Heterogeneous Adaptive Federated LoRA Fine-tuned LLM with Quantization, https://arxiv.org/pdf/2411.06581, 2025-05-16
2025-11-09 20:47:28,428 - INFO - root - Fetching page 6 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=250
2025-11-09 20:47:34,860 - INFO - root - get_all_titles_from_web 
2025-11-09 20:47:34,860 - INFO - root - Page:5, Index:0, Gradient-Free Training of Quantized Neural Networks, https://arxiv.org/pdf/2410.09734, 2025-09-29
2025-11-09 20:47:34,861 - INFO - root - Page:5, Index:1, QT-DoG: Quantization-aware Training for Domain Generalization, https://arxiv.org/pdf/2410.06020, 2025-06-26
2025-11-09 20:47:34,861 - INFO - root - Page:5, Index:2, Constraint Guided Model Quantization of Neural Networks, https://arxiv.org/pdf/2409.20138, 2025-09-12
2025-11-09 20:47:34,861 - INFO - root - Page:5, Index:3, Accumulator-Aware Post-Training Quantization for Large Language Models, https://arxiv.org/pdf/2409.17092, 2025-07-30
2025-11-09 20:47:34,861 - INFO - root - Page:5, Index:4, DilateQuant: Accurate and Efficient Diffusion Quantization via Weight Dilation, https://arxiv.org/pdf/2409.14307, 2025-07-09
2025-11-09 20:47:34,862 - INFO - root - Page:5, Index:5, Robust Training of Neural Networks at Arbitrary Precision and Sparsity, https://arxiv.org/pdf/2409.09245, 2025-09-23
2025-11-09 20:47:34,862 - INFO - root - Page:5, Index:6, VQ-CTAP: Cross-Modal Fine-Grained Sequence Representation Learning for Speech Processing, https://arxiv.org/pdf/2408.05758, 2025-05-27
2025-11-09 20:47:34,862 - INFO - root - Page:5, Index:7, DopQ-ViT: Towards Distribution-Friendly and Outlier-Aware Post-Training Quantization for Vision Transformers, https://arxiv.org/pdf/2408.03291, 2025-06-19
2025-11-09 20:47:34,862 - INFO - root - Page:5, Index:8, Temporal Feature Matters: A Framework for Diffusion Model Quantization, https://arxiv.org/pdf/2407.19547, 2025-07-11
2025-11-09 20:47:34,863 - INFO - root - Page:5, Index:9, EfficientQAT: Efficient Quantization-Aware Training for Large Language Models, https://arxiv.org/pdf/2407.11062, 2025-05-19
2025-11-09 20:47:34,863 - INFO - root - Page:5, Index:10, Integer-only Quantized Transformers for Embedded FPGA-based Time-series Forecasting in AIoT, https://arxiv.org/pdf/2407.11041, 2025-10-31
2025-11-09 20:47:34,863 - INFO - root - Fetching page 7 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=300
2025-11-09 20:47:41,801 - INFO - root - get_all_titles_from_web 
2025-11-09 20:47:41,801 - INFO - root - Page:6, Index:0, BoA: Attention-aware Post-training Quantization without Backpropagation, https://arxiv.org/pdf/2406.13474, 2025-06-06
2025-11-09 20:47:41,802 - INFO - root - Page:6, Index:1, A Rescaling-Invariant Lipschitz Bound Based on Path-Metrics for Modern ReLU Network Parameterizations, https://arxiv.org/pdf/2405.15006, 2025-06-13
2025-11-09 20:47:41,802 - INFO - root - Page:6, Index:2, Scheduling Weight Transitions for Quantization-Aware Training, https://arxiv.org/pdf/2404.19248, 2025-10-01
2025-11-09 20:47:41,802 - INFO - root - Page:6, Index:3, GPTVQ: The Blessing of Dimensionality for LLM Quantization, https://arxiv.org/pdf/2402.15319, 2025-06-03
2025-11-09 20:47:41,802 - INFO - root - Fetching page 8 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=350
2025-11-09 20:47:49,075 - INFO - root - get_all_titles_from_web 
2025-11-09 20:47:49,075 - INFO - root - Page:7, Index:0, Squat: Quant Small Language Models on the Edge, https://arxiv.org/pdf/2402.10787, 2025-07-01
2025-11-09 20:47:49,075 - INFO - root - Page:7, Index:1, L4Q: Parameter Efficient Quantization-Aware Fine-Tuning on Large Language Models, https://arxiv.org/pdf/2402.04902, 2025-07-21
2025-11-09 20:47:49,076 - INFO - root - Fetching page 9 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=400
2025-11-09 20:47:55,416 - INFO - root - ------------------------------------------------------------------------------------------------------------------------
2025-11-09 20:47:55,417 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\A Quantized VAE-MLP Botnet Detection Model_ A Systematic Evaluation of Quantizat.pdf
2025-11-09 20:47:55,418 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\FP8-Flow-MoE_ A Casting-Free FP8 Recipe without Double Quantization Error.pdf
2025-11-09 20:47:55,421 - INFO - root - 跳过已处理论文 A Quantized VAE-MLP Botnet Detection Model: A Systematic Evaluation of Quantization-Aware Training and Post-Training Quantization Strategies：d:\ChatPaper\academic Papers\Quantization-Aware-Training\A Quantized VAE-MLP Botnet Detection Model_ A Systematic Evaluation of Quantizat.pdf
2025-11-09 20:47:55,421 - INFO - root - 跳过已处理论文 FP8-Flow-MoE: A Casting-Free FP8 Recipe without Double Quantization Error：d:\ChatPaper\academic Papers\Quantization-Aware-Training\FP8-Flow-MoE_ A Casting-Free FP8 Recipe without Double Quantization Error.pdf
2025-11-09 20:47:55,421 - INFO - root - summary time: 69.47 seconds
2025-11-09 20:51:41,855 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-09 20:51:41,857 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-09 20:51:41,858 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-09 20:51:42,908 - INFO - root - LLMClientManager: 指定使用客户端: DeepSeek
2025-11-09 20:51:42,908 - INFO - root - DeepSeekClient: API key found: 9f9e270e-b...
2025-11-09 20:51:42,909 - INFO - root - DeepSeekClient: 使用模式: 火山引擎
2025-11-09 20:51:42,909 - INFO - root - DeepSeekClient: 模型名称: deepseek-v3-1-terminus
2025-11-09 20:51:47,545 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 20:51:47,574 - INFO - root - DeepSeekClient: initialized successfully with model deepseek-v3-1-terminus
2025-11-09 20:51:47,574 - INFO - root - LLMClientManager: DeepSeek 客户端初始化成功
2025-11-09 20:51:47,576 - INFO - root - LLMClientManager: switched to DeepSeek client
2025-11-09 20:51:47,577 - INFO - root - 已手动切换到 LLM 客户端: DeepSeek
2025-11-09 20:51:47,578 - INFO - root - 使用 LLM 模型: deepseek-v3-1-terminus
2025-11-09 20:51:47,579 - INFO - root - 可用客户端: ['DeepSeek']
2025-11-09 20:51:47,579 - INFO - root - === 运行配置 ===
2025-11-09 20:51:47,581 - INFO - root - 处理模式: arxiv在线搜索
2025-11-09 20:51:47,583 - INFO - root - 关键词: QAT
2025-11-09 20:51:47,583 - INFO - root - 查询: Quantization-Aware-Training
2025-11-09 20:51:47,583 - INFO - root - 排序: None
2025-11-09 20:51:47,584 - INFO - root - 最近天数: 180
2025-11-09 20:51:47,584 - INFO - root - 最大处理数量: 2
2025-11-09 20:51:47,584 - INFO - root - 保存图片: 是
2025-11-09 20:51:47,591 - INFO - root - 输出语言: 中文
2025-11-09 20:51:47,591 - INFO - root - 强制重新处理: 否
2025-11-09 20:51:47,591 - INFO - root - ====================
2025-11-09 20:51:47,592 - INFO - root - 使用 arXiv 搜索模式（通过 chat_arxiv 模块获取）
2025-11-09 20:51:47,592 - INFO - root - Fetching page 1 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50
2025-11-09 20:51:54,182 - INFO - root - get_all_titles_from_web 
2025-11-09 20:51:54,183 - INFO - root - Page:0, Index:0, A Quantized VAE-MLP Botnet Detection Model: A Systematic Evaluation of Quantization-Aware Training and Post-Training Quantization Strategies, https://arxiv.org/pdf/2511.03201, 2025-11-05
2025-11-09 20:51:54,183 - INFO - root - Page:0, Index:1, FP8-Flow-MoE: A Casting-Free FP8 Recipe without Double Quantization Error, https://arxiv.org/pdf/2511.02302, 2025-11-04
2025-11-09 20:51:54,183 - INFO - root - Page:0, Index:2, Outlier-Aware Post-Training Quantization for Image Super-Resolution, https://arxiv.org/pdf/2511.00682, 2025-11-01
2025-11-09 20:51:54,183 - INFO - root - Page:0, Index:3, Evaluation of Wafer-Scale SOT-MRAM for Analog Crossbar Array Applications, https://arxiv.org/pdf/2510.25853, 2025-11-03
2025-11-09 20:51:54,184 - INFO - root - Page:0, Index:4, Improving the Straight-Through Estimator with Zeroth-Order Information, https://arxiv.org/pdf/2510.23926, 2025-10-27
2025-11-09 20:51:54,184 - INFO - root - Page:0, Index:5, Real-Time Semantic Segmentation on FPGA for Autonomous Vehicles Using LMIINet with the CGRA4ML Framework, https://arxiv.org/pdf/2510.22243, 2025-10-25
2025-11-09 20:51:54,184 - INFO - root - Page:0, Index:6, TernaryCLIP: Efficiently Compressing Vision-Language Models with Ternary Weights and Distilled Knowledge, https://arxiv.org/pdf/2510.21879, 2025-10-23
2025-11-09 20:51:54,185 - INFO - root - Page:0, Index:7, KARIPAP: Quantum-Inspired Tensor Network Compression of Large Language Models Using Infinite Projected Entangled Pair States and Tensor Renormalization Group, https://arxiv.org/pdf/2510.21844, 2025-10-22
2025-11-09 20:51:54,185 - INFO - root - Page:0, Index:8, A Convergence Analysis of Adaptive Optimizers under Floating-point Quantization, https://arxiv.org/pdf/2510.21314, 2025-10-24
2025-11-09 20:51:54,185 - INFO - root - Page:0, Index:9, Adaptive Distribution-aware Quantization for Mixed-Precision Neural Networks, https://arxiv.org/pdf/2510.19760, 2025-10-22
2025-11-09 20:51:54,185 - INFO - root - Page:0, Index:10, CAGE: Curvature-Aware Gradient Estimation For Accurate Quantization-Aware Training, https://arxiv.org/pdf/2510.18784, 2025-10-21
2025-11-09 20:51:54,186 - INFO - root - Page:0, Index:11, Mixed-Precision Quantization for Language Models: Techniques and Prospects, https://arxiv.org/pdf/2510.16805, 2025-10-19
2025-11-09 20:51:54,186 - INFO - root - Page:0, Index:12, SPLite Hand: Sparsity-Aware Lightweight 3D Hand Pose Estimation, https://arxiv.org/pdf/2510.16396, 2025-10-30
2025-11-09 20:51:54,186 - INFO - root - Page:0, Index:13, CTR-LoRA: Curvature-Aware and Trust-Region Guided Low-Rank Adaptation for Large Language Models, https://arxiv.org/pdf/2510.15962, 2025-10-11
2025-11-09 20:51:54,186 - INFO - root - Page:0, Index:14, SANR: Scene-Aware Neural Representation for Light Field Image Compression with Rate-Distortion Optimization, https://arxiv.org/pdf/2510.15775, 2025-10-17
2025-11-09 20:51:54,186 - INFO - root - Page:0, Index:15, SpikeFit: Towards Optimal Deployment of Spiking Networks on Neuromorphic Hardware, https://arxiv.org/pdf/2510.15542, 2025-10-31
2025-11-09 20:51:54,187 - INFO - root - Page:0, Index:16, GRank: Towards Target-Aware and Streamlined Industrial Retrieval with a Generate-Rank Framework, https://arxiv.org/pdf/2510.15299, 2025-10-17
2025-11-09 20:51:54,187 - INFO - root - Page:0, Index:17, SaLon3R: Structure-aware Long-term Generalizable 3D Reconstruction from Unposed Images, https://arxiv.org/pdf/2510.15072, 2025-10-16
2025-11-09 20:51:54,187 - INFO - root - Page:0, Index:18, FraQAT: Quantization Aware Training with Fractional bits, https://arxiv.org/pdf/2510.14823, 2025-10-16
2025-11-09 20:51:54,188 - INFO - root - Page:0, Index:19, Computing-In-Memory Aware Model Adaption For Edge Devices, https://arxiv.org/pdf/2510.14379, 2025-10-16
2025-11-09 20:51:54,189 - INFO - root - Page:0, Index:20, Invited Paper: BitMedViT: Ternary-Quantized Vision Transformer for Medical AI Assistants on the Edge, https://arxiv.org/pdf/2510.13760, 2025-11-04
2025-11-09 20:51:54,189 - INFO - root - Page:0, Index:21, NeuroRVQ: Multi-Scale EEG Tokenization for Generative Large Brainwave Models, https://arxiv.org/pdf/2510.13068, 2025-10-14
2025-11-09 20:51:54,189 - INFO - root - Page:0, Index:22, Detect Anything via Next Point Prediction, https://arxiv.org/pdf/2510.12798, 2025-10-14
2025-11-09 20:51:54,190 - INFO - root - Page:0, Index:23, AndesVL Technical Report: An Efficient Mobile-side Multimodal Large Language Model, https://arxiv.org/pdf/2510.11496, 2025-10-14
2025-11-09 20:51:54,190 - INFO - root - Page:0, Index:24, Rescaling-Aware Training for Efficient Deployment of Deep Learning Models on Full-Integer Hardware, https://arxiv.org/pdf/2510.11484, 2025-10-13
2025-11-09 20:51:54,190 - INFO - root - Page:0, Index:25, SASER: Stego attacks on open-source LLMs, https://arxiv.org/pdf/2510.10486, 2025-10-12
2025-11-09 20:51:54,195 - INFO - root - Page:0, Index:26, Ultralytics YOLO Evolution: An Overview of YOLO26, YOLO11, YOLOv8 and YOLOv5 Object Detectors for Computer Vision and Pattern Recognition, https://arxiv.org/pdf/2510.09653, 2025-10-15
2025-11-09 20:51:54,196 - INFO - root - Page:0, Index:27, A Theoretically-Grounded Codebook for Digital Semantic Communications, https://arxiv.org/pdf/2510.07108, 2025-10-14
2025-11-09 20:51:54,198 - INFO - root - Page:0, Index:28, QuantDemoire: Quantization with Outlier Aware for Image Demoiréing, https://arxiv.org/pdf/2510.04066, 2025-10-05
2025-11-09 20:51:54,198 - INFO - root - Page:0, Index:29, Adaptively Sampling-Reusing-Mixing Decomposed Gradients to Speed Up Sharpness Aware Minimization, https://arxiv.org/pdf/2510.03763, 2025-10-04
2025-11-09 20:51:54,199 - INFO - root - Page:0, Index:30, Quant-dLLM: Post-Training Extreme Low-Bit Quantization for Diffusion Large Language Models, https://arxiv.org/pdf/2510.03274, 2025-09-27
2025-11-09 20:51:54,199 - INFO - root - Page:0, Index:31, PT$^2$-LLM: Post-Training Ternarization for Large Language Models, https://arxiv.org/pdf/2510.03267, 2025-09-26
2025-11-09 20:51:54,199 - INFO - root - Page:0, Index:32, Purrception: Variational Flow Matching for Vector-Quantized Image Generation, https://arxiv.org/pdf/2510.01478, 2025-10-01
2025-11-09 20:51:54,199 - INFO - root - Page:0, Index:33, Post-Training Quantization for Audio Diffusion Transformers, https://arxiv.org/pdf/2510.00313, 2025-09-30
2025-11-09 20:51:54,200 - INFO - root - Page:0, Index:34, Rethinking RoPE Scaling in Quantized LLM: Theory, Outlier, and Channel-Band Analysis with Weight Rescaling, https://arxiv.org/pdf/2510.00028, 2025-09-25
2025-11-09 20:51:54,200 - INFO - root - Page:0, Index:35, Post-Training Quantization via Residual Truncation and Zero Suppression for Diffusion Models, https://arxiv.org/pdf/2509.26436, 2025-09-30
2025-11-09 20:51:54,200 - INFO - root - Page:0, Index:36, Cat: Post-Training Quantization Error Reduction via Cluster-based Affine Transformation, https://arxiv.org/pdf/2509.26277, 2025-10-07
2025-11-09 20:51:54,200 - INFO - root - Page:0, Index:37, CAST: Continuous and Differentiable Semi-Structured Sparsity-Aware Training for Large Language Models, https://arxiv.org/pdf/2509.25996, 2025-09-30
2025-11-09 20:51:54,201 - INFO - root - Page:0, Index:38, Norm-Q: Effective Compression Method for Hidden Markov Models in Neuro-Symbolic Applications, https://arxiv.org/pdf/2509.25439, 2025-09-29
2025-11-09 20:51:54,201 - INFO - root - Page:0, Index:39, On-the-Fly Adaptation to Quantization: Configuration-Aware LoRA for Efficient Fine-Tuning of Quantized LLMs, https://arxiv.org/pdf/2509.25214, 2025-09-22
2025-11-09 20:51:54,201 - INFO - root - Page:0, Index:40, VoxCPM: Tokenizer-Free TTS for Context-Aware Speech Generation and True-to-Life Voice Cloning, https://arxiv.org/pdf/2509.24650, 2025-09-29
2025-11-09 20:51:54,202 - INFO - root - Page:0, Index:41, S$^2$NN: Sub-bit Spiking Neural Networks, https://arxiv.org/pdf/2509.24266, 2025-10-24
2025-11-09 20:51:54,202 - INFO - root - Page:0, Index:42, Tequila: Trapping-free Ternary Quantization for Large Language Models, https://arxiv.org/pdf/2509.23809, 2025-10-17
2025-11-09 20:51:54,202 - INFO - root - Page:0, Index:43, Texture Vector-Quantization and Reconstruction Aware Prediction for Generative Super-Resolution, https://arxiv.org/pdf/2509.23774, 2025-09-30
2025-11-09 20:51:54,203 - INFO - root - Page:0, Index:44, RobuQ: Pushing DiTs to W1.58A2 via Robust Activation Quantization, https://arxiv.org/pdf/2509.23582, 2025-09-27
2025-11-09 20:51:54,203 - INFO - root - Page:0, Index:45, Beyond Outliers: A Study of Optimizers Under Quantization, https://arxiv.org/pdf/2509.23500, 2025-10-02
2025-11-09 20:51:54,203 - INFO - root - Page:0, Index:46, Compute-Optimal Quantization-Aware Training, https://arxiv.org/pdf/2509.22935, 2025-09-26
2025-11-09 20:51:54,203 - INFO - root - Page:0, Index:47, COSPADI: Compressing LLMs via Calibration-Guided Sparse Dictionary Learning, https://arxiv.org/pdf/2509.22075, 2025-10-06
2025-11-09 20:51:54,204 - INFO - root - Page:0, Index:48, SlimDiff: Training-Free, Activation-Guided Hands-free Slimming of Diffusion Models, https://arxiv.org/pdf/2509.21498, 2025-09-25
2025-11-09 20:51:54,205 - INFO - root - Page:0, Index:49, Quantized Visual Geometry Grounded Transformer, https://arxiv.org/pdf/2509.21302, 2025-09-29
2025-11-09 20:51:54,205 - INFO - root - Fetching page 2 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=50
2025-11-09 20:52:01,885 - INFO - root - get_all_titles_from_web 
2025-11-09 20:52:01,886 - INFO - root - Page:1, Index:0, Can Less Precise Be More Reliable? A Systematic Evaluation of Quantization's Impact on CLIP Beyond Accuracy, https://arxiv.org/pdf/2509.21173, 2025-10-27
2025-11-09 20:52:01,886 - INFO - root - Page:1, Index:1, Punching Above Precision: Small Quantized Model Distillation with Learnable Regularizer, https://arxiv.org/pdf/2509.20854, 2025-09-25
2025-11-09 20:52:01,886 - INFO - root - Page:1, Index:2, TinyEcoWeedNet: Edge Efficient Real-Time Aerial Agricultural Weed Detection, https://arxiv.org/pdf/2509.18193, 2025-09-19
2025-11-09 20:52:01,886 - INFO - root - Page:1, Index:3, SBVR: Summation of BitVector Representation for Efficient LLM Quantization, https://arxiv.org/pdf/2509.18172, 2025-09-17
2025-11-09 20:52:01,888 - INFO - root - Page:1, Index:4, QWHA: Quantization-Aware Walsh-Hadamard Adaptation for Parameter-Efficient Fine-Tuning on Large Language Models, https://arxiv.org/pdf/2509.17428, 2025-09-26
2025-11-09 20:52:01,888 - INFO - root - Page:1, Index:5, PTQTP: Post-Training Quantization to Trit-Planes for Large Language Models, https://arxiv.org/pdf/2509.16989, 2025-10-28
2025-11-09 20:52:01,888 - INFO - root - Page:1, Index:6, MEC-Quant: Maximum Entropy Coding for Extremely Low Bit Quantization-Aware Training, https://arxiv.org/pdf/2509.15514, 2025-09-18
2025-11-09 20:52:01,888 - INFO - root - Page:1, Index:7, Q-ROAR: Outlier-Aware Rescaling for RoPE Position Interpolation in Quantized Long-Context LLMs, https://arxiv.org/pdf/2509.14391, 2025-09-17
2025-11-09 20:52:01,888 - INFO - root - Page:1, Index:8, Efficient Quantization-Aware Neural Receivers: Beyond Post-Training Quantization, https://arxiv.org/pdf/2509.13786, 2025-09-19
2025-11-09 20:52:01,889 - INFO - root - Page:1, Index:9, Rate-Distortion Limits for Multimodal Retrieval: Theory, Optimal Codes, and Finite-Sample Guarantees, https://arxiv.org/pdf/2509.11054, 2025-09-13
2025-11-09 20:52:01,890 - INFO - root - Page:1, Index:10, SQAP-VLA: A Synergistic Quantization-Aware Pruning Framework for High-Performance Vision-Language-Action Models, https://arxiv.org/pdf/2509.09090, 2025-09-10
2025-11-09 20:52:01,890 - INFO - root - Page:1, Index:11, CSI Compression Beyond Latents: End-to-End Hybrid Attention-CNN Networks with Entropy Regularization, https://arxiv.org/pdf/2509.08776, 2025-09-10
2025-11-09 20:52:01,890 - INFO - root - Page:1, Index:12, Explaining How Quantization Disparately Skews a Model, https://arxiv.org/pdf/2509.07222, 2025-09-08
2025-11-09 20:52:01,890 - INFO - root - Page:1, Index:13, LoaQ: Layer-wise Output Approximation Quantization, https://arxiv.org/pdf/2509.06297, 2025-09-07
2025-11-09 20:52:01,891 - INFO - root - Page:1, Index:14, FineServe: Precision-Aware KV Slab and Two-Level Scheduling for Heterogeneous Precision LLM Serving, https://arxiv.org/pdf/2509.06261, 2025-09-14
2025-11-09 20:52:01,891 - INFO - root - Page:1, Index:15, Sensitivity-Aware Post-Training Quantization for Deep Neural Networks, https://arxiv.org/pdf/2509.05576, 2025-09-05
2025-11-09 20:52:01,892 - INFO - root - Page:1, Index:16, SuperSNN: A Hardware-Aware Framework for Physically Realizable, High-Performance Superconducting Spiking Neural Network Chips, https://arxiv.org/pdf/2509.05532, 2025-09-05
2025-11-09 20:52:01,892 - INFO - root - Page:1, Index:17, Data-Augmented Quantization-Aware Knowledge Distillation, https://arxiv.org/pdf/2509.03850, 2025-09-03
2025-11-09 20:52:01,893 - INFO - root - Page:1, Index:18, DPQuant: Efficient and Differentially-Private Model Training via Dynamic Quantization Scheduling, https://arxiv.org/pdf/2509.03472, 2025-09-03
2025-11-09 20:52:01,893 - INFO - root - Page:1, Index:19, Empowering Large Language Model for Sequential Recommendation via Multimodal Embeddings and Semantic IDs, https://arxiv.org/pdf/2509.02017, 2025-09-02
2025-11-09 20:52:01,893 - INFO - root - Page:1, Index:20, Q-Sched: Pushing the Boundaries of Few-Step Diffusion Models with Quantization-Aware Scheduling, https://arxiv.org/pdf/2509.01624, 2025-09-01
2025-11-09 20:52:01,893 - INFO - root - Page:1, Index:21, Quantization Meets OOD: Generalizable Quantization-aware Training from a Flatness Perspective, https://arxiv.org/pdf/2509.00859, 2025-08-31
2025-11-09 20:52:01,894 - INFO - root - Page:1, Index:22, Progressive Element-wise Gradient Estimation for Neural Network Quantization, https://arxiv.org/pdf/2509.00097, 2025-08-27
2025-11-09 20:52:01,894 - INFO - root - Page:1, Index:23, End-to-End On-Device Quantization-Aware Training for LLMs at Inference Cost, https://arxiv.org/pdf/2509.00031, 2025-09-29
2025-11-09 20:52:01,894 - INFO - root - Page:1, Index:24, Quantization Robustness to Input Degradations for Object Detection, https://arxiv.org/pdf/2508.19600, 2025-08-27
2025-11-09 20:52:01,894 - INFO - root - Page:1, Index:25, Scaling Laws for Task-Stratified Knowledge in Post-Training Quantized Large Language Models, https://arxiv.org/pdf/2508.18609, 2025-08-27
2025-11-09 20:52:01,896 - INFO - root - Page:1, Index:26, AQ-PCDSys: An Adaptive Quantized Planetary Crater Detection System for Autonomous Space Exploration, https://arxiv.org/pdf/2508.18025, 2025-08-25
2025-11-09 20:52:01,896 - INFO - root - Page:1, Index:27, TaDiCodec: Text-aware Diffusion Speech Tokenizer for Speech Language Modeling, https://arxiv.org/pdf/2508.16790, 2025-08-22
2025-11-09 20:52:01,896 - INFO - root - Page:1, Index:28, A Node-Aware Dynamic Quantization Approach for Graph Collaborative Filtering, https://arxiv.org/pdf/2508.16516, 2025-08-22
2025-11-09 20:52:01,897 - INFO - root - Page:1, Index:29, JEDI-linear: Fast and Efficient Graph Neural Networks for Jet Tagging on FPGAs, https://arxiv.org/pdf/2508.15468, 2025-08-21
2025-11-09 20:52:01,897 - INFO - root - Page:1, Index:30, MMQ: Multimodal Mixture-of-Quantization Tokenization for Semantic ID Generation and User Behavioral Adaptation, https://arxiv.org/pdf/2508.15281, 2025-08-21
2025-11-09 20:52:01,897 - INFO - root - Page:1, Index:31, DLLMQuant: Quantizing Diffusion-based Large Language Models, https://arxiv.org/pdf/2508.14090, 2025-08-25
2025-11-09 20:52:01,897 - INFO - root - Page:1, Index:32, Automated Energy-Aware Time-Series Model Deployment on Embedded FPGAs for Resilient Combined Sewer Overflow Management, https://arxiv.org/pdf/2508.13905, 2025-08-19
2025-11-09 20:52:01,909 - INFO - root - Page:1, Index:33, XR-NPE: High-Throughput Mixed-precision SIMD Neural Processing Engine for Extended Reality Perception Workloads, https://arxiv.org/pdf/2508.13049, 2025-08-18
2025-11-09 20:52:01,909 - INFO - root - Page:1, Index:34, Exploring Self-Supervised Audio Models for Generalized Anomalous Sound Detection, https://arxiv.org/pdf/2508.12230, 2025-08-17
2025-11-09 20:52:01,910 - INFO - root - Page:1, Index:35, TriQDef: Disrupting Semantic and Gradient Alignment to Prevent Adversarial Patch Transferability in Quantized Neural Networks, https://arxiv.org/pdf/2508.12132, 2025-08-16
2025-11-09 20:52:01,911 - INFO - root - Page:1, Index:36, Error Propagation Mechanisms and Compensation Strategies for Quantized Diffusion, https://arxiv.org/pdf/2508.12094, 2025-10-13
2025-11-09 20:52:01,912 - INFO - root - Page:1, Index:37, Extending Straight-Through Estimation for Robust Neural Networks on Analog CIM Hardware, https://arxiv.org/pdf/2508.11940, 2025-08-16
2025-11-09 20:52:01,912 - INFO - root - Page:1, Index:38, PTQAT: A Hybrid Parameter-Efficient Quantization Algorithm for 3D Perception Tasks, https://arxiv.org/pdf/2508.10557, 2025-08-15
2025-11-09 20:52:01,912 - INFO - root - Page:1, Index:39, MiCo: End-to-End Mixed Precision Neural Network Co-Exploration Framework for Edge AI, https://arxiv.org/pdf/2508.09500, 2025-08-13
2025-11-09 20:52:01,912 - INFO - root - Page:1, Index:40, SPARC: Soft Probabilistic Adaptive multi-interest Retrieval Model via Codebooks for recommender system, https://arxiv.org/pdf/2508.09090, 2025-08-12
2025-11-09 20:52:01,914 - INFO - root - Page:1, Index:41, Rethinking 1-bit Optimization Leveraging Pre-trained Large Language Models, https://arxiv.org/pdf/2508.06974, 2025-08-09
2025-11-09 20:52:01,915 - INFO - root - Page:1, Index:42, Efficient Deep Neural Receiver with Post-Training Quantization, https://arxiv.org/pdf/2508.06275, 2025-08-08
2025-11-09 20:52:01,915 - INFO - root - Page:1, Index:43, iFairy: the First 2-bit Complex LLM with All Parameters in $\{\pm1, \pm i\}$, https://arxiv.org/pdf/2508.05571, 2025-08-16
2025-11-09 20:52:01,915 - INFO - root - Page:1, Index:44, S$^2$Q-VDiT: Accurate Quantized Video Diffusion Transformer with Salient Data and Sparse Token Distillation, https://arxiv.org/pdf/2508.04016, 2025-10-27
2025-11-09 20:52:01,920 - INFO - root - Page:1, Index:45, LRQ-DiT: Log-Rotation Post-Training Quantization of Diffusion Transformers for Image and Video Generation, https://arxiv.org/pdf/2508.03485, 2025-09-23
2025-11-09 20:52:01,920 - INFO - root - Page:1, Index:46, VLMQ: Efficient Post-Training Quantization for Large Vision-Language Models via Hessian Augmentation, https://arxiv.org/pdf/2508.03351, 2025-08-05
2025-11-09 20:52:01,920 - INFO - root - Page:1, Index:47, TF-MLPNet: Tiny Real-Time Neural Speech Separation, https://arxiv.org/pdf/2508.03047, 2025-08-04
2025-11-09 20:52:01,922 - INFO - root - Page:1, Index:48, SaviorRec: Semantic-Behavior Alignment for Cold-Start Recommendation, https://arxiv.org/pdf/2508.01375, 2025-08-02
2025-11-09 20:52:01,922 - INFO - root - Page:1, Index:49, MixA-Q: Revisiting Activation Sparsity for Vision Transformers from a Mixed-Precision Quantization Perspective, https://arxiv.org/pdf/2507.19131, 2025-07-25
2025-11-09 20:52:01,923 - INFO - root - Fetching page 3 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=100
2025-11-09 20:52:08,418 - INFO - root - get_all_titles_from_web 
2025-11-09 20:52:08,418 - INFO - root - Page:2, Index:0, Enhancing Quantization-Aware Training on Edge Devices via Relative Entropy Coreset Selection and Cascaded Layer Correction, https://arxiv.org/pdf/2507.17768, 2025-07-16
2025-11-09 20:52:08,419 - INFO - root - Page:2, Index:1, SiLQ: Simple Large Language Model Quantization-Aware Training, https://arxiv.org/pdf/2507.16933, 2025-07-22
2025-11-09 20:52:08,419 - INFO - root - Page:2, Index:2, Task-Specific Zero-shot Quantization-Aware Training for Object Detection, https://arxiv.org/pdf/2507.16782, 2025-07-22
2025-11-09 20:52:08,419 - INFO - root - Page:2, Index:3, TorchAO: PyTorch-Native Training-to-Serving Model Optimization, https://arxiv.org/pdf/2507.16099, 2025-07-21
2025-11-09 20:52:08,420 - INFO - root - Page:2, Index:4, SegQuant: A Semantics-Aware and Generalizable Quantization Framework for Diffusion Models, https://arxiv.org/pdf/2507.14811, 2025-08-27
2025-11-09 20:52:08,420 - INFO - root - Page:2, Index:5, Apple Intelligence Foundation Language Models: Tech Report 2025, https://arxiv.org/pdf/2507.13575, 2025-08-27
2025-11-09 20:52:08,420 - INFO - root - Page:2, Index:6, Generative Multi-Target Cross-Domain Recommendation, https://arxiv.org/pdf/2507.12871, 2025-08-07
2025-11-09 20:52:08,420 - INFO - root - Page:2, Index:7, DAF: An Efficient End-to-End Dynamic Activation Framework for on-Device DNN Training, https://arxiv.org/pdf/2507.07149, 2025-07-09
2025-11-09 20:52:08,422 - INFO - root - Page:2, Index:8, Opto-ViT: Architecting a Near-Sensor Region of Interest-Aware Vision Transformer Accelerator with Silicon Photonics, https://arxiv.org/pdf/2507.07044, 2025-07-15
2025-11-09 20:52:08,423 - INFO - root - Page:2, Index:9, QS4D: Quantization-aware training for efficient hardware deployment of structured state-space sequential models, https://arxiv.org/pdf/2507.06079, 2025-07-08
2025-11-09 20:52:08,423 - INFO - root - Page:2, Index:10, GSVR: 2D Gaussian-based Video Representation for 800+ FPS with Hybrid Deformation Field, https://arxiv.org/pdf/2507.05594, 2025-07-07
2025-11-09 20:52:08,425 - INFO - root - Page:2, Index:11, Hita: Holistic Tokenizer for Autoregressive Image Generation, https://arxiv.org/pdf/2507.02358, 2025-07-11
2025-11-09 20:52:08,425 - INFO - root - Page:2, Index:12, QPART: Adaptive Model Quantization and Dynamic Workload Balancing for Accuracy-aware Edge Inference, https://arxiv.org/pdf/2506.23934, 2025-06-30
2025-11-09 20:52:08,426 - INFO - root - Page:2, Index:13, FedWSQ: Efficient Federated Learning with Weight Standardization and Distribution-Aware Non-Uniform Quantization, https://arxiv.org/pdf/2506.23516, 2025-07-21
2025-11-09 20:52:08,426 - INFO - root - Page:2, Index:14, Spectra 1.1: Scaling Laws and Efficient Inference for Ternary Language Models, https://arxiv.org/pdf/2506.23025, 2025-06-28
2025-11-09 20:52:08,426 - INFO - root - Page:2, Index:15, Joint Quantization and Pruning Neural Networks Approach: A Case Study on FSO Receivers, https://arxiv.org/pdf/2506.20084, 2025-06-24
2025-11-09 20:52:08,427 - INFO - root - Page:2, Index:16, Single-step Diffusion for Image Compression at Ultra-Low Bitrates, https://arxiv.org/pdf/2506.16572, 2025-09-22
2025-11-09 20:52:08,427 - INFO - root - Page:2, Index:17, LittleBit: Ultra Low-Bit Quantization via Latent Factorization, https://arxiv.org/pdf/2506.13771, 2025-10-28
2025-11-09 20:52:08,427 - INFO - root - Page:2, Index:18, MARCO: Hardware-Aware Neural Architecture Search for Edge Devices with Multi-Agent Reinforcement Learning and Conformal Prediction Filtering, https://arxiv.org/pdf/2506.13755, 2025-06-16
2025-11-09 20:52:08,427 - INFO - root - Page:2, Index:19, EAQuant: Enhancing Post-Training Quantization for MoE Models via Expert-Aware Optimization, https://arxiv.org/pdf/2506.13329, 2025-07-04
2025-11-09 20:52:08,427 - INFO - root - Page:2, Index:20, Towards Neural Audio Codec Source Parsing, https://arxiv.org/pdf/2506.12627, 2025-06-14
2025-11-09 20:52:08,429 - INFO - root - Page:2, Index:21, Quantizing Small-Scale State-Space Models for Edge AI, https://arxiv.org/pdf/2506.12480, 2025-06-14
2025-11-09 20:52:08,429 - INFO - root - Page:2, Index:22, EMLoC: Emulator-based Memory-efficient Fine-tuning with LoRA Correction, https://arxiv.org/pdf/2506.12015, 2025-06-13
2025-11-09 20:52:08,429 - INFO - root - Page:2, Index:23, Compression Aware Certified Training, https://arxiv.org/pdf/2506.11992, 2025-06-13
2025-11-09 20:52:08,430 - INFO - root - Page:2, Index:24, GPLQ: A General, Practical, and Lightning QAT Method for Vision Transformers, https://arxiv.org/pdf/2506.11784, 2025-06-13
2025-11-09 20:52:08,430 - INFO - root - Page:2, Index:25, TruncQuant: Truncation-Ready Quantization for DNNs with Flexible Weight Bit Precision, https://arxiv.org/pdf/2506.11431, 2025-06-12
2025-11-09 20:52:08,431 - INFO - root - Page:2, Index:26, EfficientQuant: An Efficient Post-Training Quantization for CNN-Transformer Hybrid Models on Edge Devices, https://arxiv.org/pdf/2506.11093, 2025-06-05
2025-11-09 20:52:08,431 - INFO - root - Page:2, Index:27, Starting Positions Matter: A Study on Better Weight Initialization for Neural Network Quantization, https://arxiv.org/pdf/2506.10463, 2025-06-12
2025-11-09 20:52:08,431 - INFO - root - Page:2, Index:28, AWP: Activation-Aware Weight Pruning and Quantization with Projected Gradient Descent, https://arxiv.org/pdf/2506.10205, 2025-06-11
2025-11-09 20:52:08,431 - INFO - root - Page:2, Index:29, Q-SAM2: Accurate Quantization for Segment Anything Model 2, https://arxiv.org/pdf/2506.09782, 2025-06-11
2025-11-09 20:52:08,432 - INFO - root - Page:2, Index:30, Unifying Block-wise PTQ and Distillation-based QAT for Progressive Quantization toward 2-bit Instruction-Tuned LLMs, https://arxiv.org/pdf/2506.09104, 2025-06-10
2025-11-09 20:52:08,432 - INFO - root - Page:2, Index:31, Implementing Keyword Spotting on the MCUX947 Microcontroller with Integrated NPU, https://arxiv.org/pdf/2506.08911, 2025-06-10
2025-11-09 20:52:08,432 - INFO - root - Page:2, Index:32, POLARON: Precision-aware On-device Learning and Adaptive Runtime-cONfigurable AI acceleration, https://arxiv.org/pdf/2506.08785, 2025-06-10
2025-11-09 20:52:08,433 - INFO - root - Page:2, Index:33, MoQAE: Mixed-Precision Quantization for Long-Context LLM Inference via Mixture of Quantization-Aware Experts, https://arxiv.org/pdf/2506.07533, 2025-06-09
2025-11-09 20:52:08,433 - INFO - root - Page:2, Index:34, BitVLA: 1-bit Vision-Language-Action Models for Robotics Manipulation, https://arxiv.org/pdf/2506.07530, 2025-06-09
2025-11-09 20:52:08,433 - INFO - root - Page:2, Index:35, RecGPT: A Foundation Model for Sequential Recommendation, https://arxiv.org/pdf/2506.06270, 2025-06-12
2025-11-09 20:52:08,433 - INFO - root - Page:2, Index:36, FPSAttention: Training-Aware FP8 and Sparsity Co-Design for Fast Video Diffusion, https://arxiv.org/pdf/2506.04648, 2025-06-05
2025-11-09 20:52:08,434 - INFO - root - Page:2, Index:37, BitTTS: Highly Compact Text-to-Speech Using 1.58-bit Quantization and Weight Indexing, https://arxiv.org/pdf/2506.03515, 2025-06-03
2025-11-09 20:52:08,434 - INFO - root - Page:2, Index:38, ShapeLLM-Omni: A Native Multimodal LLM for 3D Generation and Understanding, https://arxiv.org/pdf/2506.01853, 2025-06-02
2025-11-09 20:52:08,434 - INFO - root - Page:2, Index:39, Movable Antenna Enhanced Federated Fine-Tuning of Large Language Models via Hybrid Client Selection Optimization, https://arxiv.org/pdf/2506.00011, 2025-10-26
2025-11-09 20:52:08,434 - INFO - root - Page:2, Index:40, Running Conventional Automatic Speech Recognition on Memristor Hardware: A Simulated Approach, https://arxiv.org/pdf/2505.24721, 2025-05-30
2025-11-09 20:52:08,434 - INFO - root - Page:2, Index:41, GARLIC: GAussian Representation LearnIng for spaCe partitioning, https://arxiv.org/pdf/2505.24608, 2025-10-02
2025-11-09 20:52:08,435 - INFO - root - Page:2, Index:42, AutoChemSchematic AI: Agentic Physics-Aware Automation for Chemical Manufacturing Scale-Up, https://arxiv.org/pdf/2505.24584, 2025-08-18
2025-11-09 20:52:08,435 - INFO - root - Page:2, Index:43, Model-Preserving Adaptive Rounding, https://arxiv.org/pdf/2505.22988, 2025-09-25
2025-11-09 20:52:08,435 - INFO - root - Page:2, Index:44, Highly Efficient and Effective LLMs with Multi-Boolean Architectures, https://arxiv.org/pdf/2505.22811, 2025-10-03
2025-11-09 20:52:08,435 - INFO - root - Page:2, Index:45, Pioneering 4-Bit FP Quantization for Diffusion Models: Mixup-Sign Quantization and Timestep-Aware Fine-Tuning, https://arxiv.org/pdf/2505.21591, 2025-05-27
2025-11-09 20:52:08,435 - INFO - root - Page:2, Index:46, Frequency Composition for Compressed and Domain-Adaptive Neural Networks, https://arxiv.org/pdf/2505.20890, 2025-05-27
2025-11-09 20:52:08,437 - INFO - root - Page:2, Index:47, MoPFormer: Motion-Primitive Transformer for Wearable-Sensor Activity Recognition, https://arxiv.org/pdf/2505.20744, 2025-10-27
2025-11-09 20:52:08,438 - INFO - root - Page:2, Index:48, Optimizing edge AI models on HPC systems with the edge in the loop, https://arxiv.org/pdf/2505.19995, 2025-05-26
2025-11-09 20:52:08,438 - INFO - root - Fetching page 4 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=150
2025-11-09 20:52:15,383 - INFO - root - get_all_titles_from_web 
2025-11-09 20:52:15,383 - INFO - root - Page:3, Index:0, DPASyn: Mechanism-Aware Drug Synergy Prediction via Dual Attention and Precision-Aware Quantization, https://arxiv.org/pdf/2505.19144, 2025-09-20
2025-11-09 20:52:15,383 - INFO - root - Page:3, Index:1, Reducing Storage of Pretrained Neural Networks by Rate-Constrained Quantization and Entropy Coding, https://arxiv.org/pdf/2505.18758, 2025-05-24
2025-11-09 20:52:15,385 - INFO - root - Page:3, Index:2, Beyond Discreteness: Finite-Sample Analysis of Straight-Through Estimator for Quantization, https://arxiv.org/pdf/2505.18113, 2025-05-23
2025-11-09 20:52:15,385 - INFO - root - Page:3, Index:3, Automating Versatile Time-Series Analysis with Tiny Transformers on Embedded FPGAs, https://arxiv.org/pdf/2505.17662, 2025-09-19
2025-11-09 20:52:15,385 - INFO - root - Page:3, Index:4, FPQVAR: Floating Point Quantization for Visual Autoregressive Model with FPGA Hardware Co-design, https://arxiv.org/pdf/2505.16335, 2025-05-22
2025-11-09 20:52:15,385 - INFO - root - Page:3, Index:5, Saliency-Aware Quantized Imitation Learning for Efficient Robotic Control, https://arxiv.org/pdf/2505.15304, 2025-05-30
2025-11-09 20:52:15,386 - INFO - root - Page:3, Index:6, Scaling Law for Quantization-Aware Training, https://arxiv.org/pdf/2505.14302, 2025-05-20
2025-11-09 20:52:15,386 - INFO - root - Page:3, Index:7, Automatic mixed precision for optimizing gained time with constrained loss mean-squared-error based on model partition to sequential sub-graphs, https://arxiv.org/pdf/2505.13060, 2025-05-19
2025-11-09 20:52:15,386 - INFO - root - Page:3, Index:8, Deep Unfolding with Kernel-based Quantization in MIMO Detection, https://arxiv.org/pdf/2505.12736, 2025-05-19
2025-11-09 20:52:15,386 - INFO - root - Page:3, Index:9, FedHQ: Hybrid Runtime Quantization for Federated Learning, https://arxiv.org/pdf/2505.11982, 2025-05-17
2025-11-09 20:52:15,386 - INFO - root - Page:3, Index:10, QVGen: Pushing the Limit of Quantized Video Generative Models, https://arxiv.org/pdf/2505.11497, 2025-09-27
2025-11-09 20:52:15,387 - INFO - root - Page:3, Index:11, EA-3DGS: Efficient and Adaptive 3D Gaussians with Highly Enhanced Quality for outdoor scenes, https://arxiv.org/pdf/2505.10787, 2025-05-15
2025-11-09 20:52:15,387 - INFO - root - Page:3, Index:12, ITERA-LLM: Boosting Sub-8-Bit Large Language Model Inference via Iterative Tensor Decomposition, https://arxiv.org/pdf/2505.08981, 2025-05-13
2025-11-09 20:52:15,387 - INFO - root - Page:3, Index:13, PROM: Prioritize Reduction of Multiplications Over Lower Bit-Widths for Efficient CNNs, https://arxiv.org/pdf/2505.03254, 2025-08-06
2025-11-09 20:52:15,387 - INFO - root - Page:3, Index:14, ICQuant: Index Coding enables Low-bit LLM Quantization, https://arxiv.org/pdf/2505.00850, 2025-08-24
2025-11-09 20:52:15,388 - INFO - root - Page:3, Index:15, Enhancing Ultra-Low-Bit Quantization of Large Language Models Through Saliency-Aware Partial Retraining, https://arxiv.org/pdf/2504.13932, 2025-07-30
2025-11-09 20:52:15,388 - INFO - root - Page:3, Index:16, Achieving binary weight and activation for LLMs using Post-Training Quantization, https://arxiv.org/pdf/2504.05352, 2025-06-30
2025-11-09 20:52:15,388 - INFO - root - Page:3, Index:17, Wireless Hearables With Programmable Speech AI Accelerators, https://arxiv.org/pdf/2503.18698, 2025-10-21
2025-11-09 20:52:15,388 - INFO - root - Page:3, Index:18, GranQ: Efficient Channel-wise Quantization via Vectorized Pre-Scaling for Zero-Shot QAT, https://arxiv.org/pdf/2503.18339, 2025-10-15
2025-11-09 20:52:15,390 - INFO - root - Page:3, Index:19, CompMarkGS: Robust Watermarking for Compressed 3D Gaussian Splatting, https://arxiv.org/pdf/2503.12836, 2025-09-29
2025-11-09 20:52:15,390 - INFO - root - Page:3, Index:20, AHCPTQ: Accurate and Hardware-Compatible Post-Training Quantization for Segment Anything Model, https://arxiv.org/pdf/2503.03088, 2025-07-11
2025-11-09 20:52:15,390 - INFO - root - Page:3, Index:21, Teaching Metric Distance to Discrete Autoregressive Language Models, https://arxiv.org/pdf/2503.02379, 2025-10-07
2025-11-09 20:52:15,391 - INFO - root - Page:3, Index:22, Regularization-based Framework for Quantization-, Fault- and Variability-Aware Training, https://arxiv.org/pdf/2503.01297, 2025-07-12
2025-11-09 20:52:15,391 - INFO - root - Fetching page 5 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=200
2025-11-09 20:52:21,697 - INFO - root - get_all_titles_from_web 
2025-11-09 20:52:21,697 - INFO - root - Page:4, Index:0, Investigating the Impact of Quantization Methods on the Safety and Reliability of Large Language Models, https://arxiv.org/pdf/2502.15799, 2025-06-29
2025-11-09 20:52:21,697 - INFO - root - Page:4, Index:1, Rotate, Clip, and Partition: Towards W2A4KV4 Quantization by Integrating Rotation and Learnable Non-uniform Quantizer, https://arxiv.org/pdf/2502.15779, 2025-09-01
2025-11-09 20:52:21,697 - INFO - root - Page:4, Index:2, RoSTE: An Efficient Quantization-Aware Supervised Fine-Tuning Approach for Large Language Models, https://arxiv.org/pdf/2502.09003, 2025-06-05
2025-11-09 20:52:21,697 - INFO - root - Page:4, Index:3, Spatial Degradation-Aware and Temporal Consistent Diffusion Model for Compressed Video Super-Resolution, https://arxiv.org/pdf/2502.07381, 2025-06-27
2025-11-09 20:52:21,699 - INFO - root - Page:4, Index:4, QuEST: Stable Training of LLMs with 1-Bit Weights and Activations, https://arxiv.org/pdf/2502.05003, 2025-06-10
2025-11-09 20:52:21,699 - INFO - root - Page:4, Index:5, HALO: Hadamard-Assisted Lower-Precision Optimization for LLMs, https://arxiv.org/pdf/2501.02625, 2025-11-05
2025-11-09 20:52:21,699 - INFO - root - Page:4, Index:6, TAR3D: Creating High-Quality 3D Assets via Next-Part Prediction, https://arxiv.org/pdf/2412.16919, 2025-08-08
2025-11-09 20:52:21,699 - INFO - root - Page:4, Index:7, Training Multi-Layer Binary Neural Networks With Local Binary Error Signals, https://arxiv.org/pdf/2412.00119, 2025-08-05
2025-11-09 20:52:21,700 - INFO - root - Page:4, Index:8, Scaling Large-scale GNN Training to Thousands of Processors on CPU-based Supercomputers, https://arxiv.org/pdf/2411.16025, 2025-05-26
2025-11-09 20:52:21,700 - INFO - root - Page:4, Index:9, HAFLQ: Heterogeneous Adaptive Federated LoRA Fine-tuned LLM with Quantization, https://arxiv.org/pdf/2411.06581, 2025-05-16
2025-11-09 20:52:21,700 - INFO - root - Fetching page 6 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=250
2025-11-09 20:52:29,866 - INFO - root - get_all_titles_from_web 
2025-11-09 20:52:29,867 - INFO - root - Page:5, Index:0, Gradient-Free Training of Quantized Neural Networks, https://arxiv.org/pdf/2410.09734, 2025-09-29
2025-11-09 20:52:29,867 - INFO - root - Page:5, Index:1, QT-DoG: Quantization-aware Training for Domain Generalization, https://arxiv.org/pdf/2410.06020, 2025-06-26
2025-11-09 20:52:29,867 - INFO - root - Page:5, Index:2, Constraint Guided Model Quantization of Neural Networks, https://arxiv.org/pdf/2409.20138, 2025-09-12
2025-11-09 20:52:29,868 - INFO - root - Page:5, Index:3, Accumulator-Aware Post-Training Quantization for Large Language Models, https://arxiv.org/pdf/2409.17092, 2025-07-30
2025-11-09 20:52:29,868 - INFO - root - Page:5, Index:4, DilateQuant: Accurate and Efficient Diffusion Quantization via Weight Dilation, https://arxiv.org/pdf/2409.14307, 2025-07-09
2025-11-09 20:52:29,868 - INFO - root - Page:5, Index:5, Robust Training of Neural Networks at Arbitrary Precision and Sparsity, https://arxiv.org/pdf/2409.09245, 2025-09-23
2025-11-09 20:52:29,868 - INFO - root - Page:5, Index:6, VQ-CTAP: Cross-Modal Fine-Grained Sequence Representation Learning for Speech Processing, https://arxiv.org/pdf/2408.05758, 2025-05-27
2025-11-09 20:52:29,873 - INFO - root - Page:5, Index:7, DopQ-ViT: Towards Distribution-Friendly and Outlier-Aware Post-Training Quantization for Vision Transformers, https://arxiv.org/pdf/2408.03291, 2025-06-19
2025-11-09 20:52:29,874 - INFO - root - Page:5, Index:8, Temporal Feature Matters: A Framework for Diffusion Model Quantization, https://arxiv.org/pdf/2407.19547, 2025-07-11
2025-11-09 20:52:29,874 - INFO - root - Page:5, Index:9, EfficientQAT: Efficient Quantization-Aware Training for Large Language Models, https://arxiv.org/pdf/2407.11062, 2025-05-19
2025-11-09 20:52:29,874 - INFO - root - Page:5, Index:10, Integer-only Quantized Transformers for Embedded FPGA-based Time-series Forecasting in AIoT, https://arxiv.org/pdf/2407.11041, 2025-10-31
2025-11-09 20:52:29,875 - INFO - root - Fetching page 7 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=300
2025-11-09 20:52:36,995 - INFO - root - get_all_titles_from_web 
2025-11-09 20:52:36,995 - INFO - root - Page:6, Index:0, BoA: Attention-aware Post-training Quantization without Backpropagation, https://arxiv.org/pdf/2406.13474, 2025-06-06
2025-11-09 20:52:36,995 - INFO - root - Page:6, Index:1, A Rescaling-Invariant Lipschitz Bound Based on Path-Metrics for Modern ReLU Network Parameterizations, https://arxiv.org/pdf/2405.15006, 2025-06-13
2025-11-09 20:52:36,996 - INFO - root - Page:6, Index:2, Scheduling Weight Transitions for Quantization-Aware Training, https://arxiv.org/pdf/2404.19248, 2025-10-01
2025-11-09 20:52:36,996 - INFO - root - Page:6, Index:3, GPTVQ: The Blessing of Dimensionality for LLM Quantization, https://arxiv.org/pdf/2402.15319, 2025-06-03
2025-11-09 20:52:36,997 - INFO - root - Fetching page 8 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=350
2025-11-09 20:52:43,870 - INFO - root - get_all_titles_from_web 
2025-11-09 20:52:43,870 - INFO - root - Page:7, Index:0, Squat: Quant Small Language Models on the Edge, https://arxiv.org/pdf/2402.10787, 2025-07-01
2025-11-09 20:52:43,871 - INFO - root - Page:7, Index:1, L4Q: Parameter Efficient Quantization-Aware Fine-Tuning on Large Language Models, https://arxiv.org/pdf/2402.04902, 2025-07-21
2025-11-09 20:52:43,871 - INFO - root - Fetching page 9 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=400
2025-11-09 20:52:50,584 - INFO - root - ------------------------------------------------------------------------------------------------------------------------
2025-11-09 20:52:50,585 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\A Quantized VAE-MLP Botnet Detection Model_ A Systematic Evaluation of Quantizat.pdf
2025-11-09 20:52:50,592 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\FP8-Flow-MoE_ A Casting-Free FP8 Recipe without Double Quantization Error.pdf
2025-11-09 20:52:50,593 - INFO - root - 跳过已处理论文 A Quantized VAE-MLP Botnet Detection Model: A Systematic Evaluation of Quantization-Aware Training and Post-Training Quantization Strategies：d:\ChatPaper\academic Papers\Quantization-Aware-Training\A Quantized VAE-MLP Botnet Detection Model_ A Systematic Evaluation of Quantizat.pdf
2025-11-09 20:52:50,593 - INFO - root - 跳过已处理论文 FP8-Flow-MoE: A Casting-Free FP8 Recipe without Double Quantization Error：d:\ChatPaper\academic Papers\Quantization-Aware-Training\FP8-Flow-MoE_ A Casting-Free FP8 Recipe without Double Quantization Error.pdf
2025-11-09 20:52:50,595 - INFO - root - summary time: 68.74 seconds
2025-11-09 20:53:28,383 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-09 20:53:28,385 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-09 20:53:28,391 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-09 20:53:29,228 - INFO - root - LLMClientManager: 指定使用客户端: DeepSeek
2025-11-09 20:53:29,229 - INFO - root - DeepSeekClient: API key found: 9f9e270e-b...
2025-11-09 20:53:29,229 - INFO - root - DeepSeekClient: 使用模式: 火山引擎
2025-11-09 20:53:29,230 - INFO - root - DeepSeekClient: 模型名称: deepseek-v3-1-terminus
2025-11-09 20:53:32,466 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 20:53:32,475 - INFO - root - DeepSeekClient: initialized successfully with model deepseek-v3-1-terminus
2025-11-09 20:53:32,477 - INFO - root - LLMClientManager: DeepSeek 客户端初始化成功
2025-11-09 20:53:32,477 - INFO - root - LLMClientManager: switched to DeepSeek client
2025-11-09 20:53:32,477 - INFO - root - 已手动切换到 LLM 客户端: DeepSeek
2025-11-09 20:53:32,478 - INFO - root - 使用 LLM 模型: deepseek-v3-1-terminus
2025-11-09 20:53:32,478 - INFO - root - 可用客户端: ['DeepSeek']
2025-11-09 20:53:32,478 - INFO - root - === 运行配置 ===
2025-11-09 20:53:32,479 - INFO - root - 处理模式: arxiv在线搜索
2025-11-09 20:53:32,479 - INFO - root - 关键词: QAT
2025-11-09 20:53:32,479 - INFO - root - 查询: Quantization-Aware-Training
2025-11-09 20:53:32,479 - INFO - root - 排序: None
2025-11-09 20:53:32,480 - INFO - root - 最近天数: 180
2025-11-09 20:53:32,480 - INFO - root - 最大处理数量: 2
2025-11-09 20:53:32,481 - INFO - root - 保存图片: 是
2025-11-09 20:53:32,481 - INFO - root - 输出语言: 中文
2025-11-09 20:53:32,482 - INFO - root - 强制重新处理: 否
2025-11-09 20:53:32,482 - INFO - root - ====================
2025-11-09 20:53:32,483 - INFO - root - 使用 arXiv 搜索模式（通过 chat_arxiv 模块获取）
2025-11-09 20:53:32,483 - INFO - root - Fetching page 1 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50
2025-11-09 20:53:59,745 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-09 20:53:59,747 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-09 20:53:59,748 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-09 20:54:00,555 - INFO - root - LLMClientManager: 指定使用客户端: Gemini
2025-11-09 20:54:01,669 - INFO - root - GeminiClient: trying model gemini-2.5-flash
2025-11-09 20:54:04,999 - INFO - root - GeminiClient: initialized model gemini-2.5-flash
2025-11-09 20:54:04,999 - INFO - root - LLMClientManager: Gemini 客户端初始化成功
2025-11-09 20:54:04,999 - INFO - root - LLMClientManager: switched to Gemini client
2025-11-09 20:54:05,000 - INFO - root - 已手动切换到 LLM 客户端: Gemini
2025-11-09 20:54:05,000 - INFO - root - 使用 LLM 模型: gemini-2.5-flash
2025-11-09 20:54:05,000 - INFO - root - 可用客户端: ['Gemini']
2025-11-09 20:54:05,001 - INFO - root - === 运行配置 ===
2025-11-09 20:54:05,001 - INFO - root - 处理模式: arxiv在线搜索
2025-11-09 20:54:05,001 - INFO - root - 关键词: QAT
2025-11-09 20:54:05,001 - INFO - root - 查询: Quantization-Aware-Training
2025-11-09 20:54:05,002 - INFO - root - 排序: None
2025-11-09 20:54:05,003 - INFO - root - 最近天数: 180
2025-11-09 20:54:05,003 - INFO - root - 最大处理数量: 2
2025-11-09 20:54:05,003 - INFO - root - 保存图片: 是
2025-11-09 20:54:05,003 - INFO - root - 输出语言: 中文
2025-11-09 20:54:05,004 - INFO - root - 强制重新处理: 否
2025-11-09 20:54:05,004 - INFO - root - ====================
2025-11-09 20:54:05,004 - INFO - root - 使用 arXiv 搜索模式（通过 chat_arxiv 模块获取）
2025-11-09 20:54:05,005 - INFO - root - Fetching page 1 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50
2025-11-09 20:54:12,438 - INFO - root - get_all_titles_from_web 
2025-11-09 20:54:12,440 - INFO - root - Page:0, Index:0, A Quantized VAE-MLP Botnet Detection Model: A Systematic Evaluation of Quantization-Aware Training and Post-Training Quantization Strategies, https://arxiv.org/pdf/2511.03201, 2025-11-05
2025-11-09 20:54:12,440 - INFO - root - Page:0, Index:1, FP8-Flow-MoE: A Casting-Free FP8 Recipe without Double Quantization Error, https://arxiv.org/pdf/2511.02302, 2025-11-04
2025-11-09 20:54:12,440 - INFO - root - Page:0, Index:2, Outlier-Aware Post-Training Quantization for Image Super-Resolution, https://arxiv.org/pdf/2511.00682, 2025-11-01
2025-11-09 20:54:12,442 - INFO - root - Page:0, Index:3, Evaluation of Wafer-Scale SOT-MRAM for Analog Crossbar Array Applications, https://arxiv.org/pdf/2510.25853, 2025-11-03
2025-11-09 20:54:12,443 - INFO - root - Page:0, Index:4, Improving the Straight-Through Estimator with Zeroth-Order Information, https://arxiv.org/pdf/2510.23926, 2025-10-27
2025-11-09 20:54:12,444 - INFO - root - Page:0, Index:5, Real-Time Semantic Segmentation on FPGA for Autonomous Vehicles Using LMIINet with the CGRA4ML Framework, https://arxiv.org/pdf/2510.22243, 2025-10-25
2025-11-09 20:54:12,445 - INFO - root - Page:0, Index:6, TernaryCLIP: Efficiently Compressing Vision-Language Models with Ternary Weights and Distilled Knowledge, https://arxiv.org/pdf/2510.21879, 2025-10-23
2025-11-09 20:54:12,446 - INFO - root - Page:0, Index:7, KARIPAP: Quantum-Inspired Tensor Network Compression of Large Language Models Using Infinite Projected Entangled Pair States and Tensor Renormalization Group, https://arxiv.org/pdf/2510.21844, 2025-10-22
2025-11-09 20:54:12,452 - INFO - root - Page:0, Index:8, A Convergence Analysis of Adaptive Optimizers under Floating-point Quantization, https://arxiv.org/pdf/2510.21314, 2025-10-24
2025-11-09 20:54:12,452 - INFO - root - Page:0, Index:9, Adaptive Distribution-aware Quantization for Mixed-Precision Neural Networks, https://arxiv.org/pdf/2510.19760, 2025-10-22
2025-11-09 20:54:12,454 - INFO - root - Page:0, Index:10, CAGE: Curvature-Aware Gradient Estimation For Accurate Quantization-Aware Training, https://arxiv.org/pdf/2510.18784, 2025-10-21
2025-11-09 20:54:12,455 - INFO - root - Page:0, Index:11, Mixed-Precision Quantization for Language Models: Techniques and Prospects, https://arxiv.org/pdf/2510.16805, 2025-10-19
2025-11-09 20:54:12,455 - INFO - root - Page:0, Index:12, SPLite Hand: Sparsity-Aware Lightweight 3D Hand Pose Estimation, https://arxiv.org/pdf/2510.16396, 2025-10-30
2025-11-09 20:54:12,455 - INFO - root - Page:0, Index:13, CTR-LoRA: Curvature-Aware and Trust-Region Guided Low-Rank Adaptation for Large Language Models, https://arxiv.org/pdf/2510.15962, 2025-10-11
2025-11-09 20:54:12,456 - INFO - root - Page:0, Index:14, SANR: Scene-Aware Neural Representation for Light Field Image Compression with Rate-Distortion Optimization, https://arxiv.org/pdf/2510.15775, 2025-10-17
2025-11-09 20:54:12,456 - INFO - root - Page:0, Index:15, SpikeFit: Towards Optimal Deployment of Spiking Networks on Neuromorphic Hardware, https://arxiv.org/pdf/2510.15542, 2025-10-31
2025-11-09 20:54:12,458 - INFO - root - Page:0, Index:16, GRank: Towards Target-Aware and Streamlined Industrial Retrieval with a Generate-Rank Framework, https://arxiv.org/pdf/2510.15299, 2025-10-17
2025-11-09 20:54:12,460 - INFO - root - Page:0, Index:17, SaLon3R: Structure-aware Long-term Generalizable 3D Reconstruction from Unposed Images, https://arxiv.org/pdf/2510.15072, 2025-10-16
2025-11-09 20:54:12,461 - INFO - root - Page:0, Index:18, FraQAT: Quantization Aware Training with Fractional bits, https://arxiv.org/pdf/2510.14823, 2025-10-16
2025-11-09 20:54:12,462 - INFO - root - Page:0, Index:19, Computing-In-Memory Aware Model Adaption For Edge Devices, https://arxiv.org/pdf/2510.14379, 2025-10-16
2025-11-09 20:54:12,463 - INFO - root - Page:0, Index:20, Invited Paper: BitMedViT: Ternary-Quantized Vision Transformer for Medical AI Assistants on the Edge, https://arxiv.org/pdf/2510.13760, 2025-11-04
2025-11-09 20:54:12,467 - INFO - root - Page:0, Index:21, NeuroRVQ: Multi-Scale EEG Tokenization for Generative Large Brainwave Models, https://arxiv.org/pdf/2510.13068, 2025-10-14
2025-11-09 20:54:12,467 - INFO - root - Page:0, Index:22, Detect Anything via Next Point Prediction, https://arxiv.org/pdf/2510.12798, 2025-10-14
2025-11-09 20:54:12,469 - INFO - root - Page:0, Index:23, AndesVL Technical Report: An Efficient Mobile-side Multimodal Large Language Model, https://arxiv.org/pdf/2510.11496, 2025-10-14
2025-11-09 20:54:12,469 - INFO - root - Page:0, Index:24, Rescaling-Aware Training for Efficient Deployment of Deep Learning Models on Full-Integer Hardware, https://arxiv.org/pdf/2510.11484, 2025-10-13
2025-11-09 20:54:12,471 - INFO - root - Page:0, Index:25, SASER: Stego attacks on open-source LLMs, https://arxiv.org/pdf/2510.10486, 2025-10-12
2025-11-09 20:54:12,472 - INFO - root - Page:0, Index:26, Ultralytics YOLO Evolution: An Overview of YOLO26, YOLO11, YOLOv8 and YOLOv5 Object Detectors for Computer Vision and Pattern Recognition, https://arxiv.org/pdf/2510.09653, 2025-10-15
2025-11-09 20:54:12,472 - INFO - root - Page:0, Index:27, A Theoretically-Grounded Codebook for Digital Semantic Communications, https://arxiv.org/pdf/2510.07108, 2025-10-14
2025-11-09 20:54:12,472 - INFO - root - Page:0, Index:28, QuantDemoire: Quantization with Outlier Aware for Image Demoiréing, https://arxiv.org/pdf/2510.04066, 2025-10-05
2025-11-09 20:54:12,473 - INFO - root - Page:0, Index:29, Adaptively Sampling-Reusing-Mixing Decomposed Gradients to Speed Up Sharpness Aware Minimization, https://arxiv.org/pdf/2510.03763, 2025-10-04
2025-11-09 20:54:12,474 - INFO - root - Page:0, Index:30, Quant-dLLM: Post-Training Extreme Low-Bit Quantization for Diffusion Large Language Models, https://arxiv.org/pdf/2510.03274, 2025-09-27
2025-11-09 20:54:12,474 - INFO - root - Page:0, Index:31, PT$^2$-LLM: Post-Training Ternarization for Large Language Models, https://arxiv.org/pdf/2510.03267, 2025-09-26
2025-11-09 20:54:12,475 - INFO - root - Page:0, Index:32, Purrception: Variational Flow Matching for Vector-Quantized Image Generation, https://arxiv.org/pdf/2510.01478, 2025-10-01
2025-11-09 20:54:12,479 - INFO - root - Page:0, Index:33, Post-Training Quantization for Audio Diffusion Transformers, https://arxiv.org/pdf/2510.00313, 2025-09-30
2025-11-09 20:54:12,488 - INFO - root - Page:0, Index:34, Rethinking RoPE Scaling in Quantized LLM: Theory, Outlier, and Channel-Band Analysis with Weight Rescaling, https://arxiv.org/pdf/2510.00028, 2025-09-25
2025-11-09 20:54:12,488 - INFO - root - Page:0, Index:35, Post-Training Quantization via Residual Truncation and Zero Suppression for Diffusion Models, https://arxiv.org/pdf/2509.26436, 2025-09-30
2025-11-09 20:54:12,489 - INFO - root - Page:0, Index:36, Cat: Post-Training Quantization Error Reduction via Cluster-based Affine Transformation, https://arxiv.org/pdf/2509.26277, 2025-10-07
2025-11-09 20:54:12,489 - INFO - root - Page:0, Index:37, CAST: Continuous and Differentiable Semi-Structured Sparsity-Aware Training for Large Language Models, https://arxiv.org/pdf/2509.25996, 2025-09-30
2025-11-09 20:54:12,490 - INFO - root - Page:0, Index:38, Norm-Q: Effective Compression Method for Hidden Markov Models in Neuro-Symbolic Applications, https://arxiv.org/pdf/2509.25439, 2025-09-29
2025-11-09 20:54:12,491 - INFO - root - Page:0, Index:39, On-the-Fly Adaptation to Quantization: Configuration-Aware LoRA for Efficient Fine-Tuning of Quantized LLMs, https://arxiv.org/pdf/2509.25214, 2025-09-22
2025-11-09 20:54:12,494 - INFO - root - Page:0, Index:40, VoxCPM: Tokenizer-Free TTS for Context-Aware Speech Generation and True-to-Life Voice Cloning, https://arxiv.org/pdf/2509.24650, 2025-09-29
2025-11-09 20:54:12,496 - INFO - root - Page:0, Index:41, S$^2$NN: Sub-bit Spiking Neural Networks, https://arxiv.org/pdf/2509.24266, 2025-10-24
2025-11-09 20:54:12,503 - INFO - root - Page:0, Index:42, Tequila: Trapping-free Ternary Quantization for Large Language Models, https://arxiv.org/pdf/2509.23809, 2025-10-17
2025-11-09 20:54:12,503 - INFO - root - Page:0, Index:43, Texture Vector-Quantization and Reconstruction Aware Prediction for Generative Super-Resolution, https://arxiv.org/pdf/2509.23774, 2025-09-30
2025-11-09 20:54:12,504 - INFO - root - Page:0, Index:44, RobuQ: Pushing DiTs to W1.58A2 via Robust Activation Quantization, https://arxiv.org/pdf/2509.23582, 2025-09-27
2025-11-09 20:54:12,507 - INFO - root - Page:0, Index:45, Beyond Outliers: A Study of Optimizers Under Quantization, https://arxiv.org/pdf/2509.23500, 2025-10-02
2025-11-09 20:54:12,529 - INFO - root - Page:0, Index:46, Compute-Optimal Quantization-Aware Training, https://arxiv.org/pdf/2509.22935, 2025-09-26
2025-11-09 20:54:12,538 - INFO - root - Page:0, Index:47, COSPADI: Compressing LLMs via Calibration-Guided Sparse Dictionary Learning, https://arxiv.org/pdf/2509.22075, 2025-10-06
2025-11-09 20:54:12,538 - INFO - root - Page:0, Index:48, SlimDiff: Training-Free, Activation-Guided Hands-free Slimming of Diffusion Models, https://arxiv.org/pdf/2509.21498, 2025-09-25
2025-11-09 20:54:12,539 - INFO - root - Page:0, Index:49, Quantized Visual Geometry Grounded Transformer, https://arxiv.org/pdf/2509.21302, 2025-09-29
2025-11-09 20:54:12,540 - INFO - root - Fetching page 2 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=50
2025-11-09 20:54:19,046 - INFO - root - get_all_titles_from_web 
2025-11-09 20:54:19,046 - INFO - root - Page:1, Index:0, Can Less Precise Be More Reliable? A Systematic Evaluation of Quantization's Impact on CLIP Beyond Accuracy, https://arxiv.org/pdf/2509.21173, 2025-10-27
2025-11-09 20:54:19,046 - INFO - root - Page:1, Index:1, Punching Above Precision: Small Quantized Model Distillation with Learnable Regularizer, https://arxiv.org/pdf/2509.20854, 2025-09-25
2025-11-09 20:54:19,046 - INFO - root - Page:1, Index:2, TinyEcoWeedNet: Edge Efficient Real-Time Aerial Agricultural Weed Detection, https://arxiv.org/pdf/2509.18193, 2025-09-19
2025-11-09 20:54:19,048 - INFO - root - Page:1, Index:3, SBVR: Summation of BitVector Representation for Efficient LLM Quantization, https://arxiv.org/pdf/2509.18172, 2025-09-17
2025-11-09 20:54:19,048 - INFO - root - Page:1, Index:4, QWHA: Quantization-Aware Walsh-Hadamard Adaptation for Parameter-Efficient Fine-Tuning on Large Language Models, https://arxiv.org/pdf/2509.17428, 2025-09-26
2025-11-09 20:54:19,048 - INFO - root - Page:1, Index:5, PTQTP: Post-Training Quantization to Trit-Planes for Large Language Models, https://arxiv.org/pdf/2509.16989, 2025-10-28
2025-11-09 20:54:19,048 - INFO - root - Page:1, Index:6, MEC-Quant: Maximum Entropy Coding for Extremely Low Bit Quantization-Aware Training, https://arxiv.org/pdf/2509.15514, 2025-09-18
2025-11-09 20:54:19,048 - INFO - root - Page:1, Index:7, Q-ROAR: Outlier-Aware Rescaling for RoPE Position Interpolation in Quantized Long-Context LLMs, https://arxiv.org/pdf/2509.14391, 2025-09-17
2025-11-09 20:54:19,049 - INFO - root - Page:1, Index:8, Efficient Quantization-Aware Neural Receivers: Beyond Post-Training Quantization, https://arxiv.org/pdf/2509.13786, 2025-09-19
2025-11-09 20:54:19,049 - INFO - root - Page:1, Index:9, Rate-Distortion Limits for Multimodal Retrieval: Theory, Optimal Codes, and Finite-Sample Guarantees, https://arxiv.org/pdf/2509.11054, 2025-09-13
2025-11-09 20:54:19,049 - INFO - root - Page:1, Index:10, SQAP-VLA: A Synergistic Quantization-Aware Pruning Framework for High-Performance Vision-Language-Action Models, https://arxiv.org/pdf/2509.09090, 2025-09-10
2025-11-09 20:54:19,049 - INFO - root - Page:1, Index:11, CSI Compression Beyond Latents: End-to-End Hybrid Attention-CNN Networks with Entropy Regularization, https://arxiv.org/pdf/2509.08776, 2025-09-10
2025-11-09 20:54:19,050 - INFO - root - Page:1, Index:12, Explaining How Quantization Disparately Skews a Model, https://arxiv.org/pdf/2509.07222, 2025-09-08
2025-11-09 20:54:19,050 - INFO - root - Page:1, Index:13, LoaQ: Layer-wise Output Approximation Quantization, https://arxiv.org/pdf/2509.06297, 2025-09-07
2025-11-09 20:54:19,050 - INFO - root - Page:1, Index:14, FineServe: Precision-Aware KV Slab and Two-Level Scheduling for Heterogeneous Precision LLM Serving, https://arxiv.org/pdf/2509.06261, 2025-09-14
2025-11-09 20:54:19,051 - INFO - root - Page:1, Index:15, Sensitivity-Aware Post-Training Quantization for Deep Neural Networks, https://arxiv.org/pdf/2509.05576, 2025-09-05
2025-11-09 20:54:19,051 - INFO - root - Page:1, Index:16, SuperSNN: A Hardware-Aware Framework for Physically Realizable, High-Performance Superconducting Spiking Neural Network Chips, https://arxiv.org/pdf/2509.05532, 2025-09-05
2025-11-09 20:54:19,051 - INFO - root - Page:1, Index:17, Data-Augmented Quantization-Aware Knowledge Distillation, https://arxiv.org/pdf/2509.03850, 2025-09-03
2025-11-09 20:54:19,051 - INFO - root - Page:1, Index:18, DPQuant: Efficient and Differentially-Private Model Training via Dynamic Quantization Scheduling, https://arxiv.org/pdf/2509.03472, 2025-09-03
2025-11-09 20:54:19,052 - INFO - root - Page:1, Index:19, Empowering Large Language Model for Sequential Recommendation via Multimodal Embeddings and Semantic IDs, https://arxiv.org/pdf/2509.02017, 2025-09-02
2025-11-09 20:54:19,052 - INFO - root - Page:1, Index:20, Q-Sched: Pushing the Boundaries of Few-Step Diffusion Models with Quantization-Aware Scheduling, https://arxiv.org/pdf/2509.01624, 2025-09-01
2025-11-09 20:54:19,052 - INFO - root - Page:1, Index:21, Quantization Meets OOD: Generalizable Quantization-aware Training from a Flatness Perspective, https://arxiv.org/pdf/2509.00859, 2025-08-31
2025-11-09 20:54:19,054 - INFO - root - Page:1, Index:22, Progressive Element-wise Gradient Estimation for Neural Network Quantization, https://arxiv.org/pdf/2509.00097, 2025-08-27
2025-11-09 20:54:19,056 - INFO - root - Page:1, Index:23, End-to-End On-Device Quantization-Aware Training for LLMs at Inference Cost, https://arxiv.org/pdf/2509.00031, 2025-09-29
2025-11-09 20:54:19,056 - INFO - root - Page:1, Index:24, Quantization Robustness to Input Degradations for Object Detection, https://arxiv.org/pdf/2508.19600, 2025-08-27
2025-11-09 20:54:19,056 - INFO - root - Page:1, Index:25, Scaling Laws for Task-Stratified Knowledge in Post-Training Quantized Large Language Models, https://arxiv.org/pdf/2508.18609, 2025-08-27
2025-11-09 20:54:19,057 - INFO - root - Page:1, Index:26, AQ-PCDSys: An Adaptive Quantized Planetary Crater Detection System for Autonomous Space Exploration, https://arxiv.org/pdf/2508.18025, 2025-08-25
2025-11-09 20:54:19,059 - INFO - root - Page:1, Index:27, TaDiCodec: Text-aware Diffusion Speech Tokenizer for Speech Language Modeling, https://arxiv.org/pdf/2508.16790, 2025-08-22
2025-11-09 20:54:19,060 - INFO - root - Page:1, Index:28, A Node-Aware Dynamic Quantization Approach for Graph Collaborative Filtering, https://arxiv.org/pdf/2508.16516, 2025-08-22
2025-11-09 20:54:19,061 - INFO - root - Page:1, Index:29, JEDI-linear: Fast and Efficient Graph Neural Networks for Jet Tagging on FPGAs, https://arxiv.org/pdf/2508.15468, 2025-08-21
2025-11-09 20:54:19,061 - INFO - root - Page:1, Index:30, MMQ: Multimodal Mixture-of-Quantization Tokenization for Semantic ID Generation and User Behavioral Adaptation, https://arxiv.org/pdf/2508.15281, 2025-08-21
2025-11-09 20:54:19,062 - INFO - root - Page:1, Index:31, DLLMQuant: Quantizing Diffusion-based Large Language Models, https://arxiv.org/pdf/2508.14090, 2025-08-25
2025-11-09 20:54:19,062 - INFO - root - Page:1, Index:32, Automated Energy-Aware Time-Series Model Deployment on Embedded FPGAs for Resilient Combined Sewer Overflow Management, https://arxiv.org/pdf/2508.13905, 2025-08-19
2025-11-09 20:54:19,062 - INFO - root - Page:1, Index:33, XR-NPE: High-Throughput Mixed-precision SIMD Neural Processing Engine for Extended Reality Perception Workloads, https://arxiv.org/pdf/2508.13049, 2025-08-18
2025-11-09 20:54:19,064 - INFO - root - Page:1, Index:34, Exploring Self-Supervised Audio Models for Generalized Anomalous Sound Detection, https://arxiv.org/pdf/2508.12230, 2025-08-17
2025-11-09 20:54:19,064 - INFO - root - Page:1, Index:35, TriQDef: Disrupting Semantic and Gradient Alignment to Prevent Adversarial Patch Transferability in Quantized Neural Networks, https://arxiv.org/pdf/2508.12132, 2025-08-16
2025-11-09 20:54:19,064 - INFO - root - Page:1, Index:36, Error Propagation Mechanisms and Compensation Strategies for Quantized Diffusion, https://arxiv.org/pdf/2508.12094, 2025-10-13
2025-11-09 20:54:19,064 - INFO - root - Page:1, Index:37, Extending Straight-Through Estimation for Robust Neural Networks on Analog CIM Hardware, https://arxiv.org/pdf/2508.11940, 2025-08-16
2025-11-09 20:54:19,064 - INFO - root - Page:1, Index:38, PTQAT: A Hybrid Parameter-Efficient Quantization Algorithm for 3D Perception Tasks, https://arxiv.org/pdf/2508.10557, 2025-08-15
2025-11-09 20:54:19,065 - INFO - root - Page:1, Index:39, MiCo: End-to-End Mixed Precision Neural Network Co-Exploration Framework for Edge AI, https://arxiv.org/pdf/2508.09500, 2025-08-13
2025-11-09 20:54:19,065 - INFO - root - Page:1, Index:40, SPARC: Soft Probabilistic Adaptive multi-interest Retrieval Model via Codebooks for recommender system, https://arxiv.org/pdf/2508.09090, 2025-08-12
2025-11-09 20:54:19,066 - INFO - root - Page:1, Index:41, Rethinking 1-bit Optimization Leveraging Pre-trained Large Language Models, https://arxiv.org/pdf/2508.06974, 2025-08-09
2025-11-09 20:54:19,066 - INFO - root - Page:1, Index:42, Efficient Deep Neural Receiver with Post-Training Quantization, https://arxiv.org/pdf/2508.06275, 2025-08-08
2025-11-09 20:54:19,066 - INFO - root - Page:1, Index:43, iFairy: the First 2-bit Complex LLM with All Parameters in $\{\pm1, \pm i\}$, https://arxiv.org/pdf/2508.05571, 2025-08-16
2025-11-09 20:54:19,067 - INFO - root - Page:1, Index:44, S$^2$Q-VDiT: Accurate Quantized Video Diffusion Transformer with Salient Data and Sparse Token Distillation, https://arxiv.org/pdf/2508.04016, 2025-10-27
2025-11-09 20:54:19,067 - INFO - root - Page:1, Index:45, LRQ-DiT: Log-Rotation Post-Training Quantization of Diffusion Transformers for Image and Video Generation, https://arxiv.org/pdf/2508.03485, 2025-09-23
2025-11-09 20:54:19,067 - INFO - root - Page:1, Index:46, VLMQ: Efficient Post-Training Quantization for Large Vision-Language Models via Hessian Augmentation, https://arxiv.org/pdf/2508.03351, 2025-08-05
2025-11-09 20:54:19,068 - INFO - root - Page:1, Index:47, TF-MLPNet: Tiny Real-Time Neural Speech Separation, https://arxiv.org/pdf/2508.03047, 2025-08-04
2025-11-09 20:54:19,068 - INFO - root - Page:1, Index:48, SaviorRec: Semantic-Behavior Alignment for Cold-Start Recommendation, https://arxiv.org/pdf/2508.01375, 2025-08-02
2025-11-09 20:54:19,069 - INFO - root - Page:1, Index:49, MixA-Q: Revisiting Activation Sparsity for Vision Transformers from a Mixed-Precision Quantization Perspective, https://arxiv.org/pdf/2507.19131, 2025-07-25
2025-11-09 20:54:19,069 - INFO - root - Fetching page 3 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=100
2025-11-09 20:54:25,722 - INFO - root - get_all_titles_from_web 
2025-11-09 20:54:25,722 - INFO - root - Page:2, Index:0, Enhancing Quantization-Aware Training on Edge Devices via Relative Entropy Coreset Selection and Cascaded Layer Correction, https://arxiv.org/pdf/2507.17768, 2025-07-16
2025-11-09 20:54:25,724 - INFO - root - Page:2, Index:1, SiLQ: Simple Large Language Model Quantization-Aware Training, https://arxiv.org/pdf/2507.16933, 2025-07-22
2025-11-09 20:54:25,724 - INFO - root - Page:2, Index:2, Task-Specific Zero-shot Quantization-Aware Training for Object Detection, https://arxiv.org/pdf/2507.16782, 2025-07-22
2025-11-09 20:54:25,724 - INFO - root - Page:2, Index:3, TorchAO: PyTorch-Native Training-to-Serving Model Optimization, https://arxiv.org/pdf/2507.16099, 2025-07-21
2025-11-09 20:54:25,725 - INFO - root - Page:2, Index:4, SegQuant: A Semantics-Aware and Generalizable Quantization Framework for Diffusion Models, https://arxiv.org/pdf/2507.14811, 2025-08-27
2025-11-09 20:54:25,725 - INFO - root - Page:2, Index:5, Apple Intelligence Foundation Language Models: Tech Report 2025, https://arxiv.org/pdf/2507.13575, 2025-08-27
2025-11-09 20:54:25,725 - INFO - root - Page:2, Index:6, Generative Multi-Target Cross-Domain Recommendation, https://arxiv.org/pdf/2507.12871, 2025-08-07
2025-11-09 20:54:25,725 - INFO - root - Page:2, Index:7, DAF: An Efficient End-to-End Dynamic Activation Framework for on-Device DNN Training, https://arxiv.org/pdf/2507.07149, 2025-07-09
2025-11-09 20:54:25,726 - INFO - root - Page:2, Index:8, Opto-ViT: Architecting a Near-Sensor Region of Interest-Aware Vision Transformer Accelerator with Silicon Photonics, https://arxiv.org/pdf/2507.07044, 2025-07-15
2025-11-09 20:54:25,727 - INFO - root - Page:2, Index:9, QS4D: Quantization-aware training for efficient hardware deployment of structured state-space sequential models, https://arxiv.org/pdf/2507.06079, 2025-07-08
2025-11-09 20:54:25,729 - INFO - root - Page:2, Index:10, GSVR: 2D Gaussian-based Video Representation for 800+ FPS with Hybrid Deformation Field, https://arxiv.org/pdf/2507.05594, 2025-07-07
2025-11-09 20:54:25,732 - INFO - root - Page:2, Index:11, Hita: Holistic Tokenizer for Autoregressive Image Generation, https://arxiv.org/pdf/2507.02358, 2025-07-11
2025-11-09 20:54:25,733 - INFO - root - Page:2, Index:12, QPART: Adaptive Model Quantization and Dynamic Workload Balancing for Accuracy-aware Edge Inference, https://arxiv.org/pdf/2506.23934, 2025-06-30
2025-11-09 20:54:25,733 - INFO - root - Page:2, Index:13, FedWSQ: Efficient Federated Learning with Weight Standardization and Distribution-Aware Non-Uniform Quantization, https://arxiv.org/pdf/2506.23516, 2025-07-21
2025-11-09 20:54:25,735 - INFO - root - Page:2, Index:14, Spectra 1.1: Scaling Laws and Efficient Inference for Ternary Language Models, https://arxiv.org/pdf/2506.23025, 2025-06-28
2025-11-09 20:54:25,735 - INFO - root - Page:2, Index:15, Joint Quantization and Pruning Neural Networks Approach: A Case Study on FSO Receivers, https://arxiv.org/pdf/2506.20084, 2025-06-24
2025-11-09 20:54:25,736 - INFO - root - Page:2, Index:16, Single-step Diffusion for Image Compression at Ultra-Low Bitrates, https://arxiv.org/pdf/2506.16572, 2025-09-22
2025-11-09 20:54:25,736 - INFO - root - Page:2, Index:17, LittleBit: Ultra Low-Bit Quantization via Latent Factorization, https://arxiv.org/pdf/2506.13771, 2025-10-28
2025-11-09 20:54:25,736 - INFO - root - Page:2, Index:18, MARCO: Hardware-Aware Neural Architecture Search for Edge Devices with Multi-Agent Reinforcement Learning and Conformal Prediction Filtering, https://arxiv.org/pdf/2506.13755, 2025-06-16
2025-11-09 20:54:25,737 - INFO - root - Page:2, Index:19, EAQuant: Enhancing Post-Training Quantization for MoE Models via Expert-Aware Optimization, https://arxiv.org/pdf/2506.13329, 2025-07-04
2025-11-09 20:54:25,737 - INFO - root - Page:2, Index:20, Towards Neural Audio Codec Source Parsing, https://arxiv.org/pdf/2506.12627, 2025-06-14
2025-11-09 20:54:25,737 - INFO - root - Page:2, Index:21, Quantizing Small-Scale State-Space Models for Edge AI, https://arxiv.org/pdf/2506.12480, 2025-06-14
2025-11-09 20:54:25,738 - INFO - root - Page:2, Index:22, EMLoC: Emulator-based Memory-efficient Fine-tuning with LoRA Correction, https://arxiv.org/pdf/2506.12015, 2025-06-13
2025-11-09 20:54:25,738 - INFO - root - Page:2, Index:23, Compression Aware Certified Training, https://arxiv.org/pdf/2506.11992, 2025-06-13
2025-11-09 20:54:25,738 - INFO - root - Page:2, Index:24, GPLQ: A General, Practical, and Lightning QAT Method for Vision Transformers, https://arxiv.org/pdf/2506.11784, 2025-06-13
2025-11-09 20:54:25,738 - INFO - root - Page:2, Index:25, TruncQuant: Truncation-Ready Quantization for DNNs with Flexible Weight Bit Precision, https://arxiv.org/pdf/2506.11431, 2025-06-12
2025-11-09 20:54:25,739 - INFO - root - Page:2, Index:26, EfficientQuant: An Efficient Post-Training Quantization for CNN-Transformer Hybrid Models on Edge Devices, https://arxiv.org/pdf/2506.11093, 2025-06-05
2025-11-09 20:54:25,739 - INFO - root - Page:2, Index:27, Starting Positions Matter: A Study on Better Weight Initialization for Neural Network Quantization, https://arxiv.org/pdf/2506.10463, 2025-06-12
2025-11-09 20:54:25,741 - INFO - root - Page:2, Index:28, AWP: Activation-Aware Weight Pruning and Quantization with Projected Gradient Descent, https://arxiv.org/pdf/2506.10205, 2025-06-11
2025-11-09 20:54:25,741 - INFO - root - Page:2, Index:29, Q-SAM2: Accurate Quantization for Segment Anything Model 2, https://arxiv.org/pdf/2506.09782, 2025-06-11
2025-11-09 20:54:25,741 - INFO - root - Page:2, Index:30, Unifying Block-wise PTQ and Distillation-based QAT for Progressive Quantization toward 2-bit Instruction-Tuned LLMs, https://arxiv.org/pdf/2506.09104, 2025-06-10
2025-11-09 20:54:25,742 - INFO - root - Page:2, Index:31, Implementing Keyword Spotting on the MCUX947 Microcontroller with Integrated NPU, https://arxiv.org/pdf/2506.08911, 2025-06-10
2025-11-09 20:54:25,742 - INFO - root - Page:2, Index:32, POLARON: Precision-aware On-device Learning and Adaptive Runtime-cONfigurable AI acceleration, https://arxiv.org/pdf/2506.08785, 2025-06-10
2025-11-09 20:54:25,743 - INFO - root - Page:2, Index:33, MoQAE: Mixed-Precision Quantization for Long-Context LLM Inference via Mixture of Quantization-Aware Experts, https://arxiv.org/pdf/2506.07533, 2025-06-09
2025-11-09 20:54:25,743 - INFO - root - Page:2, Index:34, BitVLA: 1-bit Vision-Language-Action Models for Robotics Manipulation, https://arxiv.org/pdf/2506.07530, 2025-06-09
2025-11-09 20:54:25,744 - INFO - root - Page:2, Index:35, RecGPT: A Foundation Model for Sequential Recommendation, https://arxiv.org/pdf/2506.06270, 2025-06-12
2025-11-09 20:54:25,748 - INFO - root - Page:2, Index:36, FPSAttention: Training-Aware FP8 and Sparsity Co-Design for Fast Video Diffusion, https://arxiv.org/pdf/2506.04648, 2025-06-05
2025-11-09 20:54:25,748 - INFO - root - Page:2, Index:37, BitTTS: Highly Compact Text-to-Speech Using 1.58-bit Quantization and Weight Indexing, https://arxiv.org/pdf/2506.03515, 2025-06-03
2025-11-09 20:54:25,749 - INFO - root - Page:2, Index:38, ShapeLLM-Omni: A Native Multimodal LLM for 3D Generation and Understanding, https://arxiv.org/pdf/2506.01853, 2025-06-02
2025-11-09 20:54:25,749 - INFO - root - Page:2, Index:39, Movable Antenna Enhanced Federated Fine-Tuning of Large Language Models via Hybrid Client Selection Optimization, https://arxiv.org/pdf/2506.00011, 2025-10-26
2025-11-09 20:54:25,750 - INFO - root - Page:2, Index:40, Running Conventional Automatic Speech Recognition on Memristor Hardware: A Simulated Approach, https://arxiv.org/pdf/2505.24721, 2025-05-30
2025-11-09 20:54:25,750 - INFO - root - Page:2, Index:41, GARLIC: GAussian Representation LearnIng for spaCe partitioning, https://arxiv.org/pdf/2505.24608, 2025-10-02
2025-11-09 20:54:25,751 - INFO - root - Page:2, Index:42, AutoChemSchematic AI: Agentic Physics-Aware Automation for Chemical Manufacturing Scale-Up, https://arxiv.org/pdf/2505.24584, 2025-08-18
2025-11-09 20:54:25,751 - INFO - root - Page:2, Index:43, Model-Preserving Adaptive Rounding, https://arxiv.org/pdf/2505.22988, 2025-09-25
2025-11-09 20:54:25,753 - INFO - root - Page:2, Index:44, Highly Efficient and Effective LLMs with Multi-Boolean Architectures, https://arxiv.org/pdf/2505.22811, 2025-10-03
2025-11-09 20:54:25,774 - INFO - root - Page:2, Index:45, Pioneering 4-Bit FP Quantization for Diffusion Models: Mixup-Sign Quantization and Timestep-Aware Fine-Tuning, https://arxiv.org/pdf/2505.21591, 2025-05-27
2025-11-09 20:54:25,774 - INFO - root - Page:2, Index:46, Frequency Composition for Compressed and Domain-Adaptive Neural Networks, https://arxiv.org/pdf/2505.20890, 2025-05-27
2025-11-09 20:54:25,774 - INFO - root - Page:2, Index:47, MoPFormer: Motion-Primitive Transformer for Wearable-Sensor Activity Recognition, https://arxiv.org/pdf/2505.20744, 2025-10-27
2025-11-09 20:54:25,775 - INFO - root - Page:2, Index:48, Optimizing edge AI models on HPC systems with the edge in the loop, https://arxiv.org/pdf/2505.19995, 2025-05-26
2025-11-09 20:54:25,775 - INFO - root - Fetching page 4 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=150
2025-11-09 20:54:33,499 - INFO - root - get_all_titles_from_web 
2025-11-09 20:54:33,500 - INFO - root - Page:3, Index:0, DPASyn: Mechanism-Aware Drug Synergy Prediction via Dual Attention and Precision-Aware Quantization, https://arxiv.org/pdf/2505.19144, 2025-09-20
2025-11-09 20:54:33,500 - INFO - root - Page:3, Index:1, Reducing Storage of Pretrained Neural Networks by Rate-Constrained Quantization and Entropy Coding, https://arxiv.org/pdf/2505.18758, 2025-05-24
2025-11-09 20:54:33,500 - INFO - root - Page:3, Index:2, Beyond Discreteness: Finite-Sample Analysis of Straight-Through Estimator for Quantization, https://arxiv.org/pdf/2505.18113, 2025-05-23
2025-11-09 20:54:33,501 - INFO - root - Page:3, Index:3, Automating Versatile Time-Series Analysis with Tiny Transformers on Embedded FPGAs, https://arxiv.org/pdf/2505.17662, 2025-09-19
2025-11-09 20:54:33,501 - INFO - root - Page:3, Index:4, FPQVAR: Floating Point Quantization for Visual Autoregressive Model with FPGA Hardware Co-design, https://arxiv.org/pdf/2505.16335, 2025-05-22
2025-11-09 20:54:33,501 - INFO - root - Page:3, Index:5, Saliency-Aware Quantized Imitation Learning for Efficient Robotic Control, https://arxiv.org/pdf/2505.15304, 2025-05-30
2025-11-09 20:54:33,502 - INFO - root - Page:3, Index:6, Scaling Law for Quantization-Aware Training, https://arxiv.org/pdf/2505.14302, 2025-05-20
2025-11-09 20:54:33,503 - INFO - root - Page:3, Index:7, Automatic mixed precision for optimizing gained time with constrained loss mean-squared-error based on model partition to sequential sub-graphs, https://arxiv.org/pdf/2505.13060, 2025-05-19
2025-11-09 20:54:33,503 - INFO - root - Page:3, Index:8, Deep Unfolding with Kernel-based Quantization in MIMO Detection, https://arxiv.org/pdf/2505.12736, 2025-05-19
2025-11-09 20:54:33,504 - INFO - root - Page:3, Index:9, FedHQ: Hybrid Runtime Quantization for Federated Learning, https://arxiv.org/pdf/2505.11982, 2025-05-17
2025-11-09 20:54:33,504 - INFO - root - Page:3, Index:10, QVGen: Pushing the Limit of Quantized Video Generative Models, https://arxiv.org/pdf/2505.11497, 2025-09-27
2025-11-09 20:54:33,504 - INFO - root - Page:3, Index:11, EA-3DGS: Efficient and Adaptive 3D Gaussians with Highly Enhanced Quality for outdoor scenes, https://arxiv.org/pdf/2505.10787, 2025-05-15
2025-11-09 20:54:33,505 - INFO - root - Page:3, Index:12, ITERA-LLM: Boosting Sub-8-Bit Large Language Model Inference via Iterative Tensor Decomposition, https://arxiv.org/pdf/2505.08981, 2025-05-13
2025-11-09 20:54:33,505 - INFO - root - Page:3, Index:13, PROM: Prioritize Reduction of Multiplications Over Lower Bit-Widths for Efficient CNNs, https://arxiv.org/pdf/2505.03254, 2025-08-06
2025-11-09 20:54:33,505 - INFO - root - Page:3, Index:14, ICQuant: Index Coding enables Low-bit LLM Quantization, https://arxiv.org/pdf/2505.00850, 2025-08-24
2025-11-09 20:54:33,507 - INFO - root - Page:3, Index:15, Enhancing Ultra-Low-Bit Quantization of Large Language Models Through Saliency-Aware Partial Retraining, https://arxiv.org/pdf/2504.13932, 2025-07-30
2025-11-09 20:54:33,508 - INFO - root - Page:3, Index:16, Achieving binary weight and activation for LLMs using Post-Training Quantization, https://arxiv.org/pdf/2504.05352, 2025-06-30
2025-11-09 20:54:33,508 - INFO - root - Page:3, Index:17, Wireless Hearables With Programmable Speech AI Accelerators, https://arxiv.org/pdf/2503.18698, 2025-10-21
2025-11-09 20:54:33,509 - INFO - root - Page:3, Index:18, GranQ: Efficient Channel-wise Quantization via Vectorized Pre-Scaling for Zero-Shot QAT, https://arxiv.org/pdf/2503.18339, 2025-10-15
2025-11-09 20:54:33,509 - INFO - root - Page:3, Index:19, CompMarkGS: Robust Watermarking for Compressed 3D Gaussian Splatting, https://arxiv.org/pdf/2503.12836, 2025-09-29
2025-11-09 20:54:33,509 - INFO - root - Page:3, Index:20, AHCPTQ: Accurate and Hardware-Compatible Post-Training Quantization for Segment Anything Model, https://arxiv.org/pdf/2503.03088, 2025-07-11
2025-11-09 20:54:33,510 - INFO - root - Page:3, Index:21, Teaching Metric Distance to Discrete Autoregressive Language Models, https://arxiv.org/pdf/2503.02379, 2025-10-07
2025-11-09 20:54:33,512 - INFO - root - Page:3, Index:22, Regularization-based Framework for Quantization-, Fault- and Variability-Aware Training, https://arxiv.org/pdf/2503.01297, 2025-07-12
2025-11-09 20:54:33,513 - INFO - root - Fetching page 5 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=200
2025-11-09 20:54:39,936 - INFO - root - get_all_titles_from_web 
2025-11-09 20:54:39,937 - INFO - root - Page:4, Index:0, Investigating the Impact of Quantization Methods on the Safety and Reliability of Large Language Models, https://arxiv.org/pdf/2502.15799, 2025-06-29
2025-11-09 20:54:39,937 - INFO - root - Page:4, Index:1, Rotate, Clip, and Partition: Towards W2A4KV4 Quantization by Integrating Rotation and Learnable Non-uniform Quantizer, https://arxiv.org/pdf/2502.15779, 2025-09-01
2025-11-09 20:54:39,937 - INFO - root - Page:4, Index:2, RoSTE: An Efficient Quantization-Aware Supervised Fine-Tuning Approach for Large Language Models, https://arxiv.org/pdf/2502.09003, 2025-06-05
2025-11-09 20:54:39,937 - INFO - root - Page:4, Index:3, Spatial Degradation-Aware and Temporal Consistent Diffusion Model for Compressed Video Super-Resolution, https://arxiv.org/pdf/2502.07381, 2025-06-27
2025-11-09 20:54:39,938 - INFO - root - Page:4, Index:4, QuEST: Stable Training of LLMs with 1-Bit Weights and Activations, https://arxiv.org/pdf/2502.05003, 2025-06-10
2025-11-09 20:54:39,938 - INFO - root - Page:4, Index:5, HALO: Hadamard-Assisted Lower-Precision Optimization for LLMs, https://arxiv.org/pdf/2501.02625, 2025-11-05
2025-11-09 20:54:39,938 - INFO - root - Page:4, Index:6, TAR3D: Creating High-Quality 3D Assets via Next-Part Prediction, https://arxiv.org/pdf/2412.16919, 2025-08-08
2025-11-09 20:54:39,939 - INFO - root - Page:4, Index:7, Training Multi-Layer Binary Neural Networks With Local Binary Error Signals, https://arxiv.org/pdf/2412.00119, 2025-08-05
2025-11-09 20:54:39,939 - INFO - root - Page:4, Index:8, Scaling Large-scale GNN Training to Thousands of Processors on CPU-based Supercomputers, https://arxiv.org/pdf/2411.16025, 2025-05-26
2025-11-09 20:54:39,939 - INFO - root - Page:4, Index:9, HAFLQ: Heterogeneous Adaptive Federated LoRA Fine-tuned LLM with Quantization, https://arxiv.org/pdf/2411.06581, 2025-05-16
2025-11-09 20:54:39,939 - INFO - root - Fetching page 6 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=250
2025-11-09 20:54:47,345 - INFO - root - get_all_titles_from_web 
2025-11-09 20:54:47,345 - INFO - root - Page:5, Index:0, Gradient-Free Training of Quantized Neural Networks, https://arxiv.org/pdf/2410.09734, 2025-09-29
2025-11-09 20:54:47,346 - INFO - root - Page:5, Index:1, QT-DoG: Quantization-aware Training for Domain Generalization, https://arxiv.org/pdf/2410.06020, 2025-06-26
2025-11-09 20:54:47,346 - INFO - root - Page:5, Index:2, Constraint Guided Model Quantization of Neural Networks, https://arxiv.org/pdf/2409.20138, 2025-09-12
2025-11-09 20:54:47,347 - INFO - root - Page:5, Index:3, Accumulator-Aware Post-Training Quantization for Large Language Models, https://arxiv.org/pdf/2409.17092, 2025-07-30
2025-11-09 20:54:47,347 - INFO - root - Page:5, Index:4, DilateQuant: Accurate and Efficient Diffusion Quantization via Weight Dilation, https://arxiv.org/pdf/2409.14307, 2025-07-09
2025-11-09 20:54:47,347 - INFO - root - Page:5, Index:5, Robust Training of Neural Networks at Arbitrary Precision and Sparsity, https://arxiv.org/pdf/2409.09245, 2025-09-23
2025-11-09 20:54:47,347 - INFO - root - Page:5, Index:6, VQ-CTAP: Cross-Modal Fine-Grained Sequence Representation Learning for Speech Processing, https://arxiv.org/pdf/2408.05758, 2025-05-27
2025-11-09 20:54:47,348 - INFO - root - Page:5, Index:7, DopQ-ViT: Towards Distribution-Friendly and Outlier-Aware Post-Training Quantization for Vision Transformers, https://arxiv.org/pdf/2408.03291, 2025-06-19
2025-11-09 20:54:47,349 - INFO - root - Page:5, Index:8, Temporal Feature Matters: A Framework for Diffusion Model Quantization, https://arxiv.org/pdf/2407.19547, 2025-07-11
2025-11-09 20:54:47,351 - INFO - root - Page:5, Index:9, EfficientQAT: Efficient Quantization-Aware Training for Large Language Models, https://arxiv.org/pdf/2407.11062, 2025-05-19
2025-11-09 20:54:47,351 - INFO - root - Page:5, Index:10, Integer-only Quantized Transformers for Embedded FPGA-based Time-series Forecasting in AIoT, https://arxiv.org/pdf/2407.11041, 2025-10-31
2025-11-09 20:54:47,352 - INFO - root - Fetching page 7 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=300
2025-11-09 20:54:53,912 - INFO - root - get_all_titles_from_web 
2025-11-09 20:54:53,912 - INFO - root - Page:6, Index:0, BoA: Attention-aware Post-training Quantization without Backpropagation, https://arxiv.org/pdf/2406.13474, 2025-06-06
2025-11-09 20:54:53,913 - INFO - root - Page:6, Index:1, A Rescaling-Invariant Lipschitz Bound Based on Path-Metrics for Modern ReLU Network Parameterizations, https://arxiv.org/pdf/2405.15006, 2025-06-13
2025-11-09 20:54:53,913 - INFO - root - Page:6, Index:2, Scheduling Weight Transitions for Quantization-Aware Training, https://arxiv.org/pdf/2404.19248, 2025-10-01
2025-11-09 20:54:53,913 - INFO - root - Page:6, Index:3, GPTVQ: The Blessing of Dimensionality for LLM Quantization, https://arxiv.org/pdf/2402.15319, 2025-06-03
2025-11-09 20:54:53,913 - INFO - root - Fetching page 8 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=350
2025-11-09 20:55:01,153 - INFO - root - get_all_titles_from_web 
2025-11-09 20:55:01,153 - INFO - root - Page:7, Index:0, Squat: Quant Small Language Models on the Edge, https://arxiv.org/pdf/2402.10787, 2025-07-01
2025-11-09 20:55:01,154 - INFO - root - Page:7, Index:1, L4Q: Parameter Efficient Quantization-Aware Fine-Tuning on Large Language Models, https://arxiv.org/pdf/2402.04902, 2025-07-21
2025-11-09 20:55:01,154 - INFO - root - Fetching page 9 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=400
2025-11-09 20:55:07,954 - INFO - root - ------------------------------------------------------------------------------------------------------------------------
2025-11-09 20:55:07,955 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\A Quantized VAE-MLP Botnet Detection Model_ A Systematic Evaluation of Quantizat.pdf
2025-11-09 20:55:07,958 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\FP8-Flow-MoE_ A Casting-Free FP8 Recipe without Double Quantization Error.pdf
2025-11-09 20:55:07,959 - INFO - root - 跳过已处理论文 A Quantized VAE-MLP Botnet Detection Model: A Systematic Evaluation of Quantization-Aware Training and Post-Training Quantization Strategies：d:\ChatPaper\academic Papers\Quantization-Aware-Training\A Quantized VAE-MLP Botnet Detection Model_ A Systematic Evaluation of Quantizat.pdf
2025-11-09 20:55:07,959 - INFO - root - 跳过已处理论文 FP8-Flow-MoE: A Casting-Free FP8 Recipe without Double Quantization Error：d:\ChatPaper\academic Papers\Quantization-Aware-Training\FP8-Flow-MoE_ A Casting-Free FP8 Recipe without Double Quantization Error.pdf
2025-11-09 20:55:07,960 - INFO - root - summary time: 68.21 seconds
2025-11-09 20:58:06,281 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-09 20:58:06,283 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-09 20:58:06,286 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-09 20:58:07,080 - INFO - root - LLMClientManager: 指定使用客户端: Gemini
2025-11-09 20:58:08,427 - INFO - root - GeminiClient: trying model gemini-2.5-flash
2025-11-09 20:58:11,567 - INFO - root - GeminiClient: initialized model gemini-2.5-flash
2025-11-09 20:58:11,568 - INFO - root - LLMClientManager: Gemini 客户端初始化成功
2025-11-09 20:58:11,568 - INFO - root - LLMClientManager: switched to Gemini client
2025-11-09 20:58:11,568 - INFO - root - 已手动切换到 LLM 客户端: Gemini
2025-11-09 20:58:11,569 - INFO - root - 使用 LLM 模型: gemini-2.5-flash
2025-11-09 20:58:11,569 - INFO - root - 可用客户端: ['Gemini']
2025-11-09 20:58:11,570 - INFO - root - === 运行配置 ===
2025-11-09 20:58:11,570 - INFO - root - 处理模式: arxiv在线搜索
2025-11-09 20:58:11,570 - INFO - root - 关键词: QAT
2025-11-09 20:58:11,570 - INFO - root - 查询: Quantization-Aware-Training
2025-11-09 20:58:11,571 - INFO - root - 排序: None
2025-11-09 20:58:11,572 - INFO - root - 最近天数: 180
2025-11-09 20:58:11,573 - INFO - root - 最大处理数量: 40
2025-11-09 20:58:11,573 - INFO - root - 保存图片: 是
2025-11-09 20:58:11,573 - INFO - root - 输出语言: 中文
2025-11-09 20:58:11,574 - INFO - root - 强制重新处理: 否
2025-11-09 20:58:11,575 - INFO - root - ====================
2025-11-09 20:58:11,575 - INFO - root - 使用 arXiv 搜索模式（通过 chat_arxiv 模块获取）
2025-11-09 20:58:11,575 - INFO - root - Fetching page 1 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50
2025-11-09 20:58:18,450 - INFO - root - get_all_titles_from_web 
2025-11-09 20:58:18,450 - INFO - root - Page:0, Index:0, A Quantized VAE-MLP Botnet Detection Model: A Systematic Evaluation of Quantization-Aware Training and Post-Training Quantization Strategies, https://arxiv.org/pdf/2511.03201, 2025-11-05
2025-11-09 20:58:18,451 - INFO - root - Page:0, Index:1, FP8-Flow-MoE: A Casting-Free FP8 Recipe without Double Quantization Error, https://arxiv.org/pdf/2511.02302, 2025-11-04
2025-11-09 20:58:18,451 - INFO - root - Page:0, Index:2, Outlier-Aware Post-Training Quantization for Image Super-Resolution, https://arxiv.org/pdf/2511.00682, 2025-11-01
2025-11-09 20:58:18,451 - INFO - root - Page:0, Index:3, Evaluation of Wafer-Scale SOT-MRAM for Analog Crossbar Array Applications, https://arxiv.org/pdf/2510.25853, 2025-11-03
2025-11-09 20:58:18,452 - INFO - root - Page:0, Index:4, Improving the Straight-Through Estimator with Zeroth-Order Information, https://arxiv.org/pdf/2510.23926, 2025-10-27
2025-11-09 20:58:18,452 - INFO - root - Page:0, Index:5, Real-Time Semantic Segmentation on FPGA for Autonomous Vehicles Using LMIINet with the CGRA4ML Framework, https://arxiv.org/pdf/2510.22243, 2025-10-25
2025-11-09 20:58:18,453 - INFO - root - Page:0, Index:6, TernaryCLIP: Efficiently Compressing Vision-Language Models with Ternary Weights and Distilled Knowledge, https://arxiv.org/pdf/2510.21879, 2025-10-23
2025-11-09 20:58:18,453 - INFO - root - Page:0, Index:7, KARIPAP: Quantum-Inspired Tensor Network Compression of Large Language Models Using Infinite Projected Entangled Pair States and Tensor Renormalization Group, https://arxiv.org/pdf/2510.21844, 2025-10-22
2025-11-09 20:58:18,453 - INFO - root - Page:0, Index:8, A Convergence Analysis of Adaptive Optimizers under Floating-point Quantization, https://arxiv.org/pdf/2510.21314, 2025-10-24
2025-11-09 20:58:18,455 - INFO - root - Page:0, Index:9, Adaptive Distribution-aware Quantization for Mixed-Precision Neural Networks, https://arxiv.org/pdf/2510.19760, 2025-10-22
2025-11-09 20:58:18,455 - INFO - root - Page:0, Index:10, CAGE: Curvature-Aware Gradient Estimation For Accurate Quantization-Aware Training, https://arxiv.org/pdf/2510.18784, 2025-10-21
2025-11-09 20:58:18,455 - INFO - root - Page:0, Index:11, Mixed-Precision Quantization for Language Models: Techniques and Prospects, https://arxiv.org/pdf/2510.16805, 2025-10-19
2025-11-09 20:58:18,456 - INFO - root - Page:0, Index:12, SPLite Hand: Sparsity-Aware Lightweight 3D Hand Pose Estimation, https://arxiv.org/pdf/2510.16396, 2025-10-30
2025-11-09 20:58:18,456 - INFO - root - Page:0, Index:13, CTR-LoRA: Curvature-Aware and Trust-Region Guided Low-Rank Adaptation for Large Language Models, https://arxiv.org/pdf/2510.15962, 2025-10-11
2025-11-09 20:58:18,457 - INFO - root - Page:0, Index:14, SANR: Scene-Aware Neural Representation for Light Field Image Compression with Rate-Distortion Optimization, https://arxiv.org/pdf/2510.15775, 2025-10-17
2025-11-09 20:58:18,457 - INFO - root - Page:0, Index:15, SpikeFit: Towards Optimal Deployment of Spiking Networks on Neuromorphic Hardware, https://arxiv.org/pdf/2510.15542, 2025-10-31
2025-11-09 20:58:18,458 - INFO - root - Page:0, Index:16, GRank: Towards Target-Aware and Streamlined Industrial Retrieval with a Generate-Rank Framework, https://arxiv.org/pdf/2510.15299, 2025-10-17
2025-11-09 20:58:18,458 - INFO - root - Page:0, Index:17, SaLon3R: Structure-aware Long-term Generalizable 3D Reconstruction from Unposed Images, https://arxiv.org/pdf/2510.15072, 2025-10-16
2025-11-09 20:58:18,459 - INFO - root - Page:0, Index:18, FraQAT: Quantization Aware Training with Fractional bits, https://arxiv.org/pdf/2510.14823, 2025-10-16
2025-11-09 20:58:18,459 - INFO - root - Page:0, Index:19, Computing-In-Memory Aware Model Adaption For Edge Devices, https://arxiv.org/pdf/2510.14379, 2025-10-16
2025-11-09 20:58:18,461 - INFO - root - Page:0, Index:20, Invited Paper: BitMedViT: Ternary-Quantized Vision Transformer for Medical AI Assistants on the Edge, https://arxiv.org/pdf/2510.13760, 2025-11-04
2025-11-09 20:58:18,462 - INFO - root - Page:0, Index:21, NeuroRVQ: Multi-Scale EEG Tokenization for Generative Large Brainwave Models, https://arxiv.org/pdf/2510.13068, 2025-10-14
2025-11-09 20:58:18,463 - INFO - root - Page:0, Index:22, Detect Anything via Next Point Prediction, https://arxiv.org/pdf/2510.12798, 2025-10-14
2025-11-09 20:58:18,464 - INFO - root - Page:0, Index:23, AndesVL Technical Report: An Efficient Mobile-side Multimodal Large Language Model, https://arxiv.org/pdf/2510.11496, 2025-10-14
2025-11-09 20:58:18,464 - INFO - root - Page:0, Index:24, Rescaling-Aware Training for Efficient Deployment of Deep Learning Models on Full-Integer Hardware, https://arxiv.org/pdf/2510.11484, 2025-10-13
2025-11-09 20:58:18,464 - INFO - root - Page:0, Index:25, SASER: Stego attacks on open-source LLMs, https://arxiv.org/pdf/2510.10486, 2025-10-12
2025-11-09 20:58:18,466 - INFO - root - Page:0, Index:26, Ultralytics YOLO Evolution: An Overview of YOLO26, YOLO11, YOLOv8 and YOLOv5 Object Detectors for Computer Vision and Pattern Recognition, https://arxiv.org/pdf/2510.09653, 2025-10-15
2025-11-09 20:58:18,466 - INFO - root - Page:0, Index:27, A Theoretically-Grounded Codebook for Digital Semantic Communications, https://arxiv.org/pdf/2510.07108, 2025-10-14
2025-11-09 20:58:18,467 - INFO - root - Page:0, Index:28, QuantDemoire: Quantization with Outlier Aware for Image Demoiréing, https://arxiv.org/pdf/2510.04066, 2025-10-05
2025-11-09 20:58:18,469 - INFO - root - Page:0, Index:29, Adaptively Sampling-Reusing-Mixing Decomposed Gradients to Speed Up Sharpness Aware Minimization, https://arxiv.org/pdf/2510.03763, 2025-10-04
2025-11-09 20:58:18,474 - INFO - root - Page:0, Index:30, Quant-dLLM: Post-Training Extreme Low-Bit Quantization for Diffusion Large Language Models, https://arxiv.org/pdf/2510.03274, 2025-09-27
2025-11-09 20:58:18,474 - INFO - root - Page:0, Index:31, PT$^2$-LLM: Post-Training Ternarization for Large Language Models, https://arxiv.org/pdf/2510.03267, 2025-09-26
2025-11-09 20:58:18,475 - INFO - root - Page:0, Index:32, Purrception: Variational Flow Matching for Vector-Quantized Image Generation, https://arxiv.org/pdf/2510.01478, 2025-10-01
2025-11-09 20:58:18,476 - INFO - root - Page:0, Index:33, Post-Training Quantization for Audio Diffusion Transformers, https://arxiv.org/pdf/2510.00313, 2025-09-30
2025-11-09 20:58:18,477 - INFO - root - Page:0, Index:34, Rethinking RoPE Scaling in Quantized LLM: Theory, Outlier, and Channel-Band Analysis with Weight Rescaling, https://arxiv.org/pdf/2510.00028, 2025-09-25
2025-11-09 20:58:18,477 - INFO - root - Page:0, Index:35, Post-Training Quantization via Residual Truncation and Zero Suppression for Diffusion Models, https://arxiv.org/pdf/2509.26436, 2025-09-30
2025-11-09 20:58:18,483 - INFO - root - Page:0, Index:36, Cat: Post-Training Quantization Error Reduction via Cluster-based Affine Transformation, https://arxiv.org/pdf/2509.26277, 2025-10-07
2025-11-09 20:58:18,484 - INFO - root - Page:0, Index:37, CAST: Continuous and Differentiable Semi-Structured Sparsity-Aware Training for Large Language Models, https://arxiv.org/pdf/2509.25996, 2025-09-30
2025-11-09 20:58:18,484 - INFO - root - Page:0, Index:38, Norm-Q: Effective Compression Method for Hidden Markov Models in Neuro-Symbolic Applications, https://arxiv.org/pdf/2509.25439, 2025-09-29
2025-11-09 20:58:18,484 - INFO - root - Page:0, Index:39, On-the-Fly Adaptation to Quantization: Configuration-Aware LoRA for Efficient Fine-Tuning of Quantized LLMs, https://arxiv.org/pdf/2509.25214, 2025-09-22
2025-11-09 20:58:18,485 - INFO - root - Page:0, Index:40, VoxCPM: Tokenizer-Free TTS for Context-Aware Speech Generation and True-to-Life Voice Cloning, https://arxiv.org/pdf/2509.24650, 2025-09-29
2025-11-09 20:58:18,485 - INFO - root - Page:0, Index:41, S$^2$NN: Sub-bit Spiking Neural Networks, https://arxiv.org/pdf/2509.24266, 2025-10-24
2025-11-09 20:58:18,486 - INFO - root - Page:0, Index:42, Tequila: Trapping-free Ternary Quantization for Large Language Models, https://arxiv.org/pdf/2509.23809, 2025-10-17
2025-11-09 20:58:18,486 - INFO - root - Page:0, Index:43, Texture Vector-Quantization and Reconstruction Aware Prediction for Generative Super-Resolution, https://arxiv.org/pdf/2509.23774, 2025-09-30
2025-11-09 20:58:18,486 - INFO - root - Page:0, Index:44, RobuQ: Pushing DiTs to W1.58A2 via Robust Activation Quantization, https://arxiv.org/pdf/2509.23582, 2025-09-27
2025-11-09 20:58:18,487 - INFO - root - Page:0, Index:45, Beyond Outliers: A Study of Optimizers Under Quantization, https://arxiv.org/pdf/2509.23500, 2025-10-02
2025-11-09 20:58:18,487 - INFO - root - Page:0, Index:46, Compute-Optimal Quantization-Aware Training, https://arxiv.org/pdf/2509.22935, 2025-09-26
2025-11-09 20:58:18,487 - INFO - root - Page:0, Index:47, COSPADI: Compressing LLMs via Calibration-Guided Sparse Dictionary Learning, https://arxiv.org/pdf/2509.22075, 2025-10-06
2025-11-09 20:58:18,488 - INFO - root - Page:0, Index:48, SlimDiff: Training-Free, Activation-Guided Hands-free Slimming of Diffusion Models, https://arxiv.org/pdf/2509.21498, 2025-09-25
2025-11-09 20:58:18,489 - INFO - root - Page:0, Index:49, Quantized Visual Geometry Grounded Transformer, https://arxiv.org/pdf/2509.21302, 2025-09-29
2025-11-09 20:58:18,492 - INFO - root - Fetching page 2 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=50
2025-11-09 20:58:25,321 - INFO - root - get_all_titles_from_web 
2025-11-09 20:58:25,323 - INFO - root - Page:1, Index:0, Can Less Precise Be More Reliable? A Systematic Evaluation of Quantization's Impact on CLIP Beyond Accuracy, https://arxiv.org/pdf/2509.21173, 2025-10-27
2025-11-09 20:58:25,324 - INFO - root - Page:1, Index:1, Punching Above Precision: Small Quantized Model Distillation with Learnable Regularizer, https://arxiv.org/pdf/2509.20854, 2025-09-25
2025-11-09 20:58:25,325 - INFO - root - Page:1, Index:2, TinyEcoWeedNet: Edge Efficient Real-Time Aerial Agricultural Weed Detection, https://arxiv.org/pdf/2509.18193, 2025-09-19
2025-11-09 20:58:25,325 - INFO - root - Page:1, Index:3, SBVR: Summation of BitVector Representation for Efficient LLM Quantization, https://arxiv.org/pdf/2509.18172, 2025-09-17
2025-11-09 20:58:25,326 - INFO - root - Page:1, Index:4, QWHA: Quantization-Aware Walsh-Hadamard Adaptation for Parameter-Efficient Fine-Tuning on Large Language Models, https://arxiv.org/pdf/2509.17428, 2025-09-26
2025-11-09 20:58:25,327 - INFO - root - Page:1, Index:5, PTQTP: Post-Training Quantization to Trit-Planes for Large Language Models, https://arxiv.org/pdf/2509.16989, 2025-10-28
2025-11-09 20:58:25,329 - INFO - root - Page:1, Index:6, MEC-Quant: Maximum Entropy Coding for Extremely Low Bit Quantization-Aware Training, https://arxiv.org/pdf/2509.15514, 2025-09-18
2025-11-09 20:58:25,330 - INFO - root - Page:1, Index:7, Q-ROAR: Outlier-Aware Rescaling for RoPE Position Interpolation in Quantized Long-Context LLMs, https://arxiv.org/pdf/2509.14391, 2025-09-17
2025-11-09 20:58:25,332 - INFO - root - Page:1, Index:8, Efficient Quantization-Aware Neural Receivers: Beyond Post-Training Quantization, https://arxiv.org/pdf/2509.13786, 2025-09-19
2025-11-09 20:58:25,341 - INFO - root - Page:1, Index:9, Rate-Distortion Limits for Multimodal Retrieval: Theory, Optimal Codes, and Finite-Sample Guarantees, https://arxiv.org/pdf/2509.11054, 2025-09-13
2025-11-09 20:58:25,345 - INFO - root - Page:1, Index:10, SQAP-VLA: A Synergistic Quantization-Aware Pruning Framework for High-Performance Vision-Language-Action Models, https://arxiv.org/pdf/2509.09090, 2025-09-10
2025-11-09 20:58:25,347 - INFO - root - Page:1, Index:11, CSI Compression Beyond Latents: End-to-End Hybrid Attention-CNN Networks with Entropy Regularization, https://arxiv.org/pdf/2509.08776, 2025-09-10
2025-11-09 20:58:25,348 - INFO - root - Page:1, Index:12, Explaining How Quantization Disparately Skews a Model, https://arxiv.org/pdf/2509.07222, 2025-09-08
2025-11-09 20:58:25,348 - INFO - root - Page:1, Index:13, LoaQ: Layer-wise Output Approximation Quantization, https://arxiv.org/pdf/2509.06297, 2025-09-07
2025-11-09 20:58:25,350 - INFO - root - Page:1, Index:14, FineServe: Precision-Aware KV Slab and Two-Level Scheduling for Heterogeneous Precision LLM Serving, https://arxiv.org/pdf/2509.06261, 2025-09-14
2025-11-09 20:58:25,350 - INFO - root - Page:1, Index:15, Sensitivity-Aware Post-Training Quantization for Deep Neural Networks, https://arxiv.org/pdf/2509.05576, 2025-09-05
2025-11-09 20:58:25,351 - INFO - root - Page:1, Index:16, SuperSNN: A Hardware-Aware Framework for Physically Realizable, High-Performance Superconducting Spiking Neural Network Chips, https://arxiv.org/pdf/2509.05532, 2025-09-05
2025-11-09 20:58:25,351 - INFO - root - Page:1, Index:17, Data-Augmented Quantization-Aware Knowledge Distillation, https://arxiv.org/pdf/2509.03850, 2025-09-03
2025-11-09 20:58:25,353 - INFO - root - Page:1, Index:18, DPQuant: Efficient and Differentially-Private Model Training via Dynamic Quantization Scheduling, https://arxiv.org/pdf/2509.03472, 2025-09-03
2025-11-09 20:58:25,356 - INFO - root - Page:1, Index:19, Empowering Large Language Model for Sequential Recommendation via Multimodal Embeddings and Semantic IDs, https://arxiv.org/pdf/2509.02017, 2025-09-02
2025-11-09 20:58:25,357 - INFO - root - Page:1, Index:20, Q-Sched: Pushing the Boundaries of Few-Step Diffusion Models with Quantization-Aware Scheduling, https://arxiv.org/pdf/2509.01624, 2025-09-01
2025-11-09 20:58:25,357 - INFO - root - Page:1, Index:21, Quantization Meets OOD: Generalizable Quantization-aware Training from a Flatness Perspective, https://arxiv.org/pdf/2509.00859, 2025-08-31
2025-11-09 20:58:25,357 - INFO - root - Page:1, Index:22, Progressive Element-wise Gradient Estimation for Neural Network Quantization, https://arxiv.org/pdf/2509.00097, 2025-08-27
2025-11-09 20:58:25,359 - INFO - root - Page:1, Index:23, End-to-End On-Device Quantization-Aware Training for LLMs at Inference Cost, https://arxiv.org/pdf/2509.00031, 2025-09-29
2025-11-09 20:58:25,359 - INFO - root - Page:1, Index:24, Quantization Robustness to Input Degradations for Object Detection, https://arxiv.org/pdf/2508.19600, 2025-08-27
2025-11-09 20:58:25,359 - INFO - root - Page:1, Index:25, Scaling Laws for Task-Stratified Knowledge in Post-Training Quantized Large Language Models, https://arxiv.org/pdf/2508.18609, 2025-08-27
2025-11-09 20:58:25,360 - INFO - root - Page:1, Index:26, AQ-PCDSys: An Adaptive Quantized Planetary Crater Detection System for Autonomous Space Exploration, https://arxiv.org/pdf/2508.18025, 2025-08-25
2025-11-09 20:58:25,361 - INFO - root - Page:1, Index:27, TaDiCodec: Text-aware Diffusion Speech Tokenizer for Speech Language Modeling, https://arxiv.org/pdf/2508.16790, 2025-08-22
2025-11-09 20:58:25,362 - INFO - root - Page:1, Index:28, A Node-Aware Dynamic Quantization Approach for Graph Collaborative Filtering, https://arxiv.org/pdf/2508.16516, 2025-08-22
2025-11-09 20:58:25,365 - INFO - root - Page:1, Index:29, JEDI-linear: Fast and Efficient Graph Neural Networks for Jet Tagging on FPGAs, https://arxiv.org/pdf/2508.15468, 2025-08-21
2025-11-09 20:58:25,366 - INFO - root - Page:1, Index:30, MMQ: Multimodal Mixture-of-Quantization Tokenization for Semantic ID Generation and User Behavioral Adaptation, https://arxiv.org/pdf/2508.15281, 2025-08-21
2025-11-09 20:58:25,366 - INFO - root - Page:1, Index:31, DLLMQuant: Quantizing Diffusion-based Large Language Models, https://arxiv.org/pdf/2508.14090, 2025-08-25
2025-11-09 20:58:25,366 - INFO - root - Page:1, Index:32, Automated Energy-Aware Time-Series Model Deployment on Embedded FPGAs for Resilient Combined Sewer Overflow Management, https://arxiv.org/pdf/2508.13905, 2025-08-19
2025-11-09 20:58:25,368 - INFO - root - Page:1, Index:33, XR-NPE: High-Throughput Mixed-precision SIMD Neural Processing Engine for Extended Reality Perception Workloads, https://arxiv.org/pdf/2508.13049, 2025-08-18
2025-11-09 20:58:25,368 - INFO - root - Page:1, Index:34, Exploring Self-Supervised Audio Models for Generalized Anomalous Sound Detection, https://arxiv.org/pdf/2508.12230, 2025-08-17
2025-11-09 20:58:25,370 - INFO - root - Page:1, Index:35, TriQDef: Disrupting Semantic and Gradient Alignment to Prevent Adversarial Patch Transferability in Quantized Neural Networks, https://arxiv.org/pdf/2508.12132, 2025-08-16
2025-11-09 20:58:25,373 - INFO - root - Page:1, Index:36, Error Propagation Mechanisms and Compensation Strategies for Quantized Diffusion, https://arxiv.org/pdf/2508.12094, 2025-10-13
2025-11-09 20:58:25,375 - INFO - root - Page:1, Index:37, Extending Straight-Through Estimation for Robust Neural Networks on Analog CIM Hardware, https://arxiv.org/pdf/2508.11940, 2025-08-16
2025-11-09 20:58:25,375 - INFO - root - Page:1, Index:38, PTQAT: A Hybrid Parameter-Efficient Quantization Algorithm for 3D Perception Tasks, https://arxiv.org/pdf/2508.10557, 2025-08-15
2025-11-09 20:58:25,377 - INFO - root - Page:1, Index:39, MiCo: End-to-End Mixed Precision Neural Network Co-Exploration Framework for Edge AI, https://arxiv.org/pdf/2508.09500, 2025-08-13
2025-11-09 20:58:25,378 - INFO - root - Page:1, Index:40, SPARC: Soft Probabilistic Adaptive multi-interest Retrieval Model via Codebooks for recommender system, https://arxiv.org/pdf/2508.09090, 2025-08-12
2025-11-09 20:58:25,379 - INFO - root - Page:1, Index:41, Rethinking 1-bit Optimization Leveraging Pre-trained Large Language Models, https://arxiv.org/pdf/2508.06974, 2025-08-09
2025-11-09 20:58:25,380 - INFO - root - Page:1, Index:42, Efficient Deep Neural Receiver with Post-Training Quantization, https://arxiv.org/pdf/2508.06275, 2025-08-08
2025-11-09 20:58:25,381 - INFO - root - Page:1, Index:43, iFairy: the First 2-bit Complex LLM with All Parameters in $\{\pm1, \pm i\}$, https://arxiv.org/pdf/2508.05571, 2025-08-16
2025-11-09 20:58:25,381 - INFO - root - Page:1, Index:44, S$^2$Q-VDiT: Accurate Quantized Video Diffusion Transformer with Salient Data and Sparse Token Distillation, https://arxiv.org/pdf/2508.04016, 2025-10-27
2025-11-09 20:58:25,381 - INFO - root - Page:1, Index:45, LRQ-DiT: Log-Rotation Post-Training Quantization of Diffusion Transformers for Image and Video Generation, https://arxiv.org/pdf/2508.03485, 2025-09-23
2025-11-09 20:58:25,383 - INFO - root - Page:1, Index:46, VLMQ: Efficient Post-Training Quantization for Large Vision-Language Models via Hessian Augmentation, https://arxiv.org/pdf/2508.03351, 2025-08-05
2025-11-09 20:58:25,383 - INFO - root - Page:1, Index:47, TF-MLPNet: Tiny Real-Time Neural Speech Separation, https://arxiv.org/pdf/2508.03047, 2025-08-04
2025-11-09 20:58:25,384 - INFO - root - Page:1, Index:48, SaviorRec: Semantic-Behavior Alignment for Cold-Start Recommendation, https://arxiv.org/pdf/2508.01375, 2025-08-02
2025-11-09 20:58:25,384 - INFO - root - Page:1, Index:49, MixA-Q: Revisiting Activation Sparsity for Vision Transformers from a Mixed-Precision Quantization Perspective, https://arxiv.org/pdf/2507.19131, 2025-07-25
2025-11-09 20:58:25,384 - INFO - root - Fetching page 3 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=100
2025-11-09 20:58:32,730 - INFO - root - get_all_titles_from_web 
2025-11-09 20:58:32,730 - INFO - root - Page:2, Index:0, Enhancing Quantization-Aware Training on Edge Devices via Relative Entropy Coreset Selection and Cascaded Layer Correction, https://arxiv.org/pdf/2507.17768, 2025-07-16
2025-11-09 20:58:32,731 - INFO - root - Page:2, Index:1, SiLQ: Simple Large Language Model Quantization-Aware Training, https://arxiv.org/pdf/2507.16933, 2025-07-22
2025-11-09 20:58:32,731 - INFO - root - Page:2, Index:2, Task-Specific Zero-shot Quantization-Aware Training for Object Detection, https://arxiv.org/pdf/2507.16782, 2025-07-22
2025-11-09 20:58:32,731 - INFO - root - Page:2, Index:3, TorchAO: PyTorch-Native Training-to-Serving Model Optimization, https://arxiv.org/pdf/2507.16099, 2025-07-21
2025-11-09 20:58:32,731 - INFO - root - Page:2, Index:4, SegQuant: A Semantics-Aware and Generalizable Quantization Framework for Diffusion Models, https://arxiv.org/pdf/2507.14811, 2025-08-27
2025-11-09 20:58:32,732 - INFO - root - Page:2, Index:5, Apple Intelligence Foundation Language Models: Tech Report 2025, https://arxiv.org/pdf/2507.13575, 2025-08-27
2025-11-09 20:58:32,732 - INFO - root - Page:2, Index:6, Generative Multi-Target Cross-Domain Recommendation, https://arxiv.org/pdf/2507.12871, 2025-08-07
2025-11-09 20:58:32,732 - INFO - root - Page:2, Index:7, DAF: An Efficient End-to-End Dynamic Activation Framework for on-Device DNN Training, https://arxiv.org/pdf/2507.07149, 2025-07-09
2025-11-09 20:58:32,732 - INFO - root - Page:2, Index:8, Opto-ViT: Architecting a Near-Sensor Region of Interest-Aware Vision Transformer Accelerator with Silicon Photonics, https://arxiv.org/pdf/2507.07044, 2025-07-15
2025-11-09 20:58:32,733 - INFO - root - Page:2, Index:9, QS4D: Quantization-aware training for efficient hardware deployment of structured state-space sequential models, https://arxiv.org/pdf/2507.06079, 2025-07-08
2025-11-09 20:58:32,733 - INFO - root - Page:2, Index:10, GSVR: 2D Gaussian-based Video Representation for 800+ FPS with Hybrid Deformation Field, https://arxiv.org/pdf/2507.05594, 2025-07-07
2025-11-09 20:58:32,733 - INFO - root - Page:2, Index:11, Hita: Holistic Tokenizer for Autoregressive Image Generation, https://arxiv.org/pdf/2507.02358, 2025-07-11
2025-11-09 20:58:32,734 - INFO - root - Page:2, Index:12, QPART: Adaptive Model Quantization and Dynamic Workload Balancing for Accuracy-aware Edge Inference, https://arxiv.org/pdf/2506.23934, 2025-06-30
2025-11-09 20:58:32,734 - INFO - root - Page:2, Index:13, FedWSQ: Efficient Federated Learning with Weight Standardization and Distribution-Aware Non-Uniform Quantization, https://arxiv.org/pdf/2506.23516, 2025-07-21
2025-11-09 20:58:32,734 - INFO - root - Page:2, Index:14, Spectra 1.1: Scaling Laws and Efficient Inference for Ternary Language Models, https://arxiv.org/pdf/2506.23025, 2025-06-28
2025-11-09 20:58:32,734 - INFO - root - Page:2, Index:15, Joint Quantization and Pruning Neural Networks Approach: A Case Study on FSO Receivers, https://arxiv.org/pdf/2506.20084, 2025-06-24
2025-11-09 20:58:32,734 - INFO - root - Page:2, Index:16, Single-step Diffusion for Image Compression at Ultra-Low Bitrates, https://arxiv.org/pdf/2506.16572, 2025-09-22
2025-11-09 20:58:32,735 - INFO - root - Page:2, Index:17, LittleBit: Ultra Low-Bit Quantization via Latent Factorization, https://arxiv.org/pdf/2506.13771, 2025-10-28
2025-11-09 20:58:32,736 - INFO - root - Page:2, Index:18, MARCO: Hardware-Aware Neural Architecture Search for Edge Devices with Multi-Agent Reinforcement Learning and Conformal Prediction Filtering, https://arxiv.org/pdf/2506.13755, 2025-06-16
2025-11-09 20:58:32,736 - INFO - root - Page:2, Index:19, EAQuant: Enhancing Post-Training Quantization for MoE Models via Expert-Aware Optimization, https://arxiv.org/pdf/2506.13329, 2025-07-04
2025-11-09 20:58:32,737 - INFO - root - Page:2, Index:20, Towards Neural Audio Codec Source Parsing, https://arxiv.org/pdf/2506.12627, 2025-06-14
2025-11-09 20:58:32,746 - INFO - root - Page:2, Index:21, Quantizing Small-Scale State-Space Models for Edge AI, https://arxiv.org/pdf/2506.12480, 2025-06-14
2025-11-09 20:58:32,748 - INFO - root - Page:2, Index:22, EMLoC: Emulator-based Memory-efficient Fine-tuning with LoRA Correction, https://arxiv.org/pdf/2506.12015, 2025-06-13
2025-11-09 20:58:32,749 - INFO - root - Page:2, Index:23, Compression Aware Certified Training, https://arxiv.org/pdf/2506.11992, 2025-06-13
2025-11-09 20:58:32,750 - INFO - root - Page:2, Index:24, GPLQ: A General, Practical, and Lightning QAT Method for Vision Transformers, https://arxiv.org/pdf/2506.11784, 2025-06-13
2025-11-09 20:58:32,750 - INFO - root - Page:2, Index:25, TruncQuant: Truncation-Ready Quantization for DNNs with Flexible Weight Bit Precision, https://arxiv.org/pdf/2506.11431, 2025-06-12
2025-11-09 20:58:32,750 - INFO - root - Page:2, Index:26, EfficientQuant: An Efficient Post-Training Quantization for CNN-Transformer Hybrid Models on Edge Devices, https://arxiv.org/pdf/2506.11093, 2025-06-05
2025-11-09 20:58:32,751 - INFO - root - Page:2, Index:27, Starting Positions Matter: A Study on Better Weight Initialization for Neural Network Quantization, https://arxiv.org/pdf/2506.10463, 2025-06-12
2025-11-09 20:58:32,751 - INFO - root - Page:2, Index:28, AWP: Activation-Aware Weight Pruning and Quantization with Projected Gradient Descent, https://arxiv.org/pdf/2506.10205, 2025-06-11
2025-11-09 20:58:32,752 - INFO - root - Page:2, Index:29, Q-SAM2: Accurate Quantization for Segment Anything Model 2, https://arxiv.org/pdf/2506.09782, 2025-06-11
2025-11-09 20:58:32,752 - INFO - root - Page:2, Index:30, Unifying Block-wise PTQ and Distillation-based QAT for Progressive Quantization toward 2-bit Instruction-Tuned LLMs, https://arxiv.org/pdf/2506.09104, 2025-06-10
2025-11-09 20:58:32,752 - INFO - root - Page:2, Index:31, Implementing Keyword Spotting on the MCUX947 Microcontroller with Integrated NPU, https://arxiv.org/pdf/2506.08911, 2025-06-10
2025-11-09 20:58:32,755 - INFO - root - Page:2, Index:32, POLARON: Precision-aware On-device Learning and Adaptive Runtime-cONfigurable AI acceleration, https://arxiv.org/pdf/2506.08785, 2025-06-10
2025-11-09 20:58:32,758 - INFO - root - Page:2, Index:33, MoQAE: Mixed-Precision Quantization for Long-Context LLM Inference via Mixture of Quantization-Aware Experts, https://arxiv.org/pdf/2506.07533, 2025-06-09
2025-11-09 20:58:32,761 - INFO - root - Page:2, Index:34, BitVLA: 1-bit Vision-Language-Action Models for Robotics Manipulation, https://arxiv.org/pdf/2506.07530, 2025-06-09
2025-11-09 20:58:32,762 - INFO - root - Page:2, Index:35, RecGPT: A Foundation Model for Sequential Recommendation, https://arxiv.org/pdf/2506.06270, 2025-06-12
2025-11-09 20:58:32,762 - INFO - root - Page:2, Index:36, FPSAttention: Training-Aware FP8 and Sparsity Co-Design for Fast Video Diffusion, https://arxiv.org/pdf/2506.04648, 2025-06-05
2025-11-09 20:58:32,763 - INFO - root - Page:2, Index:37, BitTTS: Highly Compact Text-to-Speech Using 1.58-bit Quantization and Weight Indexing, https://arxiv.org/pdf/2506.03515, 2025-06-03
2025-11-09 20:58:32,763 - INFO - root - Page:2, Index:38, ShapeLLM-Omni: A Native Multimodal LLM for 3D Generation and Understanding, https://arxiv.org/pdf/2506.01853, 2025-06-02
2025-11-09 20:58:32,763 - INFO - root - Page:2, Index:39, Movable Antenna Enhanced Federated Fine-Tuning of Large Language Models via Hybrid Client Selection Optimization, https://arxiv.org/pdf/2506.00011, 2025-10-26
2025-11-09 20:58:32,763 - INFO - root - Page:2, Index:40, Running Conventional Automatic Speech Recognition on Memristor Hardware: A Simulated Approach, https://arxiv.org/pdf/2505.24721, 2025-05-30
2025-11-09 20:58:32,765 - INFO - root - Page:2, Index:41, GARLIC: GAussian Representation LearnIng for spaCe partitioning, https://arxiv.org/pdf/2505.24608, 2025-10-02
2025-11-09 20:58:32,765 - INFO - root - Page:2, Index:42, AutoChemSchematic AI: Agentic Physics-Aware Automation for Chemical Manufacturing Scale-Up, https://arxiv.org/pdf/2505.24584, 2025-08-18
2025-11-09 20:58:32,765 - INFO - root - Page:2, Index:43, Model-Preserving Adaptive Rounding, https://arxiv.org/pdf/2505.22988, 2025-09-25
2025-11-09 20:58:32,766 - INFO - root - Page:2, Index:44, Highly Efficient and Effective LLMs with Multi-Boolean Architectures, https://arxiv.org/pdf/2505.22811, 2025-10-03
2025-11-09 20:58:32,766 - INFO - root - Page:2, Index:45, Pioneering 4-Bit FP Quantization for Diffusion Models: Mixup-Sign Quantization and Timestep-Aware Fine-Tuning, https://arxiv.org/pdf/2505.21591, 2025-05-27
2025-11-09 20:58:32,768 - INFO - root - Page:2, Index:46, Frequency Composition for Compressed and Domain-Adaptive Neural Networks, https://arxiv.org/pdf/2505.20890, 2025-05-27
2025-11-09 20:58:32,768 - INFO - root - Page:2, Index:47, MoPFormer: Motion-Primitive Transformer for Wearable-Sensor Activity Recognition, https://arxiv.org/pdf/2505.20744, 2025-10-27
2025-11-09 20:58:32,770 - INFO - root - Page:2, Index:48, Optimizing edge AI models on HPC systems with the edge in the loop, https://arxiv.org/pdf/2505.19995, 2025-05-26
2025-11-09 20:58:32,789 - INFO - root - Fetching page 4 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=150
2025-11-09 20:58:39,412 - INFO - root - get_all_titles_from_web 
2025-11-09 20:58:39,412 - INFO - root - Page:3, Index:0, DPASyn: Mechanism-Aware Drug Synergy Prediction via Dual Attention and Precision-Aware Quantization, https://arxiv.org/pdf/2505.19144, 2025-09-20
2025-11-09 20:58:39,413 - INFO - root - Page:3, Index:1, Reducing Storage of Pretrained Neural Networks by Rate-Constrained Quantization and Entropy Coding, https://arxiv.org/pdf/2505.18758, 2025-05-24
2025-11-09 20:58:39,413 - INFO - root - Page:3, Index:2, Beyond Discreteness: Finite-Sample Analysis of Straight-Through Estimator for Quantization, https://arxiv.org/pdf/2505.18113, 2025-05-23
2025-11-09 20:58:39,413 - INFO - root - Page:3, Index:3, Automating Versatile Time-Series Analysis with Tiny Transformers on Embedded FPGAs, https://arxiv.org/pdf/2505.17662, 2025-09-19
2025-11-09 20:58:39,413 - INFO - root - Page:3, Index:4, FPQVAR: Floating Point Quantization for Visual Autoregressive Model with FPGA Hardware Co-design, https://arxiv.org/pdf/2505.16335, 2025-05-22
2025-11-09 20:58:39,414 - INFO - root - Page:3, Index:5, Saliency-Aware Quantized Imitation Learning for Efficient Robotic Control, https://arxiv.org/pdf/2505.15304, 2025-05-30
2025-11-09 20:58:39,414 - INFO - root - Page:3, Index:6, Scaling Law for Quantization-Aware Training, https://arxiv.org/pdf/2505.14302, 2025-05-20
2025-11-09 20:58:39,414 - INFO - root - Page:3, Index:7, Automatic mixed precision for optimizing gained time with constrained loss mean-squared-error based on model partition to sequential sub-graphs, https://arxiv.org/pdf/2505.13060, 2025-05-19
2025-11-09 20:58:39,415 - INFO - root - Page:3, Index:8, Deep Unfolding with Kernel-based Quantization in MIMO Detection, https://arxiv.org/pdf/2505.12736, 2025-05-19
2025-11-09 20:58:39,415 - INFO - root - Page:3, Index:9, FedHQ: Hybrid Runtime Quantization for Federated Learning, https://arxiv.org/pdf/2505.11982, 2025-05-17
2025-11-09 20:58:39,415 - INFO - root - Page:3, Index:10, QVGen: Pushing the Limit of Quantized Video Generative Models, https://arxiv.org/pdf/2505.11497, 2025-09-27
2025-11-09 20:58:39,415 - INFO - root - Page:3, Index:11, EA-3DGS: Efficient and Adaptive 3D Gaussians with Highly Enhanced Quality for outdoor scenes, https://arxiv.org/pdf/2505.10787, 2025-05-15
2025-11-09 20:58:39,416 - INFO - root - Page:3, Index:12, ITERA-LLM: Boosting Sub-8-Bit Large Language Model Inference via Iterative Tensor Decomposition, https://arxiv.org/pdf/2505.08981, 2025-05-13
2025-11-09 20:58:39,417 - INFO - root - Page:3, Index:13, PROM: Prioritize Reduction of Multiplications Over Lower Bit-Widths for Efficient CNNs, https://arxiv.org/pdf/2505.03254, 2025-08-06
2025-11-09 20:58:39,417 - INFO - root - Page:3, Index:14, ICQuant: Index Coding enables Low-bit LLM Quantization, https://arxiv.org/pdf/2505.00850, 2025-08-24
2025-11-09 20:58:39,417 - INFO - root - Page:3, Index:15, Enhancing Ultra-Low-Bit Quantization of Large Language Models Through Saliency-Aware Partial Retraining, https://arxiv.org/pdf/2504.13932, 2025-07-30
2025-11-09 20:58:39,418 - INFO - root - Page:3, Index:16, Achieving binary weight and activation for LLMs using Post-Training Quantization, https://arxiv.org/pdf/2504.05352, 2025-06-30
2025-11-09 20:58:39,418 - INFO - root - Page:3, Index:17, Wireless Hearables With Programmable Speech AI Accelerators, https://arxiv.org/pdf/2503.18698, 2025-10-21
2025-11-09 20:58:39,420 - INFO - root - Page:3, Index:18, GranQ: Efficient Channel-wise Quantization via Vectorized Pre-Scaling for Zero-Shot QAT, https://arxiv.org/pdf/2503.18339, 2025-10-15
2025-11-09 20:58:39,420 - INFO - root - Page:3, Index:19, CompMarkGS: Robust Watermarking for Compressed 3D Gaussian Splatting, https://arxiv.org/pdf/2503.12836, 2025-09-29
2025-11-09 20:58:39,421 - INFO - root - Page:3, Index:20, AHCPTQ: Accurate and Hardware-Compatible Post-Training Quantization for Segment Anything Model, https://arxiv.org/pdf/2503.03088, 2025-07-11
2025-11-09 20:58:39,421 - INFO - root - Page:3, Index:21, Teaching Metric Distance to Discrete Autoregressive Language Models, https://arxiv.org/pdf/2503.02379, 2025-10-07
2025-11-09 20:58:39,421 - INFO - root - Page:3, Index:22, Regularization-based Framework for Quantization-, Fault- and Variability-Aware Training, https://arxiv.org/pdf/2503.01297, 2025-07-12
2025-11-09 20:58:39,422 - INFO - root - Fetching page 5 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=200
2025-11-09 20:58:46,111 - INFO - root - get_all_titles_from_web 
2025-11-09 20:58:46,111 - INFO - root - Page:4, Index:0, Investigating the Impact of Quantization Methods on the Safety and Reliability of Large Language Models, https://arxiv.org/pdf/2502.15799, 2025-06-29
2025-11-09 20:58:46,111 - INFO - root - Page:4, Index:1, Rotate, Clip, and Partition: Towards W2A4KV4 Quantization by Integrating Rotation and Learnable Non-uniform Quantizer, https://arxiv.org/pdf/2502.15779, 2025-09-01
2025-11-09 20:58:46,111 - INFO - root - Page:4, Index:2, RoSTE: An Efficient Quantization-Aware Supervised Fine-Tuning Approach for Large Language Models, https://arxiv.org/pdf/2502.09003, 2025-06-05
2025-11-09 20:58:46,111 - INFO - root - Page:4, Index:3, Spatial Degradation-Aware and Temporal Consistent Diffusion Model for Compressed Video Super-Resolution, https://arxiv.org/pdf/2502.07381, 2025-06-27
2025-11-09 20:58:46,112 - INFO - root - Page:4, Index:4, QuEST: Stable Training of LLMs with 1-Bit Weights and Activations, https://arxiv.org/pdf/2502.05003, 2025-06-10
2025-11-09 20:58:46,112 - INFO - root - Page:4, Index:5, HALO: Hadamard-Assisted Lower-Precision Optimization for LLMs, https://arxiv.org/pdf/2501.02625, 2025-11-05
2025-11-09 20:58:46,112 - INFO - root - Page:4, Index:6, TAR3D: Creating High-Quality 3D Assets via Next-Part Prediction, https://arxiv.org/pdf/2412.16919, 2025-08-08
2025-11-09 20:58:46,112 - INFO - root - Page:4, Index:7, Training Multi-Layer Binary Neural Networks With Local Binary Error Signals, https://arxiv.org/pdf/2412.00119, 2025-08-05
2025-11-09 20:58:46,113 - INFO - root - Page:4, Index:8, Scaling Large-scale GNN Training to Thousands of Processors on CPU-based Supercomputers, https://arxiv.org/pdf/2411.16025, 2025-05-26
2025-11-09 20:58:46,113 - INFO - root - Page:4, Index:9, HAFLQ: Heterogeneous Adaptive Federated LoRA Fine-tuned LLM with Quantization, https://arxiv.org/pdf/2411.06581, 2025-05-16
2025-11-09 20:58:46,113 - INFO - root - Fetching page 6 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=250
2025-11-09 20:58:51,485 - INFO - root - get_all_titles_from_web 
2025-11-09 20:58:51,486 - INFO - root - Page:5, Index:0, Gradient-Free Training of Quantized Neural Networks, https://arxiv.org/pdf/2410.09734, 2025-09-29
2025-11-09 20:58:51,486 - INFO - root - Page:5, Index:1, QT-DoG: Quantization-aware Training for Domain Generalization, https://arxiv.org/pdf/2410.06020, 2025-06-26
2025-11-09 20:58:51,486 - INFO - root - Page:5, Index:2, Constraint Guided Model Quantization of Neural Networks, https://arxiv.org/pdf/2409.20138, 2025-09-12
2025-11-09 20:58:51,486 - INFO - root - Page:5, Index:3, Accumulator-Aware Post-Training Quantization for Large Language Models, https://arxiv.org/pdf/2409.17092, 2025-07-30
2025-11-09 20:58:51,487 - INFO - root - Page:5, Index:4, DilateQuant: Accurate and Efficient Diffusion Quantization via Weight Dilation, https://arxiv.org/pdf/2409.14307, 2025-07-09
2025-11-09 20:58:51,487 - INFO - root - Page:5, Index:5, Robust Training of Neural Networks at Arbitrary Precision and Sparsity, https://arxiv.org/pdf/2409.09245, 2025-09-23
2025-11-09 20:58:51,487 - INFO - root - Page:5, Index:6, VQ-CTAP: Cross-Modal Fine-Grained Sequence Representation Learning for Speech Processing, https://arxiv.org/pdf/2408.05758, 2025-05-27
2025-11-09 20:58:51,487 - INFO - root - Page:5, Index:7, DopQ-ViT: Towards Distribution-Friendly and Outlier-Aware Post-Training Quantization for Vision Transformers, https://arxiv.org/pdf/2408.03291, 2025-06-19
2025-11-09 20:58:51,488 - INFO - root - Page:5, Index:8, Temporal Feature Matters: A Framework for Diffusion Model Quantization, https://arxiv.org/pdf/2407.19547, 2025-07-11
2025-11-09 20:58:51,488 - INFO - root - Page:5, Index:9, EfficientQAT: Efficient Quantization-Aware Training for Large Language Models, https://arxiv.org/pdf/2407.11062, 2025-05-19
2025-11-09 20:58:51,488 - INFO - root - Page:5, Index:10, Integer-only Quantized Transformers for Embedded FPGA-based Time-series Forecasting in AIoT, https://arxiv.org/pdf/2407.11041, 2025-10-31
2025-11-09 20:58:51,489 - INFO - root - Fetching page 7 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=300
2025-11-09 20:58:59,088 - INFO - root - get_all_titles_from_web 
2025-11-09 20:58:59,088 - INFO - root - Page:6, Index:0, BoA: Attention-aware Post-training Quantization without Backpropagation, https://arxiv.org/pdf/2406.13474, 2025-06-06
2025-11-09 20:58:59,089 - INFO - root - Page:6, Index:1, A Rescaling-Invariant Lipschitz Bound Based on Path-Metrics for Modern ReLU Network Parameterizations, https://arxiv.org/pdf/2405.15006, 2025-06-13
2025-11-09 20:58:59,089 - INFO - root - Page:6, Index:2, Scheduling Weight Transitions for Quantization-Aware Training, https://arxiv.org/pdf/2404.19248, 2025-10-01
2025-11-09 20:58:59,089 - INFO - root - Page:6, Index:3, GPTVQ: The Blessing of Dimensionality for LLM Quantization, https://arxiv.org/pdf/2402.15319, 2025-06-03
2025-11-09 20:58:59,090 - INFO - root - Fetching page 8 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=350
2025-11-09 20:59:05,602 - INFO - root - get_all_titles_from_web 
2025-11-09 20:59:05,602 - INFO - root - Page:7, Index:0, Squat: Quant Small Language Models on the Edge, https://arxiv.org/pdf/2402.10787, 2025-07-01
2025-11-09 20:59:05,603 - INFO - root - Page:7, Index:1, L4Q: Parameter Efficient Quantization-Aware Fine-Tuning on Large Language Models, https://arxiv.org/pdf/2402.04902, 2025-07-21
2025-11-09 20:59:05,603 - INFO - root - Fetching page 9 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=400
2025-11-09 20:59:12,042 - INFO - root - ------------------------------------------------------------------------------------------------------------------------
2025-11-09 21:05:14,531 - INFO - root - 正在总结论文 1/40: A Quantized VAE-MLP Botnet Detection Model: A Systematic Evaluation of Quantization-Aware Training and Post-Training Quantization Strategies
2025-11-09 21:05:56,734 - INFO - root - LLMClient: rate limit reached, sleeping 17.8s
2025-11-09 21:06:34,404 - INFO - root - 正在提取论文图片...
2025-11-09 21:06:34,576 - INFO - root - 已保存图片 1/10：./export\images_A Quantized VAE-MLP Botnet Detection Model_ A Systematic Evaluation of Quantizat\figure_1_page4.png
2025-11-09 21:06:34,640 - INFO - root - 已保存图片 2/10：./export\images_A Quantized VAE-MLP Botnet Detection Model_ A Systematic Evaluation of Quantizat\figure_2_page4.png
2025-11-09 21:06:34,701 - INFO - root - 已保存图片 3/10：./export\images_A Quantized VAE-MLP Botnet Detection Model_ A Systematic Evaluation of Quantizat\figure_3_page4.png
2025-11-09 21:06:34,831 - INFO - root - 已保存图片 4/10：./export\images_A Quantized VAE-MLP Botnet Detection Model_ A Systematic Evaluation of Quantizat\figure_4_page5.png
2025-11-09 21:06:34,908 - INFO - root - 已保存图片 5/10：./export\images_A Quantized VAE-MLP Botnet Detection Model_ A Systematic Evaluation of Quantizat\figure_5_page3.png
2025-11-09 21:06:34,998 - INFO - root - 已保存图片 6/10：./export\images_A Quantized VAE-MLP Botnet Detection Model_ A Systematic Evaluation of Quantizat\figure_6_page4.png
2025-11-09 21:06:35,000 - INFO - root - 成功添加图片 1：./export\images_A Quantized VAE-MLP Botnet Detection Model_ A Systematic Evaluation of Quantizat\figure_1_page4.png
2025-11-09 21:06:35,001 - INFO - root - 成功添加图片 2：./export\images_A Quantized VAE-MLP Botnet Detection Model_ A Systematic Evaluation of Quantizat\figure_2_page4.png
2025-11-09 21:06:35,001 - INFO - root - 成功添加图片 3：./export\images_A Quantized VAE-MLP Botnet Detection Model_ A Systematic Evaluation of Quantizat\figure_3_page4.png
2025-11-09 21:06:35,002 - INFO - root - 成功添加图片 4：./export\images_A Quantized VAE-MLP Botnet Detection Model_ A Systematic Evaluation of Quantizat\figure_4_page5.png
2025-11-09 21:06:35,002 - INFO - root - 成功添加图片 5：./export\images_A Quantized VAE-MLP Botnet Detection Model_ A Systematic Evaluation of Quantizat\figure_5_page3.png
2025-11-09 21:06:35,003 - INFO - root - 成功添加图片 6：./export\images_A Quantized VAE-MLP Botnet Detection Model_ A Systematic Evaluation of Quantizat\figure_6_page4.png
2025-11-09 21:06:35,013 - INFO - root - 论文《A Quantized VAE-MLP Botnet Detection Model: A Systematic Evaluation of Quantization-Aware Training and Post-Training Quantization Strategies》的分析已保存到 ./export\A Quantized VAE-MLP Botnet Detection Model_ A Systematic Evaluation of Quantizat.md
2025-11-09 21:06:35,034 - INFO - root - 正在总结论文 2/40: FP8-Flow-MoE: A Casting-Free FP8 Recipe without Double Quantization Error
2025-11-09 21:06:46,076 - INFO - root - LLMClient: rate limit reached, sleeping 28.5s
2025-11-09 21:08:01,934 - INFO - root - 正在提取论文图片...
2025-11-09 21:08:05,846 - INFO - root - 已保存图片 1/10：./export\images_FP8-Flow-MoE_ A Casting-Free FP8 Recipe without Double Quantization Error\figure_1_page6.png
2025-11-09 21:08:06,250 - INFO - root - 已保存图片 2/10：./export\images_FP8-Flow-MoE_ A Casting-Free FP8 Recipe without Double Quantization Error\figure_2_page6.png
2025-11-09 21:08:06,570 - INFO - root - 已保存图片 3/10：./export\images_FP8-Flow-MoE_ A Casting-Free FP8 Recipe without Double Quantization Error\figure_3_page6.png
2025-11-09 21:08:06,923 - INFO - root - 已保存图片 4/10：./export\images_FP8-Flow-MoE_ A Casting-Free FP8 Recipe without Double Quantization Error\figure_4_page6.png
2025-11-09 21:08:06,981 - INFO - root - 成功添加图片 1：./export\images_FP8-Flow-MoE_ A Casting-Free FP8 Recipe without Double Quantization Error\figure_1_page6.png
2025-11-09 21:08:06,982 - INFO - root - 成功添加图片 2：./export\images_FP8-Flow-MoE_ A Casting-Free FP8 Recipe without Double Quantization Error\figure_2_page6.png
2025-11-09 21:08:06,982 - INFO - root - 成功添加图片 3：./export\images_FP8-Flow-MoE_ A Casting-Free FP8 Recipe without Double Quantization Error\figure_3_page6.png
2025-11-09 21:08:06,982 - INFO - root - 成功添加图片 4：./export\images_FP8-Flow-MoE_ A Casting-Free FP8 Recipe without Double Quantization Error\figure_4_page6.png
2025-11-09 21:08:06,993 - INFO - root - 论文《FP8-Flow-MoE: A Casting-Free FP8 Recipe without Double Quantization Error》的分析已保存到 ./export\FP8-Flow-MoE_ A Casting-Free FP8 Recipe without Double Quantization Error.md
2025-11-09 21:08:07,043 - INFO - root - 正在总结论文 3/40: Outlier-Aware Post-Training Quantization for Image Super-Resolution
2025-11-09 21:08:07,051 - INFO - root - LLMClient: rate limit reached, sleeping 7.5s
2025-11-09 21:08:25,249 - INFO - root - LLMClient: rate limit reached, sleeping 16.9s
2025-11-09 21:09:12,054 - INFO - root - LLMClient: rate limit reached, sleeping 2.5s
2025-11-09 21:09:31,067 - INFO - root - 正在提取论文图片...
2025-11-09 21:09:31,978 - INFO - root - 已保存图片 1/10：./export\images_Outlier-Aware Post-Training Quantization for Image Super-Resolution\figure_1_page7.jpeg
2025-11-09 21:09:32,111 - INFO - root - 已保存图片 2/10：./export\images_Outlier-Aware Post-Training Quantization for Image Super-Resolution\figure_2_page4.png
2025-11-09 21:09:32,115 - INFO - root - 成功添加图片 1：./export\images_Outlier-Aware Post-Training Quantization for Image Super-Resolution\figure_1_page7.jpeg
2025-11-09 21:09:32,117 - INFO - root - 成功添加图片 2：./export\images_Outlier-Aware Post-Training Quantization for Image Super-Resolution\figure_2_page4.png
2025-11-09 21:09:32,121 - INFO - root - 论文《Outlier-Aware Post-Training Quantization for Image Super-Resolution》的分析已保存到 ./export\Outlier-Aware Post-Training Quantization for Image Super-Resolution.md
2025-11-09 21:09:32,134 - INFO - root - 正在总结论文 4/40: Evaluation of Wafer-Scale SOT-MRAM for Analog Crossbar Array Applications
2025-11-09 21:09:32,138 - INFO - root - LLMClient: rate limit reached, sleeping 10.0s
2025-11-09 21:09:54,523 - INFO - root - LLMClient: rate limit reached, sleeping 20.0s
2025-11-09 21:11:08,565 - INFO - root - 正在提取论文图片...
2025-11-09 21:11:09,565 - INFO - root - 已保存图片 1/10：./export\images_Evaluation of Wafer-Scale SOT-MRAM for Analog Crossbar Array Applications\figure_1_page4.png
2025-11-09 21:11:09,674 - INFO - root - 已保存图片 2/10：./export\images_Evaluation of Wafer-Scale SOT-MRAM for Analog Crossbar Array Applications\figure_2_page6.png
2025-11-09 21:11:09,754 - INFO - root - 已保存图片 3/10：./export\images_Evaluation of Wafer-Scale SOT-MRAM for Analog Crossbar Array Applications\figure_3_page6.png
2025-11-09 21:11:09,820 - INFO - root - 已保存图片 4/10：./export\images_Evaluation of Wafer-Scale SOT-MRAM for Analog Crossbar Array Applications\figure_4_page6.png
2025-11-09 21:11:09,885 - INFO - root - 已保存图片 5/10：./export\images_Evaluation of Wafer-Scale SOT-MRAM for Analog Crossbar Array Applications\figure_5_page6.png
2025-11-09 21:11:09,964 - INFO - root - 已保存图片 6/10：./export\images_Evaluation of Wafer-Scale SOT-MRAM for Analog Crossbar Array Applications\figure_6_page6.png
2025-11-09 21:11:10,013 - INFO - root - 已保存图片 7/10：./export\images_Evaluation of Wafer-Scale SOT-MRAM for Analog Crossbar Array Applications\figure_7_page6.png
2025-11-09 21:11:10,069 - INFO - root - 已保存图片 8/10：./export\images_Evaluation of Wafer-Scale SOT-MRAM for Analog Crossbar Array Applications\figure_8_page6.png
2025-11-09 21:11:10,125 - INFO - root - 已保存图片 9/10：./export\images_Evaluation of Wafer-Scale SOT-MRAM for Analog Crossbar Array Applications\figure_9_page6.png
2025-11-09 21:11:10,171 - INFO - root - 已保存图片 10/10：./export\images_Evaluation of Wafer-Scale SOT-MRAM for Analog Crossbar Array Applications\figure_10_page6.png
2025-11-09 21:11:10,176 - INFO - root - 成功添加图片 1：./export\images_Evaluation of Wafer-Scale SOT-MRAM for Analog Crossbar Array Applications\figure_1_page4.png
2025-11-09 21:11:10,176 - INFO - root - 成功添加图片 2：./export\images_Evaluation of Wafer-Scale SOT-MRAM for Analog Crossbar Array Applications\figure_2_page6.png
2025-11-09 21:11:10,177 - INFO - root - 成功添加图片 3：./export\images_Evaluation of Wafer-Scale SOT-MRAM for Analog Crossbar Array Applications\figure_3_page6.png
2025-11-09 21:11:10,177 - INFO - root - 成功添加图片 4：./export\images_Evaluation of Wafer-Scale SOT-MRAM for Analog Crossbar Array Applications\figure_4_page6.png
2025-11-09 21:11:10,177 - INFO - root - 成功添加图片 5：./export\images_Evaluation of Wafer-Scale SOT-MRAM for Analog Crossbar Array Applications\figure_5_page6.png
2025-11-09 21:11:10,177 - INFO - root - 成功添加图片 6：./export\images_Evaluation of Wafer-Scale SOT-MRAM for Analog Crossbar Array Applications\figure_6_page6.png
2025-11-09 21:11:10,179 - INFO - root - 成功添加图片 7：./export\images_Evaluation of Wafer-Scale SOT-MRAM for Analog Crossbar Array Applications\figure_7_page6.png
2025-11-09 21:11:10,179 - INFO - root - 成功添加图片 8：./export\images_Evaluation of Wafer-Scale SOT-MRAM for Analog Crossbar Array Applications\figure_8_page6.png
2025-11-09 21:11:10,179 - INFO - root - 成功添加图片 9：./export\images_Evaluation of Wafer-Scale SOT-MRAM for Analog Crossbar Array Applications\figure_9_page6.png
2025-11-09 21:11:10,180 - INFO - root - 成功添加图片 10：./export\images_Evaluation of Wafer-Scale SOT-MRAM for Analog Crossbar Array Applications\figure_10_page6.png
2025-11-09 21:11:10,185 - INFO - root - 论文《Evaluation of Wafer-Scale SOT-MRAM for Analog Crossbar Array Applications》的分析已保存到 ./export\Evaluation of Wafer-Scale SOT-MRAM for Analog Crossbar Array Applications.md
2025-11-09 21:11:10,194 - INFO - root - 正在总结论文 5/40: Improving the Straight-Through Estimator with Zeroth-Order Information
2025-11-09 21:11:10,194 - INFO - root - LLMClient: rate limit reached, sleeping 4.3s
2025-11-09 21:11:24,951 - INFO - root - LLMClient: rate limit reached, sleeping 18.8s
2025-11-09 21:12:07,988 - INFO - root - LLMClient: rate limit reached, sleeping 6.6s
2025-11-09 21:12:32,927 - INFO - root - 正在提取论文图片...
2025-11-09 21:12:34,064 - INFO - root - 已保存图片 1/10：./export\images_Improving the Straight-Through Estimator with Zeroth-Order Information\figure_1_page8.png
2025-11-09 21:12:34,128 - INFO - root - 已保存图片 2/10：./export\images_Improving the Straight-Through Estimator with Zeroth-Order Information\figure_2_page9.png
2025-11-09 21:12:34,177 - INFO - root - 已保存图片 3/10：./export\images_Improving the Straight-Through Estimator with Zeroth-Order Information\figure_3_page7.png
2025-11-09 21:12:34,264 - INFO - root - 已保存图片 4/10：./export\images_Improving the Straight-Through Estimator with Zeroth-Order Information\figure_4_page23.png
2025-11-09 21:12:34,379 - INFO - root - 已保存图片 5/10：./export\images_Improving the Straight-Through Estimator with Zeroth-Order Information\figure_5_page25.png
2025-11-09 21:12:34,447 - INFO - root - 已保存图片 6/10：./export\images_Improving the Straight-Through Estimator with Zeroth-Order Information\figure_6_page25.png
2025-11-09 21:12:34,524 - INFO - root - 已保存图片 7/10：./export\images_Improving the Straight-Through Estimator with Zeroth-Order Information\figure_7_page25.png
2025-11-09 21:12:34,598 - INFO - root - 已保存图片 8/10：./export\images_Improving the Straight-Through Estimator with Zeroth-Order Information\figure_8_page26.png
2025-11-09 21:12:34,672 - INFO - root - 已保存图片 9/10：./export\images_Improving the Straight-Through Estimator with Zeroth-Order Information\figure_9_page26.png
2025-11-09 21:12:34,720 - INFO - root - 已保存图片 10/10：./export\images_Improving the Straight-Through Estimator with Zeroth-Order Information\figure_10_page26.png
2025-11-09 21:12:34,723 - INFO - root - 成功添加图片 1：./export\images_Improving the Straight-Through Estimator with Zeroth-Order Information\figure_1_page8.png
2025-11-09 21:12:34,723 - INFO - root - 成功添加图片 2：./export\images_Improving the Straight-Through Estimator with Zeroth-Order Information\figure_2_page9.png
2025-11-09 21:12:34,724 - INFO - root - 成功添加图片 3：./export\images_Improving the Straight-Through Estimator with Zeroth-Order Information\figure_3_page7.png
2025-11-09 21:12:34,724 - INFO - root - 成功添加图片 4：./export\images_Improving the Straight-Through Estimator with Zeroth-Order Information\figure_4_page23.png
2025-11-09 21:12:34,725 - INFO - root - 成功添加图片 5：./export\images_Improving the Straight-Through Estimator with Zeroth-Order Information\figure_5_page25.png
2025-11-09 21:12:34,725 - INFO - root - 成功添加图片 6：./export\images_Improving the Straight-Through Estimator with Zeroth-Order Information\figure_6_page25.png
2025-11-09 21:12:34,726 - INFO - root - 成功添加图片 7：./export\images_Improving the Straight-Through Estimator with Zeroth-Order Information\figure_7_page25.png
2025-11-09 21:12:34,726 - INFO - root - 成功添加图片 8：./export\images_Improving the Straight-Through Estimator with Zeroth-Order Information\figure_8_page26.png
2025-11-09 21:12:34,726 - INFO - root - 成功添加图片 9：./export\images_Improving the Straight-Through Estimator with Zeroth-Order Information\figure_9_page26.png
2025-11-09 21:12:34,727 - INFO - root - 成功添加图片 10：./export\images_Improving the Straight-Through Estimator with Zeroth-Order Information\figure_10_page26.png
2025-11-09 21:12:34,729 - INFO - root - 论文《Improving the Straight-Through Estimator with Zeroth-Order Information》的分析已保存到 ./export\Improving the Straight-Through Estimator with Zeroth-Order Information.md
2025-11-09 21:12:34,734 - INFO - root - 正在总结论文 6/40: Real-Time Semantic Segmentation on FPGA for Autonomous Vehicles Using LMIINet with the CGRA4ML Framework
2025-11-09 21:12:34,736 - INFO - root - LLMClient: rate limit reached, sleeping 9.1s
2025-11-09 21:12:53,598 - INFO - root - LLMClient: rate limit reached, sleeping 20.9s
2025-11-09 21:13:39,268 - INFO - root - LLMClient: rate limit reached, sleeping 4.5s
2025-11-09 21:14:06,878 - INFO - root - 正在提取论文图片...
2025-11-09 21:14:10,482 - INFO - root - 已保存图片 1/10：./export\images_Real-Time Semantic Segmentation on FPGA for Autonomous Vehicles Using LMIINet wi\figure_1_page5.png
2025-11-09 21:14:10,841 - INFO - root - 已保存图片 2/10：./export\images_Real-Time Semantic Segmentation on FPGA for Autonomous Vehicles Using LMIINet wi\figure_2_page5.png
2025-11-09 21:14:10,967 - INFO - root - 已保存图片 3/10：./export\images_Real-Time Semantic Segmentation on FPGA for Autonomous Vehicles Using LMIINet wi\figure_3_page4.png
2025-11-09 21:14:11,122 - INFO - root - 已保存图片 4/10：./export\images_Real-Time Semantic Segmentation on FPGA for Autonomous Vehicles Using LMIINet wi\figure_4_page4.png
2025-11-09 21:14:11,237 - INFO - root - 已保存图片 5/10：./export\images_Real-Time Semantic Segmentation on FPGA for Autonomous Vehicles Using LMIINet wi\figure_5_page8.png
2025-11-09 21:14:11,529 - INFO - root - 已保存图片 6/10：./export\images_Real-Time Semantic Segmentation on FPGA for Autonomous Vehicles Using LMIINet wi\figure_6_page8.png
2025-11-09 21:14:11,866 - INFO - root - 已保存图片 7/10：./export\images_Real-Time Semantic Segmentation on FPGA for Autonomous Vehicles Using LMIINet wi\figure_7_page8.png
2025-11-09 21:14:11,924 - INFO - root - 已保存图片 8/10：./export\images_Real-Time Semantic Segmentation on FPGA for Autonomous Vehicles Using LMIINet wi\figure_8_page7.png
2025-11-09 21:14:12,003 - INFO - root - 已保存图片 9/10：./export\images_Real-Time Semantic Segmentation on FPGA for Autonomous Vehicles Using LMIINet wi\figure_9_page7.png
2025-11-09 21:14:12,162 - INFO - root - 已保存图片 10/10：./export\images_Real-Time Semantic Segmentation on FPGA for Autonomous Vehicles Using LMIINet wi\figure_10_page7.png
2025-11-09 21:14:12,199 - INFO - root - 成功添加图片 1：./export\images_Real-Time Semantic Segmentation on FPGA for Autonomous Vehicles Using LMIINet wi\figure_1_page5.png
2025-11-09 21:14:12,202 - INFO - root - 成功添加图片 2：./export\images_Real-Time Semantic Segmentation on FPGA for Autonomous Vehicles Using LMIINet wi\figure_2_page5.png
2025-11-09 21:14:12,204 - INFO - root - 成功添加图片 3：./export\images_Real-Time Semantic Segmentation on FPGA for Autonomous Vehicles Using LMIINet wi\figure_3_page4.png
2025-11-09 21:14:12,207 - INFO - root - 成功添加图片 4：./export\images_Real-Time Semantic Segmentation on FPGA for Autonomous Vehicles Using LMIINet wi\figure_4_page4.png
2025-11-09 21:14:12,209 - INFO - root - 成功添加图片 5：./export\images_Real-Time Semantic Segmentation on FPGA for Autonomous Vehicles Using LMIINet wi\figure_5_page8.png
2025-11-09 21:14:12,211 - INFO - root - 成功添加图片 6：./export\images_Real-Time Semantic Segmentation on FPGA for Autonomous Vehicles Using LMIINet wi\figure_6_page8.png
2025-11-09 21:14:12,212 - INFO - root - 成功添加图片 7：./export\images_Real-Time Semantic Segmentation on FPGA for Autonomous Vehicles Using LMIINet wi\figure_7_page8.png
2025-11-09 21:14:12,215 - INFO - root - 成功添加图片 8：./export\images_Real-Time Semantic Segmentation on FPGA for Autonomous Vehicles Using LMIINet wi\figure_8_page7.png
2025-11-09 21:14:12,218 - INFO - root - 成功添加图片 9：./export\images_Real-Time Semantic Segmentation on FPGA for Autonomous Vehicles Using LMIINet wi\figure_9_page7.png
2025-11-09 21:14:12,222 - INFO - root - 成功添加图片 10：./export\images_Real-Time Semantic Segmentation on FPGA for Autonomous Vehicles Using LMIINet wi\figure_10_page7.png
2025-11-09 21:14:12,239 - INFO - root - 论文《Real-Time Semantic Segmentation on FPGA for Autonomous Vehicles Using LMIINet with the CGRA4ML Framework》的分析已保存到 ./export\Real-Time Semantic Segmentation on FPGA for Autonomous Vehicles Using LMIINet wi.md
2025-11-09 21:14:12,259 - INFO - root - 正在总结论文 7/40: TernaryCLIP: Efficiently Compressing Vision-Language Models with Ternary Weights and Distilled Knowledge
2025-11-09 21:14:12,265 - INFO - root - LLMClient: rate limit reached, sleeping 2.3s
2025-11-09 21:14:24,786 - INFO - root - LLMClient: rate limit reached, sleeping 19.0s
2025-11-09 21:15:10,252 - INFO - root - LLMClient: rate limit reached, sleeping 4.3s
2025-11-09 21:15:34,652 - INFO - root - 正在提取论文图片...
2025-11-09 21:15:38,659 - INFO - root - 已保存图片 1/10：./export\images_TernaryCLIP_ Efficiently Compressing Vision-Language Models with Ternary Weights\figure_1_page1.png
2025-11-09 21:15:38,945 - INFO - root - 已保存图片 2/10：./export\images_TernaryCLIP_ Efficiently Compressing Vision-Language Models with Ternary Weights\figure_2_page22.png
2025-11-09 21:15:39,102 - INFO - root - 已保存图片 3/10：./export\images_TernaryCLIP_ Efficiently Compressing Vision-Language Models with Ternary Weights\figure_3_page9.png
2025-11-09 21:15:39,255 - INFO - root - 已保存图片 4/10：./export\images_TernaryCLIP_ Efficiently Compressing Vision-Language Models with Ternary Weights\figure_4_page9.png
2025-11-09 21:15:39,405 - INFO - root - 已保存图片 5/10：./export\images_TernaryCLIP_ Efficiently Compressing Vision-Language Models with Ternary Weights\figure_5_page11.png
2025-11-09 21:15:39,552 - INFO - root - 已保存图片 6/10：./export\images_TernaryCLIP_ Efficiently Compressing Vision-Language Models with Ternary Weights\figure_6_page11.png
2025-11-09 21:15:39,703 - INFO - root - 已保存图片 7/10：./export\images_TernaryCLIP_ Efficiently Compressing Vision-Language Models with Ternary Weights\figure_7_page26.png
2025-11-09 21:15:39,887 - INFO - root - 已保存图片 8/10：./export\images_TernaryCLIP_ Efficiently Compressing Vision-Language Models with Ternary Weights\figure_8_page28.png
2025-11-09 21:15:40,064 - INFO - root - 已保存图片 9/10：./export\images_TernaryCLIP_ Efficiently Compressing Vision-Language Models with Ternary Weights\figure_9_page27.png
2025-11-09 21:15:40,140 - INFO - root - 已保存图片 10/10：./export\images_TernaryCLIP_ Efficiently Compressing Vision-Language Models with Ternary Weights\figure_10_page21.png
2025-11-09 21:15:40,164 - INFO - root - 成功添加图片 1：./export\images_TernaryCLIP_ Efficiently Compressing Vision-Language Models with Ternary Weights\figure_1_page1.png
2025-11-09 21:15:40,165 - INFO - root - 成功添加图片 2：./export\images_TernaryCLIP_ Efficiently Compressing Vision-Language Models with Ternary Weights\figure_2_page22.png
2025-11-09 21:15:40,165 - INFO - root - 成功添加图片 3：./export\images_TernaryCLIP_ Efficiently Compressing Vision-Language Models with Ternary Weights\figure_3_page9.png
2025-11-09 21:15:40,165 - INFO - root - 成功添加图片 4：./export\images_TernaryCLIP_ Efficiently Compressing Vision-Language Models with Ternary Weights\figure_4_page9.png
2025-11-09 21:15:40,165 - INFO - root - 成功添加图片 5：./export\images_TernaryCLIP_ Efficiently Compressing Vision-Language Models with Ternary Weights\figure_5_page11.png
2025-11-09 21:15:40,166 - INFO - root - 成功添加图片 6：./export\images_TernaryCLIP_ Efficiently Compressing Vision-Language Models with Ternary Weights\figure_6_page11.png
2025-11-09 21:15:40,166 - INFO - root - 成功添加图片 7：./export\images_TernaryCLIP_ Efficiently Compressing Vision-Language Models with Ternary Weights\figure_7_page26.png
2025-11-09 21:15:40,166 - INFO - root - 成功添加图片 8：./export\images_TernaryCLIP_ Efficiently Compressing Vision-Language Models with Ternary Weights\figure_8_page28.png
2025-11-09 21:15:40,167 - INFO - root - 成功添加图片 9：./export\images_TernaryCLIP_ Efficiently Compressing Vision-Language Models with Ternary Weights\figure_9_page27.png
2025-11-09 21:15:40,167 - INFO - root - 成功添加图片 10：./export\images_TernaryCLIP_ Efficiently Compressing Vision-Language Models with Ternary Weights\figure_10_page21.png
2025-11-09 21:15:40,171 - INFO - root - 论文《TernaryCLIP: Efficiently Compressing Vision-Language Models with Ternary Weights and Distilled Knowledge》的分析已保存到 ./export\TernaryCLIP_ Efficiently Compressing Vision-Language Models with Ternary Weights.md
2025-11-09 21:15:40,174 - INFO - root - 正在总结论文 8/40: KARIPAP: Quantum-Inspired Tensor Network Compression of Large Language Models Using Infinite Projected Entangled Pair States and Tensor Renormalization Group
2025-11-09 21:15:40,174 - INFO - root - LLMClient: rate limit reached, sleeping 3.6s
2025-11-09 21:15:52,700 - INFO - root - LLMClient: rate limit reached, sleeping 21.9s
2025-11-09 21:16:39,943 - INFO - root - LLMClient: rate limit reached, sleeping 3.9s
2025-11-09 21:17:52,194 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-09 21:17:52,196 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-09 21:17:52,199 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-09 21:17:53,700 - INFO - root - LLMClientManager: 指定使用客户端: Gemini
2025-11-09 21:17:55,425 - INFO - root - GeminiClient: trying model models/gemini-2.5-flash
2025-11-09 21:17:57,334 - INFO - root - GeminiClient: initialized model gemini-2.5-flash
2025-11-09 21:17:57,334 - INFO - root - LLMClientManager: Gemini 客户端初始化成功
2025-11-09 21:17:57,334 - INFO - root - LLMClientManager: switched to Gemini client
2025-11-09 21:17:57,334 - INFO - root - 已手动切换到 LLM 客户端: Gemini
2025-11-09 21:17:57,334 - INFO - root - 使用 LLM 模型: gemini-2.5-flash
2025-11-09 21:17:57,336 - INFO - root - 可用客户端: ['Gemini']
2025-11-09 21:17:57,337 - INFO - root - === 运行配置 ===
2025-11-09 21:17:57,337 - INFO - root - 处理模式: arxiv在线搜索
2025-11-09 21:17:57,338 - INFO - root - 关键词: QAT
2025-11-09 21:17:57,338 - INFO - root - 查询: Quantization-Aware-Training
2025-11-09 21:17:57,339 - INFO - root - 排序: None
2025-11-09 21:17:57,354 - INFO - root - 最近天数: 180
2025-11-09 21:17:57,355 - INFO - root - 最大处理数量: 40
2025-11-09 21:17:57,356 - INFO - root - 保存图片: 是
2025-11-09 21:17:57,357 - INFO - root - 输出语言: 中文
2025-11-09 21:17:57,357 - INFO - root - 强制重新处理: 否
2025-11-09 21:17:57,358 - INFO - root - ====================
2025-11-09 21:17:57,358 - INFO - root - 使用 arXiv 搜索模式（通过 chat_arxiv 模块获取）
2025-11-09 21:17:57,358 - INFO - root - Fetching page 1 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50
2025-11-09 21:18:04,307 - INFO - root - get_all_titles_from_web 
2025-11-09 21:18:04,310 - INFO - root - Page:0, Index:0, A Quantized VAE-MLP Botnet Detection Model: A Systematic Evaluation of Quantization-Aware Training and Post-Training Quantization Strategies, https://arxiv.org/pdf/2511.03201, 2025-11-05
2025-11-09 21:18:04,311 - INFO - root - Page:0, Index:1, FP8-Flow-MoE: A Casting-Free FP8 Recipe without Double Quantization Error, https://arxiv.org/pdf/2511.02302, 2025-11-04
2025-11-09 21:18:04,312 - INFO - root - Page:0, Index:2, Outlier-Aware Post-Training Quantization for Image Super-Resolution, https://arxiv.org/pdf/2511.00682, 2025-11-01
2025-11-09 21:18:04,313 - INFO - root - Page:0, Index:3, Evaluation of Wafer-Scale SOT-MRAM for Analog Crossbar Array Applications, https://arxiv.org/pdf/2510.25853, 2025-11-03
2025-11-09 21:18:04,331 - INFO - root - Page:0, Index:4, Improving the Straight-Through Estimator with Zeroth-Order Information, https://arxiv.org/pdf/2510.23926, 2025-10-27
2025-11-09 21:18:04,339 - INFO - root - Page:0, Index:5, Real-Time Semantic Segmentation on FPGA for Autonomous Vehicles Using LMIINet with the CGRA4ML Framework, https://arxiv.org/pdf/2510.22243, 2025-10-25
2025-11-09 21:18:04,343 - INFO - root - Page:0, Index:6, TernaryCLIP: Efficiently Compressing Vision-Language Models with Ternary Weights and Distilled Knowledge, https://arxiv.org/pdf/2510.21879, 2025-10-23
2025-11-09 21:18:04,347 - INFO - root - Page:0, Index:7, KARIPAP: Quantum-Inspired Tensor Network Compression of Large Language Models Using Infinite Projected Entangled Pair States and Tensor Renormalization Group, https://arxiv.org/pdf/2510.21844, 2025-10-22
2025-11-09 21:18:04,349 - INFO - root - Page:0, Index:8, A Convergence Analysis of Adaptive Optimizers under Floating-point Quantization, https://arxiv.org/pdf/2510.21314, 2025-10-24
2025-11-09 21:18:04,351 - INFO - root - Page:0, Index:9, Adaptive Distribution-aware Quantization for Mixed-Precision Neural Networks, https://arxiv.org/pdf/2510.19760, 2025-10-22
2025-11-09 21:18:04,352 - INFO - root - Page:0, Index:10, CAGE: Curvature-Aware Gradient Estimation For Accurate Quantization-Aware Training, https://arxiv.org/pdf/2510.18784, 2025-10-21
2025-11-09 21:18:04,353 - INFO - root - Page:0, Index:11, Mixed-Precision Quantization for Language Models: Techniques and Prospects, https://arxiv.org/pdf/2510.16805, 2025-10-19
2025-11-09 21:18:04,373 - INFO - root - Page:0, Index:12, SPLite Hand: Sparsity-Aware Lightweight 3D Hand Pose Estimation, https://arxiv.org/pdf/2510.16396, 2025-10-30
2025-11-09 21:18:04,378 - INFO - root - Page:0, Index:13, CTR-LoRA: Curvature-Aware and Trust-Region Guided Low-Rank Adaptation for Large Language Models, https://arxiv.org/pdf/2510.15962, 2025-10-11
2025-11-09 21:18:04,380 - INFO - root - Page:0, Index:14, SANR: Scene-Aware Neural Representation for Light Field Image Compression with Rate-Distortion Optimization, https://arxiv.org/pdf/2510.15775, 2025-10-17
2025-11-09 21:18:04,380 - INFO - root - Page:0, Index:15, SpikeFit: Towards Optimal Deployment of Spiking Networks on Neuromorphic Hardware, https://arxiv.org/pdf/2510.15542, 2025-10-31
2025-11-09 21:18:04,380 - INFO - root - Page:0, Index:16, GRank: Towards Target-Aware and Streamlined Industrial Retrieval with a Generate-Rank Framework, https://arxiv.org/pdf/2510.15299, 2025-10-17
2025-11-09 21:18:04,381 - INFO - root - Page:0, Index:17, SaLon3R: Structure-aware Long-term Generalizable 3D Reconstruction from Unposed Images, https://arxiv.org/pdf/2510.15072, 2025-10-16
2025-11-09 21:18:04,381 - INFO - root - Page:0, Index:18, FraQAT: Quantization Aware Training with Fractional bits, https://arxiv.org/pdf/2510.14823, 2025-10-16
2025-11-09 21:18:04,382 - INFO - root - Page:0, Index:19, Computing-In-Memory Aware Model Adaption For Edge Devices, https://arxiv.org/pdf/2510.14379, 2025-10-16
2025-11-09 21:18:04,382 - INFO - root - Page:0, Index:20, Invited Paper: BitMedViT: Ternary-Quantized Vision Transformer for Medical AI Assistants on the Edge, https://arxiv.org/pdf/2510.13760, 2025-11-04
2025-11-09 21:18:04,383 - INFO - root - Page:0, Index:21, NeuroRVQ: Multi-Scale EEG Tokenization for Generative Large Brainwave Models, https://arxiv.org/pdf/2510.13068, 2025-10-14
2025-11-09 21:18:04,383 - INFO - root - Page:0, Index:22, Detect Anything via Next Point Prediction, https://arxiv.org/pdf/2510.12798, 2025-10-14
2025-11-09 21:18:04,393 - INFO - root - Page:0, Index:23, AndesVL Technical Report: An Efficient Mobile-side Multimodal Large Language Model, https://arxiv.org/pdf/2510.11496, 2025-10-14
2025-11-09 21:18:04,396 - INFO - root - Page:0, Index:24, Rescaling-Aware Training for Efficient Deployment of Deep Learning Models on Full-Integer Hardware, https://arxiv.org/pdf/2510.11484, 2025-10-13
2025-11-09 21:18:04,398 - INFO - root - Page:0, Index:25, SASER: Stego attacks on open-source LLMs, https://arxiv.org/pdf/2510.10486, 2025-10-12
2025-11-09 21:18:04,398 - INFO - root - Page:0, Index:26, Ultralytics YOLO Evolution: An Overview of YOLO26, YOLO11, YOLOv8 and YOLOv5 Object Detectors for Computer Vision and Pattern Recognition, https://arxiv.org/pdf/2510.09653, 2025-10-15
2025-11-09 21:18:04,398 - INFO - root - Page:0, Index:27, A Theoretically-Grounded Codebook for Digital Semantic Communications, https://arxiv.org/pdf/2510.07108, 2025-10-14
2025-11-09 21:18:04,398 - INFO - root - Page:0, Index:28, QuantDemoire: Quantization with Outlier Aware for Image Demoiréing, https://arxiv.org/pdf/2510.04066, 2025-10-05
2025-11-09 21:18:04,399 - INFO - root - Page:0, Index:29, Adaptively Sampling-Reusing-Mixing Decomposed Gradients to Speed Up Sharpness Aware Minimization, https://arxiv.org/pdf/2510.03763, 2025-10-04
2025-11-09 21:18:04,399 - INFO - root - Page:0, Index:30, Quant-dLLM: Post-Training Extreme Low-Bit Quantization for Diffusion Large Language Models, https://arxiv.org/pdf/2510.03274, 2025-09-27
2025-11-09 21:18:04,399 - INFO - root - Page:0, Index:31, PT$^2$-LLM: Post-Training Ternarization for Large Language Models, https://arxiv.org/pdf/2510.03267, 2025-09-26
2025-11-09 21:18:04,401 - INFO - root - Page:0, Index:32, Purrception: Variational Flow Matching for Vector-Quantized Image Generation, https://arxiv.org/pdf/2510.01478, 2025-10-01
2025-11-09 21:18:04,401 - INFO - root - Page:0, Index:33, Post-Training Quantization for Audio Diffusion Transformers, https://arxiv.org/pdf/2510.00313, 2025-09-30
2025-11-09 21:18:04,403 - INFO - root - Page:0, Index:34, Rethinking RoPE Scaling in Quantized LLM: Theory, Outlier, and Channel-Band Analysis with Weight Rescaling, https://arxiv.org/pdf/2510.00028, 2025-09-25
2025-11-09 21:18:04,414 - INFO - root - Page:0, Index:35, Post-Training Quantization via Residual Truncation and Zero Suppression for Diffusion Models, https://arxiv.org/pdf/2509.26436, 2025-09-30
2025-11-09 21:18:04,415 - INFO - root - Page:0, Index:36, Cat: Post-Training Quantization Error Reduction via Cluster-based Affine Transformation, https://arxiv.org/pdf/2509.26277, 2025-10-07
2025-11-09 21:18:04,415 - INFO - root - Page:0, Index:37, CAST: Continuous and Differentiable Semi-Structured Sparsity-Aware Training for Large Language Models, https://arxiv.org/pdf/2509.25996, 2025-09-30
2025-11-09 21:18:04,415 - INFO - root - Page:0, Index:38, Norm-Q: Effective Compression Method for Hidden Markov Models in Neuro-Symbolic Applications, https://arxiv.org/pdf/2509.25439, 2025-09-29
2025-11-09 21:18:04,416 - INFO - root - Page:0, Index:39, On-the-Fly Adaptation to Quantization: Configuration-Aware LoRA for Efficient Fine-Tuning of Quantized LLMs, https://arxiv.org/pdf/2509.25214, 2025-09-22
2025-11-09 21:18:04,416 - INFO - root - Page:0, Index:40, VoxCPM: Tokenizer-Free TTS for Context-Aware Speech Generation and True-to-Life Voice Cloning, https://arxiv.org/pdf/2509.24650, 2025-09-29
2025-11-09 21:18:04,416 - INFO - root - Page:0, Index:41, S$^2$NN: Sub-bit Spiking Neural Networks, https://arxiv.org/pdf/2509.24266, 2025-10-24
2025-11-09 21:18:04,418 - INFO - root - Page:0, Index:42, Tequila: Trapping-free Ternary Quantization for Large Language Models, https://arxiv.org/pdf/2509.23809, 2025-10-17
2025-11-09 21:18:04,418 - INFO - root - Page:0, Index:43, Texture Vector-Quantization and Reconstruction Aware Prediction for Generative Super-Resolution, https://arxiv.org/pdf/2509.23774, 2025-09-30
2025-11-09 21:18:04,420 - INFO - root - Page:0, Index:44, RobuQ: Pushing DiTs to W1.58A2 via Robust Activation Quantization, https://arxiv.org/pdf/2509.23582, 2025-09-27
2025-11-09 21:18:04,434 - INFO - root - Page:0, Index:45, Beyond Outliers: A Study of Optimizers Under Quantization, https://arxiv.org/pdf/2509.23500, 2025-10-02
2025-11-09 21:18:04,435 - INFO - root - Page:0, Index:46, Compute-Optimal Quantization-Aware Training, https://arxiv.org/pdf/2509.22935, 2025-09-26
2025-11-09 21:18:04,435 - INFO - root - Page:0, Index:47, COSPADI: Compressing LLMs via Calibration-Guided Sparse Dictionary Learning, https://arxiv.org/pdf/2509.22075, 2025-10-06
2025-11-09 21:18:04,436 - INFO - root - Page:0, Index:48, SlimDiff: Training-Free, Activation-Guided Hands-free Slimming of Diffusion Models, https://arxiv.org/pdf/2509.21498, 2025-09-25
2025-11-09 21:18:04,448 - INFO - root - Page:0, Index:49, Quantized Visual Geometry Grounded Transformer, https://arxiv.org/pdf/2509.21302, 2025-09-29
2025-11-09 21:18:04,449 - INFO - root - Fetching page 2 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=50
2025-11-09 21:18:11,158 - INFO - root - get_all_titles_from_web 
2025-11-09 21:18:11,159 - INFO - root - Page:1, Index:0, Can Less Precise Be More Reliable? A Systematic Evaluation of Quantization's Impact on CLIP Beyond Accuracy, https://arxiv.org/pdf/2509.21173, 2025-10-27
2025-11-09 21:18:11,159 - INFO - root - Page:1, Index:1, Punching Above Precision: Small Quantized Model Distillation with Learnable Regularizer, https://arxiv.org/pdf/2509.20854, 2025-09-25
2025-11-09 21:18:11,159 - INFO - root - Page:1, Index:2, TinyEcoWeedNet: Edge Efficient Real-Time Aerial Agricultural Weed Detection, https://arxiv.org/pdf/2509.18193, 2025-09-19
2025-11-09 21:18:11,161 - INFO - root - Page:1, Index:3, SBVR: Summation of BitVector Representation for Efficient LLM Quantization, https://arxiv.org/pdf/2509.18172, 2025-09-17
2025-11-09 21:18:11,162 - INFO - root - Page:1, Index:4, QWHA: Quantization-Aware Walsh-Hadamard Adaptation for Parameter-Efficient Fine-Tuning on Large Language Models, https://arxiv.org/pdf/2509.17428, 2025-09-26
2025-11-09 21:18:11,163 - INFO - root - Page:1, Index:5, PTQTP: Post-Training Quantization to Trit-Planes for Large Language Models, https://arxiv.org/pdf/2509.16989, 2025-10-28
2025-11-09 21:18:11,164 - INFO - root - Page:1, Index:6, MEC-Quant: Maximum Entropy Coding for Extremely Low Bit Quantization-Aware Training, https://arxiv.org/pdf/2509.15514, 2025-09-18
2025-11-09 21:18:11,164 - INFO - root - Page:1, Index:7, Q-ROAR: Outlier-Aware Rescaling for RoPE Position Interpolation in Quantized Long-Context LLMs, https://arxiv.org/pdf/2509.14391, 2025-09-17
2025-11-09 21:18:11,165 - INFO - root - Page:1, Index:8, Efficient Quantization-Aware Neural Receivers: Beyond Post-Training Quantization, https://arxiv.org/pdf/2509.13786, 2025-09-19
2025-11-09 21:18:11,166 - INFO - root - Page:1, Index:9, Rate-Distortion Limits for Multimodal Retrieval: Theory, Optimal Codes, and Finite-Sample Guarantees, https://arxiv.org/pdf/2509.11054, 2025-09-13
2025-11-09 21:18:11,166 - INFO - root - Page:1, Index:10, SQAP-VLA: A Synergistic Quantization-Aware Pruning Framework for High-Performance Vision-Language-Action Models, https://arxiv.org/pdf/2509.09090, 2025-09-10
2025-11-09 21:18:11,167 - INFO - root - Page:1, Index:11, CSI Compression Beyond Latents: End-to-End Hybrid Attention-CNN Networks with Entropy Regularization, https://arxiv.org/pdf/2509.08776, 2025-09-10
2025-11-09 21:18:11,167 - INFO - root - Page:1, Index:12, Explaining How Quantization Disparately Skews a Model, https://arxiv.org/pdf/2509.07222, 2025-09-08
2025-11-09 21:18:11,168 - INFO - root - Page:1, Index:13, LoaQ: Layer-wise Output Approximation Quantization, https://arxiv.org/pdf/2509.06297, 2025-09-07
2025-11-09 21:18:11,168 - INFO - root - Page:1, Index:14, FineServe: Precision-Aware KV Slab and Two-Level Scheduling for Heterogeneous Precision LLM Serving, https://arxiv.org/pdf/2509.06261, 2025-09-14
2025-11-09 21:18:11,168 - INFO - root - Page:1, Index:15, Sensitivity-Aware Post-Training Quantization for Deep Neural Networks, https://arxiv.org/pdf/2509.05576, 2025-09-05
2025-11-09 21:18:11,170 - INFO - root - Page:1, Index:16, SuperSNN: A Hardware-Aware Framework for Physically Realizable, High-Performance Superconducting Spiking Neural Network Chips, https://arxiv.org/pdf/2509.05532, 2025-09-05
2025-11-09 21:18:11,173 - INFO - root - Page:1, Index:17, Data-Augmented Quantization-Aware Knowledge Distillation, https://arxiv.org/pdf/2509.03850, 2025-09-03
2025-11-09 21:18:11,173 - INFO - root - Page:1, Index:18, DPQuant: Efficient and Differentially-Private Model Training via Dynamic Quantization Scheduling, https://arxiv.org/pdf/2509.03472, 2025-09-03
2025-11-09 21:18:11,174 - INFO - root - Page:1, Index:19, Empowering Large Language Model for Sequential Recommendation via Multimodal Embeddings and Semantic IDs, https://arxiv.org/pdf/2509.02017, 2025-09-02
2025-11-09 21:18:11,174 - INFO - root - Page:1, Index:20, Q-Sched: Pushing the Boundaries of Few-Step Diffusion Models with Quantization-Aware Scheduling, https://arxiv.org/pdf/2509.01624, 2025-09-01
2025-11-09 21:18:11,174 - INFO - root - Page:1, Index:21, Quantization Meets OOD: Generalizable Quantization-aware Training from a Flatness Perspective, https://arxiv.org/pdf/2509.00859, 2025-08-31
2025-11-09 21:18:11,174 - INFO - root - Page:1, Index:22, Progressive Element-wise Gradient Estimation for Neural Network Quantization, https://arxiv.org/pdf/2509.00097, 2025-08-27
2025-11-09 21:18:11,175 - INFO - root - Page:1, Index:23, End-to-End On-Device Quantization-Aware Training for LLMs at Inference Cost, https://arxiv.org/pdf/2509.00031, 2025-09-29
2025-11-09 21:18:11,175 - INFO - root - Page:1, Index:24, Quantization Robustness to Input Degradations for Object Detection, https://arxiv.org/pdf/2508.19600, 2025-08-27
2025-11-09 21:18:11,175 - INFO - root - Page:1, Index:25, Scaling Laws for Task-Stratified Knowledge in Post-Training Quantized Large Language Models, https://arxiv.org/pdf/2508.18609, 2025-08-27
2025-11-09 21:18:11,176 - INFO - root - Page:1, Index:26, AQ-PCDSys: An Adaptive Quantized Planetary Crater Detection System for Autonomous Space Exploration, https://arxiv.org/pdf/2508.18025, 2025-08-25
2025-11-09 21:18:11,180 - INFO - root - Page:1, Index:27, TaDiCodec: Text-aware Diffusion Speech Tokenizer for Speech Language Modeling, https://arxiv.org/pdf/2508.16790, 2025-08-22
2025-11-09 21:18:11,180 - INFO - root - Page:1, Index:28, A Node-Aware Dynamic Quantization Approach for Graph Collaborative Filtering, https://arxiv.org/pdf/2508.16516, 2025-08-22
2025-11-09 21:18:11,180 - INFO - root - Page:1, Index:29, JEDI-linear: Fast and Efficient Graph Neural Networks for Jet Tagging on FPGAs, https://arxiv.org/pdf/2508.15468, 2025-08-21
2025-11-09 21:18:11,183 - INFO - root - Page:1, Index:30, MMQ: Multimodal Mixture-of-Quantization Tokenization for Semantic ID Generation and User Behavioral Adaptation, https://arxiv.org/pdf/2508.15281, 2025-08-21
2025-11-09 21:18:11,183 - INFO - root - Page:1, Index:31, DLLMQuant: Quantizing Diffusion-based Large Language Models, https://arxiv.org/pdf/2508.14090, 2025-08-25
2025-11-09 21:18:11,184 - INFO - root - Page:1, Index:32, Automated Energy-Aware Time-Series Model Deployment on Embedded FPGAs for Resilient Combined Sewer Overflow Management, https://arxiv.org/pdf/2508.13905, 2025-08-19
2025-11-09 21:18:11,184 - INFO - root - Page:1, Index:33, XR-NPE: High-Throughput Mixed-precision SIMD Neural Processing Engine for Extended Reality Perception Workloads, https://arxiv.org/pdf/2508.13049, 2025-08-18
2025-11-09 21:18:11,184 - INFO - root - Page:1, Index:34, Exploring Self-Supervised Audio Models for Generalized Anomalous Sound Detection, https://arxiv.org/pdf/2508.12230, 2025-08-17
2025-11-09 21:18:11,185 - INFO - root - Page:1, Index:35, TriQDef: Disrupting Semantic and Gradient Alignment to Prevent Adversarial Patch Transferability in Quantized Neural Networks, https://arxiv.org/pdf/2508.12132, 2025-08-16
2025-11-09 21:18:11,185 - INFO - root - Page:1, Index:36, Error Propagation Mechanisms and Compensation Strategies for Quantized Diffusion, https://arxiv.org/pdf/2508.12094, 2025-10-13
2025-11-09 21:18:11,186 - INFO - root - Page:1, Index:37, Extending Straight-Through Estimation for Robust Neural Networks on Analog CIM Hardware, https://arxiv.org/pdf/2508.11940, 2025-08-16
2025-11-09 21:18:11,186 - INFO - root - Page:1, Index:38, PTQAT: A Hybrid Parameter-Efficient Quantization Algorithm for 3D Perception Tasks, https://arxiv.org/pdf/2508.10557, 2025-08-15
2025-11-09 21:18:11,187 - INFO - root - Page:1, Index:39, MiCo: End-to-End Mixed Precision Neural Network Co-Exploration Framework for Edge AI, https://arxiv.org/pdf/2508.09500, 2025-08-13
2025-11-09 21:18:11,187 - INFO - root - Page:1, Index:40, SPARC: Soft Probabilistic Adaptive multi-interest Retrieval Model via Codebooks for recommender system, https://arxiv.org/pdf/2508.09090, 2025-08-12
2025-11-09 21:18:11,187 - INFO - root - Page:1, Index:41, Rethinking 1-bit Optimization Leveraging Pre-trained Large Language Models, https://arxiv.org/pdf/2508.06974, 2025-08-09
2025-11-09 21:18:11,188 - INFO - root - Page:1, Index:42, Efficient Deep Neural Receiver with Post-Training Quantization, https://arxiv.org/pdf/2508.06275, 2025-08-08
2025-11-09 21:18:11,188 - INFO - root - Page:1, Index:43, iFairy: the First 2-bit Complex LLM with All Parameters in $\{\pm1, \pm i\}$, https://arxiv.org/pdf/2508.05571, 2025-08-16
2025-11-09 21:18:11,188 - INFO - root - Page:1, Index:44, S$^2$Q-VDiT: Accurate Quantized Video Diffusion Transformer with Salient Data and Sparse Token Distillation, https://arxiv.org/pdf/2508.04016, 2025-10-27
2025-11-09 21:18:11,189 - INFO - root - Page:1, Index:45, LRQ-DiT: Log-Rotation Post-Training Quantization of Diffusion Transformers for Image and Video Generation, https://arxiv.org/pdf/2508.03485, 2025-09-23
2025-11-09 21:18:11,189 - INFO - root - Page:1, Index:46, VLMQ: Efficient Post-Training Quantization for Large Vision-Language Models via Hessian Augmentation, https://arxiv.org/pdf/2508.03351, 2025-08-05
2025-11-09 21:18:11,189 - INFO - root - Page:1, Index:47, TF-MLPNet: Tiny Real-Time Neural Speech Separation, https://arxiv.org/pdf/2508.03047, 2025-08-04
2025-11-09 21:18:11,191 - INFO - root - Page:1, Index:48, SaviorRec: Semantic-Behavior Alignment for Cold-Start Recommendation, https://arxiv.org/pdf/2508.01375, 2025-08-02
2025-11-09 21:18:11,191 - INFO - root - Page:1, Index:49, MixA-Q: Revisiting Activation Sparsity for Vision Transformers from a Mixed-Precision Quantization Perspective, https://arxiv.org/pdf/2507.19131, 2025-07-25
2025-11-09 21:18:11,192 - INFO - root - Fetching page 3 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=100
2025-11-09 21:18:18,230 - INFO - root - get_all_titles_from_web 
2025-11-09 21:18:18,238 - INFO - root - Page:2, Index:0, Enhancing Quantization-Aware Training on Edge Devices via Relative Entropy Coreset Selection and Cascaded Layer Correction, https://arxiv.org/pdf/2507.17768, 2025-07-16
2025-11-09 21:18:18,239 - INFO - root - Page:2, Index:1, SiLQ: Simple Large Language Model Quantization-Aware Training, https://arxiv.org/pdf/2507.16933, 2025-07-22
2025-11-09 21:18:18,240 - INFO - root - Page:2, Index:2, Task-Specific Zero-shot Quantization-Aware Training for Object Detection, https://arxiv.org/pdf/2507.16782, 2025-07-22
2025-11-09 21:18:18,244 - INFO - root - Page:2, Index:3, TorchAO: PyTorch-Native Training-to-Serving Model Optimization, https://arxiv.org/pdf/2507.16099, 2025-07-21
2025-11-09 21:18:18,245 - INFO - root - Page:2, Index:4, SegQuant: A Semantics-Aware and Generalizable Quantization Framework for Diffusion Models, https://arxiv.org/pdf/2507.14811, 2025-08-27
2025-11-09 21:18:18,245 - INFO - root - Page:2, Index:5, Apple Intelligence Foundation Language Models: Tech Report 2025, https://arxiv.org/pdf/2507.13575, 2025-08-27
2025-11-09 21:18:18,245 - INFO - root - Page:2, Index:6, Generative Multi-Target Cross-Domain Recommendation, https://arxiv.org/pdf/2507.12871, 2025-08-07
2025-11-09 21:18:18,246 - INFO - root - Page:2, Index:7, DAF: An Efficient End-to-End Dynamic Activation Framework for on-Device DNN Training, https://arxiv.org/pdf/2507.07149, 2025-07-09
2025-11-09 21:18:18,247 - INFO - root - Page:2, Index:8, Opto-ViT: Architecting a Near-Sensor Region of Interest-Aware Vision Transformer Accelerator with Silicon Photonics, https://arxiv.org/pdf/2507.07044, 2025-07-15
2025-11-09 21:18:18,249 - INFO - root - Page:2, Index:9, QS4D: Quantization-aware training for efficient hardware deployment of structured state-space sequential models, https://arxiv.org/pdf/2507.06079, 2025-07-08
2025-11-09 21:18:18,249 - INFO - root - Page:2, Index:10, GSVR: 2D Gaussian-based Video Representation for 800+ FPS with Hybrid Deformation Field, https://arxiv.org/pdf/2507.05594, 2025-07-07
2025-11-09 21:18:18,250 - INFO - root - Page:2, Index:11, Hita: Holistic Tokenizer for Autoregressive Image Generation, https://arxiv.org/pdf/2507.02358, 2025-07-11
2025-11-09 21:18:18,250 - INFO - root - Page:2, Index:12, QPART: Adaptive Model Quantization and Dynamic Workload Balancing for Accuracy-aware Edge Inference, https://arxiv.org/pdf/2506.23934, 2025-06-30
2025-11-09 21:18:18,257 - INFO - root - Page:2, Index:13, FedWSQ: Efficient Federated Learning with Weight Standardization and Distribution-Aware Non-Uniform Quantization, https://arxiv.org/pdf/2506.23516, 2025-07-21
2025-11-09 21:18:18,269 - INFO - root - Page:2, Index:14, Spectra 1.1: Scaling Laws and Efficient Inference for Ternary Language Models, https://arxiv.org/pdf/2506.23025, 2025-06-28
2025-11-09 21:18:18,344 - INFO - root - Page:2, Index:15, Joint Quantization and Pruning Neural Networks Approach: A Case Study on FSO Receivers, https://arxiv.org/pdf/2506.20084, 2025-06-24
2025-11-09 21:18:18,375 - INFO - root - Page:2, Index:16, Single-step Diffusion for Image Compression at Ultra-Low Bitrates, https://arxiv.org/pdf/2506.16572, 2025-09-22
2025-11-09 21:18:18,391 - INFO - root - Page:2, Index:17, LittleBit: Ultra Low-Bit Quantization via Latent Factorization, https://arxiv.org/pdf/2506.13771, 2025-10-28
2025-11-09 21:18:18,407 - INFO - root - Page:2, Index:18, MARCO: Hardware-Aware Neural Architecture Search for Edge Devices with Multi-Agent Reinforcement Learning and Conformal Prediction Filtering, https://arxiv.org/pdf/2506.13755, 2025-06-16
2025-11-09 21:18:18,410 - INFO - root - Page:2, Index:19, EAQuant: Enhancing Post-Training Quantization for MoE Models via Expert-Aware Optimization, https://arxiv.org/pdf/2506.13329, 2025-07-04
2025-11-09 21:18:18,413 - INFO - root - Page:2, Index:20, Towards Neural Audio Codec Source Parsing, https://arxiv.org/pdf/2506.12627, 2025-06-14
2025-11-09 21:18:18,416 - INFO - root - Page:2, Index:21, Quantizing Small-Scale State-Space Models for Edge AI, https://arxiv.org/pdf/2506.12480, 2025-06-14
2025-11-09 21:18:18,420 - INFO - root - Page:2, Index:22, EMLoC: Emulator-based Memory-efficient Fine-tuning with LoRA Correction, https://arxiv.org/pdf/2506.12015, 2025-06-13
2025-11-09 21:18:18,426 - INFO - root - Page:2, Index:23, Compression Aware Certified Training, https://arxiv.org/pdf/2506.11992, 2025-06-13
2025-11-09 21:18:18,429 - INFO - root - Page:2, Index:24, GPLQ: A General, Practical, and Lightning QAT Method for Vision Transformers, https://arxiv.org/pdf/2506.11784, 2025-06-13
2025-11-09 21:18:18,433 - INFO - root - Page:2, Index:25, TruncQuant: Truncation-Ready Quantization for DNNs with Flexible Weight Bit Precision, https://arxiv.org/pdf/2506.11431, 2025-06-12
2025-11-09 21:18:18,441 - INFO - root - Page:2, Index:26, EfficientQuant: An Efficient Post-Training Quantization for CNN-Transformer Hybrid Models on Edge Devices, https://arxiv.org/pdf/2506.11093, 2025-06-05
2025-11-09 21:18:18,443 - INFO - root - Page:2, Index:27, Starting Positions Matter: A Study on Better Weight Initialization for Neural Network Quantization, https://arxiv.org/pdf/2506.10463, 2025-06-12
2025-11-09 21:18:18,451 - INFO - root - Page:2, Index:28, AWP: Activation-Aware Weight Pruning and Quantization with Projected Gradient Descent, https://arxiv.org/pdf/2506.10205, 2025-06-11
2025-11-09 21:18:18,458 - INFO - root - Page:2, Index:29, Q-SAM2: Accurate Quantization for Segment Anything Model 2, https://arxiv.org/pdf/2506.09782, 2025-06-11
2025-11-09 21:18:18,460 - INFO - root - Page:2, Index:30, Unifying Block-wise PTQ and Distillation-based QAT for Progressive Quantization toward 2-bit Instruction-Tuned LLMs, https://arxiv.org/pdf/2506.09104, 2025-06-10
2025-11-09 21:18:18,462 - INFO - root - Page:2, Index:31, Implementing Keyword Spotting on the MCUX947 Microcontroller with Integrated NPU, https://arxiv.org/pdf/2506.08911, 2025-06-10
2025-11-09 21:18:18,469 - INFO - root - Page:2, Index:32, POLARON: Precision-aware On-device Learning and Adaptive Runtime-cONfigurable AI acceleration, https://arxiv.org/pdf/2506.08785, 2025-06-10
2025-11-09 21:18:18,477 - INFO - root - Page:2, Index:33, MoQAE: Mixed-Precision Quantization for Long-Context LLM Inference via Mixture of Quantization-Aware Experts, https://arxiv.org/pdf/2506.07533, 2025-06-09
2025-11-09 21:18:18,483 - INFO - root - Page:2, Index:34, BitVLA: 1-bit Vision-Language-Action Models for Robotics Manipulation, https://arxiv.org/pdf/2506.07530, 2025-06-09
2025-11-09 21:18:18,487 - INFO - root - Page:2, Index:35, RecGPT: A Foundation Model for Sequential Recommendation, https://arxiv.org/pdf/2506.06270, 2025-06-12
2025-11-09 21:18:18,492 - INFO - root - Page:2, Index:36, FPSAttention: Training-Aware FP8 and Sparsity Co-Design for Fast Video Diffusion, https://arxiv.org/pdf/2506.04648, 2025-06-05
2025-11-09 21:18:18,494 - INFO - root - Page:2, Index:37, BitTTS: Highly Compact Text-to-Speech Using 1.58-bit Quantization and Weight Indexing, https://arxiv.org/pdf/2506.03515, 2025-06-03
2025-11-09 21:18:18,495 - INFO - root - Page:2, Index:38, ShapeLLM-Omni: A Native Multimodal LLM for 3D Generation and Understanding, https://arxiv.org/pdf/2506.01853, 2025-06-02
2025-11-09 21:18:18,495 - INFO - root - Page:2, Index:39, Movable Antenna Enhanced Federated Fine-Tuning of Large Language Models via Hybrid Client Selection Optimization, https://arxiv.org/pdf/2506.00011, 2025-10-26
2025-11-09 21:18:18,496 - INFO - root - Page:2, Index:40, Running Conventional Automatic Speech Recognition on Memristor Hardware: A Simulated Approach, https://arxiv.org/pdf/2505.24721, 2025-05-30
2025-11-09 21:18:18,496 - INFO - root - Page:2, Index:41, GARLIC: GAussian Representation LearnIng for spaCe partitioning, https://arxiv.org/pdf/2505.24608, 2025-10-02
2025-11-09 21:18:18,496 - INFO - root - Page:2, Index:42, AutoChemSchematic AI: Agentic Physics-Aware Automation for Chemical Manufacturing Scale-Up, https://arxiv.org/pdf/2505.24584, 2025-08-18
2025-11-09 21:18:18,498 - INFO - root - Page:2, Index:43, Model-Preserving Adaptive Rounding, https://arxiv.org/pdf/2505.22988, 2025-09-25
2025-11-09 21:18:18,498 - INFO - root - Page:2, Index:44, Highly Efficient and Effective LLMs with Multi-Boolean Architectures, https://arxiv.org/pdf/2505.22811, 2025-10-03
2025-11-09 21:18:18,498 - INFO - root - Page:2, Index:45, Pioneering 4-Bit FP Quantization for Diffusion Models: Mixup-Sign Quantization and Timestep-Aware Fine-Tuning, https://arxiv.org/pdf/2505.21591, 2025-05-27
2025-11-09 21:18:18,498 - INFO - root - Page:2, Index:46, Frequency Composition for Compressed and Domain-Adaptive Neural Networks, https://arxiv.org/pdf/2505.20890, 2025-05-27
2025-11-09 21:18:18,500 - INFO - root - Page:2, Index:47, MoPFormer: Motion-Primitive Transformer for Wearable-Sensor Activity Recognition, https://arxiv.org/pdf/2505.20744, 2025-10-27
2025-11-09 21:18:18,500 - INFO - root - Page:2, Index:48, Optimizing edge AI models on HPC systems with the edge in the loop, https://arxiv.org/pdf/2505.19995, 2025-05-26
2025-11-09 21:18:18,501 - INFO - root - Fetching page 4 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=150
2025-11-09 21:18:24,851 - INFO - root - get_all_titles_from_web 
2025-11-09 21:18:24,852 - INFO - root - Page:3, Index:0, DPASyn: Mechanism-Aware Drug Synergy Prediction via Dual Attention and Precision-Aware Quantization, https://arxiv.org/pdf/2505.19144, 2025-09-20
2025-11-09 21:18:24,852 - INFO - root - Page:3, Index:1, Reducing Storage of Pretrained Neural Networks by Rate-Constrained Quantization and Entropy Coding, https://arxiv.org/pdf/2505.18758, 2025-05-24
2025-11-09 21:18:24,852 - INFO - root - Page:3, Index:2, Beyond Discreteness: Finite-Sample Analysis of Straight-Through Estimator for Quantization, https://arxiv.org/pdf/2505.18113, 2025-05-23
2025-11-09 21:18:24,852 - INFO - root - Page:3, Index:3, Automating Versatile Time-Series Analysis with Tiny Transformers on Embedded FPGAs, https://arxiv.org/pdf/2505.17662, 2025-09-19
2025-11-09 21:18:24,854 - INFO - root - Page:3, Index:4, FPQVAR: Floating Point Quantization for Visual Autoregressive Model with FPGA Hardware Co-design, https://arxiv.org/pdf/2505.16335, 2025-05-22
2025-11-09 21:18:24,854 - INFO - root - Page:3, Index:5, Saliency-Aware Quantized Imitation Learning for Efficient Robotic Control, https://arxiv.org/pdf/2505.15304, 2025-05-30
2025-11-09 21:18:24,854 - INFO - root - Page:3, Index:6, Scaling Law for Quantization-Aware Training, https://arxiv.org/pdf/2505.14302, 2025-05-20
2025-11-09 21:18:24,854 - INFO - root - Page:3, Index:7, Automatic mixed precision for optimizing gained time with constrained loss mean-squared-error based on model partition to sequential sub-graphs, https://arxiv.org/pdf/2505.13060, 2025-05-19
2025-11-09 21:18:24,855 - INFO - root - Page:3, Index:8, Deep Unfolding with Kernel-based Quantization in MIMO Detection, https://arxiv.org/pdf/2505.12736, 2025-05-19
2025-11-09 21:18:24,855 - INFO - root - Page:3, Index:9, FedHQ: Hybrid Runtime Quantization for Federated Learning, https://arxiv.org/pdf/2505.11982, 2025-05-17
2025-11-09 21:18:24,855 - INFO - root - Page:3, Index:10, QVGen: Pushing the Limit of Quantized Video Generative Models, https://arxiv.org/pdf/2505.11497, 2025-09-27
2025-11-09 21:18:24,855 - INFO - root - Page:3, Index:11, EA-3DGS: Efficient and Adaptive 3D Gaussians with Highly Enhanced Quality for outdoor scenes, https://arxiv.org/pdf/2505.10787, 2025-05-15
2025-11-09 21:18:24,856 - INFO - root - Page:3, Index:12, ITERA-LLM: Boosting Sub-8-Bit Large Language Model Inference via Iterative Tensor Decomposition, https://arxiv.org/pdf/2505.08981, 2025-05-13
2025-11-09 21:18:24,856 - INFO - root - Page:3, Index:13, PROM: Prioritize Reduction of Multiplications Over Lower Bit-Widths for Efficient CNNs, https://arxiv.org/pdf/2505.03254, 2025-08-06
2025-11-09 21:18:24,857 - INFO - root - Page:3, Index:14, ICQuant: Index Coding enables Low-bit LLM Quantization, https://arxiv.org/pdf/2505.00850, 2025-08-24
2025-11-09 21:18:24,862 - INFO - root - Page:3, Index:15, Enhancing Ultra-Low-Bit Quantization of Large Language Models Through Saliency-Aware Partial Retraining, https://arxiv.org/pdf/2504.13932, 2025-07-30
2025-11-09 21:18:24,864 - INFO - root - Page:3, Index:16, Achieving binary weight and activation for LLMs using Post-Training Quantization, https://arxiv.org/pdf/2504.05352, 2025-06-30
2025-11-09 21:18:24,864 - INFO - root - Page:3, Index:17, Wireless Hearables With Programmable Speech AI Accelerators, https://arxiv.org/pdf/2503.18698, 2025-10-21
2025-11-09 21:18:24,865 - INFO - root - Page:3, Index:18, GranQ: Efficient Channel-wise Quantization via Vectorized Pre-Scaling for Zero-Shot QAT, https://arxiv.org/pdf/2503.18339, 2025-10-15
2025-11-09 21:18:24,865 - INFO - root - Page:3, Index:19, CompMarkGS: Robust Watermarking for Compressed 3D Gaussian Splatting, https://arxiv.org/pdf/2503.12836, 2025-09-29
2025-11-09 21:18:24,866 - INFO - root - Page:3, Index:20, AHCPTQ: Accurate and Hardware-Compatible Post-Training Quantization for Segment Anything Model, https://arxiv.org/pdf/2503.03088, 2025-07-11
2025-11-09 21:18:24,866 - INFO - root - Page:3, Index:21, Teaching Metric Distance to Discrete Autoregressive Language Models, https://arxiv.org/pdf/2503.02379, 2025-10-07
2025-11-09 21:18:24,866 - INFO - root - Page:3, Index:22, Regularization-based Framework for Quantization-, Fault- and Variability-Aware Training, https://arxiv.org/pdf/2503.01297, 2025-07-12
2025-11-09 21:18:24,867 - INFO - root - Fetching page 5 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=200
2025-11-09 21:18:31,718 - INFO - root - get_all_titles_from_web 
2025-11-09 21:18:31,718 - INFO - root - Page:4, Index:0, Investigating the Impact of Quantization Methods on the Safety and Reliability of Large Language Models, https://arxiv.org/pdf/2502.15799, 2025-06-29
2025-11-09 21:18:31,719 - INFO - root - Page:4, Index:1, Rotate, Clip, and Partition: Towards W2A4KV4 Quantization by Integrating Rotation and Learnable Non-uniform Quantizer, https://arxiv.org/pdf/2502.15779, 2025-09-01
2025-11-09 21:18:31,719 - INFO - root - Page:4, Index:2, RoSTE: An Efficient Quantization-Aware Supervised Fine-Tuning Approach for Large Language Models, https://arxiv.org/pdf/2502.09003, 2025-06-05
2025-11-09 21:18:31,719 - INFO - root - Page:4, Index:3, Spatial Degradation-Aware and Temporal Consistent Diffusion Model for Compressed Video Super-Resolution, https://arxiv.org/pdf/2502.07381, 2025-06-27
2025-11-09 21:18:31,719 - INFO - root - Page:4, Index:4, QuEST: Stable Training of LLMs with 1-Bit Weights and Activations, https://arxiv.org/pdf/2502.05003, 2025-06-10
2025-11-09 21:18:31,720 - INFO - root - Page:4, Index:5, HALO: Hadamard-Assisted Lower-Precision Optimization for LLMs, https://arxiv.org/pdf/2501.02625, 2025-11-05
2025-11-09 21:18:31,720 - INFO - root - Page:4, Index:6, TAR3D: Creating High-Quality 3D Assets via Next-Part Prediction, https://arxiv.org/pdf/2412.16919, 2025-08-08
2025-11-09 21:18:31,720 - INFO - root - Page:4, Index:7, Training Multi-Layer Binary Neural Networks With Local Binary Error Signals, https://arxiv.org/pdf/2412.00119, 2025-08-05
2025-11-09 21:18:31,721 - INFO - root - Page:4, Index:8, Scaling Large-scale GNN Training to Thousands of Processors on CPU-based Supercomputers, https://arxiv.org/pdf/2411.16025, 2025-05-26
2025-11-09 21:18:31,721 - INFO - root - Page:4, Index:9, HAFLQ: Heterogeneous Adaptive Federated LoRA Fine-tuned LLM with Quantization, https://arxiv.org/pdf/2411.06581, 2025-05-16
2025-11-09 21:18:31,721 - INFO - root - Fetching page 6 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=250
2025-11-09 21:18:38,692 - INFO - root - get_all_titles_from_web 
2025-11-09 21:18:38,692 - INFO - root - Page:5, Index:0, Gradient-Free Training of Quantized Neural Networks, https://arxiv.org/pdf/2410.09734, 2025-09-29
2025-11-09 21:18:38,693 - INFO - root - Page:5, Index:1, QT-DoG: Quantization-aware Training for Domain Generalization, https://arxiv.org/pdf/2410.06020, 2025-06-26
2025-11-09 21:18:38,693 - INFO - root - Page:5, Index:2, Constraint Guided Model Quantization of Neural Networks, https://arxiv.org/pdf/2409.20138, 2025-09-12
2025-11-09 21:18:38,693 - INFO - root - Page:5, Index:3, Accumulator-Aware Post-Training Quantization for Large Language Models, https://arxiv.org/pdf/2409.17092, 2025-07-30
2025-11-09 21:18:38,693 - INFO - root - Page:5, Index:4, DilateQuant: Accurate and Efficient Diffusion Quantization via Weight Dilation, https://arxiv.org/pdf/2409.14307, 2025-07-09
2025-11-09 21:18:38,693 - INFO - root - Page:5, Index:5, Robust Training of Neural Networks at Arbitrary Precision and Sparsity, https://arxiv.org/pdf/2409.09245, 2025-09-23
2025-11-09 21:18:38,694 - INFO - root - Page:5, Index:6, VQ-CTAP: Cross-Modal Fine-Grained Sequence Representation Learning for Speech Processing, https://arxiv.org/pdf/2408.05758, 2025-05-27
2025-11-09 21:18:38,694 - INFO - root - Page:5, Index:7, DopQ-ViT: Towards Distribution-Friendly and Outlier-Aware Post-Training Quantization for Vision Transformers, https://arxiv.org/pdf/2408.03291, 2025-06-19
2025-11-09 21:18:38,694 - INFO - root - Page:5, Index:8, Temporal Feature Matters: A Framework for Diffusion Model Quantization, https://arxiv.org/pdf/2407.19547, 2025-07-11
2025-11-09 21:18:38,694 - INFO - root - Page:5, Index:9, EfficientQAT: Efficient Quantization-Aware Training for Large Language Models, https://arxiv.org/pdf/2407.11062, 2025-05-19
2025-11-09 21:18:38,694 - INFO - root - Page:5, Index:10, Integer-only Quantized Transformers for Embedded FPGA-based Time-series Forecasting in AIoT, https://arxiv.org/pdf/2407.11041, 2025-10-31
2025-11-09 21:18:38,695 - INFO - root - Fetching page 7 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=300
2025-11-09 21:18:45,887 - INFO - root - get_all_titles_from_web 
2025-11-09 21:18:45,889 - INFO - root - Page:6, Index:0, BoA: Attention-aware Post-training Quantization without Backpropagation, https://arxiv.org/pdf/2406.13474, 2025-06-06
2025-11-09 21:18:45,889 - INFO - root - Page:6, Index:1, A Rescaling-Invariant Lipschitz Bound Based on Path-Metrics for Modern ReLU Network Parameterizations, https://arxiv.org/pdf/2405.15006, 2025-06-13
2025-11-09 21:18:45,891 - INFO - root - Page:6, Index:2, Scheduling Weight Transitions for Quantization-Aware Training, https://arxiv.org/pdf/2404.19248, 2025-10-01
2025-11-09 21:18:45,891 - INFO - root - Page:6, Index:3, GPTVQ: The Blessing of Dimensionality for LLM Quantization, https://arxiv.org/pdf/2402.15319, 2025-06-03
2025-11-09 21:18:45,893 - INFO - root - Fetching page 8 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=350
2025-11-09 21:18:53,552 - INFO - root - get_all_titles_from_web 
2025-11-09 21:18:53,559 - INFO - root - Page:7, Index:0, Squat: Quant Small Language Models on the Edge, https://arxiv.org/pdf/2402.10787, 2025-07-01
2025-11-09 21:18:53,562 - INFO - root - Page:7, Index:1, L4Q: Parameter Efficient Quantization-Aware Fine-Tuning on Large Language Models, https://arxiv.org/pdf/2402.04902, 2025-07-21
2025-11-09 21:18:53,563 - INFO - root - Fetching page 9 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=400
2025-11-09 21:19:00,507 - INFO - root - ------------------------------------------------------------------------------------------------------------------------
2025-11-09 21:19:00,508 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\A Quantized VAE-MLP Botnet Detection Model_ A Systematic Evaluation of Quantizat.pdf
2025-11-09 21:19:00,514 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\FP8-Flow-MoE_ A Casting-Free FP8 Recipe without Double Quantization Error.pdf
2025-11-09 21:19:00,516 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\Outlier-Aware Post-Training Quantization for Image Super-Resolution.pdf
2025-11-09 21:19:00,517 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\Evaluation of Wafer-Scale SOT-MRAM for Analog Crossbar Array Applications.pdf
2025-11-09 21:19:00,517 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\Improving the Straight-Through Estimator with Zeroth-Order Information.pdf
2025-11-09 21:19:00,518 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\Real-Time Semantic Segmentation on FPGA for Autonomous Vehicles Using LMIINet wi.pdf
2025-11-09 21:19:00,519 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\TernaryCLIP_ Efficiently Compressing Vision-Language Models with Ternary Weights.pdf
2025-11-09 21:19:00,523 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\KARIPAP_ Quantum-Inspired Tensor Network Compression of Large Language Models Us.pdf
2025-11-09 21:19:00,524 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\A Convergence Analysis of Adaptive Optimizers under Floating-point Quantization.pdf
2025-11-09 21:19:00,525 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\Adaptive Distribution-aware Quantization for Mixed-Precision Neural Networks.pdf
2025-11-09 21:19:00,525 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\CAGE_ Curvature-Aware Gradient Estimation For Accurate Quantization-Aware Traini.pdf
2025-11-09 21:19:00,528 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\Mixed-Precision Quantization for Language Models_ Techniques and Prospects.pdf
2025-11-09 21:19:00,531 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\SPLite Hand_ Sparsity-Aware Lightweight 3D Hand Pose Estimation.pdf
2025-11-09 21:19:00,532 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\CTR-LoRA_ Curvature-Aware and Trust-Region Guided Low-Rank Adaptation for Large.pdf
2025-11-09 21:19:00,535 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\SANR_ Scene-Aware Neural Representation for Light Field Image Compression with R.pdf
2025-11-09 21:19:00,538 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\SpikeFit_ Towards Optimal Deployment of Spiking Networks on Neuromorphic Hardwar.pdf
2025-11-09 21:19:00,539 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\GRank_ Towards Target-Aware and Streamlined Industrial Retrieval with a Generate.pdf
2025-11-09 21:19:00,540 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\SaLon3R_ Structure-aware Long-term Generalizable 3D Reconstruction from Unposed.pdf
2025-11-09 21:19:00,542 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\FraQAT_ Quantization Aware Training with Fractional bits.pdf
2025-11-09 21:19:00,543 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\Computing-In-Memory Aware Model Adaption For Edge Devices.pdf
2025-11-09 21:19:00,547 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\Invited Paper_ BitMedViT_ Ternary-Quantized Vision Transformer for Medical AI As.pdf
2025-11-09 21:19:00,547 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\NeuroRVQ_ Multi-Scale EEG Tokenization for Generative Large Brainwave Models.pdf
2025-11-09 21:19:00,548 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\Detect Anything via Next Point Prediction.pdf
2025-11-09 21:19:00,550 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\AndesVL Technical Report_ An Efficient Mobile-side Multimodal Large Language Mod.pdf
2025-11-09 21:19:00,553 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\Rescaling-Aware Training for Efficient Deployment of Deep Learning Models on Ful.pdf
2025-11-09 21:19:00,555 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\SASER_ Stego attacks on open-source LLMs.pdf
2025-11-09 21:19:00,556 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\Ultralytics YOLO Evolution_ An Overview of YOLO26, YOLO11, YOLOv8 and YOLOv5 Obj.pdf
2025-11-09 21:19:00,556 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\A Theoretically-Grounded Codebook for Digital Semantic Communications.pdf
2025-11-09 21:19:00,557 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\QuantDemoire_ Quantization with Outlier Aware for Image Demoiréing.pdf
2025-11-09 21:19:00,558 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\Adaptively Sampling-Reusing-Mixing Decomposed Gradients to Speed Up Sharpness Aw.pdf
2025-11-09 21:19:00,563 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\Quant-dLLM_ Post-Training Extreme Low-Bit Quantization for Diffusion Large Langu.pdf
2025-11-09 21:19:00,564 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\PT$^2$-LLM_ Post-Training Ternarization for Large Language Models.pdf
2025-11-09 21:19:00,565 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\Purrception_ Variational Flow Matching for Vector-Quantized Image Generation.pdf
2025-11-09 21:19:00,570 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\Post-Training Quantization for Audio Diffusion Transformers.pdf
2025-11-09 21:19:00,572 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\Rethinking RoPE Scaling in Quantized LLM_ Theory, Outlier, and Channel-Band Anal.pdf
2025-11-09 21:19:00,573 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\Post-Training Quantization via Residual Truncation and Zero Suppression for Diff.pdf
2025-11-09 21:19:00,574 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\Cat_ Post-Training Quantization Error Reduction via Cluster-based Affine Transfo.pdf
2025-11-09 21:19:00,575 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\CAST_ Continuous and Differentiable Semi-Structured Sparsity-Aware Training for.pdf
2025-11-09 21:19:00,576 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\Norm-Q_ Effective Compression Method for Hidden Markov Models in Neuro-Symbolic.pdf
2025-11-09 21:19:00,580 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\On-the-Fly Adaptation to Quantization_ Configuration-Aware LoRA for Efficient Fi.pdf
2025-11-09 21:19:00,581 - INFO - root - 跳过已处理论文 A Quantized VAE-MLP Botnet Detection Model: A Systematic Evaluation of Quantization-Aware Training and Post-Training Quantization Strategies：d:\ChatPaper\academic Papers\Quantization-Aware-Training\A Quantized VAE-MLP Botnet Detection Model_ A Systematic Evaluation of Quantizat.pdf
2025-11-09 21:19:00,582 - INFO - root - 跳过已处理论文 FP8-Flow-MoE: A Casting-Free FP8 Recipe without Double Quantization Error：d:\ChatPaper\academic Papers\Quantization-Aware-Training\FP8-Flow-MoE_ A Casting-Free FP8 Recipe without Double Quantization Error.pdf
2025-11-09 21:19:00,585 - INFO - root - 跳过已处理论文 Outlier-Aware Post-Training Quantization for Image Super-Resolution：d:\ChatPaper\academic Papers\Quantization-Aware-Training\Outlier-Aware Post-Training Quantization for Image Super-Resolution.pdf
2025-11-09 21:19:00,585 - INFO - root - 跳过已处理论文 Evaluation of Wafer-Scale SOT-MRAM for Analog Crossbar Array Applications：d:\ChatPaper\academic Papers\Quantization-Aware-Training\Evaluation of Wafer-Scale SOT-MRAM for Analog Crossbar Array Applications.pdf
2025-11-09 21:19:00,586 - INFO - root - 跳过已处理论文 Improving the Straight-Through Estimator with Zeroth-Order Information：d:\ChatPaper\academic Papers\Quantization-Aware-Training\Improving the Straight-Through Estimator with Zeroth-Order Information.pdf
2025-11-09 21:19:00,587 - INFO - root - 跳过已处理论文 Real-Time Semantic Segmentation on FPGA for Autonomous Vehicles Using LMIINet with the CGRA4ML Framework：d:\ChatPaper\academic Papers\Quantization-Aware-Training\Real-Time Semantic Segmentation on FPGA for Autonomous Vehicles Using LMIINet wi.pdf
2025-11-09 21:19:00,587 - INFO - root - 跳过已处理论文 TernaryCLIP: Efficiently Compressing Vision-Language Models with Ternary Weights and Distilled Knowledge：d:\ChatPaper\academic Papers\Quantization-Aware-Training\TernaryCLIP_ Efficiently Compressing Vision-Language Models with Ternary Weights.pdf
2025-11-09 21:19:00,587 - INFO - root - 正在总结论文 8/40: KARIPAP: Quantum-Inspired Tensor Network Compression of Large Language Models Using Infinite Projected Entangled Pair States and Tensor Renormalization Group
2025-11-09 21:19:35,806 - INFO - root - LLMClient: rate limit reached, sleeping 24.8s
2025-11-09 21:20:21,177 - INFO - root - 正在提取论文图片...
2025-11-09 21:20:21,328 - INFO - root - 已保存图片 1/10：./export\images_KARIPAP_ Quantum-Inspired Tensor Network Compression of Large Language Models Us\figure_1_page3.jpeg
2025-11-09 21:20:21,403 - INFO - root - 已保存图片 2/10：./export\images_KARIPAP_ Quantum-Inspired Tensor Network Compression of Large Language Models Us\figure_2_page7.png
2025-11-09 21:20:21,472 - INFO - root - 已保存图片 3/10：./export\images_KARIPAP_ Quantum-Inspired Tensor Network Compression of Large Language Models Us\figure_3_page9.png
2025-11-09 21:20:21,550 - INFO - root - 已保存图片 4/10：./export\images_KARIPAP_ Quantum-Inspired Tensor Network Compression of Large Language Models Us\figure_4_page8.png
2025-11-09 21:20:21,552 - INFO - root - 成功添加图片 1：./export\images_KARIPAP_ Quantum-Inspired Tensor Network Compression of Large Language Models Us\figure_1_page3.jpeg
2025-11-09 21:20:21,552 - INFO - root - 成功添加图片 2：./export\images_KARIPAP_ Quantum-Inspired Tensor Network Compression of Large Language Models Us\figure_2_page7.png
2025-11-09 21:20:21,552 - INFO - root - 成功添加图片 3：./export\images_KARIPAP_ Quantum-Inspired Tensor Network Compression of Large Language Models Us\figure_3_page9.png
2025-11-09 21:20:21,553 - INFO - root - 成功添加图片 4：./export\images_KARIPAP_ Quantum-Inspired Tensor Network Compression of Large Language Models Us\figure_4_page8.png
2025-11-09 21:20:21,554 - INFO - root - 论文《KARIPAP: Quantum-Inspired Tensor Network Compression of Large Language Models Using Infinite Projected Entangled Pair States and Tensor Renormalization Group》的分析已保存到 ./export\KARIPAP_ Quantum-Inspired Tensor Network Compression of Large Language Models Us.md
2025-11-09 21:20:21,557 - INFO - root - 正在总结论文 9/40: A Convergence Analysis of Adaptive Optimizers under Floating-point Quantization
2025-11-09 21:20:31,698 - INFO - root - LLMClient: rate limit reached, sleeping 28.9s
2025-11-09 21:21:50,391 - INFO - root - 正在提取论文图片...
2025-11-09 21:21:50,458 - INFO - root - 论文《A Convergence Analysis of Adaptive Optimizers under Floating-point Quantization》的分析已保存到 ./export\A Convergence Analysis of Adaptive Optimizers under Floating-point Quantization.md
2025-11-09 21:21:50,460 - INFO - root - 正在总结论文 10/40: Adaptive Distribution-aware Quantization for Mixed-Precision Neural Networks
2025-11-09 21:21:50,460 - INFO - root - LLMClient: rate limit reached, sleeping 10.1s
2025-11-09 21:22:11,535 - INFO - root - LLMClient: rate limit reached, sleeping 17.7s
2025-11-09 21:22:56,386 - INFO - root - LLMClient: rate limit reached, sleeping 4.2s
2025-11-09 21:23:19,458 - INFO - root - 正在提取论文图片...
2025-11-09 21:23:19,622 - INFO - root - 已保存图片 1/10：./export\images_Adaptive Distribution-aware Quantization for Mixed-Precision Neural Networks\figure_1_page6.png
2025-11-09 21:23:19,678 - INFO - root - 已保存图片 2/10：./export\images_Adaptive Distribution-aware Quantization for Mixed-Precision Neural Networks\figure_2_page13.png
2025-11-09 21:23:19,735 - INFO - root - 已保存图片 3/10：./export\images_Adaptive Distribution-aware Quantization for Mixed-Precision Neural Networks\figure_3_page13.png
2025-11-09 21:23:19,750 - INFO - root - 已保存图片 4/10：./export\images_Adaptive Distribution-aware Quantization for Mixed-Precision Neural Networks\figure_4_page3.jpeg
2025-11-09 21:23:19,780 - INFO - root - 已保存图片 5/10：./export\images_Adaptive Distribution-aware Quantization for Mixed-Precision Neural Networks\figure_5_page3.jpeg
2025-11-09 21:23:19,808 - INFO - root - 已保存图片 6/10：./export\images_Adaptive Distribution-aware Quantization for Mixed-Precision Neural Networks\figure_6_page3.jpeg
2025-11-09 21:23:19,848 - INFO - root - 已保存图片 7/10：./export\images_Adaptive Distribution-aware Quantization for Mixed-Precision Neural Networks\figure_7_page3.jpeg
2025-11-09 21:23:20,010 - INFO - root - 已保存图片 8/10：./export\images_Adaptive Distribution-aware Quantization for Mixed-Precision Neural Networks\figure_8_page2.png
2025-11-09 21:23:20,123 - INFO - root - 已保存图片 9/10：./export\images_Adaptive Distribution-aware Quantization for Mixed-Precision Neural Networks\figure_9_page2.png
2025-11-09 21:23:20,230 - INFO - root - 已保存图片 10/10：./export\images_Adaptive Distribution-aware Quantization for Mixed-Precision Neural Networks\figure_10_page2.png
2025-11-09 21:23:20,233 - INFO - root - 成功添加图片 1：./export\images_Adaptive Distribution-aware Quantization for Mixed-Precision Neural Networks\figure_1_page6.png
2025-11-09 21:23:20,233 - INFO - root - 成功添加图片 2：./export\images_Adaptive Distribution-aware Quantization for Mixed-Precision Neural Networks\figure_2_page13.png
2025-11-09 21:23:20,234 - INFO - root - 成功添加图片 3：./export\images_Adaptive Distribution-aware Quantization for Mixed-Precision Neural Networks\figure_3_page13.png
2025-11-09 21:23:20,235 - INFO - root - 成功添加图片 4：./export\images_Adaptive Distribution-aware Quantization for Mixed-Precision Neural Networks\figure_4_page3.jpeg
2025-11-09 21:23:20,235 - INFO - root - 成功添加图片 5：./export\images_Adaptive Distribution-aware Quantization for Mixed-Precision Neural Networks\figure_5_page3.jpeg
2025-11-09 21:23:20,243 - INFO - root - 成功添加图片 6：./export\images_Adaptive Distribution-aware Quantization for Mixed-Precision Neural Networks\figure_6_page3.jpeg
2025-11-09 21:23:20,243 - INFO - root - 成功添加图片 7：./export\images_Adaptive Distribution-aware Quantization for Mixed-Precision Neural Networks\figure_7_page3.jpeg
2025-11-09 21:23:20,246 - INFO - root - 成功添加图片 8：./export\images_Adaptive Distribution-aware Quantization for Mixed-Precision Neural Networks\figure_8_page2.png
2025-11-09 21:23:20,247 - INFO - root - 成功添加图片 9：./export\images_Adaptive Distribution-aware Quantization for Mixed-Precision Neural Networks\figure_9_page2.png
2025-11-09 21:23:20,248 - INFO - root - 成功添加图片 10：./export\images_Adaptive Distribution-aware Quantization for Mixed-Precision Neural Networks\figure_10_page2.png
2025-11-09 21:23:20,266 - INFO - root - 论文《Adaptive Distribution-aware Quantization for Mixed-Precision Neural Networks》的分析已保存到 ./export\Adaptive Distribution-aware Quantization for Mixed-Precision Neural Networks.md
2025-11-09 21:23:20,280 - INFO - root - 正在总结论文 11/40: CAGE: Curvature-Aware Gradient Estimation For Accurate Quantization-Aware Training
2025-11-09 21:23:20,280 - INFO - root - LLMClient: rate limit reached, sleeping 8.9s
2025-11-09 21:23:39,801 - INFO - root - LLMClient: rate limit reached, sleeping 20.8s
2025-11-09 21:25:27,247 - INFO - root - 正在提取论文图片...
2025-11-09 21:25:27,274 - INFO - root - 已保存图片 1/10：./export\images_CAGE_ Curvature-Aware Gradient Estimation For Accurate Quantization-Aware Traini\figure_1_page8.png
2025-11-09 21:25:27,278 - INFO - root - 成功添加图片 1：./export\images_CAGE_ Curvature-Aware Gradient Estimation For Accurate Quantization-Aware Traini\figure_1_page8.png
2025-11-09 21:25:27,280 - INFO - root - 论文《CAGE: Curvature-Aware Gradient Estimation For Accurate Quantization-Aware Training》的分析已保存到 ./export\CAGE_ Curvature-Aware Gradient Estimation For Accurate Quantization-Aware Traini.md
2025-11-09 21:25:27,286 - INFO - root - 正在总结论文 12/40: Mixed-Precision Quantization for Language Models: Techniques and Prospects
2025-11-09 21:25:38,271 - INFO - root - LLMClient: rate limit reached, sleeping 23.1s
2025-11-09 21:26:26,869 - INFO - root - LLMClient: rate limit reached, sleeping 0.4s
2025-11-09 21:26:45,787 - INFO - root - 正在提取论文图片...
2025-11-09 21:26:50,900 - INFO - root - 已保存图片 1/10：./export\images_Mixed-Precision Quantization for Language Models_ Techniques and Prospects\figure_1_page28.png
2025-11-09 21:26:51,503 - INFO - root - 已保存图片 2/10：./export\images_Mixed-Precision Quantization for Language Models_ Techniques and Prospects\figure_2_page4.png
2025-11-09 21:26:51,627 - INFO - root - 已保存图片 3/10：./export\images_Mixed-Precision Quantization for Language Models_ Techniques and Prospects\figure_3_page6.png
2025-11-09 21:26:51,763 - INFO - root - 已保存图片 4/10：./export\images_Mixed-Precision Quantization for Language Models_ Techniques and Prospects\figure_4_page6.png
2025-11-09 21:26:51,901 - INFO - root - 已保存图片 5/10：./export\images_Mixed-Precision Quantization for Language Models_ Techniques and Prospects\figure_5_page6.png
2025-11-09 21:26:52,008 - INFO - root - 已保存图片 6/10：./export\images_Mixed-Precision Quantization for Language Models_ Techniques and Prospects\figure_6_page6.png
2025-11-09 21:26:52,028 - INFO - root - 成功添加图片 1：./export\images_Mixed-Precision Quantization for Language Models_ Techniques and Prospects\figure_1_page28.png
2025-11-09 21:26:52,029 - INFO - root - 成功添加图片 2：./export\images_Mixed-Precision Quantization for Language Models_ Techniques and Prospects\figure_2_page4.png
2025-11-09 21:26:52,029 - INFO - root - 成功添加图片 3：./export\images_Mixed-Precision Quantization for Language Models_ Techniques and Prospects\figure_3_page6.png
2025-11-09 21:26:52,032 - INFO - root - 成功添加图片 4：./export\images_Mixed-Precision Quantization for Language Models_ Techniques and Prospects\figure_4_page6.png
2025-11-09 21:26:52,038 - INFO - root - 成功添加图片 5：./export\images_Mixed-Precision Quantization for Language Models_ Techniques and Prospects\figure_5_page6.png
2025-11-09 21:26:52,038 - INFO - root - 成功添加图片 6：./export\images_Mixed-Precision Quantization for Language Models_ Techniques and Prospects\figure_6_page6.png
2025-11-09 21:26:52,060 - INFO - root - 论文《Mixed-Precision Quantization for Language Models: Techniques and Prospects》的分析已保存到 ./export\Mixed-Precision Quantization for Language Models_ Techniques and Prospects.md
2025-11-09 21:26:52,092 - INFO - root - 正在总结论文 13/40: SPLite Hand: Sparsity-Aware Lightweight 3D Hand Pose Estimation
2025-11-09 21:26:52,094 - INFO - root - LLMClient: rate limit reached, sleeping 9.4s
2025-11-09 21:27:11,444 - INFO - root - LLMClient: rate limit reached, sleeping 15.8s
2025-11-09 21:27:55,394 - INFO - root - LLMClient: rate limit reached, sleeping 6.1s
2025-11-09 21:28:20,315 - INFO - root - 正在提取论文图片...
2025-11-09 21:28:23,476 - INFO - root - 已保存图片 1/10：./export\images_SPLite Hand_ Sparsity-Aware Lightweight 3D Hand Pose Estimation\figure_1_page3.jpeg
2025-11-09 21:28:24,254 - INFO - root - 已保存图片 2/10：./export\images_SPLite Hand_ Sparsity-Aware Lightweight 3D Hand Pose Estimation\figure_2_page8.png
2025-11-09 21:28:24,571 - INFO - root - 已保存图片 3/10：./export\images_SPLite Hand_ Sparsity-Aware Lightweight 3D Hand Pose Estimation\figure_3_page8.png
2025-11-09 21:28:24,928 - INFO - root - 已保存图片 4/10：./export\images_SPLite Hand_ Sparsity-Aware Lightweight 3D Hand Pose Estimation\figure_4_page10.png
2025-11-09 21:28:25,221 - INFO - root - 已保存图片 5/10：./export\images_SPLite Hand_ Sparsity-Aware Lightweight 3D Hand Pose Estimation\figure_5_page9.png
2025-11-09 21:28:25,280 - INFO - root - 成功添加图片 1：./export\images_SPLite Hand_ Sparsity-Aware Lightweight 3D Hand Pose Estimation\figure_1_page3.jpeg
2025-11-09 21:28:25,290 - INFO - root - 成功添加图片 2：./export\images_SPLite Hand_ Sparsity-Aware Lightweight 3D Hand Pose Estimation\figure_2_page8.png
2025-11-09 21:28:25,301 - INFO - root - 成功添加图片 3：./export\images_SPLite Hand_ Sparsity-Aware Lightweight 3D Hand Pose Estimation\figure_3_page8.png
2025-11-09 21:28:25,316 - INFO - root - 成功添加图片 4：./export\images_SPLite Hand_ Sparsity-Aware Lightweight 3D Hand Pose Estimation\figure_4_page10.png
2025-11-09 21:28:25,366 - INFO - root - 成功添加图片 5：./export\images_SPLite Hand_ Sparsity-Aware Lightweight 3D Hand Pose Estimation\figure_5_page9.png
2025-11-09 21:28:25,380 - INFO - root - 论文《SPLite Hand: Sparsity-Aware Lightweight 3D Hand Pose Estimation》的分析已保存到 ./export\SPLite Hand_ Sparsity-Aware Lightweight 3D Hand Pose Estimation.md
2025-11-09 21:28:25,385 - INFO - root - 正在总结论文 14/40: CTR-LoRA: Curvature-Aware and Trust-Region Guided Low-Rank Adaptation for Large Language Models
2025-11-09 21:28:25,386 - INFO - root - LLMClient: rate limit reached, sleeping 1.9s
2025-11-09 21:28:38,613 - INFO - root - LLMClient: rate limit reached, sleeping 22.9s
2025-11-09 21:29:50,653 - INFO - root - 正在提取论文图片...
2025-11-09 21:29:51,070 - INFO - root - 已保存图片 1/10：./export\images_CTR-LoRA_ Curvature-Aware and Trust-Region Guided Low-Rank Adaptation for Large\figure_1_page3.png
2025-11-09 21:29:51,154 - INFO - root - 已保存图片 2/10：./export\images_CTR-LoRA_ Curvature-Aware and Trust-Region Guided Low-Rank Adaptation for Large\figure_2_page1.png
2025-11-09 21:29:51,158 - INFO - root - 成功添加图片 1：./export\images_CTR-LoRA_ Curvature-Aware and Trust-Region Guided Low-Rank Adaptation for Large\figure_1_page3.png
2025-11-09 21:29:51,159 - INFO - root - 成功添加图片 2：./export\images_CTR-LoRA_ Curvature-Aware and Trust-Region Guided Low-Rank Adaptation for Large\figure_2_page1.png
2025-11-09 21:29:51,168 - INFO - root - 论文《CTR-LoRA: Curvature-Aware and Trust-Region Guided Low-Rank Adaptation for Large Language Models》的分析已保存到 ./export\CTR-LoRA_ Curvature-Aware and Trust-Region Guided Low-Rank Adaptation for Large.md
2025-11-09 21:29:51,175 - INFO - root - 正在总结论文 15/40: SANR: Scene-Aware Neural Representation for Light Field Image Compression with Rate-Distortion Optimization
2025-11-09 21:29:51,175 - INFO - root - LLMClient: rate limit reached, sleeping 10.3s
2025-11-09 21:30:11,215 - INFO - root - LLMClient: rate limit reached, sleeping 20.7s
2025-11-09 21:32:00,506 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-09 21:32:00,508 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-09 21:32:00,512 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-09 21:32:01,688 - INFO - root - LLMClientManager: 指定使用客户端: Gemini
2025-11-09 21:32:02,454 - INFO - root - GeminiClient: trying model models/gemini-2.5-flash
2025-11-09 21:32:04,768 - INFO - root - GeminiClient: initialized model gemini-2.5-flash
2025-11-09 21:32:04,777 - INFO - root - LLMClientManager: Gemini 客户端初始化成功
2025-11-09 21:32:04,782 - INFO - root - LLMClientManager: switched to Gemini client
2025-11-09 21:32:04,785 - INFO - root - 已手动切换到 LLM 客户端: Gemini
2025-11-09 21:32:04,789 - INFO - root - 使用 LLM 模型: gemini-2.5-flash
2025-11-09 21:32:04,792 - INFO - root - 可用客户端: ['Gemini']
2025-11-09 21:32:04,794 - INFO - root - === 运行配置 ===
2025-11-09 21:32:04,799 - INFO - root - 处理模式: arxiv在线搜索
2025-11-09 21:32:04,803 - INFO - root - 关键词: QAT
2025-11-09 21:32:04,808 - INFO - root - 查询: Quantization-Aware-Training
2025-11-09 21:32:04,813 - INFO - root - 排序: None
2025-11-09 21:32:04,817 - INFO - root - 最近天数: 180
2025-11-09 21:32:04,819 - INFO - root - 最大处理数量: 40
2025-11-09 21:32:04,823 - INFO - root - 保存图片: 是
2025-11-09 21:32:04,825 - INFO - root - 输出语言: 中文
2025-11-09 21:32:04,828 - INFO - root - 强制重新处理: 否
2025-11-09 21:32:04,834 - INFO - root - ====================
2025-11-09 21:32:04,837 - INFO - root - 使用 arXiv 搜索模式（通过 chat_arxiv 模块获取）
2025-11-09 21:32:04,840 - INFO - root - Fetching page 1 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50
2025-11-09 21:32:12,412 - INFO - root - get_all_titles_from_web 
2025-11-09 21:32:12,413 - INFO - root - Page:0, Index:0, A Quantized VAE-MLP Botnet Detection Model: A Systematic Evaluation of Quantization-Aware Training and Post-Training Quantization Strategies, https://arxiv.org/pdf/2511.03201, 2025-11-05
2025-11-09 21:32:12,413 - INFO - root - Page:0, Index:1, FP8-Flow-MoE: A Casting-Free FP8 Recipe without Double Quantization Error, https://arxiv.org/pdf/2511.02302, 2025-11-04
2025-11-09 21:32:12,413 - INFO - root - Page:0, Index:2, Outlier-Aware Post-Training Quantization for Image Super-Resolution, https://arxiv.org/pdf/2511.00682, 2025-11-01
2025-11-09 21:32:12,413 - INFO - root - Page:0, Index:3, Evaluation of Wafer-Scale SOT-MRAM for Analog Crossbar Array Applications, https://arxiv.org/pdf/2510.25853, 2025-11-03
2025-11-09 21:32:12,414 - INFO - root - Page:0, Index:4, Improving the Straight-Through Estimator with Zeroth-Order Information, https://arxiv.org/pdf/2510.23926, 2025-10-27
2025-11-09 21:32:12,414 - INFO - root - Page:0, Index:5, Real-Time Semantic Segmentation on FPGA for Autonomous Vehicles Using LMIINet with the CGRA4ML Framework, https://arxiv.org/pdf/2510.22243, 2025-10-25
2025-11-09 21:32:12,414 - INFO - root - Page:0, Index:6, TernaryCLIP: Efficiently Compressing Vision-Language Models with Ternary Weights and Distilled Knowledge, https://arxiv.org/pdf/2510.21879, 2025-10-23
2025-11-09 21:32:12,415 - INFO - root - Page:0, Index:7, KARIPAP: Quantum-Inspired Tensor Network Compression of Large Language Models Using Infinite Projected Entangled Pair States and Tensor Renormalization Group, https://arxiv.org/pdf/2510.21844, 2025-10-22
2025-11-09 21:32:12,415 - INFO - root - Page:0, Index:8, A Convergence Analysis of Adaptive Optimizers under Floating-point Quantization, https://arxiv.org/pdf/2510.21314, 2025-10-24
2025-11-09 21:32:12,415 - INFO - root - Page:0, Index:9, Adaptive Distribution-aware Quantization for Mixed-Precision Neural Networks, https://arxiv.org/pdf/2510.19760, 2025-10-22
2025-11-09 21:32:12,415 - INFO - root - Page:0, Index:10, CAGE: Curvature-Aware Gradient Estimation For Accurate Quantization-Aware Training, https://arxiv.org/pdf/2510.18784, 2025-10-21
2025-11-09 21:32:12,416 - INFO - root - Page:0, Index:11, Mixed-Precision Quantization for Language Models: Techniques and Prospects, https://arxiv.org/pdf/2510.16805, 2025-10-19
2025-11-09 21:32:12,416 - INFO - root - Page:0, Index:12, SPLite Hand: Sparsity-Aware Lightweight 3D Hand Pose Estimation, https://arxiv.org/pdf/2510.16396, 2025-10-30
2025-11-09 21:32:12,416 - INFO - root - Page:0, Index:13, CTR-LoRA: Curvature-Aware and Trust-Region Guided Low-Rank Adaptation for Large Language Models, https://arxiv.org/pdf/2510.15962, 2025-10-11
2025-11-09 21:32:12,416 - INFO - root - Page:0, Index:14, SANR: Scene-Aware Neural Representation for Light Field Image Compression with Rate-Distortion Optimization, https://arxiv.org/pdf/2510.15775, 2025-10-17
2025-11-09 21:32:12,417 - INFO - root - Page:0, Index:15, SpikeFit: Towards Optimal Deployment of Spiking Networks on Neuromorphic Hardware, https://arxiv.org/pdf/2510.15542, 2025-10-31
2025-11-09 21:32:12,417 - INFO - root - Page:0, Index:16, GRank: Towards Target-Aware and Streamlined Industrial Retrieval with a Generate-Rank Framework, https://arxiv.org/pdf/2510.15299, 2025-10-17
2025-11-09 21:32:12,417 - INFO - root - Page:0, Index:17, SaLon3R: Structure-aware Long-term Generalizable 3D Reconstruction from Unposed Images, https://arxiv.org/pdf/2510.15072, 2025-10-16
2025-11-09 21:32:12,418 - INFO - root - Page:0, Index:18, FraQAT: Quantization Aware Training with Fractional bits, https://arxiv.org/pdf/2510.14823, 2025-10-16
2025-11-09 21:32:12,418 - INFO - root - Page:0, Index:19, Computing-In-Memory Aware Model Adaption For Edge Devices, https://arxiv.org/pdf/2510.14379, 2025-10-16
2025-11-09 21:32:12,418 - INFO - root - Page:0, Index:20, Invited Paper: BitMedViT: Ternary-Quantized Vision Transformer for Medical AI Assistants on the Edge, https://arxiv.org/pdf/2510.13760, 2025-11-04
2025-11-09 21:32:12,418 - INFO - root - Page:0, Index:21, NeuroRVQ: Multi-Scale EEG Tokenization for Generative Large Brainwave Models, https://arxiv.org/pdf/2510.13068, 2025-10-14
2025-11-09 21:32:12,419 - INFO - root - Page:0, Index:22, Detect Anything via Next Point Prediction, https://arxiv.org/pdf/2510.12798, 2025-10-14
2025-11-09 21:32:12,420 - INFO - root - Page:0, Index:23, AndesVL Technical Report: An Efficient Mobile-side Multimodal Large Language Model, https://arxiv.org/pdf/2510.11496, 2025-10-14
2025-11-09 21:32:12,420 - INFO - root - Page:0, Index:24, Rescaling-Aware Training for Efficient Deployment of Deep Learning Models on Full-Integer Hardware, https://arxiv.org/pdf/2510.11484, 2025-10-13
2025-11-09 21:32:12,421 - INFO - root - Page:0, Index:25, SASER: Stego attacks on open-source LLMs, https://arxiv.org/pdf/2510.10486, 2025-10-12
2025-11-09 21:32:12,421 - INFO - root - Page:0, Index:26, Ultralytics YOLO Evolution: An Overview of YOLO26, YOLO11, YOLOv8 and YOLOv5 Object Detectors for Computer Vision and Pattern Recognition, https://arxiv.org/pdf/2510.09653, 2025-10-15
2025-11-09 21:32:12,422 - INFO - root - Page:0, Index:27, A Theoretically-Grounded Codebook for Digital Semantic Communications, https://arxiv.org/pdf/2510.07108, 2025-10-14
2025-11-09 21:32:12,423 - INFO - root - Page:0, Index:28, QuantDemoire: Quantization with Outlier Aware for Image Demoiréing, https://arxiv.org/pdf/2510.04066, 2025-10-05
2025-11-09 21:32:12,423 - INFO - root - Page:0, Index:29, Adaptively Sampling-Reusing-Mixing Decomposed Gradients to Speed Up Sharpness Aware Minimization, https://arxiv.org/pdf/2510.03763, 2025-10-04
2025-11-09 21:32:12,424 - INFO - root - Page:0, Index:30, Quant-dLLM: Post-Training Extreme Low-Bit Quantization for Diffusion Large Language Models, https://arxiv.org/pdf/2510.03274, 2025-09-27
2025-11-09 21:32:12,424 - INFO - root - Page:0, Index:31, PT$^2$-LLM: Post-Training Ternarization for Large Language Models, https://arxiv.org/pdf/2510.03267, 2025-09-26
2025-11-09 21:32:12,424 - INFO - root - Page:0, Index:32, Purrception: Variational Flow Matching for Vector-Quantized Image Generation, https://arxiv.org/pdf/2510.01478, 2025-10-01
2025-11-09 21:32:12,426 - INFO - root - Page:0, Index:33, Post-Training Quantization for Audio Diffusion Transformers, https://arxiv.org/pdf/2510.00313, 2025-09-30
2025-11-09 21:32:12,426 - INFO - root - Page:0, Index:34, Rethinking RoPE Scaling in Quantized LLM: Theory, Outlier, and Channel-Band Analysis with Weight Rescaling, https://arxiv.org/pdf/2510.00028, 2025-09-25
2025-11-09 21:32:12,426 - INFO - root - Page:0, Index:35, Post-Training Quantization via Residual Truncation and Zero Suppression for Diffusion Models, https://arxiv.org/pdf/2509.26436, 2025-09-30
2025-11-09 21:32:12,427 - INFO - root - Page:0, Index:36, Cat: Post-Training Quantization Error Reduction via Cluster-based Affine Transformation, https://arxiv.org/pdf/2509.26277, 2025-10-07
2025-11-09 21:32:12,427 - INFO - root - Page:0, Index:37, CAST: Continuous and Differentiable Semi-Structured Sparsity-Aware Training for Large Language Models, https://arxiv.org/pdf/2509.25996, 2025-09-30
2025-11-09 21:32:12,427 - INFO - root - Page:0, Index:38, Norm-Q: Effective Compression Method for Hidden Markov Models in Neuro-Symbolic Applications, https://arxiv.org/pdf/2509.25439, 2025-09-29
2025-11-09 21:32:12,427 - INFO - root - Page:0, Index:39, On-the-Fly Adaptation to Quantization: Configuration-Aware LoRA for Efficient Fine-Tuning of Quantized LLMs, https://arxiv.org/pdf/2509.25214, 2025-09-22
2025-11-09 21:32:12,429 - INFO - root - Page:0, Index:40, VoxCPM: Tokenizer-Free TTS for Context-Aware Speech Generation and True-to-Life Voice Cloning, https://arxiv.org/pdf/2509.24650, 2025-09-29
2025-11-09 21:32:12,429 - INFO - root - Page:0, Index:41, S$^2$NN: Sub-bit Spiking Neural Networks, https://arxiv.org/pdf/2509.24266, 2025-10-24
2025-11-09 21:32:12,430 - INFO - root - Page:0, Index:42, Tequila: Trapping-free Ternary Quantization for Large Language Models, https://arxiv.org/pdf/2509.23809, 2025-10-17
2025-11-09 21:32:12,430 - INFO - root - Page:0, Index:43, Texture Vector-Quantization and Reconstruction Aware Prediction for Generative Super-Resolution, https://arxiv.org/pdf/2509.23774, 2025-09-30
2025-11-09 21:32:12,430 - INFO - root - Page:0, Index:44, RobuQ: Pushing DiTs to W1.58A2 via Robust Activation Quantization, https://arxiv.org/pdf/2509.23582, 2025-09-27
2025-11-09 21:32:12,430 - INFO - root - Page:0, Index:45, Beyond Outliers: A Study of Optimizers Under Quantization, https://arxiv.org/pdf/2509.23500, 2025-10-02
2025-11-09 21:32:12,431 - INFO - root - Page:0, Index:46, Compute-Optimal Quantization-Aware Training, https://arxiv.org/pdf/2509.22935, 2025-09-26
2025-11-09 21:32:12,431 - INFO - root - Page:0, Index:47, COSPADI: Compressing LLMs via Calibration-Guided Sparse Dictionary Learning, https://arxiv.org/pdf/2509.22075, 2025-10-06
2025-11-09 21:32:12,432 - INFO - root - Page:0, Index:48, SlimDiff: Training-Free, Activation-Guided Hands-free Slimming of Diffusion Models, https://arxiv.org/pdf/2509.21498, 2025-09-25
2025-11-09 21:32:12,432 - INFO - root - Page:0, Index:49, Quantized Visual Geometry Grounded Transformer, https://arxiv.org/pdf/2509.21302, 2025-09-29
2025-11-09 21:32:12,432 - INFO - root - Fetching page 2 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=50
2025-11-09 21:32:19,102 - INFO - root - get_all_titles_from_web 
2025-11-09 21:32:19,102 - INFO - root - Page:1, Index:0, Can Less Precise Be More Reliable? A Systematic Evaluation of Quantization's Impact on CLIP Beyond Accuracy, https://arxiv.org/pdf/2509.21173, 2025-10-27
2025-11-09 21:32:19,103 - INFO - root - Page:1, Index:1, Punching Above Precision: Small Quantized Model Distillation with Learnable Regularizer, https://arxiv.org/pdf/2509.20854, 2025-09-25
2025-11-09 21:32:19,103 - INFO - root - Page:1, Index:2, TinyEcoWeedNet: Edge Efficient Real-Time Aerial Agricultural Weed Detection, https://arxiv.org/pdf/2509.18193, 2025-09-19
2025-11-09 21:32:19,103 - INFO - root - Page:1, Index:3, SBVR: Summation of BitVector Representation for Efficient LLM Quantization, https://arxiv.org/pdf/2509.18172, 2025-09-17
2025-11-09 21:32:19,103 - INFO - root - Page:1, Index:4, QWHA: Quantization-Aware Walsh-Hadamard Adaptation for Parameter-Efficient Fine-Tuning on Large Language Models, https://arxiv.org/pdf/2509.17428, 2025-09-26
2025-11-09 21:32:19,104 - INFO - root - Page:1, Index:5, PTQTP: Post-Training Quantization to Trit-Planes for Large Language Models, https://arxiv.org/pdf/2509.16989, 2025-10-28
2025-11-09 21:32:19,104 - INFO - root - Page:1, Index:6, MEC-Quant: Maximum Entropy Coding for Extremely Low Bit Quantization-Aware Training, https://arxiv.org/pdf/2509.15514, 2025-09-18
2025-11-09 21:32:19,104 - INFO - root - Page:1, Index:7, Q-ROAR: Outlier-Aware Rescaling for RoPE Position Interpolation in Quantized Long-Context LLMs, https://arxiv.org/pdf/2509.14391, 2025-09-17
2025-11-09 21:32:19,104 - INFO - root - Page:1, Index:8, Efficient Quantization-Aware Neural Receivers: Beyond Post-Training Quantization, https://arxiv.org/pdf/2509.13786, 2025-09-19
2025-11-09 21:32:19,105 - INFO - root - Page:1, Index:9, Rate-Distortion Limits for Multimodal Retrieval: Theory, Optimal Codes, and Finite-Sample Guarantees, https://arxiv.org/pdf/2509.11054, 2025-09-13
2025-11-09 21:32:19,105 - INFO - root - Page:1, Index:10, SQAP-VLA: A Synergistic Quantization-Aware Pruning Framework for High-Performance Vision-Language-Action Models, https://arxiv.org/pdf/2509.09090, 2025-09-10
2025-11-09 21:32:19,105 - INFO - root - Page:1, Index:11, CSI Compression Beyond Latents: End-to-End Hybrid Attention-CNN Networks with Entropy Regularization, https://arxiv.org/pdf/2509.08776, 2025-09-10
2025-11-09 21:32:19,105 - INFO - root - Page:1, Index:12, Explaining How Quantization Disparately Skews a Model, https://arxiv.org/pdf/2509.07222, 2025-09-08
2025-11-09 21:32:19,106 - INFO - root - Page:1, Index:13, LoaQ: Layer-wise Output Approximation Quantization, https://arxiv.org/pdf/2509.06297, 2025-09-07
2025-11-09 21:32:19,106 - INFO - root - Page:1, Index:14, FineServe: Precision-Aware KV Slab and Two-Level Scheduling for Heterogeneous Precision LLM Serving, https://arxiv.org/pdf/2509.06261, 2025-09-14
2025-11-09 21:32:19,106 - INFO - root - Page:1, Index:15, Sensitivity-Aware Post-Training Quantization for Deep Neural Networks, https://arxiv.org/pdf/2509.05576, 2025-09-05
2025-11-09 21:32:19,106 - INFO - root - Page:1, Index:16, SuperSNN: A Hardware-Aware Framework for Physically Realizable, High-Performance Superconducting Spiking Neural Network Chips, https://arxiv.org/pdf/2509.05532, 2025-09-05
2025-11-09 21:32:19,107 - INFO - root - Page:1, Index:17, Data-Augmented Quantization-Aware Knowledge Distillation, https://arxiv.org/pdf/2509.03850, 2025-09-03
2025-11-09 21:32:19,107 - INFO - root - Page:1, Index:18, DPQuant: Efficient and Differentially-Private Model Training via Dynamic Quantization Scheduling, https://arxiv.org/pdf/2509.03472, 2025-09-03
2025-11-09 21:32:19,107 - INFO - root - Page:1, Index:19, Empowering Large Language Model for Sequential Recommendation via Multimodal Embeddings and Semantic IDs, https://arxiv.org/pdf/2509.02017, 2025-09-02
2025-11-09 21:32:19,108 - INFO - root - Page:1, Index:20, Q-Sched: Pushing the Boundaries of Few-Step Diffusion Models with Quantization-Aware Scheduling, https://arxiv.org/pdf/2509.01624, 2025-09-01
2025-11-09 21:32:19,108 - INFO - root - Page:1, Index:21, Quantization Meets OOD: Generalizable Quantization-aware Training from a Flatness Perspective, https://arxiv.org/pdf/2509.00859, 2025-08-31
2025-11-09 21:32:19,108 - INFO - root - Page:1, Index:22, Progressive Element-wise Gradient Estimation for Neural Network Quantization, https://arxiv.org/pdf/2509.00097, 2025-08-27
2025-11-09 21:32:19,109 - INFO - root - Page:1, Index:23, End-to-End On-Device Quantization-Aware Training for LLMs at Inference Cost, https://arxiv.org/pdf/2509.00031, 2025-09-29
2025-11-09 21:32:19,109 - INFO - root - Page:1, Index:24, Quantization Robustness to Input Degradations for Object Detection, https://arxiv.org/pdf/2508.19600, 2025-08-27
2025-11-09 21:32:19,109 - INFO - root - Page:1, Index:25, Scaling Laws for Task-Stratified Knowledge in Post-Training Quantized Large Language Models, https://arxiv.org/pdf/2508.18609, 2025-08-27
2025-11-09 21:32:19,110 - INFO - root - Page:1, Index:26, AQ-PCDSys: An Adaptive Quantized Planetary Crater Detection System for Autonomous Space Exploration, https://arxiv.org/pdf/2508.18025, 2025-08-25
2025-11-09 21:32:19,110 - INFO - root - Page:1, Index:27, TaDiCodec: Text-aware Diffusion Speech Tokenizer for Speech Language Modeling, https://arxiv.org/pdf/2508.16790, 2025-08-22
2025-11-09 21:32:19,112 - INFO - root - Page:1, Index:28, A Node-Aware Dynamic Quantization Approach for Graph Collaborative Filtering, https://arxiv.org/pdf/2508.16516, 2025-08-22
2025-11-09 21:32:19,113 - INFO - root - Page:1, Index:29, JEDI-linear: Fast and Efficient Graph Neural Networks for Jet Tagging on FPGAs, https://arxiv.org/pdf/2508.15468, 2025-08-21
2025-11-09 21:32:19,113 - INFO - root - Page:1, Index:30, MMQ: Multimodal Mixture-of-Quantization Tokenization for Semantic ID Generation and User Behavioral Adaptation, https://arxiv.org/pdf/2508.15281, 2025-08-21
2025-11-09 21:32:19,114 - INFO - root - Page:1, Index:31, DLLMQuant: Quantizing Diffusion-based Large Language Models, https://arxiv.org/pdf/2508.14090, 2025-08-25
2025-11-09 21:32:19,114 - INFO - root - Page:1, Index:32, Automated Energy-Aware Time-Series Model Deployment on Embedded FPGAs for Resilient Combined Sewer Overflow Management, https://arxiv.org/pdf/2508.13905, 2025-08-19
2025-11-09 21:32:19,115 - INFO - root - Page:1, Index:33, XR-NPE: High-Throughput Mixed-precision SIMD Neural Processing Engine for Extended Reality Perception Workloads, https://arxiv.org/pdf/2508.13049, 2025-08-18
2025-11-09 21:32:19,115 - INFO - root - Page:1, Index:34, Exploring Self-Supervised Audio Models for Generalized Anomalous Sound Detection, https://arxiv.org/pdf/2508.12230, 2025-08-17
2025-11-09 21:32:19,115 - INFO - root - Page:1, Index:35, TriQDef: Disrupting Semantic and Gradient Alignment to Prevent Adversarial Patch Transferability in Quantized Neural Networks, https://arxiv.org/pdf/2508.12132, 2025-08-16
2025-11-09 21:32:19,115 - INFO - root - Page:1, Index:36, Error Propagation Mechanisms and Compensation Strategies for Quantized Diffusion, https://arxiv.org/pdf/2508.12094, 2025-10-13
2025-11-09 21:32:19,116 - INFO - root - Page:1, Index:37, Extending Straight-Through Estimation for Robust Neural Networks on Analog CIM Hardware, https://arxiv.org/pdf/2508.11940, 2025-08-16
2025-11-09 21:32:19,116 - INFO - root - Page:1, Index:38, PTQAT: A Hybrid Parameter-Efficient Quantization Algorithm for 3D Perception Tasks, https://arxiv.org/pdf/2508.10557, 2025-08-15
2025-11-09 21:32:19,116 - INFO - root - Page:1, Index:39, MiCo: End-to-End Mixed Precision Neural Network Co-Exploration Framework for Edge AI, https://arxiv.org/pdf/2508.09500, 2025-08-13
2025-11-09 21:32:19,117 - INFO - root - Page:1, Index:40, SPARC: Soft Probabilistic Adaptive multi-interest Retrieval Model via Codebooks for recommender system, https://arxiv.org/pdf/2508.09090, 2025-08-12
2025-11-09 21:32:19,117 - INFO - root - Page:1, Index:41, Rethinking 1-bit Optimization Leveraging Pre-trained Large Language Models, https://arxiv.org/pdf/2508.06974, 2025-08-09
2025-11-09 21:32:19,118 - INFO - root - Page:1, Index:42, Efficient Deep Neural Receiver with Post-Training Quantization, https://arxiv.org/pdf/2508.06275, 2025-08-08
2025-11-09 21:32:19,118 - INFO - root - Page:1, Index:43, iFairy: the First 2-bit Complex LLM with All Parameters in $\{\pm1, \pm i\}$, https://arxiv.org/pdf/2508.05571, 2025-08-16
2025-11-09 21:32:19,119 - INFO - root - Page:1, Index:44, S$^2$Q-VDiT: Accurate Quantized Video Diffusion Transformer with Salient Data and Sparse Token Distillation, https://arxiv.org/pdf/2508.04016, 2025-10-27
2025-11-09 21:32:19,119 - INFO - root - Page:1, Index:45, LRQ-DiT: Log-Rotation Post-Training Quantization of Diffusion Transformers for Image and Video Generation, https://arxiv.org/pdf/2508.03485, 2025-09-23
2025-11-09 21:32:19,119 - INFO - root - Page:1, Index:46, VLMQ: Efficient Post-Training Quantization for Large Vision-Language Models via Hessian Augmentation, https://arxiv.org/pdf/2508.03351, 2025-08-05
2025-11-09 21:32:19,120 - INFO - root - Page:1, Index:47, TF-MLPNet: Tiny Real-Time Neural Speech Separation, https://arxiv.org/pdf/2508.03047, 2025-08-04
2025-11-09 21:32:19,120 - INFO - root - Page:1, Index:48, SaviorRec: Semantic-Behavior Alignment for Cold-Start Recommendation, https://arxiv.org/pdf/2508.01375, 2025-08-02
2025-11-09 21:32:19,120 - INFO - root - Page:1, Index:49, MixA-Q: Revisiting Activation Sparsity for Vision Transformers from a Mixed-Precision Quantization Perspective, https://arxiv.org/pdf/2507.19131, 2025-07-25
2025-11-09 21:32:19,121 - INFO - root - Fetching page 3 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=100
2025-11-09 21:32:26,679 - INFO - root - get_all_titles_from_web 
2025-11-09 21:32:26,680 - INFO - root - Page:2, Index:0, Enhancing Quantization-Aware Training on Edge Devices via Relative Entropy Coreset Selection and Cascaded Layer Correction, https://arxiv.org/pdf/2507.17768, 2025-07-16
2025-11-09 21:32:26,680 - INFO - root - Page:2, Index:1, SiLQ: Simple Large Language Model Quantization-Aware Training, https://arxiv.org/pdf/2507.16933, 2025-07-22
2025-11-09 21:32:26,680 - INFO - root - Page:2, Index:2, Task-Specific Zero-shot Quantization-Aware Training for Object Detection, https://arxiv.org/pdf/2507.16782, 2025-07-22
2025-11-09 21:32:26,681 - INFO - root - Page:2, Index:3, TorchAO: PyTorch-Native Training-to-Serving Model Optimization, https://arxiv.org/pdf/2507.16099, 2025-07-21
2025-11-09 21:32:26,681 - INFO - root - Page:2, Index:4, SegQuant: A Semantics-Aware and Generalizable Quantization Framework for Diffusion Models, https://arxiv.org/pdf/2507.14811, 2025-08-27
2025-11-09 21:32:26,681 - INFO - root - Page:2, Index:5, Apple Intelligence Foundation Language Models: Tech Report 2025, https://arxiv.org/pdf/2507.13575, 2025-08-27
2025-11-09 21:32:26,681 - INFO - root - Page:2, Index:6, Generative Multi-Target Cross-Domain Recommendation, https://arxiv.org/pdf/2507.12871, 2025-08-07
2025-11-09 21:32:26,681 - INFO - root - Page:2, Index:7, DAF: An Efficient End-to-End Dynamic Activation Framework for on-Device DNN Training, https://arxiv.org/pdf/2507.07149, 2025-07-09
2025-11-09 21:32:26,682 - INFO - root - Page:2, Index:8, Opto-ViT: Architecting a Near-Sensor Region of Interest-Aware Vision Transformer Accelerator with Silicon Photonics, https://arxiv.org/pdf/2507.07044, 2025-07-15
2025-11-09 21:32:26,682 - INFO - root - Page:2, Index:9, QS4D: Quantization-aware training for efficient hardware deployment of structured state-space sequential models, https://arxiv.org/pdf/2507.06079, 2025-07-08
2025-11-09 21:32:26,682 - INFO - root - Page:2, Index:10, GSVR: 2D Gaussian-based Video Representation for 800+ FPS with Hybrid Deformation Field, https://arxiv.org/pdf/2507.05594, 2025-07-07
2025-11-09 21:32:26,684 - INFO - root - Page:2, Index:11, Hita: Holistic Tokenizer for Autoregressive Image Generation, https://arxiv.org/pdf/2507.02358, 2025-07-11
2025-11-09 21:32:26,684 - INFO - root - Page:2, Index:12, QPART: Adaptive Model Quantization and Dynamic Workload Balancing for Accuracy-aware Edge Inference, https://arxiv.org/pdf/2506.23934, 2025-06-30
2025-11-09 21:32:26,685 - INFO - root - Page:2, Index:13, FedWSQ: Efficient Federated Learning with Weight Standardization and Distribution-Aware Non-Uniform Quantization, https://arxiv.org/pdf/2506.23516, 2025-07-21
2025-11-09 21:32:26,686 - INFO - root - Page:2, Index:14, Spectra 1.1: Scaling Laws and Efficient Inference for Ternary Language Models, https://arxiv.org/pdf/2506.23025, 2025-06-28
2025-11-09 21:32:26,687 - INFO - root - Page:2, Index:15, Joint Quantization and Pruning Neural Networks Approach: A Case Study on FSO Receivers, https://arxiv.org/pdf/2506.20084, 2025-06-24
2025-11-09 21:32:26,687 - INFO - root - Page:2, Index:16, Single-step Diffusion for Image Compression at Ultra-Low Bitrates, https://arxiv.org/pdf/2506.16572, 2025-09-22
2025-11-09 21:32:26,687 - INFO - root - Page:2, Index:17, LittleBit: Ultra Low-Bit Quantization via Latent Factorization, https://arxiv.org/pdf/2506.13771, 2025-10-28
2025-11-09 21:32:26,687 - INFO - root - Page:2, Index:18, MARCO: Hardware-Aware Neural Architecture Search for Edge Devices with Multi-Agent Reinforcement Learning and Conformal Prediction Filtering, https://arxiv.org/pdf/2506.13755, 2025-06-16
2025-11-09 21:32:26,688 - INFO - root - Page:2, Index:19, EAQuant: Enhancing Post-Training Quantization for MoE Models via Expert-Aware Optimization, https://arxiv.org/pdf/2506.13329, 2025-07-04
2025-11-09 21:32:26,688 - INFO - root - Page:2, Index:20, Towards Neural Audio Codec Source Parsing, https://arxiv.org/pdf/2506.12627, 2025-06-14
2025-11-09 21:32:26,688 - INFO - root - Page:2, Index:21, Quantizing Small-Scale State-Space Models for Edge AI, https://arxiv.org/pdf/2506.12480, 2025-06-14
2025-11-09 21:32:26,689 - INFO - root - Page:2, Index:22, EMLoC: Emulator-based Memory-efficient Fine-tuning with LoRA Correction, https://arxiv.org/pdf/2506.12015, 2025-06-13
2025-11-09 21:32:26,689 - INFO - root - Page:2, Index:23, Compression Aware Certified Training, https://arxiv.org/pdf/2506.11992, 2025-06-13
2025-11-09 21:32:26,689 - INFO - root - Page:2, Index:24, GPLQ: A General, Practical, and Lightning QAT Method for Vision Transformers, https://arxiv.org/pdf/2506.11784, 2025-06-13
2025-11-09 21:32:26,690 - INFO - root - Page:2, Index:25, TruncQuant: Truncation-Ready Quantization for DNNs with Flexible Weight Bit Precision, https://arxiv.org/pdf/2506.11431, 2025-06-12
2025-11-09 21:32:26,690 - INFO - root - Page:2, Index:26, EfficientQuant: An Efficient Post-Training Quantization for CNN-Transformer Hybrid Models on Edge Devices, https://arxiv.org/pdf/2506.11093, 2025-06-05
2025-11-09 21:32:26,690 - INFO - root - Page:2, Index:27, Starting Positions Matter: A Study on Better Weight Initialization for Neural Network Quantization, https://arxiv.org/pdf/2506.10463, 2025-06-12
2025-11-09 21:32:26,691 - INFO - root - Page:2, Index:28, AWP: Activation-Aware Weight Pruning and Quantization with Projected Gradient Descent, https://arxiv.org/pdf/2506.10205, 2025-06-11
2025-11-09 21:32:26,691 - INFO - root - Page:2, Index:29, Q-SAM2: Accurate Quantization for Segment Anything Model 2, https://arxiv.org/pdf/2506.09782, 2025-06-11
2025-11-09 21:32:26,692 - INFO - root - Page:2, Index:30, Unifying Block-wise PTQ and Distillation-based QAT for Progressive Quantization toward 2-bit Instruction-Tuned LLMs, https://arxiv.org/pdf/2506.09104, 2025-06-10
2025-11-09 21:32:26,692 - INFO - root - Page:2, Index:31, Implementing Keyword Spotting on the MCUX947 Microcontroller with Integrated NPU, https://arxiv.org/pdf/2506.08911, 2025-06-10
2025-11-09 21:32:26,692 - INFO - root - Page:2, Index:32, POLARON: Precision-aware On-device Learning and Adaptive Runtime-cONfigurable AI acceleration, https://arxiv.org/pdf/2506.08785, 2025-06-10
2025-11-09 21:32:26,693 - INFO - root - Page:2, Index:33, MoQAE: Mixed-Precision Quantization for Long-Context LLM Inference via Mixture of Quantization-Aware Experts, https://arxiv.org/pdf/2506.07533, 2025-06-09
2025-11-09 21:32:26,693 - INFO - root - Page:2, Index:34, BitVLA: 1-bit Vision-Language-Action Models for Robotics Manipulation, https://arxiv.org/pdf/2506.07530, 2025-06-09
2025-11-09 21:32:26,693 - INFO - root - Page:2, Index:35, RecGPT: A Foundation Model for Sequential Recommendation, https://arxiv.org/pdf/2506.06270, 2025-06-12
2025-11-09 21:32:26,693 - INFO - root - Page:2, Index:36, FPSAttention: Training-Aware FP8 and Sparsity Co-Design for Fast Video Diffusion, https://arxiv.org/pdf/2506.04648, 2025-06-05
2025-11-09 21:32:26,695 - INFO - root - Page:2, Index:37, BitTTS: Highly Compact Text-to-Speech Using 1.58-bit Quantization and Weight Indexing, https://arxiv.org/pdf/2506.03515, 2025-06-03
2025-11-09 21:32:26,695 - INFO - root - Page:2, Index:38, ShapeLLM-Omni: A Native Multimodal LLM for 3D Generation and Understanding, https://arxiv.org/pdf/2506.01853, 2025-06-02
2025-11-09 21:32:26,695 - INFO - root - Page:2, Index:39, Movable Antenna Enhanced Federated Fine-Tuning of Large Language Models via Hybrid Client Selection Optimization, https://arxiv.org/pdf/2506.00011, 2025-10-26
2025-11-09 21:32:26,695 - INFO - root - Page:2, Index:40, Running Conventional Automatic Speech Recognition on Memristor Hardware: A Simulated Approach, https://arxiv.org/pdf/2505.24721, 2025-05-30
2025-11-09 21:32:26,696 - INFO - root - Page:2, Index:41, GARLIC: GAussian Representation LearnIng for spaCe partitioning, https://arxiv.org/pdf/2505.24608, 2025-10-02
2025-11-09 21:32:26,696 - INFO - root - Page:2, Index:42, AutoChemSchematic AI: Agentic Physics-Aware Automation for Chemical Manufacturing Scale-Up, https://arxiv.org/pdf/2505.24584, 2025-08-18
2025-11-09 21:32:26,696 - INFO - root - Page:2, Index:43, Model-Preserving Adaptive Rounding, https://arxiv.org/pdf/2505.22988, 2025-09-25
2025-11-09 21:32:26,697 - INFO - root - Page:2, Index:44, Highly Efficient and Effective LLMs with Multi-Boolean Architectures, https://arxiv.org/pdf/2505.22811, 2025-10-03
2025-11-09 21:32:26,697 - INFO - root - Page:2, Index:45, Pioneering 4-Bit FP Quantization for Diffusion Models: Mixup-Sign Quantization and Timestep-Aware Fine-Tuning, https://arxiv.org/pdf/2505.21591, 2025-05-27
2025-11-09 21:32:26,697 - INFO - root - Page:2, Index:46, Frequency Composition for Compressed and Domain-Adaptive Neural Networks, https://arxiv.org/pdf/2505.20890, 2025-05-27
2025-11-09 21:32:26,698 - INFO - root - Page:2, Index:47, MoPFormer: Motion-Primitive Transformer for Wearable-Sensor Activity Recognition, https://arxiv.org/pdf/2505.20744, 2025-10-27
2025-11-09 21:32:26,698 - INFO - root - Page:2, Index:48, Optimizing edge AI models on HPC systems with the edge in the loop, https://arxiv.org/pdf/2505.19995, 2025-05-26
2025-11-09 21:32:26,698 - INFO - root - Fetching page 4 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=150
2025-11-09 21:32:33,070 - INFO - root - get_all_titles_from_web 
2025-11-09 21:32:33,070 - INFO - root - Page:3, Index:0, DPASyn: Mechanism-Aware Drug Synergy Prediction via Dual Attention and Precision-Aware Quantization, https://arxiv.org/pdf/2505.19144, 2025-09-20
2025-11-09 21:32:33,071 - INFO - root - Page:3, Index:1, Reducing Storage of Pretrained Neural Networks by Rate-Constrained Quantization and Entropy Coding, https://arxiv.org/pdf/2505.18758, 2025-05-24
2025-11-09 21:32:33,071 - INFO - root - Page:3, Index:2, Beyond Discreteness: Finite-Sample Analysis of Straight-Through Estimator for Quantization, https://arxiv.org/pdf/2505.18113, 2025-05-23
2025-11-09 21:32:33,071 - INFO - root - Page:3, Index:3, Automating Versatile Time-Series Analysis with Tiny Transformers on Embedded FPGAs, https://arxiv.org/pdf/2505.17662, 2025-09-19
2025-11-09 21:32:33,071 - INFO - root - Page:3, Index:4, FPQVAR: Floating Point Quantization for Visual Autoregressive Model with FPGA Hardware Co-design, https://arxiv.org/pdf/2505.16335, 2025-05-22
2025-11-09 21:32:33,073 - INFO - root - Page:3, Index:5, Saliency-Aware Quantized Imitation Learning for Efficient Robotic Control, https://arxiv.org/pdf/2505.15304, 2025-05-30
2025-11-09 21:32:33,073 - INFO - root - Page:3, Index:6, Scaling Law for Quantization-Aware Training, https://arxiv.org/pdf/2505.14302, 2025-05-20
2025-11-09 21:32:33,073 - INFO - root - Page:3, Index:7, Automatic mixed precision for optimizing gained time with constrained loss mean-squared-error based on model partition to sequential sub-graphs, https://arxiv.org/pdf/2505.13060, 2025-05-19
2025-11-09 21:32:33,073 - INFO - root - Page:3, Index:8, Deep Unfolding with Kernel-based Quantization in MIMO Detection, https://arxiv.org/pdf/2505.12736, 2025-05-19
2025-11-09 21:32:33,074 - INFO - root - Page:3, Index:9, FedHQ: Hybrid Runtime Quantization for Federated Learning, https://arxiv.org/pdf/2505.11982, 2025-05-17
2025-11-09 21:32:33,074 - INFO - root - Page:3, Index:10, QVGen: Pushing the Limit of Quantized Video Generative Models, https://arxiv.org/pdf/2505.11497, 2025-09-27
2025-11-09 21:32:33,074 - INFO - root - Page:3, Index:11, EA-3DGS: Efficient and Adaptive 3D Gaussians with Highly Enhanced Quality for outdoor scenes, https://arxiv.org/pdf/2505.10787, 2025-05-15
2025-11-09 21:32:33,076 - INFO - root - Page:3, Index:12, ITERA-LLM: Boosting Sub-8-Bit Large Language Model Inference via Iterative Tensor Decomposition, https://arxiv.org/pdf/2505.08981, 2025-05-13
2025-11-09 21:32:33,077 - INFO - root - Page:3, Index:13, PROM: Prioritize Reduction of Multiplications Over Lower Bit-Widths for Efficient CNNs, https://arxiv.org/pdf/2505.03254, 2025-08-06
2025-11-09 21:32:33,078 - INFO - root - Page:3, Index:14, ICQuant: Index Coding enables Low-bit LLM Quantization, https://arxiv.org/pdf/2505.00850, 2025-08-24
2025-11-09 21:32:33,078 - INFO - root - Page:3, Index:15, Enhancing Ultra-Low-Bit Quantization of Large Language Models Through Saliency-Aware Partial Retraining, https://arxiv.org/pdf/2504.13932, 2025-07-30
2025-11-09 21:32:33,079 - INFO - root - Page:3, Index:16, Achieving binary weight and activation for LLMs using Post-Training Quantization, https://arxiv.org/pdf/2504.05352, 2025-06-30
2025-11-09 21:32:33,079 - INFO - root - Page:3, Index:17, Wireless Hearables With Programmable Speech AI Accelerators, https://arxiv.org/pdf/2503.18698, 2025-10-21
2025-11-09 21:32:33,080 - INFO - root - Page:3, Index:18, GranQ: Efficient Channel-wise Quantization via Vectorized Pre-Scaling for Zero-Shot QAT, https://arxiv.org/pdf/2503.18339, 2025-10-15
2025-11-09 21:32:33,080 - INFO - root - Page:3, Index:19, CompMarkGS: Robust Watermarking for Compressed 3D Gaussian Splatting, https://arxiv.org/pdf/2503.12836, 2025-09-29
2025-11-09 21:32:33,080 - INFO - root - Page:3, Index:20, AHCPTQ: Accurate and Hardware-Compatible Post-Training Quantization for Segment Anything Model, https://arxiv.org/pdf/2503.03088, 2025-07-11
2025-11-09 21:32:33,081 - INFO - root - Page:3, Index:21, Teaching Metric Distance to Discrete Autoregressive Language Models, https://arxiv.org/pdf/2503.02379, 2025-10-07
2025-11-09 21:32:33,081 - INFO - root - Page:3, Index:22, Regularization-based Framework for Quantization-, Fault- and Variability-Aware Training, https://arxiv.org/pdf/2503.01297, 2025-07-12
2025-11-09 21:32:33,081 - INFO - root - Fetching page 5 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=200
2025-11-09 21:32:40,344 - INFO - root - get_all_titles_from_web 
2025-11-09 21:32:40,350 - INFO - root - Page:4, Index:0, Investigating the Impact of Quantization Methods on the Safety and Reliability of Large Language Models, https://arxiv.org/pdf/2502.15799, 2025-06-29
2025-11-09 21:32:40,351 - INFO - root - Page:4, Index:1, Rotate, Clip, and Partition: Towards W2A4KV4 Quantization by Integrating Rotation and Learnable Non-uniform Quantizer, https://arxiv.org/pdf/2502.15779, 2025-09-01
2025-11-09 21:32:40,352 - INFO - root - Page:4, Index:2, RoSTE: An Efficient Quantization-Aware Supervised Fine-Tuning Approach for Large Language Models, https://arxiv.org/pdf/2502.09003, 2025-06-05
2025-11-09 21:32:40,353 - INFO - root - Page:4, Index:3, Spatial Degradation-Aware and Temporal Consistent Diffusion Model for Compressed Video Super-Resolution, https://arxiv.org/pdf/2502.07381, 2025-06-27
2025-11-09 21:32:40,354 - INFO - root - Page:4, Index:4, QuEST: Stable Training of LLMs with 1-Bit Weights and Activations, https://arxiv.org/pdf/2502.05003, 2025-06-10
2025-11-09 21:32:40,355 - INFO - root - Page:4, Index:5, HALO: Hadamard-Assisted Lower-Precision Optimization for LLMs, https://arxiv.org/pdf/2501.02625, 2025-11-05
2025-11-09 21:32:40,356 - INFO - root - Page:4, Index:6, TAR3D: Creating High-Quality 3D Assets via Next-Part Prediction, https://arxiv.org/pdf/2412.16919, 2025-08-08
2025-11-09 21:32:40,357 - INFO - root - Page:4, Index:7, Training Multi-Layer Binary Neural Networks With Local Binary Error Signals, https://arxiv.org/pdf/2412.00119, 2025-08-05
2025-11-09 21:32:40,358 - INFO - root - Page:4, Index:8, Scaling Large-scale GNN Training to Thousands of Processors on CPU-based Supercomputers, https://arxiv.org/pdf/2411.16025, 2025-05-26
2025-11-09 21:32:40,359 - INFO - root - Page:4, Index:9, HAFLQ: Heterogeneous Adaptive Federated LoRA Fine-tuned LLM with Quantization, https://arxiv.org/pdf/2411.06581, 2025-05-16
2025-11-09 21:32:40,361 - INFO - root - Fetching page 6 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=250
2025-11-09 21:32:47,201 - INFO - root - get_all_titles_from_web 
2025-11-09 21:32:47,202 - INFO - root - Page:5, Index:0, Gradient-Free Training of Quantized Neural Networks, https://arxiv.org/pdf/2410.09734, 2025-09-29
2025-11-09 21:32:47,202 - INFO - root - Page:5, Index:1, QT-DoG: Quantization-aware Training for Domain Generalization, https://arxiv.org/pdf/2410.06020, 2025-06-26
2025-11-09 21:32:47,202 - INFO - root - Page:5, Index:2, Constraint Guided Model Quantization of Neural Networks, https://arxiv.org/pdf/2409.20138, 2025-09-12
2025-11-09 21:32:47,203 - INFO - root - Page:5, Index:3, Accumulator-Aware Post-Training Quantization for Large Language Models, https://arxiv.org/pdf/2409.17092, 2025-07-30
2025-11-09 21:32:47,203 - INFO - root - Page:5, Index:4, DilateQuant: Accurate and Efficient Diffusion Quantization via Weight Dilation, https://arxiv.org/pdf/2409.14307, 2025-07-09
2025-11-09 21:32:47,203 - INFO - root - Page:5, Index:5, Robust Training of Neural Networks at Arbitrary Precision and Sparsity, https://arxiv.org/pdf/2409.09245, 2025-09-23
2025-11-09 21:32:47,204 - INFO - root - Page:5, Index:6, VQ-CTAP: Cross-Modal Fine-Grained Sequence Representation Learning for Speech Processing, https://arxiv.org/pdf/2408.05758, 2025-05-27
2025-11-09 21:32:47,204 - INFO - root - Page:5, Index:7, DopQ-ViT: Towards Distribution-Friendly and Outlier-Aware Post-Training Quantization for Vision Transformers, https://arxiv.org/pdf/2408.03291, 2025-06-19
2025-11-09 21:32:47,205 - INFO - root - Page:5, Index:8, Temporal Feature Matters: A Framework for Diffusion Model Quantization, https://arxiv.org/pdf/2407.19547, 2025-07-11
2025-11-09 21:32:47,205 - INFO - root - Page:5, Index:9, EfficientQAT: Efficient Quantization-Aware Training for Large Language Models, https://arxiv.org/pdf/2407.11062, 2025-05-19
2025-11-09 21:32:47,206 - INFO - root - Page:5, Index:10, Integer-only Quantized Transformers for Embedded FPGA-based Time-series Forecasting in AIoT, https://arxiv.org/pdf/2407.11041, 2025-10-31
2025-11-09 21:32:47,206 - INFO - root - Fetching page 7 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=300
2025-11-09 21:32:54,890 - INFO - root - get_all_titles_from_web 
2025-11-09 21:32:54,890 - INFO - root - Page:6, Index:0, BoA: Attention-aware Post-training Quantization without Backpropagation, https://arxiv.org/pdf/2406.13474, 2025-06-06
2025-11-09 21:32:54,891 - INFO - root - Page:6, Index:1, A Rescaling-Invariant Lipschitz Bound Based on Path-Metrics for Modern ReLU Network Parameterizations, https://arxiv.org/pdf/2405.15006, 2025-06-13
2025-11-09 21:32:54,891 - INFO - root - Page:6, Index:2, Scheduling Weight Transitions for Quantization-Aware Training, https://arxiv.org/pdf/2404.19248, 2025-10-01
2025-11-09 21:32:54,891 - INFO - root - Page:6, Index:3, GPTVQ: The Blessing of Dimensionality for LLM Quantization, https://arxiv.org/pdf/2402.15319, 2025-06-03
2025-11-09 21:32:54,892 - INFO - root - Fetching page 8 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=350
2025-11-09 21:33:03,380 - INFO - root - get_all_titles_from_web 
2025-11-09 21:33:03,498 - INFO - root - Page:7, Index:0, Squat: Quant Small Language Models on the Edge, https://arxiv.org/pdf/2402.10787, 2025-07-01
2025-11-09 21:33:03,517 - INFO - root - Page:7, Index:1, L4Q: Parameter Efficient Quantization-Aware Fine-Tuning on Large Language Models, https://arxiv.org/pdf/2402.04902, 2025-07-21
2025-11-09 21:33:03,518 - INFO - root - Fetching page 9 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=400
2025-11-09 21:33:11,451 - INFO - root - ------------------------------------------------------------------------------------------------------------------------
2025-11-09 21:33:11,453 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\A Quantized VAE-MLP Botnet Detection Model_ A Systematic Evaluation of Quantizat.pdf
2025-11-09 21:33:11,489 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\FP8-Flow-MoE_ A Casting-Free FP8 Recipe without Double Quantization Error.pdf
2025-11-09 21:33:11,491 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\Outlier-Aware Post-Training Quantization for Image Super-Resolution.pdf
2025-11-09 21:33:11,493 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\Evaluation of Wafer-Scale SOT-MRAM for Analog Crossbar Array Applications.pdf
2025-11-09 21:33:11,494 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\Improving the Straight-Through Estimator with Zeroth-Order Information.pdf
2025-11-09 21:33:11,502 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\Real-Time Semantic Segmentation on FPGA for Autonomous Vehicles Using LMIINet wi.pdf
2025-11-09 21:33:11,505 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\TernaryCLIP_ Efficiently Compressing Vision-Language Models with Ternary Weights.pdf
2025-11-09 21:33:11,506 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\KARIPAP_ Quantum-Inspired Tensor Network Compression of Large Language Models Us.pdf
2025-11-09 21:33:11,509 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\A Convergence Analysis of Adaptive Optimizers under Floating-point Quantization.pdf
2025-11-09 21:33:11,511 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\Adaptive Distribution-aware Quantization for Mixed-Precision Neural Networks.pdf
2025-11-09 21:33:11,514 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\CAGE_ Curvature-Aware Gradient Estimation For Accurate Quantization-Aware Traini.pdf
2025-11-09 21:33:11,516 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\Mixed-Precision Quantization for Language Models_ Techniques and Prospects.pdf
2025-11-09 21:33:11,518 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\SPLite Hand_ Sparsity-Aware Lightweight 3D Hand Pose Estimation.pdf
2025-11-09 21:33:11,520 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\CTR-LoRA_ Curvature-Aware and Trust-Region Guided Low-Rank Adaptation for Large.pdf
2025-11-09 21:33:11,521 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\SANR_ Scene-Aware Neural Representation for Light Field Image Compression with R.pdf
2025-11-09 21:33:11,523 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\SpikeFit_ Towards Optimal Deployment of Spiking Networks on Neuromorphic Hardwar.pdf
2025-11-09 21:33:11,528 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\GRank_ Towards Target-Aware and Streamlined Industrial Retrieval with a Generate.pdf
2025-11-09 21:33:11,534 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\SaLon3R_ Structure-aware Long-term Generalizable 3D Reconstruction from Unposed.pdf
2025-11-09 21:33:11,535 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\FraQAT_ Quantization Aware Training with Fractional bits.pdf
2025-11-09 21:33:11,537 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\Computing-In-Memory Aware Model Adaption For Edge Devices.pdf
2025-11-09 21:33:11,542 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\Invited Paper_ BitMedViT_ Ternary-Quantized Vision Transformer for Medical AI As.pdf
2025-11-09 21:33:11,545 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\NeuroRVQ_ Multi-Scale EEG Tokenization for Generative Large Brainwave Models.pdf
2025-11-09 21:33:11,548 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\Detect Anything via Next Point Prediction.pdf
2025-11-09 21:33:11,550 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\AndesVL Technical Report_ An Efficient Mobile-side Multimodal Large Language Mod.pdf
2025-11-09 21:33:11,556 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\Rescaling-Aware Training for Efficient Deployment of Deep Learning Models on Ful.pdf
2025-11-09 21:33:11,558 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\SASER_ Stego attacks on open-source LLMs.pdf
2025-11-09 21:33:11,560 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\Ultralytics YOLO Evolution_ An Overview of YOLO26, YOLO11, YOLOv8 and YOLOv5 Obj.pdf
2025-11-09 21:33:11,566 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\A Theoretically-Grounded Codebook for Digital Semantic Communications.pdf
2025-11-09 21:33:11,567 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\QuantDemoire_ Quantization with Outlier Aware for Image Demoiréing.pdf
2025-11-09 21:33:11,568 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\Adaptively Sampling-Reusing-Mixing Decomposed Gradients to Speed Up Sharpness Aw.pdf
2025-11-09 21:33:11,571 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\Quant-dLLM_ Post-Training Extreme Low-Bit Quantization for Diffusion Large Langu.pdf
2025-11-09 21:33:11,573 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\PT$^2$-LLM_ Post-Training Ternarization for Large Language Models.pdf
2025-11-09 21:33:11,577 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\Purrception_ Variational Flow Matching for Vector-Quantized Image Generation.pdf
2025-11-09 21:33:11,581 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\Post-Training Quantization for Audio Diffusion Transformers.pdf
2025-11-09 21:33:11,582 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\Rethinking RoPE Scaling in Quantized LLM_ Theory, Outlier, and Channel-Band Anal.pdf
2025-11-09 21:33:11,584 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\Post-Training Quantization via Residual Truncation and Zero Suppression for Diff.pdf
2025-11-09 21:33:11,585 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\Cat_ Post-Training Quantization Error Reduction via Cluster-based Affine Transfo.pdf
2025-11-09 21:33:11,586 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\CAST_ Continuous and Differentiable Semi-Structured Sparsity-Aware Training for.pdf
2025-11-09 21:33:11,588 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\Norm-Q_ Effective Compression Method for Hidden Markov Models in Neuro-Symbolic.pdf
2025-11-09 21:33:11,590 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\On-the-Fly Adaptation to Quantization_ Configuration-Aware LoRA for Efficient Fi.pdf
2025-11-09 21:33:11,601 - INFO - root - 跳过已处理论文 A Quantized VAE-MLP Botnet Detection Model: A Systematic Evaluation of Quantization-Aware Training and Post-Training Quantization Strategies：d:\ChatPaper\academic Papers\Quantization-Aware-Training\A Quantized VAE-MLP Botnet Detection Model_ A Systematic Evaluation of Quantizat.pdf
2025-11-09 21:33:11,602 - INFO - root - 跳过已处理论文 FP8-Flow-MoE: A Casting-Free FP8 Recipe without Double Quantization Error：d:\ChatPaper\academic Papers\Quantization-Aware-Training\FP8-Flow-MoE_ A Casting-Free FP8 Recipe without Double Quantization Error.pdf
2025-11-09 21:33:11,611 - INFO - root - 跳过已处理论文 Outlier-Aware Post-Training Quantization for Image Super-Resolution：d:\ChatPaper\academic Papers\Quantization-Aware-Training\Outlier-Aware Post-Training Quantization for Image Super-Resolution.pdf
2025-11-09 21:33:11,612 - INFO - root - 跳过已处理论文 Evaluation of Wafer-Scale SOT-MRAM for Analog Crossbar Array Applications：d:\ChatPaper\academic Papers\Quantization-Aware-Training\Evaluation of Wafer-Scale SOT-MRAM for Analog Crossbar Array Applications.pdf
2025-11-09 21:33:11,616 - INFO - root - 跳过已处理论文 Improving the Straight-Through Estimator with Zeroth-Order Information：d:\ChatPaper\academic Papers\Quantization-Aware-Training\Improving the Straight-Through Estimator with Zeroth-Order Information.pdf
2025-11-09 21:33:11,616 - INFO - root - 跳过已处理论文 Real-Time Semantic Segmentation on FPGA for Autonomous Vehicles Using LMIINet with the CGRA4ML Framework：d:\ChatPaper\academic Papers\Quantization-Aware-Training\Real-Time Semantic Segmentation on FPGA for Autonomous Vehicles Using LMIINet wi.pdf
2025-11-09 21:33:11,617 - INFO - root - 跳过已处理论文 TernaryCLIP: Efficiently Compressing Vision-Language Models with Ternary Weights and Distilled Knowledge：d:\ChatPaper\academic Papers\Quantization-Aware-Training\TernaryCLIP_ Efficiently Compressing Vision-Language Models with Ternary Weights.pdf
2025-11-09 21:33:11,617 - INFO - root - 跳过已处理论文 KARIPAP: Quantum-Inspired Tensor Network Compression of Large Language Models Using Infinite Projected Entangled Pair States and Tensor Renormalization Group：d:\ChatPaper\academic Papers\Quantization-Aware-Training\KARIPAP_ Quantum-Inspired Tensor Network Compression of Large Language Models Us.pdf
2025-11-09 21:33:11,619 - INFO - root - 跳过已处理论文 A Convergence Analysis of Adaptive Optimizers under Floating-point Quantization：d:\ChatPaper\academic Papers\Quantization-Aware-Training\A Convergence Analysis of Adaptive Optimizers under Floating-point Quantization.pdf
2025-11-09 21:33:11,619 - INFO - root - 跳过已处理论文 Adaptive Distribution-aware Quantization for Mixed-Precision Neural Networks：d:\ChatPaper\academic Papers\Quantization-Aware-Training\Adaptive Distribution-aware Quantization for Mixed-Precision Neural Networks.pdf
2025-11-09 21:33:11,686 - INFO - root - 跳过已处理论文 CAGE: Curvature-Aware Gradient Estimation For Accurate Quantization-Aware Training：d:\ChatPaper\academic Papers\Quantization-Aware-Training\CAGE_ Curvature-Aware Gradient Estimation For Accurate Quantization-Aware Traini.pdf
2025-11-09 21:33:11,854 - INFO - root - 跳过已处理论文 Mixed-Precision Quantization for Language Models: Techniques and Prospects：d:\ChatPaper\academic Papers\Quantization-Aware-Training\Mixed-Precision Quantization for Language Models_ Techniques and Prospects.pdf
2025-11-09 21:33:11,868 - INFO - root - 跳过已处理论文 SPLite Hand: Sparsity-Aware Lightweight 3D Hand Pose Estimation：d:\ChatPaper\academic Papers\Quantization-Aware-Training\SPLite Hand_ Sparsity-Aware Lightweight 3D Hand Pose Estimation.pdf
2025-11-09 21:33:11,870 - INFO - root - 跳过已处理论文 CTR-LoRA: Curvature-Aware and Trust-Region Guided Low-Rank Adaptation for Large Language Models：d:\ChatPaper\academic Papers\Quantization-Aware-Training\CTR-LoRA_ Curvature-Aware and Trust-Region Guided Low-Rank Adaptation for Large.pdf
2025-11-09 21:33:11,872 - INFO - root - 正在总结论文 15/40: SANR: Scene-Aware Neural Representation for Light Field Image Compression with Rate-Distortion Optimization
2025-11-09 21:33:52,442 - INFO - root - LLMClient: rate limit reached, sleeping 19.4s
2025-11-09 21:34:31,622 - INFO - root - 正在提取论文图片...
2025-11-09 21:34:33,820 - INFO - root - 已保存图片 1/10：./export\images_SANR_ Scene-Aware Neural Representation for Light Field Image Compression with R\figure_1_page3.png
2025-11-09 21:34:34,007 - INFO - root - 已保存图片 2/10：./export\images_SANR_ Scene-Aware Neural Representation for Light Field Image Compression with R\figure_2_page8.png
2025-11-09 21:34:34,142 - INFO - root - 已保存图片 3/10：./export\images_SANR_ Scene-Aware Neural Representation for Light Field Image Compression with R\figure_3_page8.png
2025-11-09 21:34:34,239 - INFO - root - 已保存图片 4/10：./export\images_SANR_ Scene-Aware Neural Representation for Light Field Image Compression with R\figure_4_page8.png
2025-11-09 21:34:34,376 - INFO - root - 已保存图片 5/10：./export\images_SANR_ Scene-Aware Neural Representation for Light Field Image Compression with R\figure_5_page8.png
2025-11-09 21:34:34,477 - INFO - root - 已保存图片 6/10：./export\images_SANR_ Scene-Aware Neural Representation for Light Field Image Compression with R\figure_6_page8.png
2025-11-09 21:34:34,585 - INFO - root - 已保存图片 7/10：./export\images_SANR_ Scene-Aware Neural Representation for Light Field Image Compression with R\figure_7_page8.png
2025-11-09 21:34:34,696 - INFO - root - 已保存图片 8/10：./export\images_SANR_ Scene-Aware Neural Representation for Light Field Image Compression with R\figure_8_page8.png
2025-11-09 21:34:34,852 - INFO - root - 已保存图片 9/10：./export\images_SANR_ Scene-Aware Neural Representation for Light Field Image Compression with R\figure_9_page8.png
2025-11-09 21:34:34,936 - INFO - root - 已保存图片 10/10：./export\images_SANR_ Scene-Aware Neural Representation for Light Field Image Compression with R\figure_10_page10.png
2025-11-09 21:34:34,942 - INFO - root - 成功添加图片 1：./export\images_SANR_ Scene-Aware Neural Representation for Light Field Image Compression with R\figure_1_page3.png
2025-11-09 21:34:34,942 - INFO - root - 成功添加图片 2：./export\images_SANR_ Scene-Aware Neural Representation for Light Field Image Compression with R\figure_2_page8.png
2025-11-09 21:34:34,942 - INFO - root - 成功添加图片 3：./export\images_SANR_ Scene-Aware Neural Representation for Light Field Image Compression with R\figure_3_page8.png
2025-11-09 21:34:34,943 - INFO - root - 成功添加图片 4：./export\images_SANR_ Scene-Aware Neural Representation for Light Field Image Compression with R\figure_4_page8.png
2025-11-09 21:34:34,945 - INFO - root - 成功添加图片 5：./export\images_SANR_ Scene-Aware Neural Representation for Light Field Image Compression with R\figure_5_page8.png
2025-11-09 21:34:34,945 - INFO - root - 成功添加图片 6：./export\images_SANR_ Scene-Aware Neural Representation for Light Field Image Compression with R\figure_6_page8.png
2025-11-09 21:34:34,950 - INFO - root - 成功添加图片 7：./export\images_SANR_ Scene-Aware Neural Representation for Light Field Image Compression with R\figure_7_page8.png
2025-11-09 21:34:34,950 - INFO - root - 成功添加图片 8：./export\images_SANR_ Scene-Aware Neural Representation for Light Field Image Compression with R\figure_8_page8.png
2025-11-09 21:34:34,951 - INFO - root - 成功添加图片 9：./export\images_SANR_ Scene-Aware Neural Representation for Light Field Image Compression with R\figure_9_page8.png
2025-11-09 21:34:34,951 - INFO - root - 成功添加图片 10：./export\images_SANR_ Scene-Aware Neural Representation for Light Field Image Compression with R\figure_10_page10.png
2025-11-09 21:34:34,954 - INFO - root - 论文《SANR: Scene-Aware Neural Representation for Light Field Image Compression with Rate-Distortion Optimization》的分析已保存到 ./export\SANR_ Scene-Aware Neural Representation for Light Field Image Compression with R.md
2025-11-09 21:34:34,960 - INFO - root - 正在总结论文 16/40: SpikeFit: Towards Optimal Deployment of Spiking Networks on Neuromorphic Hardware
2025-11-09 21:34:44,556 - INFO - root - LLMClient: rate limit reached, sleeping 27.3s
2025-11-09 21:36:00,667 - INFO - root - 正在提取论文图片...
2025-11-09 21:36:00,708 - INFO - root - 论文《SpikeFit: Towards Optimal Deployment of Spiking Networks on Neuromorphic Hardware》的分析已保存到 ./export\SpikeFit_ Towards Optimal Deployment of Spiking Networks on Neuromorphic Hardwar.md
2025-11-09 21:36:00,713 - INFO - root - 正在总结论文 17/40: GRank: Towards Target-Aware and Streamlined Industrial Retrieval with a Generate-Rank Framework
2025-11-09 21:36:00,713 - INFO - root - LLMClient: rate limit reached, sleeping 11.2s
2025-11-09 21:36:23,920 - INFO - root - LLMClient: rate limit reached, sleeping 17.6s
2025-11-09 21:38:08,051 - INFO - root - 正在提取论文图片...
2025-11-09 21:38:09,983 - INFO - root - 已保存图片 1/10：./export\images_GRank_ Towards Target-Aware and Streamlined Industrial Retrieval with a Generate\figure_1_page7.png
2025-11-09 21:38:10,124 - INFO - root - 已保存图片 2/10：./export\images_GRank_ Towards Target-Aware and Streamlined Industrial Retrieval with a Generate\figure_2_page3.png
2025-11-09 21:38:10,276 - INFO - root - 已保存图片 3/10：./export\images_GRank_ Towards Target-Aware and Streamlined Industrial Retrieval with a Generate\figure_3_page4.png
2025-11-09 21:38:10,281 - INFO - root - 成功添加图片 1：./export\images_GRank_ Towards Target-Aware and Streamlined Industrial Retrieval with a Generate\figure_1_page7.png
2025-11-09 21:38:10,282 - INFO - root - 成功添加图片 2：./export\images_GRank_ Towards Target-Aware and Streamlined Industrial Retrieval with a Generate\figure_2_page3.png
2025-11-09 21:38:10,283 - INFO - root - 成功添加图片 3：./export\images_GRank_ Towards Target-Aware and Streamlined Industrial Retrieval with a Generate\figure_3_page4.png
2025-11-09 21:38:10,284 - INFO - root - 论文《GRank: Towards Target-Aware and Streamlined Industrial Retrieval with a Generate-Rank Framework》的分析已保存到 ./export\GRank_ Towards Target-Aware and Streamlined Industrial Retrieval with a Generate.md
2025-11-09 21:38:10,299 - INFO - root - 正在总结论文 18/40: SaLon3R: Structure-aware Long-term Generalizable 3D Reconstruction from Unposed Images
2025-11-09 21:38:22,479 - INFO - root - LLMClient: rate limit reached, sleeping 21.1s
2025-11-09 21:39:35,988 - INFO - root - 正在提取论文图片...
2025-11-09 21:39:41,895 - INFO - root - 已保存图片 1/10：./export\images_SaLon3R_ Structure-aware Long-term Generalizable 3D Reconstruction from Unposed\figure_1_page15.jpeg
2025-11-09 21:39:41,948 - INFO - root - 已保存图片 2/10：./export\images_SaLon3R_ Structure-aware Long-term Generalizable 3D Reconstruction from Unposed\figure_2_page15.jpeg
2025-11-09 21:39:42,005 - INFO - root - 已保存图片 3/10：./export\images_SaLon3R_ Structure-aware Long-term Generalizable 3D Reconstruction from Unposed\figure_3_page15.jpeg
2025-11-09 21:39:42,061 - INFO - root - 已保存图片 4/10：./export\images_SaLon3R_ Structure-aware Long-term Generalizable 3D Reconstruction from Unposed\figure_4_page15.jpeg
2025-11-09 21:39:42,125 - INFO - root - 已保存图片 5/10：./export\images_SaLon3R_ Structure-aware Long-term Generalizable 3D Reconstruction from Unposed\figure_5_page15.jpeg
2025-11-09 21:39:42,193 - INFO - root - 已保存图片 6/10：./export\images_SaLon3R_ Structure-aware Long-term Generalizable 3D Reconstruction from Unposed\figure_6_page15.jpeg
2025-11-09 21:39:42,271 - INFO - root - 已保存图片 7/10：./export\images_SaLon3R_ Structure-aware Long-term Generalizable 3D Reconstruction from Unposed\figure_7_page15.jpeg
2025-11-09 21:39:42,401 - INFO - root - 已保存图片 8/10：./export\images_SaLon3R_ Structure-aware Long-term Generalizable 3D Reconstruction from Unposed\figure_8_page15.jpeg
2025-11-09 21:39:42,479 - INFO - root - 已保存图片 9/10：./export\images_SaLon3R_ Structure-aware Long-term Generalizable 3D Reconstruction from Unposed\figure_9_page15.jpeg
2025-11-09 21:39:42,548 - INFO - root - 已保存图片 10/10：./export\images_SaLon3R_ Structure-aware Long-term Generalizable 3D Reconstruction from Unposed\figure_10_page15.jpeg
2025-11-09 21:39:42,566 - INFO - root - 成功添加图片 1：./export\images_SaLon3R_ Structure-aware Long-term Generalizable 3D Reconstruction from Unposed\figure_1_page15.jpeg
2025-11-09 21:39:42,566 - INFO - root - 成功添加图片 2：./export\images_SaLon3R_ Structure-aware Long-term Generalizable 3D Reconstruction from Unposed\figure_2_page15.jpeg
2025-11-09 21:39:42,567 - INFO - root - 成功添加图片 3：./export\images_SaLon3R_ Structure-aware Long-term Generalizable 3D Reconstruction from Unposed\figure_3_page15.jpeg
2025-11-09 21:39:42,568 - INFO - root - 成功添加图片 4：./export\images_SaLon3R_ Structure-aware Long-term Generalizable 3D Reconstruction from Unposed\figure_4_page15.jpeg
2025-11-09 21:39:42,579 - INFO - root - 成功添加图片 5：./export\images_SaLon3R_ Structure-aware Long-term Generalizable 3D Reconstruction from Unposed\figure_5_page15.jpeg
2025-11-09 21:39:42,583 - INFO - root - 成功添加图片 6：./export\images_SaLon3R_ Structure-aware Long-term Generalizable 3D Reconstruction from Unposed\figure_6_page15.jpeg
2025-11-09 21:39:42,584 - INFO - root - 成功添加图片 7：./export\images_SaLon3R_ Structure-aware Long-term Generalizable 3D Reconstruction from Unposed\figure_7_page15.jpeg
2025-11-09 21:39:42,586 - INFO - root - 成功添加图片 8：./export\images_SaLon3R_ Structure-aware Long-term Generalizable 3D Reconstruction from Unposed\figure_8_page15.jpeg
2025-11-09 21:39:42,591 - INFO - root - 成功添加图片 9：./export\images_SaLon3R_ Structure-aware Long-term Generalizable 3D Reconstruction from Unposed\figure_9_page15.jpeg
2025-11-09 21:39:42,592 - INFO - root - 成功添加图片 10：./export\images_SaLon3R_ Structure-aware Long-term Generalizable 3D Reconstruction from Unposed\figure_10_page15.jpeg
2025-11-09 21:39:42,602 - INFO - root - 论文《SaLon3R: Structure-aware Long-term Generalizable 3D Reconstruction from Unposed Images》的分析已保存到 ./export\SaLon3R_ Structure-aware Long-term Generalizable 3D Reconstruction from Unposed.md
2025-11-09 21:39:42,610 - INFO - root - 正在总结论文 19/40: FraQAT: Quantization Aware Training with Fractional bits
2025-11-09 21:39:42,611 - INFO - root - LLMClient: rate limit reached, sleeping 1.0s
2025-11-09 21:39:53,351 - INFO - root - LLMClient: rate limit reached, sleeping 24.2s
2025-11-09 21:41:12,276 - INFO - root - 正在提取论文图片...
2025-11-09 21:41:15,291 - INFO - root - 已保存图片 1/10：./export\images_FraQAT_ Quantization Aware Training with Fractional bits\figure_1_page4.png
2025-11-09 21:41:15,462 - INFO - root - 已保存图片 2/10：./export\images_FraQAT_ Quantization Aware Training with Fractional bits\figure_2_page1.png
2025-11-09 21:41:15,640 - INFO - root - 已保存图片 3/10：./export\images_FraQAT_ Quantization Aware Training with Fractional bits\figure_3_page1.png
2025-11-09 21:41:15,850 - INFO - root - 已保存图片 4/10：./export\images_FraQAT_ Quantization Aware Training with Fractional bits\figure_4_page1.png
2025-11-09 21:41:16,068 - INFO - root - 已保存图片 5/10：./export\images_FraQAT_ Quantization Aware Training with Fractional bits\figure_5_page1.png
2025-11-09 21:41:16,286 - INFO - root - 已保存图片 6/10：./export\images_FraQAT_ Quantization Aware Training with Fractional bits\figure_6_page1.png
2025-11-09 21:41:16,496 - INFO - root - 已保存图片 7/10：./export\images_FraQAT_ Quantization Aware Training with Fractional bits\figure_7_page1.png
2025-11-09 21:41:16,732 - INFO - root - 已保存图片 8/10：./export\images_FraQAT_ Quantization Aware Training with Fractional bits\figure_8_page8.png
2025-11-09 21:41:17,013 - INFO - root - 已保存图片 9/10：./export\images_FraQAT_ Quantization Aware Training with Fractional bits\figure_9_page8.png
2025-11-09 21:41:17,193 - INFO - root - 已保存图片 10/10：./export\images_FraQAT_ Quantization Aware Training with Fractional bits\figure_10_page8.png
2025-11-09 21:41:17,198 - INFO - root - 成功添加图片 1：./export\images_FraQAT_ Quantization Aware Training with Fractional bits\figure_1_page4.png
2025-11-09 21:41:17,198 - INFO - root - 成功添加图片 2：./export\images_FraQAT_ Quantization Aware Training with Fractional bits\figure_2_page1.png
2025-11-09 21:41:17,200 - INFO - root - 成功添加图片 3：./export\images_FraQAT_ Quantization Aware Training with Fractional bits\figure_3_page1.png
2025-11-09 21:41:17,200 - INFO - root - 成功添加图片 4：./export\images_FraQAT_ Quantization Aware Training with Fractional bits\figure_4_page1.png
2025-11-09 21:41:17,200 - INFO - root - 成功添加图片 5：./export\images_FraQAT_ Quantization Aware Training with Fractional bits\figure_5_page1.png
2025-11-09 21:41:17,201 - INFO - root - 成功添加图片 6：./export\images_FraQAT_ Quantization Aware Training with Fractional bits\figure_6_page1.png
2025-11-09 21:41:17,201 - INFO - root - 成功添加图片 7：./export\images_FraQAT_ Quantization Aware Training with Fractional bits\figure_7_page1.png
2025-11-09 21:41:17,203 - INFO - root - 成功添加图片 8：./export\images_FraQAT_ Quantization Aware Training with Fractional bits\figure_8_page8.png
2025-11-09 21:41:17,203 - INFO - root - 成功添加图片 9：./export\images_FraQAT_ Quantization Aware Training with Fractional bits\figure_9_page8.png
2025-11-09 21:41:17,204 - INFO - root - 成功添加图片 10：./export\images_FraQAT_ Quantization Aware Training with Fractional bits\figure_10_page8.png
2025-11-09 21:41:17,209 - INFO - root - 论文《FraQAT: Quantization Aware Training with Fractional bits》的分析已保存到 ./export\FraQAT_ Quantization Aware Training with Fractional bits.md
2025-11-09 21:41:17,213 - INFO - root - 正在总结论文 20/40: Computing-In-Memory Aware Model Adaption For Edge Devices
2025-11-09 21:41:17,213 - INFO - root - LLMClient: rate limit reached, sleeping 0.3s
2025-11-09 21:41:29,186 - INFO - root - LLMClient: rate limit reached, sleeping 23.2s
2025-11-09 21:42:37,435 - INFO - root - 正在提取论文图片...
2025-11-09 21:42:38,522 - INFO - root - 已保存图片 1/10：./export\images_Computing-In-Memory Aware Model Adaption For Edge Devices\figure_1_page2.png
2025-11-09 21:42:38,638 - INFO - root - 已保存图片 2/10：./export\images_Computing-In-Memory Aware Model Adaption For Edge Devices\figure_2_page2.png
2025-11-09 21:42:38,791 - INFO - root - 已保存图片 3/10：./export\images_Computing-In-Memory Aware Model Adaption For Edge Devices\figure_3_page4.png
2025-11-09 21:42:38,933 - INFO - root - 已保存图片 4/10：./export\images_Computing-In-Memory Aware Model Adaption For Edge Devices\figure_4_page2.png
2025-11-09 21:42:39,079 - INFO - root - 已保存图片 5/10：./export\images_Computing-In-Memory Aware Model Adaption For Edge Devices\figure_5_page2.png
2025-11-09 21:42:39,182 - INFO - root - 已保存图片 6/10：./export\images_Computing-In-Memory Aware Model Adaption For Edge Devices\figure_6_page5.png
2025-11-09 21:42:39,408 - INFO - root - 已保存图片 7/10：./export\images_Computing-In-Memory Aware Model Adaption For Edge Devices\figure_7_page5.png
2025-11-09 21:42:39,487 - INFO - root - 已保存图片 8/10：./export\images_Computing-In-Memory Aware Model Adaption For Edge Devices\figure_8_page9.jpeg
2025-11-09 21:42:39,551 - INFO - root - 已保存图片 9/10：./export\images_Computing-In-Memory Aware Model Adaption For Edge Devices\figure_9_page4.png
2025-11-09 21:42:39,662 - INFO - root - 已保存图片 10/10：./export\images_Computing-In-Memory Aware Model Adaption For Edge Devices\figure_10_page4.png
2025-11-09 21:42:39,669 - INFO - root - 成功添加图片 1：./export\images_Computing-In-Memory Aware Model Adaption For Edge Devices\figure_1_page2.png
2025-11-09 21:42:39,670 - INFO - root - 成功添加图片 2：./export\images_Computing-In-Memory Aware Model Adaption For Edge Devices\figure_2_page2.png
2025-11-09 21:42:39,671 - INFO - root - 成功添加图片 3：./export\images_Computing-In-Memory Aware Model Adaption For Edge Devices\figure_3_page4.png
2025-11-09 21:42:39,673 - INFO - root - 成功添加图片 4：./export\images_Computing-In-Memory Aware Model Adaption For Edge Devices\figure_4_page2.png
2025-11-09 21:42:39,675 - INFO - root - 成功添加图片 5：./export\images_Computing-In-Memory Aware Model Adaption For Edge Devices\figure_5_page2.png
2025-11-09 21:42:39,677 - INFO - root - 成功添加图片 6：./export\images_Computing-In-Memory Aware Model Adaption For Edge Devices\figure_6_page5.png
2025-11-09 21:42:39,680 - INFO - root - 成功添加图片 7：./export\images_Computing-In-Memory Aware Model Adaption For Edge Devices\figure_7_page5.png
2025-11-09 21:42:39,680 - INFO - root - 成功添加图片 8：./export\images_Computing-In-Memory Aware Model Adaption For Edge Devices\figure_8_page9.jpeg
2025-11-09 21:42:39,682 - INFO - root - 成功添加图片 9：./export\images_Computing-In-Memory Aware Model Adaption For Edge Devices\figure_9_page4.png
2025-11-09 21:42:39,688 - INFO - root - 成功添加图片 10：./export\images_Computing-In-Memory Aware Model Adaption For Edge Devices\figure_10_page4.png
2025-11-09 21:42:39,694 - INFO - root - 论文《Computing-In-Memory Aware Model Adaption For Edge Devices》的分析已保存到 ./export\Computing-In-Memory Aware Model Adaption For Edge Devices.md
2025-11-09 21:42:39,700 - INFO - root - 正在总结论文 21/40: Invited Paper: BitMedViT: Ternary-Quantized Vision Transformer for Medical AI Assistants on the Edge
2025-11-09 21:42:39,702 - INFO - root - LLMClient: rate limit reached, sleeping 12.7s
2025-11-09 21:43:02,670 - INFO - root - LLMClient: rate limit reached, sleeping 16.3s
2025-11-09 21:43:42,938 - INFO - root - LLMClient: rate limit reached, sleeping 9.4s
2025-11-09 21:44:11,552 - INFO - root - 正在提取论文图片...
2025-11-09 21:44:15,378 - INFO - root - 已保存图片 1/10：./export\images_Invited Paper_ BitMedViT_ Ternary-Quantized Vision Transformer for Medical AI As\figure_1_page6.png
2025-11-09 21:44:15,605 - INFO - root - 已保存图片 2/10：./export\images_Invited Paper_ BitMedViT_ Ternary-Quantized Vision Transformer for Medical AI As\figure_2_page5.png
2025-11-09 21:44:15,798 - INFO - root - 已保存图片 3/10：./export\images_Invited Paper_ BitMedViT_ Ternary-Quantized Vision Transformer for Medical AI As\figure_3_page3.png
2025-11-09 21:44:15,891 - INFO - root - 已保存图片 4/10：./export\images_Invited Paper_ BitMedViT_ Ternary-Quantized Vision Transformer for Medical AI As\figure_4_page4.png
2025-11-09 21:44:15,988 - INFO - root - 已保存图片 5/10：./export\images_Invited Paper_ BitMedViT_ Ternary-Quantized Vision Transformer for Medical AI As\figure_5_page1.png
2025-11-09 21:44:16,169 - INFO - root - 已保存图片 6/10：./export\images_Invited Paper_ BitMedViT_ Ternary-Quantized Vision Transformer for Medical AI As\figure_6_page5.png
2025-11-09 21:44:16,182 - INFO - root - 成功添加图片 1：./export\images_Invited Paper_ BitMedViT_ Ternary-Quantized Vision Transformer for Medical AI As\figure_1_page6.png
2025-11-09 21:44:16,184 - INFO - root - 成功添加图片 2：./export\images_Invited Paper_ BitMedViT_ Ternary-Quantized Vision Transformer for Medical AI As\figure_2_page5.png
2025-11-09 21:44:16,186 - INFO - root - 成功添加图片 3：./export\images_Invited Paper_ BitMedViT_ Ternary-Quantized Vision Transformer for Medical AI As\figure_3_page3.png
2025-11-09 21:44:16,186 - INFO - root - 成功添加图片 4：./export\images_Invited Paper_ BitMedViT_ Ternary-Quantized Vision Transformer for Medical AI As\figure_4_page4.png
2025-11-09 21:44:16,187 - INFO - root - 成功添加图片 5：./export\images_Invited Paper_ BitMedViT_ Ternary-Quantized Vision Transformer for Medical AI As\figure_5_page1.png
2025-11-09 21:44:16,188 - INFO - root - 成功添加图片 6：./export\images_Invited Paper_ BitMedViT_ Ternary-Quantized Vision Transformer for Medical AI As\figure_6_page5.png
2025-11-09 21:44:16,197 - INFO - root - 论文《Invited Paper: BitMedViT: Ternary-Quantized Vision Transformer for Medical AI Assistants on the Edge》的分析已保存到 ./export\Invited Paper_ BitMedViT_ Ternary-Quantized Vision Transformer for Medical AI As.md
2025-11-09 21:44:16,203 - INFO - root - 正在总结论文 22/40: NeuroRVQ: Multi-Scale EEG Tokenization for Generative Large Brainwave Models
2025-11-09 21:44:16,203 - INFO - root - LLMClient: rate limit reached, sleeping 2.8s
2025-11-09 21:44:29,913 - INFO - root - LLMClient: rate limit reached, sleeping 22.5s
2025-11-09 21:45:45,204 - INFO - root - 正在提取论文图片...
2025-11-09 21:45:46,089 - INFO - root - 已保存图片 1/10：./export\images_NeuroRVQ_ Multi-Scale EEG Tokenization for Generative Large Brainwave Models\figure_1_page3.png
2025-11-09 21:45:46,233 - INFO - root - 已保存图片 2/10：./export\images_NeuroRVQ_ Multi-Scale EEG Tokenization for Generative Large Brainwave Models\figure_2_page6.png
2025-11-09 21:45:46,344 - INFO - root - 已保存图片 3/10：./export\images_NeuroRVQ_ Multi-Scale EEG Tokenization for Generative Large Brainwave Models\figure_3_page5.png
2025-11-09 21:45:46,444 - INFO - root - 已保存图片 4/10：./export\images_NeuroRVQ_ Multi-Scale EEG Tokenization for Generative Large Brainwave Models\figure_4_page5.png
2025-11-09 21:45:46,559 - INFO - root - 已保存图片 5/10：./export\images_NeuroRVQ_ Multi-Scale EEG Tokenization for Generative Large Brainwave Models\figure_5_page7.png
2025-11-09 21:45:46,636 - INFO - root - 已保存图片 6/10：./export\images_NeuroRVQ_ Multi-Scale EEG Tokenization for Generative Large Brainwave Models\figure_6_page15.png
2025-11-09 21:45:46,762 - INFO - root - 已保存图片 7/10：./export\images_NeuroRVQ_ Multi-Scale EEG Tokenization for Generative Large Brainwave Models\figure_7_page17.png
2025-11-09 21:45:46,771 - INFO - root - 成功添加图片 1：./export\images_NeuroRVQ_ Multi-Scale EEG Tokenization for Generative Large Brainwave Models\figure_1_page3.png
2025-11-09 21:45:46,778 - INFO - root - 成功添加图片 2：./export\images_NeuroRVQ_ Multi-Scale EEG Tokenization for Generative Large Brainwave Models\figure_2_page6.png
2025-11-09 21:45:46,780 - INFO - root - 成功添加图片 3：./export\images_NeuroRVQ_ Multi-Scale EEG Tokenization for Generative Large Brainwave Models\figure_3_page5.png
2025-11-09 21:45:46,780 - INFO - root - 成功添加图片 4：./export\images_NeuroRVQ_ Multi-Scale EEG Tokenization for Generative Large Brainwave Models\figure_4_page5.png
2025-11-09 21:45:46,783 - INFO - root - 成功添加图片 5：./export\images_NeuroRVQ_ Multi-Scale EEG Tokenization for Generative Large Brainwave Models\figure_5_page7.png
2025-11-09 21:45:46,783 - INFO - root - 成功添加图片 6：./export\images_NeuroRVQ_ Multi-Scale EEG Tokenization for Generative Large Brainwave Models\figure_6_page15.png
2025-11-09 21:45:46,787 - INFO - root - 成功添加图片 7：./export\images_NeuroRVQ_ Multi-Scale EEG Tokenization for Generative Large Brainwave Models\figure_7_page17.png
2025-11-09 21:45:46,793 - INFO - root - 论文《NeuroRVQ: Multi-Scale EEG Tokenization for Generative Large Brainwave Models》的分析已保存到 ./export\NeuroRVQ_ Multi-Scale EEG Tokenization for Generative Large Brainwave Models.md
2025-11-09 21:45:46,805 - INFO - root - 正在总结论文 23/40: Detect Anything via Next Point Prediction
2025-11-09 21:45:46,806 - INFO - root - LLMClient: rate limit reached, sleeping 5.6s
2025-11-09 21:46:02,156 - INFO - root - LLMClient: rate limit reached, sleeping 18.9s
2025-11-09 21:46:47,221 - INFO - root - LLMClient: rate limit reached, sleeping 5.2s
2025-11-09 21:47:12,026 - INFO - root - 正在提取论文图片...
2025-11-09 21:47:14,731 - INFO - root - 已保存图片 1/10：./export\images_Detect Anything via Next Point Prediction\figure_1_page27.png
2025-11-09 21:47:14,963 - INFO - root - 已保存图片 2/10：./export\images_Detect Anything via Next Point Prediction\figure_2_page30.png
2025-11-09 21:47:15,124 - INFO - root - 已保存图片 3/10：./export\images_Detect Anything via Next Point Prediction\figure_3_page1.jpeg
2025-11-09 21:47:15,316 - INFO - root - 已保存图片 4/10：./export\images_Detect Anything via Next Point Prediction\figure_4_page47.jpeg
2025-11-09 21:47:15,426 - INFO - root - 已保存图片 5/10：./export\images_Detect Anything via Next Point Prediction\figure_5_page1.jpeg
2025-11-09 21:47:15,521 - INFO - root - 已保存图片 6/10：./export\images_Detect Anything via Next Point Prediction\figure_6_page7.jpeg
2025-11-09 21:47:15,602 - INFO - root - 已保存图片 7/10：./export\images_Detect Anything via Next Point Prediction\figure_7_page25.jpeg
2025-11-09 21:47:15,711 - INFO - root - 已保存图片 8/10：./export\images_Detect Anything via Next Point Prediction\figure_8_page47.jpeg
2025-11-09 21:47:15,847 - INFO - root - 已保存图片 9/10：./export\images_Detect Anything via Next Point Prediction\figure_9_page47.jpeg
2025-11-09 21:47:15,962 - INFO - root - 已保存图片 10/10：./export\images_Detect Anything via Next Point Prediction\figure_10_page47.jpeg
2025-11-09 21:47:15,999 - INFO - root - 成功添加图片 1：./export\images_Detect Anything via Next Point Prediction\figure_1_page27.png
2025-11-09 21:47:16,000 - INFO - root - 成功添加图片 2：./export\images_Detect Anything via Next Point Prediction\figure_2_page30.png
2025-11-09 21:47:16,000 - INFO - root - 成功添加图片 3：./export\images_Detect Anything via Next Point Prediction\figure_3_page1.jpeg
2025-11-09 21:47:16,000 - INFO - root - 成功添加图片 4：./export\images_Detect Anything via Next Point Prediction\figure_4_page47.jpeg
2025-11-09 21:47:16,002 - INFO - root - 成功添加图片 5：./export\images_Detect Anything via Next Point Prediction\figure_5_page1.jpeg
2025-11-09 21:47:16,002 - INFO - root - 成功添加图片 6：./export\images_Detect Anything via Next Point Prediction\figure_6_page7.jpeg
2025-11-09 21:47:16,002 - INFO - root - 成功添加图片 7：./export\images_Detect Anything via Next Point Prediction\figure_7_page25.jpeg
2025-11-09 21:47:16,003 - INFO - root - 成功添加图片 8：./export\images_Detect Anything via Next Point Prediction\figure_8_page47.jpeg
2025-11-09 21:47:16,003 - INFO - root - 成功添加图片 9：./export\images_Detect Anything via Next Point Prediction\figure_9_page47.jpeg
2025-11-09 21:47:16,004 - INFO - root - 成功添加图片 10：./export\images_Detect Anything via Next Point Prediction\figure_10_page47.jpeg
2025-11-09 21:47:16,014 - INFO - root - 论文《Detect Anything via Next Point Prediction》的分析已保存到 ./export\Detect Anything via Next Point Prediction.md
2025-11-09 21:47:16,017 - INFO - root - 正在总结论文 24/40: AndesVL Technical Report: An Efficient Mobile-side Multimodal Large Language Model
2025-11-09 21:47:16,021 - INFO - root - LLMClient: rate limit reached, sleeping 5.0s
2025-11-09 21:47:33,434 - INFO - root - LLMClient: rate limit reached, sleeping 18.9s
2025-11-09 21:48:20,242 - INFO - root - LLMClient: rate limit reached, sleeping 0.8s
2025-11-09 21:48:41,393 - INFO - root - 正在提取论文图片...
2025-11-09 21:48:44,224 - INFO - root - 已保存图片 1/10：./export\images_AndesVL Technical Report_ An Efficient Mobile-side Multimodal Large Language Mod\figure_1_page2.png
2025-11-09 21:48:44,451 - INFO - root - 已保存图片 2/10：./export\images_AndesVL Technical Report_ An Efficient Mobile-side Multimodal Large Language Mod\figure_2_page52.png
2025-11-09 21:48:44,702 - INFO - root - 已保存图片 3/10：./export\images_AndesVL Technical Report_ An Efficient Mobile-side Multimodal Large Language Mod\figure_3_page49.png
2025-11-09 21:48:44,823 - INFO - root - 已保存图片 4/10：./export\images_AndesVL Technical Report_ An Efficient Mobile-side Multimodal Large Language Mod\figure_4_page48.jpeg
2025-11-09 21:48:44,981 - INFO - root - 已保存图片 5/10：./export\images_AndesVL Technical Report_ An Efficient Mobile-side Multimodal Large Language Mod\figure_5_page51.png
2025-11-09 21:48:45,076 - INFO - root - 已保存图片 6/10：./export\images_AndesVL Technical Report_ An Efficient Mobile-side Multimodal Large Language Mod\figure_6_page46.png
2025-11-09 21:48:45,167 - INFO - root - 已保存图片 7/10：./export\images_AndesVL Technical Report_ An Efficient Mobile-side Multimodal Large Language Mod\figure_7_page51.png
2025-11-09 21:48:45,296 - INFO - root - 已保存图片 8/10：./export\images_AndesVL Technical Report_ An Efficient Mobile-side Multimodal Large Language Mod\figure_8_page5.png
2025-11-09 21:48:45,363 - INFO - root - 已保存图片 9/10：./export\images_AndesVL Technical Report_ An Efficient Mobile-side Multimodal Large Language Mod\figure_9_page11.png
2025-11-09 21:48:45,395 - INFO - root - 已保存图片 10/10：./export\images_AndesVL Technical Report_ An Efficient Mobile-side Multimodal Large Language Mod\figure_10_page13.png
2025-11-09 21:48:45,406 - INFO - root - 成功添加图片 1：./export\images_AndesVL Technical Report_ An Efficient Mobile-side Multimodal Large Language Mod\figure_1_page2.png
2025-11-09 21:48:45,406 - INFO - root - 成功添加图片 2：./export\images_AndesVL Technical Report_ An Efficient Mobile-side Multimodal Large Language Mod\figure_2_page52.png
2025-11-09 21:48:45,407 - INFO - root - 成功添加图片 3：./export\images_AndesVL Technical Report_ An Efficient Mobile-side Multimodal Large Language Mod\figure_3_page49.png
2025-11-09 21:48:45,407 - INFO - root - 成功添加图片 4：./export\images_AndesVL Technical Report_ An Efficient Mobile-side Multimodal Large Language Mod\figure_4_page48.jpeg
2025-11-09 21:48:45,407 - INFO - root - 成功添加图片 5：./export\images_AndesVL Technical Report_ An Efficient Mobile-side Multimodal Large Language Mod\figure_5_page51.png
2025-11-09 21:48:45,409 - INFO - root - 成功添加图片 6：./export\images_AndesVL Technical Report_ An Efficient Mobile-side Multimodal Large Language Mod\figure_6_page46.png
2025-11-09 21:48:45,409 - INFO - root - 成功添加图片 7：./export\images_AndesVL Technical Report_ An Efficient Mobile-side Multimodal Large Language Mod\figure_7_page51.png
2025-11-09 21:48:45,409 - INFO - root - 成功添加图片 8：./export\images_AndesVL Technical Report_ An Efficient Mobile-side Multimodal Large Language Mod\figure_8_page5.png
2025-11-09 21:48:45,409 - INFO - root - 成功添加图片 9：./export\images_AndesVL Technical Report_ An Efficient Mobile-side Multimodal Large Language Mod\figure_9_page11.png
2025-11-09 21:48:45,410 - INFO - root - 成功添加图片 10：./export\images_AndesVL Technical Report_ An Efficient Mobile-side Multimodal Large Language Mod\figure_10_page13.png
2025-11-09 21:48:45,418 - INFO - root - 论文《AndesVL Technical Report: An Efficient Mobile-side Multimodal Large Language Model》的分析已保存到 ./export\AndesVL Technical Report_ An Efficient Mobile-side Multimodal Large Language Mod.md
2025-11-09 21:48:45,424 - INFO - root - 正在总结论文 25/40: Rescaling-Aware Training for Efficient Deployment of Deep Learning Models on Full-Integer Hardware
2025-11-09 21:48:45,424 - INFO - root - LLMClient: rate limit reached, sleeping 7.0s
2025-11-09 21:49:02,758 - INFO - root - LLMClient: rate limit reached, sleeping 18.3s
2025-11-09 21:50:12,311 - INFO - root - 正在提取论文图片...
2025-11-09 21:50:12,410 - INFO - root - 已保存图片 1/10：./export\images_Rescaling-Aware Training for Efficient Deployment of Deep Learning Models on Ful\figure_1_page1.png
2025-11-09 21:50:12,460 - INFO - root - 已保存图片 2/10：./export\images_Rescaling-Aware Training for Efficient Deployment of Deep Learning Models on Ful\figure_2_page3.png
2025-11-09 21:50:12,479 - INFO - root - 已保存图片 3/10：./export\images_Rescaling-Aware Training for Efficient Deployment of Deep Learning Models on Ful\figure_3_page3.png
2025-11-09 21:50:12,498 - INFO - root - 已保存图片 4/10：./export\images_Rescaling-Aware Training for Efficient Deployment of Deep Learning Models on Ful\figure_4_page3.png
2025-11-09 21:50:12,513 - INFO - root - 已保存图片 5/10：./export\images_Rescaling-Aware Training for Efficient Deployment of Deep Learning Models on Ful\figure_5_page3.png
2025-11-09 21:50:12,525 - INFO - root - 已保存图片 6/10：./export\images_Rescaling-Aware Training for Efficient Deployment of Deep Learning Models on Ful\figure_6_page1.png
2025-11-09 21:50:12,545 - INFO - root - 已保存图片 7/10：./export\images_Rescaling-Aware Training for Efficient Deployment of Deep Learning Models on Ful\figure_7_page3.png
2025-11-09 21:50:12,565 - INFO - root - 已保存图片 8/10：./export\images_Rescaling-Aware Training for Efficient Deployment of Deep Learning Models on Ful\figure_8_page3.png
2025-11-09 21:50:12,583 - INFO - root - 已保存图片 9/10：./export\images_Rescaling-Aware Training for Efficient Deployment of Deep Learning Models on Ful\figure_9_page1.png
2025-11-09 21:50:12,609 - INFO - root - 已保存图片 10/10：./export\images_Rescaling-Aware Training for Efficient Deployment of Deep Learning Models on Ful\figure_10_page1.png
2025-11-09 21:50:12,610 - INFO - root - 成功添加图片 1：./export\images_Rescaling-Aware Training for Efficient Deployment of Deep Learning Models on Ful\figure_1_page1.png
2025-11-09 21:50:12,611 - INFO - root - 成功添加图片 2：./export\images_Rescaling-Aware Training for Efficient Deployment of Deep Learning Models on Ful\figure_2_page3.png
2025-11-09 21:50:12,611 - INFO - root - 成功添加图片 3：./export\images_Rescaling-Aware Training for Efficient Deployment of Deep Learning Models on Ful\figure_3_page3.png
2025-11-09 21:50:12,611 - INFO - root - 成功添加图片 4：./export\images_Rescaling-Aware Training for Efficient Deployment of Deep Learning Models on Ful\figure_4_page3.png
2025-11-09 21:50:12,613 - INFO - root - 成功添加图片 5：./export\images_Rescaling-Aware Training for Efficient Deployment of Deep Learning Models on Ful\figure_5_page3.png
2025-11-09 21:50:12,614 - INFO - root - 成功添加图片 6：./export\images_Rescaling-Aware Training for Efficient Deployment of Deep Learning Models on Ful\figure_6_page1.png
2025-11-09 21:50:12,615 - INFO - root - 成功添加图片 7：./export\images_Rescaling-Aware Training for Efficient Deployment of Deep Learning Models on Ful\figure_7_page3.png
2025-11-09 21:50:12,617 - INFO - root - 成功添加图片 8：./export\images_Rescaling-Aware Training for Efficient Deployment of Deep Learning Models on Ful\figure_8_page3.png
2025-11-09 21:50:12,622 - INFO - root - 成功添加图片 9：./export\images_Rescaling-Aware Training for Efficient Deployment of Deep Learning Models on Ful\figure_9_page1.png
2025-11-09 21:50:12,624 - INFO - root - 成功添加图片 10：./export\images_Rescaling-Aware Training for Efficient Deployment of Deep Learning Models on Ful\figure_10_page1.png
2025-11-09 21:50:12,628 - INFO - root - 论文《Rescaling-Aware Training for Efficient Deployment of Deep Learning Models on Full-Integer Hardware》的分析已保存到 ./export\Rescaling-Aware Training for Efficient Deployment of Deep Learning Models on Ful.md
2025-11-09 21:50:12,657 - INFO - root - 正在总结论文 26/40: SASER: Stego attacks on open-source LLMs
2025-11-09 21:50:12,658 - INFO - root - LLMClient: rate limit reached, sleeping 8.4s
2025-11-09 21:50:32,098 - INFO - root - LLMClient: rate limit reached, sleeping 20.6s
2025-11-09 21:51:51,023 - INFO - root - 正在提取论文图片...
2025-11-09 21:51:52,545 - INFO - root - 已保存图片 1/10：./export\images_SASER_ Stego attacks on open-source LLMs\figure_1_page5.png
2025-11-09 21:51:52,557 - INFO - root - 已保存图片 2/10：./export\images_SASER_ Stego attacks on open-source LLMs\figure_2_page8.png
2025-11-09 21:51:52,574 - INFO - root - 已保存图片 3/10：./export\images_SASER_ Stego attacks on open-source LLMs\figure_3_page8.png
2025-11-09 21:51:52,591 - INFO - root - 已保存图片 4/10：./export\images_SASER_ Stego attacks on open-source LLMs\figure_4_page8.png
2025-11-09 21:51:52,604 - INFO - root - 已保存图片 5/10：./export\images_SASER_ Stego attacks on open-source LLMs\figure_5_page8.png
2025-11-09 21:51:52,617 - INFO - root - 已保存图片 6/10：./export\images_SASER_ Stego attacks on open-source LLMs\figure_6_page9.png
2025-11-09 21:51:52,632 - INFO - root - 已保存图片 7/10：./export\images_SASER_ Stego attacks on open-source LLMs\figure_7_page9.png
2025-11-09 21:51:52,644 - INFO - root - 已保存图片 8/10：./export\images_SASER_ Stego attacks on open-source LLMs\figure_8_page9.png
2025-11-09 21:51:52,656 - INFO - root - 已保存图片 9/10：./export\images_SASER_ Stego attacks on open-source LLMs\figure_9_page9.png
2025-11-09 21:51:52,670 - INFO - root - 已保存图片 10/10：./export\images_SASER_ Stego attacks on open-source LLMs\figure_10_page11.png
2025-11-09 21:51:52,677 - INFO - root - 成功添加图片 1：./export\images_SASER_ Stego attacks on open-source LLMs\figure_1_page5.png
2025-11-09 21:51:52,678 - INFO - root - 成功添加图片 2：./export\images_SASER_ Stego attacks on open-source LLMs\figure_2_page8.png
2025-11-09 21:51:52,679 - INFO - root - 成功添加图片 3：./export\images_SASER_ Stego attacks on open-source LLMs\figure_3_page8.png
2025-11-09 21:51:52,680 - INFO - root - 成功添加图片 4：./export\images_SASER_ Stego attacks on open-source LLMs\figure_4_page8.png
2025-11-09 21:51:52,680 - INFO - root - 成功添加图片 5：./export\images_SASER_ Stego attacks on open-source LLMs\figure_5_page8.png
2025-11-09 21:51:52,680 - INFO - root - 成功添加图片 6：./export\images_SASER_ Stego attacks on open-source LLMs\figure_6_page9.png
2025-11-09 21:51:52,681 - INFO - root - 成功添加图片 7：./export\images_SASER_ Stego attacks on open-source LLMs\figure_7_page9.png
2025-11-09 21:51:52,681 - INFO - root - 成功添加图片 8：./export\images_SASER_ Stego attacks on open-source LLMs\figure_8_page9.png
2025-11-09 21:51:52,681 - INFO - root - 成功添加图片 9：./export\images_SASER_ Stego attacks on open-source LLMs\figure_9_page9.png
2025-11-09 21:51:52,683 - INFO - root - 成功添加图片 10：./export\images_SASER_ Stego attacks on open-source LLMs\figure_10_page11.png
2025-11-09 21:51:52,688 - INFO - root - 论文《SASER: Stego attacks on open-source LLMs》的分析已保存到 ./export\SASER_ Stego attacks on open-source LLMs.md
2025-11-09 21:51:52,696 - INFO - root - 正在总结论文 27/40: Ultralytics YOLO Evolution: An Overview of YOLO26, YOLO11, YOLOv8 and YOLOv5 Object Detectors for Computer Vision and Pattern Recognition
2025-11-09 21:51:52,697 - INFO - root - LLMClient: rate limit reached, sleeping 0.0s
2025-11-09 21:52:01,821 - INFO - root - LLMClient: rate limit reached, sleeping 22.6s
2025-11-09 21:53:20,194 - INFO - root - 正在提取论文图片...
2025-11-09 21:53:20,666 - INFO - root - 已保存图片 1/10：./export\images_Ultralytics YOLO Evolution_ An Overview of YOLO26, YOLO11, YOLOv8 and YOLOv5 Obj\figure_1_page6.png
2025-11-09 21:53:20,727 - INFO - root - 已保存图片 2/10：./export\images_Ultralytics YOLO Evolution_ An Overview of YOLO26, YOLO11, YOLOv8 and YOLOv5 Obj\figure_2_page8.png
2025-11-09 21:53:20,738 - INFO - root - 已保存图片 3/10：./export\images_Ultralytics YOLO Evolution_ An Overview of YOLO26, YOLO11, YOLOv8 and YOLOv5 Obj\figure_3_page7.jpeg
2025-11-09 21:53:20,779 - INFO - root - 已保存图片 4/10：./export\images_Ultralytics YOLO Evolution_ An Overview of YOLO26, YOLO11, YOLOv8 and YOLOv5 Obj\figure_4_page5.jpeg
2025-11-09 21:53:20,818 - INFO - root - 已保存图片 5/10：./export\images_Ultralytics YOLO Evolution_ An Overview of YOLO26, YOLO11, YOLOv8 and YOLOv5 Obj\figure_5_page5.jpeg
2025-11-09 21:53:20,850 - INFO - root - 已保存图片 6/10：./export\images_Ultralytics YOLO Evolution_ An Overview of YOLO26, YOLO11, YOLOv8 and YOLOv5 Obj\figure_6_page5.jpeg
2025-11-09 21:53:20,866 - INFO - root - 已保存图片 7/10：./export\images_Ultralytics YOLO Evolution_ An Overview of YOLO26, YOLO11, YOLOv8 and YOLOv5 Obj\figure_7_page5.jpeg
2025-11-09 21:53:20,909 - INFO - root - 已保存图片 8/10：./export\images_Ultralytics YOLO Evolution_ An Overview of YOLO26, YOLO11, YOLOv8 and YOLOv5 Obj\figure_8_page5.jpeg
2025-11-09 21:53:20,923 - INFO - root - 已保存图片 9/10：./export\images_Ultralytics YOLO Evolution_ An Overview of YOLO26, YOLO11, YOLOv8 and YOLOv5 Obj\figure_9_page5.jpeg
2025-11-09 21:53:20,972 - INFO - root - 已保存图片 10/10：./export\images_Ultralytics YOLO Evolution_ An Overview of YOLO26, YOLO11, YOLOv8 and YOLOv5 Obj\figure_10_page5.png
2025-11-09 21:53:20,977 - INFO - root - 成功添加图片 1：./export\images_Ultralytics YOLO Evolution_ An Overview of YOLO26, YOLO11, YOLOv8 and YOLOv5 Obj\figure_1_page6.png
2025-11-09 21:53:20,977 - INFO - root - 成功添加图片 2：./export\images_Ultralytics YOLO Evolution_ An Overview of YOLO26, YOLO11, YOLOv8 and YOLOv5 Obj\figure_2_page8.png
2025-11-09 21:53:20,978 - INFO - root - 成功添加图片 3：./export\images_Ultralytics YOLO Evolution_ An Overview of YOLO26, YOLO11, YOLOv8 and YOLOv5 Obj\figure_3_page7.jpeg
2025-11-09 21:53:20,978 - INFO - root - 成功添加图片 4：./export\images_Ultralytics YOLO Evolution_ An Overview of YOLO26, YOLO11, YOLOv8 and YOLOv5 Obj\figure_4_page5.jpeg
2025-11-09 21:53:20,979 - INFO - root - 成功添加图片 5：./export\images_Ultralytics YOLO Evolution_ An Overview of YOLO26, YOLO11, YOLOv8 and YOLOv5 Obj\figure_5_page5.jpeg
2025-11-09 21:53:20,979 - INFO - root - 成功添加图片 6：./export\images_Ultralytics YOLO Evolution_ An Overview of YOLO26, YOLO11, YOLOv8 and YOLOv5 Obj\figure_6_page5.jpeg
2025-11-09 21:53:20,979 - INFO - root - 成功添加图片 7：./export\images_Ultralytics YOLO Evolution_ An Overview of YOLO26, YOLO11, YOLOv8 and YOLOv5 Obj\figure_7_page5.jpeg
2025-11-09 21:53:20,980 - INFO - root - 成功添加图片 8：./export\images_Ultralytics YOLO Evolution_ An Overview of YOLO26, YOLO11, YOLOv8 and YOLOv5 Obj\figure_8_page5.jpeg
2025-11-09 21:53:20,980 - INFO - root - 成功添加图片 9：./export\images_Ultralytics YOLO Evolution_ An Overview of YOLO26, YOLO11, YOLOv8 and YOLOv5 Obj\figure_9_page5.jpeg
2025-11-09 21:53:20,980 - INFO - root - 成功添加图片 10：./export\images_Ultralytics YOLO Evolution_ An Overview of YOLO26, YOLO11, YOLOv8 and YOLOv5 Obj\figure_10_page5.png
2025-11-09 21:53:20,984 - INFO - root - 论文《Ultralytics YOLO Evolution: An Overview of YOLO26, YOLO11, YOLOv8 and YOLOv5 Object Detectors for Computer Vision and Pattern Recognition》的分析已保存到 ./export\Ultralytics YOLO Evolution_ An Overview of YOLO26, YOLO11, YOLOv8 and YOLOv5 Obj.md
2025-11-09 21:53:20,998 - INFO - root - 正在总结论文 28/40: A Theoretically-Grounded Codebook for Digital Semantic Communications
2025-11-09 21:53:21,000 - INFO - root - LLMClient: rate limit reached, sleeping 3.4s
2025-11-09 21:53:36,120 - INFO - root - LLMClient: rate limit reached, sleeping 19.6s
2025-11-09 21:54:43,975 - INFO - root - 正在提取论文图片...
2025-11-09 21:54:48,650 - INFO - root - 已保存图片 1/10：./export\images_A Theoretically-Grounded Codebook for Digital Semantic Communications\figure_1_page2.png
2025-11-09 21:54:49,210 - INFO - root - 已保存图片 2/10：./export\images_A Theoretically-Grounded Codebook for Digital Semantic Communications\figure_2_page3.png
2025-11-09 21:54:49,322 - INFO - root - 已保存图片 3/10：./export\images_A Theoretically-Grounded Codebook for Digital Semantic Communications\figure_3_page6.png
2025-11-09 21:54:49,453 - INFO - root - 已保存图片 4/10：./export\images_A Theoretically-Grounded Codebook for Digital Semantic Communications\figure_4_page6.png
2025-11-09 21:54:49,497 - INFO - root - 成功添加图片 1：./export\images_A Theoretically-Grounded Codebook for Digital Semantic Communications\figure_1_page2.png
2025-11-09 21:54:49,498 - INFO - root - 成功添加图片 2：./export\images_A Theoretically-Grounded Codebook for Digital Semantic Communications\figure_2_page3.png
2025-11-09 21:54:49,498 - INFO - root - 成功添加图片 3：./export\images_A Theoretically-Grounded Codebook for Digital Semantic Communications\figure_3_page6.png
2025-11-09 21:54:49,498 - INFO - root - 成功添加图片 4：./export\images_A Theoretically-Grounded Codebook for Digital Semantic Communications\figure_4_page6.png
2025-11-09 21:54:49,503 - INFO - root - 论文《A Theoretically-Grounded Codebook for Digital Semantic Communications》的分析已保存到 ./export\A Theoretically-Grounded Codebook for Digital Semantic Communications.md
2025-11-09 21:54:49,509 - INFO - root - 正在总结论文 29/40: QuantDemoire: Quantization with Outlier Aware for Image Demoiréing
2025-11-09 21:54:49,509 - INFO - root - LLMClient: rate limit reached, sleeping 6.2s
2025-11-09 21:55:04,882 - INFO - root - LLMClient: rate limit reached, sleeping 20.6s
2025-11-09 21:56:22,465 - INFO - root - 正在提取论文图片...
2025-11-09 21:56:30,614 - INFO - root - 已保存图片 1/10：./export\images_QuantDemoire_ Quantization with Outlier Aware for Image Demoiréing\figure_1_page8.png
2025-11-09 21:56:31,050 - INFO - root - 已保存图片 2/10：./export\images_QuantDemoire_ Quantization with Outlier Aware for Image Demoiréing\figure_2_page8.png
2025-11-09 21:56:31,489 - INFO - root - 已保存图片 3/10：./export\images_QuantDemoire_ Quantization with Outlier Aware for Image Demoiréing\figure_3_page8.png
2025-11-09 21:56:31,911 - INFO - root - 已保存图片 4/10：./export\images_QuantDemoire_ Quantization with Outlier Aware for Image Demoiréing\figure_4_page8.png
2025-11-09 21:56:31,984 - INFO - root - 已保存图片 5/10：./export\images_QuantDemoire_ Quantization with Outlier Aware for Image Demoiréing\figure_5_page4.jpeg
2025-11-09 21:56:32,041 - INFO - root - 已保存图片 6/10：./export\images_QuantDemoire_ Quantization with Outlier Aware for Image Demoiréing\figure_6_page4.jpeg
2025-11-09 21:56:32,105 - INFO - root - 已保存图片 7/10：./export\images_QuantDemoire_ Quantization with Outlier Aware for Image Demoiréing\figure_7_page4.jpeg
2025-11-09 21:56:32,123 - INFO - root - 已保存图片 8/10：./export\images_QuantDemoire_ Quantization with Outlier Aware for Image Demoiréing\figure_8_page3.jpeg
2025-11-09 21:56:32,146 - INFO - root - 已保存图片 9/10：./export\images_QuantDemoire_ Quantization with Outlier Aware for Image Demoiréing\figure_9_page3.jpeg
2025-11-09 21:56:32,196 - INFO - root - 已保存图片 10/10：./export\images_QuantDemoire_ Quantization with Outlier Aware for Image Demoiréing\figure_10_page2.jpeg
2025-11-09 21:56:32,219 - INFO - root - 成功添加图片 1：./export\images_QuantDemoire_ Quantization with Outlier Aware for Image Demoiréing\figure_1_page8.png
2025-11-09 21:56:32,219 - INFO - root - 成功添加图片 2：./export\images_QuantDemoire_ Quantization with Outlier Aware for Image Demoiréing\figure_2_page8.png
2025-11-09 21:56:32,220 - INFO - root - 成功添加图片 3：./export\images_QuantDemoire_ Quantization with Outlier Aware for Image Demoiréing\figure_3_page8.png
2025-11-09 21:56:32,220 - INFO - root - 成功添加图片 4：./export\images_QuantDemoire_ Quantization with Outlier Aware for Image Demoiréing\figure_4_page8.png
2025-11-09 21:56:32,220 - INFO - root - 成功添加图片 5：./export\images_QuantDemoire_ Quantization with Outlier Aware for Image Demoiréing\figure_5_page4.jpeg
2025-11-09 21:56:32,221 - INFO - root - 成功添加图片 6：./export\images_QuantDemoire_ Quantization with Outlier Aware for Image Demoiréing\figure_6_page4.jpeg
2025-11-09 21:56:32,221 - INFO - root - 成功添加图片 7：./export\images_QuantDemoire_ Quantization with Outlier Aware for Image Demoiréing\figure_7_page4.jpeg
2025-11-09 21:56:32,223 - INFO - root - 成功添加图片 8：./export\images_QuantDemoire_ Quantization with Outlier Aware for Image Demoiréing\figure_8_page3.jpeg
2025-11-09 21:56:32,223 - INFO - root - 成功添加图片 9：./export\images_QuantDemoire_ Quantization with Outlier Aware for Image Demoiréing\figure_9_page3.jpeg
2025-11-09 21:56:32,223 - INFO - root - 成功添加图片 10：./export\images_QuantDemoire_ Quantization with Outlier Aware for Image Demoiréing\figure_10_page2.jpeg
2025-11-09 21:56:32,229 - INFO - root - 论文《QuantDemoire: Quantization with Outlier Aware for Image Demoiréing》的分析已保存到 ./export\QuantDemoire_ Quantization with Outlier Aware for Image Demoiréing.md
2025-11-09 21:56:32,237 - INFO - root - 正在总结论文 30/40: Adaptively Sampling-Reusing-Mixing Decomposed Gradients to Speed Up Sharpness Aware Minimization
2025-11-09 21:56:42,609 - INFO - root - LLMClient: rate limit reached, sleeping 15.9s
2025-11-09 21:58:02,642 - INFO - root - 正在提取论文图片...
2025-11-09 21:58:02,655 - INFO - root - 论文《Adaptively Sampling-Reusing-Mixing Decomposed Gradients to Speed Up Sharpness Aware Minimization》的分析已保存到 ./export\Adaptively Sampling-Reusing-Mixing Decomposed Gradients to Speed Up Sharpness Aw.md
2025-11-09 21:58:02,661 - INFO - root - 正在总结论文 31/40: Quant-dLLM: Post-Training Extreme Low-Bit Quantization for Diffusion Large Language Models
2025-11-09 21:58:16,405 - INFO - root - LLMClient: rate limit reached, sleeping 24.1s
2025-11-09 21:59:33,510 - INFO - root - 正在提取论文图片...
2025-11-09 21:59:33,594 - INFO - root - 已保存图片 1/10：./export\images_Quant-dLLM_ Post-Training Extreme Low-Bit Quantization for Diffusion Large Langu\figure_1_page3.jpeg
2025-11-09 21:59:33,680 - INFO - root - 已保存图片 2/10：./export\images_Quant-dLLM_ Post-Training Extreme Low-Bit Quantization for Diffusion Large Langu\figure_2_page3.png
2025-11-09 21:59:33,727 - INFO - root - 已保存图片 3/10：./export\images_Quant-dLLM_ Post-Training Extreme Low-Bit Quantization for Diffusion Large Langu\figure_3_page3.jpeg
2025-11-09 21:59:33,806 - INFO - root - 已保存图片 4/10：./export\images_Quant-dLLM_ Post-Training Extreme Low-Bit Quantization for Diffusion Large Langu\figure_4_page3.png
2025-11-09 21:59:33,871 - INFO - root - 已保存图片 5/10：./export\images_Quant-dLLM_ Post-Training Extreme Low-Bit Quantization for Diffusion Large Langu\figure_5_page3.png
2025-11-09 21:59:33,952 - INFO - root - 已保存图片 6/10：./export\images_Quant-dLLM_ Post-Training Extreme Low-Bit Quantization for Diffusion Large Langu\figure_6_page3.png
2025-11-09 21:59:34,016 - INFO - root - 已保存图片 7/10：./export\images_Quant-dLLM_ Post-Training Extreme Low-Bit Quantization for Diffusion Large Langu\figure_7_page3.png
2025-11-09 21:59:34,058 - INFO - root - 已保存图片 8/10：./export\images_Quant-dLLM_ Post-Training Extreme Low-Bit Quantization for Diffusion Large Langu\figure_8_page3.jpeg
2025-11-09 21:59:34,143 - INFO - root - 已保存图片 9/10：./export\images_Quant-dLLM_ Post-Training Extreme Low-Bit Quantization for Diffusion Large Langu\figure_9_page3.png
2025-11-09 21:59:34,160 - INFO - root - 已保存图片 10/10：./export\images_Quant-dLLM_ Post-Training Extreme Low-Bit Quantization for Diffusion Large Langu\figure_10_page3.png
2025-11-09 21:59:34,165 - INFO - root - 成功添加图片 1：./export\images_Quant-dLLM_ Post-Training Extreme Low-Bit Quantization for Diffusion Large Langu\figure_1_page3.jpeg
2025-11-09 21:59:34,166 - INFO - root - 成功添加图片 2：./export\images_Quant-dLLM_ Post-Training Extreme Low-Bit Quantization for Diffusion Large Langu\figure_2_page3.png
2025-11-09 21:59:34,166 - INFO - root - 成功添加图片 3：./export\images_Quant-dLLM_ Post-Training Extreme Low-Bit Quantization for Diffusion Large Langu\figure_3_page3.jpeg
2025-11-09 21:59:34,167 - INFO - root - 成功添加图片 4：./export\images_Quant-dLLM_ Post-Training Extreme Low-Bit Quantization for Diffusion Large Langu\figure_4_page3.png
2025-11-09 21:59:34,167 - INFO - root - 成功添加图片 5：./export\images_Quant-dLLM_ Post-Training Extreme Low-Bit Quantization for Diffusion Large Langu\figure_5_page3.png
2025-11-09 21:59:34,167 - INFO - root - 成功添加图片 6：./export\images_Quant-dLLM_ Post-Training Extreme Low-Bit Quantization for Diffusion Large Langu\figure_6_page3.png
2025-11-09 21:59:34,169 - INFO - root - 成功添加图片 7：./export\images_Quant-dLLM_ Post-Training Extreme Low-Bit Quantization for Diffusion Large Langu\figure_7_page3.png
2025-11-09 21:59:34,169 - INFO - root - 成功添加图片 8：./export\images_Quant-dLLM_ Post-Training Extreme Low-Bit Quantization for Diffusion Large Langu\figure_8_page3.jpeg
2025-11-09 21:59:34,169 - INFO - root - 成功添加图片 9：./export\images_Quant-dLLM_ Post-Training Extreme Low-Bit Quantization for Diffusion Large Langu\figure_9_page3.png
2025-11-09 21:59:34,170 - INFO - root - 成功添加图片 10：./export\images_Quant-dLLM_ Post-Training Extreme Low-Bit Quantization for Diffusion Large Langu\figure_10_page3.png
2025-11-09 21:59:34,177 - INFO - root - 论文《Quant-dLLM: Post-Training Extreme Low-Bit Quantization for Diffusion Large Language Models》的分析已保存到 ./export\Quant-dLLM_ Post-Training Extreme Low-Bit Quantization for Diffusion Large Langu.md
2025-11-09 21:59:34,188 - INFO - root - 正在总结论文 32/40: PT$^2$-LLM: Post-Training Ternarization for Large Language Models
2025-11-09 21:59:34,189 - INFO - root - LLMClient: rate limit reached, sleeping 6.3s
2025-11-09 21:59:51,794 - INFO - root - LLMClient: rate limit reached, sleeping 19.7s
2025-11-09 22:01:38,787 - INFO - root - 正在提取论文图片...
2025-11-09 22:01:39,482 - INFO - root - 已保存图片 1/10：./export\images_PT$^2$-LLM_ Post-Training Ternarization for Large Language Models\figure_1_page6.png
2025-11-09 22:01:39,686 - INFO - root - 已保存图片 2/10：./export\images_PT$^2$-LLM_ Post-Training Ternarization for Large Language Models\figure_2_page6.png
2025-11-09 22:01:39,766 - INFO - root - 已保存图片 3/10：./export\images_PT$^2$-LLM_ Post-Training Ternarization for Large Language Models\figure_3_page6.png
2025-11-09 22:01:39,844 - INFO - root - 已保存图片 4/10：./export\images_PT$^2$-LLM_ Post-Training Ternarization for Large Language Models\figure_4_page3.png
2025-11-09 22:01:39,918 - INFO - root - 已保存图片 5/10：./export\images_PT$^2$-LLM_ Post-Training Ternarization for Large Language Models\figure_5_page3.png
2025-11-09 22:01:39,966 - INFO - root - 已保存图片 6/10：./export\images_PT$^2$-LLM_ Post-Training Ternarization for Large Language Models\figure_6_page3.jpeg
2025-11-09 22:01:40,001 - INFO - root - 已保存图片 7/10：./export\images_PT$^2$-LLM_ Post-Training Ternarization for Large Language Models\figure_7_page6.jpeg
2025-11-09 22:01:40,048 - INFO - root - 已保存图片 8/10：./export\images_PT$^2$-LLM_ Post-Training Ternarization for Large Language Models\figure_8_page3.jpeg
2025-11-09 22:01:40,092 - INFO - root - 已保存图片 9/10：./export\images_PT$^2$-LLM_ Post-Training Ternarization for Large Language Models\figure_9_page6.jpeg
2025-11-09 22:01:40,171 - INFO - root - 已保存图片 10/10：./export\images_PT$^2$-LLM_ Post-Training Ternarization for Large Language Models\figure_10_page3.png
2025-11-09 22:01:40,177 - INFO - root - 成功添加图片 1：./export\images_PT$^2$-LLM_ Post-Training Ternarization for Large Language Models\figure_1_page6.png
2025-11-09 22:01:40,177 - INFO - root - 成功添加图片 2：./export\images_PT$^2$-LLM_ Post-Training Ternarization for Large Language Models\figure_2_page6.png
2025-11-09 22:01:40,179 - INFO - root - 成功添加图片 3：./export\images_PT$^2$-LLM_ Post-Training Ternarization for Large Language Models\figure_3_page6.png
2025-11-09 22:01:40,180 - INFO - root - 成功添加图片 4：./export\images_PT$^2$-LLM_ Post-Training Ternarization for Large Language Models\figure_4_page3.png
2025-11-09 22:01:40,181 - INFO - root - 成功添加图片 5：./export\images_PT$^2$-LLM_ Post-Training Ternarization for Large Language Models\figure_5_page3.png
2025-11-09 22:01:40,181 - INFO - root - 成功添加图片 6：./export\images_PT$^2$-LLM_ Post-Training Ternarization for Large Language Models\figure_6_page3.jpeg
2025-11-09 22:01:40,182 - INFO - root - 成功添加图片 7：./export\images_PT$^2$-LLM_ Post-Training Ternarization for Large Language Models\figure_7_page6.jpeg
2025-11-09 22:01:40,182 - INFO - root - 成功添加图片 8：./export\images_PT$^2$-LLM_ Post-Training Ternarization for Large Language Models\figure_8_page3.jpeg
2025-11-09 22:01:40,182 - INFO - root - 成功添加图片 9：./export\images_PT$^2$-LLM_ Post-Training Ternarization for Large Language Models\figure_9_page6.jpeg
2025-11-09 22:01:40,183 - INFO - root - 成功添加图片 10：./export\images_PT$^2$-LLM_ Post-Training Ternarization for Large Language Models\figure_10_page3.png
2025-11-09 22:01:40,198 - INFO - root - 论文《PT$^2$-LLM: Post-Training Ternarization for Large Language Models》的分析已保存到 ./export\PT$^2$-LLM_ Post-Training Ternarization for Large Language Models.md
2025-11-09 22:01:40,201 - INFO - root - 正在总结论文 33/40: Purrception: Variational Flow Matching for Vector-Quantized Image Generation
2025-11-09 22:01:50,870 - INFO - root - LLMClient: rate limit reached, sleeping 25.4s
2025-11-09 22:03:22,927 - INFO - root - 正在提取论文图片...
2025-11-09 22:03:23,208 - INFO - root - 已保存图片 1/10：./export\images_Purrception_ Variational Flow Matching for Vector-Quantized Image Generation\figure_1_page7.jpeg
2025-11-09 22:03:23,688 - INFO - root - 已保存图片 2/10：./export\images_Purrception_ Variational Flow Matching for Vector-Quantized Image Generation\figure_2_page5.jpeg
2025-11-09 22:03:23,809 - INFO - root - 已保存图片 3/10：./export\images_Purrception_ Variational Flow Matching for Vector-Quantized Image Generation\figure_3_page1.jpeg
2025-11-09 22:03:23,837 - INFO - root - 成功添加图片 1：./export\images_Purrception_ Variational Flow Matching for Vector-Quantized Image Generation\figure_1_page7.jpeg
2025-11-09 22:03:23,852 - INFO - root - 成功添加图片 2：./export\images_Purrception_ Variational Flow Matching for Vector-Quantized Image Generation\figure_2_page5.jpeg
2025-11-09 22:03:23,871 - INFO - root - 成功添加图片 3：./export\images_Purrception_ Variational Flow Matching for Vector-Quantized Image Generation\figure_3_page1.jpeg
2025-11-09 22:03:23,886 - INFO - root - 论文《Purrception: Variational Flow Matching for Vector-Quantized Image Generation》的分析已保存到 ./export\Purrception_ Variational Flow Matching for Vector-Quantized Image Generation.md
2025-11-09 22:03:23,897 - INFO - root - 正在总结论文 34/40: Post-Training Quantization for Audio Diffusion Transformers
2025-11-09 22:03:32,806 - INFO - root - LLMClient: rate limit reached, sleeping 24.2s
2025-11-09 22:04:49,380 - INFO - root - 正在提取论文图片...
2025-11-09 22:04:50,141 - INFO - root - 已保存图片 1/10：./export\images_Post-Training Quantization for Audio Diffusion Transformers\figure_1_page4.png
2025-11-09 22:04:50,271 - INFO - root - 已保存图片 2/10：./export\images_Post-Training Quantization for Audio Diffusion Transformers\figure_2_page3.png
2025-11-09 22:04:50,366 - INFO - root - 已保存图片 3/10：./export\images_Post-Training Quantization for Audio Diffusion Transformers\figure_3_page2.png
2025-11-09 22:04:50,411 - INFO - root - 已保存图片 4/10：./export\images_Post-Training Quantization for Audio Diffusion Transformers\figure_4_page2.png
2025-11-09 22:04:50,417 - INFO - root - 成功添加图片 1：./export\images_Post-Training Quantization for Audio Diffusion Transformers\figure_1_page4.png
2025-11-09 22:04:50,418 - INFO - root - 成功添加图片 2：./export\images_Post-Training Quantization for Audio Diffusion Transformers\figure_2_page3.png
2025-11-09 22:04:50,418 - INFO - root - 成功添加图片 3：./export\images_Post-Training Quantization for Audio Diffusion Transformers\figure_3_page2.png
2025-11-09 22:04:50,418 - INFO - root - 成功添加图片 4：./export\images_Post-Training Quantization for Audio Diffusion Transformers\figure_4_page2.png
2025-11-09 22:04:50,421 - INFO - root - 论文《Post-Training Quantization for Audio Diffusion Transformers》的分析已保存到 ./export\Post-Training Quantization for Audio Diffusion Transformers.md
2025-11-09 22:04:50,425 - INFO - root - 正在总结论文 35/40: Rethinking RoPE Scaling in Quantized LLM: Theory, Outlier, and Channel-Band Analysis with Weight Rescaling
2025-11-09 22:04:50,426 - INFO - root - LLMClient: rate limit reached, sleeping 6.5s
2025-11-09 22:05:09,479 - INFO - root - LLMClient: rate limit reached, sleeping 17.3s
2025-11-09 22:06:19,331 - INFO - root - 正在提取论文图片...
2025-11-09 22:06:19,862 - INFO - root - 已保存图片 1/10：./export\images_Rethinking RoPE Scaling in Quantized LLM_ Theory, Outlier, and Channel-Band Anal\figure_1_page20.png
2025-11-09 22:06:20,053 - INFO - root - 已保存图片 2/10：./export\images_Rethinking RoPE Scaling in Quantized LLM_ Theory, Outlier, and Channel-Band Anal\figure_2_page25.png
2025-11-09 22:06:20,066 - INFO - root - 已保存图片 3/10：./export\images_Rethinking RoPE Scaling in Quantized LLM_ Theory, Outlier, and Channel-Band Anal\figure_3_page25.png
2025-11-09 22:06:20,076 - INFO - root - 成功添加图片 1：./export\images_Rethinking RoPE Scaling in Quantized LLM_ Theory, Outlier, and Channel-Band Anal\figure_1_page20.png
2025-11-09 22:06:20,090 - INFO - root - 成功添加图片 2：./export\images_Rethinking RoPE Scaling in Quantized LLM_ Theory, Outlier, and Channel-Band Anal\figure_2_page25.png
2025-11-09 22:06:20,090 - INFO - root - 成功添加图片 3：./export\images_Rethinking RoPE Scaling in Quantized LLM_ Theory, Outlier, and Channel-Band Anal\figure_3_page25.png
2025-11-09 22:06:20,095 - INFO - root - 论文《Rethinking RoPE Scaling in Quantized LLM: Theory, Outlier, and Channel-Band Analysis with Weight Rescaling》的分析已保存到 ./export\Rethinking RoPE Scaling in Quantized LLM_ Theory, Outlier, and Channel-Band Anal.md
2025-11-09 22:06:20,106 - INFO - root - 正在总结论文 36/40: Post-Training Quantization via Residual Truncation and Zero Suppression for Diffusion Models
2025-11-09 22:06:20,106 - INFO - root - LLMClient: rate limit reached, sleeping 6.6s
2025-11-09 22:06:35,581 - INFO - root - LLMClient: rate limit reached, sleeping 22.4s
2025-11-09 22:07:48,240 - INFO - root - 正在提取论文图片...
2025-11-09 22:07:51,782 - INFO - root - 已保存图片 1/10：./export\images_Post-Training Quantization via Residual Truncation and Zero Suppression for Diff\figure_1_page3.png
2025-11-09 22:07:51,936 - INFO - root - 已保存图片 2/10：./export\images_Post-Training Quantization via Residual Truncation and Zero Suppression for Diff\figure_2_page9.png
2025-11-09 22:07:52,086 - INFO - root - 已保存图片 3/10：./export\images_Post-Training Quantization via Residual Truncation and Zero Suppression for Diff\figure_3_page19.png
2025-11-09 22:07:52,148 - INFO - root - 已保存图片 4/10：./export\images_Post-Training Quantization via Residual Truncation and Zero Suppression for Diff\figure_4_page9.png
2025-11-09 22:07:52,241 - INFO - root - 已保存图片 5/10：./export\images_Post-Training Quantization via Residual Truncation and Zero Suppression for Diff\figure_5_page1.png
2025-11-09 22:07:52,345 - INFO - root - 已保存图片 6/10：./export\images_Post-Training Quantization via Residual Truncation and Zero Suppression for Diff\figure_6_page7.png
2025-11-09 22:07:52,436 - INFO - root - 已保存图片 7/10：./export\images_Post-Training Quantization via Residual Truncation and Zero Suppression for Diff\figure_7_page7.png
2025-11-09 22:07:52,505 - INFO - root - 已保存图片 8/10：./export\images_Post-Training Quantization via Residual Truncation and Zero Suppression for Diff\figure_8_page5.png
2025-11-09 22:07:52,575 - INFO - root - 已保存图片 9/10：./export\images_Post-Training Quantization via Residual Truncation and Zero Suppression for Diff\figure_9_page14.png
2025-11-09 22:07:52,655 - INFO - root - 已保存图片 10/10：./export\images_Post-Training Quantization via Residual Truncation and Zero Suppression for Diff\figure_10_page14.png
2025-11-09 22:07:52,669 - INFO - root - 成功添加图片 1：./export\images_Post-Training Quantization via Residual Truncation and Zero Suppression for Diff\figure_1_page3.png
2025-11-09 22:07:52,669 - INFO - root - 成功添加图片 2：./export\images_Post-Training Quantization via Residual Truncation and Zero Suppression for Diff\figure_2_page9.png
2025-11-09 22:07:52,671 - INFO - root - 成功添加图片 3：./export\images_Post-Training Quantization via Residual Truncation and Zero Suppression for Diff\figure_3_page19.png
2025-11-09 22:07:52,672 - INFO - root - 成功添加图片 4：./export\images_Post-Training Quantization via Residual Truncation and Zero Suppression for Diff\figure_4_page9.png
2025-11-09 22:07:52,672 - INFO - root - 成功添加图片 5：./export\images_Post-Training Quantization via Residual Truncation and Zero Suppression for Diff\figure_5_page1.png
2025-11-09 22:07:52,673 - INFO - root - 成功添加图片 6：./export\images_Post-Training Quantization via Residual Truncation and Zero Suppression for Diff\figure_6_page7.png
2025-11-09 22:07:52,675 - INFO - root - 成功添加图片 7：./export\images_Post-Training Quantization via Residual Truncation and Zero Suppression for Diff\figure_7_page7.png
2025-11-09 22:07:52,677 - INFO - root - 成功添加图片 8：./export\images_Post-Training Quantization via Residual Truncation and Zero Suppression for Diff\figure_8_page5.png
2025-11-09 22:07:52,680 - INFO - root - 成功添加图片 9：./export\images_Post-Training Quantization via Residual Truncation and Zero Suppression for Diff\figure_9_page14.png
2025-11-09 22:07:52,681 - INFO - root - 成功添加图片 10：./export\images_Post-Training Quantization via Residual Truncation and Zero Suppression for Diff\figure_10_page14.png
2025-11-09 22:07:52,710 - INFO - root - 论文《Post-Training Quantization via Residual Truncation and Zero Suppression for Diffusion Models》的分析已保存到 ./export\Post-Training Quantization via Residual Truncation and Zero Suppression for Diff.md
2025-11-09 22:07:52,760 - INFO - root - 正在总结论文 37/40: Cat: Post-Training Quantization Error Reduction via Cluster-based Affine Transformation
2025-11-09 22:07:52,760 - INFO - root - LLMClient: rate limit reached, sleeping 5.2s
2025-11-09 22:08:09,192 - INFO - root - LLMClient: rate limit reached, sleeping 20.0s
2025-11-09 22:09:29,376 - INFO - root - 正在提取论文图片...
2025-11-09 22:09:29,405 - INFO - root - 论文《Cat: Post-Training Quantization Error Reduction via Cluster-based Affine Transformation》的分析已保存到 ./export\Cat_ Post-Training Quantization Error Reduction via Cluster-based Affine Transfo.md
2025-11-09 22:09:29,413 - INFO - root - 正在总结论文 38/40: CAST: Continuous and Differentiable Semi-Structured Sparsity-Aware Training for Large Language Models
2025-11-09 22:09:41,558 - INFO - root - LLMClient: rate limit reached, sleeping 22.0s
2025-11-09 22:10:54,556 - INFO - root - 正在提取论文图片...
2025-11-09 22:10:54,782 - INFO - root - 已保存图片 1/10：./export\images_CAST_ Continuous and Differentiable Semi-Structured Sparsity-Aware Training for\figure_1_page12.jpeg
2025-11-09 22:10:54,873 - INFO - root - 已保存图片 2/10：./export\images_CAST_ Continuous and Differentiable Semi-Structured Sparsity-Aware Training for\figure_2_page12.jpeg
2025-11-09 22:10:54,974 - INFO - root - 已保存图片 3/10：./export\images_CAST_ Continuous and Differentiable Semi-Structured Sparsity-Aware Training for\figure_3_page12.jpeg
2025-11-09 22:10:55,028 - INFO - root - 已保存图片 4/10：./export\images_CAST_ Continuous and Differentiable Semi-Structured Sparsity-Aware Training for\figure_4_page15.jpeg
2025-11-09 22:10:55,101 - INFO - root - 已保存图片 5/10：./export\images_CAST_ Continuous and Differentiable Semi-Structured Sparsity-Aware Training for\figure_5_page5.png
2025-11-09 22:10:55,148 - INFO - root - 已保存图片 6/10：./export\images_CAST_ Continuous and Differentiable Semi-Structured Sparsity-Aware Training for\figure_6_page15.jpeg
2025-11-09 22:10:55,252 - INFO - root - 已保存图片 7/10：./export\images_CAST_ Continuous and Differentiable Semi-Structured Sparsity-Aware Training for\figure_7_page15.jpeg
2025-11-09 22:10:55,279 - INFO - root - 已保存图片 8/10：./export\images_CAST_ Continuous and Differentiable Semi-Structured Sparsity-Aware Training for\figure_8_page8.jpeg
2025-11-09 22:10:55,342 - INFO - root - 已保存图片 9/10：./export\images_CAST_ Continuous and Differentiable Semi-Structured Sparsity-Aware Training for\figure_9_page15.jpeg
2025-11-09 22:10:55,360 - INFO - root - 已保存图片 10/10：./export\images_CAST_ Continuous and Differentiable Semi-Structured Sparsity-Aware Training for\figure_10_page4.jpeg
2025-11-09 22:10:55,367 - INFO - root - 成功添加图片 1：./export\images_CAST_ Continuous and Differentiable Semi-Structured Sparsity-Aware Training for\figure_1_page12.jpeg
2025-11-09 22:10:55,367 - INFO - root - 成功添加图片 2：./export\images_CAST_ Continuous and Differentiable Semi-Structured Sparsity-Aware Training for\figure_2_page12.jpeg
2025-11-09 22:10:55,367 - INFO - root - 成功添加图片 3：./export\images_CAST_ Continuous and Differentiable Semi-Structured Sparsity-Aware Training for\figure_3_page12.jpeg
2025-11-09 22:10:55,368 - INFO - root - 成功添加图片 4：./export\images_CAST_ Continuous and Differentiable Semi-Structured Sparsity-Aware Training for\figure_4_page15.jpeg
2025-11-09 22:10:55,368 - INFO - root - 成功添加图片 5：./export\images_CAST_ Continuous and Differentiable Semi-Structured Sparsity-Aware Training for\figure_5_page5.png
2025-11-09 22:10:55,369 - INFO - root - 成功添加图片 6：./export\images_CAST_ Continuous and Differentiable Semi-Structured Sparsity-Aware Training for\figure_6_page15.jpeg
2025-11-09 22:10:55,369 - INFO - root - 成功添加图片 7：./export\images_CAST_ Continuous and Differentiable Semi-Structured Sparsity-Aware Training for\figure_7_page15.jpeg
2025-11-09 22:10:55,369 - INFO - root - 成功添加图片 8：./export\images_CAST_ Continuous and Differentiable Semi-Structured Sparsity-Aware Training for\figure_8_page8.jpeg
2025-11-09 22:10:55,370 - INFO - root - 成功添加图片 9：./export\images_CAST_ Continuous and Differentiable Semi-Structured Sparsity-Aware Training for\figure_9_page15.jpeg
2025-11-09 22:10:55,370 - INFO - root - 成功添加图片 10：./export\images_CAST_ Continuous and Differentiable Semi-Structured Sparsity-Aware Training for\figure_10_page4.jpeg
2025-11-09 22:10:55,374 - INFO - root - 论文《CAST: Continuous and Differentiable Semi-Structured Sparsity-Aware Training for Large Language Models》的分析已保存到 ./export\CAST_ Continuous and Differentiable Semi-Structured Sparsity-Aware Training for.md
2025-11-09 22:10:55,382 - INFO - root - 正在总结论文 39/40: Norm-Q: Effective Compression Method for Hidden Markov Models in Neuro-Symbolic Applications
2025-11-09 22:10:55,383 - INFO - root - LLMClient: rate limit reached, sleeping 8.2s
2025-11-09 22:11:18,062 - INFO - root - LLMClient: rate limit reached, sleeping 15.2s
2025-11-09 22:12:03,132 - INFO - root - LLMClient: rate limit reached, sleeping 0.5s
2025-11-09 22:12:21,552 - INFO - root - 正在提取论文图片...
2025-11-09 22:12:21,575 - INFO - root - 已保存图片 1/10：./export\images_Norm-Q_ Effective Compression Method for Hidden Markov Models in Neuro-Symbolic\figure_1_page3.png
2025-11-09 22:12:21,582 - INFO - root - 成功添加图片 1：./export\images_Norm-Q_ Effective Compression Method for Hidden Markov Models in Neuro-Symbolic\figure_1_page3.png
2025-11-09 22:12:21,586 - INFO - root - 论文《Norm-Q: Effective Compression Method for Hidden Markov Models in Neuro-Symbolic Applications》的分析已保存到 ./export\Norm-Q_ Effective Compression Method for Hidden Markov Models in Neuro-Symbolic.md
2025-11-09 22:12:21,592 - INFO - root - 正在总结论文 40/40: On-the-Fly Adaptation to Quantization: Configuration-Aware LoRA for Efficient Fine-Tuning of Quantized LLMs
2025-11-09 22:12:21,595 - INFO - root - LLMClient: rate limit reached, sleeping 11.7s
2025-11-09 22:12:44,615 - INFO - root - LLMClient: rate limit reached, sleeping 19.0s
2025-11-09 22:14:00,619 - INFO - root - 正在提取论文图片...
2025-11-09 22:14:00,905 - INFO - root - 已保存图片 1/10：./export\images_On-the-Fly Adaptation to Quantization_ Configuration-Aware LoRA for Efficient Fi\figure_1_page4.jpeg
2025-11-09 22:14:00,944 - INFO - root - 已保存图片 2/10：./export\images_On-the-Fly Adaptation to Quantization_ Configuration-Aware LoRA for Efficient Fi\figure_2_page5.png
2025-11-09 22:14:01,007 - INFO - root - 已保存图片 3/10：./export\images_On-the-Fly Adaptation to Quantization_ Configuration-Aware LoRA for Efficient Fi\figure_3_page5.png
2025-11-09 22:14:01,015 - INFO - root - 已保存图片 4/10：./export\images_On-the-Fly Adaptation to Quantization_ Configuration-Aware LoRA for Efficient Fi\figure_4_page16.png
2025-11-09 22:14:01,025 - INFO - root - 已保存图片 5/10：./export\images_On-the-Fly Adaptation to Quantization_ Configuration-Aware LoRA for Efficient Fi\figure_5_page16.png
2025-11-09 22:14:01,038 - INFO - root - 已保存图片 6/10：./export\images_On-the-Fly Adaptation to Quantization_ Configuration-Aware LoRA for Efficient Fi\figure_6_page16.png
2025-11-09 22:14:01,048 - INFO - root - 已保存图片 7/10：./export\images_On-the-Fly Adaptation to Quantization_ Configuration-Aware LoRA for Efficient Fi\figure_7_page16.png
2025-11-09 22:14:01,061 - INFO - root - 已保存图片 8/10：./export\images_On-the-Fly Adaptation to Quantization_ Configuration-Aware LoRA for Efficient Fi\figure_8_page16.png
2025-11-09 22:14:01,072 - INFO - root - 已保存图片 9/10：./export\images_On-the-Fly Adaptation to Quantization_ Configuration-Aware LoRA for Efficient Fi\figure_9_page16.png
2025-11-09 22:14:01,084 - INFO - root - 已保存图片 10/10：./export\images_On-the-Fly Adaptation to Quantization_ Configuration-Aware LoRA for Efficient Fi\figure_10_page16.png
2025-11-09 22:14:01,085 - INFO - root - 成功添加图片 1：./export\images_On-the-Fly Adaptation to Quantization_ Configuration-Aware LoRA for Efficient Fi\figure_1_page4.jpeg
2025-11-09 22:14:01,085 - INFO - root - 成功添加图片 2：./export\images_On-the-Fly Adaptation to Quantization_ Configuration-Aware LoRA for Efficient Fi\figure_2_page5.png
2025-11-09 22:14:01,086 - INFO - root - 成功添加图片 3：./export\images_On-the-Fly Adaptation to Quantization_ Configuration-Aware LoRA for Efficient Fi\figure_3_page5.png
2025-11-09 22:14:01,087 - INFO - root - 成功添加图片 4：./export\images_On-the-Fly Adaptation to Quantization_ Configuration-Aware LoRA for Efficient Fi\figure_4_page16.png
2025-11-09 22:14:01,087 - INFO - root - 成功添加图片 5：./export\images_On-the-Fly Adaptation to Quantization_ Configuration-Aware LoRA for Efficient Fi\figure_5_page16.png
2025-11-09 22:14:01,089 - INFO - root - 成功添加图片 6：./export\images_On-the-Fly Adaptation to Quantization_ Configuration-Aware LoRA for Efficient Fi\figure_6_page16.png
2025-11-09 22:14:01,089 - INFO - root - 成功添加图片 7：./export\images_On-the-Fly Adaptation to Quantization_ Configuration-Aware LoRA for Efficient Fi\figure_7_page16.png
2025-11-09 22:14:01,090 - INFO - root - 成功添加图片 8：./export\images_On-the-Fly Adaptation to Quantization_ Configuration-Aware LoRA for Efficient Fi\figure_8_page16.png
2025-11-09 22:14:01,090 - INFO - root - 成功添加图片 9：./export\images_On-the-Fly Adaptation to Quantization_ Configuration-Aware LoRA for Efficient Fi\figure_9_page16.png
2025-11-09 22:14:01,090 - INFO - root - 成功添加图片 10：./export\images_On-the-Fly Adaptation to Quantization_ Configuration-Aware LoRA for Efficient Fi\figure_10_page16.png
2025-11-09 22:14:01,093 - INFO - root - 论文《On-the-Fly Adaptation to Quantization: Configuration-Aware LoRA for Efficient Fine-Tuning of Quantized LLMs》的分析已保存到 ./export\On-the-Fly Adaptation to Quantization_ Configuration-Aware LoRA for Efficient Fi.md
2025-11-09 22:14:01,099 - INFO - root - summary time: 2520.59 seconds
2025-11-09 22:23:34,726 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-09 22:23:34,728 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-09 22:23:34,729 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-09 22:23:35,988 - INFO - root - LLMClientManager: 指定使用客户端: DeepSeek
2025-11-09 22:23:35,990 - INFO - root - DeepSeekClient: API key found: 9f9e270e-b...
2025-11-09 22:23:35,990 - INFO - root - DeepSeekClient: 使用模式: 火山引擎
2025-11-09 22:23:35,991 - INFO - root - DeepSeekClient: 模型名称: deepseek-v3-1-terminus
2025-11-09 22:23:40,254 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 22:23:40,276 - INFO - root - DeepSeekClient: initialized successfully with model deepseek-v3-1-terminus
2025-11-09 22:23:40,278 - INFO - root - LLMClientManager: DeepSeek 客户端初始化成功
2025-11-09 22:23:40,278 - INFO - root - LLMClientManager: switched to DeepSeek client
2025-11-09 22:23:40,279 - INFO - root - 已手动切换到 LLM 客户端: DeepSeek
2025-11-09 22:23:40,279 - INFO - root - 使用 LLM 模型: deepseek-v3-1-terminus
2025-11-09 22:23:40,281 - INFO - root - 可用客户端: ['DeepSeek']
2025-11-09 22:23:40,281 - INFO - root - === 运行配置 ===
2025-11-09 22:23:40,281 - INFO - root - 处理模式: arxiv在线搜索
2025-11-09 22:23:40,282 - INFO - root - 关键词: QAT
2025-11-09 22:23:40,282 - INFO - root - 查询: Quantization-Aware-Training
2025-11-09 22:23:40,282 - INFO - root - 排序: None
2025-11-09 22:23:40,283 - INFO - root - 最近天数: 180
2025-11-09 22:23:40,283 - INFO - root - 最大处理数量: 80
2025-11-09 22:23:40,284 - INFO - root - 保存图片: 是
2025-11-09 22:23:40,284 - INFO - root - 输出语言: 中文
2025-11-09 22:23:40,284 - INFO - root - 强制重新处理: 否
2025-11-09 22:23:40,285 - INFO - root - ====================
2025-11-09 22:23:40,285 - INFO - root - 使用 arXiv 搜索模式（通过 chat_arxiv 模块获取）
2025-11-09 22:23:40,285 - INFO - root - Fetching page 1 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50
2025-11-09 22:23:47,708 - INFO - root - get_all_titles_from_web 
2025-11-09 22:23:47,708 - INFO - root - Page:0, Index:0, A Quantized VAE-MLP Botnet Detection Model: A Systematic Evaluation of Quantization-Aware Training and Post-Training Quantization Strategies, https://arxiv.org/pdf/2511.03201, 2025-11-05
2025-11-09 22:23:47,709 - INFO - root - Page:0, Index:1, FP8-Flow-MoE: A Casting-Free FP8 Recipe without Double Quantization Error, https://arxiv.org/pdf/2511.02302, 2025-11-04
2025-11-09 22:23:47,709 - INFO - root - Page:0, Index:2, Outlier-Aware Post-Training Quantization for Image Super-Resolution, https://arxiv.org/pdf/2511.00682, 2025-11-01
2025-11-09 22:23:47,709 - INFO - root - Page:0, Index:3, Evaluation of Wafer-Scale SOT-MRAM for Analog Crossbar Array Applications, https://arxiv.org/pdf/2510.25853, 2025-11-03
2025-11-09 22:23:47,710 - INFO - root - Page:0, Index:4, Improving the Straight-Through Estimator with Zeroth-Order Information, https://arxiv.org/pdf/2510.23926, 2025-10-27
2025-11-09 22:23:47,710 - INFO - root - Page:0, Index:5, Real-Time Semantic Segmentation on FPGA for Autonomous Vehicles Using LMIINet with the CGRA4ML Framework, https://arxiv.org/pdf/2510.22243, 2025-10-25
2025-11-09 22:23:47,710 - INFO - root - Page:0, Index:6, TernaryCLIP: Efficiently Compressing Vision-Language Models with Ternary Weights and Distilled Knowledge, https://arxiv.org/pdf/2510.21879, 2025-10-23
2025-11-09 22:23:47,710 - INFO - root - Page:0, Index:7, KARIPAP: Quantum-Inspired Tensor Network Compression of Large Language Models Using Infinite Projected Entangled Pair States and Tensor Renormalization Group, https://arxiv.org/pdf/2510.21844, 2025-10-22
2025-11-09 22:23:47,710 - INFO - root - Page:0, Index:8, A Convergence Analysis of Adaptive Optimizers under Floating-point Quantization, https://arxiv.org/pdf/2510.21314, 2025-10-24
2025-11-09 22:23:47,711 - INFO - root - Page:0, Index:9, Adaptive Distribution-aware Quantization for Mixed-Precision Neural Networks, https://arxiv.org/pdf/2510.19760, 2025-10-22
2025-11-09 22:23:47,711 - INFO - root - Page:0, Index:10, CAGE: Curvature-Aware Gradient Estimation For Accurate Quantization-Aware Training, https://arxiv.org/pdf/2510.18784, 2025-10-21
2025-11-09 22:23:47,711 - INFO - root - Page:0, Index:11, Mixed-Precision Quantization for Language Models: Techniques and Prospects, https://arxiv.org/pdf/2510.16805, 2025-10-19
2025-11-09 22:23:47,711 - INFO - root - Page:0, Index:12, SPLite Hand: Sparsity-Aware Lightweight 3D Hand Pose Estimation, https://arxiv.org/pdf/2510.16396, 2025-10-30
2025-11-09 22:23:47,712 - INFO - root - Page:0, Index:13, CTR-LoRA: Curvature-Aware and Trust-Region Guided Low-Rank Adaptation for Large Language Models, https://arxiv.org/pdf/2510.15962, 2025-10-11
2025-11-09 22:23:47,712 - INFO - root - Page:0, Index:14, SANR: Scene-Aware Neural Representation for Light Field Image Compression with Rate-Distortion Optimization, https://arxiv.org/pdf/2510.15775, 2025-10-17
2025-11-09 22:23:47,712 - INFO - root - Page:0, Index:15, SpikeFit: Towards Optimal Deployment of Spiking Networks on Neuromorphic Hardware, https://arxiv.org/pdf/2510.15542, 2025-10-31
2025-11-09 22:23:47,712 - INFO - root - Page:0, Index:16, GRank: Towards Target-Aware and Streamlined Industrial Retrieval with a Generate-Rank Framework, https://arxiv.org/pdf/2510.15299, 2025-10-17
2025-11-09 22:23:47,713 - INFO - root - Page:0, Index:17, SaLon3R: Structure-aware Long-term Generalizable 3D Reconstruction from Unposed Images, https://arxiv.org/pdf/2510.15072, 2025-10-16
2025-11-09 22:23:47,713 - INFO - root - Page:0, Index:18, FraQAT: Quantization Aware Training with Fractional bits, https://arxiv.org/pdf/2510.14823, 2025-10-16
2025-11-09 22:23:47,713 - INFO - root - Page:0, Index:19, Computing-In-Memory Aware Model Adaption For Edge Devices, https://arxiv.org/pdf/2510.14379, 2025-10-16
2025-11-09 22:23:47,714 - INFO - root - Page:0, Index:20, Invited Paper: BitMedViT: Ternary-Quantized Vision Transformer for Medical AI Assistants on the Edge, https://arxiv.org/pdf/2510.13760, 2025-11-04
2025-11-09 22:23:47,714 - INFO - root - Page:0, Index:21, NeuroRVQ: Multi-Scale EEG Tokenization for Generative Large Brainwave Models, https://arxiv.org/pdf/2510.13068, 2025-10-14
2025-11-09 22:23:47,714 - INFO - root - Page:0, Index:22, Detect Anything via Next Point Prediction, https://arxiv.org/pdf/2510.12798, 2025-10-14
2025-11-09 22:23:47,716 - INFO - root - Page:0, Index:23, AndesVL Technical Report: An Efficient Mobile-side Multimodal Large Language Model, https://arxiv.org/pdf/2510.11496, 2025-10-14
2025-11-09 22:23:47,716 - INFO - root - Page:0, Index:24, Rescaling-Aware Training for Efficient Deployment of Deep Learning Models on Full-Integer Hardware, https://arxiv.org/pdf/2510.11484, 2025-10-13
2025-11-09 22:23:47,716 - INFO - root - Page:0, Index:25, SASER: Stego attacks on open-source LLMs, https://arxiv.org/pdf/2510.10486, 2025-10-12
2025-11-09 22:23:47,716 - INFO - root - Page:0, Index:26, Ultralytics YOLO Evolution: An Overview of YOLO26, YOLO11, YOLOv8 and YOLOv5 Object Detectors for Computer Vision and Pattern Recognition, https://arxiv.org/pdf/2510.09653, 2025-10-15
2025-11-09 22:23:47,717 - INFO - root - Page:0, Index:27, A Theoretically-Grounded Codebook for Digital Semantic Communications, https://arxiv.org/pdf/2510.07108, 2025-10-14
2025-11-09 22:23:47,718 - INFO - root - Page:0, Index:28, QuantDemoire: Quantization with Outlier Aware for Image Demoiréing, https://arxiv.org/pdf/2510.04066, 2025-10-05
2025-11-09 22:23:47,718 - INFO - root - Page:0, Index:29, Adaptively Sampling-Reusing-Mixing Decomposed Gradients to Speed Up Sharpness Aware Minimization, https://arxiv.org/pdf/2510.03763, 2025-10-04
2025-11-09 22:23:47,719 - INFO - root - Page:0, Index:30, Quant-dLLM: Post-Training Extreme Low-Bit Quantization for Diffusion Large Language Models, https://arxiv.org/pdf/2510.03274, 2025-09-27
2025-11-09 22:23:47,719 - INFO - root - Page:0, Index:31, PT$^2$-LLM: Post-Training Ternarization for Large Language Models, https://arxiv.org/pdf/2510.03267, 2025-09-26
2025-11-09 22:23:47,720 - INFO - root - Page:0, Index:32, Purrception: Variational Flow Matching for Vector-Quantized Image Generation, https://arxiv.org/pdf/2510.01478, 2025-10-01
2025-11-09 22:23:47,720 - INFO - root - Page:0, Index:33, Post-Training Quantization for Audio Diffusion Transformers, https://arxiv.org/pdf/2510.00313, 2025-09-30
2025-11-09 22:23:47,720 - INFO - root - Page:0, Index:34, Rethinking RoPE Scaling in Quantized LLM: Theory, Outlier, and Channel-Band Analysis with Weight Rescaling, https://arxiv.org/pdf/2510.00028, 2025-09-25
2025-11-09 22:23:47,720 - INFO - root - Page:0, Index:35, Post-Training Quantization via Residual Truncation and Zero Suppression for Diffusion Models, https://arxiv.org/pdf/2509.26436, 2025-09-30
2025-11-09 22:23:47,721 - INFO - root - Page:0, Index:36, Cat: Post-Training Quantization Error Reduction via Cluster-based Affine Transformation, https://arxiv.org/pdf/2509.26277, 2025-10-07
2025-11-09 22:23:47,721 - INFO - root - Page:0, Index:37, CAST: Continuous and Differentiable Semi-Structured Sparsity-Aware Training for Large Language Models, https://arxiv.org/pdf/2509.25996, 2025-09-30
2025-11-09 22:23:47,722 - INFO - root - Page:0, Index:38, Norm-Q: Effective Compression Method for Hidden Markov Models in Neuro-Symbolic Applications, https://arxiv.org/pdf/2509.25439, 2025-09-29
2025-11-09 22:23:47,725 - INFO - root - Page:0, Index:39, On-the-Fly Adaptation to Quantization: Configuration-Aware LoRA for Efficient Fine-Tuning of Quantized LLMs, https://arxiv.org/pdf/2509.25214, 2025-09-22
2025-11-09 22:23:47,725 - INFO - root - Page:0, Index:40, VoxCPM: Tokenizer-Free TTS for Context-Aware Speech Generation and True-to-Life Voice Cloning, https://arxiv.org/pdf/2509.24650, 2025-09-29
2025-11-09 22:23:47,726 - INFO - root - Page:0, Index:41, S$^2$NN: Sub-bit Spiking Neural Networks, https://arxiv.org/pdf/2509.24266, 2025-10-24
2025-11-09 22:23:47,726 - INFO - root - Page:0, Index:42, Tequila: Trapping-free Ternary Quantization for Large Language Models, https://arxiv.org/pdf/2509.23809, 2025-10-17
2025-11-09 22:23:47,726 - INFO - root - Page:0, Index:43, Texture Vector-Quantization and Reconstruction Aware Prediction for Generative Super-Resolution, https://arxiv.org/pdf/2509.23774, 2025-09-30
2025-11-09 22:23:47,728 - INFO - root - Page:0, Index:44, RobuQ: Pushing DiTs to W1.58A2 via Robust Activation Quantization, https://arxiv.org/pdf/2509.23582, 2025-09-27
2025-11-09 22:23:47,728 - INFO - root - Page:0, Index:45, Beyond Outliers: A Study of Optimizers Under Quantization, https://arxiv.org/pdf/2509.23500, 2025-10-02
2025-11-09 22:23:47,728 - INFO - root - Page:0, Index:46, Compute-Optimal Quantization-Aware Training, https://arxiv.org/pdf/2509.22935, 2025-09-26
2025-11-09 22:23:47,728 - INFO - root - Page:0, Index:47, COSPADI: Compressing LLMs via Calibration-Guided Sparse Dictionary Learning, https://arxiv.org/pdf/2509.22075, 2025-10-06
2025-11-09 22:23:47,729 - INFO - root - Page:0, Index:48, SlimDiff: Training-Free, Activation-Guided Hands-free Slimming of Diffusion Models, https://arxiv.org/pdf/2509.21498, 2025-09-25
2025-11-09 22:23:47,729 - INFO - root - Page:0, Index:49, Quantized Visual Geometry Grounded Transformer, https://arxiv.org/pdf/2509.21302, 2025-09-29
2025-11-09 22:23:47,729 - INFO - root - Fetching page 2 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=50
2025-11-09 22:23:55,497 - INFO - root - get_all_titles_from_web 
2025-11-09 22:23:55,497 - INFO - root - Page:1, Index:0, Can Less Precise Be More Reliable? A Systematic Evaluation of Quantization's Impact on CLIP Beyond Accuracy, https://arxiv.org/pdf/2509.21173, 2025-10-27
2025-11-09 22:23:55,499 - INFO - root - Page:1, Index:1, Punching Above Precision: Small Quantized Model Distillation with Learnable Regularizer, https://arxiv.org/pdf/2509.20854, 2025-09-25
2025-11-09 22:23:55,499 - INFO - root - Page:1, Index:2, TinyEcoWeedNet: Edge Efficient Real-Time Aerial Agricultural Weed Detection, https://arxiv.org/pdf/2509.18193, 2025-09-19
2025-11-09 22:23:55,499 - INFO - root - Page:1, Index:3, SBVR: Summation of BitVector Representation for Efficient LLM Quantization, https://arxiv.org/pdf/2509.18172, 2025-09-17
2025-11-09 22:23:55,500 - INFO - root - Page:1, Index:4, QWHA: Quantization-Aware Walsh-Hadamard Adaptation for Parameter-Efficient Fine-Tuning on Large Language Models, https://arxiv.org/pdf/2509.17428, 2025-09-26
2025-11-09 22:23:55,500 - INFO - root - Page:1, Index:5, PTQTP: Post-Training Quantization to Trit-Planes for Large Language Models, https://arxiv.org/pdf/2509.16989, 2025-10-28
2025-11-09 22:23:55,500 - INFO - root - Page:1, Index:6, MEC-Quant: Maximum Entropy Coding for Extremely Low Bit Quantization-Aware Training, https://arxiv.org/pdf/2509.15514, 2025-09-18
2025-11-09 22:23:55,500 - INFO - root - Page:1, Index:7, Q-ROAR: Outlier-Aware Rescaling for RoPE Position Interpolation in Quantized Long-Context LLMs, https://arxiv.org/pdf/2509.14391, 2025-09-17
2025-11-09 22:23:55,501 - INFO - root - Page:1, Index:8, Efficient Quantization-Aware Neural Receivers: Beyond Post-Training Quantization, https://arxiv.org/pdf/2509.13786, 2025-09-19
2025-11-09 22:23:55,501 - INFO - root - Page:1, Index:9, Rate-Distortion Limits for Multimodal Retrieval: Theory, Optimal Codes, and Finite-Sample Guarantees, https://arxiv.org/pdf/2509.11054, 2025-09-13
2025-11-09 22:23:55,501 - INFO - root - Page:1, Index:10, SQAP-VLA: A Synergistic Quantization-Aware Pruning Framework for High-Performance Vision-Language-Action Models, https://arxiv.org/pdf/2509.09090, 2025-09-10
2025-11-09 22:23:55,501 - INFO - root - Page:1, Index:11, CSI Compression Beyond Latents: End-to-End Hybrid Attention-CNN Networks with Entropy Regularization, https://arxiv.org/pdf/2509.08776, 2025-09-10
2025-11-09 22:23:55,502 - INFO - root - Page:1, Index:12, Explaining How Quantization Disparately Skews a Model, https://arxiv.org/pdf/2509.07222, 2025-09-08
2025-11-09 22:23:55,502 - INFO - root - Page:1, Index:13, LoaQ: Layer-wise Output Approximation Quantization, https://arxiv.org/pdf/2509.06297, 2025-09-07
2025-11-09 22:23:55,502 - INFO - root - Page:1, Index:14, FineServe: Precision-Aware KV Slab and Two-Level Scheduling for Heterogeneous Precision LLM Serving, https://arxiv.org/pdf/2509.06261, 2025-09-14
2025-11-09 22:23:55,503 - INFO - root - Page:1, Index:15, Sensitivity-Aware Post-Training Quantization for Deep Neural Networks, https://arxiv.org/pdf/2509.05576, 2025-09-05
2025-11-09 22:23:55,503 - INFO - root - Page:1, Index:16, SuperSNN: A Hardware-Aware Framework for Physically Realizable, High-Performance Superconducting Spiking Neural Network Chips, https://arxiv.org/pdf/2509.05532, 2025-09-05
2025-11-09 22:23:55,504 - INFO - root - Page:1, Index:17, Data-Augmented Quantization-Aware Knowledge Distillation, https://arxiv.org/pdf/2509.03850, 2025-09-03
2025-11-09 22:23:55,504 - INFO - root - Page:1, Index:18, DPQuant: Efficient and Differentially-Private Model Training via Dynamic Quantization Scheduling, https://arxiv.org/pdf/2509.03472, 2025-09-03
2025-11-09 22:23:55,505 - INFO - root - Page:1, Index:19, Empowering Large Language Model for Sequential Recommendation via Multimodal Embeddings and Semantic IDs, https://arxiv.org/pdf/2509.02017, 2025-09-02
2025-11-09 22:23:55,505 - INFO - root - Page:1, Index:20, Q-Sched: Pushing the Boundaries of Few-Step Diffusion Models with Quantization-Aware Scheduling, https://arxiv.org/pdf/2509.01624, 2025-09-01
2025-11-09 22:23:55,506 - INFO - root - Page:1, Index:21, Quantization Meets OOD: Generalizable Quantization-aware Training from a Flatness Perspective, https://arxiv.org/pdf/2509.00859, 2025-08-31
2025-11-09 22:23:55,506 - INFO - root - Page:1, Index:22, Progressive Element-wise Gradient Estimation for Neural Network Quantization, https://arxiv.org/pdf/2509.00097, 2025-08-27
2025-11-09 22:23:55,507 - INFO - root - Page:1, Index:23, End-to-End On-Device Quantization-Aware Training for LLMs at Inference Cost, https://arxiv.org/pdf/2509.00031, 2025-09-29
2025-11-09 22:23:55,507 - INFO - root - Page:1, Index:24, Quantization Robustness to Input Degradations for Object Detection, https://arxiv.org/pdf/2508.19600, 2025-08-27
2025-11-09 22:23:55,515 - INFO - root - Page:1, Index:25, Scaling Laws for Task-Stratified Knowledge in Post-Training Quantized Large Language Models, https://arxiv.org/pdf/2508.18609, 2025-08-27
2025-11-09 22:23:55,519 - INFO - root - Page:1, Index:26, AQ-PCDSys: An Adaptive Quantized Planetary Crater Detection System for Autonomous Space Exploration, https://arxiv.org/pdf/2508.18025, 2025-08-25
2025-11-09 22:23:55,521 - INFO - root - Page:1, Index:27, TaDiCodec: Text-aware Diffusion Speech Tokenizer for Speech Language Modeling, https://arxiv.org/pdf/2508.16790, 2025-08-22
2025-11-09 22:23:55,521 - INFO - root - Page:1, Index:28, A Node-Aware Dynamic Quantization Approach for Graph Collaborative Filtering, https://arxiv.org/pdf/2508.16516, 2025-08-22
2025-11-09 22:23:55,522 - INFO - root - Page:1, Index:29, JEDI-linear: Fast and Efficient Graph Neural Networks for Jet Tagging on FPGAs, https://arxiv.org/pdf/2508.15468, 2025-08-21
2025-11-09 22:23:55,522 - INFO - root - Page:1, Index:30, MMQ: Multimodal Mixture-of-Quantization Tokenization for Semantic ID Generation and User Behavioral Adaptation, https://arxiv.org/pdf/2508.15281, 2025-08-21
2025-11-09 22:23:55,522 - INFO - root - Page:1, Index:31, DLLMQuant: Quantizing Diffusion-based Large Language Models, https://arxiv.org/pdf/2508.14090, 2025-08-25
2025-11-09 22:23:55,522 - INFO - root - Page:1, Index:32, Automated Energy-Aware Time-Series Model Deployment on Embedded FPGAs for Resilient Combined Sewer Overflow Management, https://arxiv.org/pdf/2508.13905, 2025-08-19
2025-11-09 22:23:55,524 - INFO - root - Page:1, Index:33, XR-NPE: High-Throughput Mixed-precision SIMD Neural Processing Engine for Extended Reality Perception Workloads, https://arxiv.org/pdf/2508.13049, 2025-08-18
2025-11-09 22:23:55,524 - INFO - root - Page:1, Index:34, Exploring Self-Supervised Audio Models for Generalized Anomalous Sound Detection, https://arxiv.org/pdf/2508.12230, 2025-08-17
2025-11-09 22:23:55,529 - INFO - root - Page:1, Index:35, TriQDef: Disrupting Semantic and Gradient Alignment to Prevent Adversarial Patch Transferability in Quantized Neural Networks, https://arxiv.org/pdf/2508.12132, 2025-08-16
2025-11-09 22:23:55,529 - INFO - root - Page:1, Index:36, Error Propagation Mechanisms and Compensation Strategies for Quantized Diffusion, https://arxiv.org/pdf/2508.12094, 2025-10-13
2025-11-09 22:23:55,529 - INFO - root - Page:1, Index:37, Extending Straight-Through Estimation for Robust Neural Networks on Analog CIM Hardware, https://arxiv.org/pdf/2508.11940, 2025-08-16
2025-11-09 22:23:55,530 - INFO - root - Page:1, Index:38, PTQAT: A Hybrid Parameter-Efficient Quantization Algorithm for 3D Perception Tasks, https://arxiv.org/pdf/2508.10557, 2025-08-15
2025-11-09 22:23:55,530 - INFO - root - Page:1, Index:39, MiCo: End-to-End Mixed Precision Neural Network Co-Exploration Framework for Edge AI, https://arxiv.org/pdf/2508.09500, 2025-08-13
2025-11-09 22:23:55,530 - INFO - root - Page:1, Index:40, SPARC: Soft Probabilistic Adaptive multi-interest Retrieval Model via Codebooks for recommender system, https://arxiv.org/pdf/2508.09090, 2025-08-12
2025-11-09 22:23:55,531 - INFO - root - Page:1, Index:41, Rethinking 1-bit Optimization Leveraging Pre-trained Large Language Models, https://arxiv.org/pdf/2508.06974, 2025-08-09
2025-11-09 22:23:55,532 - INFO - root - Page:1, Index:42, Efficient Deep Neural Receiver with Post-Training Quantization, https://arxiv.org/pdf/2508.06275, 2025-08-08
2025-11-09 22:23:55,533 - INFO - root - Page:1, Index:43, iFairy: the First 2-bit Complex LLM with All Parameters in $\{\pm1, \pm i\}$, https://arxiv.org/pdf/2508.05571, 2025-08-16
2025-11-09 22:23:55,533 - INFO - root - Page:1, Index:44, S$^2$Q-VDiT: Accurate Quantized Video Diffusion Transformer with Salient Data and Sparse Token Distillation, https://arxiv.org/pdf/2508.04016, 2025-10-27
2025-11-09 22:23:55,533 - INFO - root - Page:1, Index:45, LRQ-DiT: Log-Rotation Post-Training Quantization of Diffusion Transformers for Image and Video Generation, https://arxiv.org/pdf/2508.03485, 2025-09-23
2025-11-09 22:23:55,535 - INFO - root - Page:1, Index:46, VLMQ: Efficient Post-Training Quantization for Large Vision-Language Models via Hessian Augmentation, https://arxiv.org/pdf/2508.03351, 2025-08-05
2025-11-09 22:23:55,535 - INFO - root - Page:1, Index:47, TF-MLPNet: Tiny Real-Time Neural Speech Separation, https://arxiv.org/pdf/2508.03047, 2025-08-04
2025-11-09 22:23:55,535 - INFO - root - Page:1, Index:48, SaviorRec: Semantic-Behavior Alignment for Cold-Start Recommendation, https://arxiv.org/pdf/2508.01375, 2025-08-02
2025-11-09 22:23:55,536 - INFO - root - Page:1, Index:49, MixA-Q: Revisiting Activation Sparsity for Vision Transformers from a Mixed-Precision Quantization Perspective, https://arxiv.org/pdf/2507.19131, 2025-07-25
2025-11-09 22:23:55,536 - INFO - root - Fetching page 3 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=100
2025-11-09 22:24:04,061 - INFO - root - get_all_titles_from_web 
2025-11-09 22:24:04,061 - INFO - root - Page:2, Index:0, Enhancing Quantization-Aware Training on Edge Devices via Relative Entropy Coreset Selection and Cascaded Layer Correction, https://arxiv.org/pdf/2507.17768, 2025-07-16
2025-11-09 22:24:04,062 - INFO - root - Page:2, Index:1, SiLQ: Simple Large Language Model Quantization-Aware Training, https://arxiv.org/pdf/2507.16933, 2025-07-22
2025-11-09 22:24:04,062 - INFO - root - Page:2, Index:2, Task-Specific Zero-shot Quantization-Aware Training for Object Detection, https://arxiv.org/pdf/2507.16782, 2025-07-22
2025-11-09 22:24:04,062 - INFO - root - Page:2, Index:3, TorchAO: PyTorch-Native Training-to-Serving Model Optimization, https://arxiv.org/pdf/2507.16099, 2025-07-21
2025-11-09 22:24:04,063 - INFO - root - Page:2, Index:4, SegQuant: A Semantics-Aware and Generalizable Quantization Framework for Diffusion Models, https://arxiv.org/pdf/2507.14811, 2025-08-27
2025-11-09 22:24:04,063 - INFO - root - Page:2, Index:5, Apple Intelligence Foundation Language Models: Tech Report 2025, https://arxiv.org/pdf/2507.13575, 2025-08-27
2025-11-09 22:24:04,063 - INFO - root - Page:2, Index:6, Generative Multi-Target Cross-Domain Recommendation, https://arxiv.org/pdf/2507.12871, 2025-08-07
2025-11-09 22:24:04,063 - INFO - root - Page:2, Index:7, DAF: An Efficient End-to-End Dynamic Activation Framework for on-Device DNN Training, https://arxiv.org/pdf/2507.07149, 2025-07-09
2025-11-09 22:24:04,064 - INFO - root - Page:2, Index:8, Opto-ViT: Architecting a Near-Sensor Region of Interest-Aware Vision Transformer Accelerator with Silicon Photonics, https://arxiv.org/pdf/2507.07044, 2025-07-15
2025-11-09 22:24:04,064 - INFO - root - Page:2, Index:9, QS4D: Quantization-aware training for efficient hardware deployment of structured state-space sequential models, https://arxiv.org/pdf/2507.06079, 2025-07-08
2025-11-09 22:24:04,064 - INFO - root - Page:2, Index:10, GSVR: 2D Gaussian-based Video Representation for 800+ FPS with Hybrid Deformation Field, https://arxiv.org/pdf/2507.05594, 2025-07-07
2025-11-09 22:24:04,064 - INFO - root - Page:2, Index:11, Hita: Holistic Tokenizer for Autoregressive Image Generation, https://arxiv.org/pdf/2507.02358, 2025-07-11
2025-11-09 22:24:04,065 - INFO - root - Page:2, Index:12, QPART: Adaptive Model Quantization and Dynamic Workload Balancing for Accuracy-aware Edge Inference, https://arxiv.org/pdf/2506.23934, 2025-06-30
2025-11-09 22:24:04,065 - INFO - root - Page:2, Index:13, FedWSQ: Efficient Federated Learning with Weight Standardization and Distribution-Aware Non-Uniform Quantization, https://arxiv.org/pdf/2506.23516, 2025-07-21
2025-11-09 22:24:04,065 - INFO - root - Page:2, Index:14, Spectra 1.1: Scaling Laws and Efficient Inference for Ternary Language Models, https://arxiv.org/pdf/2506.23025, 2025-06-28
2025-11-09 22:24:04,066 - INFO - root - Page:2, Index:15, Joint Quantization and Pruning Neural Networks Approach: A Case Study on FSO Receivers, https://arxiv.org/pdf/2506.20084, 2025-06-24
2025-11-09 22:24:04,066 - INFO - root - Page:2, Index:16, Single-step Diffusion for Image Compression at Ultra-Low Bitrates, https://arxiv.org/pdf/2506.16572, 2025-09-22
2025-11-09 22:24:04,066 - INFO - root - Page:2, Index:17, LittleBit: Ultra Low-Bit Quantization via Latent Factorization, https://arxiv.org/pdf/2506.13771, 2025-10-28
2025-11-09 22:24:04,067 - INFO - root - Page:2, Index:18, MARCO: Hardware-Aware Neural Architecture Search for Edge Devices with Multi-Agent Reinforcement Learning and Conformal Prediction Filtering, https://arxiv.org/pdf/2506.13755, 2025-06-16
2025-11-09 22:24:04,068 - INFO - root - Page:2, Index:19, EAQuant: Enhancing Post-Training Quantization for MoE Models via Expert-Aware Optimization, https://arxiv.org/pdf/2506.13329, 2025-07-04
2025-11-09 22:24:04,068 - INFO - root - Page:2, Index:20, Towards Neural Audio Codec Source Parsing, https://arxiv.org/pdf/2506.12627, 2025-06-14
2025-11-09 22:24:04,069 - INFO - root - Page:2, Index:21, Quantizing Small-Scale State-Space Models for Edge AI, https://arxiv.org/pdf/2506.12480, 2025-06-14
2025-11-09 22:24:04,069 - INFO - root - Page:2, Index:22, EMLoC: Emulator-based Memory-efficient Fine-tuning with LoRA Correction, https://arxiv.org/pdf/2506.12015, 2025-06-13
2025-11-09 22:24:04,069 - INFO - root - Page:2, Index:23, Compression Aware Certified Training, https://arxiv.org/pdf/2506.11992, 2025-06-13
2025-11-09 22:24:04,070 - INFO - root - Page:2, Index:24, GPLQ: A General, Practical, and Lightning QAT Method for Vision Transformers, https://arxiv.org/pdf/2506.11784, 2025-06-13
2025-11-09 22:24:04,070 - INFO - root - Page:2, Index:25, TruncQuant: Truncation-Ready Quantization for DNNs with Flexible Weight Bit Precision, https://arxiv.org/pdf/2506.11431, 2025-06-12
2025-11-09 22:24:04,072 - INFO - root - Page:2, Index:26, EfficientQuant: An Efficient Post-Training Quantization for CNN-Transformer Hybrid Models on Edge Devices, https://arxiv.org/pdf/2506.11093, 2025-06-05
2025-11-09 22:24:04,073 - INFO - root - Page:2, Index:27, Starting Positions Matter: A Study on Better Weight Initialization for Neural Network Quantization, https://arxiv.org/pdf/2506.10463, 2025-06-12
2025-11-09 22:24:04,075 - INFO - root - Page:2, Index:28, AWP: Activation-Aware Weight Pruning and Quantization with Projected Gradient Descent, https://arxiv.org/pdf/2506.10205, 2025-06-11
2025-11-09 22:24:04,075 - INFO - root - Page:2, Index:29, Q-SAM2: Accurate Quantization for Segment Anything Model 2, https://arxiv.org/pdf/2506.09782, 2025-06-11
2025-11-09 22:24:04,076 - INFO - root - Page:2, Index:30, Unifying Block-wise PTQ and Distillation-based QAT for Progressive Quantization toward 2-bit Instruction-Tuned LLMs, https://arxiv.org/pdf/2506.09104, 2025-06-10
2025-11-09 22:24:04,076 - INFO - root - Page:2, Index:31, Implementing Keyword Spotting on the MCUX947 Microcontroller with Integrated NPU, https://arxiv.org/pdf/2506.08911, 2025-06-10
2025-11-09 22:24:04,077 - INFO - root - Page:2, Index:32, POLARON: Precision-aware On-device Learning and Adaptive Runtime-cONfigurable AI acceleration, https://arxiv.org/pdf/2506.08785, 2025-06-10
2025-11-09 22:24:04,077 - INFO - root - Page:2, Index:33, MoQAE: Mixed-Precision Quantization for Long-Context LLM Inference via Mixture of Quantization-Aware Experts, https://arxiv.org/pdf/2506.07533, 2025-06-09
2025-11-09 22:24:04,079 - INFO - root - Page:2, Index:34, BitVLA: 1-bit Vision-Language-Action Models for Robotics Manipulation, https://arxiv.org/pdf/2506.07530, 2025-06-09
2025-11-09 22:24:04,079 - INFO - root - Page:2, Index:35, RecGPT: A Foundation Model for Sequential Recommendation, https://arxiv.org/pdf/2506.06270, 2025-06-12
2025-11-09 22:24:04,079 - INFO - root - Page:2, Index:36, FPSAttention: Training-Aware FP8 and Sparsity Co-Design for Fast Video Diffusion, https://arxiv.org/pdf/2506.04648, 2025-06-05
2025-11-09 22:24:04,079 - INFO - root - Page:2, Index:37, BitTTS: Highly Compact Text-to-Speech Using 1.58-bit Quantization and Weight Indexing, https://arxiv.org/pdf/2506.03515, 2025-06-03
2025-11-09 22:24:04,080 - INFO - root - Page:2, Index:38, ShapeLLM-Omni: A Native Multimodal LLM for 3D Generation and Understanding, https://arxiv.org/pdf/2506.01853, 2025-06-02
2025-11-09 22:24:04,080 - INFO - root - Page:2, Index:39, Movable Antenna Enhanced Federated Fine-Tuning of Large Language Models via Hybrid Client Selection Optimization, https://arxiv.org/pdf/2506.00011, 2025-10-26
2025-11-09 22:24:04,080 - INFO - root - Page:2, Index:40, Running Conventional Automatic Speech Recognition on Memristor Hardware: A Simulated Approach, https://arxiv.org/pdf/2505.24721, 2025-05-30
2025-11-09 22:24:04,081 - INFO - root - Page:2, Index:41, GARLIC: GAussian Representation LearnIng for spaCe partitioning, https://arxiv.org/pdf/2505.24608, 2025-10-02
2025-11-09 22:24:04,081 - INFO - root - Page:2, Index:42, AutoChemSchematic AI: Agentic Physics-Aware Automation for Chemical Manufacturing Scale-Up, https://arxiv.org/pdf/2505.24584, 2025-08-18
2025-11-09 22:24:04,081 - INFO - root - Page:2, Index:43, Model-Preserving Adaptive Rounding, https://arxiv.org/pdf/2505.22988, 2025-09-25
2025-11-09 22:24:04,081 - INFO - root - Page:2, Index:44, Highly Efficient and Effective LLMs with Multi-Boolean Architectures, https://arxiv.org/pdf/2505.22811, 2025-10-03
2025-11-09 22:24:04,082 - INFO - root - Page:2, Index:45, Pioneering 4-Bit FP Quantization for Diffusion Models: Mixup-Sign Quantization and Timestep-Aware Fine-Tuning, https://arxiv.org/pdf/2505.21591, 2025-05-27
2025-11-09 22:24:04,082 - INFO - root - Page:2, Index:46, Frequency Composition for Compressed and Domain-Adaptive Neural Networks, https://arxiv.org/pdf/2505.20890, 2025-05-27
2025-11-09 22:24:04,082 - INFO - root - Page:2, Index:47, MoPFormer: Motion-Primitive Transformer for Wearable-Sensor Activity Recognition, https://arxiv.org/pdf/2505.20744, 2025-10-27
2025-11-09 22:24:04,083 - INFO - root - Page:2, Index:48, Optimizing edge AI models on HPC systems with the edge in the loop, https://arxiv.org/pdf/2505.19995, 2025-05-26
2025-11-09 22:24:04,085 - INFO - root - Fetching page 4 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=150
2025-11-09 22:24:11,565 - INFO - root - get_all_titles_from_web 
2025-11-09 22:24:11,565 - INFO - root - Page:3, Index:0, DPASyn: Mechanism-Aware Drug Synergy Prediction via Dual Attention and Precision-Aware Quantization, https://arxiv.org/pdf/2505.19144, 2025-09-20
2025-11-09 22:24:11,565 - INFO - root - Page:3, Index:1, Reducing Storage of Pretrained Neural Networks by Rate-Constrained Quantization and Entropy Coding, https://arxiv.org/pdf/2505.18758, 2025-05-24
2025-11-09 22:24:11,566 - INFO - root - Page:3, Index:2, Beyond Discreteness: Finite-Sample Analysis of Straight-Through Estimator for Quantization, https://arxiv.org/pdf/2505.18113, 2025-05-23
2025-11-09 22:24:11,566 - INFO - root - Page:3, Index:3, Automating Versatile Time-Series Analysis with Tiny Transformers on Embedded FPGAs, https://arxiv.org/pdf/2505.17662, 2025-09-19
2025-11-09 22:24:11,566 - INFO - root - Page:3, Index:4, FPQVAR: Floating Point Quantization for Visual Autoregressive Model with FPGA Hardware Co-design, https://arxiv.org/pdf/2505.16335, 2025-05-22
2025-11-09 22:24:11,567 - INFO - root - Page:3, Index:5, Saliency-Aware Quantized Imitation Learning for Efficient Robotic Control, https://arxiv.org/pdf/2505.15304, 2025-05-30
2025-11-09 22:24:11,567 - INFO - root - Page:3, Index:6, Scaling Law for Quantization-Aware Training, https://arxiv.org/pdf/2505.14302, 2025-05-20
2025-11-09 22:24:11,567 - INFO - root - Page:3, Index:7, Automatic mixed precision for optimizing gained time with constrained loss mean-squared-error based on model partition to sequential sub-graphs, https://arxiv.org/pdf/2505.13060, 2025-05-19
2025-11-09 22:24:11,568 - INFO - root - Page:3, Index:8, Deep Unfolding with Kernel-based Quantization in MIMO Detection, https://arxiv.org/pdf/2505.12736, 2025-05-19
2025-11-09 22:24:11,568 - INFO - root - Page:3, Index:9, FedHQ: Hybrid Runtime Quantization for Federated Learning, https://arxiv.org/pdf/2505.11982, 2025-05-17
2025-11-09 22:24:11,568 - INFO - root - Page:3, Index:10, QVGen: Pushing the Limit of Quantized Video Generative Models, https://arxiv.org/pdf/2505.11497, 2025-09-27
2025-11-09 22:24:11,568 - INFO - root - Page:3, Index:11, EA-3DGS: Efficient and Adaptive 3D Gaussians with Highly Enhanced Quality for outdoor scenes, https://arxiv.org/pdf/2505.10787, 2025-05-15
2025-11-09 22:24:11,569 - INFO - root - Page:3, Index:12, ITERA-LLM: Boosting Sub-8-Bit Large Language Model Inference via Iterative Tensor Decomposition, https://arxiv.org/pdf/2505.08981, 2025-05-13
2025-11-09 22:24:11,569 - INFO - root - Page:3, Index:13, PROM: Prioritize Reduction of Multiplications Over Lower Bit-Widths for Efficient CNNs, https://arxiv.org/pdf/2505.03254, 2025-08-06
2025-11-09 22:24:11,569 - INFO - root - Page:3, Index:14, ICQuant: Index Coding enables Low-bit LLM Quantization, https://arxiv.org/pdf/2505.00850, 2025-08-24
2025-11-09 22:24:11,570 - INFO - root - Page:3, Index:15, Enhancing Ultra-Low-Bit Quantization of Large Language Models Through Saliency-Aware Partial Retraining, https://arxiv.org/pdf/2504.13932, 2025-07-30
2025-11-09 22:24:11,570 - INFO - root - Page:3, Index:16, Achieving binary weight and activation for LLMs using Post-Training Quantization, https://arxiv.org/pdf/2504.05352, 2025-06-30
2025-11-09 22:24:11,572 - INFO - root - Page:3, Index:17, Wireless Hearables With Programmable Speech AI Accelerators, https://arxiv.org/pdf/2503.18698, 2025-10-21
2025-11-09 22:24:11,575 - INFO - root - Page:3, Index:18, GranQ: Efficient Channel-wise Quantization via Vectorized Pre-Scaling for Zero-Shot QAT, https://arxiv.org/pdf/2503.18339, 2025-10-15
2025-11-09 22:24:11,576 - INFO - root - Page:3, Index:19, CompMarkGS: Robust Watermarking for Compressed 3D Gaussian Splatting, https://arxiv.org/pdf/2503.12836, 2025-09-29
2025-11-09 22:24:11,577 - INFO - root - Page:3, Index:20, AHCPTQ: Accurate and Hardware-Compatible Post-Training Quantization for Segment Anything Model, https://arxiv.org/pdf/2503.03088, 2025-07-11
2025-11-09 22:24:11,578 - INFO - root - Page:3, Index:21, Teaching Metric Distance to Discrete Autoregressive Language Models, https://arxiv.org/pdf/2503.02379, 2025-10-07
2025-11-09 22:24:11,580 - INFO - root - Page:3, Index:22, Regularization-based Framework for Quantization-, Fault- and Variability-Aware Training, https://arxiv.org/pdf/2503.01297, 2025-07-12
2025-11-09 22:24:11,580 - INFO - root - Fetching page 5 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=200
2025-11-09 22:24:16,560 - INFO - root - get_all_titles_from_web 
2025-11-09 22:24:16,560 - INFO - root - Page:4, Index:0, Investigating the Impact of Quantization Methods on the Safety and Reliability of Large Language Models, https://arxiv.org/pdf/2502.15799, 2025-06-29
2025-11-09 22:24:16,561 - INFO - root - Page:4, Index:1, Rotate, Clip, and Partition: Towards W2A4KV4 Quantization by Integrating Rotation and Learnable Non-uniform Quantizer, https://arxiv.org/pdf/2502.15779, 2025-09-01
2025-11-09 22:24:16,561 - INFO - root - Page:4, Index:2, RoSTE: An Efficient Quantization-Aware Supervised Fine-Tuning Approach for Large Language Models, https://arxiv.org/pdf/2502.09003, 2025-06-05
2025-11-09 22:24:16,561 - INFO - root - Page:4, Index:3, Spatial Degradation-Aware and Temporal Consistent Diffusion Model for Compressed Video Super-Resolution, https://arxiv.org/pdf/2502.07381, 2025-06-27
2025-11-09 22:24:16,562 - INFO - root - Page:4, Index:4, QuEST: Stable Training of LLMs with 1-Bit Weights and Activations, https://arxiv.org/pdf/2502.05003, 2025-06-10
2025-11-09 22:24:16,562 - INFO - root - Page:4, Index:5, HALO: Hadamard-Assisted Lower-Precision Optimization for LLMs, https://arxiv.org/pdf/2501.02625, 2025-11-05
2025-11-09 22:24:16,563 - INFO - root - Page:4, Index:6, TAR3D: Creating High-Quality 3D Assets via Next-Part Prediction, https://arxiv.org/pdf/2412.16919, 2025-08-08
2025-11-09 22:24:16,563 - INFO - root - Page:4, Index:7, Training Multi-Layer Binary Neural Networks With Local Binary Error Signals, https://arxiv.org/pdf/2412.00119, 2025-08-05
2025-11-09 22:24:16,563 - INFO - root - Page:4, Index:8, Scaling Large-scale GNN Training to Thousands of Processors on CPU-based Supercomputers, https://arxiv.org/pdf/2411.16025, 2025-05-26
2025-11-09 22:24:16,563 - INFO - root - Page:4, Index:9, HAFLQ: Heterogeneous Adaptive Federated LoRA Fine-tuned LLM with Quantization, https://arxiv.org/pdf/2411.06581, 2025-05-16
2025-11-09 22:24:16,564 - INFO - root - Fetching page 6 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=250
2025-11-09 22:24:25,122 - INFO - root - get_all_titles_from_web 
2025-11-09 22:24:25,123 - INFO - root - Page:5, Index:0, Gradient-Free Training of Quantized Neural Networks, https://arxiv.org/pdf/2410.09734, 2025-09-29
2025-11-09 22:24:25,123 - INFO - root - Page:5, Index:1, QT-DoG: Quantization-aware Training for Domain Generalization, https://arxiv.org/pdf/2410.06020, 2025-06-26
2025-11-09 22:24:25,123 - INFO - root - Page:5, Index:2, Constraint Guided Model Quantization of Neural Networks, https://arxiv.org/pdf/2409.20138, 2025-09-12
2025-11-09 22:24:25,124 - INFO - root - Page:5, Index:3, Accumulator-Aware Post-Training Quantization for Large Language Models, https://arxiv.org/pdf/2409.17092, 2025-07-30
2025-11-09 22:24:25,124 - INFO - root - Page:5, Index:4, DilateQuant: Accurate and Efficient Diffusion Quantization via Weight Dilation, https://arxiv.org/pdf/2409.14307, 2025-07-09
2025-11-09 22:24:25,124 - INFO - root - Page:5, Index:5, Robust Training of Neural Networks at Arbitrary Precision and Sparsity, https://arxiv.org/pdf/2409.09245, 2025-09-23
2025-11-09 22:24:25,126 - INFO - root - Page:5, Index:6, VQ-CTAP: Cross-Modal Fine-Grained Sequence Representation Learning for Speech Processing, https://arxiv.org/pdf/2408.05758, 2025-05-27
2025-11-09 22:24:25,127 - INFO - root - Page:5, Index:7, DopQ-ViT: Towards Distribution-Friendly and Outlier-Aware Post-Training Quantization for Vision Transformers, https://arxiv.org/pdf/2408.03291, 2025-06-19
2025-11-09 22:24:25,128 - INFO - root - Page:5, Index:8, Temporal Feature Matters: A Framework for Diffusion Model Quantization, https://arxiv.org/pdf/2407.19547, 2025-07-11
2025-11-09 22:24:25,129 - INFO - root - Page:5, Index:9, EfficientQAT: Efficient Quantization-Aware Training for Large Language Models, https://arxiv.org/pdf/2407.11062, 2025-05-19
2025-11-09 22:24:25,130 - INFO - root - Page:5, Index:10, Integer-only Quantized Transformers for Embedded FPGA-based Time-series Forecasting in AIoT, https://arxiv.org/pdf/2407.11041, 2025-10-31
2025-11-09 22:24:25,132 - INFO - root - Fetching page 7 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=300
2025-11-09 22:24:31,567 - INFO - root - get_all_titles_from_web 
2025-11-09 22:24:31,567 - INFO - root - Page:6, Index:0, BoA: Attention-aware Post-training Quantization without Backpropagation, https://arxiv.org/pdf/2406.13474, 2025-06-06
2025-11-09 22:24:31,568 - INFO - root - Page:6, Index:1, A Rescaling-Invariant Lipschitz Bound Based on Path-Metrics for Modern ReLU Network Parameterizations, https://arxiv.org/pdf/2405.15006, 2025-06-13
2025-11-09 22:24:31,568 - INFO - root - Page:6, Index:2, Scheduling Weight Transitions for Quantization-Aware Training, https://arxiv.org/pdf/2404.19248, 2025-10-01
2025-11-09 22:24:31,569 - INFO - root - Page:6, Index:3, GPTVQ: The Blessing of Dimensionality for LLM Quantization, https://arxiv.org/pdf/2402.15319, 2025-06-03
2025-11-09 22:24:31,570 - INFO - root - Fetching page 8 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=350
2025-11-09 22:24:38,850 - INFO - root - get_all_titles_from_web 
2025-11-09 22:24:38,851 - INFO - root - Page:7, Index:0, Squat: Quant Small Language Models on the Edge, https://arxiv.org/pdf/2402.10787, 2025-07-01
2025-11-09 22:24:38,852 - INFO - root - Page:7, Index:1, L4Q: Parameter Efficient Quantization-Aware Fine-Tuning on Large Language Models, https://arxiv.org/pdf/2402.04902, 2025-07-21
2025-11-09 22:24:38,853 - INFO - root - Fetching page 9 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=400
2025-11-09 22:24:45,687 - INFO - root - ------------------------------------------------------------------------------------------------------------------------
2025-11-09 22:24:45,688 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\A Quantized VAE-MLP Botnet Detection Model_ A Systematic Evaluation of Quantizat.pdf
2025-11-09 22:24:45,691 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\FP8-Flow-MoE_ A Casting-Free FP8 Recipe without Double Quantization Error.pdf
2025-11-09 22:24:45,695 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\Outlier-Aware Post-Training Quantization for Image Super-Resolution.pdf
2025-11-09 22:24:45,696 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\Evaluation of Wafer-Scale SOT-MRAM for Analog Crossbar Array Applications.pdf
2025-11-09 22:24:45,698 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\Improving the Straight-Through Estimator with Zeroth-Order Information.pdf
2025-11-09 22:24:45,699 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\Real-Time Semantic Segmentation on FPGA for Autonomous Vehicles Using LMIINet wi.pdf
2025-11-09 22:24:45,702 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\TernaryCLIP_ Efficiently Compressing Vision-Language Models with Ternary Weights.pdf
2025-11-09 22:24:45,702 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\KARIPAP_ Quantum-Inspired Tensor Network Compression of Large Language Models Us.pdf
2025-11-09 22:24:45,704 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\A Convergence Analysis of Adaptive Optimizers under Floating-point Quantization.pdf
2025-11-09 22:24:45,705 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\Adaptive Distribution-aware Quantization for Mixed-Precision Neural Networks.pdf
2025-11-09 22:24:45,708 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\CAGE_ Curvature-Aware Gradient Estimation For Accurate Quantization-Aware Traini.pdf
2025-11-09 22:24:45,710 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\Mixed-Precision Quantization for Language Models_ Techniques and Prospects.pdf
2025-11-09 22:24:45,712 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\SPLite Hand_ Sparsity-Aware Lightweight 3D Hand Pose Estimation.pdf
2025-11-09 22:24:45,713 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\CTR-LoRA_ Curvature-Aware and Trust-Region Guided Low-Rank Adaptation for Large.pdf
2025-11-09 22:24:45,716 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\SANR_ Scene-Aware Neural Representation for Light Field Image Compression with R.pdf
2025-11-09 22:24:45,717 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\SpikeFit_ Towards Optimal Deployment of Spiking Networks on Neuromorphic Hardwar.pdf
2025-11-09 22:24:45,719 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\GRank_ Towards Target-Aware and Streamlined Industrial Retrieval with a Generate.pdf
2025-11-09 22:24:45,719 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\SaLon3R_ Structure-aware Long-term Generalizable 3D Reconstruction from Unposed.pdf
2025-11-09 22:24:45,723 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\FraQAT_ Quantization Aware Training with Fractional bits.pdf
2025-11-09 22:24:45,725 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\Computing-In-Memory Aware Model Adaption For Edge Devices.pdf
2025-11-09 22:24:45,732 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\Invited Paper_ BitMedViT_ Ternary-Quantized Vision Transformer for Medical AI As.pdf
2025-11-09 22:24:45,733 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\NeuroRVQ_ Multi-Scale EEG Tokenization for Generative Large Brainwave Models.pdf
2025-11-09 22:24:45,735 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\Detect Anything via Next Point Prediction.pdf
2025-11-09 22:24:45,735 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\AndesVL Technical Report_ An Efficient Mobile-side Multimodal Large Language Mod.pdf
2025-11-09 22:24:45,737 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\Rescaling-Aware Training for Efficient Deployment of Deep Learning Models on Ful.pdf
2025-11-09 22:24:45,738 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\SASER_ Stego attacks on open-source LLMs.pdf
2025-11-09 22:24:45,739 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\Ultralytics YOLO Evolution_ An Overview of YOLO26, YOLO11, YOLOv8 and YOLOv5 Obj.pdf
2025-11-09 22:24:45,740 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\A Theoretically-Grounded Codebook for Digital Semantic Communications.pdf
2025-11-09 22:24:45,744 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\QuantDemoire_ Quantization with Outlier Aware for Image Demoiréing.pdf
2025-11-09 22:24:45,748 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\Adaptively Sampling-Reusing-Mixing Decomposed Gradients to Speed Up Sharpness Aw.pdf
2025-11-09 22:24:45,749 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\Quant-dLLM_ Post-Training Extreme Low-Bit Quantization for Diffusion Large Langu.pdf
2025-11-09 22:24:45,752 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\PT$^2$-LLM_ Post-Training Ternarization for Large Language Models.pdf
2025-11-09 22:24:45,761 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\Purrception_ Variational Flow Matching for Vector-Quantized Image Generation.pdf
2025-11-09 22:24:45,766 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\Post-Training Quantization for Audio Diffusion Transformers.pdf
2025-11-09 22:24:45,767 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\Rethinking RoPE Scaling in Quantized LLM_ Theory, Outlier, and Channel-Band Anal.pdf
2025-11-09 22:24:45,781 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\Post-Training Quantization via Residual Truncation and Zero Suppression for Diff.pdf
2025-11-09 22:24:45,782 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\Cat_ Post-Training Quantization Error Reduction via Cluster-based Affine Transfo.pdf
2025-11-09 22:24:45,785 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\CAST_ Continuous and Differentiable Semi-Structured Sparsity-Aware Training for.pdf
2025-11-09 22:24:45,786 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\Norm-Q_ Effective Compression Method for Hidden Markov Models in Neuro-Symbolic.pdf
2025-11-09 22:24:45,787 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\Quantization-Aware-Training\On-the-Fly Adaptation to Quantization_ Configuration-Aware LoRA for Efficient Fi.pdf
2025-11-09 22:36:00,924 - INFO - root - 跳过已处理论文 A Quantized VAE-MLP Botnet Detection Model: A Systematic Evaluation of Quantization-Aware Training and Post-Training Quantization Strategies：d:\ChatPaper\academic Papers\Quantization-Aware-Training\A Quantized VAE-MLP Botnet Detection Model_ A Systematic Evaluation of Quantizat.pdf
2025-11-09 22:36:00,924 - INFO - root - 跳过已处理论文 FP8-Flow-MoE: A Casting-Free FP8 Recipe without Double Quantization Error：d:\ChatPaper\academic Papers\Quantization-Aware-Training\FP8-Flow-MoE_ A Casting-Free FP8 Recipe without Double Quantization Error.pdf
2025-11-09 22:36:00,924 - INFO - root - 跳过已处理论文 Outlier-Aware Post-Training Quantization for Image Super-Resolution：d:\ChatPaper\academic Papers\Quantization-Aware-Training\Outlier-Aware Post-Training Quantization for Image Super-Resolution.pdf
2025-11-09 22:36:00,925 - INFO - root - 跳过已处理论文 Evaluation of Wafer-Scale SOT-MRAM for Analog Crossbar Array Applications：d:\ChatPaper\academic Papers\Quantization-Aware-Training\Evaluation of Wafer-Scale SOT-MRAM for Analog Crossbar Array Applications.pdf
2025-11-09 22:36:00,926 - INFO - root - 跳过已处理论文 Improving the Straight-Through Estimator with Zeroth-Order Information：d:\ChatPaper\academic Papers\Quantization-Aware-Training\Improving the Straight-Through Estimator with Zeroth-Order Information.pdf
2025-11-09 22:36:00,926 - INFO - root - 跳过已处理论文 Real-Time Semantic Segmentation on FPGA for Autonomous Vehicles Using LMIINet with the CGRA4ML Framework：d:\ChatPaper\academic Papers\Quantization-Aware-Training\Real-Time Semantic Segmentation on FPGA for Autonomous Vehicles Using LMIINet wi.pdf
2025-11-09 22:36:00,927 - INFO - root - 跳过已处理论文 TernaryCLIP: Efficiently Compressing Vision-Language Models with Ternary Weights and Distilled Knowledge：d:\ChatPaper\academic Papers\Quantization-Aware-Training\TernaryCLIP_ Efficiently Compressing Vision-Language Models with Ternary Weights.pdf
2025-11-09 22:36:00,927 - INFO - root - 跳过已处理论文 KARIPAP: Quantum-Inspired Tensor Network Compression of Large Language Models Using Infinite Projected Entangled Pair States and Tensor Renormalization Group：d:\ChatPaper\academic Papers\Quantization-Aware-Training\KARIPAP_ Quantum-Inspired Tensor Network Compression of Large Language Models Us.pdf
2025-11-09 22:36:00,928 - INFO - root - 跳过已处理论文 A Convergence Analysis of Adaptive Optimizers under Floating-point Quantization：d:\ChatPaper\academic Papers\Quantization-Aware-Training\A Convergence Analysis of Adaptive Optimizers under Floating-point Quantization.pdf
2025-11-09 22:36:00,928 - INFO - root - 跳过已处理论文 Adaptive Distribution-aware Quantization for Mixed-Precision Neural Networks：d:\ChatPaper\academic Papers\Quantization-Aware-Training\Adaptive Distribution-aware Quantization for Mixed-Precision Neural Networks.pdf
2025-11-09 22:36:00,928 - INFO - root - 跳过已处理论文 CAGE: Curvature-Aware Gradient Estimation For Accurate Quantization-Aware Training：d:\ChatPaper\academic Papers\Quantization-Aware-Training\CAGE_ Curvature-Aware Gradient Estimation For Accurate Quantization-Aware Traini.pdf
2025-11-09 22:36:00,929 - INFO - root - 跳过已处理论文 Mixed-Precision Quantization for Language Models: Techniques and Prospects：d:\ChatPaper\academic Papers\Quantization-Aware-Training\Mixed-Precision Quantization for Language Models_ Techniques and Prospects.pdf
2025-11-09 22:36:00,929 - INFO - root - 跳过已处理论文 SPLite Hand: Sparsity-Aware Lightweight 3D Hand Pose Estimation：d:\ChatPaper\academic Papers\Quantization-Aware-Training\SPLite Hand_ Sparsity-Aware Lightweight 3D Hand Pose Estimation.pdf
2025-11-09 22:36:00,930 - INFO - root - 跳过已处理论文 CTR-LoRA: Curvature-Aware and Trust-Region Guided Low-Rank Adaptation for Large Language Models：d:\ChatPaper\academic Papers\Quantization-Aware-Training\CTR-LoRA_ Curvature-Aware and Trust-Region Guided Low-Rank Adaptation for Large.pdf
2025-11-09 22:36:00,930 - INFO - root - 跳过已处理论文 SANR: Scene-Aware Neural Representation for Light Field Image Compression with Rate-Distortion Optimization：d:\ChatPaper\academic Papers\Quantization-Aware-Training\SANR_ Scene-Aware Neural Representation for Light Field Image Compression with R.pdf
2025-11-09 22:36:00,931 - INFO - root - 跳过已处理论文 SpikeFit: Towards Optimal Deployment of Spiking Networks on Neuromorphic Hardware：d:\ChatPaper\academic Papers\Quantization-Aware-Training\SpikeFit_ Towards Optimal Deployment of Spiking Networks on Neuromorphic Hardwar.pdf
2025-11-09 22:36:00,932 - INFO - root - 跳过已处理论文 GRank: Towards Target-Aware and Streamlined Industrial Retrieval with a Generate-Rank Framework：d:\ChatPaper\academic Papers\Quantization-Aware-Training\GRank_ Towards Target-Aware and Streamlined Industrial Retrieval with a Generate.pdf
2025-11-09 22:36:00,933 - INFO - root - 跳过已处理论文 SaLon3R: Structure-aware Long-term Generalizable 3D Reconstruction from Unposed Images：d:\ChatPaper\academic Papers\Quantization-Aware-Training\SaLon3R_ Structure-aware Long-term Generalizable 3D Reconstruction from Unposed.pdf
2025-11-09 22:36:00,935 - INFO - root - 跳过已处理论文 FraQAT: Quantization Aware Training with Fractional bits：d:\ChatPaper\academic Papers\Quantization-Aware-Training\FraQAT_ Quantization Aware Training with Fractional bits.pdf
2025-11-09 22:36:00,937 - INFO - root - 跳过已处理论文 Computing-In-Memory Aware Model Adaption For Edge Devices：d:\ChatPaper\academic Papers\Quantization-Aware-Training\Computing-In-Memory Aware Model Adaption For Edge Devices.pdf
2025-11-09 22:36:00,940 - INFO - root - 跳过已处理论文 Invited Paper: BitMedViT: Ternary-Quantized Vision Transformer for Medical AI Assistants on the Edge：d:\ChatPaper\academic Papers\Quantization-Aware-Training\Invited Paper_ BitMedViT_ Ternary-Quantized Vision Transformer for Medical AI As.pdf
2025-11-09 22:36:00,942 - INFO - root - 跳过已处理论文 NeuroRVQ: Multi-Scale EEG Tokenization for Generative Large Brainwave Models：d:\ChatPaper\academic Papers\Quantization-Aware-Training\NeuroRVQ_ Multi-Scale EEG Tokenization for Generative Large Brainwave Models.pdf
2025-11-09 22:36:00,943 - INFO - root - 跳过已处理论文 Detect Anything via Next Point Prediction：d:\ChatPaper\academic Papers\Quantization-Aware-Training\Detect Anything via Next Point Prediction.pdf
2025-11-09 22:36:00,944 - INFO - root - 跳过已处理论文 AndesVL Technical Report: An Efficient Mobile-side Multimodal Large Language Model：d:\ChatPaper\academic Papers\Quantization-Aware-Training\AndesVL Technical Report_ An Efficient Mobile-side Multimodal Large Language Mod.pdf
2025-11-09 22:36:00,945 - INFO - root - 跳过已处理论文 Rescaling-Aware Training for Efficient Deployment of Deep Learning Models on Full-Integer Hardware：d:\ChatPaper\academic Papers\Quantization-Aware-Training\Rescaling-Aware Training for Efficient Deployment of Deep Learning Models on Ful.pdf
2025-11-09 22:36:00,958 - INFO - root - 跳过已处理论文 SASER: Stego attacks on open-source LLMs：d:\ChatPaper\academic Papers\Quantization-Aware-Training\SASER_ Stego attacks on open-source LLMs.pdf
2025-11-09 22:36:00,960 - INFO - root - 跳过已处理论文 Ultralytics YOLO Evolution: An Overview of YOLO26, YOLO11, YOLOv8 and YOLOv5 Object Detectors for Computer Vision and Pattern Recognition：d:\ChatPaper\academic Papers\Quantization-Aware-Training\Ultralytics YOLO Evolution_ An Overview of YOLO26, YOLO11, YOLOv8 and YOLOv5 Obj.pdf
2025-11-09 22:36:00,960 - INFO - root - 跳过已处理论文 A Theoretically-Grounded Codebook for Digital Semantic Communications：d:\ChatPaper\academic Papers\Quantization-Aware-Training\A Theoretically-Grounded Codebook for Digital Semantic Communications.pdf
2025-11-09 22:36:00,961 - INFO - root - 跳过已处理论文 QuantDemoire: Quantization with Outlier Aware for Image Demoiréing：d:\ChatPaper\academic Papers\Quantization-Aware-Training\QuantDemoire_ Quantization with Outlier Aware for Image Demoiréing.pdf
2025-11-09 22:36:00,962 - INFO - root - 跳过已处理论文 Adaptively Sampling-Reusing-Mixing Decomposed Gradients to Speed Up Sharpness Aware Minimization：d:\ChatPaper\academic Papers\Quantization-Aware-Training\Adaptively Sampling-Reusing-Mixing Decomposed Gradients to Speed Up Sharpness Aw.pdf
2025-11-09 22:36:00,962 - INFO - root - 跳过已处理论文 Quant-dLLM: Post-Training Extreme Low-Bit Quantization for Diffusion Large Language Models：d:\ChatPaper\academic Papers\Quantization-Aware-Training\Quant-dLLM_ Post-Training Extreme Low-Bit Quantization for Diffusion Large Langu.pdf
2025-11-09 22:36:00,963 - INFO - root - 跳过已处理论文 PT$^2$-LLM: Post-Training Ternarization for Large Language Models：d:\ChatPaper\academic Papers\Quantization-Aware-Training\PT$^2$-LLM_ Post-Training Ternarization for Large Language Models.pdf
2025-11-09 22:36:00,963 - INFO - root - 跳过已处理论文 Purrception: Variational Flow Matching for Vector-Quantized Image Generation：d:\ChatPaper\academic Papers\Quantization-Aware-Training\Purrception_ Variational Flow Matching for Vector-Quantized Image Generation.pdf
2025-11-09 22:36:00,964 - INFO - root - 跳过已处理论文 Post-Training Quantization for Audio Diffusion Transformers：d:\ChatPaper\academic Papers\Quantization-Aware-Training\Post-Training Quantization for Audio Diffusion Transformers.pdf
2025-11-09 22:36:00,964 - INFO - root - 跳过已处理论文 Rethinking RoPE Scaling in Quantized LLM: Theory, Outlier, and Channel-Band Analysis with Weight Rescaling：d:\ChatPaper\academic Papers\Quantization-Aware-Training\Rethinking RoPE Scaling in Quantized LLM_ Theory, Outlier, and Channel-Band Anal.pdf
2025-11-09 22:36:00,965 - INFO - root - 跳过已处理论文 Post-Training Quantization via Residual Truncation and Zero Suppression for Diffusion Models：d:\ChatPaper\academic Papers\Quantization-Aware-Training\Post-Training Quantization via Residual Truncation and Zero Suppression for Diff.pdf
2025-11-09 22:36:00,966 - INFO - root - 跳过已处理论文 Cat: Post-Training Quantization Error Reduction via Cluster-based Affine Transformation：d:\ChatPaper\academic Papers\Quantization-Aware-Training\Cat_ Post-Training Quantization Error Reduction via Cluster-based Affine Transfo.pdf
2025-11-09 22:36:00,969 - INFO - root - 跳过已处理论文 CAST: Continuous and Differentiable Semi-Structured Sparsity-Aware Training for Large Language Models：d:\ChatPaper\academic Papers\Quantization-Aware-Training\CAST_ Continuous and Differentiable Semi-Structured Sparsity-Aware Training for.pdf
2025-11-09 22:36:00,970 - INFO - root - 跳过已处理论文 Norm-Q: Effective Compression Method for Hidden Markov Models in Neuro-Symbolic Applications：d:\ChatPaper\academic Papers\Quantization-Aware-Training\Norm-Q_ Effective Compression Method for Hidden Markov Models in Neuro-Symbolic.pdf
2025-11-09 22:36:00,971 - INFO - root - 跳过已处理论文 On-the-Fly Adaptation to Quantization: Configuration-Aware LoRA for Efficient Fine-Tuning of Quantized LLMs：d:\ChatPaper\academic Papers\Quantization-Aware-Training\On-the-Fly Adaptation to Quantization_ Configuration-Aware LoRA for Efficient Fi.pdf
2025-11-09 22:36:00,972 - INFO - root - 正在总结论文 41/80: VoxCPM: Tokenizer-Free TTS for Context-Aware Speech Generation and True-to-Life Voice Cloning
2025-11-09 22:36:17,942 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 22:37:12,758 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 22:37:51,764 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 22:37:51,766 - INFO - root - 正在提取论文图片...
2025-11-09 22:37:54,337 - INFO - root - 已保存图片 1/10：./export\images_VoxCPM_ Tokenizer-Free TTS for Context-Aware Speech Generation and True-to-Life\figure_1_page14.png
2025-11-09 22:37:54,596 - INFO - root - 已保存图片 2/10：./export\images_VoxCPM_ Tokenizer-Free TTS for Context-Aware Speech Generation and True-to-Life\figure_2_page13.png
2025-11-09 22:37:54,710 - INFO - root - 已保存图片 3/10：./export\images_VoxCPM_ Tokenizer-Free TTS for Context-Aware Speech Generation and True-to-Life\figure_3_page5.png
2025-11-09 22:37:54,763 - INFO - root - 已保存图片 4/10：./export\images_VoxCPM_ Tokenizer-Free TTS for Context-Aware Speech Generation and True-to-Life\figure_4_page1.png
2025-11-09 22:37:54,811 - INFO - root - 已保存图片 5/10：./export\images_VoxCPM_ Tokenizer-Free TTS for Context-Aware Speech Generation and True-to-Life\figure_5_page2.png
2025-11-09 22:37:54,853 - INFO - root - 已保存图片 6/10：./export\images_VoxCPM_ Tokenizer-Free TTS for Context-Aware Speech Generation and True-to-Life\figure_6_page3.png
2025-11-09 22:37:54,907 - INFO - root - 已保存图片 7/10：./export\images_VoxCPM_ Tokenizer-Free TTS for Context-Aware Speech Generation and True-to-Life\figure_7_page4.png
2025-11-09 22:37:54,960 - INFO - root - 已保存图片 8/10：./export\images_VoxCPM_ Tokenizer-Free TTS for Context-Aware Speech Generation and True-to-Life\figure_8_page5.png
2025-11-09 22:37:55,000 - INFO - root - 已保存图片 9/10：./export\images_VoxCPM_ Tokenizer-Free TTS for Context-Aware Speech Generation and True-to-Life\figure_9_page6.png
2025-11-09 22:37:55,051 - INFO - root - 已保存图片 10/10：./export\images_VoxCPM_ Tokenizer-Free TTS for Context-Aware Speech Generation and True-to-Life\figure_10_page7.png
2025-11-09 22:37:55,063 - INFO - root - 成功添加图片 1：./export\images_VoxCPM_ Tokenizer-Free TTS for Context-Aware Speech Generation and True-to-Life\figure_1_page14.png
2025-11-09 22:37:55,068 - INFO - root - 成功添加图片 2：./export\images_VoxCPM_ Tokenizer-Free TTS for Context-Aware Speech Generation and True-to-Life\figure_2_page13.png
2025-11-09 22:37:55,069 - INFO - root - 成功添加图片 3：./export\images_VoxCPM_ Tokenizer-Free TTS for Context-Aware Speech Generation and True-to-Life\figure_3_page5.png
2025-11-09 22:37:55,071 - INFO - root - 成功添加图片 4：./export\images_VoxCPM_ Tokenizer-Free TTS for Context-Aware Speech Generation and True-to-Life\figure_4_page1.png
2025-11-09 22:37:55,071 - INFO - root - 成功添加图片 5：./export\images_VoxCPM_ Tokenizer-Free TTS for Context-Aware Speech Generation and True-to-Life\figure_5_page2.png
2025-11-09 22:37:55,073 - INFO - root - 成功添加图片 6：./export\images_VoxCPM_ Tokenizer-Free TTS for Context-Aware Speech Generation and True-to-Life\figure_6_page3.png
2025-11-09 22:37:55,073 - INFO - root - 成功添加图片 7：./export\images_VoxCPM_ Tokenizer-Free TTS for Context-Aware Speech Generation and True-to-Life\figure_7_page4.png
2025-11-09 22:37:55,074 - INFO - root - 成功添加图片 8：./export\images_VoxCPM_ Tokenizer-Free TTS for Context-Aware Speech Generation and True-to-Life\figure_8_page5.png
2025-11-09 22:37:55,074 - INFO - root - 成功添加图片 9：./export\images_VoxCPM_ Tokenizer-Free TTS for Context-Aware Speech Generation and True-to-Life\figure_9_page6.png
2025-11-09 22:37:55,076 - INFO - root - 成功添加图片 10：./export\images_VoxCPM_ Tokenizer-Free TTS for Context-Aware Speech Generation and True-to-Life\figure_10_page7.png
2025-11-09 22:37:55,078 - INFO - root - 论文《VoxCPM: Tokenizer-Free TTS for Context-Aware Speech Generation and True-to-Life Voice Cloning》的分析已保存到 ./export\VoxCPM_ Tokenizer-Free TTS for Context-Aware Speech Generation and True-to-Life.md
2025-11-09 22:37:55,087 - INFO - root - 正在总结论文 42/80: S$^2$NN: Sub-bit Spiking Neural Networks
2025-11-09 22:38:11,374 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 22:38:11,376 - INFO - root - LLMClient: rate limit reached, sleeping 1.4s
2025-11-09 22:39:02,879 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 22:39:41,228 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 22:39:41,231 - INFO - root - 正在提取论文图片...
2025-11-09 22:39:41,918 - INFO - root - 已保存图片 1/10：./export\images_S$^2$NN_ Sub-bit Spiking Neural Networks\figure_1_page5.jpeg
2025-11-09 22:39:42,131 - INFO - root - 已保存图片 2/10：./export\images_S$^2$NN_ Sub-bit Spiking Neural Networks\figure_2_page4.jpeg
2025-11-09 22:39:42,262 - INFO - root - 已保存图片 3/10：./export\images_S$^2$NN_ Sub-bit Spiking Neural Networks\figure_3_page4.jpeg
2025-11-09 22:39:42,370 - INFO - root - 已保存图片 4/10：./export\images_S$^2$NN_ Sub-bit Spiking Neural Networks\figure_4_page27.png
2025-11-09 22:39:42,409 - INFO - root - 已保存图片 5/10：./export\images_S$^2$NN_ Sub-bit Spiking Neural Networks\figure_5_page9.jpeg
2025-11-09 22:39:42,495 - INFO - root - 已保存图片 6/10：./export\images_S$^2$NN_ Sub-bit Spiking Neural Networks\figure_6_page9.jpeg
2025-11-09 22:39:42,554 - INFO - root - 已保存图片 7/10：./export\images_S$^2$NN_ Sub-bit Spiking Neural Networks\figure_7_page9.jpeg
2025-11-09 22:39:42,609 - INFO - root - 已保存图片 8/10：./export\images_S$^2$NN_ Sub-bit Spiking Neural Networks\figure_8_page9.jpeg
2025-11-09 22:39:42,651 - INFO - root - 已保存图片 9/10：./export\images_S$^2$NN_ Sub-bit Spiking Neural Networks\figure_9_page9.jpeg
2025-11-09 22:39:42,694 - INFO - root - 已保存图片 10/10：./export\images_S$^2$NN_ Sub-bit Spiking Neural Networks\figure_10_page9.jpeg
2025-11-09 22:39:42,714 - INFO - root - 成功添加图片 1：./export\images_S$^2$NN_ Sub-bit Spiking Neural Networks\figure_1_page5.jpeg
2025-11-09 22:39:42,715 - INFO - root - 成功添加图片 2：./export\images_S$^2$NN_ Sub-bit Spiking Neural Networks\figure_2_page4.jpeg
2025-11-09 22:39:42,715 - INFO - root - 成功添加图片 3：./export\images_S$^2$NN_ Sub-bit Spiking Neural Networks\figure_3_page4.jpeg
2025-11-09 22:39:42,715 - INFO - root - 成功添加图片 4：./export\images_S$^2$NN_ Sub-bit Spiking Neural Networks\figure_4_page27.png
2025-11-09 22:39:42,716 - INFO - root - 成功添加图片 5：./export\images_S$^2$NN_ Sub-bit Spiking Neural Networks\figure_5_page9.jpeg
2025-11-09 22:39:42,716 - INFO - root - 成功添加图片 6：./export\images_S$^2$NN_ Sub-bit Spiking Neural Networks\figure_6_page9.jpeg
2025-11-09 22:39:42,716 - INFO - root - 成功添加图片 7：./export\images_S$^2$NN_ Sub-bit Spiking Neural Networks\figure_7_page9.jpeg
2025-11-09 22:39:42,717 - INFO - root - 成功添加图片 8：./export\images_S$^2$NN_ Sub-bit Spiking Neural Networks\figure_8_page9.jpeg
2025-11-09 22:39:42,717 - INFO - root - 成功添加图片 9：./export\images_S$^2$NN_ Sub-bit Spiking Neural Networks\figure_9_page9.jpeg
2025-11-09 22:39:42,717 - INFO - root - 成功添加图片 10：./export\images_S$^2$NN_ Sub-bit Spiking Neural Networks\figure_10_page9.jpeg
2025-11-09 22:39:42,720 - INFO - root - 论文《S$^2$NN: Sub-bit Spiking Neural Networks》的分析已保存到 ./export\S$^2$NN_ Sub-bit Spiking Neural Networks.md
2025-11-09 22:39:42,728 - INFO - root - 正在总结论文 43/80: Tequila: Trapping-free Ternary Quantization for Large Language Models
2025-11-09 22:39:57,705 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 22:39:57,706 - INFO - root - LLMClient: rate limit reached, sleeping 5.2s
2025-11-09 22:41:00,219 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 22:41:50,493 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 22:41:50,495 - INFO - root - 正在提取论文图片...
2025-11-09 22:41:51,197 - INFO - root - 已保存图片 1/10：./export\images_Tequila_ Trapping-free Ternary Quantization for Large Language Models\figure_1_page16.png
2025-11-09 22:41:51,337 - INFO - root - 已保存图片 2/10：./export\images_Tequila_ Trapping-free Ternary Quantization for Large Language Models\figure_2_page16.png
2025-11-09 22:41:51,407 - INFO - root - 已保存图片 3/10：./export\images_Tequila_ Trapping-free Ternary Quantization for Large Language Models\figure_3_page2.png
2025-11-09 22:41:51,455 - INFO - root - 已保存图片 4/10：./export\images_Tequila_ Trapping-free Ternary Quantization for Large Language Models\figure_4_page2.png
2025-11-09 22:41:51,508 - INFO - root - 已保存图片 5/10：./export\images_Tequila_ Trapping-free Ternary Quantization for Large Language Models\figure_5_page2.png
2025-11-09 22:41:51,555 - INFO - root - 已保存图片 6/10：./export\images_Tequila_ Trapping-free Ternary Quantization for Large Language Models\figure_6_page2.png
2025-11-09 22:41:51,597 - INFO - root - 已保存图片 7/10：./export\images_Tequila_ Trapping-free Ternary Quantization for Large Language Models\figure_7_page16.png
2025-11-09 22:41:51,644 - INFO - root - 已保存图片 8/10：./export\images_Tequila_ Trapping-free Ternary Quantization for Large Language Models\figure_8_page16.png
2025-11-09 22:41:51,689 - INFO - root - 已保存图片 9/10：./export\images_Tequila_ Trapping-free Ternary Quantization for Large Language Models\figure_9_page16.png
2025-11-09 22:41:51,759 - INFO - root - 已保存图片 10/10：./export\images_Tequila_ Trapping-free Ternary Quantization for Large Language Models\figure_10_page16.png
2025-11-09 22:41:51,765 - INFO - root - 成功添加图片 1：./export\images_Tequila_ Trapping-free Ternary Quantization for Large Language Models\figure_1_page16.png
2025-11-09 22:41:51,769 - INFO - root - 成功添加图片 2：./export\images_Tequila_ Trapping-free Ternary Quantization for Large Language Models\figure_2_page16.png
2025-11-09 22:41:51,770 - INFO - root - 成功添加图片 3：./export\images_Tequila_ Trapping-free Ternary Quantization for Large Language Models\figure_3_page2.png
2025-11-09 22:41:51,772 - INFO - root - 成功添加图片 4：./export\images_Tequila_ Trapping-free Ternary Quantization for Large Language Models\figure_4_page2.png
2025-11-09 22:41:51,784 - INFO - root - 成功添加图片 5：./export\images_Tequila_ Trapping-free Ternary Quantization for Large Language Models\figure_5_page2.png
2025-11-09 22:41:51,791 - INFO - root - 成功添加图片 6：./export\images_Tequila_ Trapping-free Ternary Quantization for Large Language Models\figure_6_page2.png
2025-11-09 22:41:51,791 - INFO - root - 成功添加图片 7：./export\images_Tequila_ Trapping-free Ternary Quantization for Large Language Models\figure_7_page16.png
2025-11-09 22:41:51,792 - INFO - root - 成功添加图片 8：./export\images_Tequila_ Trapping-free Ternary Quantization for Large Language Models\figure_8_page16.png
2025-11-09 22:41:51,792 - INFO - root - 成功添加图片 9：./export\images_Tequila_ Trapping-free Ternary Quantization for Large Language Models\figure_9_page16.png
2025-11-09 22:41:51,793 - INFO - root - 成功添加图片 10：./export\images_Tequila_ Trapping-free Ternary Quantization for Large Language Models\figure_10_page16.png
2025-11-09 22:41:51,798 - INFO - root - 论文《Tequila: Trapping-free Ternary Quantization for Large Language Models》的分析已保存到 ./export\Tequila_ Trapping-free Ternary Quantization for Large Language Models.md
2025-11-09 22:41:51,807 - INFO - root - 正在总结论文 44/80: Texture Vector-Quantization and Reconstruction Aware Prediction for Generative Super-Resolution
2025-11-09 22:42:10,665 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 22:43:21,183 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 22:43:59,545 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 22:43:59,548 - INFO - root - 正在提取论文图片...
2025-11-09 22:44:00,334 - INFO - root - 已保存图片 1/10：./export\images_Texture Vector-Quantization and Reconstruction Aware Prediction for Generative S\figure_1_page8.png
2025-11-09 22:44:00,411 - INFO - root - 已保存图片 2/10：./export\images_Texture Vector-Quantization and Reconstruction Aware Prediction for Generative S\figure_2_page19.jpeg
2025-11-09 22:44:00,536 - INFO - root - 已保存图片 3/10：./export\images_Texture Vector-Quantization and Reconstruction Aware Prediction for Generative S\figure_3_page19.jpeg
2025-11-09 22:44:00,629 - INFO - root - 已保存图片 4/10：./export\images_Texture Vector-Quantization and Reconstruction Aware Prediction for Generative S\figure_4_page19.jpeg
2025-11-09 22:44:00,699 - INFO - root - 已保存图片 5/10：./export\images_Texture Vector-Quantization and Reconstruction Aware Prediction for Generative S\figure_5_page19.jpeg
2025-11-09 22:44:00,779 - INFO - root - 已保存图片 6/10：./export\images_Texture Vector-Quantization and Reconstruction Aware Prediction for Generative S\figure_6_page19.jpeg
2025-11-09 22:44:00,836 - INFO - root - 已保存图片 7/10：./export\images_Texture Vector-Quantization and Reconstruction Aware Prediction for Generative S\figure_7_page19.jpeg
2025-11-09 22:44:00,887 - INFO - root - 已保存图片 8/10：./export\images_Texture Vector-Quantization and Reconstruction Aware Prediction for Generative S\figure_8_page19.jpeg
2025-11-09 22:44:00,942 - INFO - root - 已保存图片 9/10：./export\images_Texture Vector-Quantization and Reconstruction Aware Prediction for Generative S\figure_9_page19.jpeg
2025-11-09 22:44:00,988 - INFO - root - 已保存图片 10/10：./export\images_Texture Vector-Quantization and Reconstruction Aware Prediction for Generative S\figure_10_page19.jpeg
2025-11-09 22:44:00,996 - INFO - root - 成功添加图片 1：./export\images_Texture Vector-Quantization and Reconstruction Aware Prediction for Generative S\figure_1_page8.png
2025-11-09 22:44:00,996 - INFO - root - 成功添加图片 2：./export\images_Texture Vector-Quantization and Reconstruction Aware Prediction for Generative S\figure_2_page19.jpeg
2025-11-09 22:44:00,997 - INFO - root - 成功添加图片 3：./export\images_Texture Vector-Quantization and Reconstruction Aware Prediction for Generative S\figure_3_page19.jpeg
2025-11-09 22:44:00,998 - INFO - root - 成功添加图片 4：./export\images_Texture Vector-Quantization and Reconstruction Aware Prediction for Generative S\figure_4_page19.jpeg
2025-11-09 22:44:00,999 - INFO - root - 成功添加图片 5：./export\images_Texture Vector-Quantization and Reconstruction Aware Prediction for Generative S\figure_5_page19.jpeg
2025-11-09 22:44:00,999 - INFO - root - 成功添加图片 6：./export\images_Texture Vector-Quantization and Reconstruction Aware Prediction for Generative S\figure_6_page19.jpeg
2025-11-09 22:44:01,000 - INFO - root - 成功添加图片 7：./export\images_Texture Vector-Quantization and Reconstruction Aware Prediction for Generative S\figure_7_page19.jpeg
2025-11-09 22:44:01,000 - INFO - root - 成功添加图片 8：./export\images_Texture Vector-Quantization and Reconstruction Aware Prediction for Generative S\figure_8_page19.jpeg
2025-11-09 22:44:01,000 - INFO - root - 成功添加图片 9：./export\images_Texture Vector-Quantization and Reconstruction Aware Prediction for Generative S\figure_9_page19.jpeg
2025-11-09 22:44:01,003 - INFO - root - 成功添加图片 10：./export\images_Texture Vector-Quantization and Reconstruction Aware Prediction for Generative S\figure_10_page19.jpeg
2025-11-09 22:44:01,011 - INFO - root - 论文《Texture Vector-Quantization and Reconstruction Aware Prediction for Generative Super-Resolution》的分析已保存到 ./export\Texture Vector-Quantization and Reconstruction Aware Prediction for Generative S.md
2025-11-09 22:44:01,020 - INFO - root - 正在总结论文 45/80: RobuQ: Pushing DiTs to W1.58A2 via Robust Activation Quantization
2025-11-09 22:44:16,421 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 22:44:16,422 - INFO - root - LLMClient: rate limit reached, sleeping 4.8s
2025-11-09 22:45:25,755 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 22:45:59,146 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 22:45:59,150 - INFO - root - 正在提取论文图片...
2025-11-09 22:46:00,130 - INFO - root - 已保存图片 1/10：./export\images_RobuQ_ Pushing DiTs to W1.58A2 via Robust Activation Quantization\figure_1_page6.jpeg
2025-11-09 22:46:00,477 - INFO - root - 已保存图片 2/10：./export\images_RobuQ_ Pushing DiTs to W1.58A2 via Robust Activation Quantization\figure_2_page1.png
2025-11-09 22:46:00,573 - INFO - root - 已保存图片 3/10：./export\images_RobuQ_ Pushing DiTs to W1.58A2 via Robust Activation Quantization\figure_3_page21.png
2025-11-09 22:46:00,635 - INFO - root - 已保存图片 4/10：./export\images_RobuQ_ Pushing DiTs to W1.58A2 via Robust Activation Quantization\figure_4_page6.jpeg
2025-11-09 22:46:00,664 - INFO - root - 已保存图片 5/10：./export\images_RobuQ_ Pushing DiTs to W1.58A2 via Robust Activation Quantization\figure_5_page22.jpeg
2025-11-09 22:46:00,695 - INFO - root - 已保存图片 6/10：./export\images_RobuQ_ Pushing DiTs to W1.58A2 via Robust Activation Quantization\figure_6_page22.jpeg
2025-11-09 22:46:00,728 - INFO - root - 已保存图片 7/10：./export\images_RobuQ_ Pushing DiTs to W1.58A2 via Robust Activation Quantization\figure_7_page22.jpeg
2025-11-09 22:46:00,774 - INFO - root - 已保存图片 8/10：./export\images_RobuQ_ Pushing DiTs to W1.58A2 via Robust Activation Quantization\figure_8_page22.jpeg
2025-11-09 22:46:00,813 - INFO - root - 已保存图片 9/10：./export\images_RobuQ_ Pushing DiTs to W1.58A2 via Robust Activation Quantization\figure_9_page22.jpeg
2025-11-09 22:46:00,844 - INFO - root - 已保存图片 10/10：./export\images_RobuQ_ Pushing DiTs to W1.58A2 via Robust Activation Quantization\figure_10_page22.jpeg
2025-11-09 22:46:00,853 - INFO - root - 成功添加图片 1：./export\images_RobuQ_ Pushing DiTs to W1.58A2 via Robust Activation Quantization\figure_1_page6.jpeg
2025-11-09 22:46:00,855 - INFO - root - 成功添加图片 2：./export\images_RobuQ_ Pushing DiTs to W1.58A2 via Robust Activation Quantization\figure_2_page1.png
2025-11-09 22:46:00,855 - INFO - root - 成功添加图片 3：./export\images_RobuQ_ Pushing DiTs to W1.58A2 via Robust Activation Quantization\figure_3_page21.png
2025-11-09 22:46:00,856 - INFO - root - 成功添加图片 4：./export\images_RobuQ_ Pushing DiTs to W1.58A2 via Robust Activation Quantization\figure_4_page6.jpeg
2025-11-09 22:46:00,857 - INFO - root - 成功添加图片 5：./export\images_RobuQ_ Pushing DiTs to W1.58A2 via Robust Activation Quantization\figure_5_page22.jpeg
2025-11-09 22:46:00,858 - INFO - root - 成功添加图片 6：./export\images_RobuQ_ Pushing DiTs to W1.58A2 via Robust Activation Quantization\figure_6_page22.jpeg
2025-11-09 22:46:00,860 - INFO - root - 成功添加图片 7：./export\images_RobuQ_ Pushing DiTs to W1.58A2 via Robust Activation Quantization\figure_7_page22.jpeg
2025-11-09 22:46:00,861 - INFO - root - 成功添加图片 8：./export\images_RobuQ_ Pushing DiTs to W1.58A2 via Robust Activation Quantization\figure_8_page22.jpeg
2025-11-09 22:46:00,861 - INFO - root - 成功添加图片 9：./export\images_RobuQ_ Pushing DiTs to W1.58A2 via Robust Activation Quantization\figure_9_page22.jpeg
2025-11-09 22:46:00,862 - INFO - root - 成功添加图片 10：./export\images_RobuQ_ Pushing DiTs to W1.58A2 via Robust Activation Quantization\figure_10_page22.jpeg
2025-11-09 22:46:00,871 - INFO - root - 论文《RobuQ: Pushing DiTs to W1.58A2 via Robust Activation Quantization》的分析已保存到 ./export\RobuQ_ Pushing DiTs to W1.58A2 via Robust Activation Quantization.md
2025-11-09 22:46:00,878 - INFO - root - 正在总结论文 46/80: Beyond Outliers: A Study of Optimizers Under Quantization
2025-11-09 22:46:21,143 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 22:46:21,145 - INFO - root - LLMClient: rate limit reached, sleeping 4.6s
2025-11-09 22:47:20,920 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 22:48:11,469 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 22:48:11,472 - INFO - root - 正在提取论文图片...
2025-11-09 22:48:11,486 - INFO - root - 论文《Beyond Outliers: A Study of Optimizers Under Quantization》的分析已保存到 ./export\Beyond Outliers_ A Study of Optimizers Under Quantization.md
2025-11-09 22:48:11,522 - INFO - root - 正在总结论文 47/80: Compute-Optimal Quantization-Aware Training
2025-11-09 22:48:25,774 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 22:49:30,487 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 22:50:19,078 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 22:50:19,080 - INFO - root - 正在提取论文图片...
2025-11-09 22:50:19,530 - INFO - root - 已保存图片 1/10：./export\images_Compute-Optimal Quantization-Aware Training\figure_1_page2.png
2025-11-09 22:50:19,603 - INFO - root - 已保存图片 2/10：./export\images_Compute-Optimal Quantization-Aware Training\figure_2_page8.png
2025-11-09 22:50:19,658 - INFO - root - 已保存图片 3/10：./export\images_Compute-Optimal Quantization-Aware Training\figure_3_page22.png
2025-11-09 22:50:19,769 - INFO - root - 已保存图片 4/10：./export\images_Compute-Optimal Quantization-Aware Training\figure_4_page18.png
2025-11-09 22:50:19,865 - INFO - root - 已保存图片 5/10：./export\images_Compute-Optimal Quantization-Aware Training\figure_5_page19.png
2025-11-09 22:50:20,001 - INFO - root - 已保存图片 6/10：./export\images_Compute-Optimal Quantization-Aware Training\figure_6_page20.png
2025-11-09 22:50:20,108 - INFO - root - 已保存图片 7/10：./export\images_Compute-Optimal Quantization-Aware Training\figure_7_page18.png
2025-11-09 22:50:20,207 - INFO - root - 已保存图片 8/10：./export\images_Compute-Optimal Quantization-Aware Training\figure_8_page19.png
2025-11-09 22:50:20,288 - INFO - root - 已保存图片 9/10：./export\images_Compute-Optimal Quantization-Aware Training\figure_9_page19.png
2025-11-09 22:50:20,388 - INFO - root - 已保存图片 10/10：./export\images_Compute-Optimal Quantization-Aware Training\figure_10_page19.png
2025-11-09 22:50:20,390 - INFO - root - 成功添加图片 1：./export\images_Compute-Optimal Quantization-Aware Training\figure_1_page2.png
2025-11-09 22:50:20,390 - INFO - root - 成功添加图片 2：./export\images_Compute-Optimal Quantization-Aware Training\figure_2_page8.png
2025-11-09 22:50:20,391 - INFO - root - 成功添加图片 3：./export\images_Compute-Optimal Quantization-Aware Training\figure_3_page22.png
2025-11-09 22:50:20,391 - INFO - root - 成功添加图片 4：./export\images_Compute-Optimal Quantization-Aware Training\figure_4_page18.png
2025-11-09 22:50:20,391 - INFO - root - 成功添加图片 5：./export\images_Compute-Optimal Quantization-Aware Training\figure_5_page19.png
2025-11-09 22:50:20,391 - INFO - root - 成功添加图片 6：./export\images_Compute-Optimal Quantization-Aware Training\figure_6_page20.png
2025-11-09 22:50:20,393 - INFO - root - 成功添加图片 7：./export\images_Compute-Optimal Quantization-Aware Training\figure_7_page18.png
2025-11-09 22:50:20,393 - INFO - root - 成功添加图片 8：./export\images_Compute-Optimal Quantization-Aware Training\figure_8_page19.png
2025-11-09 22:50:20,395 - INFO - root - 成功添加图片 9：./export\images_Compute-Optimal Quantization-Aware Training\figure_9_page19.png
2025-11-09 22:50:20,397 - INFO - root - 成功添加图片 10：./export\images_Compute-Optimal Quantization-Aware Training\figure_10_page19.png
2025-11-09 22:50:20,403 - INFO - root - 论文《Compute-Optimal Quantization-Aware Training》的分析已保存到 ./export\Compute-Optimal Quantization-Aware Training.md
2025-11-09 22:50:20,411 - INFO - root - 正在总结论文 48/80: COSPADI: Compressing LLMs via Calibration-Guided Sparse Dictionary Learning
2025-11-09 22:50:34,369 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 22:51:26,359 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 22:51:55,270 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 22:51:55,277 - INFO - root - 正在提取论文图片...
2025-11-09 22:51:57,819 - INFO - root - 已保存图片 1/10：./export\images_COSPADI_ Compressing LLMs via Calibration-Guided Sparse Dictionary Learning\figure_1_page21.png
2025-11-09 22:51:58,075 - INFO - root - 已保存图片 2/10：./export\images_COSPADI_ Compressing LLMs via Calibration-Guided Sparse Dictionary Learning\figure_2_page20.png
2025-11-09 22:51:58,636 - INFO - root - 已保存图片 3/10：./export\images_COSPADI_ Compressing LLMs via Calibration-Guided Sparse Dictionary Learning\figure_3_page20.png
2025-11-09 22:51:58,782 - INFO - root - 已保存图片 4/10：./export\images_COSPADI_ Compressing LLMs via Calibration-Guided Sparse Dictionary Learning\figure_4_page7.png
2025-11-09 22:51:58,835 - INFO - root - 成功添加图片 1：./export\images_COSPADI_ Compressing LLMs via Calibration-Guided Sparse Dictionary Learning\figure_1_page21.png
2025-11-09 22:51:58,836 - INFO - root - 成功添加图片 2：./export\images_COSPADI_ Compressing LLMs via Calibration-Guided Sparse Dictionary Learning\figure_2_page20.png
2025-11-09 22:51:58,836 - INFO - root - 成功添加图片 3：./export\images_COSPADI_ Compressing LLMs via Calibration-Guided Sparse Dictionary Learning\figure_3_page20.png
2025-11-09 22:51:58,837 - INFO - root - 成功添加图片 4：./export\images_COSPADI_ Compressing LLMs via Calibration-Guided Sparse Dictionary Learning\figure_4_page7.png
2025-11-09 22:51:58,844 - INFO - root - 论文《COSPADI: Compressing LLMs via Calibration-Guided Sparse Dictionary Learning》的分析已保存到 ./export\COSPADI_ Compressing LLMs via Calibration-Guided Sparse Dictionary Learning.md
2025-11-09 22:51:58,855 - INFO - root - 正在总结论文 49/80: SlimDiff: Training-Free, Activation-Guided Hands-free Slimming of Diffusion Models
2025-11-09 22:52:10,026 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 22:52:10,044 - INFO - root - LLMClient: rate limit reached, sleeping 16.3s
2025-11-09 22:53:19,618 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 22:53:52,770 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 22:53:52,773 - INFO - root - 正在提取论文图片...
2025-11-09 22:53:56,941 - INFO - root - 已保存图片 1/10：./export\images_SlimDiff_ Training-Free, Activation-Guided Hands-free Slimming of Diffusion Mode\figure_1_page18.png
2025-11-09 22:53:57,083 - INFO - root - 已保存图片 2/10：./export\images_SlimDiff_ Training-Free, Activation-Guided Hands-free Slimming of Diffusion Mode\figure_2_page3.png
2025-11-09 22:53:57,319 - INFO - root - 已保存图片 3/10：./export\images_SlimDiff_ Training-Free, Activation-Guided Hands-free Slimming of Diffusion Mode\figure_3_page19.png
2025-11-09 22:53:57,602 - INFO - root - 已保存图片 4/10：./export\images_SlimDiff_ Training-Free, Activation-Guided Hands-free Slimming of Diffusion Mode\figure_4_page19.png
2025-11-09 22:53:57,863 - INFO - root - 已保存图片 5/10：./export\images_SlimDiff_ Training-Free, Activation-Guided Hands-free Slimming of Diffusion Mode\figure_5_page7.png
2025-11-09 22:53:57,979 - INFO - root - 已保存图片 6/10：./export\images_SlimDiff_ Training-Free, Activation-Guided Hands-free Slimming of Diffusion Mode\figure_6_page18.png
2025-11-09 22:53:58,083 - INFO - root - 已保存图片 7/10：./export\images_SlimDiff_ Training-Free, Activation-Guided Hands-free Slimming of Diffusion Mode\figure_7_page9.png
2025-11-09 22:53:58,100 - INFO - root - 已保存图片 8/10：./export\images_SlimDiff_ Training-Free, Activation-Guided Hands-free Slimming of Diffusion Mode\figure_8_page18.png
2025-11-09 22:53:58,119 - INFO - root - 成功添加图片 1：./export\images_SlimDiff_ Training-Free, Activation-Guided Hands-free Slimming of Diffusion Mode\figure_1_page18.png
2025-11-09 22:53:58,120 - INFO - root - 成功添加图片 2：./export\images_SlimDiff_ Training-Free, Activation-Guided Hands-free Slimming of Diffusion Mode\figure_2_page3.png
2025-11-09 22:53:58,120 - INFO - root - 成功添加图片 3：./export\images_SlimDiff_ Training-Free, Activation-Guided Hands-free Slimming of Diffusion Mode\figure_3_page19.png
2025-11-09 22:53:58,121 - INFO - root - 成功添加图片 4：./export\images_SlimDiff_ Training-Free, Activation-Guided Hands-free Slimming of Diffusion Mode\figure_4_page19.png
2025-11-09 22:53:58,121 - INFO - root - 成功添加图片 5：./export\images_SlimDiff_ Training-Free, Activation-Guided Hands-free Slimming of Diffusion Mode\figure_5_page7.png
2025-11-09 22:53:58,122 - INFO - root - 成功添加图片 6：./export\images_SlimDiff_ Training-Free, Activation-Guided Hands-free Slimming of Diffusion Mode\figure_6_page18.png
2025-11-09 22:53:58,126 - INFO - root - 成功添加图片 7：./export\images_SlimDiff_ Training-Free, Activation-Guided Hands-free Slimming of Diffusion Mode\figure_7_page9.png
2025-11-09 22:53:58,126 - INFO - root - 成功添加图片 8：./export\images_SlimDiff_ Training-Free, Activation-Guided Hands-free Slimming of Diffusion Mode\figure_8_page18.png
2025-11-09 22:53:58,136 - INFO - root - 论文《SlimDiff: Training-Free, Activation-Guided Hands-free Slimming of Diffusion Models》的分析已保存到 ./export\SlimDiff_ Training-Free, Activation-Guided Hands-free Slimming of Diffusion Mode.md
2025-11-09 22:53:58,149 - INFO - root - 正在总结论文 50/80: Quantized Visual Geometry Grounded Transformer
2025-11-09 22:54:13,686 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 22:54:13,687 - INFO - root - LLMClient: rate limit reached, sleeping 5.9s
2025-11-09 22:55:07,951 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 22:55:35,665 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 22:55:35,667 - INFO - root - 正在提取论文图片...
2025-11-09 22:55:36,015 - INFO - root - 已保存图片 1/10：./export\images_Quantized Visual Geometry Grounded Transformer\figure_1_page6.jpeg
2025-11-09 22:55:36,256 - INFO - root - 已保存图片 2/10：./export\images_Quantized Visual Geometry Grounded Transformer\figure_2_page5.jpeg
2025-11-09 22:55:36,512 - INFO - root - 已保存图片 3/10：./export\images_Quantized Visual Geometry Grounded Transformer\figure_3_page15.jpeg
2025-11-09 22:55:36,721 - INFO - root - 已保存图片 4/10：./export\images_Quantized Visual Geometry Grounded Transformer\figure_4_page15.jpeg
2025-11-09 22:55:37,000 - INFO - root - 已保存图片 5/10：./export\images_Quantized Visual Geometry Grounded Transformer\figure_5_page15.jpeg
2025-11-09 22:55:37,230 - INFO - root - 已保存图片 6/10：./export\images_Quantized Visual Geometry Grounded Transformer\figure_6_page15.jpeg
2025-11-09 22:55:37,433 - INFO - root - 已保存图片 7/10：./export\images_Quantized Visual Geometry Grounded Transformer\figure_7_page5.jpeg
2025-11-09 22:55:37,612 - INFO - root - 已保存图片 8/10：./export\images_Quantized Visual Geometry Grounded Transformer\figure_8_page5.jpeg
2025-11-09 22:55:37,812 - INFO - root - 已保存图片 9/10：./export\images_Quantized Visual Geometry Grounded Transformer\figure_9_page5.jpeg
2025-11-09 22:55:38,046 - INFO - root - 已保存图片 10/10：./export\images_Quantized Visual Geometry Grounded Transformer\figure_10_page15.jpeg
2025-11-09 22:55:38,082 - INFO - root - 成功添加图片 1：./export\images_Quantized Visual Geometry Grounded Transformer\figure_1_page6.jpeg
2025-11-09 22:55:38,083 - INFO - root - 成功添加图片 2：./export\images_Quantized Visual Geometry Grounded Transformer\figure_2_page5.jpeg
2025-11-09 22:55:38,083 - INFO - root - 成功添加图片 3：./export\images_Quantized Visual Geometry Grounded Transformer\figure_3_page15.jpeg
2025-11-09 22:55:38,084 - INFO - root - 成功添加图片 4：./export\images_Quantized Visual Geometry Grounded Transformer\figure_4_page15.jpeg
2025-11-09 22:55:38,084 - INFO - root - 成功添加图片 5：./export\images_Quantized Visual Geometry Grounded Transformer\figure_5_page15.jpeg
2025-11-09 22:55:38,085 - INFO - root - 成功添加图片 6：./export\images_Quantized Visual Geometry Grounded Transformer\figure_6_page15.jpeg
2025-11-09 22:55:38,085 - INFO - root - 成功添加图片 7：./export\images_Quantized Visual Geometry Grounded Transformer\figure_7_page5.jpeg
2025-11-09 22:55:38,086 - INFO - root - 成功添加图片 8：./export\images_Quantized Visual Geometry Grounded Transformer\figure_8_page5.jpeg
2025-11-09 22:55:38,086 - INFO - root - 成功添加图片 9：./export\images_Quantized Visual Geometry Grounded Transformer\figure_9_page5.jpeg
2025-11-09 22:55:38,086 - INFO - root - 成功添加图片 10：./export\images_Quantized Visual Geometry Grounded Transformer\figure_10_page15.jpeg
2025-11-09 22:55:38,096 - INFO - root - 论文《Quantized Visual Geometry Grounded Transformer》的分析已保存到 ./export\Quantized Visual Geometry Grounded Transformer.md
2025-11-09 22:55:38,101 - INFO - root - 正在总结论文 51/80: Can Less Precise Be More Reliable? A Systematic Evaluation of Quantization's Impact on CLIP Beyond Accuracy
2025-11-09 22:55:51,391 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 22:55:51,393 - INFO - root - LLMClient: rate limit reached, sleeping 16.6s
2025-11-09 22:56:53,942 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 22:57:24,647 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 22:57:24,649 - INFO - root - 正在提取论文图片...
2025-11-09 22:57:25,473 - INFO - root - 已保存图片 1/10：./export\images_Can Less Precise Be More Reliable_ A Systematic Evaluation of Quantization's Imp\figure_1_page1.png
2025-11-09 22:57:25,607 - INFO - root - 已保存图片 2/10：./export\images_Can Less Precise Be More Reliable_ A Systematic Evaluation of Quantization's Imp\figure_2_page18.png
2025-11-09 22:57:25,651 - INFO - root - 已保存图片 3/10：./export\images_Can Less Precise Be More Reliable_ A Systematic Evaluation of Quantization's Imp\figure_3_page7.png
2025-11-09 22:57:25,704 - INFO - root - 已保存图片 4/10：./export\images_Can Less Precise Be More Reliable_ A Systematic Evaluation of Quantization's Imp\figure_4_page7.png
2025-11-09 22:57:25,750 - INFO - root - 已保存图片 5/10：./export\images_Can Less Precise Be More Reliable_ A Systematic Evaluation of Quantization's Imp\figure_5_page7.png
2025-11-09 22:57:25,826 - INFO - root - 已保存图片 6/10：./export\images_Can Less Precise Be More Reliable_ A Systematic Evaluation of Quantization's Imp\figure_6_page7.png
2025-11-09 22:57:25,897 - INFO - root - 已保存图片 7/10：./export\images_Can Less Precise Be More Reliable_ A Systematic Evaluation of Quantization's Imp\figure_7_page7.png
2025-11-09 22:57:25,964 - INFO - root - 已保存图片 8/10：./export\images_Can Less Precise Be More Reliable_ A Systematic Evaluation of Quantization's Imp\figure_8_page12.png
2025-11-09 22:57:26,023 - INFO - root - 已保存图片 9/10：./export\images_Can Less Precise Be More Reliable_ A Systematic Evaluation of Quantization's Imp\figure_9_page12.png
2025-11-09 22:57:26,100 - INFO - root - 已保存图片 10/10：./export\images_Can Less Precise Be More Reliable_ A Systematic Evaluation of Quantization's Imp\figure_10_page12.png
2025-11-09 22:57:26,104 - INFO - root - 成功添加图片 1：./export\images_Can Less Precise Be More Reliable_ A Systematic Evaluation of Quantization's Imp\figure_1_page1.png
2025-11-09 22:57:26,105 - INFO - root - 成功添加图片 2：./export\images_Can Less Precise Be More Reliable_ A Systematic Evaluation of Quantization's Imp\figure_2_page18.png
2025-11-09 22:57:26,105 - INFO - root - 成功添加图片 3：./export\images_Can Less Precise Be More Reliable_ A Systematic Evaluation of Quantization's Imp\figure_3_page7.png
2025-11-09 22:57:26,106 - INFO - root - 成功添加图片 4：./export\images_Can Less Precise Be More Reliable_ A Systematic Evaluation of Quantization's Imp\figure_4_page7.png
2025-11-09 22:57:26,107 - INFO - root - 成功添加图片 5：./export\images_Can Less Precise Be More Reliable_ A Systematic Evaluation of Quantization's Imp\figure_5_page7.png
2025-11-09 22:57:26,107 - INFO - root - 成功添加图片 6：./export\images_Can Less Precise Be More Reliable_ A Systematic Evaluation of Quantization's Imp\figure_6_page7.png
2025-11-09 22:57:26,107 - INFO - root - 成功添加图片 7：./export\images_Can Less Precise Be More Reliable_ A Systematic Evaluation of Quantization's Imp\figure_7_page7.png
2025-11-09 22:57:26,110 - INFO - root - 成功添加图片 8：./export\images_Can Less Precise Be More Reliable_ A Systematic Evaluation of Quantization's Imp\figure_8_page12.png
2025-11-09 22:57:26,110 - INFO - root - 成功添加图片 9：./export\images_Can Less Precise Be More Reliable_ A Systematic Evaluation of Quantization's Imp\figure_9_page12.png
2025-11-09 22:57:26,110 - INFO - root - 成功添加图片 10：./export\images_Can Less Precise Be More Reliable_ A Systematic Evaluation of Quantization's Imp\figure_10_page12.png
2025-11-09 22:57:26,117 - INFO - root - 论文《Can Less Precise Be More Reliable? A Systematic Evaluation of Quantization's Impact on CLIP Beyond Accuracy》的分析已保存到 ./export\Can Less Precise Be More Reliable_ A Systematic Evaluation of Quantization's Imp.md
2025-11-09 22:57:26,126 - INFO - root - 正在总结论文 52/80: Punching Above Precision: Small Quantized Model Distillation with Learnable Regularizer
2025-11-09 22:57:38,672 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 22:57:38,674 - INFO - root - LLMClient: rate limit reached, sleeping 15.3s
2025-11-09 22:58:45,481 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 22:59:25,122 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 22:59:25,126 - INFO - root - 正在提取论文图片...
2025-11-09 22:59:25,684 - INFO - root - 已保存图片 1/10：./export\images_Punching Above Precision_ Small Quantized Model Distillation with Learnable Regu\figure_1_page11.png
2025-11-09 22:59:25,765 - INFO - root - 已保存图片 2/10：./export\images_Punching Above Precision_ Small Quantized Model Distillation with Learnable Regu\figure_2_page5.png
2025-11-09 22:59:25,834 - INFO - root - 已保存图片 3/10：./export\images_Punching Above Precision_ Small Quantized Model Distillation with Learnable Regu\figure_3_page5.png
2025-11-09 22:59:25,859 - INFO - root - 已保存图片 4/10：./export\images_Punching Above Precision_ Small Quantized Model Distillation with Learnable Regu\figure_4_page5.jpeg
2025-11-09 22:59:25,882 - INFO - root - 已保存图片 5/10：./export\images_Punching Above Precision_ Small Quantized Model Distillation with Learnable Regu\figure_5_page5.jpeg
2025-11-09 22:59:25,906 - INFO - root - 已保存图片 6/10：./export\images_Punching Above Precision_ Small Quantized Model Distillation with Learnable Regu\figure_6_page5.jpeg
2025-11-09 22:59:25,926 - INFO - root - 已保存图片 7/10：./export\images_Punching Above Precision_ Small Quantized Model Distillation with Learnable Regu\figure_7_page5.jpeg
2025-11-09 22:59:25,950 - INFO - root - 已保存图片 8/10：./export\images_Punching Above Precision_ Small Quantized Model Distillation with Learnable Regu\figure_8_page5.jpeg
2025-11-09 22:59:25,975 - INFO - root - 已保存图片 9/10：./export\images_Punching Above Precision_ Small Quantized Model Distillation with Learnable Regu\figure_9_page5.jpeg
2025-11-09 22:59:26,046 - INFO - root - 已保存图片 10/10：./export\images_Punching Above Precision_ Small Quantized Model Distillation with Learnable Regu\figure_10_page5.jpeg
2025-11-09 22:59:26,058 - INFO - root - 成功添加图片 1：./export\images_Punching Above Precision_ Small Quantized Model Distillation with Learnable Regu\figure_1_page11.png
2025-11-09 22:59:26,060 - INFO - root - 成功添加图片 2：./export\images_Punching Above Precision_ Small Quantized Model Distillation with Learnable Regu\figure_2_page5.png
2025-11-09 22:59:26,061 - INFO - root - 成功添加图片 3：./export\images_Punching Above Precision_ Small Quantized Model Distillation with Learnable Regu\figure_3_page5.png
2025-11-09 22:59:26,062 - INFO - root - 成功添加图片 4：./export\images_Punching Above Precision_ Small Quantized Model Distillation with Learnable Regu\figure_4_page5.jpeg
2025-11-09 22:59:26,072 - INFO - root - 成功添加图片 5：./export\images_Punching Above Precision_ Small Quantized Model Distillation with Learnable Regu\figure_5_page5.jpeg
2025-11-09 22:59:26,079 - INFO - root - 成功添加图片 6：./export\images_Punching Above Precision_ Small Quantized Model Distillation with Learnable Regu\figure_6_page5.jpeg
2025-11-09 22:59:26,080 - INFO - root - 成功添加图片 7：./export\images_Punching Above Precision_ Small Quantized Model Distillation with Learnable Regu\figure_7_page5.jpeg
2025-11-09 22:59:26,081 - INFO - root - 成功添加图片 8：./export\images_Punching Above Precision_ Small Quantized Model Distillation with Learnable Regu\figure_8_page5.jpeg
2025-11-09 22:59:26,083 - INFO - root - 成功添加图片 9：./export\images_Punching Above Precision_ Small Quantized Model Distillation with Learnable Regu\figure_9_page5.jpeg
2025-11-09 22:59:26,084 - INFO - root - 成功添加图片 10：./export\images_Punching Above Precision_ Small Quantized Model Distillation with Learnable Regu\figure_10_page5.jpeg
2025-11-09 22:59:26,098 - INFO - root - 论文《Punching Above Precision: Small Quantized Model Distillation with Learnable Regularizer》的分析已保存到 ./export\Punching Above Precision_ Small Quantized Model Distillation with Learnable Regu.md
2025-11-09 22:59:26,102 - INFO - root - 正在总结论文 53/80: TinyEcoWeedNet: Edge Efficient Real-Time Aerial Agricultural Weed Detection
2025-11-09 22:59:35,611 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 22:59:35,613 - INFO - root - LLMClient: rate limit reached, sleeping 9.9s
2025-11-09 23:00:43,338 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 23:01:20,990 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 23:01:20,993 - INFO - root - 正在提取论文图片...
2025-11-09 23:01:21,119 - INFO - root - 已保存图片 1/10：./export\images_TinyEcoWeedNet_ Edge Efficient Real-Time Aerial Agricultural Weed Detection\figure_1_page5.jpeg
2025-11-09 23:01:21,199 - INFO - root - 已保存图片 2/10：./export\images_TinyEcoWeedNet_ Edge Efficient Real-Time Aerial Agricultural Weed Detection\figure_2_page5.jpeg
2025-11-09 23:01:21,261 - INFO - root - 已保存图片 3/10：./export\images_TinyEcoWeedNet_ Edge Efficient Real-Time Aerial Agricultural Weed Detection\figure_3_page5.jpeg
2025-11-09 23:01:21,296 - INFO - root - 已保存图片 4/10：./export\images_TinyEcoWeedNet_ Edge Efficient Real-Time Aerial Agricultural Weed Detection\figure_4_page5.jpeg
2025-11-09 23:01:21,344 - INFO - root - 已保存图片 5/10：./export\images_TinyEcoWeedNet_ Edge Efficient Real-Time Aerial Agricultural Weed Detection\figure_5_page5.jpeg
2025-11-09 23:01:21,378 - INFO - root - 已保存图片 6/10：./export\images_TinyEcoWeedNet_ Edge Efficient Real-Time Aerial Agricultural Weed Detection\figure_6_page5.jpeg
2025-11-09 23:01:21,412 - INFO - root - 已保存图片 7/10：./export\images_TinyEcoWeedNet_ Edge Efficient Real-Time Aerial Agricultural Weed Detection\figure_7_page5.jpeg
2025-11-09 23:01:21,448 - INFO - root - 已保存图片 8/10：./export\images_TinyEcoWeedNet_ Edge Efficient Real-Time Aerial Agricultural Weed Detection\figure_8_page5.jpeg
2025-11-09 23:01:21,479 - INFO - root - 已保存图片 9/10：./export\images_TinyEcoWeedNet_ Edge Efficient Real-Time Aerial Agricultural Weed Detection\figure_9_page5.jpeg
2025-11-09 23:01:21,509 - INFO - root - 已保存图片 10/10：./export\images_TinyEcoWeedNet_ Edge Efficient Real-Time Aerial Agricultural Weed Detection\figure_10_page5.jpeg
2025-11-09 23:01:21,511 - INFO - root - 成功添加图片 1：./export\images_TinyEcoWeedNet_ Edge Efficient Real-Time Aerial Agricultural Weed Detection\figure_1_page5.jpeg
2025-11-09 23:01:21,512 - INFO - root - 成功添加图片 2：./export\images_TinyEcoWeedNet_ Edge Efficient Real-Time Aerial Agricultural Weed Detection\figure_2_page5.jpeg
2025-11-09 23:01:21,512 - INFO - root - 成功添加图片 3：./export\images_TinyEcoWeedNet_ Edge Efficient Real-Time Aerial Agricultural Weed Detection\figure_3_page5.jpeg
2025-11-09 23:01:21,512 - INFO - root - 成功添加图片 4：./export\images_TinyEcoWeedNet_ Edge Efficient Real-Time Aerial Agricultural Weed Detection\figure_4_page5.jpeg
2025-11-09 23:01:21,513 - INFO - root - 成功添加图片 5：./export\images_TinyEcoWeedNet_ Edge Efficient Real-Time Aerial Agricultural Weed Detection\figure_5_page5.jpeg
2025-11-09 23:01:21,513 - INFO - root - 成功添加图片 6：./export\images_TinyEcoWeedNet_ Edge Efficient Real-Time Aerial Agricultural Weed Detection\figure_6_page5.jpeg
2025-11-09 23:01:21,513 - INFO - root - 成功添加图片 7：./export\images_TinyEcoWeedNet_ Edge Efficient Real-Time Aerial Agricultural Weed Detection\figure_7_page5.jpeg
2025-11-09 23:01:21,515 - INFO - root - 成功添加图片 8：./export\images_TinyEcoWeedNet_ Edge Efficient Real-Time Aerial Agricultural Weed Detection\figure_8_page5.jpeg
2025-11-09 23:01:21,515 - INFO - root - 成功添加图片 9：./export\images_TinyEcoWeedNet_ Edge Efficient Real-Time Aerial Agricultural Weed Detection\figure_9_page5.jpeg
2025-11-09 23:01:21,516 - INFO - root - 成功添加图片 10：./export\images_TinyEcoWeedNet_ Edge Efficient Real-Time Aerial Agricultural Weed Detection\figure_10_page5.jpeg
2025-11-09 23:01:21,517 - INFO - root - 论文《TinyEcoWeedNet: Edge Efficient Real-Time Aerial Agricultural Weed Detection》的分析已保存到 ./export\TinyEcoWeedNet_ Edge Efficient Real-Time Aerial Agricultural Weed Detection.md
2025-11-09 23:01:21,526 - INFO - root - 正在总结论文 54/80: SBVR: Summation of BitVector Representation for Efficient LLM Quantization
2025-11-09 23:01:35,939 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 23:01:35,941 - INFO - root - LLMClient: rate limit reached, sleeping 7.5s
2025-11-09 23:02:50,730 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 23:03:27,069 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 23:03:27,070 - INFO - root - 正在提取论文图片...
2025-11-09 23:03:27,611 - INFO - root - 已保存图片 1/10：./export\images_SBVR_ Summation of BitVector Representation for Efficient LLM Quantization\figure_1_page2.png
2025-11-09 23:03:27,708 - INFO - root - 已保存图片 2/10：./export\images_SBVR_ Summation of BitVector Representation for Efficient LLM Quantization\figure_2_page2.png
2025-11-09 23:03:27,838 - INFO - root - 已保存图片 3/10：./export\images_SBVR_ Summation of BitVector Representation for Efficient LLM Quantization\figure_3_page2.png
2025-11-09 23:03:27,908 - INFO - root - 已保存图片 4/10：./export\images_SBVR_ Summation of BitVector Representation for Efficient LLM Quantization\figure_4_page2.png
2025-11-09 23:03:27,980 - INFO - root - 已保存图片 5/10：./export\images_SBVR_ Summation of BitVector Representation for Efficient LLM Quantization\figure_5_page4.png
2025-11-09 23:03:27,987 - INFO - root - 成功添加图片 1：./export\images_SBVR_ Summation of BitVector Representation for Efficient LLM Quantization\figure_1_page2.png
2025-11-09 23:03:27,989 - INFO - root - 成功添加图片 2：./export\images_SBVR_ Summation of BitVector Representation for Efficient LLM Quantization\figure_2_page2.png
2025-11-09 23:03:27,990 - INFO - root - 成功添加图片 3：./export\images_SBVR_ Summation of BitVector Representation for Efficient LLM Quantization\figure_3_page2.png
2025-11-09 23:03:27,990 - INFO - root - 成功添加图片 4：./export\images_SBVR_ Summation of BitVector Representation for Efficient LLM Quantization\figure_4_page2.png
2025-11-09 23:03:27,991 - INFO - root - 成功添加图片 5：./export\images_SBVR_ Summation of BitVector Representation for Efficient LLM Quantization\figure_5_page4.png
2025-11-09 23:03:27,994 - INFO - root - 论文《SBVR: Summation of BitVector Representation for Efficient LLM Quantization》的分析已保存到 ./export\SBVR_ Summation of BitVector Representation for Efficient LLM Quantization.md
2025-11-09 23:03:28,001 - INFO - root - 正在总结论文 55/80: QWHA: Quantization-Aware Walsh-Hadamard Adaptation for Parameter-Efficient Fine-Tuning on Large Language Models
2025-11-09 23:03:39,191 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 23:03:39,192 - INFO - root - LLMClient: rate limit reached, sleeping 11.5s
2025-11-09 23:04:49,317 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 23:05:27,595 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 23:05:27,598 - INFO - root - 正在提取论文图片...
2025-11-09 23:05:30,054 - INFO - root - 已保存图片 1/10：./export\images_QWHA_ Quantization-Aware Walsh-Hadamard Adaptation for Parameter-Efficient Fine-\figure_1_page20.png
2025-11-09 23:05:30,247 - INFO - root - 已保存图片 2/10：./export\images_QWHA_ Quantization-Aware Walsh-Hadamard Adaptation for Parameter-Efficient Fine-\figure_2_page5.png
2025-11-09 23:05:30,427 - INFO - root - 已保存图片 3/10：./export\images_QWHA_ Quantization-Aware Walsh-Hadamard Adaptation for Parameter-Efficient Fine-\figure_3_page18.png
2025-11-09 23:05:30,590 - INFO - root - 已保存图片 4/10：./export\images_QWHA_ Quantization-Aware Walsh-Hadamard Adaptation for Parameter-Efficient Fine-\figure_4_page20.png
2025-11-09 23:05:30,699 - INFO - root - 已保存图片 5/10：./export\images_QWHA_ Quantization-Aware Walsh-Hadamard Adaptation for Parameter-Efficient Fine-\figure_5_page20.png
2025-11-09 23:05:30,833 - INFO - root - 已保存图片 6/10：./export\images_QWHA_ Quantization-Aware Walsh-Hadamard Adaptation for Parameter-Efficient Fine-\figure_6_page5.png
2025-11-09 23:05:30,964 - INFO - root - 已保存图片 7/10：./export\images_QWHA_ Quantization-Aware Walsh-Hadamard Adaptation for Parameter-Efficient Fine-\figure_7_page15.png
2025-11-09 23:05:31,061 - INFO - root - 已保存图片 8/10：./export\images_QWHA_ Quantization-Aware Walsh-Hadamard Adaptation for Parameter-Efficient Fine-\figure_8_page5.jpeg
2025-11-09 23:05:31,240 - INFO - root - 已保存图片 9/10：./export\images_QWHA_ Quantization-Aware Walsh-Hadamard Adaptation for Parameter-Efficient Fine-\figure_9_page9.png
2025-11-09 23:05:31,361 - INFO - root - 已保存图片 10/10：./export\images_QWHA_ Quantization-Aware Walsh-Hadamard Adaptation for Parameter-Efficient Fine-\figure_10_page7.png
2025-11-09 23:05:31,379 - INFO - root - 成功添加图片 1：./export\images_QWHA_ Quantization-Aware Walsh-Hadamard Adaptation for Parameter-Efficient Fine-\figure_1_page20.png
2025-11-09 23:05:31,380 - INFO - root - 成功添加图片 2：./export\images_QWHA_ Quantization-Aware Walsh-Hadamard Adaptation for Parameter-Efficient Fine-\figure_2_page5.png
2025-11-09 23:05:31,380 - INFO - root - 成功添加图片 3：./export\images_QWHA_ Quantization-Aware Walsh-Hadamard Adaptation for Parameter-Efficient Fine-\figure_3_page18.png
2025-11-09 23:05:31,381 - INFO - root - 成功添加图片 4：./export\images_QWHA_ Quantization-Aware Walsh-Hadamard Adaptation for Parameter-Efficient Fine-\figure_4_page20.png
2025-11-09 23:05:31,382 - INFO - root - 成功添加图片 5：./export\images_QWHA_ Quantization-Aware Walsh-Hadamard Adaptation for Parameter-Efficient Fine-\figure_5_page20.png
2025-11-09 23:05:31,383 - INFO - root - 成功添加图片 6：./export\images_QWHA_ Quantization-Aware Walsh-Hadamard Adaptation for Parameter-Efficient Fine-\figure_6_page5.png
2025-11-09 23:05:31,384 - INFO - root - 成功添加图片 7：./export\images_QWHA_ Quantization-Aware Walsh-Hadamard Adaptation for Parameter-Efficient Fine-\figure_7_page15.png
2025-11-09 23:05:31,384 - INFO - root - 成功添加图片 8：./export\images_QWHA_ Quantization-Aware Walsh-Hadamard Adaptation for Parameter-Efficient Fine-\figure_8_page5.jpeg
2025-11-09 23:05:31,386 - INFO - root - 成功添加图片 9：./export\images_QWHA_ Quantization-Aware Walsh-Hadamard Adaptation for Parameter-Efficient Fine-\figure_9_page9.png
2025-11-09 23:05:31,386 - INFO - root - 成功添加图片 10：./export\images_QWHA_ Quantization-Aware Walsh-Hadamard Adaptation for Parameter-Efficient Fine-\figure_10_page7.png
2025-11-09 23:05:31,394 - INFO - root - 论文《QWHA: Quantization-Aware Walsh-Hadamard Adaptation for Parameter-Efficient Fine-Tuning on Large Language Models》的分析已保存到 ./export\QWHA_ Quantization-Aware Walsh-Hadamard Adaptation for Parameter-Efficient Fine-.md
2025-11-09 23:05:31,399 - INFO - root - 正在总结论文 56/80: PTQTP: Post-Training Quantization to Trit-Planes for Large Language Models
2025-11-09 23:05:42,847 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 23:05:42,849 - INFO - root - LLMClient: rate limit reached, sleeping 6.5s
2025-11-09 23:07:01,264 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 23:07:37,734 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 23:07:37,736 - INFO - root - 正在提取论文图片...
2025-11-09 23:07:39,741 - INFO - root - 已保存图片 1/10：./export\images_PTQTP_ Post-Training Quantization to Trit-Planes for Large Language Models\figure_1_page14.png
2025-11-09 23:07:40,056 - INFO - root - 已保存图片 2/10：./export\images_PTQTP_ Post-Training Quantization to Trit-Planes for Large Language Models\figure_2_page14.jpeg
2025-11-09 23:07:40,233 - INFO - root - 已保存图片 3/10：./export\images_PTQTP_ Post-Training Quantization to Trit-Planes for Large Language Models\figure_3_page2.png
2025-11-09 23:07:40,286 - INFO - root - 已保存图片 4/10：./export\images_PTQTP_ Post-Training Quantization to Trit-Planes for Large Language Models\figure_4_page2.png
2025-11-09 23:07:40,416 - INFO - root - 已保存图片 5/10：./export\images_PTQTP_ Post-Training Quantization to Trit-Planes for Large Language Models\figure_5_page2.png
2025-11-09 23:07:40,491 - INFO - root - 已保存图片 6/10：./export\images_PTQTP_ Post-Training Quantization to Trit-Planes for Large Language Models\figure_6_page2.png
2025-11-09 23:07:40,538 - INFO - root - 已保存图片 7/10：./export\images_PTQTP_ Post-Training Quantization to Trit-Planes for Large Language Models\figure_7_page2.png
2025-11-09 23:07:40,592 - INFO - root - 已保存图片 8/10：./export\images_PTQTP_ Post-Training Quantization to Trit-Planes for Large Language Models\figure_8_page2.png
2025-11-09 23:07:40,626 - INFO - root - 已保存图片 9/10：./export\images_PTQTP_ Post-Training Quantization to Trit-Planes for Large Language Models\figure_9_page4.png
2025-11-09 23:07:40,714 - INFO - root - 已保存图片 10/10：./export\images_PTQTP_ Post-Training Quantization to Trit-Planes for Large Language Models\figure_10_page4.png
2025-11-09 23:07:40,720 - INFO - root - 成功添加图片 1：./export\images_PTQTP_ Post-Training Quantization to Trit-Planes for Large Language Models\figure_1_page14.png
2025-11-09 23:07:40,721 - INFO - root - 成功添加图片 2：./export\images_PTQTP_ Post-Training Quantization to Trit-Planes for Large Language Models\figure_2_page14.jpeg
2025-11-09 23:07:40,722 - INFO - root - 成功添加图片 3：./export\images_PTQTP_ Post-Training Quantization to Trit-Planes for Large Language Models\figure_3_page2.png
2025-11-09 23:07:40,724 - INFO - root - 成功添加图片 4：./export\images_PTQTP_ Post-Training Quantization to Trit-Planes for Large Language Models\figure_4_page2.png
2025-11-09 23:07:40,726 - INFO - root - 成功添加图片 5：./export\images_PTQTP_ Post-Training Quantization to Trit-Planes for Large Language Models\figure_5_page2.png
2025-11-09 23:07:40,727 - INFO - root - 成功添加图片 6：./export\images_PTQTP_ Post-Training Quantization to Trit-Planes for Large Language Models\figure_6_page2.png
2025-11-09 23:07:40,729 - INFO - root - 成功添加图片 7：./export\images_PTQTP_ Post-Training Quantization to Trit-Planes for Large Language Models\figure_7_page2.png
2025-11-09 23:07:40,730 - INFO - root - 成功添加图片 8：./export\images_PTQTP_ Post-Training Quantization to Trit-Planes for Large Language Models\figure_8_page2.png
2025-11-09 23:07:40,731 - INFO - root - 成功添加图片 9：./export\images_PTQTP_ Post-Training Quantization to Trit-Planes for Large Language Models\figure_9_page4.png
2025-11-09 23:07:40,731 - INFO - root - 成功添加图片 10：./export\images_PTQTP_ Post-Training Quantization to Trit-Planes for Large Language Models\figure_10_page4.png
2025-11-09 23:07:40,742 - INFO - root - 论文《PTQTP: Post-Training Quantization to Trit-Planes for Large Language Models》的分析已保存到 ./export\PTQTP_ Post-Training Quantization to Trit-Planes for Large Language Models.md
2025-11-09 23:07:40,773 - INFO - root - 正在总结论文 57/80: MEC-Quant: Maximum Entropy Coding for Extremely Low Bit Quantization-Aware Training
2025-11-09 23:07:55,319 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 23:07:55,322 - INFO - root - LLMClient: rate limit reached, sleeping 5.9s
2025-11-09 23:08:53,861 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 23:09:31,774 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 23:09:31,780 - INFO - root - 正在提取论文图片...
2025-11-09 23:09:31,792 - INFO - root - 论文《MEC-Quant: Maximum Entropy Coding for Extremely Low Bit Quantization-Aware Training》的分析已保存到 ./export\MEC-Quant_ Maximum Entropy Coding for Extremely Low Bit Quantization-Aware Train.md
2025-11-09 23:09:31,802 - INFO - root - 正在总结论文 58/80: Q-ROAR: Outlier-Aware Rescaling for RoPE Position Interpolation in Quantized Long-Context LLMs
2025-11-09 23:09:44,360 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 23:09:44,362 - INFO - root - LLMClient: rate limit reached, sleeping 9.5s
2025-11-09 23:10:49,561 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 23:11:26,233 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 23:11:26,238 - INFO - root - 正在提取论文图片...
2025-11-09 23:11:26,248 - INFO - root - 论文《Q-ROAR: Outlier-Aware Rescaling for RoPE Position Interpolation in Quantized Long-Context LLMs》的分析已保存到 ./export\Q-ROAR_ Outlier-Aware Rescaling for RoPE Position Interpolation in Quantized Lon.md
2025-11-09 23:11:26,254 - INFO - root - 正在总结论文 59/80: Efficient Quantization-Aware Neural Receivers: Beyond Post-Training Quantization
2025-11-09 23:11:39,633 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 23:11:39,635 - INFO - root - LLMClient: rate limit reached, sleeping 9.9s
2025-11-09 23:12:41,935 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 23:13:16,957 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 23:13:16,960 - INFO - root - 正在提取论文图片...
2025-11-09 23:13:19,451 - INFO - root - 已保存图片 1/10：./export\images_Efficient Quantization-Aware Neural Receivers_ Beyond Post-Training Quantization\figure_1_page4.png
2025-11-09 23:13:19,462 - INFO - root - 成功添加图片 1：./export\images_Efficient Quantization-Aware Neural Receivers_ Beyond Post-Training Quantization\figure_1_page4.png
2025-11-09 23:13:19,464 - INFO - root - 论文《Efficient Quantization-Aware Neural Receivers: Beyond Post-Training Quantization》的分析已保存到 ./export\Efficient Quantization-Aware Neural Receivers_ Beyond Post-Training Quantization.md
2025-11-09 23:13:19,469 - INFO - root - 正在总结论文 60/80: Rate-Distortion Limits for Multimodal Retrieval: Theory, Optimal Codes, and Finite-Sample Guarantees
2025-11-09 23:13:34,621 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 23:13:34,623 - INFO - root - LLMClient: rate limit reached, sleeping 7.3s
2025-11-09 23:14:37,171 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 23:15:12,084 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 23:15:12,085 - INFO - root - 正在提取论文图片...
2025-11-09 23:15:12,113 - INFO - root - 论文《Rate-Distortion Limits for Multimodal Retrieval: Theory, Optimal Codes, and Finite-Sample Guarantees》的分析已保存到 ./export\Rate-Distortion Limits for Multimodal Retrieval_ Theory, Optimal Codes, and Fini.md
2025-11-09 23:15:12,118 - INFO - root - 正在总结论文 61/80: SQAP-VLA: A Synergistic Quantization-Aware Pruning Framework for High-Performance Vision-Language-Action Models
2025-11-09 23:15:20,725 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 23:15:20,748 - INFO - root - LLMClient: rate limit reached, sleeping 16.4s
2025-11-09 23:16:35,525 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 23:17:06,298 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 23:17:06,300 - INFO - root - 正在提取论文图片...
2025-11-09 23:17:09,336 - INFO - root - 已保存图片 1/10：./export\images_SQAP-VLA_ A Synergistic Quantization-Aware Pruning Framework for High-Performanc\figure_1_page6.png
2025-11-09 23:17:09,722 - INFO - root - 已保存图片 2/10：./export\images_SQAP-VLA_ A Synergistic Quantization-Aware Pruning Framework for High-Performanc\figure_2_page6.png
2025-11-09 23:17:09,841 - INFO - root - 已保存图片 3/10：./export\images_SQAP-VLA_ A Synergistic Quantization-Aware Pruning Framework for High-Performanc\figure_3_page2.png
2025-11-09 23:17:09,873 - INFO - root - 已保存图片 4/10：./export\images_SQAP-VLA_ A Synergistic Quantization-Aware Pruning Framework for High-Performanc\figure_4_page8.png
2025-11-09 23:17:09,912 - INFO - root - 已保存图片 5/10：./export\images_SQAP-VLA_ A Synergistic Quantization-Aware Pruning Framework for High-Performanc\figure_5_page8.png
2025-11-09 23:17:10,046 - INFO - root - 已保存图片 6/10：./export\images_SQAP-VLA_ A Synergistic Quantization-Aware Pruning Framework for High-Performanc\figure_6_page4.png
2025-11-09 23:17:10,201 - INFO - root - 已保存图片 7/10：./export\images_SQAP-VLA_ A Synergistic Quantization-Aware Pruning Framework for High-Performanc\figure_7_page4.png
2025-11-09 23:17:10,446 - INFO - root - 已保存图片 8/10：./export\images_SQAP-VLA_ A Synergistic Quantization-Aware Pruning Framework for High-Performanc\figure_8_page4.png
2025-11-09 23:17:10,667 - INFO - root - 已保存图片 9/10：./export\images_SQAP-VLA_ A Synergistic Quantization-Aware Pruning Framework for High-Performanc\figure_9_page4.png
2025-11-09 23:17:10,685 - INFO - root - 成功添加图片 1：./export\images_SQAP-VLA_ A Synergistic Quantization-Aware Pruning Framework for High-Performanc\figure_1_page6.png
2025-11-09 23:17:10,686 - INFO - root - 成功添加图片 2：./export\images_SQAP-VLA_ A Synergistic Quantization-Aware Pruning Framework for High-Performanc\figure_2_page6.png
2025-11-09 23:17:10,686 - INFO - root - 成功添加图片 3：./export\images_SQAP-VLA_ A Synergistic Quantization-Aware Pruning Framework for High-Performanc\figure_3_page2.png
2025-11-09 23:17:10,687 - INFO - root - 成功添加图片 4：./export\images_SQAP-VLA_ A Synergistic Quantization-Aware Pruning Framework for High-Performanc\figure_4_page8.png
2025-11-09 23:17:10,688 - INFO - root - 成功添加图片 5：./export\images_SQAP-VLA_ A Synergistic Quantization-Aware Pruning Framework for High-Performanc\figure_5_page8.png
2025-11-09 23:17:10,693 - INFO - root - 成功添加图片 6：./export\images_SQAP-VLA_ A Synergistic Quantization-Aware Pruning Framework for High-Performanc\figure_6_page4.png
2025-11-09 23:17:10,694 - INFO - root - 成功添加图片 7：./export\images_SQAP-VLA_ A Synergistic Quantization-Aware Pruning Framework for High-Performanc\figure_7_page4.png
2025-11-09 23:17:10,694 - INFO - root - 成功添加图片 8：./export\images_SQAP-VLA_ A Synergistic Quantization-Aware Pruning Framework for High-Performanc\figure_8_page4.png
2025-11-09 23:17:10,695 - INFO - root - 成功添加图片 9：./export\images_SQAP-VLA_ A Synergistic Quantization-Aware Pruning Framework for High-Performanc\figure_9_page4.png
2025-11-09 23:17:10,700 - INFO - root - 论文《SQAP-VLA: A Synergistic Quantization-Aware Pruning Framework for High-Performance Vision-Language-Action Models》的分析已保存到 ./export\SQAP-VLA_ A Synergistic Quantization-Aware Pruning Framework for High-Performanc.md
2025-11-09 23:17:10,713 - INFO - root - 正在总结论文 62/80: CSI Compression Beyond Latents: End-to-End Hybrid Attention-CNN Networks with Entropy Regularization
2025-11-09 23:17:19,079 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 23:17:19,080 - INFO - root - LLMClient: rate limit reached, sleeping 16.4s
2025-11-09 23:18:27,934 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 23:18:56,233 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 23:18:56,234 - INFO - root - 正在提取论文图片...
2025-11-09 23:18:56,397 - INFO - root - 已保存图片 1/10：./export\images_CSI Compression Beyond Latents_ End-to-End Hybrid Attention-CNN Networks with En\figure_1_page2.png
2025-11-09 23:18:56,456 - INFO - root - 已保存图片 2/10：./export\images_CSI Compression Beyond Latents_ End-to-End Hybrid Attention-CNN Networks with En\figure_2_page2.png
2025-11-09 23:18:56,464 - INFO - root - 成功添加图片 1：./export\images_CSI Compression Beyond Latents_ End-to-End Hybrid Attention-CNN Networks with En\figure_1_page2.png
2025-11-09 23:18:56,467 - INFO - root - 成功添加图片 2：./export\images_CSI Compression Beyond Latents_ End-to-End Hybrid Attention-CNN Networks with En\figure_2_page2.png
2025-11-09 23:18:56,471 - INFO - root - 论文《CSI Compression Beyond Latents: End-to-End Hybrid Attention-CNN Networks with Entropy Regularization》的分析已保存到 ./export\CSI Compression Beyond Latents_ End-to-End Hybrid Attention-CNN Networks with En.md
2025-11-09 23:18:56,480 - INFO - root - 正在总结论文 63/80: Explaining How Quantization Disparately Skews a Model
2025-11-09 23:19:07,125 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 23:19:07,125 - INFO - root - LLMClient: rate limit reached, sleeping 20.8s
2025-11-09 23:20:13,663 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 23:20:52,312 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 23:20:52,315 - INFO - root - 正在提取论文图片...
2025-11-09 23:20:52,909 - INFO - root - 已保存图片 1/10：./export\images_Explaining How Quantization Disparately Skews a Model\figure_1_page11.jpeg
2025-11-09 23:20:53,225 - INFO - root - 已保存图片 2/10：./export\images_Explaining How Quantization Disparately Skews a Model\figure_2_page7.jpeg
2025-11-09 23:20:53,460 - INFO - root - 已保存图片 3/10：./export\images_Explaining How Quantization Disparately Skews a Model\figure_3_page7.jpeg
2025-11-09 23:20:53,723 - INFO - root - 已保存图片 4/10：./export\images_Explaining How Quantization Disparately Skews a Model\figure_4_page7.jpeg
2025-11-09 23:20:53,957 - INFO - root - 已保存图片 5/10：./export\images_Explaining How Quantization Disparately Skews a Model\figure_5_page2.jpeg
2025-11-09 23:20:54,187 - INFO - root - 已保存图片 6/10：./export\images_Explaining How Quantization Disparately Skews a Model\figure_6_page10.jpeg
2025-11-09 23:20:54,392 - INFO - root - 已保存图片 7/10：./export\images_Explaining How Quantization Disparately Skews a Model\figure_7_page10.jpeg
2025-11-09 23:20:54,525 - INFO - root - 已保存图片 8/10：./export\images_Explaining How Quantization Disparately Skews a Model\figure_8_page8.jpeg
2025-11-09 23:20:54,728 - INFO - root - 已保存图片 9/10：./export\images_Explaining How Quantization Disparately Skews a Model\figure_9_page10.jpeg
2025-11-09 23:20:54,834 - INFO - root - 已保存图片 10/10：./export\images_Explaining How Quantization Disparately Skews a Model\figure_10_page5.jpeg
2025-11-09 23:20:54,895 - INFO - root - 成功添加图片 1：./export\images_Explaining How Quantization Disparately Skews a Model\figure_1_page11.jpeg
2025-11-09 23:20:54,895 - INFO - root - 成功添加图片 2：./export\images_Explaining How Quantization Disparately Skews a Model\figure_2_page7.jpeg
2025-11-09 23:20:54,896 - INFO - root - 成功添加图片 3：./export\images_Explaining How Quantization Disparately Skews a Model\figure_3_page7.jpeg
2025-11-09 23:20:54,897 - INFO - root - 成功添加图片 4：./export\images_Explaining How Quantization Disparately Skews a Model\figure_4_page7.jpeg
2025-11-09 23:20:54,898 - INFO - root - 成功添加图片 5：./export\images_Explaining How Quantization Disparately Skews a Model\figure_5_page2.jpeg
2025-11-09 23:20:54,899 - INFO - root - 成功添加图片 6：./export\images_Explaining How Quantization Disparately Skews a Model\figure_6_page10.jpeg
2025-11-09 23:20:54,899 - INFO - root - 成功添加图片 7：./export\images_Explaining How Quantization Disparately Skews a Model\figure_7_page10.jpeg
2025-11-09 23:20:54,899 - INFO - root - 成功添加图片 8：./export\images_Explaining How Quantization Disparately Skews a Model\figure_8_page8.jpeg
2025-11-09 23:20:54,900 - INFO - root - 成功添加图片 9：./export\images_Explaining How Quantization Disparately Skews a Model\figure_9_page10.jpeg
2025-11-09 23:20:54,901 - INFO - root - 成功添加图片 10：./export\images_Explaining How Quantization Disparately Skews a Model\figure_10_page5.jpeg
2025-11-09 23:20:54,904 - INFO - root - 论文《Explaining How Quantization Disparately Skews a Model》的分析已保存到 ./export\Explaining How Quantization Disparately Skews a Model.md
2025-11-09 23:20:54,909 - INFO - root - 正在总结论文 64/80: LoaQ: Layer-wise Output Approximation Quantization
2025-11-09 23:21:08,393 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 23:21:08,394 - INFO - root - LLMClient: rate limit reached, sleeping 5.3s
2025-11-09 23:22:02,106 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 23:22:39,104 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 23:22:39,106 - INFO - root - 正在提取论文图片...
2025-11-09 23:22:39,122 - INFO - root - 论文《LoaQ: Layer-wise Output Approximation Quantization》的分析已保存到 ./export\LoaQ_ Layer-wise Output Approximation Quantization.md
2025-11-09 23:22:39,135 - INFO - root - 正在总结论文 65/80: FineServe: Precision-Aware KV Slab and Two-Level Scheduling for Heterogeneous Precision LLM Serving
2025-11-09 23:22:56,247 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 23:22:56,248 - INFO - root - LLMClient: rate limit reached, sleeping 5.9s
2025-11-09 23:23:50,246 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 23:24:24,448 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 23:24:24,472 - INFO - root - 正在提取论文图片...
2025-11-09 23:24:25,495 - INFO - root - 已保存图片 1/10：./export\images_FineServe_ Precision-Aware KV Slab and Two-Level Scheduling for Heterogeneous Pr\figure_1_page4.png
2025-11-09 23:24:25,594 - INFO - root - 已保存图片 2/10：./export\images_FineServe_ Precision-Aware KV Slab and Two-Level Scheduling for Heterogeneous Pr\figure_2_page10.png
2025-11-09 23:24:25,656 - INFO - root - 已保存图片 3/10：./export\images_FineServe_ Precision-Aware KV Slab and Two-Level Scheduling for Heterogeneous Pr\figure_3_page4.png
2025-11-09 23:24:25,716 - INFO - root - 已保存图片 4/10：./export\images_FineServe_ Precision-Aware KV Slab and Two-Level Scheduling for Heterogeneous Pr\figure_4_page6.png
2025-11-09 23:24:25,781 - INFO - root - 已保存图片 5/10：./export\images_FineServe_ Precision-Aware KV Slab and Two-Level Scheduling for Heterogeneous Pr\figure_5_page3.png
2025-11-09 23:24:25,839 - INFO - root - 已保存图片 6/10：./export\images_FineServe_ Precision-Aware KV Slab and Two-Level Scheduling for Heterogeneous Pr\figure_6_page3.png
2025-11-09 23:24:25,917 - INFO - root - 已保存图片 7/10：./export\images_FineServe_ Precision-Aware KV Slab and Two-Level Scheduling for Heterogeneous Pr\figure_7_page6.png
2025-11-09 23:24:25,972 - INFO - root - 已保存图片 8/10：./export\images_FineServe_ Precision-Aware KV Slab and Two-Level Scheduling for Heterogeneous Pr\figure_8_page10.png
2025-11-09 23:24:26,029 - INFO - root - 已保存图片 9/10：./export\images_FineServe_ Precision-Aware KV Slab and Two-Level Scheduling for Heterogeneous Pr\figure_9_page10.png
2025-11-09 23:24:26,081 - INFO - root - 已保存图片 10/10：./export\images_FineServe_ Precision-Aware KV Slab and Two-Level Scheduling for Heterogeneous Pr\figure_10_page5.png
2025-11-09 23:24:26,089 - INFO - root - 成功添加图片 1：./export\images_FineServe_ Precision-Aware KV Slab and Two-Level Scheduling for Heterogeneous Pr\figure_1_page4.png
2025-11-09 23:24:26,092 - INFO - root - 成功添加图片 2：./export\images_FineServe_ Precision-Aware KV Slab and Two-Level Scheduling for Heterogeneous Pr\figure_2_page10.png
2025-11-09 23:24:26,092 - INFO - root - 成功添加图片 3：./export\images_FineServe_ Precision-Aware KV Slab and Two-Level Scheduling for Heterogeneous Pr\figure_3_page4.png
2025-11-09 23:24:26,093 - INFO - root - 成功添加图片 4：./export\images_FineServe_ Precision-Aware KV Slab and Two-Level Scheduling for Heterogeneous Pr\figure_4_page6.png
2025-11-09 23:24:26,093 - INFO - root - 成功添加图片 5：./export\images_FineServe_ Precision-Aware KV Slab and Two-Level Scheduling for Heterogeneous Pr\figure_5_page3.png
2025-11-09 23:24:26,094 - INFO - root - 成功添加图片 6：./export\images_FineServe_ Precision-Aware KV Slab and Two-Level Scheduling for Heterogeneous Pr\figure_6_page3.png
2025-11-09 23:24:26,095 - INFO - root - 成功添加图片 7：./export\images_FineServe_ Precision-Aware KV Slab and Two-Level Scheduling for Heterogeneous Pr\figure_7_page6.png
2025-11-09 23:24:26,095 - INFO - root - 成功添加图片 8：./export\images_FineServe_ Precision-Aware KV Slab and Two-Level Scheduling for Heterogeneous Pr\figure_8_page10.png
2025-11-09 23:24:26,097 - INFO - root - 成功添加图片 9：./export\images_FineServe_ Precision-Aware KV Slab and Two-Level Scheduling for Heterogeneous Pr\figure_9_page10.png
2025-11-09 23:24:26,097 - INFO - root - 成功添加图片 10：./export\images_FineServe_ Precision-Aware KV Slab and Two-Level Scheduling for Heterogeneous Pr\figure_10_page5.png
2025-11-09 23:24:26,100 - INFO - root - 论文《FineServe: Precision-Aware KV Slab and Two-Level Scheduling for Heterogeneous Precision LLM Serving》的分析已保存到 ./export\FineServe_ Precision-Aware KV Slab and Two-Level Scheduling for Heterogeneous Pr.md
2025-11-09 23:24:26,114 - INFO - root - 正在总结论文 66/80: Sensitivity-Aware Post-Training Quantization for Deep Neural Networks
2025-11-09 23:24:41,668 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 23:24:41,669 - INFO - root - LLMClient: rate limit reached, sleeping 8.6s
2025-11-09 23:25:42,565 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 23:26:17,991 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 23:26:17,997 - INFO - root - 正在提取论文图片...
2025-11-09 23:26:21,330 - INFO - root - 已保存图片 1/10：./export\images_Sensitivity-Aware Post-Training Quantization for Deep Neural Networks\figure_1_page7.png
2025-11-09 23:26:21,638 - INFO - root - 已保存图片 2/10：./export\images_Sensitivity-Aware Post-Training Quantization for Deep Neural Networks\figure_2_page7.png
2025-11-09 23:26:21,962 - INFO - root - 已保存图片 3/10：./export\images_Sensitivity-Aware Post-Training Quantization for Deep Neural Networks\figure_3_page7.png
2025-11-09 23:26:22,254 - INFO - root - 已保存图片 4/10：./export\images_Sensitivity-Aware Post-Training Quantization for Deep Neural Networks\figure_4_page7.png
2025-11-09 23:26:22,519 - INFO - root - 已保存图片 5/10：./export\images_Sensitivity-Aware Post-Training Quantization for Deep Neural Networks\figure_5_page7.png
2025-11-09 23:26:22,543 - INFO - root - 成功添加图片 1：./export\images_Sensitivity-Aware Post-Training Quantization for Deep Neural Networks\figure_1_page7.png
2025-11-09 23:26:22,544 - INFO - root - 成功添加图片 2：./export\images_Sensitivity-Aware Post-Training Quantization for Deep Neural Networks\figure_2_page7.png
2025-11-09 23:26:22,545 - INFO - root - 成功添加图片 3：./export\images_Sensitivity-Aware Post-Training Quantization for Deep Neural Networks\figure_3_page7.png
2025-11-09 23:26:22,546 - INFO - root - 成功添加图片 4：./export\images_Sensitivity-Aware Post-Training Quantization for Deep Neural Networks\figure_4_page7.png
2025-11-09 23:26:22,547 - INFO - root - 成功添加图片 5：./export\images_Sensitivity-Aware Post-Training Quantization for Deep Neural Networks\figure_5_page7.png
2025-11-09 23:26:22,550 - INFO - root - 论文《Sensitivity-Aware Post-Training Quantization for Deep Neural Networks》的分析已保存到 ./export\Sensitivity-Aware Post-Training Quantization for Deep Neural Networks.md
2025-11-09 23:26:22,554 - INFO - root - 正在总结论文 67/80: SuperSNN: A Hardware-Aware Framework for Physically Realizable, High-Performance Superconducting Spiking Neural Network Chips
2025-11-09 23:26:38,312 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 23:26:38,396 - INFO - root - LLMClient: rate limit reached, sleeping 4.2s
2025-11-09 23:27:32,391 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 23:28:11,018 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 23:28:11,020 - INFO - root - 正在提取论文图片...
2025-11-09 23:28:14,882 - INFO - root - 已保存图片 1/10：./export\images_SuperSNN_ A Hardware-Aware Framework for Physically Realizable, High-Performance\figure_1_page6.png
2025-11-09 23:28:15,180 - INFO - root - 已保存图片 2/10：./export\images_SuperSNN_ A Hardware-Aware Framework for Physically Realizable, High-Performance\figure_2_page9.png
2025-11-09 23:28:15,534 - INFO - root - 已保存图片 3/10：./export\images_SuperSNN_ A Hardware-Aware Framework for Physically Realizable, High-Performance\figure_3_page9.png
2025-11-09 23:28:15,848 - INFO - root - 已保存图片 4/10：./export\images_SuperSNN_ A Hardware-Aware Framework for Physically Realizable, High-Performance\figure_4_page6.png
2025-11-09 23:28:15,963 - INFO - root - 已保存图片 5/10：./export\images_SuperSNN_ A Hardware-Aware Framework for Physically Realizable, High-Performance\figure_5_page7.png
2025-11-09 23:28:16,264 - INFO - root - 已保存图片 6/10：./export\images_SuperSNN_ A Hardware-Aware Framework for Physically Realizable, High-Performance\figure_6_page8.png
2025-11-09 23:28:16,376 - INFO - root - 已保存图片 7/10：./export\images_SuperSNN_ A Hardware-Aware Framework for Physically Realizable, High-Performance\figure_7_page6.png
2025-11-09 23:28:16,583 - INFO - root - 已保存图片 8/10：./export\images_SuperSNN_ A Hardware-Aware Framework for Physically Realizable, High-Performance\figure_8_page6.png
2025-11-09 23:28:16,790 - INFO - root - 已保存图片 9/10：./export\images_SuperSNN_ A Hardware-Aware Framework for Physically Realizable, High-Performance\figure_9_page3.png
2025-11-09 23:28:16,869 - INFO - root - 已保存图片 10/10：./export\images_SuperSNN_ A Hardware-Aware Framework for Physically Realizable, High-Performance\figure_10_page4.png
2025-11-09 23:28:16,888 - INFO - root - 成功添加图片 1：./export\images_SuperSNN_ A Hardware-Aware Framework for Physically Realizable, High-Performance\figure_1_page6.png
2025-11-09 23:28:16,890 - INFO - root - 成功添加图片 2：./export\images_SuperSNN_ A Hardware-Aware Framework for Physically Realizable, High-Performance\figure_2_page9.png
2025-11-09 23:28:16,891 - INFO - root - 成功添加图片 3：./export\images_SuperSNN_ A Hardware-Aware Framework for Physically Realizable, High-Performance\figure_3_page9.png
2025-11-09 23:28:16,891 - INFO - root - 成功添加图片 4：./export\images_SuperSNN_ A Hardware-Aware Framework for Physically Realizable, High-Performance\figure_4_page6.png
2025-11-09 23:28:16,893 - INFO - root - 成功添加图片 5：./export\images_SuperSNN_ A Hardware-Aware Framework for Physically Realizable, High-Performance\figure_5_page7.png
2025-11-09 23:28:16,894 - INFO - root - 成功添加图片 6：./export\images_SuperSNN_ A Hardware-Aware Framework for Physically Realizable, High-Performance\figure_6_page8.png
2025-11-09 23:28:16,894 - INFO - root - 成功添加图片 7：./export\images_SuperSNN_ A Hardware-Aware Framework for Physically Realizable, High-Performance\figure_7_page6.png
2025-11-09 23:28:16,895 - INFO - root - 成功添加图片 8：./export\images_SuperSNN_ A Hardware-Aware Framework for Physically Realizable, High-Performance\figure_8_page6.png
2025-11-09 23:28:16,897 - INFO - root - 成功添加图片 9：./export\images_SuperSNN_ A Hardware-Aware Framework for Physically Realizable, High-Performance\figure_9_page3.png
2025-11-09 23:28:16,898 - INFO - root - 成功添加图片 10：./export\images_SuperSNN_ A Hardware-Aware Framework for Physically Realizable, High-Performance\figure_10_page4.png
2025-11-09 23:28:16,910 - INFO - root - 论文《SuperSNN: A Hardware-Aware Framework for Physically Realizable, High-Performance Superconducting Spiking Neural Network Chips》的分析已保存到 ./export\SuperSNN_ A Hardware-Aware Framework for Physically Realizable, High-Performance.md
2025-11-09 23:28:16,914 - INFO - root - 正在总结论文 68/80: Data-Augmented Quantization-Aware Knowledge Distillation
2025-11-09 23:28:28,395 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 23:28:28,396 - INFO - root - LLMClient: rate limit reached, sleeping 4.0s
2025-11-09 23:29:19,668 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 23:29:52,137 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 23:29:52,139 - INFO - root - 正在提取论文图片...
2025-11-09 23:29:52,416 - INFO - root - 已保存图片 1/10：./export\images_Data-Augmented Quantization-Aware Knowledge Distillation\figure_1_page8.png
2025-11-09 23:29:52,573 - INFO - root - 已保存图片 2/10：./export\images_Data-Augmented Quantization-Aware Knowledge Distillation\figure_2_page8.png
2025-11-09 23:29:52,799 - INFO - root - 已保存图片 3/10：./export\images_Data-Augmented Quantization-Aware Knowledge Distillation\figure_3_page8.png
2025-11-09 23:29:52,800 - INFO - root - 成功添加图片 1：./export\images_Data-Augmented Quantization-Aware Knowledge Distillation\figure_1_page8.png
2025-11-09 23:29:52,800 - INFO - root - 成功添加图片 2：./export\images_Data-Augmented Quantization-Aware Knowledge Distillation\figure_2_page8.png
2025-11-09 23:29:52,800 - INFO - root - 成功添加图片 3：./export\images_Data-Augmented Quantization-Aware Knowledge Distillation\figure_3_page8.png
2025-11-09 23:29:52,808 - INFO - root - 论文《Data-Augmented Quantization-Aware Knowledge Distillation》的分析已保存到 ./export\Data-Augmented Quantization-Aware Knowledge Distillation.md
2025-11-09 23:29:52,816 - INFO - root - 正在总结论文 69/80: DPQuant: Efficient and Differentially-Private Model Training via Dynamic Quantization Scheduling
2025-11-09 23:30:12,010 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 23:30:12,042 - INFO - root - LLMClient: rate limit reached, sleeping 7.6s
2025-11-09 23:31:18,665 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 23:31:53,424 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 23:31:53,430 - INFO - root - 正在提取论文图片...
2025-11-09 23:31:53,474 - INFO - root - 论文《DPQuant: Efficient and Differentially-Private Model Training via Dynamic Quantization Scheduling》的分析已保存到 ./export\DPQuant_ Efficient and Differentially-Private Model Training via Dynamic Quantiz.md
2025-11-09 23:31:53,507 - INFO - root - 正在总结论文 70/80: Empowering Large Language Model for Sequential Recommendation via Multimodal Embeddings and Semantic IDs
2025-11-09 23:32:10,140 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 23:32:10,143 - INFO - root - LLMClient: rate limit reached, sleeping 8.5s
2025-11-09 23:33:17,625 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 23:33:55,497 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 23:33:55,500 - INFO - root - 正在提取论文图片...
2025-11-09 23:33:55,610 - INFO - root - 已保存图片 1/10：./export\images_Empowering Large Language Model for Sequential Recommendation via Multimodal Emb\figure_1_page4.jpeg
2025-11-09 23:33:55,614 - INFO - root - 成功添加图片 1：./export\images_Empowering Large Language Model for Sequential Recommendation via Multimodal Emb\figure_1_page4.jpeg
2025-11-09 23:33:55,623 - INFO - root - 论文《Empowering Large Language Model for Sequential Recommendation via Multimodal Embeddings and Semantic IDs》的分析已保存到 ./export\Empowering Large Language Model for Sequential Recommendation via Multimodal Emb.md
2025-11-09 23:33:55,632 - INFO - root - 正在总结论文 71/80: Q-Sched: Pushing the Boundaries of Few-Step Diffusion Models with Quantization-Aware Scheduling
2025-11-09 23:34:07,099 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 23:34:07,100 - INFO - root - LLMClient: rate limit reached, sleeping 10.5s
2025-11-09 23:35:15,795 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 23:35:44,888 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 23:35:44,891 - INFO - root - 正在提取论文图片...
2025-11-09 23:35:47,552 - INFO - root - 已保存图片 1/10：./export\images_Q-Sched_ Pushing the Boundaries of Few-Step Diffusion Models with Quantization-A\figure_1_page2.png
2025-11-09 23:35:47,751 - INFO - root - 已保存图片 2/10：./export\images_Q-Sched_ Pushing the Boundaries of Few-Step Diffusion Models with Quantization-A\figure_2_page22.jpeg
2025-11-09 23:35:47,920 - INFO - root - 已保存图片 3/10：./export\images_Q-Sched_ Pushing the Boundaries of Few-Step Diffusion Models with Quantization-A\figure_3_page23.jpeg
2025-11-09 23:35:48,431 - INFO - root - 已保存图片 4/10：./export\images_Q-Sched_ Pushing the Boundaries of Few-Step Diffusion Models with Quantization-A\figure_4_page22.jpeg
2025-11-09 23:35:48,967 - INFO - root - 已保存图片 5/10：./export\images_Q-Sched_ Pushing the Boundaries of Few-Step Diffusion Models with Quantization-A\figure_5_page8.png
2025-11-09 23:35:49,277 - INFO - root - 已保存图片 6/10：./export\images_Q-Sched_ Pushing the Boundaries of Few-Step Diffusion Models with Quantization-A\figure_6_page1.png
2025-11-09 23:35:49,459 - INFO - root - 已保存图片 7/10：./export\images_Q-Sched_ Pushing the Boundaries of Few-Step Diffusion Models with Quantization-A\figure_7_page3.png
2025-11-09 23:35:49,587 - INFO - root - 已保存图片 8/10：./export\images_Q-Sched_ Pushing the Boundaries of Few-Step Diffusion Models with Quantization-A\figure_8_page16.png
2025-11-09 23:35:49,756 - INFO - root - 已保存图片 9/10：./export\images_Q-Sched_ Pushing the Boundaries of Few-Step Diffusion Models with Quantization-A\figure_9_page16.png
2025-11-09 23:35:49,897 - INFO - root - 已保存图片 10/10：./export\images_Q-Sched_ Pushing the Boundaries of Few-Step Diffusion Models with Quantization-A\figure_10_page9.png
2025-11-09 23:35:49,923 - INFO - root - 成功添加图片 1：./export\images_Q-Sched_ Pushing the Boundaries of Few-Step Diffusion Models with Quantization-A\figure_1_page2.png
2025-11-09 23:35:49,923 - INFO - root - 成功添加图片 2：./export\images_Q-Sched_ Pushing the Boundaries of Few-Step Diffusion Models with Quantization-A\figure_2_page22.jpeg
2025-11-09 23:35:49,924 - INFO - root - 成功添加图片 3：./export\images_Q-Sched_ Pushing the Boundaries of Few-Step Diffusion Models with Quantization-A\figure_3_page23.jpeg
2025-11-09 23:35:49,926 - INFO - root - 成功添加图片 4：./export\images_Q-Sched_ Pushing the Boundaries of Few-Step Diffusion Models with Quantization-A\figure_4_page22.jpeg
2025-11-09 23:35:49,927 - INFO - root - 成功添加图片 5：./export\images_Q-Sched_ Pushing the Boundaries of Few-Step Diffusion Models with Quantization-A\figure_5_page8.png
2025-11-09 23:35:49,928 - INFO - root - 成功添加图片 6：./export\images_Q-Sched_ Pushing the Boundaries of Few-Step Diffusion Models with Quantization-A\figure_6_page1.png
2025-11-09 23:35:49,929 - INFO - root - 成功添加图片 7：./export\images_Q-Sched_ Pushing the Boundaries of Few-Step Diffusion Models with Quantization-A\figure_7_page3.png
2025-11-09 23:35:49,930 - INFO - root - 成功添加图片 8：./export\images_Q-Sched_ Pushing the Boundaries of Few-Step Diffusion Models with Quantization-A\figure_8_page16.png
2025-11-09 23:35:49,930 - INFO - root - 成功添加图片 9：./export\images_Q-Sched_ Pushing the Boundaries of Few-Step Diffusion Models with Quantization-A\figure_9_page16.png
2025-11-09 23:35:49,930 - INFO - root - 成功添加图片 10：./export\images_Q-Sched_ Pushing the Boundaries of Few-Step Diffusion Models with Quantization-A\figure_10_page9.png
2025-11-09 23:35:49,933 - INFO - root - 论文《Q-Sched: Pushing the Boundaries of Few-Step Diffusion Models with Quantization-Aware Scheduling》的分析已保存到 ./export\Q-Sched_ Pushing the Boundaries of Few-Step Diffusion Models with Quantization-A.md
2025-11-09 23:35:49,944 - INFO - root - 正在总结论文 72/80: Quantization Meets OOD: Generalizable Quantization-aware Training from a Flatness Perspective
2025-11-09 23:36:01,122 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 23:36:01,123 - INFO - root - LLMClient: rate limit reached, sleeping 14.7s
2025-11-09 23:37:09,842 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 23:37:44,192 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 23:37:44,194 - INFO - root - 正在提取论文图片...
2025-11-09 23:37:46,699 - INFO - root - 已保存图片 1/10：./export\images_Quantization Meets OOD_ Generalizable Quantization-aware Training from a Flatnes\figure_1_page8.png
2025-11-09 23:37:46,850 - INFO - root - 已保存图片 2/10：./export\images_Quantization Meets OOD_ Generalizable Quantization-aware Training from a Flatnes\figure_2_page8.png
2025-11-09 23:37:47,029 - INFO - root - 已保存图片 3/10：./export\images_Quantization Meets OOD_ Generalizable Quantization-aware Training from a Flatnes\figure_3_page8.png
2025-11-09 23:37:47,220 - INFO - root - 已保存图片 4/10：./export\images_Quantization Meets OOD_ Generalizable Quantization-aware Training from a Flatnes\figure_4_page8.png
2025-11-09 23:37:47,438 - INFO - root - 已保存图片 5/10：./export\images_Quantization Meets OOD_ Generalizable Quantization-aware Training from a Flatnes\figure_5_page8.png
2025-11-09 23:37:47,621 - INFO - root - 已保存图片 6/10：./export\images_Quantization Meets OOD_ Generalizable Quantization-aware Training from a Flatnes\figure_6_page8.png
2025-11-09 23:37:47,801 - INFO - root - 已保存图片 7/10：./export\images_Quantization Meets OOD_ Generalizable Quantization-aware Training from a Flatnes\figure_7_page8.png
2025-11-09 23:37:47,974 - INFO - root - 已保存图片 8/10：./export\images_Quantization Meets OOD_ Generalizable Quantization-aware Training from a Flatnes\figure_8_page8.png
2025-11-09 23:37:48,067 - INFO - root - 已保存图片 9/10：./export\images_Quantization Meets OOD_ Generalizable Quantization-aware Training from a Flatnes\figure_9_page12.jpeg
2025-11-09 23:37:48,153 - INFO - root - 已保存图片 10/10：./export\images_Quantization Meets OOD_ Generalizable Quantization-aware Training from a Flatnes\figure_10_page12.jpeg
2025-11-09 23:37:48,163 - INFO - root - 成功添加图片 1：./export\images_Quantization Meets OOD_ Generalizable Quantization-aware Training from a Flatnes\figure_1_page8.png
2025-11-09 23:37:48,163 - INFO - root - 成功添加图片 2：./export\images_Quantization Meets OOD_ Generalizable Quantization-aware Training from a Flatnes\figure_2_page8.png
2025-11-09 23:37:48,164 - INFO - root - 成功添加图片 3：./export\images_Quantization Meets OOD_ Generalizable Quantization-aware Training from a Flatnes\figure_3_page8.png
2025-11-09 23:37:48,165 - INFO - root - 成功添加图片 4：./export\images_Quantization Meets OOD_ Generalizable Quantization-aware Training from a Flatnes\figure_4_page8.png
2025-11-09 23:37:48,166 - INFO - root - 成功添加图片 5：./export\images_Quantization Meets OOD_ Generalizable Quantization-aware Training from a Flatnes\figure_5_page8.png
2025-11-09 23:37:48,166 - INFO - root - 成功添加图片 6：./export\images_Quantization Meets OOD_ Generalizable Quantization-aware Training from a Flatnes\figure_6_page8.png
2025-11-09 23:37:48,167 - INFO - root - 成功添加图片 7：./export\images_Quantization Meets OOD_ Generalizable Quantization-aware Training from a Flatnes\figure_7_page8.png
2025-11-09 23:37:48,167 - INFO - root - 成功添加图片 8：./export\images_Quantization Meets OOD_ Generalizable Quantization-aware Training from a Flatnes\figure_8_page8.png
2025-11-09 23:37:48,171 - INFO - root - 成功添加图片 9：./export\images_Quantization Meets OOD_ Generalizable Quantization-aware Training from a Flatnes\figure_9_page12.jpeg
2025-11-09 23:37:48,172 - INFO - root - 成功添加图片 10：./export\images_Quantization Meets OOD_ Generalizable Quantization-aware Training from a Flatnes\figure_10_page12.jpeg
2025-11-09 23:37:48,179 - INFO - root - 论文《Quantization Meets OOD: Generalizable Quantization-aware Training from a Flatness Perspective》的分析已保存到 ./export\Quantization Meets OOD_ Generalizable Quantization-aware Training from a Flatnes.md
2025-11-09 23:37:48,188 - INFO - root - 正在总结论文 73/80: Progressive Element-wise Gradient Estimation for Neural Network Quantization
2025-11-09 23:38:02,142 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 23:38:02,143 - INFO - root - LLMClient: rate limit reached, sleeping 7.7s
2025-11-09 23:39:10,469 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 23:39:44,856 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 23:39:44,857 - INFO - root - 正在提取论文图片...
2025-11-09 23:39:44,875 - INFO - root - 论文《Progressive Element-wise Gradient Estimation for Neural Network Quantization》的分析已保存到 ./export\Progressive Element-wise Gradient Estimation for Neural Network Quantization.md
2025-11-09 23:39:44,883 - INFO - root - 正在总结论文 74/80: End-to-End On-Device Quantization-Aware Training for LLMs at Inference Cost
2025-11-09 23:39:56,861 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 23:39:56,891 - INFO - root - LLMClient: rate limit reached, sleeping 13.6s
2025-11-09 23:41:14,382 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 23:41:50,601 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 23:41:50,605 - INFO - root - 正在提取论文图片...
2025-11-09 23:41:51,306 - INFO - root - 已保存图片 1/10：./export\images_End-to-End On-Device Quantization-Aware Training for LLMs at Inference Cost\figure_1_page6.png
2025-11-09 23:41:51,386 - INFO - root - 已保存图片 2/10：./export\images_End-to-End On-Device Quantization-Aware Training for LLMs at Inference Cost\figure_2_page6.png
2025-11-09 23:41:51,460 - INFO - root - 已保存图片 3/10：./export\images_End-to-End On-Device Quantization-Aware Training for LLMs at Inference Cost\figure_3_page6.png
2025-11-09 23:41:51,542 - INFO - root - 已保存图片 4/10：./export\images_End-to-End On-Device Quantization-Aware Training for LLMs at Inference Cost\figure_4_page6.png
2025-11-09 23:41:51,612 - INFO - root - 已保存图片 5/10：./export\images_End-to-End On-Device Quantization-Aware Training for LLMs at Inference Cost\figure_5_page6.png
2025-11-09 23:41:51,706 - INFO - root - 已保存图片 6/10：./export\images_End-to-End On-Device Quantization-Aware Training for LLMs at Inference Cost\figure_6_page6.png
2025-11-09 23:41:51,808 - INFO - root - 已保存图片 7/10：./export\images_End-to-End On-Device Quantization-Aware Training for LLMs at Inference Cost\figure_7_page6.png
2025-11-09 23:41:51,926 - INFO - root - 已保存图片 8/10：./export\images_End-to-End On-Device Quantization-Aware Training for LLMs at Inference Cost\figure_8_page6.png
2025-11-09 23:41:52,045 - INFO - root - 已保存图片 9/10：./export\images_End-to-End On-Device Quantization-Aware Training for LLMs at Inference Cost\figure_9_page6.png
2025-11-09 23:41:52,209 - INFO - root - 已保存图片 10/10：./export\images_End-to-End On-Device Quantization-Aware Training for LLMs at Inference Cost\figure_10_page6.png
2025-11-09 23:41:52,211 - INFO - root - 成功添加图片 1：./export\images_End-to-End On-Device Quantization-Aware Training for LLMs at Inference Cost\figure_1_page6.png
2025-11-09 23:41:52,212 - INFO - root - 成功添加图片 2：./export\images_End-to-End On-Device Quantization-Aware Training for LLMs at Inference Cost\figure_2_page6.png
2025-11-09 23:41:52,212 - INFO - root - 成功添加图片 3：./export\images_End-to-End On-Device Quantization-Aware Training for LLMs at Inference Cost\figure_3_page6.png
2025-11-09 23:41:52,213 - INFO - root - 成功添加图片 4：./export\images_End-to-End On-Device Quantization-Aware Training for LLMs at Inference Cost\figure_4_page6.png
2025-11-09 23:41:52,214 - INFO - root - 成功添加图片 5：./export\images_End-to-End On-Device Quantization-Aware Training for LLMs at Inference Cost\figure_5_page6.png
2025-11-09 23:41:52,214 - INFO - root - 成功添加图片 6：./export\images_End-to-End On-Device Quantization-Aware Training for LLMs at Inference Cost\figure_6_page6.png
2025-11-09 23:41:52,215 - INFO - root - 成功添加图片 7：./export\images_End-to-End On-Device Quantization-Aware Training for LLMs at Inference Cost\figure_7_page6.png
2025-11-09 23:41:52,215 - INFO - root - 成功添加图片 8：./export\images_End-to-End On-Device Quantization-Aware Training for LLMs at Inference Cost\figure_8_page6.png
2025-11-09 23:41:52,217 - INFO - root - 成功添加图片 9：./export\images_End-to-End On-Device Quantization-Aware Training for LLMs at Inference Cost\figure_9_page6.png
2025-11-09 23:41:52,218 - INFO - root - 成功添加图片 10：./export\images_End-to-End On-Device Quantization-Aware Training for LLMs at Inference Cost\figure_10_page6.png
2025-11-09 23:41:52,224 - INFO - root - 论文《End-to-End On-Device Quantization-Aware Training for LLMs at Inference Cost》的分析已保存到 ./export\End-to-End On-Device Quantization-Aware Training for LLMs at Inference Cost.md
2025-11-09 23:41:52,230 - INFO - root - 正在总结论文 75/80: Quantization Robustness to Input Degradations for Object Detection
2025-11-09 23:42:08,037 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 23:42:08,042 - INFO - root - LLMClient: rate limit reached, sleeping 6.3s
2025-11-09 23:43:10,780 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 23:43:48,038 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 23:43:48,042 - INFO - root - 正在提取论文图片...
2025-11-09 23:43:48,062 - INFO - root - 论文《Quantization Robustness to Input Degradations for Object Detection》的分析已保存到 ./export\Quantization Robustness to Input Degradations for Object Detection.md
2025-11-09 23:43:48,067 - INFO - root - 正在总结论文 76/80: Scaling Laws for Task-Stratified Knowledge in Post-Training Quantized Large Language Models
2025-11-09 23:44:00,197 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 23:44:00,198 - INFO - root - LLMClient: rate limit reached, sleeping 10.6s
2025-11-09 23:45:04,388 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 23:45:37,193 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 23:45:37,195 - INFO - root - 正在提取论文图片...
2025-11-09 23:45:37,610 - INFO - root - 已保存图片 1/10：./export\images_Scaling Laws for Task-Stratified Knowledge in Post-Training Quantized Large Lang\figure_1_page8.png
2025-11-09 23:45:37,611 - INFO - root - 成功添加图片 1：./export\images_Scaling Laws for Task-Stratified Knowledge in Post-Training Quantized Large Lang\figure_1_page8.png
2025-11-09 23:45:37,622 - INFO - root - 论文《Scaling Laws for Task-Stratified Knowledge in Post-Training Quantized Large Language Models》的分析已保存到 ./export\Scaling Laws for Task-Stratified Knowledge in Post-Training Quantized Large Lang.md
2025-11-09 23:45:37,633 - INFO - root - 正在总结论文 77/80: AQ-PCDSys: An Adaptive Quantized Planetary Crater Detection System for Autonomous Space Exploration
2025-11-09 23:45:48,573 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 23:45:48,575 - INFO - root - LLMClient: rate limit reached, sleeping 15.8s
2025-11-09 23:46:55,033 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 23:47:30,402 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 23:47:30,408 - INFO - root - 正在提取论文图片...
2025-11-09 23:47:30,428 - INFO - root - 论文《AQ-PCDSys: An Adaptive Quantized Planetary Crater Detection System for Autonomous Space Exploration》的分析已保存到 ./export\AQ-PCDSys_ An Adaptive Quantized Planetary Crater Detection System for Autonomou.md
2025-11-09 23:47:30,437 - INFO - root - 正在总结论文 78/80: TaDiCodec: Text-aware Diffusion Speech Tokenizer for Speech Language Modeling
2025-11-09 23:47:41,871 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 23:47:41,874 - INFO - root - LLMClient: rate limit reached, sleeping 13.2s
2025-11-09 23:48:48,500 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 23:49:22,358 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 23:49:22,364 - INFO - root - 正在提取论文图片...
2025-11-09 23:49:22,744 - INFO - root - 已保存图片 1/10：./export\images_TaDiCodec_ Text-aware Diffusion Speech Tokenizer for Speech Language Modeling\figure_1_page22.png
2025-11-09 23:49:22,751 - INFO - root - 成功添加图片 1：./export\images_TaDiCodec_ Text-aware Diffusion Speech Tokenizer for Speech Language Modeling\figure_1_page22.png
2025-11-09 23:49:22,754 - INFO - root - 论文《TaDiCodec: Text-aware Diffusion Speech Tokenizer for Speech Language Modeling》的分析已保存到 ./export\TaDiCodec_ Text-aware Diffusion Speech Tokenizer for Speech Language Modeling.md
2025-11-09 23:49:22,764 - INFO - root - 正在总结论文 79/80: A Node-Aware Dynamic Quantization Approach for Graph Collaborative Filtering
2025-11-09 23:49:42,402 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 23:49:42,404 - INFO - root - LLMClient: rate limit reached, sleeping 6.1s
2025-11-09 23:50:45,375 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 23:51:29,547 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 23:51:29,554 - INFO - root - 正在提取论文图片...
2025-11-09 23:51:31,371 - INFO - root - 已保存图片 1/10：./export\images_A Node-Aware Dynamic Quantization Approach for Graph Collaborative Filtering\figure_1_page4.png
2025-11-09 23:51:31,623 - INFO - root - 已保存图片 2/10：./export\images_A Node-Aware Dynamic Quantization Approach for Graph Collaborative Filtering\figure_2_page7.png
2025-11-09 23:51:31,824 - INFO - root - 已保存图片 3/10：./export\images_A Node-Aware Dynamic Quantization Approach for Graph Collaborative Filtering\figure_3_page2.png
2025-11-09 23:51:31,915 - INFO - root - 已保存图片 4/10：./export\images_A Node-Aware Dynamic Quantization Approach for Graph Collaborative Filtering\figure_4_page6.png
2025-11-09 23:51:31,936 - INFO - root - 成功添加图片 1：./export\images_A Node-Aware Dynamic Quantization Approach for Graph Collaborative Filtering\figure_1_page4.png
2025-11-09 23:51:31,940 - INFO - root - 成功添加图片 2：./export\images_A Node-Aware Dynamic Quantization Approach for Graph Collaborative Filtering\figure_2_page7.png
2025-11-09 23:51:31,941 - INFO - root - 成功添加图片 3：./export\images_A Node-Aware Dynamic Quantization Approach for Graph Collaborative Filtering\figure_3_page2.png
2025-11-09 23:51:31,942 - INFO - root - 成功添加图片 4：./export\images_A Node-Aware Dynamic Quantization Approach for Graph Collaborative Filtering\figure_4_page6.png
2025-11-09 23:51:31,955 - INFO - root - 论文《A Node-Aware Dynamic Quantization Approach for Graph Collaborative Filtering》的分析已保存到 ./export\A Node-Aware Dynamic Quantization Approach for Graph Collaborative Filtering.md
2025-11-09 23:51:31,959 - INFO - root - 正在总结论文 80/80: JEDI-linear: Fast and Efficient Graph Neural Networks for Jet Tagging on FPGAs
2025-11-09 23:51:45,016 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 23:51:45,017 - INFO - root - LLMClient: rate limit reached, sleeping 0.4s
2025-11-09 23:52:35,452 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 23:53:04,401 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-09 23:53:04,403 - INFO - root - 正在提取论文图片...
2025-11-09 23:53:04,689 - INFO - root - 已保存图片 1/10：./export\images_JEDI-linear_ Fast and Efficient Graph Neural Networks for Jet Tagging on FPGAs\figure_1_page6.jpeg
2025-11-09 23:53:04,753 - INFO - root - 已保存图片 2/10：./export\images_JEDI-linear_ Fast and Efficient Graph Neural Networks for Jet Tagging on FPGAs\figure_2_page6.jpeg
2025-11-09 23:53:04,809 - INFO - root - 已保存图片 3/10：./export\images_JEDI-linear_ Fast and Efficient Graph Neural Networks for Jet Tagging on FPGAs\figure_3_page7.jpeg
2025-11-09 23:53:04,854 - INFO - root - 已保存图片 4/10：./export\images_JEDI-linear_ Fast and Efficient Graph Neural Networks for Jet Tagging on FPGAs\figure_4_page7.jpeg
2025-11-09 23:53:04,909 - INFO - root - 已保存图片 5/10：./export\images_JEDI-linear_ Fast and Efficient Graph Neural Networks for Jet Tagging on FPGAs\figure_5_page6.jpeg
2025-11-09 23:53:04,952 - INFO - root - 已保存图片 6/10：./export\images_JEDI-linear_ Fast and Efficient Graph Neural Networks for Jet Tagging on FPGAs\figure_6_page2.jpeg
2025-11-09 23:53:05,055 - INFO - root - 已保存图片 7/10：./export\images_JEDI-linear_ Fast and Efficient Graph Neural Networks for Jet Tagging on FPGAs\figure_7_page5.png
2025-11-09 23:53:05,057 - INFO - root - 成功添加图片 1：./export\images_JEDI-linear_ Fast and Efficient Graph Neural Networks for Jet Tagging on FPGAs\figure_1_page6.jpeg
2025-11-09 23:53:05,058 - INFO - root - 成功添加图片 2：./export\images_JEDI-linear_ Fast and Efficient Graph Neural Networks for Jet Tagging on FPGAs\figure_2_page6.jpeg
2025-11-09 23:53:05,058 - INFO - root - 成功添加图片 3：./export\images_JEDI-linear_ Fast and Efficient Graph Neural Networks for Jet Tagging on FPGAs\figure_3_page7.jpeg
2025-11-09 23:53:05,059 - INFO - root - 成功添加图片 4：./export\images_JEDI-linear_ Fast and Efficient Graph Neural Networks for Jet Tagging on FPGAs\figure_4_page7.jpeg
2025-11-09 23:53:05,059 - INFO - root - 成功添加图片 5：./export\images_JEDI-linear_ Fast and Efficient Graph Neural Networks for Jet Tagging on FPGAs\figure_5_page6.jpeg
2025-11-09 23:53:05,059 - INFO - root - 成功添加图片 6：./export\images_JEDI-linear_ Fast and Efficient Graph Neural Networks for Jet Tagging on FPGAs\figure_6_page2.jpeg
2025-11-09 23:53:05,060 - INFO - root - 成功添加图片 7：./export\images_JEDI-linear_ Fast and Efficient Graph Neural Networks for Jet Tagging on FPGAs\figure_7_page5.png
2025-11-09 23:53:05,066 - INFO - root - 论文《JEDI-linear: Fast and Efficient Graph Neural Networks for Jet Tagging on FPGAs》的分析已保存到 ./export\JEDI-linear_ Fast and Efficient Graph Neural Networks for Jet Tagging on FPGAs.md
2025-11-09 23:53:05,077 - INFO - root - summary time: 5370.35 seconds
2025-11-10 22:57:34,877 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-10 22:57:34,885 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-10 22:57:34,906 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-10 22:58:38,105 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-10 22:58:38,107 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-10 22:58:38,109 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-10 22:58:39,202 - INFO - root - LLMClientManager: 指定使用客户端: DeepSeek
2025-11-10 22:58:39,202 - INFO - root - DeepSeekClient: API key found: 9f9e270e-b...
2025-11-10 22:58:39,204 - INFO - root - DeepSeekClient: 使用模式: 火山引擎
2025-11-10 22:58:39,204 - INFO - root - DeepSeekClient: 模型名称: deepseek-v3-1-terminus
2025-11-10 22:58:43,423 - INFO - httpx - HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
2025-11-10 22:58:43,441 - INFO - root - DeepSeekClient: initialized successfully with model deepseek-v3-1-terminus
2025-11-10 22:58:43,442 - INFO - root - LLMClientManager: DeepSeek 客户端初始化成功
2025-11-10 22:58:43,442 - INFO - root - LLMClientManager: switched to DeepSeek client
2025-11-10 22:58:43,443 - INFO - root - 已手动切换到 LLM 客户端: DeepSeek
2025-11-10 22:58:43,443 - INFO - root - 使用 LLM 模型: deepseek-v3-1-terminus
2025-11-10 22:58:43,444 - INFO - root - 可用客户端: ['DeepSeek']
2025-11-10 22:58:43,445 - INFO - root - === 运行配置 ===
2025-11-10 22:58:43,445 - INFO - root - 处理模式: arxiv在线搜索
2025-11-10 22:58:43,446 - INFO - root - 关键词: QAT
2025-11-10 22:58:43,447 - INFO - root - 查询: CVPR 2025
2025-11-10 22:58:43,452 - INFO - root - 排序: None
2025-11-10 22:58:43,457 - INFO - root - 最近天数: 180
2025-11-10 22:58:43,457 - INFO - root - 最大处理数量: 2
2025-11-10 22:58:43,459 - INFO - root - 保存图片: 是
2025-11-10 22:58:43,459 - INFO - root - 输出语言: 中文
2025-11-10 22:58:43,460 - INFO - root - 强制重新处理: 否
2025-11-10 22:58:43,460 - INFO - root - ====================
2025-11-10 22:58:43,460 - INFO - root - 使用 arXiv 搜索模式（通过 chat_arxiv 模块获取）
2025-11-10 22:58:43,461 - INFO - root - Fetching page 1 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50
2025-11-10 22:59:07,882 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-10 22:59:07,883 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-10 22:59:07,885 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-10 22:59:08,759 - INFO - root - LLMClientManager: 指定使用客户端: Gemini
2025-11-10 22:59:09,607 - INFO - root - GeminiClient: trying model models/gemini-2.5-flash
2025-11-10 22:59:13,513 - INFO - root - GeminiClient: initialized model gemini-2.5-flash
2025-11-10 22:59:13,514 - INFO - root - LLMClientManager: Gemini 客户端初始化成功
2025-11-10 22:59:13,514 - INFO - root - LLMClientManager: switched to Gemini client
2025-11-10 22:59:13,514 - INFO - root - 已手动切换到 LLM 客户端: Gemini
2025-11-10 22:59:13,515 - INFO - root - 使用 LLM 模型: gemini-2.5-flash
2025-11-10 22:59:13,515 - INFO - root - 可用客户端: ['Gemini']
2025-11-10 22:59:13,515 - INFO - root - === 运行配置 ===
2025-11-10 22:59:13,516 - INFO - root - 处理模式: arxiv在线搜索
2025-11-10 22:59:13,516 - INFO - root - 关键词: QAT
2025-11-10 22:59:13,516 - INFO - root - 查询: CVPR 2025
2025-11-10 22:59:13,517 - INFO - root - 排序: None
2025-11-10 22:59:13,517 - INFO - root - 最近天数: 180
2025-11-10 22:59:13,517 - INFO - root - 最大处理数量: 2
2025-11-10 22:59:13,518 - INFO - root - 保存图片: 是
2025-11-10 22:59:13,518 - INFO - root - 输出语言: 中文
2025-11-10 22:59:13,518 - INFO - root - 强制重新处理: 否
2025-11-10 22:59:13,518 - INFO - root - ====================
2025-11-10 22:59:13,519 - INFO - root - 使用 arXiv 搜索模式（通过 chat_arxiv 模块获取）
2025-11-10 22:59:13,519 - INFO - root - Fetching page 1 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50
2025-11-10 22:59:21,010 - INFO - root - get_all_titles_from_web 
2025-11-10 22:59:21,011 - INFO - root - Page:0, Index:0, Learning to Seek Evidence: A Verifiable Reasoning Agent with Causal Faithfulness Analysis, https://arxiv.org/pdf/2511.01425, 2025-11-03
2025-11-10 22:59:21,011 - INFO - root - Page:0, Index:1, OmniTrack++: Omnidirectional Multi-Object Tracking by Learning Large-FoV Trajectory Feedback, https://arxiv.org/pdf/2511.00510, 2025-11-01
2025-11-10 22:59:21,011 - INFO - root - Page:0, Index:2, NeuCo-Bench: A Novel Benchmark Framework for Neural Embeddings in Earth Observation, https://arxiv.org/pdf/2510.17914, 2025-10-19
2025-11-10 22:59:21,011 - INFO - root - Page:0, Index:3, NTIRE 2025 Challenge on Low Light Image Enhancement: Methods and Results, https://arxiv.org/pdf/2510.13670, 2025-10-15
2025-11-10 22:59:21,012 - INFO - root - Page:0, Index:4, Class Prototypes based Contrastive Learning for Classifying Multi-Label and Fine-Grained Educational Videos, https://arxiv.org/pdf/2510.11204, 2025-10-13
2025-11-10 22:59:21,012 - INFO - root - Page:0, Index:5, MIMO: A medical vision language model with visual referring multimodal input and pixel grounding multimodal output, https://arxiv.org/pdf/2510.10011, 2025-10-11
2025-11-10 22:59:21,012 - INFO - root - Page:0, Index:6, Vision Language Models: A Survey of 26K Papers, https://arxiv.org/pdf/2510.09586, 2025-10-10
2025-11-10 22:59:21,012 - INFO - root - Page:0, Index:7, DiT-VTON: Diffusion Transformer Framework for Unified Multi-Category Virtual Try-On and Virtual Try-All with Integrated Image Editing, https://arxiv.org/pdf/2510.04797, 2025-10-03
2025-11-10 22:59:21,012 - INFO - root - Page:0, Index:8, PatchVSR: Breaking Video Diffusion Resolution Limits with Patch-wise Video Super-Resolution, https://arxiv.org/pdf/2509.26025, 2025-09-30
2025-11-10 22:59:21,013 - INFO - root - Page:0, Index:9, FreqDebias: Towards Generalizable Deepfake Detection via Consistency-Driven Frequency Debiasing, https://arxiv.org/pdf/2509.22412, 2025-09-26
2025-11-10 22:59:21,013 - INFO - root - Page:0, Index:10, A Mutual Learning Method for Salient Object Detection with intertwined Multi-Supervision--Revised, https://arxiv.org/pdf/2509.21363, 2025-09-21
2025-11-10 22:59:21,013 - INFO - root - Page:0, Index:11, InstructVTON: Optimal Auto-Masking and Natural-Language-Guided Interactive Style Control for Inpainting-Based Virtual Try-On, https://arxiv.org/pdf/2509.20524, 2025-09-24
2025-11-10 22:59:21,013 - INFO - root - Page:0, Index:12, Efficient Encoder-Free Pose Conditioning and Pose Control for Virtual Try-On, https://arxiv.org/pdf/2509.20343, 2025-09-24
2025-11-10 22:59:21,014 - INFO - root - Page:0, Index:13, The Photographer Eye: Teaching Multimodal Large Language Models to Understand Image Aesthetics like Photographers, https://arxiv.org/pdf/2509.18582, 2025-10-22
2025-11-10 22:59:21,014 - INFO - root - Page:0, Index:14, ENSAM: an efficient foundation model for interactive segmentation of 3D medical images, https://arxiv.org/pdf/2509.15874, 2025-09-19
2025-11-10 22:59:21,014 - INFO - root - Page:0, Index:15, DEFT-VTON: Efficient Virtual Try-On with Consistent Generalised H-Transform, https://arxiv.org/pdf/2509.13506, 2025-09-16
2025-11-10 22:59:21,014 - INFO - root - Page:0, Index:16, Weakly and Self-Supervised Class-Agnostic Motion Prediction for Autonomous Driving, https://arxiv.org/pdf/2509.13116, 2025-09-16
2025-11-10 22:59:21,016 - INFO - root - Page:0, Index:17, Domain-Adaptive Pretraining Improves Primate Behavior Recognition, https://arxiv.org/pdf/2509.12193, 2025-09-15
2025-11-10 22:59:21,016 - INFO - root - Page:0, Index:18, The System Description of CPS Team for Track on Driving with Language of CVPR 2024 Autonomous Grand Challenge, https://arxiv.org/pdf/2509.11071, 2025-09-13
2025-11-10 22:59:21,016 - INFO - root - Page:0, Index:19, An HMM-based framework for identity-aware long-term multi-object tracking from sparse and uncertain identification: use case on long-term tracking in livestock, https://arxiv.org/pdf/2509.09962, 2025-09-12
2025-11-10 22:59:21,017 - INFO - root - Page:0, Index:20, InterAct: Advancing Large-Scale Versatile 3D Human-Object Interaction Generation, https://arxiv.org/pdf/2509.09555, 2025-09-11
2025-11-10 22:59:21,022 - INFO - root - Page:0, Index:21, Geospatial Foundational Embedder: Top-1 Winning Solution on EarthVision Embed2Scale Challenge (CVPR 2025), https://arxiv.org/pdf/2509.06993, 2025-09-03
2025-11-10 22:59:21,022 - INFO - root - Page:0, Index:22, 2nd Place Solution for CVPR2024 E2E Challenge: End-to-End Autonomous Driving Using Vision Language Model, https://arxiv.org/pdf/2509.02659, 2025-09-02
2025-11-10 22:59:21,022 - INFO - root - Page:0, Index:23, Unsupervised Training of Vision Transformers with Synthetic Negatives, https://arxiv.org/pdf/2509.02024, 2025-09-02
2025-11-10 22:59:21,023 - INFO - root - Page:0, Index:24, MV-SSM: Multi-View State Space Modeling for 3D Human Pose Estimation, https://arxiv.org/pdf/2509.00649, 2025-08-30
2025-11-10 22:59:21,023 - INFO - root - Page:0, Index:25, CryptoFace: End-to-End Encrypted Face Recognition, https://arxiv.org/pdf/2509.00332, 2025-08-29
2025-11-10 22:59:21,023 - INFO - root - Page:0, Index:26, ControlEchoSynth: Boosting Ejection Fraction Estimation Models via Controlled Video Diffusion, https://arxiv.org/pdf/2508.17631, 2025-08-26
2025-11-10 22:59:21,024 - INFO - root - Page:0, Index:27, Explain Before You Answer: A Survey on Compositional Visual Reasoning, https://arxiv.org/pdf/2508.17298, 2025-08-27
2025-11-10 22:59:21,024 - INFO - root - Page:0, Index:28, Investigating Different Geo Priors for Image Classification, https://arxiv.org/pdf/2508.15946, 2025-08-21
2025-11-10 22:59:21,024 - INFO - root - Page:0, Index:29, Towards Source-Free Machine Unlearning, https://arxiv.org/pdf/2508.15127, 2025-08-20
2025-11-10 22:59:21,024 - INFO - root - Page:0, Index:30, MR6D: Benchmarking 6D Pose Estimation for Mobile Robots, https://arxiv.org/pdf/2508.13775, 2025-08-19
2025-11-10 22:59:21,026 - INFO - root - Page:0, Index:31, Calibrating Biased Distribution in VFM-derived Latent Space via Cross-Domain Geometric Consistency, https://arxiv.org/pdf/2508.13518, 2025-08-19
2025-11-10 22:59:21,026 - INFO - root - Page:0, Index:32, SIS-Challenge: Event-based Spatio-temporal Instance Segmentation Challenge at the CVPR 2025 Event-based Vision Workshop, https://arxiv.org/pdf/2508.12813, 2025-08-18
2025-11-10 22:59:21,026 - INFO - root - Page:0, Index:33, Multi-Level Knowledge Distillation and Dynamic Self-Supervised Learning for Continual Learning, https://arxiv.org/pdf/2508.12692, 2025-08-22
2025-11-10 22:59:21,026 - INFO - root - Page:0, Index:34, Stochastic-based Patch Filtering for Few-Shot Learning, https://arxiv.org/pdf/2508.10066, 2025-08-13
2025-11-10 22:59:21,027 - INFO - root - Page:0, Index:35, Slot Attention-based Feature Filtering for Few-Shot Learning, https://arxiv.org/pdf/2508.09699, 2025-08-13
2025-11-10 22:59:21,027 - INFO - root - Page:0, Index:36, Comparison Reveals Commonality: Customized Image Generation through Contrastive Inversion, https://arxiv.org/pdf/2508.07755, 2025-08-11
2025-11-10 22:59:21,028 - INFO - root - Page:0, Index:37, SLRTP2025 Sign Language Production Challenge: Methodology, Results, and Future Work, https://arxiv.org/pdf/2508.06951, 2025-08-09
2025-11-10 22:59:21,029 - INFO - root - Page:0, Index:38, Exploring Fairness across Fine-Grained Attributes in Large Vision-Language Models, https://arxiv.org/pdf/2508.03079, 2025-08-05
2025-11-10 22:59:21,029 - INFO - root - Page:0, Index:39, Devil is in the Detail: Towards Injecting Fine Details of Image Prompt in Image Generation via Conflict-free Guidance and Stratified Attention, https://arxiv.org/pdf/2508.02004, 2025-08-03
2025-11-10 22:59:21,029 - INFO - root - Page:0, Index:40, IAUNet: Instance-Aware U-Net, https://arxiv.org/pdf/2508.01928, 2025-08-03
2025-11-10 22:59:21,030 - INFO - root - Page:0, Index:41, Gaussian Splatting Feature Fields for Privacy-Preserving Visual Localization, https://arxiv.org/pdf/2507.23569, 2025-08-26
2025-11-10 22:59:21,030 - INFO - root - Page:0, Index:42, From Scan to Action: Leveraging Realistic Scans for Embodied Scene Understanding, https://arxiv.org/pdf/2507.17585, 2025-07-23
2025-11-10 22:59:21,031 - INFO - root - Page:0, Index:43, LEAD: Exploring Logit Space Evolution for Model Selection, https://arxiv.org/pdf/2507.14559, 2025-07-19
2025-11-10 22:59:21,031 - INFO - root - Page:0, Index:44, HeCoFuse: Cross-Modal Complementary V2X Cooperative Perception with Heterogeneous Sensors, https://arxiv.org/pdf/2507.13677, 2025-07-18
2025-11-10 22:59:21,033 - INFO - root - Page:0, Index:45, OmniVec2 -- A Novel Transformer based Network for Large Scale Multimodal and Multitask Learning, https://arxiv.org/pdf/2507.13364, 2025-07-06
2025-11-10 22:59:21,033 - INFO - root - Page:0, Index:46, A Training-Free, Task-Agnostic Framework for Enhancing MLLM Performance on High-Resolution Images, https://arxiv.org/pdf/2507.10202, 2025-07-14
2025-11-10 22:59:21,034 - INFO - root - Page:0, Index:47, Quantum Federated Learning for Multimodal Data: A Modality-Agnostic Approach, https://arxiv.org/pdf/2507.08217, 2025-07-10
2025-11-10 22:59:21,034 - INFO - root - Page:0, Index:48, CuriosAI Submission to the EgoExo4D Proficiency Estimation Challenge 2025, https://arxiv.org/pdf/2507.08022, 2025-07-08
2025-11-10 22:59:21,034 - INFO - root - Page:0, Index:49, Rethinking Query-based Transformer for Continual Image Segmentation, https://arxiv.org/pdf/2507.07831, 2025-07-10
2025-11-10 22:59:21,035 - INFO - root - Fetching page 2 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=50
2025-11-10 22:59:27,771 - INFO - root - get_all_titles_from_web 
2025-11-10 22:59:27,771 - INFO - root - Page:1, Index:0, Scalable and Realistic Virtual Try-on Application for Foundation Makeup with Kubelka-Munk Theory, https://arxiv.org/pdf/2507.07333, 2025-07-09
2025-11-10 22:59:27,771 - INFO - root - Page:1, Index:1, Free on the Fly: Enhancing Flexibility in Test-Time Adaptation with Online EM, https://arxiv.org/pdf/2507.06973, 2025-07-09
2025-11-10 22:59:27,772 - INFO - root - Page:1, Index:2, Adaptive Part Learning for Fine-Grained Generalized Category Discovery: A Plug-and-Play Enhancement, https://arxiv.org/pdf/2507.06928, 2025-07-09
2025-11-10 22:59:27,772 - INFO - root - Page:1, Index:3, Grounded Gesture Generation: Language, Motion, and Space, https://arxiv.org/pdf/2507.04522, 2025-07-06
2025-11-10 22:59:27,772 - INFO - root - Page:1, Index:4, Comprehensive Information Bottleneck for Unveiling Universal Attribution to Interpret Vision Transformers, https://arxiv.org/pdf/2507.04388, 2025-07-06
2025-11-10 22:59:27,772 - INFO - root - Page:1, Index:5, ZERO: Industry-ready Vision Foundation Model with Multi-modal Prompts, https://arxiv.org/pdf/2507.04270, 2025-11-07
2025-11-10 22:59:27,772 - INFO - root - Page:1, Index:6, Beyond Accuracy: Metrics that Uncover What Makes a 'Good' Visual Descriptor, https://arxiv.org/pdf/2507.03542, 2025-07-08
2025-11-10 22:59:27,773 - INFO - root - Page:1, Index:7, ConceptMix++: Leveling the Playing Field in Text-to-Image Benchmarking via Iterative Prompt Optimization, https://arxiv.org/pdf/2507.03275, 2025-07-03
2025-11-10 22:59:27,773 - INFO - root - Page:1, Index:8, APT: Adaptive Personalized Training for Diffusion Models with Limited Data, https://arxiv.org/pdf/2507.02687, 2025-07-03
2025-11-10 22:59:27,773 - INFO - root - Page:1, Index:9, DreamComposer++: Empowering Diffusion Models with Multi-View Conditions for 3D Content Generation, https://arxiv.org/pdf/2507.02299, 2025-07-03
2025-11-10 22:59:27,773 - INFO - root - Page:1, Index:10, Soft Self-labeling and Potts Relaxations for Weakly-Supervised Segmentation, https://arxiv.org/pdf/2507.01721, 2025-07-02
2025-11-10 22:59:27,773 - INFO - root - Page:1, Index:11, Interpolation-Based Event Visual Data Filtering Algorithms, https://arxiv.org/pdf/2507.01557, 2025-07-02
2025-11-10 22:59:27,780 - INFO - root - Page:1, Index:12, AVC-DPO: Aligned Video Captioning via Direct Preference Optimization, https://arxiv.org/pdf/2507.01492, 2025-07-02
2025-11-10 22:59:27,781 - INFO - root - Page:1, Index:13, NN-Former: Rethinking Graph Structure in Neural Architecture Representation, https://arxiv.org/pdf/2507.00880, 2025-07-01
2025-11-10 22:59:27,782 - INFO - root - Page:1, Index:14, Instant Particle Size Distribution Measurement Using CNNs Trained on Synthetic Data, https://arxiv.org/pdf/2507.00822, 2025-07-01
2025-11-10 22:59:27,782 - INFO - root - Page:1, Index:15, Moment Sampling in Video LLMs for Long-Form Video QA, https://arxiv.org/pdf/2507.00033, 2025-06-17
2025-11-10 22:59:27,782 - INFO - root - Page:1, Index:16, Revisiting Audio-Visual Segmentation with Vision-Centric Transformer, https://arxiv.org/pdf/2506.23623, 2025-06-30
2025-11-10 22:59:27,782 - INFO - root - Page:1, Index:17, MTADiffusion: Mask Text Alignment Diffusion Model for Object Inpainting, https://arxiv.org/pdf/2506.23482, 2025-06-29
2025-11-10 22:59:27,783 - INFO - root - Page:1, Index:18, Benchmarking Generalizable Bimanual Manipulation: RoboTwin Dual-Arm Collaboration Challenge at CVPR 2025 MEIS Workshop, https://arxiv.org/pdf/2506.23351, 2025-07-02
2025-11-10 22:59:27,783 - INFO - root - Page:1, Index:19, Prompting without Panic: Attribute-aware, Zero-shot, Test-Time Calibration, https://arxiv.org/pdf/2506.22819, 2025-06-28
2025-11-10 22:59:27,785 - INFO - root - Page:1, Index:20, Analyzing and Fine-Tuning Whisper Models for Multilingual Pilot Speech Transcription in the Cockpit, https://arxiv.org/pdf/2506.21990, 2025-06-27
2025-11-10 22:59:27,786 - INFO - root - Page:1, Index:21, SceneDiffuser++: City-Scale Traffic Simulation via a Generative World Model, https://arxiv.org/pdf/2506.21976, 2025-06-27
2025-11-10 22:59:27,787 - INFO - root - Page:1, Index:22, DIVE: Deep-search Iterative Video Exploration A Technical Report for the CVRR Challenge at CVPR 2025, https://arxiv.org/pdf/2506.21891, 2025-06-27
2025-11-10 22:59:27,787 - INFO - root - Page:1, Index:23, End-to-End RGB-IR Joint Image Compression With Channel-wise Cross-modality Entropy Model, https://arxiv.org/pdf/2506.21851, 2025-06-26
2025-11-10 22:59:27,788 - INFO - root - Page:1, Index:24, Distilling Normalizing Flows, https://arxiv.org/pdf/2506.21003, 2025-06-26
2025-11-10 22:59:27,788 - INFO - root - Page:1, Index:25, Joint attitude estimation and 3D neural reconstruction of non-cooperative space objects, https://arxiv.org/pdf/2506.20638, 2025-06-25
2025-11-10 22:59:27,788 - INFO - root - Page:1, Index:26, Accept More, Reject Less: Reducing up to 19% Unnecessary Desk-Rejections over 11 Years of ICLR Data, https://arxiv.org/pdf/2506.20141, 2025-06-25
2025-11-10 22:59:27,789 - INFO - root - Page:1, Index:27, SceneCrafter: Controllable Multi-View Driving Scene Editing, https://arxiv.org/pdf/2506.19488, 2025-06-24
2025-11-10 22:59:27,789 - INFO - root - Page:1, Index:28, Emergence of Text Readability in Vision Language Models, https://arxiv.org/pdf/2506.19389, 2025-06-24
2025-11-10 22:59:27,789 - INFO - root - Page:1, Index:29, MedErr-CT: A Visual Question Answering Benchmark for Identifying and Correcting Errors in CT Reports, https://arxiv.org/pdf/2506.19217, 2025-06-23
2025-11-10 22:59:27,790 - INFO - root - Page:1, Index:30, RareSpot: Spotting Small and Rare Wildlife in Aerial Imagery with Multi-Scale Consistency and Context-Aware Augmentation, https://arxiv.org/pdf/2506.19087, 2025-06-23
2025-11-10 22:59:27,793 - INFO - root - Page:1, Index:31, Object-aware Sound Source Localization via Audio-Visual Scene Understanding, https://arxiv.org/pdf/2506.18557, 2025-06-23
2025-11-10 22:59:27,794 - INFO - root - Page:1, Index:32, Rethinking Decoder Design: Improving Biomarker Segmentation Using Depth-to-Space Restoration and Residual Linear Attention, https://arxiv.org/pdf/2506.18335, 2025-06-23
2025-11-10 22:59:27,794 - INFO - root - Page:1, Index:33, Relation3D: Enhancing Relation Modeling for Point Cloud Instance Segmentation, https://arxiv.org/pdf/2506.17891, 2025-06-21
2025-11-10 22:59:27,795 - INFO - root - Page:1, Index:34, HIRE: Lightweight High-Resolution Image Feature Enrichment for Multimodal LLMs, https://arxiv.org/pdf/2506.17608, 2025-06-21
2025-11-10 22:59:27,795 - INFO - root - Page:1, Index:35, Spatially-Aware Evaluation of Segmentation Uncertainty, https://arxiv.org/pdf/2506.16589, 2025-06-19
2025-11-10 22:59:27,797 - INFO - root - Page:1, Index:36, Tripartite Weight-Space Ensemble for Few-Shot Class-Incremental Learning, https://arxiv.org/pdf/2506.15720, 2025-06-03
2025-11-10 22:59:27,797 - INFO - root - Page:1, Index:37, PARC: A Quantitative Framework Uncovering the Symmetries within Vision Language Models, https://arxiv.org/pdf/2506.14808, 2025-06-03
2025-11-10 22:59:27,798 - INFO - root - Page:1, Index:38, Self-supervised Representation Learning with Local Aggregation for Image-based Profiling, https://arxiv.org/pdf/2506.14265, 2025-10-27
2025-11-10 22:59:27,798 - INFO - root - Page:1, Index:39, Towards Robust Learning to Optimize with Theoretical Guarantees, https://arxiv.org/pdf/2506.14263, 2025-06-17
2025-11-10 22:59:27,798 - INFO - root - Page:1, Index:40, Hidden Bias in the Machine: Stereotypes in Text-to-Image Models, https://arxiv.org/pdf/2506.13780, 2025-06-09
2025-11-10 22:59:27,798 - INFO - root - Page:1, Index:41, SmartHome-Bench: A Comprehensive Benchmark for Video Anomaly Detection in Smart Homes Using Multi-Modal Large Language Models, https://arxiv.org/pdf/2506.12992, 2025-06-15
2025-11-10 22:59:27,799 - INFO - root - Page:1, Index:42, Generative 4D Scene Gaussian Splatting with Object View-Synthesis Priors, https://arxiv.org/pdf/2506.12716, 2025-06-15
2025-11-10 22:59:27,801 - INFO - root - Page:1, Index:43, DejaVid: Encoder-Agnostic Learned Temporal Matching for Video Classification, https://arxiv.org/pdf/2506.12585, 2025-06-14
2025-11-10 22:59:27,801 - INFO - root - Page:1, Index:44, Pushing the Limits of Safety: A Technical Report on the ATLAS Challenge 2025, https://arxiv.org/pdf/2506.12430, 2025-07-10
2025-11-10 22:59:27,802 - INFO - root - Page:1, Index:45, FIMA-Q: Post-Training Quantization for Vision Transformers by Fisher Information Matrix Approximation, https://arxiv.org/pdf/2506.11543, 2025-06-13
2025-11-10 22:59:27,802 - INFO - root - Page:1, Index:46, Stop learning it all to mitigate visual hallucination, Focus on the hallucination target, https://arxiv.org/pdf/2506.11417, 2025-06-12
2025-11-10 22:59:27,802 - INFO - root - Page:1, Index:47, EfficientQuant: An Efficient Post-Training Quantization for CNN-Transformer Hybrid Models on Edge Devices, https://arxiv.org/pdf/2506.11093, 2025-06-05
2025-11-10 22:59:27,802 - INFO - root - Page:1, Index:48, HalLoc: Token-level Localization of Hallucinations for Vision Language Models, https://arxiv.org/pdf/2506.10286, 2025-06-11
2025-11-10 22:59:27,803 - INFO - root - Page:1, Index:49, DySS: Dynamic Queries and State-Space Learning for Efficient 3D Object Detection from Multi-Camera Videos, https://arxiv.org/pdf/2506.10242, 2025-06-11
2025-11-10 22:59:27,803 - INFO - root - Fetching page 3 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=100
2025-11-10 22:59:35,475 - INFO - root - get_all_titles_from_web 
2025-11-10 22:59:35,475 - INFO - root - Page:2, Index:0, Improving Personalized Search with Regularized Low-Rank Parameter Updates, https://arxiv.org/pdf/2506.10182, 2025-06-11
2025-11-10 22:59:35,475 - INFO - root - Page:2, Index:1, Hearing Hands: Generating Sounds from Physical Interactions in 3D Scenes, https://arxiv.org/pdf/2506.09989, 2025-06-11
2025-11-10 22:59:35,476 - INFO - root - Page:2, Index:2, UniPre3D: Unified Pre-training of 3D Point Cloud Models with Cross-Modal Gaussian Splatting, https://arxiv.org/pdf/2506.09952, 2025-06-11
2025-11-10 22:59:35,476 - INFO - root - Page:2, Index:3, Provoking Multi-modal Few-Shot LVLM via Exploration-Exploitation In-Context Learning, https://arxiv.org/pdf/2506.09473, 2025-06-11
2025-11-10 22:59:35,476 - INFO - root - Page:2, Index:4, Synthetic Human Action Video Data Generation with Pose Transfer, https://arxiv.org/pdf/2506.09411, 2025-06-11
2025-11-10 22:59:35,476 - INFO - root - Page:2, Index:5, ScaleLSD: Scalable Deep Line Segment Detection Streamlined, https://arxiv.org/pdf/2506.09369, 2025-06-10
2025-11-10 22:59:35,476 - INFO - root - Page:2, Index:6, CheckManual: A New Challenge and Benchmark for Manual-based Appliance Manipulation, https://arxiv.org/pdf/2506.09343, 2025-06-10
2025-11-10 22:59:35,476 - INFO - root - Page:2, Index:7, PatchGuard: Adversarially Robust Anomaly Detection and Localization through Vision Transformers and Pseudo Anomalies, https://arxiv.org/pdf/2506.09237, 2025-10-24
2025-11-10 22:59:35,476 - INFO - root - Page:2, Index:8, SILK: Smooth InterpoLation frameworK for motion in-betweening A Simplified Computational Approach, https://arxiv.org/pdf/2506.09075, 2025-06-09
2025-11-10 22:59:35,476 - INFO - root - Page:2, Index:9, BG-HOP: A Bimanual Generative Hand-Object Prior, https://arxiv.org/pdf/2506.09068, 2025-06-08
2025-11-10 22:59:35,476 - INFO - root - Page:2, Index:10, ORIDa: Object-centric Real-world Image Composition Dataset, https://arxiv.org/pdf/2506.08964, 2025-06-10
2025-11-10 22:59:35,478 - INFO - root - Page:2, Index:11, DiscoVLA: Discrepancy Reduction in Vision, Language, and Alignment for Parameter-Efficient Video-Text Retrieval, https://arxiv.org/pdf/2506.08887, 2025-06-10
2025-11-10 22:59:35,478 - INFO - root - Page:2, Index:12, A Comprehensive Study of Decoder-Only LLMs for Text-to-Image Generation, https://arxiv.org/pdf/2506.08210, 2025-06-09
2025-11-10 22:59:35,478 - INFO - root - Page:2, Index:13, Open World Scene Graph Generation using Vision Language Models, https://arxiv.org/pdf/2506.08189, 2025-06-09
2025-11-10 22:59:35,478 - INFO - root - Page:2, Index:14, Aligning Proteins and Language: A Foundation Model for Protein Retrieval, https://arxiv.org/pdf/2506.08023, 2025-05-27
2025-11-10 22:59:35,478 - INFO - root - Page:2, Index:15, UA-Pose: Uncertainty-Aware 6D Object Pose Estimation and Online Object Completion with Partial References, https://arxiv.org/pdf/2506.07996, 2025-06-09
2025-11-10 22:59:35,480 - INFO - root - Page:2, Index:16, Speedy Deformable 3D Gaussian Splatting: Fast Rendering and Compression of Dynamic Scenes, https://arxiv.org/pdf/2506.07917, 2025-06-09
2025-11-10 22:59:35,480 - INFO - root - Page:2, Index:17, GaussianVAE: Adaptive Learning Dynamics of 3D Gaussians for High-Fidelity Super-Resolution, https://arxiv.org/pdf/2506.07897, 2025-06-09
2025-11-10 22:59:35,480 - INFO - root - Page:2, Index:18, Spatio-Temporal State Space Model For Efficient Event-Based Optical Flow, https://arxiv.org/pdf/2506.07878, 2025-06-09
2025-11-10 22:59:35,481 - INFO - root - Page:2, Index:19, FreeGave: 3D Physics Learning from Dynamic Videos by Gaussian Velocity, https://arxiv.org/pdf/2506.07865, 2025-06-09
2025-11-10 22:59:35,483 - INFO - root - Page:2, Index:20, LogoSP: Local-global Grouping of Superpoints for Unsupervised Semantic Segmentation of 3D Point Clouds, https://arxiv.org/pdf/2506.07857, 2025-06-09
2025-11-10 22:59:35,483 - INFO - root - Page:2, Index:21, Difference Inversion: Interpolate and Isolate the Difference with Token Consistency for Image Analogy Generation, https://arxiv.org/pdf/2506.07750, 2025-06-09
2025-11-10 22:59:35,484 - INFO - root - Page:2, Index:22, Synthetic Visual Genome, https://arxiv.org/pdf/2506.07643, 2025-06-09
2025-11-10 22:59:35,485 - INFO - root - Page:2, Index:23, Fractional Collisions: A Framework for Risk Estimation of Counterfactual Conflicts using Autonomous Driving Behavior Simulations, https://arxiv.org/pdf/2506.07540, 2025-06-09
2025-11-10 22:59:35,486 - INFO - root - Page:2, Index:24, Multi-Step Guided Diffusion for Image Restoration on Edge Devices: Toward Lightweight Perception in Embodied AI, https://arxiv.org/pdf/2506.07286, 2025-06-08
2025-11-10 22:59:35,486 - INFO - root - Page:2, Index:25, LLM-Enhanced Rapid-Reflex Async-Reflect Embodied Agent for Real-Time Decision-Making in Dynamically Changing Environments, https://arxiv.org/pdf/2506.07223, 2025-06-08
2025-11-10 22:59:35,487 - INFO - root - Page:2, Index:26, UCOD-DPL: Unsupervised Camouflaged Object Detection via Dynamic Pseudo-label Learning, https://arxiv.org/pdf/2506.07087, 2025-06-08
2025-11-10 22:59:35,490 - INFO - root - Page:2, Index:27, BePo: Leveraging Birds Eye View and Sparse Points for Efficient and Accurate 3D Occupancy Prediction, https://arxiv.org/pdf/2506.07002, 2025-06-08
2025-11-10 22:59:35,490 - INFO - root - Page:2, Index:28, Reading in the Dark with Foveated Event Vision, https://arxiv.org/pdf/2506.06918, 2025-06-07
2025-11-10 22:59:35,492 - INFO - root - Page:2, Index:29, NSD-Imagery: A benchmark dataset for extending fMRI vision decoding methods to mental imagery, https://arxiv.org/pdf/2506.06898, 2025-06-07
2025-11-10 22:59:35,492 - INFO - root - Page:2, Index:30, Continuous-Time SO(3) Forecasting with Savitzky--Golay Neural Controlled Differential Equations, https://arxiv.org/pdf/2506.06780, 2025-06-07
2025-11-10 22:59:35,493 - INFO - root - Page:2, Index:31, Generalized Trajectory Scoring for End-to-end Multimodal Planning, https://arxiv.org/pdf/2506.06664, 2025-06-07
2025-11-10 22:59:35,493 - INFO - root - Page:2, Index:32, EV-LayerSegNet: Self-supervised Motion Segmentation using Event Cameras, https://arxiv.org/pdf/2506.06596, 2025-06-06
2025-11-10 22:59:35,493 - INFO - root - Page:2, Index:33, Vid2Sim: Generalizable, Video-based Reconstruction of Appearance, Geometry and Physics for Mesh-free Simulation, https://arxiv.org/pdf/2506.06440, 2025-06-06
2025-11-10 22:59:35,494 - INFO - root - Page:2, Index:34, FADE: Frequency-Aware Diffusion Model Factorization for Video Editing, https://arxiv.org/pdf/2506.05934, 2025-06-06
2025-11-10 22:59:35,494 - INFO - root - Page:2, Index:35, Unleashing the Potential of Consistency Learning for Detecting and Grounding Multi-Modal Media Manipulation, https://arxiv.org/pdf/2506.05890, 2025-06-06
2025-11-10 22:59:35,494 - INFO - root - Page:2, Index:36, DeformCL: Learning Deformable Centerline Representation for Vessel Extraction in 3D Medical Image, https://arxiv.org/pdf/2506.05820, 2025-06-06
2025-11-10 22:59:35,496 - INFO - root - Page:2, Index:37, NTIRE 2025 Challenge on HR Depth from Images of Specular and Transparent Surfaces, https://arxiv.org/pdf/2506.05815, 2025-06-06
2025-11-10 22:59:35,496 - INFO - root - Page:2, Index:38, GazeNLQ @ Ego4D Natural Language Queries Challenge 2025, https://arxiv.org/pdf/2506.05782, 2025-06-06
2025-11-10 22:59:35,497 - INFO - root - Page:2, Index:39, Robust sensor fusion against on-vehicle sensor staleness, https://arxiv.org/pdf/2506.05780, 2025-06-06
2025-11-10 22:59:35,497 - INFO - root - Page:2, Index:40, Where Is The Ball: 3D Ball Trajectory Estimation From 2D Monocular Tracking, https://arxiv.org/pdf/2506.05763, 2025-06-06
2025-11-10 22:59:35,498 - INFO - root - Page:2, Index:41, VoxelSplat: Dynamic Gaussian Splatting as an Effective Loss for Occupancy and Flow Prediction, https://arxiv.org/pdf/2506.05563, 2025-06-05
2025-11-10 22:59:35,498 - INFO - root - Page:2, Index:42, Gen4D: Synthesizing Humans and Scenes in the Wild, https://arxiv.org/pdf/2506.05397, 2025-06-03
2025-11-10 22:59:35,499 - INFO - root - Page:2, Index:43, Attacking Attention of Foundation Models Disrupts Downstream Tasks, https://arxiv.org/pdf/2506.05394, 2025-09-12
2025-11-10 22:59:35,501 - INFO - root - Page:2, Index:44, FreeTimeGS: Free Gaussian Primitives at Anytime and Anywhere for Dynamic Scene Reconstruction, https://arxiv.org/pdf/2506.05348, 2025-06-06
2025-11-10 22:59:35,506 - INFO - root - Page:2, Index:45, LotusFilter: Fast Diverse Nearest Neighbor Search via a Learned Cutoff Table, https://arxiv.org/pdf/2506.04790, 2025-06-05
2025-11-10 22:59:35,506 - INFO - root - Page:2, Index:46, Towards Holistic Visual Quality Assessment of AI-Generated Videos: A LLM-Based Multi-Dimensional Evaluation Model, https://arxiv.org/pdf/2506.04715, 2025-06-11
2025-11-10 22:59:35,507 - INFO - root - Page:2, Index:47, Gradient Inversion Attacks on Parameter-Efficient Fine-Tuning, https://arxiv.org/pdf/2506.04453, 2025-06-04
2025-11-10 22:59:35,507 - INFO - root - Page:2, Index:48, HMAR: Efficient Hierarchical Masked Auto-Regressive Image Generation, https://arxiv.org/pdf/2506.04421, 2025-06-04
2025-11-10 22:59:35,509 - INFO - root - Page:2, Index:49, Visualizing and Controlling Cortical Responses Using Voxel-Weighted Activation Maximization, https://arxiv.org/pdf/2506.04379, 2025-06-04
2025-11-10 22:59:35,510 - INFO - root - Fetching page 4 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=150
2025-11-10 22:59:41,782 - INFO - root - get_all_titles_from_web 
2025-11-10 22:59:41,782 - INFO - root - Page:3, Index:0, FlexGS: Train Once, Deploy Everywhere with Many-in-One Flexible 3D Gaussian Splatting, https://arxiv.org/pdf/2506.04174, 2025-06-04
2025-11-10 22:59:41,783 - INFO - root - Page:3, Index:1, Multi-view Surface Reconstruction Using Normal and Reflectance Cues, https://arxiv.org/pdf/2506.04115, 2025-06-04
2025-11-10 22:59:41,783 - INFO - root - Page:3, Index:2, Vocabulary-free few-shot learning for Vision-Language Models, https://arxiv.org/pdf/2506.04005, 2025-06-04
2025-11-10 22:59:41,783 - INFO - root - Page:3, Index:3, Learning from Noise: Enhancing DNNs for Event-Based Vision through Controlled Noise Injection, https://arxiv.org/pdf/2506.03918, 2025-06-04
2025-11-10 22:59:41,784 - INFO - root - Page:3, Index:4, Video, How Do Your Tokens Merge?, https://arxiv.org/pdf/2506.03885, 2025-06-04
2025-11-10 22:59:41,784 - INFO - root - Page:3, Index:5, OSGNet @ Ego4D Episodic Memory Challenge 2025, https://arxiv.org/pdf/2506.03710, 2025-06-04
2025-11-10 22:59:41,784 - INFO - root - Page:3, Index:6, AetherVision-Bench: An Open-Vocabulary RGB-Infrared Benchmark for Multi-Angle Segmentation across Aerial and Ground Perspectives, https://arxiv.org/pdf/2506.03709, 2025-06-04
2025-11-10 22:59:41,785 - INFO - root - Page:3, Index:7, OV-COAST: Cost Aggregation with Optimal Transport for Open-Vocabulary Semantic Segmentation, https://arxiv.org/pdf/2506.03706, 2025-06-04
2025-11-10 22:59:41,785 - INFO - root - Page:3, Index:8, Generating 6DoF Object Manipulation Trajectories from Action Description in Egocentric Vision, https://arxiv.org/pdf/2506.03605, 2025-06-04
2025-11-10 22:59:41,785 - INFO - root - Page:3, Index:9, SemNav: A Model-Based Planner for Zero-Shot Object Goal Navigation Using Vision-Foundation Models, https://arxiv.org/pdf/2506.03516, 2025-06-03
2025-11-10 22:59:41,785 - INFO - root - Page:3, Index:10, Heterogeneous Skeleton-Based Action Representation Learning, https://arxiv.org/pdf/2506.03481, 2025-06-03
2025-11-10 22:59:41,787 - INFO - root - Page:3, Index:11, Hybrid Ensemble of Segmentation-Assisted Classification and GBDT for Skin Cancer Detection with Engineered Metadata and Synthetic Lesions from ISIC 2024 Non-Dermoscopic 3D-TBP Images, https://arxiv.org/pdf/2506.03420, 2025-06-03
2025-11-10 22:59:41,787 - INFO - root - Page:3, Index:12, Self-Supervised Spatial Correspondence Across Modalities, https://arxiv.org/pdf/2506.03148, 2025-06-03
2025-11-10 22:59:41,788 - INFO - root - Page:3, Index:13, Dense Match Summarization for Faster Two-view Estimation, https://arxiv.org/pdf/2506.02893, 2025-06-03
2025-11-10 22:59:41,789 - INFO - root - Page:3, Index:14, NTIRE 2025 XGC Quality Assessment Challenge: Methods and Results, https://arxiv.org/pdf/2506.02875, 2025-06-03
2025-11-10 22:59:41,789 - INFO - root - Page:3, Index:15, FreeScene: Mixed Graph Diffusion for 3D Scene Synthesis from Free Prompts, https://arxiv.org/pdf/2506.02781, 2025-06-03
2025-11-10 22:59:41,790 - INFO - root - Page:3, Index:16, Technical Report for Ego4D Long-Term Action Anticipation Challenge 2025, https://arxiv.org/pdf/2506.02550, 2025-06-11
2025-11-10 22:59:41,790 - INFO - root - Page:3, Index:17, Probabilistic Online Event Downsampling, https://arxiv.org/pdf/2506.02547, 2025-09-23
2025-11-10 22:59:41,790 - INFO - root - Page:3, Index:18, Towards In-the-wild 3D Plane Reconstruction from a Single Image, https://arxiv.org/pdf/2506.02493, 2025-06-03
2025-11-10 22:59:41,791 - INFO - root - Page:3, Index:19, Efficient Test-time Adaptive Object Detection via Sensitivity-Guided Pruning, https://arxiv.org/pdf/2506.02462, 2025-06-03
2025-11-10 22:59:41,791 - INFO - root - Page:3, Index:20, EgoVIS@CVPR: PAIR-Net: Enhancing Egocentric Speaker Detection via Pretrained Audio-Visual Fusion and Alignment Loss, https://arxiv.org/pdf/2506.02247, 2025-09-26
2025-11-10 22:59:41,793 - INFO - root - Page:3, Index:21, Diff2Flow: Training Flow Matching Models via Diffusion Model Alignment, https://arxiv.org/pdf/2506.02221, 2025-06-02
2025-11-10 22:59:41,793 - INFO - root - Page:3, Index:22, NTIRE 2025 Challenge on RAW Image Restoration and Super-Resolution, https://arxiv.org/pdf/2506.02197, 2025-06-04
2025-11-10 22:59:41,793 - INFO - root - Page:3, Index:23, RAW Image Reconstruction from RGB on Smartphones. NTIRE 2025 Challenge Report, https://arxiv.org/pdf/2506.01947, 2025-06-02
2025-11-10 22:59:41,795 - INFO - root - Page:3, Index:24, Silence is Golden: Leveraging Adversarial Examples to Nullify Audio Control in LDM-based Talking-Head Generation, https://arxiv.org/pdf/2506.01591, 2025-06-02
2025-11-10 22:59:41,796 - INFO - root - Page:3, Index:25, SAM2-LOVE: Segment Anything Model 2 in Language-aided Audio-Visual Scenes, https://arxiv.org/pdf/2506.01558, 2025-06-02
2025-11-10 22:59:41,796 - INFO - root - Page:3, Index:26, Neural shape reconstruction from multiple views with static pattern projection, https://arxiv.org/pdf/2506.01389, 2025-06-02
2025-11-10 22:59:41,797 - INFO - root - Page:3, Index:27, SAM-I2V: Upgrading SAM to Support Promptable Video Segmentation with Less than 0.2% Training Cost, https://arxiv.org/pdf/2506.01304, 2025-06-02
2025-11-10 22:59:41,797 - INFO - root - Page:3, Index:28, Perceptual Inductive Bias Is What You Need Before Contrastive Learning, https://arxiv.org/pdf/2506.01201, 2025-06-01
2025-11-10 22:59:41,798 - INFO - root - Page:3, Index:29, Test Automation for Interactive Scenarios via Promptable Traffic Simulation, https://arxiv.org/pdf/2506.01199, 2025-06-04
2025-11-10 22:59:41,798 - INFO - root - Page:3, Index:30, GraphPad: Inference-Time 3D Scene Graph Updates for Embodied Question Answering, https://arxiv.org/pdf/2506.01174, 2025-06-01
2025-11-10 22:59:41,799 - INFO - root - Page:3, Index:31, Aligned Contrastive Loss for Long-Tailed Recognition, https://arxiv.org/pdf/2506.01071, 2025-06-01
2025-11-10 22:59:41,799 - INFO - root - Page:3, Index:32, Self-supervised ControlNet with Spatio-Temporal Mamba for Real-world Video Super-resolution, https://arxiv.org/pdf/2506.01037, 2025-06-01
2025-11-10 22:59:41,799 - INFO - root - Page:3, Index:33, ArtiScene: Language-Driven Artistic 3D Scene Generation Through Image Intermediary, https://arxiv.org/pdf/2506.00742, 2025-05-31
2025-11-10 22:59:41,799 - INFO - root - Page:3, Index:34, 3D Gaussian Splat Vulnerabilities, https://arxiv.org/pdf/2506.00280, 2025-05-30
2025-11-10 22:59:41,799 - INFO - root - Page:3, Index:35, EgoVIS@CVPR: What Changed and What Could Have Changed? State-Change Counterfactuals for Procedure-Aware Video Representation Learning, https://arxiv.org/pdf/2506.00101, 2025-09-26
2025-11-10 22:59:41,800 - INFO - root - Page:3, Index:36, CL-LoRA: Continual Low-Rank Adaptation for Rehearsal-Free Class-Incremental Learning, https://arxiv.org/pdf/2505.24816, 2025-05-30
2025-11-10 22:59:41,800 - INFO - root - Page:3, Index:37, PatchDEMUX: A Certifiably Robust Framework for Multi-label Classifiers Against Adversarial Patches, https://arxiv.org/pdf/2505.24703, 2025-05-30
2025-11-10 22:59:41,800 - INFO - root - Page:3, Index:38, Conformal Prediction for Zero-Shot Models, https://arxiv.org/pdf/2505.24693, 2025-05-30
2025-11-10 22:59:41,800 - INFO - root - Page:3, Index:39, Learning reusable concepts across different egocentric video understanding tasks, https://arxiv.org/pdf/2505.24690, 2025-05-30
2025-11-10 22:59:41,801 - INFO - root - Page:3, Index:40, Period-LLM: Extending the Periodic Capability of Multimodal Large Language Model, https://arxiv.org/pdf/2505.24476, 2025-05-30
2025-11-10 22:59:41,801 - INFO - root - Page:3, Index:41, PCIE_Interaction Solution for Ego4D Social Interaction Challenge, https://arxiv.org/pdf/2505.24404, 2025-05-30
2025-11-10 22:59:41,801 - INFO - root - Page:3, Index:42, Leadership Assessment in Pediatric Intensive Care Unit Team Training, https://arxiv.org/pdf/2505.24389, 2025-08-28
2025-11-10 22:59:41,801 - INFO - root - Page:3, Index:43, Interpreting Large Text-to-Image Diffusion Models with Dictionary Learning, https://arxiv.org/pdf/2505.24360, 2025-07-10
2025-11-10 22:59:41,801 - INFO - root - Page:3, Index:44, InteractAnything: Zero-shot Human Object Interaction Synthesis via LLM Feedback and Object Affordance Parsing, https://arxiv.org/pdf/2505.24315, 2025-05-30
2025-11-10 22:59:41,803 - INFO - root - Page:3, Index:45, MaskAdapt: Unsupervised Geometry-Aware Domain Adaptation Using Multimodal Contextual Learning and RGB-Depth Masking, https://arxiv.org/pdf/2505.24026, 2025-05-29
2025-11-10 22:59:41,803 - INFO - root - Page:3, Index:46, Argus: Vision-Centric Reasoning with Grounded Chain-of-Thought, https://arxiv.org/pdf/2505.23766, 2025-05-29
2025-11-10 22:59:41,803 - INFO - root - Page:3, Index:47, Sketch Down the FLOPs: Towards Efficient Networks for Human Sketch, https://arxiv.org/pdf/2505.23763, 2025-05-29
2025-11-10 22:59:41,804 - INFO - root - Page:3, Index:48, Boosting Domain Incremental Learning: Selecting the Optimal Parameters is All You Need, https://arxiv.org/pdf/2505.23744, 2025-05-29
2025-11-10 22:59:41,805 - INFO - root - Page:3, Index:49, DA-VPT: Semantic-Guided Visual Prompt Tuning for Vision Transformers, https://arxiv.org/pdf/2505.23694, 2025-06-01
2025-11-10 22:59:41,806 - INFO - root - Fetching page 5 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=200
2025-11-10 22:59:48,236 - INFO - root - get_all_titles_from_web 
2025-11-10 22:59:48,236 - INFO - root - Page:4, Index:0, Bridging Classical and Modern Computer Vision: PerceptiveNet for Tree Crown Semantic Segmentation, https://arxiv.org/pdf/2505.23597, 2025-05-29
2025-11-10 22:59:48,237 - INFO - root - Page:4, Index:1, Synthetic Generation and Latent Projection Denoising of Rim Lesions in Multiple Sclerosis, https://arxiv.org/pdf/2505.23353, 2025-05-29
2025-11-10 22:59:48,237 - INFO - root - Page:4, Index:2, Wav2Sem: Plug-and-Play Audio Semantic Decoupling for 3D Speech-Driven Facial Animation, https://arxiv.org/pdf/2505.23290, 2025-05-29
2025-11-10 22:59:48,237 - INFO - root - Page:4, Index:3, Proximal Algorithm Unrolling: Flexible and Efficient Reconstruction Networks for Single-Pixel Imaging, https://arxiv.org/pdf/2505.23180, 2025-05-29
2025-11-10 22:59:48,237 - INFO - root - Page:4, Index:4, HMAD: Advancing E2E Driving with Anchored Offset Proposals and Simulation-Supervised Multi-target Scoring, https://arxiv.org/pdf/2505.23129, 2025-05-29
2025-11-10 22:59:48,238 - INFO - root - Page:4, Index:5, URWKV: Unified RWKV Model with Multi-state Perspective for Low-light Image Restoration, https://arxiv.org/pdf/2505.23068, 2025-05-29
2025-11-10 22:59:48,238 - INFO - root - Page:4, Index:6, 4DTAM: Non-Rigid Tracking and Mapping via Dynamic Surface Gaussians, https://arxiv.org/pdf/2505.22859, 2025-05-28
2025-11-10 22:59:48,239 - INFO - root - Page:4, Index:7, A Probabilistic Jump-Diffusion Framework for Open-World Egocentric Activity Recognition, https://arxiv.org/pdf/2505.22858, 2025-05-28
2025-11-10 22:59:48,239 - INFO - root - Page:4, Index:8, PS4PRO: Pixel-to-pixel Supervision for Photorealistic Rendering and Optimization, https://arxiv.org/pdf/2505.22616, 2025-05-28
2025-11-10 22:59:48,239 - INFO - root - Page:4, Index:9, Universal Domain Adaptation for Semantic Segmentation, https://arxiv.org/pdf/2505.22458, 2025-06-05
2025-11-10 22:59:48,239 - INFO - root - Page:4, Index:10, Zero-Shot 3D Visual Grounding from Vision-Language Models, https://arxiv.org/pdf/2505.22429, 2025-05-28
2025-11-10 22:59:48,239 - INFO - root - Page:4, Index:11, RC-AutoCalib: An End-to-End Radar-Camera Automatic Calibration Network, https://arxiv.org/pdf/2505.22427, 2025-05-28
2025-11-10 22:59:48,240 - INFO - root - Page:4, Index:12, Bringing CLIP to the Clinic: Dynamic Soft Labels and Negation-Aware Learning for Medical Analysis, https://arxiv.org/pdf/2505.22079, 2025-05-28
2025-11-10 22:59:48,240 - INFO - root - Page:4, Index:13, Point-to-Region Loss for Semi-Supervised Point-Based Crowd Counting, https://arxiv.org/pdf/2505.21943, 2025-05-27
2025-11-10 22:59:48,240 - INFO - root - Page:4, Index:14, FRAMES-VQA: Benchmarking Fine-Tuning Robustness across Multi-Modal Shifts in Visual Question Answering, https://arxiv.org/pdf/2505.21755, 2025-06-20
2025-11-10 22:59:48,242 - INFO - root - Page:4, Index:15, Knowledge Distillation Approach for SOS Fusion Staging: Towards Fully Automated Skeletal Maturity Assessment, https://arxiv.org/pdf/2505.21561, 2025-05-26
2025-11-10 22:59:48,242 - INFO - root - Page:4, Index:16, Enhancing Vision Transformer Explainability Using Artificial Astrocytes, https://arxiv.org/pdf/2505.21513, 2025-05-20
2025-11-10 22:59:48,242 - INFO - root - Page:4, Index:17, Empowering Vector Graphics with Consistently Arbitrary Viewing and View-dependent Visibility, https://arxiv.org/pdf/2505.21377, 2025-05-27
2025-11-10 22:59:48,242 - INFO - root - Page:4, Index:18, Structure from Collision, https://arxiv.org/pdf/2505.21335, 2025-05-27
2025-11-10 22:59:48,242 - INFO - root - Page:4, Index:19, Boosting Adversarial Transferability via High-Frequency Augmentation and Hierarchical-Gradient Fusion, https://arxiv.org/pdf/2505.21181, 2025-05-27
2025-11-10 22:59:48,243 - INFO - root - Page:4, Index:20, RefAV: Towards Planning-Centric Scenario Mining, https://arxiv.org/pdf/2505.20981, 2025-06-18
2025-11-10 22:59:48,243 - INFO - root - Page:4, Index:21, PMA: Towards Parameter-Efficient Point Cloud Understanding via Point Mamba Adapter, https://arxiv.org/pdf/2505.20941, 2025-05-27
2025-11-10 22:59:48,243 - INFO - root - Page:4, Index:22, HuMoCon: Concept Discovery for Human Motion Understanding, https://arxiv.org/pdf/2505.20920, 2025-05-27
2025-11-10 22:59:48,245 - INFO - root - Page:4, Index:23, Exploring Timeline Control for Facial Motion Generation, https://arxiv.org/pdf/2505.20861, 2025-05-27
2025-11-10 22:59:48,246 - INFO - root - Page:4, Index:24, ConText-CIR: Learning from Concepts in Text for Composed Image Retrieval, https://arxiv.org/pdf/2505.20764, 2025-05-27
2025-11-10 22:59:48,246 - INFO - root - Page:4, Index:25, HCQA-1.5 @ Ego4D EgoSchema Challenge 2025, https://arxiv.org/pdf/2505.20644, 2025-05-26
2025-11-10 22:59:48,249 - INFO - root - Page:4, Index:26, Roboflow100-VL: A Multi-Domain Object Detection Benchmark for Vision-Language Models, https://arxiv.org/pdf/2505.20612, 2025-10-22
2025-11-10 22:59:48,249 - INFO - root - Page:4, Index:27, MotionPro: A Precise Motion Controller for Image-to-Video Generation, https://arxiv.org/pdf/2505.20287, 2025-05-26
2025-11-10 22:59:48,250 - INFO - root - Page:4, Index:28, Category-Agnostic Neural Object Rigging, https://arxiv.org/pdf/2505.20283, 2025-05-26
2025-11-10 22:59:48,251 - INFO - root - Page:4, Index:29, Towards Video to Piano Music Generation with Chain-of-Perform Support Benchmarks, https://arxiv.org/pdf/2505.20038, 2025-05-26
2025-11-10 22:59:48,252 - INFO - root - Page:4, Index:30, Can Visual Encoder Learn to See Arrows?, https://arxiv.org/pdf/2505.19944, 2025-05-26
2025-11-10 22:59:48,252 - INFO - root - Page:4, Index:31, GoLF-NRT: Integrating Global Context and Local Geometry for Few-Shot View Synthesis, https://arxiv.org/pdf/2505.19813, 2025-05-26
2025-11-10 22:59:48,261 - INFO - root - Page:4, Index:32, Depth-Guided Bundle Sampling for Efficient Generalizable Neural Radiance Field Reconstruction, https://arxiv.org/pdf/2505.19793, 2025-05-26
2025-11-10 22:59:48,265 - INFO - root - Page:4, Index:33, SuperAD: A Training-free Anomaly Classification and Segmentation Method for CVPR 2025 VAND 3.0 Workshop Challenge Track 1: Adapt & Detect, https://arxiv.org/pdf/2505.19750, 2025-05-27
2025-11-10 22:59:48,268 - INFO - root - Page:4, Index:34, Knowledge-Aligned Counterfactual-Enhancement Diffusion Perception for Unsupervised Cross-Domain Visual Emotion Recognition, https://arxiv.org/pdf/2505.19694, 2025-05-26
2025-11-10 22:59:48,269 - INFO - root - Page:4, Index:35, Rotation-Equivariant Self-Supervised Method in Image Denoising, https://arxiv.org/pdf/2505.19618, 2025-05-26
2025-11-10 22:59:48,271 - INFO - root - Page:4, Index:36, NTIRE 2025 Challenge on Video Quality Enhancement for Video Conferencing: Datasets, Methods and Results, https://arxiv.org/pdf/2505.18988, 2025-05-25
2025-11-10 22:59:48,272 - INFO - root - Page:4, Index:37, Geometry-guided Online 3D Video Synthesis with Multi-View Temporal Consistency, https://arxiv.org/pdf/2505.18932, 2025-05-24
2025-11-10 22:59:48,276 - INFO - root - Page:4, Index:38, Digital Overconsumption and Waste: A Closer Look at the Impacts of Generative AI, https://arxiv.org/pdf/2505.18894, 2025-05-24
2025-11-10 22:59:48,276 - INFO - root - Page:4, Index:39, VISTA: Vision-Language Inference for Training-Free Stock Time-Series Analysis, https://arxiv.org/pdf/2505.18570, 2025-06-11
2025-11-10 22:59:48,277 - INFO - root - Page:4, Index:40, Syn3DTxt: Embedding 3D Cues for Scene Text Generation, https://arxiv.org/pdf/2505.18479, 2025-05-23
2025-11-10 22:59:48,286 - INFO - root - Page:4, Index:41, CTRL-GS: Cascaded Temporal Residue Learning for 4D Gaussian Splatting, https://arxiv.org/pdf/2505.18306, 2025-05-31
2025-11-10 22:59:48,287 - INFO - root - Page:4, Index:42, DualTalk: Dual-Speaker Interaction for 3D Talking Head Conversations, https://arxiv.org/pdf/2505.18096, 2025-05-26
2025-11-10 22:59:48,287 - INFO - root - Page:4, Index:43, SeaLion: Semantic Part-Aware Latent Point Diffusion Models for 3D Generation, https://arxiv.org/pdf/2505.17721, 2025-07-07
2025-11-10 22:59:48,288 - INFO - root - Page:4, Index:44, PoseBH: Prototypical Multi-Dataset Training Beyond Human Pose Estimation, https://arxiv.org/pdf/2505.17475, 2025-05-23
2025-11-10 22:59:48,288 - INFO - root - Page:4, Index:45, Pursuing Temporal-Consistent Video Virtual Try-On via Dynamic Pose Interaction, https://arxiv.org/pdf/2505.16980, 2025-05-22
2025-11-10 22:59:48,288 - INFO - root - Page:4, Index:46, UniPhy: Learning a Unified Constitutive Model for Inverse Physics Simulation, https://arxiv.org/pdf/2505.16971, 2025-05-22
2025-11-10 22:59:48,289 - INFO - root - Page:4, Index:47, Tracking the Flight: Exploring a Computational Framework for Analyzing Escape Responses in Plains Zebra (Equus quagga), https://arxiv.org/pdf/2505.16882, 2025-05-23
2025-11-10 22:59:48,291 - INFO - root - Page:4, Index:48, Semi-Supervised State-Space Model with Dynamic Stacking Filter for Real-World Video Deraining, https://arxiv.org/pdf/2505.16811, 2025-05-22
2025-11-10 22:59:48,292 - INFO - root - Page:4, Index:49, SOLVE: Synergy of Language-Vision and End-to-End Networks for Autonomous Driving, https://arxiv.org/pdf/2505.16805, 2025-05-22
2025-11-10 22:59:48,293 - INFO - root - Fetching page 6 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=250
2025-11-10 22:59:55,061 - INFO - root - get_all_titles_from_web 
2025-11-10 22:59:55,061 - INFO - root - Page:5, Index:0, Four Eyes Are Better Than Two: Harnessing the Collaborative Potential of Large Models via Differentiated Thinking and Complementary Ensembles, https://arxiv.org/pdf/2505.16784, 2025-06-07
2025-11-10 22:59:55,061 - INFO - root - Page:5, Index:1, Single Domain Generalization for Few-Shot Counting via Universal Representation Matching, https://arxiv.org/pdf/2505.16778, 2025-05-22
2025-11-10 22:59:55,061 - INFO - root - Page:5, Index:2, Seeing Far and Clearly: Mitigating Hallucinations in MLLMs with Attention Causal Decoding, https://arxiv.org/pdf/2505.16652, 2025-06-07
2025-11-10 22:59:55,063 - INFO - root - Page:5, Index:3, Sketchy Bounding-box Supervision for 3D Instance Segmentation, https://arxiv.org/pdf/2505.16399, 2025-05-22
2025-11-10 22:59:55,063 - INFO - root - Page:5, Index:4, DeCafNet: Delegate and Conquer for Efficient Temporal Grounding in Long Videos, https://arxiv.org/pdf/2505.16376, 2025-05-22
2025-11-10 22:59:55,063 - INFO - root - Page:5, Index:5, NTIRE 2025 challenge on Text to Image Generation Model Quality Assessment, https://arxiv.org/pdf/2505.16314, 2025-05-22
2025-11-10 22:59:55,064 - INFO - root - Page:5, Index:6, Analyzing Hierarchical Structure in Vision Models with Sparse Autoencoders, https://arxiv.org/pdf/2505.15970, 2025-05-21
2025-11-10 22:59:55,064 - INFO - root - Page:5, Index:7, Efficient Data Driven Mixture-of-Expert Extraction from Trained Networks, https://arxiv.org/pdf/2505.15414, 2025-05-21
2025-11-10 22:59:55,065 - INFO - root - Page:5, Index:8, Mouse Lockbox Dataset: Behavior Recognition for Mice Solving Lockboxes, https://arxiv.org/pdf/2505.15408, 2025-06-17
2025-11-10 22:59:55,065 - INFO - root - Page:5, Index:9, Zero-Shot Gaze-based Volumetric Medical Image Segmentation, https://arxiv.org/pdf/2505.15256, 2025-06-10
2025-11-10 22:59:55,065 - INFO - root - Page:5, Index:10, Dual Precision Quantization for Efficient and Accurate Deep Neural Networks Inference, https://arxiv.org/pdf/2505.14638, 2025-05-20
2025-11-10 22:59:55,066 - INFO - root - Page:5, Index:11, Neural Video Compression with Context Modulation, https://arxiv.org/pdf/2505.14541, 2025-05-20
2025-11-10 22:59:55,066 - INFO - root - Page:5, Index:12, Selective Structured State Space for Multispectral-fused Small Target Detection, https://arxiv.org/pdf/2505.14043, 2025-05-23
2025-11-10 22:59:55,066 - INFO - root - Page:5, Index:13, OmniStyle: Filtering High Quality Style Transfer Data at Scale, https://arxiv.org/pdf/2505.14028, 2025-05-20
2025-11-10 22:59:55,066 - INFO - root - Page:5, Index:14, Domain Adaptation of VLM for Soccer Video Understanding, https://arxiv.org/pdf/2505.13860, 2025-07-07
2025-11-10 22:59:55,067 - INFO - root - Page:5, Index:15, Ground-V: Teaching VLMs to Ground Complex Instructions in Pixels, https://arxiv.org/pdf/2505.13788, 2025-05-19
2025-11-10 22:59:55,068 - INFO - root - Page:5, Index:16, FinePhys: Fine-grained Human Action Generation by Explicitly Incorporating Physical Laws for Effective Skeletal Guidance, https://arxiv.org/pdf/2505.13437, 2025-05-19
2025-11-10 22:59:55,069 - INFO - root - Page:5, Index:17, The Way Up: A Dataset for Hold Usage Detection in Sport Climbing, https://arxiv.org/pdf/2505.12854, 2025-05-19
2025-11-10 22:59:55,070 - INFO - root - Page:5, Index:18, PEER pressure: Model-to-Model Regularization for Single Source Domain Generalization, https://arxiv.org/pdf/2505.12745, 2025-05-19
2025-11-10 22:59:55,070 - INFO - root - Page:5, Index:19, Mamba-Adaptor: State Space Model Adaptor for Visual Recognition, https://arxiv.org/pdf/2505.12685, 2025-05-19
2025-11-10 22:59:55,070 - INFO - root - Page:5, Index:20, Scalable Video-to-Dataset Generation for Cross-Platform Mobile Agents, https://arxiv.org/pdf/2505.12632, 2025-05-18
2025-11-10 22:59:55,070 - INFO - root - Page:5, Index:21, Degradation-Aware Feature Perturbation for All-in-One Image Restoration, https://arxiv.org/pdf/2505.12630, 2025-05-18
2025-11-10 22:59:55,072 - INFO - root - Page:5, Index:22, Guiding Diffusion with Deep Geometric Moments: Balancing Fidelity and Variation, https://arxiv.org/pdf/2505.12486, 2025-05-18
2025-11-10 22:59:55,072 - INFO - root - Page:5, Index:23, Learning to Highlight Audio by Watching Movies, https://arxiv.org/pdf/2505.12154, 2025-05-17
2025-11-10 22:59:55,073 - INFO - root - Page:5, Index:24, Understanding the Capabilities of Molecular Graph Neural Networks in Materials Science Through Multimodal Learning and Physical Context Encoding, https://arxiv.org/pdf/2505.12137, 2025-05-17
2025-11-10 22:59:55,073 - INFO - root - Page:5, Index:25, iSegMan: Interactive Segment-and-Manipulate 3D Gaussians, https://arxiv.org/pdf/2505.11934, 2025-05-17
2025-11-10 22:59:55,073 - INFO - root - Page:5, Index:26, Self-Learning Hyperspectral and Multispectral Image Fusion via Adaptive Residual Guided Subspace Diffusion Model, https://arxiv.org/pdf/2505.11800, 2025-05-16
2025-11-10 22:59:55,075 - INFO - root - Page:5, Index:27, X-Edit: Detecting and Localizing Edits in Images Altered by Text-Guided Diffusion Models, https://arxiv.org/pdf/2505.11753, 2025-05-16
2025-11-10 22:59:55,075 - INFO - root - Page:5, Index:28, MTevent: A Multi-Task Event Camera Dataset for 6D Pose Estimation and Moving Object Detection, https://arxiv.org/pdf/2505.11282, 2025-06-02
2025-11-10 22:59:55,076 - INFO - root - Page:5, Index:29, Imputation-free and Alignment-free: Incomplete Multi-view Clustering Driven by Consensus Semantic Learning, https://arxiv.org/pdf/2505.11182, 2025-05-16
2025-11-10 22:59:55,076 - INFO - root - Page:5, Index:30, MultiLink: Multi-class Structure Recovery via Agglomerative Clustering and Model Selection, https://arxiv.org/pdf/2505.10874, 2025-05-16
2025-11-10 22:59:55,076 - INFO - root - Page:5, Index:31, RefPose: Leveraging Reference Geometric Correspondences for Accurate 6D Pose Estimation of Unseen Objects, https://arxiv.org/pdf/2505.10841, 2025-05-16
2025-11-10 22:59:55,076 - INFO - root - Page:5, Index:32, MoCLIP: Motion-Aware Fine-Tuning and Distillation of CLIP for Human Motion Generation, https://arxiv.org/pdf/2505.10810, 2025-05-15
2025-11-10 22:59:55,077 - INFO - root - Page:5, Index:33, Automated Detection of Salvin's Albatrosses: Improving Deep Learning Tools for Aerial Wildlife Surveys, https://arxiv.org/pdf/2505.10737, 2025-05-15
2025-11-10 22:59:55,077 - INFO - root - Page:5, Index:34, Advancing Multiple Instance Learning with Continual Learning for Whole Slide Imaging, https://arxiv.org/pdf/2505.10649, 2025-05-15
2025-11-10 22:59:55,078 - INFO - root - Page:5, Index:35, Inferring Driving Maps by Deep Learning-based Trail Map Extraction, https://arxiv.org/pdf/2505.10258, 2025-05-15
2025-11-10 22:59:55,078 - INFO - root - Page:5, Index:36, Dyadic Mamba: Long-term Dyadic Human Motion Synthesis, https://arxiv.org/pdf/2505.09827, 2025-05-14
2025-11-10 22:59:55,079 - INFO - root - Page:5, Index:37, UWAV: Uncertainty-weighted Weakly-supervised Audio-Visual Video Parsing, https://arxiv.org/pdf/2505.09615, 2025-05-14
2025-11-10 22:59:55,081 - INFO - root - Page:5, Index:38, Camera-Only 3D Panoptic Scene Completion for Autonomous Driving through Differentiable Object Shapes, https://arxiv.org/pdf/2505.09562, 2025-05-14
2025-11-10 22:59:55,081 - INFO - root - Page:5, Index:39, Sparse Point Cloud Patches Rendering via Splitting 2D Gaussians, https://arxiv.org/pdf/2505.09413, 2025-05-14
2025-11-10 22:59:55,083 - INFO - root - Page:5, Index:40, UMotion: Uncertainty-driven Human Motion Estimation from Inertial and Ultra-wideband Units, https://arxiv.org/pdf/2505.09393, 2025-05-14
2025-11-10 22:59:55,084 - INFO - root - Page:5, Index:41, Marigold: Affordable Adaptation of Diffusion-Based Image Generators for Image Analysis, https://arxiv.org/pdf/2505.09358, 2025-05-14
2025-11-10 22:59:55,085 - INFO - root - Page:5, Index:42, Predicting butterfly species presence from satellite imagery using soft contrastive regularisation, https://arxiv.org/pdf/2505.09306, 2025-05-14
2025-11-10 22:59:55,086 - INFO - root - Page:5, Index:43, Behind Maya: Building a Multilingual Vision Language Model, https://arxiv.org/pdf/2505.08910, 2025-05-15
2025-11-10 22:59:55,086 - INFO - root - Page:5, Index:44, PosterO: Structuring Layout Trees to Enable Language Models in Generalized Content-Aware Layout Generation, https://arxiv.org/pdf/2505.07843, 2025-05-26
2025-11-10 22:59:55,087 - INFO - root - Page:5, Index:45, Prototype Augmented Hypernetworks for Continual Learning, https://arxiv.org/pdf/2505.07450, 2025-05-16
2025-11-10 22:59:55,087 - INFO - root - Fetching page 7 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=300
2025-11-10 23:00:01,653 - INFO - root - get_all_titles_from_web 
2025-11-10 23:00:01,653 - INFO - root - Page:6, Index:0, Convex Relaxation for Robust Vanishing Point Estimation in Manhattan World, https://arxiv.org/pdf/2505.04788, 2025-06-05
2025-11-10 23:00:01,654 - INFO - root - Page:6, Index:1, S3D: Sketch-Driven 3D Model Generation, https://arxiv.org/pdf/2505.04185, 2025-06-03
2025-11-10 23:00:01,654 - INFO - root - Page:6, Index:2, Generating Synthetic Data via Augmentations for Improved Facial Resemblance in DreamBooth and InstantID, https://arxiv.org/pdf/2505.03557, 2025-07-17
2025-11-10 23:00:01,654 - INFO - root - Page:6, Index:3, CAV-MAE Sync: Improving Contrastive Audio-Visual Mask Autoencoders via Fine-Grained Alignment, https://arxiv.org/pdf/2505.01237, 2025-05-21
2025-11-10 23:00:01,654 - INFO - root - Fetching page 8 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=350
2025-11-10 23:00:10,253 - INFO - root - get_all_titles_from_web 
2025-11-10 23:00:10,253 - INFO - root - Page:7, Index:0, Where's the liability in the Generative Era? Recovery-based Black-Box Detection of AI-Generated Content, https://arxiv.org/pdf/2505.01008, 2025-08-25
2025-11-10 23:00:10,253 - INFO - root - Page:7, Index:1, SpatialLLM: A Compound 3D-Informed Design towards Spatially-Intelligent Large Multimodal Models, https://arxiv.org/pdf/2505.00788, 2025-06-10
2025-11-10 23:00:10,254 - INFO - root - Page:7, Index:2, Prisma: An Open Source Toolkit for Mechanistic Interpretability in Vision and Video, https://arxiv.org/pdf/2504.19475, 2025-06-03
2025-11-10 23:00:10,254 - INFO - root - Page:7, Index:3, SSL4Eco: A Global Seasonal Dataset for Geospatial Foundation Models in Ecology, https://arxiv.org/pdf/2504.18256, 2025-10-20
2025-11-10 23:00:10,254 - INFO - root - Page:7, Index:4, Vision-Language Models Are Not Pragmatically Competent in Referring Expression Generation, https://arxiv.org/pdf/2504.16060, 2025-07-30
2025-11-10 23:00:10,254 - INFO - root - Fetching page 9 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=400
2025-11-10 23:00:18,561 - INFO - root - get_all_titles_from_web 
2025-11-10 23:00:18,561 - INFO - root - Page:8, Index:0, Leveraging Automatic CAD Annotations for Supervised Learning in 3D Scene Understanding, https://arxiv.org/pdf/2504.13580, 2025-05-16
2025-11-10 23:00:18,562 - INFO - root - Page:8, Index:1, CAP-Net: A Unified Network for 6D Pose and Size Estimation of Categorical Articulated Parts from a Single RGB-D Image, https://arxiv.org/pdf/2504.11230, 2025-06-02
2025-11-10 23:00:18,563 - INFO - root - Page:8, Index:2, Video Summarization with Large Language Models, https://arxiv.org/pdf/2504.11199, 2025-06-05
2025-11-10 23:00:18,563 - INFO - root - Page:8, Index:3, R-TPT: Improving Adversarial Robustness of Vision-Language Models through Test-Time Prompt Tuning, https://arxiv.org/pdf/2504.11195, 2025-08-27
2025-11-10 23:00:18,563 - INFO - root - Page:8, Index:4, TerraMesh: A Planetary Mosaic of Multimodal Earth Observation Data, https://arxiv.org/pdf/2504.11172, 2025-08-01
2025-11-10 23:00:18,563 - INFO - root - Page:8, Index:5, Seeing like a Cephalopod: Colour Vision with a Monochrome Event Camera, https://arxiv.org/pdf/2504.10984, 2025-06-06
2025-11-10 23:00:18,563 - INFO - root - Page:8, Index:6, Hearing Anywhere in Any Environment, https://arxiv.org/pdf/2504.10746, 2025-06-04
2025-11-10 23:00:18,563 - INFO - root - Fetching page 10 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=450
2025-11-10 23:00:26,240 - INFO - root - get_all_titles_from_web 
2025-11-10 23:00:26,240 - INFO - root - Page:9, Index:0, Correlative and Discriminative Label Grouping for Multi-Label Visual Prompt Tuning, https://arxiv.org/pdf/2504.09990, 2025-07-09
2025-11-10 23:00:26,240 - INFO - root - Page:9, Index:1, SPICE: A Synergistic, Precise, Iterative, and Customizable Image Editing Workflow, https://arxiv.org/pdf/2504.09697, 2025-10-16
2025-11-10 23:00:26,241 - INFO - root - Page:9, Index:2, Mimic In-Context Learning for Multimodal Tasks, https://arxiv.org/pdf/2504.08851, 2025-05-17
2025-11-10 23:00:26,241 - INFO - root - Page:9, Index:3, Digital Twin Catalog: A Large-Scale Photorealistic 3D Object Digital Twin Dataset, https://arxiv.org/pdf/2504.08541, 2025-05-18
2025-11-10 23:00:26,241 - INFO - root - Page:9, Index:4, MMLA: Multi-Environment, Multi-Species, Low-Altitude Drone Dataset, https://arxiv.org/pdf/2504.07744, 2025-10-22
2025-11-10 23:00:26,241 - INFO - root - Fetching page 11 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=500
2025-11-10 23:00:33,409 - INFO - root - get_all_titles_from_web 
2025-11-10 23:00:33,410 - INFO - root - Page:10, Index:0, PromptHMR: Promptable Human Mesh Recovery, https://arxiv.org/pdf/2504.06397, 2025-05-23
2025-11-10 23:00:33,410 - INFO - root - Page:10, Index:1, SCAM: A Real-World Typographic Robustness Evaluation for Multimodal Foundation Models, https://arxiv.org/pdf/2504.04893, 2025-09-26
2025-11-10 23:00:33,411 - INFO - root - Fetching page 12 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=550
2025-11-10 23:00:41,583 - INFO - root - get_all_titles_from_web 
2025-11-10 23:00:41,583 - INFO - root - Page:11, Index:0, Charm: The Missing Piece in ViT fine-tuning for Image Aesthetic Assessment, https://arxiv.org/pdf/2504.02522, 2025-05-15
2025-11-10 23:00:41,584 - INFO - root - Page:11, Index:1, T*: Re-thinking Temporal Search for Long-Form Video Understanding, https://arxiv.org/pdf/2504.02259, 2025-08-24
2025-11-10 23:00:41,584 - INFO - root - Page:11, Index:2, CoMatcher: Multi-View Collaborative Feature Matching, https://arxiv.org/pdf/2504.01872, 2025-08-20
2025-11-10 23:00:41,584 - INFO - root - Page:11, Index:3, Learned Image Compression with Dictionary-based Entropy Model, https://arxiv.org/pdf/2504.00496, 2025-05-14
2025-11-10 23:00:41,584 - INFO - root - Page:11, Index:4, Think Small, Act Big: Primitive Prompt Learning for Lifelong Robot Manipulation, https://arxiv.org/pdf/2504.00420, 2025-06-01
2025-11-10 23:00:41,585 - INFO - root - Fetching page 13 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=600
2025-11-10 23:00:50,520 - INFO - root - get_all_titles_from_web 
2025-11-10 23:00:50,520 - INFO - root - Page:12, Index:0, It's a (Blind) Match! Towards Vision-Language Correspondence without Parallel Data, https://arxiv.org/pdf/2503.24129, 2025-05-29
2025-11-10 23:00:50,521 - INFO - root - Page:12, Index:1, ReferDINO-Plus: 2nd Solution for 4th PVUW MeViS Challenge at CVPR 2025, https://arxiv.org/pdf/2503.23509, 2025-05-29
2025-11-10 23:00:50,521 - INFO - root - Page:12, Index:2, A Unified Image-Dense Annotation Generation Model for Underwater Scenes, https://arxiv.org/pdf/2503.21771, 2025-07-27
2025-11-10 23:00:50,521 - INFO - root - Fetching page 14 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=650
2025-11-10 23:00:57,727 - INFO - root - get_all_titles_from_web 
2025-11-10 23:00:57,727 - INFO - root - Page:13, Index:0, Learning Class Prototypes for Unified Sparse Supervised 3D Object Detection, https://arxiv.org/pdf/2503.21099, 2025-06-13
2025-11-10 23:00:57,727 - INFO - root - Page:13, Index:1, LATTE-MV: Learning to Anticipate Table Tennis Hits from Monocular Videos, https://arxiv.org/pdf/2503.20936, 2025-09-01
2025-11-10 23:00:57,728 - INFO - root - Page:13, Index:2, BizGen: Advancing Article-level Visual Text Rendering for Infographics Generation, https://arxiv.org/pdf/2503.20672, 2025-07-02
2025-11-10 23:00:57,728 - INFO - root - Page:13, Index:3, ITA-MDT: Image-Timestep-Adaptive Masked Diffusion Transformer Framework for Image-Based Virtual Try-On, https://arxiv.org/pdf/2503.20418, 2025-06-01
2025-11-10 23:00:57,728 - INFO - root - Page:13, Index:4, Faster Parameter-Efficient Tuning with Token Redundancy Reduction, https://arxiv.org/pdf/2503.20282, 2025-08-26
2025-11-10 23:00:57,729 - INFO - root - Page:13, Index:5, DINeMo: Learning Neural Mesh Models with no 3D Annotations, https://arxiv.org/pdf/2503.20220, 2025-06-09
2025-11-10 23:00:57,730 - INFO - root - Page:13, Index:6, Scaling Vision Pre-Training to 4K Resolution, https://arxiv.org/pdf/2503.19903, 2025-08-03
2025-11-10 23:00:57,731 - INFO - root - Page:13, Index:7, GENIUS: A Generative Framework for Universal Multimodal Search, https://arxiv.org/pdf/2503.19868, 2025-06-05
2025-11-10 23:00:57,731 - INFO - root - Fetching page 15 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=700
2025-11-10 23:01:04,501 - INFO - root - get_all_titles_from_web 
2025-11-10 23:01:04,501 - INFO - root - Page:14, Index:0, Galaxy Walker: Geometry-aware VLMs For Galaxy-scale Understanding, https://arxiv.org/pdf/2503.18578, 2025-05-25
2025-11-10 23:01:04,503 - INFO - root - Page:14, Index:1, LookCloser: Frequency-aware Radiance Field for Tiny-Detail Scene, https://arxiv.org/pdf/2503.18513, 2025-07-29
2025-11-10 23:01:04,503 - INFO - root - Fetching page 16 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=750
2025-11-10 23:01:12,887 - INFO - root - get_all_titles_from_web 
2025-11-10 23:01:12,888 - INFO - root - Page:15, Index:0, LoTUS: Large-Scale Machine Unlearning with a Taste of Uncertainty, https://arxiv.org/pdf/2503.18314, 2025-05-29
2025-11-10 23:01:12,888 - INFO - root - Page:15, Index:1, MammAlps: A multi-view video behavior monitoring dataset of wild mammals in the Swiss Alps, https://arxiv.org/pdf/2503.18223, 2025-06-04
2025-11-10 23:01:12,888 - INFO - root - Page:15, Index:2, Progressive Prompt Detailing for Improved Alignment in Text-to-Image Generative Models, https://arxiv.org/pdf/2503.17794, 2025-05-30
2025-11-10 23:01:12,888 - INFO - root - Page:15, Index:3, CountLLM: Towards Generalizable Repetitive Action Counting via Large Language Model, https://arxiv.org/pdf/2503.17690, 2025-06-29
2025-11-10 23:01:12,889 - INFO - root - Page:15, Index:4, TaoAvatar: Real-Time Lifelike Full-Body Talking Avatars for Augmented Reality via 3D Gaussian Splatting, https://arxiv.org/pdf/2503.17032, 2025-07-23
2025-11-10 23:01:12,889 - INFO - root - Page:15, Index:5, Generalized Few-shot 3D Point Cloud Segmentation with Vision-Language Model, https://arxiv.org/pdf/2503.16282, 2025-05-20
2025-11-10 23:01:12,889 - INFO - root - Fetching page 17 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=800
2025-11-10 23:01:23,372 - INFO - root - get_all_titles_from_web 
2025-11-10 23:01:23,373 - INFO - root - Page:16, Index:0, High Temporal Consistency through Semantic Similarity Propagation in Semi-Supervised Video Semantic Segmentation for Autonomous Flight, https://arxiv.org/pdf/2503.15676, 2025-06-26
2025-11-10 23:01:23,374 - INFO - root - Page:16, Index:1, DPFlow: Adaptive Optical Flow Estimation with a Dual-Pyramid Framework, https://arxiv.org/pdf/2503.14880, 2025-09-29
2025-11-10 23:01:23,374 - INFO - root - Fetching page 18 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=850
2025-11-10 23:01:33,228 - INFO - root - get_all_titles_from_web 
2025-11-10 23:01:33,228 - INFO - root - Page:17, Index:0, From Head to Tail: Towards Balanced Representation in Large Vision-Language Models through Adaptive Data Calibration, https://arxiv.org/pdf/2503.12821, 2025-05-29
2025-11-10 23:01:33,229 - INFO - root - Page:17, Index:1, MambaIC: State Space Models for High-Performance Learned Image Compression, https://arxiv.org/pdf/2503.12461, 2025-08-22
2025-11-10 23:01:33,229 - INFO - root - Page:17, Index:2, Localized Concept Erasure for Text-to-Image Diffusion Models Using Training-Free Gated Low-Rank Adaptation, https://arxiv.org/pdf/2503.12356, 2025-07-09
2025-11-10 23:01:33,229 - INFO - root - Page:17, Index:3, TASTE-Rob: Advancing Video Generation of Task-Oriented Hand-Object Interaction for Generalizable Robotic Manipulation, https://arxiv.org/pdf/2503.11423, 2025-06-05
2025-11-10 23:01:33,230 - INFO - root - Page:17, Index:4, Panopticon: Advancing Any-Sensor Foundation Models for Earth Observation, https://arxiv.org/pdf/2503.10845, 2025-08-01
2025-11-10 23:01:33,230 - INFO - root - Page:17, Index:5, Transformers without Normalization, https://arxiv.org/pdf/2503.10622, 2025-06-14
2025-11-10 23:01:33,231 - INFO - root - Page:17, Index:6, dFLMoE: Decentralized Federated Learning via Mixture of Experts for Medical Data Analysis, https://arxiv.org/pdf/2503.10412, 2025-05-19
2025-11-10 23:01:33,231 - INFO - root - Fetching page 19 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=900
2025-11-10 23:01:39,953 - INFO - root - get_all_titles_from_web 
2025-11-10 23:01:39,953 - INFO - root - Page:18, Index:0, Project-Probe-Aggregate: Efficient Fine-Tuning for Group Robustness, https://arxiv.org/pdf/2503.09487, 2025-08-26
2025-11-10 23:01:39,954 - INFO - root - Page:18, Index:1, VLog: Video-Language Models by Generative Retrieval of Narration Vocabulary, https://arxiv.org/pdf/2503.09402, 2025-06-09
2025-11-10 23:01:39,954 - INFO - root - Fetching page 20 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=950
2025-11-10 23:01:47,482 - INFO - root - get_all_titles_from_web 
2025-11-10 23:01:47,483 - INFO - root - Page:19, Index:0, Escaping Plato's Cave: Towards the Alignment of 3D and Text Latent Spaces, https://arxiv.org/pdf/2503.05283, 2025-06-04
2025-11-10 23:01:47,483 - INFO - root - Page:19, Index:1, FluidNexus: 3D Fluid Reconstruction and Prediction from a Single Video, https://arxiv.org/pdf/2503.04720, 2025-07-09
2025-11-10 23:01:47,484 - INFO - root - Page:19, Index:2, Question-Aware Gaussian Experts for Audio-Visual Question Answering, https://arxiv.org/pdf/2503.04459, 2025-06-11
2025-11-10 23:01:47,484 - INFO - root - Page:19, Index:3, Q-Eval-100K: Evaluating Visual Quality and Alignment Level for Text-to-Vision Content, https://arxiv.org/pdf/2503.02357, 2025-06-15
2025-11-10 23:01:47,484 - INFO - root - Fetching page 21 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=1000
2025-11-10 23:01:54,184 - INFO - root - get_all_titles_from_web 
2025-11-10 23:01:54,184 - INFO - root - Page:20, Index:0, Data Distributional Properties As Inductive Bias for Systematic Generalization, https://arxiv.org/pdf/2502.20499, 2025-06-17
2025-11-10 23:01:54,186 - INFO - root - Page:20, Index:1, Knowledge Bridger: Towards Training-free Missing Modality Completion, https://arxiv.org/pdf/2502.19834, 2025-06-17
2025-11-10 23:01:54,188 - INFO - root - Fetching page 22 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=1050
2025-11-10 23:02:00,650 - INFO - root - get_all_titles_from_web 
2025-11-10 23:02:00,650 - INFO - root - Page:21, Index:0, MALT Diffusion: Memory-Augmented Latent Transformers for Any-Length Video Generation, https://arxiv.org/pdf/2502.12632, 2025-07-08
2025-11-10 23:02:00,650 - INFO - root - Page:21, Index:1, ILIAS: Instance-Level Image retrieval At Scale, https://arxiv.org/pdf/2502.11748, 2025-06-23
2025-11-10 23:02:00,652 - INFO - root - Page:21, Index:2, Distraction is All You Need for Multimodal Large Language Model Jailbreaking, https://arxiv.org/pdf/2502.10794, 2025-06-16
2025-11-10 23:02:00,652 - INFO - root - Page:21, Index:3, Spatial457: A Diagnostic Benchmark for 6D Spatial Reasoning of Large Multimodal Models, https://arxiv.org/pdf/2502.08636, 2025-06-08
2025-11-10 23:02:00,652 - INFO - root - Page:21, Index:4, TRAVEL: Training-Free Retrieval and Alignment for Vision-and-Language Navigation, https://arxiv.org/pdf/2502.07306, 2025-06-09
2025-11-10 23:02:00,652 - INFO - root - Page:21, Index:5, DiTASK: Multi-Task Fine-Tuning with Diffeomorphic Transformations, https://arxiv.org/pdf/2502.06029, 2025-06-01
2025-11-10 23:02:00,653 - INFO - root - Page:21, Index:6, ConceptAttention: Diffusion Transformers Learn Highly Interpretable Features, https://arxiv.org/pdf/2502.04320, 2025-07-01
2025-11-10 23:02:00,653 - INFO - root - Page:21, Index:7, GCE-Pose: Global Context Enhancement for Category-level Object Pose Estimation, https://arxiv.org/pdf/2502.04293, 2025-06-24
2025-11-10 23:02:00,653 - INFO - root - Page:21, Index:8, Calibrated Multi-Preference Optimization for Aligning Diffusion Models, https://arxiv.org/pdf/2502.02588, 2025-09-26
2025-11-10 23:02:00,654 - INFO - root - Page:21, Index:9, Instruct-4DGS: Efficient Dynamic Scene Editing via 4D Gaussian-based Static-Dynamic Separation, https://arxiv.org/pdf/2502.02091, 2025-07-01
2025-11-10 23:02:00,654 - INFO - root - Page:21, Index:10, Low-Resource Video Super-Resolution using Memory, Wavelets, and Deformable Convolutions, https://arxiv.org/pdf/2502.01816, 2025-06-19
2025-11-10 23:02:00,654 - INFO - root - Page:21, Index:11, Bridging Text and Crystal Structures: Literature-driven Contrastive Learning for Materials Science, https://arxiv.org/pdf/2501.12919, 2025-06-18
2025-11-10 23:02:00,654 - INFO - root - Page:21, Index:12, T2ISafety: Benchmark for Assessing Fairness, Toxicity, and Privacy in Image Generation, https://arxiv.org/pdf/2501.12612, 2025-07-25
2025-11-10 23:02:00,655 - INFO - root - Page:21, Index:13, Fine-Grained Image-Text Correspondence with Cost Aggregation for Open-Vocabulary Part Segmentation, https://arxiv.org/pdf/2501.09688, 2025-08-08
2025-11-10 23:02:00,655 - INFO - root - Fetching page 23 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=1100
2025-11-10 23:02:07,239 - INFO - root - get_all_titles_from_web 
2025-11-10 23:02:07,239 - INFO - root - Page:22, Index:0, Bias for Action: Video Implicit Neural Representations with Bias Modulation, https://arxiv.org/pdf/2501.09277, 2025-06-06
2025-11-10 23:02:07,240 - INFO - root - Page:22, Index:1, MonSter++: Unified Stereo Matching, Multi-view Stereo, and Real-time Stereo with Monodepth Priors, https://arxiv.org/pdf/2501.08643, 2025-09-25
2025-11-10 23:02:07,240 - INFO - root - Page:22, Index:2, Go-with-the-Flow: Motion-Controllable Video Diffusion Models Using Real-Time Warped Noise, https://arxiv.org/pdf/2501.08331, 2025-08-06
2025-11-10 23:02:07,240 - INFO - root - Page:22, Index:3, Nonisotropic Gaussian Diffusion for Realistic 3D Human Motion Prediction, https://arxiv.org/pdf/2501.06035, 2025-07-08
2025-11-10 23:02:07,240 - INFO - root - Page:22, Index:4, Discovering Hidden Visual Concepts Beyond Linguistic Input in Infant Learning, https://arxiv.org/pdf/2501.05205, 2025-06-13
2025-11-10 23:02:07,241 - INFO - root - Page:22, Index:5, PERSE: Personalized 3D Generative Avatars from A Single Portrait, https://arxiv.org/pdf/2412.21206, 2025-09-28
2025-11-10 23:02:07,241 - INFO - root - Page:22, Index:6, MaskGaussian: Adaptive 3D Gaussian Representation from Probabilistic Masks, https://arxiv.org/pdf/2412.20522, 2025-06-14
2025-11-10 23:02:07,241 - INFO - root - Page:22, Index:7, SimLTD: Simple Supervised and Semi-Supervised Long-Tailed Object Detection, https://arxiv.org/pdf/2412.20047, 2025-06-09
2025-11-10 23:02:07,242 - INFO - root - Page:22, Index:8, Conditional Balance: Improving Multi-Conditioning Trade-Offs in Image Generation, https://arxiv.org/pdf/2412.19853, 2025-08-03
2025-11-10 23:02:07,242 - INFO - root - Fetching page 24 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=1150
2025-11-10 23:02:14,321 - INFO - root - get_all_titles_from_web 
2025-11-10 23:02:14,321 - INFO - root - Page:23, Index:0, CoCoGaussian: Leveraging Circle of Confusion for Gaussian Splatting from Defocused Images, https://arxiv.org/pdf/2412.16028, 2025-05-15
2025-11-10 23:02:14,321 - INFO - root - Page:23, Index:1, EnergyMoGen: Compositional Human Motion Generation with Energy-Based Diffusion Model in Latent Space, https://arxiv.org/pdf/2412.14706, 2025-06-04
2025-11-10 23:02:14,322 - INFO - root - Page:23, Index:2, DarkIR: Robust Low-Light Image Restoration, https://arxiv.org/pdf/2412.13443, 2025-10-14
2025-11-10 23:02:14,322 - INFO - root - Page:23, Index:3, FastVLM: Efficient Vision Encoding for Vision Language Models, https://arxiv.org/pdf/2412.13303, 2025-05-15
2025-11-10 23:02:14,323 - INFO - root - Page:23, Index:4, Real-time Free-view Human Rendering from Sparse-view RGB Videos using Double Unprojected Textures, https://arxiv.org/pdf/2412.13183, 2025-06-20
2025-11-10 23:02:14,324 - INFO - root - Page:23, Index:5, CondiMen: Conditional Multi-Person Mesh Recovery, https://arxiv.org/pdf/2412.13058, 2025-06-04
2025-11-10 23:02:14,324 - INFO - root - Page:23, Index:6, MASt3R-SLAM: Real-Time Dense SLAM with 3D Reconstruction Priors, https://arxiv.org/pdf/2412.12392, 2025-06-02
2025-11-10 23:02:14,325 - INFO - root - Page:23, Index:7, DynamicScaler: Seamless and Scalable Video Generation for Panoramic Scenes, https://arxiv.org/pdf/2412.11100, 2025-10-04
2025-11-10 23:02:14,325 - INFO - root - Page:23, Index:8, SnapGen-V: Generating a Five-Second Video within Five Seconds on a Mobile Device, https://arxiv.org/pdf/2412.10494, 2025-06-09
2025-11-10 23:02:14,325 - INFO - root - Page:23, Index:9, Mr. DETR++: Instructive Multi-Route Training for Detection Transformers with Mixture-of-Experts, https://arxiv.org/pdf/2412.10028, 2025-06-26
2025-11-10 23:02:14,326 - INFO - root - Page:23, Index:10, LinGen: Towards High-Resolution Minute-Length Text-to-Video Generation with Linear Computational Complexity, https://arxiv.org/pdf/2412.09856, 2025-05-24
2025-11-10 23:02:14,327 - INFO - root - Page:23, Index:11, Gaze-LLE: Gaze Target Estimation via Large-Scale Learned Encoders, https://arxiv.org/pdf/2412.09586, 2025-06-03
2025-11-10 23:02:14,328 - INFO - root - Fetching page 25 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=1200
2025-11-10 23:02:21,759 - INFO - root - get_all_titles_from_web 
2025-11-10 23:02:21,760 - INFO - root - Page:24, Index:0, From Slow Bidirectional to Fast Autoregressive Video Diffusion Models, https://arxiv.org/pdf/2412.07772, 2025-09-23
2025-11-10 23:02:21,760 - INFO - root - Page:24, Index:1, Rate-In: Information-Driven Adaptive Dropout Rates for Improved Inference-Time Uncertainty Estimation, https://arxiv.org/pdf/2412.07169, 2025-06-03
2025-11-10 23:02:21,760 - INFO - root - Page:24, Index:2, FIRE: Robust Detection of Diffusion-Generated Images via Frequency-Guided Reconstruction Error, https://arxiv.org/pdf/2412.07140, 2025-11-03
2025-11-10 23:02:21,761 - INFO - root - Page:24, Index:3, Birth and Death of a Rose, https://arxiv.org/pdf/2412.05278, 2025-06-05
2025-11-10 23:02:21,761 - INFO - root - Page:24, Index:4, DualPM: Dual Posed-Canonical Point Maps for 3D Shape and Pose Reconstruction, https://arxiv.org/pdf/2412.04464, 2025-08-14
2025-11-10 23:02:21,761 - INFO - root - Page:24, Index:5, SeeGround: See and Ground for Zero-Shot Open-Vocabulary 3D Visual Grounding, https://arxiv.org/pdf/2412.04383, 2025-05-29
2025-11-10 23:02:21,761 - INFO - root - ------------------------------------------------------------------------------------------------------------------------
2025-11-10 23:02:37,818 - INFO - root - 正在总结论文 1/2: Learning to Seek Evidence: A Verifiable Reasoning Agent with Causal Faithfulness Analysis
2025-11-10 23:03:28,449 - INFO - root - LLMClient: rate limit reached, sleeping 9.4s
2025-11-10 23:03:57,616 - INFO - root - 正在提取论文图片...
2025-11-10 23:03:57,795 - INFO - root - 已保存图片 1/10：./export\images_Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness\figure_1_page2.jpeg
2025-11-10 23:03:57,801 - INFO - root - 已保存图片 2/10：./export\images_Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness\figure_2_page2.jpeg
2025-11-10 23:03:57,816 - INFO - root - 已保存图片 3/10：./export\images_Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness\figure_3_page2.jpeg
2025-11-10 23:03:57,822 - INFO - root - 已保存图片 4/10：./export\images_Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness\figure_4_page2.jpeg
2025-11-10 23:03:57,837 - INFO - root - 已保存图片 5/10：./export\images_Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness\figure_5_page2.jpeg
2025-11-10 23:03:57,848 - INFO - root - 已保存图片 6/10：./export\images_Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness\figure_6_page2.jpeg
2025-11-10 23:03:57,864 - INFO - root - 已保存图片 7/10：./export\images_Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness\figure_7_page2.jpeg
2025-11-10 23:03:57,883 - INFO - root - 已保存图片 8/10：./export\images_Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness\figure_8_page2.jpeg
2025-11-10 23:03:57,921 - INFO - root - 已保存图片 9/10：./export\images_Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness\figure_9_page2.jpeg
2025-11-10 23:03:57,940 - INFO - root - 已保存图片 10/10：./export\images_Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness\figure_10_page2.jpeg
2025-11-10 23:03:57,944 - INFO - root - 成功添加图片 1：./export\images_Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness\figure_1_page2.jpeg
2025-11-10 23:03:57,945 - INFO - root - 成功添加图片 2：./export\images_Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness\figure_2_page2.jpeg
2025-11-10 23:03:57,946 - INFO - root - 成功添加图片 3：./export\images_Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness\figure_3_page2.jpeg
2025-11-10 23:03:57,947 - INFO - root - 成功添加图片 4：./export\images_Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness\figure_4_page2.jpeg
2025-11-10 23:03:57,947 - INFO - root - 成功添加图片 5：./export\images_Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness\figure_5_page2.jpeg
2025-11-10 23:03:57,947 - INFO - root - 成功添加图片 6：./export\images_Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness\figure_6_page2.jpeg
2025-11-10 23:03:57,949 - INFO - root - 成功添加图片 7：./export\images_Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness\figure_7_page2.jpeg
2025-11-10 23:03:57,949 - INFO - root - 成功添加图片 8：./export\images_Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness\figure_8_page2.jpeg
2025-11-10 23:03:57,950 - INFO - root - 成功添加图片 9：./export\images_Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness\figure_9_page2.jpeg
2025-11-10 23:03:57,950 - INFO - root - 成功添加图片 10：./export\images_Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness\figure_10_page2.jpeg
2025-11-10 23:03:57,977 - INFO - root - 论文《Learning to Seek Evidence: A Verifiable Reasoning Agent with Causal Faithfulness Analysis》的分析已保存到 ./export\QAT\Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness.md
2025-11-10 23:03:57,991 - INFO - root - 正在总结论文 2/2: OmniTrack++: Omnidirectional Multi-Object Tracking by Learning Large-FoV Trajectory Feedback
2025-11-10 23:04:12,676 - INFO - root - LLMClient: rate limit reached, sleeping 25.1s
2025-11-10 23:07:48,949 - INFO - root - 正在提取论文图片...
2025-11-10 23:07:49,383 - INFO - root - 已保存图片 1/10：./export\images_OmniTrack++_ Omnidirectional Multi-Object Tracking by Learning Large-FoV Traject\figure_1_page13.jpeg
2025-11-10 23:07:49,436 - INFO - root - 已保存图片 2/10：./export\images_OmniTrack++_ Omnidirectional Multi-Object Tracking by Learning Large-FoV Traject\figure_2_page13.jpeg
2025-11-10 23:07:49,482 - INFO - root - 已保存图片 3/10：./export\images_OmniTrack++_ Omnidirectional Multi-Object Tracking by Learning Large-FoV Traject\figure_3_page13.jpeg
2025-11-10 23:07:49,535 - INFO - root - 已保存图片 4/10：./export\images_OmniTrack++_ Omnidirectional Multi-Object Tracking by Learning Large-FoV Traject\figure_4_page2.jpeg
2025-11-10 23:07:49,594 - INFO - root - 已保存图片 5/10：./export\images_OmniTrack++_ Omnidirectional Multi-Object Tracking by Learning Large-FoV Traject\figure_5_page5.png
2025-11-10 23:07:49,627 - INFO - root - 已保存图片 6/10：./export\images_OmniTrack++_ Omnidirectional Multi-Object Tracking by Learning Large-FoV Traject\figure_6_page13.jpeg
2025-11-10 23:07:49,667 - INFO - root - 已保存图片 7/10：./export\images_OmniTrack++_ Omnidirectional Multi-Object Tracking by Learning Large-FoV Traject\figure_7_page2.jpeg
2025-11-10 23:07:49,701 - INFO - root - 已保存图片 8/10：./export\images_OmniTrack++_ Omnidirectional Multi-Object Tracking by Learning Large-FoV Traject\figure_8_page8.jpeg
2025-11-10 23:07:49,726 - INFO - root - 已保存图片 9/10：./export\images_OmniTrack++_ Omnidirectional Multi-Object Tracking by Learning Large-FoV Traject\figure_9_page1.jpeg
2025-11-10 23:07:49,748 - INFO - root - 已保存图片 10/10：./export\images_OmniTrack++_ Omnidirectional Multi-Object Tracking by Learning Large-FoV Traject\figure_10_page1.png
2025-11-10 23:07:49,756 - INFO - root - 成功添加图片 1：./export\images_OmniTrack++_ Omnidirectional Multi-Object Tracking by Learning Large-FoV Traject\figure_1_page13.jpeg
2025-11-10 23:07:49,756 - INFO - root - 成功添加图片 2：./export\images_OmniTrack++_ Omnidirectional Multi-Object Tracking by Learning Large-FoV Traject\figure_2_page13.jpeg
2025-11-10 23:07:49,757 - INFO - root - 成功添加图片 3：./export\images_OmniTrack++_ Omnidirectional Multi-Object Tracking by Learning Large-FoV Traject\figure_3_page13.jpeg
2025-11-10 23:07:49,757 - INFO - root - 成功添加图片 4：./export\images_OmniTrack++_ Omnidirectional Multi-Object Tracking by Learning Large-FoV Traject\figure_4_page2.jpeg
2025-11-10 23:07:49,757 - INFO - root - 成功添加图片 5：./export\images_OmniTrack++_ Omnidirectional Multi-Object Tracking by Learning Large-FoV Traject\figure_5_page5.png
2025-11-10 23:07:49,758 - INFO - root - 成功添加图片 6：./export\images_OmniTrack++_ Omnidirectional Multi-Object Tracking by Learning Large-FoV Traject\figure_6_page13.jpeg
2025-11-10 23:07:49,758 - INFO - root - 成功添加图片 7：./export\images_OmniTrack++_ Omnidirectional Multi-Object Tracking by Learning Large-FoV Traject\figure_7_page2.jpeg
2025-11-10 23:07:49,758 - INFO - root - 成功添加图片 8：./export\images_OmniTrack++_ Omnidirectional Multi-Object Tracking by Learning Large-FoV Traject\figure_8_page8.jpeg
2025-11-10 23:07:49,759 - INFO - root - 成功添加图片 9：./export\images_OmniTrack++_ Omnidirectional Multi-Object Tracking by Learning Large-FoV Traject\figure_9_page1.jpeg
2025-11-10 23:07:49,759 - INFO - root - 成功添加图片 10：./export\images_OmniTrack++_ Omnidirectional Multi-Object Tracking by Learning Large-FoV Traject\figure_10_page1.png
2025-11-10 23:07:49,770 - INFO - root - 论文《OmniTrack++: Omnidirectional Multi-Object Tracking by Learning Large-FoV Trajectory Feedback》的分析已保存到 ./export\QAT\OmniTrack++_ Omnidirectional Multi-Object Tracking by Learning Large-FoV Traject.md
2025-11-10 23:07:49,837 - WARNING - root - 生成汇总Excel表格失败: No module named 'openpyxl'
2025-11-10 23:07:49,842 - INFO - root - summary time: 521.96 seconds
2025-11-10 23:16:46,805 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-10 23:16:46,807 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-10 23:16:46,808 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-10 23:16:48,273 - INFO - root - LLMClientManager: 指定使用客户端: Gemini
2025-11-10 23:16:50,460 - INFO - root - GeminiClient: trying model models/gemini-2.5-flash
2025-11-10 23:16:53,768 - INFO - root - GeminiClient: initialized model gemini-2.5-flash
2025-11-10 23:16:53,769 - INFO - root - LLMClientManager: Gemini 客户端初始化成功
2025-11-10 23:16:53,770 - INFO - root - LLMClientManager: switched to Gemini client
2025-11-10 23:16:53,771 - INFO - root - 已手动切换到 LLM 客户端: Gemini
2025-11-10 23:16:53,771 - INFO - root - 使用 LLM 模型: gemini-2.5-flash
2025-11-10 23:16:53,773 - INFO - root - 可用客户端: ['Gemini']
2025-11-10 23:16:53,774 - INFO - root - === 运行配置 ===
2025-11-10 23:16:53,775 - INFO - root - 处理模式: arxiv在线搜索
2025-11-10 23:16:53,775 - INFO - root - 关键词: QAT
2025-11-10 23:16:53,776 - INFO - root - 查询: CVPR 2026
2025-11-10 23:16:53,777 - INFO - root - 排序: None
2025-11-10 23:16:53,778 - INFO - root - 最近天数: 180
2025-11-10 23:16:53,786 - INFO - root - 最大处理数量: 2
2025-11-10 23:16:53,788 - INFO - root - 保存图片: 是
2025-11-10 23:16:53,789 - INFO - root - 输出语言: 中文
2025-11-10 23:16:53,789 - INFO - root - 强制重新处理: 否
2025-11-10 23:16:53,789 - INFO - root - ====================
2025-11-10 23:16:53,790 - INFO - root - 使用 arXiv 搜索模式（通过 chat_arxiv 模块获取）
2025-11-10 23:16:53,790 - INFO - root - Fetching page 1 with URL: https://arxiv.org/search/?query=CVPR+2026&searchtype=all&abstracts=show&order=-announced_date_first&size=50
2025-11-10 23:17:00,013 - INFO - root - get_all_titles_from_web 
2025-11-10 23:17:00,154 - INFO - root - Page:0, Index:0, Learning to Seek Evidence: A Verifiable Reasoning Agent with Causal Faithfulness Analysis, https://arxiv.org/pdf/2511.01425, 2025-11-03
2025-11-10 23:17:00,264 - INFO - root - Fetching page 2 with URL: https://arxiv.org/search/?query=CVPR+2026&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=50
2025-11-10 23:17:06,660 - INFO - root - ------------------------------------------------------------------------------------------------------------------------
2025-11-10 23:17:18,416 - INFO - root - 跳过已处理论文 Learning to Seek Evidence: A Verifiable Reasoning Agent with Causal Faithfulness Analysis：d:\ChatPaper\academic Papers\CVPR 2026\Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness.pdf
2025-11-10 23:17:25,317 - WARNING - root - 未找到论文信息: 2511.01425
2025-11-10 23:17:25,333 - WARNING - root - 生成汇总Excel表格失败: No module named 'openpyxl'
2025-11-10 23:17:25,334 - INFO - root - summary time: 38.53 seconds
2025-11-10 23:25:03,333 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-10 23:25:03,333 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-10 23:25:03,336 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-10 23:25:04,198 - INFO - root - LLMClientManager: 指定使用客户端: Gemini
2025-11-10 23:25:05,057 - INFO - root - GeminiClient: trying model models/gemini-2.5-flash
2025-11-10 23:25:06,742 - INFO - root - GeminiClient: initialized model gemini-2.5-flash
2025-11-10 23:25:06,743 - INFO - root - LLMClientManager: Gemini 客户端初始化成功
2025-11-10 23:25:06,743 - INFO - root - LLMClientManager: switched to Gemini client
2025-11-10 23:25:06,743 - INFO - root - 已手动切换到 LLM 客户端: Gemini
2025-11-10 23:25:06,743 - INFO - root - 使用 LLM 模型: gemini-2.5-flash
2025-11-10 23:25:06,744 - INFO - root - 可用客户端: ['Gemini']
2025-11-10 23:25:06,745 - INFO - root - === 运行配置 ===
2025-11-10 23:25:06,745 - INFO - root - 处理模式: arxiv在线搜索
2025-11-10 23:25:06,745 - INFO - root - 关键词: QAT
2025-11-10 23:25:06,745 - INFO - root - 查询: CVPR 2026
2025-11-10 23:25:06,746 - INFO - root - 排序: None
2025-11-10 23:25:06,746 - INFO - root - 最近天数: 180
2025-11-10 23:25:06,747 - INFO - root - 最大处理数量: 2
2025-11-10 23:25:06,747 - INFO - root - 保存图片: 是
2025-11-10 23:25:06,747 - INFO - root - 输出语言: 中文
2025-11-10 23:25:06,747 - INFO - root - 强制重新处理: 否
2025-11-10 23:25:06,748 - INFO - root - ====================
2025-11-10 23:25:06,748 - INFO - root - 使用 arXiv 搜索模式（通过 chat_arxiv 模块获取）
2025-11-10 23:25:06,749 - INFO - root - Fetching page 1 with URL: https://arxiv.org/search/?query=CVPR+2026&searchtype=all&abstracts=show&order=-announced_date_first&size=50
2025-11-10 23:25:12,993 - INFO - root - get_all_titles_from_web 
2025-11-10 23:25:12,994 - INFO - root - Page:0, Index:0, Learning to Seek Evidence: A Verifiable Reasoning Agent with Causal Faithfulness Analysis, https://arxiv.org/pdf/2511.01425, 2025-11-03
2025-11-10 23:25:12,994 - INFO - root - Fetching page 2 with URL: https://arxiv.org/search/?query=CVPR+2026&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=50
2025-11-10 23:25:19,507 - INFO - root - ------------------------------------------------------------------------------------------------------------------------
2025-11-10 23:25:19,509 - INFO - root - File already exists, skipping download: D:\ChatPaper\academic Papers\CVPR 2026\Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness.pdf
2025-11-10 23:25:19,511 - INFO - root - 正在总结论文 1/1: Learning to Seek Evidence: A Verifiable Reasoning Agent with Causal Faithfulness Analysis
2025-11-10 23:28:36,131 - INFO - root - 正在提取论文图片...
2025-11-10 23:28:36,304 - INFO - root - 已保存图片 1/10：./export\images_Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness\figure_1_page2.jpeg
2025-11-10 23:28:36,314 - INFO - root - 已保存图片 2/10：./export\images_Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness\figure_2_page2.jpeg
2025-11-10 23:28:36,325 - INFO - root - 已保存图片 3/10：./export\images_Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness\figure_3_page2.jpeg
2025-11-10 23:28:36,402 - INFO - root - 已保存图片 4/10：./export\images_Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness\figure_4_page2.jpeg
2025-11-10 23:28:36,431 - INFO - root - 已保存图片 5/10：./export\images_Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness\figure_5_page2.jpeg
2025-11-10 23:28:36,450 - INFO - root - 已保存图片 6/10：./export\images_Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness\figure_6_page2.jpeg
2025-11-10 23:28:36,467 - INFO - root - 已保存图片 7/10：./export\images_Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness\figure_7_page2.jpeg
2025-11-10 23:28:36,480 - INFO - root - 已保存图片 8/10：./export\images_Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness\figure_8_page2.jpeg
2025-11-10 23:28:36,522 - INFO - root - 已保存图片 9/10：./export\images_Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness\figure_9_page2.jpeg
2025-11-10 23:28:36,539 - INFO - root - 已保存图片 10/10：./export\images_Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness\figure_10_page2.jpeg
2025-11-10 23:28:36,541 - INFO - root - 成功添加图片 1：./export\images_Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness\figure_1_page2.jpeg
2025-11-10 23:28:36,546 - INFO - root - 成功添加图片 2：./export\images_Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness\figure_2_page2.jpeg
2025-11-10 23:28:36,550 - INFO - root - 成功添加图片 3：./export\images_Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness\figure_3_page2.jpeg
2025-11-10 23:28:36,551 - INFO - root - 成功添加图片 4：./export\images_Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness\figure_4_page2.jpeg
2025-11-10 23:28:36,553 - INFO - root - 成功添加图片 5：./export\images_Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness\figure_5_page2.jpeg
2025-11-10 23:28:36,553 - INFO - root - 成功添加图片 6：./export\images_Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness\figure_6_page2.jpeg
2025-11-10 23:28:36,554 - INFO - root - 成功添加图片 7：./export\images_Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness\figure_7_page2.jpeg
2025-11-10 23:28:36,554 - INFO - root - 成功添加图片 8：./export\images_Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness\figure_8_page2.jpeg
2025-11-10 23:28:36,557 - INFO - root - 成功添加图片 9：./export\images_Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness\figure_9_page2.jpeg
2025-11-10 23:28:36,557 - INFO - root - 成功添加图片 10：./export\images_Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness\figure_10_page2.jpeg
2025-11-10 23:28:42,122 - WARNING - root - 未找到论文信息: 2511.01425
2025-11-10 23:28:42,132 - INFO - root - 论文《Learning to Seek Evidence: A Verifiable Reasoning Agent with Causal Faithfulness Analysis》的分析已保存到 ./export\QAT\Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness.md
2025-11-10 23:28:47,557 - WARNING - root - 未找到论文信息: 2511.01425
2025-11-10 23:28:47,848 - INFO - root - 已生成汇总Excel表格: ./export\QAT\论文汇总_QAT_20251110_232847.xlsx
2025-11-10 23:28:47,849 - INFO - root - 已生成汇总Excel表格: ./export\QAT\论文汇总_QAT_20251110_232847.xlsx
2025-11-10 23:28:47,849 - INFO - root - summary time: 224.52 seconds
2025-11-10 23:36:24,184 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-10 23:36:24,185 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-10 23:36:24,186 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-10 23:36:26,188 - INFO - root - LLMClientManager: 指定使用客户端: Gemini
2025-11-10 23:36:27,300 - INFO - root - GeminiClient: trying model models/gemini-2.5-flash
2025-11-10 23:36:31,172 - INFO - root - GeminiClient: initialized model gemini-2.5-flash
2025-11-10 23:36:31,172 - INFO - root - LLMClientManager: Gemini 客户端初始化成功
2025-11-10 23:36:31,173 - INFO - root - LLMClientManager: switched to Gemini client
2025-11-10 23:36:31,174 - INFO - root - 已手动切换到 LLM 客户端: Gemini
2025-11-10 23:36:31,174 - INFO - root - 使用 LLM 模型: gemini-2.5-flash
2025-11-10 23:36:31,175 - INFO - root - 可用客户端: ['Gemini']
2025-11-10 23:36:31,176 - INFO - root - === 运行配置 ===
2025-11-10 23:36:31,177 - INFO - root - 处理模式: arxiv在线搜索
2025-11-10 23:36:31,177 - INFO - root - 关键词: QAT
2025-11-10 23:36:31,178 - INFO - root - 查询: Quantization-Aware-Training
2025-11-10 23:36:31,179 - INFO - root - 排序: None
2025-11-10 23:36:31,180 - INFO - root - 最近天数: 180
2025-11-10 23:36:31,181 - INFO - root - 最大处理数量: 2
2025-11-10 23:36:31,187 - INFO - root - 保存图片: 是
2025-11-10 23:36:31,188 - INFO - root - 输出语言: 中文
2025-11-10 23:36:31,189 - INFO - root - 强制重新处理: 否
2025-11-10 23:36:31,189 - INFO - root - ====================
2025-11-10 23:36:31,190 - INFO - root - 使用 arXiv 搜索模式（通过 chat_arxiv 模块获取）
2025-11-10 23:36:31,191 - INFO - root - Fetching page 1 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50
2025-11-10 23:36:38,764 - INFO - root - get_all_titles_from_web 
2025-11-10 23:36:38,764 - INFO - root - Page:0, Index:0, Data Efficiency and Transfer Robustness in Biomedical Image Segmentation: A Study of Redundancy and Forgetting with Cellpose, https://arxiv.org/pdf/2511.04803, 2025-11-06
2025-11-10 23:36:38,764 - INFO - root - Page:0, Index:1, A Quantized VAE-MLP Botnet Detection Model: A Systematic Evaluation of Quantization-Aware Training and Post-Training Quantization Strategies, https://arxiv.org/pdf/2511.03201, 2025-11-05
2025-11-10 23:36:38,766 - INFO - root - Page:0, Index:2, FP8-Flow-MoE: A Casting-Free FP8 Recipe without Double Quantization Error, https://arxiv.org/pdf/2511.02302, 2025-11-04
2025-11-10 23:36:38,766 - INFO - root - Page:0, Index:3, Outlier-Aware Post-Training Quantization for Image Super-Resolution, https://arxiv.org/pdf/2511.00682, 2025-11-01
2025-11-10 23:36:38,766 - INFO - root - Page:0, Index:4, Evaluation of Wafer-Scale SOT-MRAM for Analog Crossbar Array Applications, https://arxiv.org/pdf/2510.25853, 2025-11-03
2025-11-10 23:36:38,766 - INFO - root - Page:0, Index:5, Improving the Straight-Through Estimator with Zeroth-Order Information, https://arxiv.org/pdf/2510.23926, 2025-10-27
2025-11-10 23:36:38,767 - INFO - root - Page:0, Index:6, Real-Time Semantic Segmentation on FPGA for Autonomous Vehicles Using LMIINet with the CGRA4ML Framework, https://arxiv.org/pdf/2510.22243, 2025-10-25
2025-11-10 23:36:38,767 - INFO - root - Page:0, Index:7, TernaryCLIP: Efficiently Compressing Vision-Language Models with Ternary Weights and Distilled Knowledge, https://arxiv.org/pdf/2510.21879, 2025-10-23
2025-11-10 23:36:38,767 - INFO - root - Page:0, Index:8, KARIPAP: Quantum-Inspired Tensor Network Compression of Large Language Models Using Infinite Projected Entangled Pair States and Tensor Renormalization Group, https://arxiv.org/pdf/2510.21844, 2025-10-22
2025-11-10 23:36:38,767 - INFO - root - Page:0, Index:9, A Convergence Analysis of Adaptive Optimizers under Floating-point Quantization, https://arxiv.org/pdf/2510.21314, 2025-10-24
2025-11-10 23:36:38,768 - INFO - root - Page:0, Index:10, Adaptive Distribution-aware Quantization for Mixed-Precision Neural Networks, https://arxiv.org/pdf/2510.19760, 2025-10-22
2025-11-10 23:36:38,768 - INFO - root - Page:0, Index:11, CAGE: Curvature-Aware Gradient Estimation For Accurate Quantization-Aware Training, https://arxiv.org/pdf/2510.18784, 2025-10-21
2025-11-10 23:36:38,768 - INFO - root - Page:0, Index:12, Mixed-Precision Quantization for Language Models: Techniques and Prospects, https://arxiv.org/pdf/2510.16805, 2025-10-19
2025-11-10 23:36:38,768 - INFO - root - Page:0, Index:13, SPLite Hand: Sparsity-Aware Lightweight 3D Hand Pose Estimation, https://arxiv.org/pdf/2510.16396, 2025-10-30
2025-11-10 23:36:38,769 - INFO - root - Page:0, Index:14, CTR-LoRA: Curvature-Aware and Trust-Region Guided Low-Rank Adaptation for Large Language Models, https://arxiv.org/pdf/2510.15962, 2025-10-11
2025-11-10 23:36:38,769 - INFO - root - Page:0, Index:15, SANR: Scene-Aware Neural Representation for Light Field Image Compression with Rate-Distortion Optimization, https://arxiv.org/pdf/2510.15775, 2025-10-17
2025-11-10 23:36:38,769 - INFO - root - Page:0, Index:16, SpikeFit: Towards Optimal Deployment of Spiking Networks on Neuromorphic Hardware, https://arxiv.org/pdf/2510.15542, 2025-10-31
2025-11-10 23:36:38,770 - INFO - root - Page:0, Index:17, GRank: Towards Target-Aware and Streamlined Industrial Retrieval with a Generate-Rank Framework, https://arxiv.org/pdf/2510.15299, 2025-10-17
2025-11-10 23:36:38,770 - INFO - root - Page:0, Index:18, SaLon3R: Structure-aware Long-term Generalizable 3D Reconstruction from Unposed Images, https://arxiv.org/pdf/2510.15072, 2025-10-16
2025-11-10 23:36:38,771 - INFO - root - Page:0, Index:19, FraQAT: Quantization Aware Training with Fractional bits, https://arxiv.org/pdf/2510.14823, 2025-10-16
2025-11-10 23:36:38,771 - INFO - root - Page:0, Index:20, Computing-In-Memory Aware Model Adaption For Edge Devices, https://arxiv.org/pdf/2510.14379, 2025-10-16
2025-11-10 23:36:38,772 - INFO - root - Page:0, Index:21, Invited Paper: BitMedViT: Ternary-Quantized Vision Transformer for Medical AI Assistants on the Edge, https://arxiv.org/pdf/2510.13760, 2025-11-04
2025-11-10 23:36:38,774 - INFO - root - Page:0, Index:22, NeuroRVQ: Multi-Scale EEG Tokenization for Generative Large Brainwave Models, https://arxiv.org/pdf/2510.13068, 2025-10-14
2025-11-10 23:36:38,775 - INFO - root - Page:0, Index:23, Detect Anything via Next Point Prediction, https://arxiv.org/pdf/2510.12798, 2025-10-14
2025-11-10 23:36:38,776 - INFO - root - Page:0, Index:24, AndesVL Technical Report: An Efficient Mobile-side Multimodal Large Language Model, https://arxiv.org/pdf/2510.11496, 2025-10-14
2025-11-10 23:36:38,776 - INFO - root - Page:0, Index:25, Rescaling-Aware Training for Efficient Deployment of Deep Learning Models on Full-Integer Hardware, https://arxiv.org/pdf/2510.11484, 2025-10-13
2025-11-10 23:36:38,776 - INFO - root - Page:0, Index:26, SASER: Stego attacks on open-source LLMs, https://arxiv.org/pdf/2510.10486, 2025-10-12
2025-11-10 23:36:38,778 - INFO - root - Page:0, Index:27, Ultralytics YOLO Evolution: An Overview of YOLO26, YOLO11, YOLOv8 and YOLOv5 Object Detectors for Computer Vision and Pattern Recognition, https://arxiv.org/pdf/2510.09653, 2025-10-15
2025-11-10 23:36:38,778 - INFO - root - Page:0, Index:28, A Theoretically-Grounded Codebook for Digital Semantic Communications, https://arxiv.org/pdf/2510.07108, 2025-10-14
2025-11-10 23:36:38,778 - INFO - root - Page:0, Index:29, QuantDemoire: Quantization with Outlier Aware for Image Demoiréing, https://arxiv.org/pdf/2510.04066, 2025-10-05
2025-11-10 23:36:38,779 - INFO - root - Page:0, Index:30, Adaptively Sampling-Reusing-Mixing Decomposed Gradients to Speed Up Sharpness Aware Minimization, https://arxiv.org/pdf/2510.03763, 2025-10-04
2025-11-10 23:36:38,780 - INFO - root - Page:0, Index:31, Quant-dLLM: Post-Training Extreme Low-Bit Quantization for Diffusion Large Language Models, https://arxiv.org/pdf/2510.03274, 2025-09-27
2025-11-10 23:36:38,780 - INFO - root - Page:0, Index:32, PT$^2$-LLM: Post-Training Ternarization for Large Language Models, https://arxiv.org/pdf/2510.03267, 2025-09-26
2025-11-10 23:36:38,780 - INFO - root - Page:0, Index:33, Purrception: Variational Flow Matching for Vector-Quantized Image Generation, https://arxiv.org/pdf/2510.01478, 2025-10-01
2025-11-10 23:36:38,782 - INFO - root - Page:0, Index:34, Post-Training Quantization for Audio Diffusion Transformers, https://arxiv.org/pdf/2510.00313, 2025-09-30
2025-11-10 23:36:38,783 - INFO - root - Page:0, Index:35, Rethinking RoPE Scaling in Quantized LLM: Theory, Outlier, and Channel-Band Analysis with Weight Rescaling, https://arxiv.org/pdf/2510.00028, 2025-09-25
2025-11-10 23:36:38,784 - INFO - root - Page:0, Index:36, Post-Training Quantization via Residual Truncation and Zero Suppression for Diffusion Models, https://arxiv.org/pdf/2509.26436, 2025-09-30
2025-11-10 23:36:38,785 - INFO - root - Page:0, Index:37, Cat: Post-Training Quantization Error Reduction via Cluster-based Affine Transformation, https://arxiv.org/pdf/2509.26277, 2025-10-07
2025-11-10 23:36:38,785 - INFO - root - Page:0, Index:38, CAST: Continuous and Differentiable Semi-Structured Sparsity-Aware Training for Large Language Models, https://arxiv.org/pdf/2509.25996, 2025-09-30
2025-11-10 23:36:38,786 - INFO - root - Page:0, Index:39, Norm-Q: Effective Compression Method for Hidden Markov Models in Neuro-Symbolic Applications, https://arxiv.org/pdf/2509.25439, 2025-09-29
2025-11-10 23:36:38,786 - INFO - root - Page:0, Index:40, On-the-Fly Adaptation to Quantization: Configuration-Aware LoRA for Efficient Fine-Tuning of Quantized LLMs, https://arxiv.org/pdf/2509.25214, 2025-09-22
2025-11-10 23:36:38,786 - INFO - root - Page:0, Index:41, VoxCPM: Tokenizer-Free TTS for Context-Aware Speech Generation and True-to-Life Voice Cloning, https://arxiv.org/pdf/2509.24650, 2025-09-29
2025-11-10 23:36:38,787 - INFO - root - Page:0, Index:42, S$^2$NN: Sub-bit Spiking Neural Networks, https://arxiv.org/pdf/2509.24266, 2025-10-24
2025-11-10 23:36:38,787 - INFO - root - Page:0, Index:43, Tequila: Trapping-free Ternary Quantization for Large Language Models, https://arxiv.org/pdf/2509.23809, 2025-10-17
2025-11-10 23:36:38,787 - INFO - root - Page:0, Index:44, Texture Vector-Quantization and Reconstruction Aware Prediction for Generative Super-Resolution, https://arxiv.org/pdf/2509.23774, 2025-09-30
2025-11-10 23:36:38,788 - INFO - root - Page:0, Index:45, RobuQ: Pushing DiTs to W1.58A2 via Robust Activation Quantization, https://arxiv.org/pdf/2509.23582, 2025-09-27
2025-11-10 23:36:38,788 - INFO - root - Page:0, Index:46, Beyond Outliers: A Study of Optimizers Under Quantization, https://arxiv.org/pdf/2509.23500, 2025-10-02
2025-11-10 23:36:38,793 - INFO - root - Page:0, Index:47, Compute-Optimal Quantization-Aware Training, https://arxiv.org/pdf/2509.22935, 2025-09-26
2025-11-10 23:36:38,794 - INFO - root - Page:0, Index:48, COSPADI: Compressing LLMs via Calibration-Guided Sparse Dictionary Learning, https://arxiv.org/pdf/2509.22075, 2025-10-06
2025-11-10 23:36:38,796 - INFO - root - Page:0, Index:49, SlimDiff: Training-Free, Activation-Guided Hands-free Slimming of Diffusion Models, https://arxiv.org/pdf/2509.21498, 2025-09-25
2025-11-10 23:36:38,797 - INFO - root - Fetching page 2 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=50
2025-11-10 23:36:46,495 - INFO - root - get_all_titles_from_web 
2025-11-10 23:36:46,499 - INFO - root - Page:1, Index:0, Quantized Visual Geometry Grounded Transformer, https://arxiv.org/pdf/2509.21302, 2025-09-29
2025-11-10 23:36:46,550 - INFO - root - Page:1, Index:1, Can Less Precise Be More Reliable? A Systematic Evaluation of Quantization's Impact on CLIP Beyond Accuracy, https://arxiv.org/pdf/2509.21173, 2025-10-27
2025-11-10 23:36:46,575 - INFO - root - Page:1, Index:2, Punching Above Precision: Small Quantized Model Distillation with Learnable Regularizer, https://arxiv.org/pdf/2509.20854, 2025-09-25
2025-11-10 23:36:46,623 - INFO - root - Page:1, Index:3, TinyEcoWeedNet: Edge Efficient Real-Time Aerial Agricultural Weed Detection, https://arxiv.org/pdf/2509.18193, 2025-09-19
2025-11-10 23:36:46,626 - INFO - root - Page:1, Index:4, SBVR: Summation of BitVector Representation for Efficient LLM Quantization, https://arxiv.org/pdf/2509.18172, 2025-09-17
2025-11-10 23:36:46,642 - INFO - root - Page:1, Index:5, QWHA: Quantization-Aware Walsh-Hadamard Adaptation for Parameter-Efficient Fine-Tuning on Large Language Models, https://arxiv.org/pdf/2509.17428, 2025-09-26
2025-11-10 23:36:46,644 - INFO - root - Page:1, Index:6, PTQTP: Post-Training Quantization to Trit-Planes for Large Language Models, https://arxiv.org/pdf/2509.16989, 2025-10-28
2025-11-10 23:36:46,645 - INFO - root - Page:1, Index:7, MEC-Quant: Maximum Entropy Coding for Extremely Low Bit Quantization-Aware Training, https://arxiv.org/pdf/2509.15514, 2025-09-18
2025-11-10 23:36:46,646 - INFO - root - Page:1, Index:8, Q-ROAR: Outlier-Aware Rescaling for RoPE Position Interpolation in Quantized Long-Context LLMs, https://arxiv.org/pdf/2509.14391, 2025-09-17
2025-11-10 23:36:46,649 - INFO - root - Page:1, Index:9, Efficient Quantization-Aware Neural Receivers: Beyond Post-Training Quantization, https://arxiv.org/pdf/2509.13786, 2025-09-19
2025-11-10 23:36:46,651 - INFO - root - Page:1, Index:10, Rate-Distortion Limits for Multimodal Retrieval: Theory, Optimal Codes, and Finite-Sample Guarantees, https://arxiv.org/pdf/2509.11054, 2025-09-13
2025-11-10 23:36:46,654 - INFO - root - Page:1, Index:11, SQAP-VLA: A Synergistic Quantization-Aware Pruning Framework for High-Performance Vision-Language-Action Models, https://arxiv.org/pdf/2509.09090, 2025-09-10
2025-11-10 23:36:46,655 - INFO - root - Page:1, Index:12, CSI Compression Beyond Latents: End-to-End Hybrid Attention-CNN Networks with Entropy Regularization, https://arxiv.org/pdf/2509.08776, 2025-09-10
2025-11-10 23:36:46,655 - INFO - root - Page:1, Index:13, Explaining How Quantization Disparately Skews a Model, https://arxiv.org/pdf/2509.07222, 2025-09-08
2025-11-10 23:36:46,656 - INFO - root - Page:1, Index:14, LoaQ: Layer-wise Output Approximation Quantization, https://arxiv.org/pdf/2509.06297, 2025-09-07
2025-11-10 23:36:46,657 - INFO - root - Page:1, Index:15, FineServe: Precision-Aware KV Slab and Two-Level Scheduling for Heterogeneous Precision LLM Serving, https://arxiv.org/pdf/2509.06261, 2025-09-14
2025-11-10 23:36:46,657 - INFO - root - Page:1, Index:16, Sensitivity-Aware Post-Training Quantization for Deep Neural Networks, https://arxiv.org/pdf/2509.05576, 2025-09-05
2025-11-10 23:36:46,658 - INFO - root - Page:1, Index:17, SuperSNN: A Hardware-Aware Framework for Physically Realizable, High-Performance Superconducting Spiking Neural Network Chips, https://arxiv.org/pdf/2509.05532, 2025-09-05
2025-11-10 23:36:46,667 - INFO - root - Page:1, Index:18, Data-Augmented Quantization-Aware Knowledge Distillation, https://arxiv.org/pdf/2509.03850, 2025-09-03
2025-11-10 23:36:46,676 - INFO - root - Page:1, Index:19, DPQuant: Efficient and Differentially-Private Model Training via Dynamic Quantization Scheduling, https://arxiv.org/pdf/2509.03472, 2025-09-03
2025-11-10 23:36:46,687 - INFO - root - Page:1, Index:20, Empowering Large Language Model for Sequential Recommendation via Multimodal Embeddings and Semantic IDs, https://arxiv.org/pdf/2509.02017, 2025-09-02
2025-11-10 23:36:46,688 - INFO - root - Page:1, Index:21, Q-Sched: Pushing the Boundaries of Few-Step Diffusion Models with Quantization-Aware Scheduling, https://arxiv.org/pdf/2509.01624, 2025-09-01
2025-11-10 23:36:46,690 - INFO - root - Page:1, Index:22, Quantization Meets OOD: Generalizable Quantization-aware Training from a Flatness Perspective, https://arxiv.org/pdf/2509.00859, 2025-08-31
2025-11-10 23:36:46,696 - INFO - root - Page:1, Index:23, Progressive Element-wise Gradient Estimation for Neural Network Quantization, https://arxiv.org/pdf/2509.00097, 2025-08-27
2025-11-10 23:36:46,706 - INFO - root - Page:1, Index:24, End-to-End On-Device Quantization-Aware Training for LLMs at Inference Cost, https://arxiv.org/pdf/2509.00031, 2025-09-29
2025-11-10 23:36:46,708 - INFO - root - Page:1, Index:25, Quantization Robustness to Input Degradations for Object Detection, https://arxiv.org/pdf/2508.19600, 2025-08-27
2025-11-10 23:36:46,708 - INFO - root - Page:1, Index:26, Scaling Laws for Task-Stratified Knowledge in Post-Training Quantized Large Language Models, https://arxiv.org/pdf/2508.18609, 2025-08-27
2025-11-10 23:36:46,712 - INFO - root - Page:1, Index:27, AQ-PCDSys: An Adaptive Quantized Planetary Crater Detection System for Autonomous Space Exploration, https://arxiv.org/pdf/2508.18025, 2025-08-25
2025-11-10 23:36:46,713 - INFO - root - Page:1, Index:28, TaDiCodec: Text-aware Diffusion Speech Tokenizer for Speech Language Modeling, https://arxiv.org/pdf/2508.16790, 2025-08-22
2025-11-10 23:36:46,714 - INFO - root - Page:1, Index:29, A Node-Aware Dynamic Quantization Approach for Graph Collaborative Filtering, https://arxiv.org/pdf/2508.16516, 2025-08-22
2025-11-10 23:36:46,717 - INFO - root - Page:1, Index:30, JEDI-linear: Fast and Efficient Graph Neural Networks for Jet Tagging on FPGAs, https://arxiv.org/pdf/2508.15468, 2025-08-21
2025-11-10 23:36:46,718 - INFO - root - Page:1, Index:31, MMQ: Multimodal Mixture-of-Quantization Tokenization for Semantic ID Generation and User Behavioral Adaptation, https://arxiv.org/pdf/2508.15281, 2025-08-21
2025-11-10 23:36:46,720 - INFO - root - Page:1, Index:32, DLLMQuant: Quantizing Diffusion-based Large Language Models, https://arxiv.org/pdf/2508.14090, 2025-08-25
2025-11-10 23:36:46,721 - INFO - root - Page:1, Index:33, Automated Energy-Aware Time-Series Model Deployment on Embedded FPGAs for Resilient Combined Sewer Overflow Management, https://arxiv.org/pdf/2508.13905, 2025-08-19
2025-11-10 23:36:46,722 - INFO - root - Page:1, Index:34, XR-NPE: High-Throughput Mixed-precision SIMD Neural Processing Engine for Extended Reality Perception Workloads, https://arxiv.org/pdf/2508.13049, 2025-08-18
2025-11-10 23:36:46,722 - INFO - root - Page:1, Index:35, Exploring Self-Supervised Audio Models for Generalized Anomalous Sound Detection, https://arxiv.org/pdf/2508.12230, 2025-08-17
2025-11-10 23:36:46,723 - INFO - root - Page:1, Index:36, TriQDef: Disrupting Semantic and Gradient Alignment to Prevent Adversarial Patch Transferability in Quantized Neural Networks, https://arxiv.org/pdf/2508.12132, 2025-08-16
2025-11-10 23:36:46,724 - INFO - root - Page:1, Index:37, Error Propagation Mechanisms and Compensation Strategies for Quantized Diffusion, https://arxiv.org/pdf/2508.12094, 2025-10-13
2025-11-10 23:36:46,727 - INFO - root - Page:1, Index:38, Extending Straight-Through Estimation for Robust Neural Networks on Analog CIM Hardware, https://arxiv.org/pdf/2508.11940, 2025-08-16
2025-11-10 23:36:46,730 - INFO - root - Page:1, Index:39, PTQAT: A Hybrid Parameter-Efficient Quantization Algorithm for 3D Perception Tasks, https://arxiv.org/pdf/2508.10557, 2025-08-15
2025-11-10 23:36:46,734 - INFO - root - Page:1, Index:40, MiCo: End-to-End Mixed Precision Neural Network Co-Exploration Framework for Edge AI, https://arxiv.org/pdf/2508.09500, 2025-08-13
2025-11-10 23:36:46,735 - INFO - root - Page:1, Index:41, SPARC: Soft Probabilistic Adaptive multi-interest Retrieval Model via Codebooks for recommender system, https://arxiv.org/pdf/2508.09090, 2025-08-12
2025-11-10 23:36:46,738 - INFO - root - Page:1, Index:42, Rethinking 1-bit Optimization Leveraging Pre-trained Large Language Models, https://arxiv.org/pdf/2508.06974, 2025-08-09
2025-11-10 23:36:46,738 - INFO - root - Page:1, Index:43, Efficient Deep Neural Receiver with Post-Training Quantization, https://arxiv.org/pdf/2508.06275, 2025-08-08
2025-11-10 23:36:46,742 - INFO - root - Page:1, Index:44, iFairy: the First 2-bit Complex LLM with All Parameters in $\{\pm1, \pm i\}$, https://arxiv.org/pdf/2508.05571, 2025-08-16
2025-11-10 23:36:46,742 - INFO - root - Page:1, Index:45, S$^2$Q-VDiT: Accurate Quantized Video Diffusion Transformer with Salient Data and Sparse Token Distillation, https://arxiv.org/pdf/2508.04016, 2025-10-27
2025-11-10 23:36:46,744 - INFO - root - Page:1, Index:46, LRQ-DiT: Log-Rotation Post-Training Quantization of Diffusion Transformers for Image and Video Generation, https://arxiv.org/pdf/2508.03485, 2025-09-23
2025-11-10 23:36:46,745 - INFO - root - Page:1, Index:47, VLMQ: Efficient Post-Training Quantization for Large Vision-Language Models via Hessian Augmentation, https://arxiv.org/pdf/2508.03351, 2025-08-05
2025-11-10 23:36:46,747 - INFO - root - Page:1, Index:48, TF-MLPNet: Tiny Real-Time Neural Speech Separation, https://arxiv.org/pdf/2508.03047, 2025-08-04
2025-11-10 23:36:46,758 - INFO - root - Page:1, Index:49, SaviorRec: Semantic-Behavior Alignment for Cold-Start Recommendation, https://arxiv.org/pdf/2508.01375, 2025-08-02
2025-11-10 23:36:46,763 - INFO - root - Fetching page 3 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=100
2025-11-10 23:36:53,502 - INFO - root - get_all_titles_from_web 
2025-11-10 23:36:53,504 - INFO - root - Page:2, Index:0, MixA-Q: Revisiting Activation Sparsity for Vision Transformers from a Mixed-Precision Quantization Perspective, https://arxiv.org/pdf/2507.19131, 2025-07-25
2025-11-10 23:36:53,508 - INFO - root - Page:2, Index:1, Enhancing Quantization-Aware Training on Edge Devices via Relative Entropy Coreset Selection and Cascaded Layer Correction, https://arxiv.org/pdf/2507.17768, 2025-07-16
2025-11-10 23:36:53,509 - INFO - root - Page:2, Index:2, SiLQ: Simple Large Language Model Quantization-Aware Training, https://arxiv.org/pdf/2507.16933, 2025-07-22
2025-11-10 23:36:53,511 - INFO - root - Page:2, Index:3, Task-Specific Zero-shot Quantization-Aware Training for Object Detection, https://arxiv.org/pdf/2507.16782, 2025-07-22
2025-11-10 23:36:53,512 - INFO - root - Page:2, Index:4, TorchAO: PyTorch-Native Training-to-Serving Model Optimization, https://arxiv.org/pdf/2507.16099, 2025-07-21
2025-11-10 23:36:53,516 - INFO - root - Page:2, Index:5, SegQuant: A Semantics-Aware and Generalizable Quantization Framework for Diffusion Models, https://arxiv.org/pdf/2507.14811, 2025-08-27
2025-11-10 23:36:53,547 - INFO - root - Page:2, Index:6, Apple Intelligence Foundation Language Models: Tech Report 2025, https://arxiv.org/pdf/2507.13575, 2025-08-27
2025-11-10 23:36:53,547 - INFO - root - Page:2, Index:7, Generative Multi-Target Cross-Domain Recommendation, https://arxiv.org/pdf/2507.12871, 2025-08-07
2025-11-10 23:36:53,547 - INFO - root - Page:2, Index:8, DAF: An Efficient End-to-End Dynamic Activation Framework for on-Device DNN Training, https://arxiv.org/pdf/2507.07149, 2025-07-09
2025-11-10 23:36:53,548 - INFO - root - Page:2, Index:9, Opto-ViT: Architecting a Near-Sensor Region of Interest-Aware Vision Transformer Accelerator with Silicon Photonics, https://arxiv.org/pdf/2507.07044, 2025-07-15
2025-11-10 23:36:53,548 - INFO - root - Page:2, Index:10, QS4D: Quantization-aware training for efficient hardware deployment of structured state-space sequential models, https://arxiv.org/pdf/2507.06079, 2025-07-08
2025-11-10 23:36:53,548 - INFO - root - Page:2, Index:11, GSVR: 2D Gaussian-based Video Representation for 800+ FPS with Hybrid Deformation Field, https://arxiv.org/pdf/2507.05594, 2025-07-07
2025-11-10 23:36:53,553 - INFO - root - Page:2, Index:12, Hita: Holistic Tokenizer for Autoregressive Image Generation, https://arxiv.org/pdf/2507.02358, 2025-07-11
2025-11-10 23:36:53,563 - INFO - root - Page:2, Index:13, QPART: Adaptive Model Quantization and Dynamic Workload Balancing for Accuracy-aware Edge Inference, https://arxiv.org/pdf/2506.23934, 2025-06-30
2025-11-10 23:36:53,575 - INFO - root - Page:2, Index:14, FedWSQ: Efficient Federated Learning with Weight Standardization and Distribution-Aware Non-Uniform Quantization, https://arxiv.org/pdf/2506.23516, 2025-07-21
2025-11-10 23:36:53,578 - INFO - root - Page:2, Index:15, Spectra 1.1: Scaling Laws and Efficient Inference for Ternary Language Models, https://arxiv.org/pdf/2506.23025, 2025-06-28
2025-11-10 23:36:53,580 - INFO - root - Page:2, Index:16, Joint Quantization and Pruning Neural Networks Approach: A Case Study on FSO Receivers, https://arxiv.org/pdf/2506.20084, 2025-06-24
2025-11-10 23:36:53,581 - INFO - root - Page:2, Index:17, Single-step Diffusion for Image Compression at Ultra-Low Bitrates, https://arxiv.org/pdf/2506.16572, 2025-09-22
2025-11-10 23:36:53,582 - INFO - root - Page:2, Index:18, LittleBit: Ultra Low-Bit Quantization via Latent Factorization, https://arxiv.org/pdf/2506.13771, 2025-10-28
2025-11-10 23:36:53,615 - INFO - root - Page:2, Index:19, MARCO: Hardware-Aware Neural Architecture Search for Edge Devices with Multi-Agent Reinforcement Learning and Conformal Prediction Filtering, https://arxiv.org/pdf/2506.13755, 2025-06-16
2025-11-10 23:36:53,620 - INFO - root - Page:2, Index:20, EAQuant: Enhancing Post-Training Quantization for MoE Models via Expert-Aware Optimization, https://arxiv.org/pdf/2506.13329, 2025-07-04
2025-11-10 23:36:53,624 - INFO - root - Page:2, Index:21, Towards Neural Audio Codec Source Parsing, https://arxiv.org/pdf/2506.12627, 2025-06-14
2025-11-10 23:36:53,625 - INFO - root - Page:2, Index:22, Quantizing Small-Scale State-Space Models for Edge AI, https://arxiv.org/pdf/2506.12480, 2025-06-14
2025-11-10 23:36:53,625 - INFO - root - Page:2, Index:23, EMLoC: Emulator-based Memory-efficient Fine-tuning with LoRA Correction, https://arxiv.org/pdf/2506.12015, 2025-06-13
2025-11-10 23:36:53,626 - INFO - root - Page:2, Index:24, Compression Aware Certified Training, https://arxiv.org/pdf/2506.11992, 2025-06-13
2025-11-10 23:36:53,628 - INFO - root - Page:2, Index:25, GPLQ: A General, Practical, and Lightning QAT Method for Vision Transformers, https://arxiv.org/pdf/2506.11784, 2025-06-13
2025-11-10 23:36:53,631 - INFO - root - Page:2, Index:26, TruncQuant: Truncation-Ready Quantization for DNNs with Flexible Weight Bit Precision, https://arxiv.org/pdf/2506.11431, 2025-06-12
2025-11-10 23:36:53,635 - INFO - root - Page:2, Index:27, EfficientQuant: An Efficient Post-Training Quantization for CNN-Transformer Hybrid Models on Edge Devices, https://arxiv.org/pdf/2506.11093, 2025-06-05
2025-11-10 23:36:53,637 - INFO - root - Page:2, Index:28, Starting Positions Matter: A Study on Better Weight Initialization for Neural Network Quantization, https://arxiv.org/pdf/2506.10463, 2025-06-12
2025-11-10 23:36:53,638 - INFO - root - Page:2, Index:29, AWP: Activation-Aware Weight Pruning and Quantization with Projected Gradient Descent, https://arxiv.org/pdf/2506.10205, 2025-06-11
2025-11-10 23:36:53,646 - INFO - root - Page:2, Index:30, Q-SAM2: Accurate Quantization for Segment Anything Model 2, https://arxiv.org/pdf/2506.09782, 2025-06-11
2025-11-10 23:36:53,648 - INFO - root - Page:2, Index:31, Unifying Block-wise PTQ and Distillation-based QAT for Progressive Quantization toward 2-bit Instruction-Tuned LLMs, https://arxiv.org/pdf/2506.09104, 2025-06-10
2025-11-10 23:36:53,648 - INFO - root - Page:2, Index:32, Implementing Keyword Spotting on the MCUX947 Microcontroller with Integrated NPU, https://arxiv.org/pdf/2506.08911, 2025-06-10
2025-11-10 23:36:53,650 - INFO - root - Page:2, Index:33, POLARON: Precision-aware On-device Learning and Adaptive Runtime-cONfigurable AI acceleration, https://arxiv.org/pdf/2506.08785, 2025-06-10
2025-11-10 23:36:53,652 - INFO - root - Page:2, Index:34, MoQAE: Mixed-Precision Quantization for Long-Context LLM Inference via Mixture of Quantization-Aware Experts, https://arxiv.org/pdf/2506.07533, 2025-06-09
2025-11-10 23:36:53,653 - INFO - root - Page:2, Index:35, BitVLA: 1-bit Vision-Language-Action Models for Robotics Manipulation, https://arxiv.org/pdf/2506.07530, 2025-06-09
2025-11-10 23:36:53,654 - INFO - root - Page:2, Index:36, RecGPT: A Foundation Model for Sequential Recommendation, https://arxiv.org/pdf/2506.06270, 2025-06-12
2025-11-10 23:36:53,654 - INFO - root - Page:2, Index:37, FPSAttention: Training-Aware FP8 and Sparsity Co-Design for Fast Video Diffusion, https://arxiv.org/pdf/2506.04648, 2025-06-05
2025-11-10 23:36:53,657 - INFO - root - Page:2, Index:38, BitTTS: Highly Compact Text-to-Speech Using 1.58-bit Quantization and Weight Indexing, https://arxiv.org/pdf/2506.03515, 2025-06-03
2025-11-10 23:36:53,658 - INFO - root - Page:2, Index:39, ShapeLLM-Omni: A Native Multimodal LLM for 3D Generation and Understanding, https://arxiv.org/pdf/2506.01853, 2025-06-02
2025-11-10 23:36:53,668 - INFO - root - Page:2, Index:40, Movable Antenna Enhanced Federated Fine-Tuning of Large Language Models via Hybrid Client Selection Optimization, https://arxiv.org/pdf/2506.00011, 2025-10-26
2025-11-10 23:36:53,670 - INFO - root - Page:2, Index:41, Running Conventional Automatic Speech Recognition on Memristor Hardware: A Simulated Approach, https://arxiv.org/pdf/2505.24721, 2025-05-30
2025-11-10 23:36:53,670 - INFO - root - Page:2, Index:42, GARLIC: GAussian Representation LearnIng for spaCe partitioning, https://arxiv.org/pdf/2505.24608, 2025-10-02
2025-11-10 23:36:53,671 - INFO - root - Page:2, Index:43, AutoChemSchematic AI: Agentic Physics-Aware Automation for Chemical Manufacturing Scale-Up, https://arxiv.org/pdf/2505.24584, 2025-08-18
2025-11-10 23:36:53,676 - INFO - root - Page:2, Index:44, Model-Preserving Adaptive Rounding, https://arxiv.org/pdf/2505.22988, 2025-09-25
2025-11-10 23:36:53,679 - INFO - root - Page:2, Index:45, Highly Efficient and Effective LLMs with Multi-Boolean Architectures, https://arxiv.org/pdf/2505.22811, 2025-10-03
2025-11-10 23:36:53,679 - INFO - root - Page:2, Index:46, Pioneering 4-Bit FP Quantization for Diffusion Models: Mixup-Sign Quantization and Timestep-Aware Fine-Tuning, https://arxiv.org/pdf/2505.21591, 2025-05-27
2025-11-10 23:36:53,683 - INFO - root - Page:2, Index:47, Frequency Composition for Compressed and Domain-Adaptive Neural Networks, https://arxiv.org/pdf/2505.20890, 2025-05-27
2025-11-10 23:36:53,692 - INFO - root - Page:2, Index:48, MoPFormer: Motion-Primitive Transformer for Wearable-Sensor Activity Recognition, https://arxiv.org/pdf/2505.20744, 2025-10-27
2025-11-10 23:36:53,702 - INFO - root - Fetching page 4 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=150
2025-11-10 23:37:01,052 - INFO - root - get_all_titles_from_web 
2025-11-10 23:37:01,053 - INFO - root - Page:3, Index:0, Optimizing edge AI models on HPC systems with the edge in the loop, https://arxiv.org/pdf/2505.19995, 2025-05-26
2025-11-10 23:37:01,053 - INFO - root - Page:3, Index:1, DPASyn: Mechanism-Aware Drug Synergy Prediction via Dual Attention and Precision-Aware Quantization, https://arxiv.org/pdf/2505.19144, 2025-09-20
2025-11-10 23:37:01,053 - INFO - root - Page:3, Index:2, Reducing Storage of Pretrained Neural Networks by Rate-Constrained Quantization and Entropy Coding, https://arxiv.org/pdf/2505.18758, 2025-05-24
2025-11-10 23:37:01,056 - INFO - root - Page:3, Index:3, Beyond Discreteness: Finite-Sample Analysis of Straight-Through Estimator for Quantization, https://arxiv.org/pdf/2505.18113, 2025-05-23
2025-11-10 23:37:01,056 - INFO - root - Page:3, Index:4, Automating Versatile Time-Series Analysis with Tiny Transformers on Embedded FPGAs, https://arxiv.org/pdf/2505.17662, 2025-09-19
2025-11-10 23:37:01,056 - INFO - root - Page:3, Index:5, FPQVAR: Floating Point Quantization for Visual Autoregressive Model with FPGA Hardware Co-design, https://arxiv.org/pdf/2505.16335, 2025-05-22
2025-11-10 23:37:01,056 - INFO - root - Page:3, Index:6, Saliency-Aware Quantized Imitation Learning for Efficient Robotic Control, https://arxiv.org/pdf/2505.15304, 2025-05-30
2025-11-10 23:37:01,058 - INFO - root - Page:3, Index:7, Scaling Law for Quantization-Aware Training, https://arxiv.org/pdf/2505.14302, 2025-05-20
2025-11-10 23:37:01,059 - INFO - root - Page:3, Index:8, Automatic mixed precision for optimizing gained time with constrained loss mean-squared-error based on model partition to sequential sub-graphs, https://arxiv.org/pdf/2505.13060, 2025-05-19
2025-11-10 23:37:01,060 - INFO - root - Page:3, Index:9, Deep Unfolding with Kernel-based Quantization in MIMO Detection, https://arxiv.org/pdf/2505.12736, 2025-05-19
2025-11-10 23:37:01,060 - INFO - root - Page:3, Index:10, FedHQ: Hybrid Runtime Quantization for Federated Learning, https://arxiv.org/pdf/2505.11982, 2025-05-17
2025-11-10 23:37:01,060 - INFO - root - Page:3, Index:11, QVGen: Pushing the Limit of Quantized Video Generative Models, https://arxiv.org/pdf/2505.11497, 2025-09-27
2025-11-10 23:37:01,066 - INFO - root - Page:3, Index:12, EA-3DGS: Efficient and Adaptive 3D Gaussians with Highly Enhanced Quality for outdoor scenes, https://arxiv.org/pdf/2505.10787, 2025-05-15
2025-11-10 23:37:01,066 - INFO - root - Page:3, Index:13, PROM: Prioritize Reduction of Multiplications Over Lower Bit-Widths for Efficient CNNs, https://arxiv.org/pdf/2505.03254, 2025-08-06
2025-11-10 23:37:01,066 - INFO - root - Page:3, Index:14, ICQuant: Index Coding enables Low-bit LLM Quantization, https://arxiv.org/pdf/2505.00850, 2025-08-24
2025-11-10 23:37:01,067 - INFO - root - Page:3, Index:15, Enhancing Ultra-Low-Bit Quantization of Large Language Models Through Saliency-Aware Partial Retraining, https://arxiv.org/pdf/2504.13932, 2025-07-30
2025-11-10 23:37:01,067 - INFO - root - Page:3, Index:16, Achieving binary weight and activation for LLMs using Post-Training Quantization, https://arxiv.org/pdf/2504.05352, 2025-06-30
2025-11-10 23:37:01,067 - INFO - root - Page:3, Index:17, Wireless Hearables With Programmable Speech AI Accelerators, https://arxiv.org/pdf/2503.18698, 2025-10-21
2025-11-10 23:37:01,067 - INFO - root - Page:3, Index:18, GranQ: Efficient Channel-wise Quantization via Vectorized Pre-Scaling for Zero-Shot QAT, https://arxiv.org/pdf/2503.18339, 2025-10-15
2025-11-10 23:37:01,069 - INFO - root - Page:3, Index:19, CompMarkGS: Robust Watermarking for Compressed 3D Gaussian Splatting, https://arxiv.org/pdf/2503.12836, 2025-09-29
2025-11-10 23:37:01,070 - INFO - root - Page:3, Index:20, AHCPTQ: Accurate and Hardware-Compatible Post-Training Quantization for Segment Anything Model, https://arxiv.org/pdf/2503.03088, 2025-07-11
2025-11-10 23:37:01,073 - INFO - root - Page:3, Index:21, Teaching Metric Distance to Discrete Autoregressive Language Models, https://arxiv.org/pdf/2503.02379, 2025-10-07
2025-11-10 23:37:01,076 - INFO - root - Fetching page 5 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=200
2025-11-10 23:37:07,738 - INFO - root - get_all_titles_from_web 
2025-11-10 23:37:07,738 - INFO - root - Page:4, Index:0, Regularization-based Framework for Quantization-, Fault- and Variability-Aware Training, https://arxiv.org/pdf/2503.01297, 2025-07-12
2025-11-10 23:37:07,738 - INFO - root - Page:4, Index:1, Investigating the Impact of Quantization Methods on the Safety and Reliability of Large Language Models, https://arxiv.org/pdf/2502.15799, 2025-06-29
2025-11-10 23:37:07,740 - INFO - root - Page:4, Index:2, Rotate, Clip, and Partition: Towards W2A4KV4 Quantization by Integrating Rotation and Learnable Non-uniform Quantizer, https://arxiv.org/pdf/2502.15779, 2025-09-01
2025-11-10 23:37:07,740 - INFO - root - Page:4, Index:3, RoSTE: An Efficient Quantization-Aware Supervised Fine-Tuning Approach for Large Language Models, https://arxiv.org/pdf/2502.09003, 2025-06-05
2025-11-10 23:37:07,740 - INFO - root - Page:4, Index:4, Spatial Degradation-Aware and Temporal Consistent Diffusion Model for Compressed Video Super-Resolution, https://arxiv.org/pdf/2502.07381, 2025-06-27
2025-11-10 23:37:07,740 - INFO - root - Page:4, Index:5, QuEST: Stable Training of LLMs with 1-Bit Weights and Activations, https://arxiv.org/pdf/2502.05003, 2025-06-10
2025-11-10 23:37:07,741 - INFO - root - Page:4, Index:6, HALO: Hadamard-Assisted Lower-Precision Optimization for LLMs, https://arxiv.org/pdf/2501.02625, 2025-11-05
2025-11-10 23:37:07,741 - INFO - root - Page:4, Index:7, TAR3D: Creating High-Quality 3D Assets via Next-Part Prediction, https://arxiv.org/pdf/2412.16919, 2025-08-08
2025-11-10 23:37:07,741 - INFO - root - Page:4, Index:8, Training Multi-Layer Binary Neural Networks With Local Binary Error Signals, https://arxiv.org/pdf/2412.00119, 2025-08-05
2025-11-10 23:37:07,742 - INFO - root - Page:4, Index:9, Scaling Large-scale GNN Training to Thousands of Processors on CPU-based Supercomputers, https://arxiv.org/pdf/2411.16025, 2025-05-26
2025-11-10 23:37:07,742 - INFO - root - Page:4, Index:10, HAFLQ: Heterogeneous Adaptive Federated LoRA Fine-tuned LLM with Quantization, https://arxiv.org/pdf/2411.06581, 2025-05-16
2025-11-10 23:37:07,742 - INFO - root - Fetching page 6 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=250
2025-11-10 23:37:15,385 - INFO - root - get_all_titles_from_web 
2025-11-10 23:37:15,386 - INFO - root - Page:5, Index:0, Gradient-Free Training of Quantized Neural Networks, https://arxiv.org/pdf/2410.09734, 2025-09-29
2025-11-10 23:37:15,386 - INFO - root - Page:5, Index:1, QT-DoG: Quantization-aware Training for Domain Generalization, https://arxiv.org/pdf/2410.06020, 2025-06-26
2025-11-10 23:37:15,386 - INFO - root - Page:5, Index:2, Constraint Guided Model Quantization of Neural Networks, https://arxiv.org/pdf/2409.20138, 2025-09-12
2025-11-10 23:37:15,387 - INFO - root - Page:5, Index:3, Accumulator-Aware Post-Training Quantization for Large Language Models, https://arxiv.org/pdf/2409.17092, 2025-07-30
2025-11-10 23:37:15,387 - INFO - root - Page:5, Index:4, DilateQuant: Accurate and Efficient Diffusion Quantization via Weight Dilation, https://arxiv.org/pdf/2409.14307, 2025-07-09
2025-11-10 23:37:15,388 - INFO - root - Page:5, Index:5, Robust Training of Neural Networks at Arbitrary Precision and Sparsity, https://arxiv.org/pdf/2409.09245, 2025-09-23
2025-11-10 23:37:15,388 - INFO - root - Page:5, Index:6, VQ-CTAP: Cross-Modal Fine-Grained Sequence Representation Learning for Speech Processing, https://arxiv.org/pdf/2408.05758, 2025-05-27
2025-11-10 23:37:15,389 - INFO - root - Page:5, Index:7, DopQ-ViT: Towards Distribution-Friendly and Outlier-Aware Post-Training Quantization for Vision Transformers, https://arxiv.org/pdf/2408.03291, 2025-06-19
2025-11-10 23:37:15,389 - INFO - root - Page:5, Index:8, Temporal Feature Matters: A Framework for Diffusion Model Quantization, https://arxiv.org/pdf/2407.19547, 2025-07-11
2025-11-10 23:37:15,390 - INFO - root - Page:5, Index:9, EfficientQAT: Efficient Quantization-Aware Training for Large Language Models, https://arxiv.org/pdf/2407.11062, 2025-05-19
2025-11-10 23:37:15,390 - INFO - root - Page:5, Index:10, Integer-only Quantized Transformers for Embedded FPGA-based Time-series Forecasting in AIoT, https://arxiv.org/pdf/2407.11041, 2025-10-31
2025-11-10 23:37:15,390 - INFO - root - Fetching page 7 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=300
2025-11-10 23:37:22,802 - INFO - root - get_all_titles_from_web 
2025-11-10 23:37:22,802 - INFO - root - Page:6, Index:0, BoA: Attention-aware Post-training Quantization without Backpropagation, https://arxiv.org/pdf/2406.13474, 2025-06-06
2025-11-10 23:37:22,803 - INFO - root - Page:6, Index:1, A Rescaling-Invariant Lipschitz Bound Based on Path-Metrics for Modern ReLU Network Parameterizations, https://arxiv.org/pdf/2405.15006, 2025-06-13
2025-11-10 23:37:22,803 - INFO - root - Page:6, Index:2, Scheduling Weight Transitions for Quantization-Aware Training, https://arxiv.org/pdf/2404.19248, 2025-10-01
2025-11-10 23:37:22,803 - INFO - root - Page:6, Index:3, GPTVQ: The Blessing of Dimensionality for LLM Quantization, https://arxiv.org/pdf/2402.15319, 2025-06-03
2025-11-10 23:37:22,806 - INFO - root - Fetching page 8 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=350
2025-11-10 23:37:30,847 - INFO - root - get_all_titles_from_web 
2025-11-10 23:37:30,847 - INFO - root - Page:7, Index:0, Squat: Quant Small Language Models on the Edge, https://arxiv.org/pdf/2402.10787, 2025-07-01
2025-11-10 23:37:30,848 - INFO - root - Page:7, Index:1, L4Q: Parameter Efficient Quantization-Aware Fine-Tuning on Large Language Models, https://arxiv.org/pdf/2402.04902, 2025-07-21
2025-11-10 23:37:30,848 - INFO - root - Fetching page 9 with URL: https://arxiv.org/search/?query=Quantization-Aware-Training&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=400
2025-11-10 23:37:39,094 - INFO - root - ------------------------------------------------------------------------------------------------------------------------
2025-11-10 23:37:48,292 - INFO - root - File already exists, skipping download: D:\ChatPaper\academic Papers\Quantization-Aware-Training\A Quantized VAE-MLP Botnet Detection Model_ A Systematic Evaluation of Quantizat.pdf
2025-11-10 23:37:48,294 - INFO - root - 正在总结论文 1/2: Data Efficiency and Transfer Robustness in Biomedical Image Segmentation: A Study of Redundancy and Forgetting with Cellpose
2025-11-10 23:40:22,460 - INFO - root - 正在提取论文图片...
2025-11-10 23:40:24,695 - INFO - root - 已保存图片 1/10：./export\images_Data Efficiency and Transfer Robustness in Biomedical Image Segmentation_ A Stud\figure_1_page4.png
2025-11-10 23:40:24,873 - INFO - root - 已保存图片 2/10：./export\images_Data Efficiency and Transfer Robustness in Biomedical Image Segmentation_ A Stud\figure_2_page6.png
2025-11-10 23:40:25,127 - INFO - root - 已保存图片 3/10：./export\images_Data Efficiency and Transfer Robustness in Biomedical Image Segmentation_ A Stud\figure_3_page3.png
2025-11-10 23:40:25,462 - INFO - root - 已保存图片 4/10：./export\images_Data Efficiency and Transfer Robustness in Biomedical Image Segmentation_ A Stud\figure_4_page4.png
2025-11-10 23:40:25,481 - INFO - root - 成功添加图片 1：./export\images_Data Efficiency and Transfer Robustness in Biomedical Image Segmentation_ A Stud\figure_1_page4.png
2025-11-10 23:40:25,509 - INFO - root - 成功添加图片 2：./export\images_Data Efficiency and Transfer Robustness in Biomedical Image Segmentation_ A Stud\figure_2_page6.png
2025-11-10 23:40:25,521 - INFO - root - 成功添加图片 3：./export\images_Data Efficiency and Transfer Robustness in Biomedical Image Segmentation_ A Stud\figure_3_page3.png
2025-11-10 23:40:25,529 - INFO - root - 成功添加图片 4：./export\images_Data Efficiency and Transfer Robustness in Biomedical Image Segmentation_ A Stud\figure_4_page4.png
2025-11-10 23:40:25,538 - INFO - root - 提取到arXiv ID: 2511.04803
2025-11-10 23:40:25,541 - INFO - root - 调用arXiv API: https://export.arxiv.org/api/query?id=2511.04803
2025-11-10 23:40:31,564 - WARNING - root - 未找到论文信息: 2511.04803
2025-11-10 23:40:31,567 - INFO - root - 估算引用量: 10
2025-11-10 23:40:31,574 - INFO - root - 论文《Data Efficiency and Transfer Robustness in Biomedical Image Segmentation: A Study of Redundancy and Forgetting with Cellpose》的分析已保存到 ./export\QAT\Data Efficiency and Transfer Robustness in Biomedical Image Segmentation_ A Stud.md
2025-11-10 23:40:31,597 - INFO - root - 正在总结论文 2/2: A Quantized VAE-MLP Botnet Detection Model: A Systematic Evaluation of Quantization-Aware Training and Post-Training Quantization Strategies
2025-11-10 23:41:27,488 - INFO - root - LLMClient: rate limit reached, sleeping 4.1s
2025-11-10 23:41:57,342 - INFO - root - 正在提取论文图片...
2025-11-10 23:41:57,472 - INFO - root - 已保存图片 1/10：./export\images_A Quantized VAE-MLP Botnet Detection Model_ A Systematic Evaluation of Quantizat\figure_1_page4.png
2025-11-10 23:41:57,569 - INFO - root - 已保存图片 2/10：./export\images_A Quantized VAE-MLP Botnet Detection Model_ A Systematic Evaluation of Quantizat\figure_2_page4.png
2025-11-10 23:41:57,677 - INFO - root - 已保存图片 3/10：./export\images_A Quantized VAE-MLP Botnet Detection Model_ A Systematic Evaluation of Quantizat\figure_3_page4.png
2025-11-10 23:41:57,769 - INFO - root - 已保存图片 4/10：./export\images_A Quantized VAE-MLP Botnet Detection Model_ A Systematic Evaluation of Quantizat\figure_4_page5.png
2025-11-10 23:41:57,850 - INFO - root - 已保存图片 5/10：./export\images_A Quantized VAE-MLP Botnet Detection Model_ A Systematic Evaluation of Quantizat\figure_5_page3.png
2025-11-10 23:41:58,032 - INFO - root - 已保存图片 6/10：./export\images_A Quantized VAE-MLP Botnet Detection Model_ A Systematic Evaluation of Quantizat\figure_6_page4.png
2025-11-10 23:41:58,034 - INFO - root - 成功添加图片 1：./export\images_A Quantized VAE-MLP Botnet Detection Model_ A Systematic Evaluation of Quantizat\figure_1_page4.png
2025-11-10 23:41:58,035 - INFO - root - 成功添加图片 2：./export\images_A Quantized VAE-MLP Botnet Detection Model_ A Systematic Evaluation of Quantizat\figure_2_page4.png
2025-11-10 23:41:58,035 - INFO - root - 成功添加图片 3：./export\images_A Quantized VAE-MLP Botnet Detection Model_ A Systematic Evaluation of Quantizat\figure_3_page4.png
2025-11-10 23:41:58,036 - INFO - root - 成功添加图片 4：./export\images_A Quantized VAE-MLP Botnet Detection Model_ A Systematic Evaluation of Quantizat\figure_4_page5.png
2025-11-10 23:41:58,036 - INFO - root - 成功添加图片 5：./export\images_A Quantized VAE-MLP Botnet Detection Model_ A Systematic Evaluation of Quantizat\figure_5_page3.png
2025-11-10 23:41:58,037 - INFO - root - 成功添加图片 6：./export\images_A Quantized VAE-MLP Botnet Detection Model_ A Systematic Evaluation of Quantizat\figure_6_page4.png
2025-11-10 23:41:58,037 - INFO - root - 提取到arXiv ID: 2511.03201
2025-11-10 23:41:58,037 - INFO - root - 调用arXiv API: https://export.arxiv.org/api/query?id=2511.03201
2025-11-10 23:42:03,803 - WARNING - root - 未找到论文信息: 2511.03201
2025-11-10 23:42:03,805 - INFO - root - 估算引用量: 10
2025-11-10 23:42:03,809 - INFO - root - 论文《A Quantized VAE-MLP Botnet Detection Model: A Systematic Evaluation of Quantization-Aware Training and Post-Training Quantization Strategies》的分析已保存到 ./export\QAT\A Quantized VAE-MLP Botnet Detection Model_ A Systematic Evaluation of Quantizat.md
2025-11-10 23:42:03,826 - INFO - root - 提取到arXiv ID: 2511.04803
2025-11-10 23:42:03,837 - INFO - root - 调用arXiv API: https://export.arxiv.org/api/query?id=2511.04803
2025-11-10 23:42:09,223 - WARNING - root - 未找到论文信息: 2511.04803
2025-11-10 23:42:09,226 - INFO - root - 估算引用量: 10
2025-11-10 23:42:09,226 - INFO - root - 提取到arXiv ID: 2511.03201
2025-11-10 23:42:09,226 - INFO - root - 调用arXiv API: https://export.arxiv.org/api/query?id=2511.03201
2025-11-10 23:42:14,645 - WARNING - root - 未找到论文信息: 2511.03201
2025-11-10 23:42:14,647 - INFO - root - 估算引用量: 7
2025-11-10 23:42:15,227 - INFO - root - 已生成汇总Excel表格: ./export\QAT\论文汇总_QAT_20251110_234214.xlsx
2025-11-10 23:42:15,231 - INFO - root - 已生成汇总Excel表格: ./export\QAT\论文汇总_QAT_20251110_234214.xlsx
2025-11-10 23:42:15,232 - INFO - root - summary time: 351.05 seconds
2025-11-10 23:47:17,286 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-10 23:47:17,288 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-10 23:47:17,290 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-10 23:47:18,855 - INFO - root - LLMClientManager: 指定使用客户端: Gemini
2025-11-10 23:47:19,845 - INFO - root - GeminiClient: trying model models/gemini-2.5-flash
2025-11-10 23:47:27,021 - INFO - root - GeminiClient: initialized model gemini-2.5-flash
2025-11-10 23:47:27,022 - INFO - root - LLMClientManager: Gemini 客户端初始化成功
2025-11-10 23:47:27,022 - INFO - root - LLMClientManager: switched to Gemini client
2025-11-10 23:47:27,023 - INFO - root - 已手动切换到 LLM 客户端: Gemini
2025-11-10 23:47:27,023 - INFO - root - 使用 LLM 模型: gemini-2.5-flash
2025-11-10 23:47:27,023 - INFO - root - 可用客户端: ['Gemini']
2025-11-10 23:47:27,024 - INFO - root - === 运行配置 ===
2025-11-10 23:47:27,024 - INFO - root - 处理模式: arxiv在线搜索
2025-11-10 23:47:27,025 - INFO - root - 关键词: QAT
2025-11-10 23:47:27,025 - INFO - root - 查询: CVPR 2026
2025-11-10 23:47:27,025 - INFO - root - 排序: None
2025-11-10 23:47:27,026 - INFO - root - 最近天数: 180
2025-11-10 23:47:27,027 - INFO - root - 最大处理数量: 2
2025-11-10 23:47:27,028 - INFO - root - 保存图片: 是
2025-11-10 23:47:27,029 - INFO - root - 输出语言: 中文
2025-11-10 23:47:27,029 - INFO - root - 强制重新处理: 否
2025-11-10 23:47:27,030 - INFO - root - ====================
2025-11-10 23:47:27,030 - INFO - root - 使用 arXiv 搜索模式（通过 chat_arxiv 模块获取）
2025-11-10 23:47:27,031 - INFO - root - Fetching page 1 with URL: https://arxiv.org/search/?query=CVPR+2026&searchtype=all&abstracts=show&order=-announced_date_first&size=50
2025-11-10 23:47:32,894 - INFO - root - get_all_titles_from_web 
2025-11-10 23:47:32,895 - INFO - root - Page:0, Index:0, Learning to Seek Evidence: A Verifiable Reasoning Agent with Causal Faithfulness Analysis, https://arxiv.org/pdf/2511.01425, 2025-11-03
2025-11-10 23:47:32,895 - INFO - root - Fetching page 2 with URL: https://arxiv.org/search/?query=CVPR+2026&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=50
2025-11-10 23:47:39,628 - INFO - root - ------------------------------------------------------------------------------------------------------------------------
2025-11-10 23:47:39,633 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\CVPR 2026\Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness.pdf
2025-11-10 23:47:39,639 - INFO - root - 跳过已处理论文 Learning to Seek Evidence: A Verifiable Reasoning Agent with Causal Faithfulness Analysis：d:\ChatPaper\academic Papers\CVPR 2026\Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness.pdf
2025-11-10 23:47:39,641 - INFO - root - 提取到arXiv ID: 2511.01425
2025-11-10 23:47:39,641 - INFO - root - 估算引用量: 12
2025-11-10 23:47:40,285 - INFO - root - 已生成汇总Excel表格: ./export\QAT\论文汇总_QAT_20251110_234739.xlsx
2025-11-10 23:47:40,291 - INFO - root - 已生成汇总Excel表格: ./export\QAT\论文汇总_QAT_20251110_234739.xlsx
2025-11-10 23:47:40,293 - INFO - root - summary time: 23.01 seconds
2025-11-10 23:52:29,381 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-10 23:52:29,386 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-10 23:52:29,391 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-10 23:52:34,846 - INFO - root - LLMClientManager: 指定使用客户端: Gemini
2025-11-10 23:52:36,052 - INFO - root - GeminiClient: trying model models/gemini-2.5-flash
2025-11-10 23:52:45,998 - INFO - root - GeminiClient: initialized model gemini-2.5-flash
2025-11-10 23:52:45,998 - INFO - root - LLMClientManager: Gemini 客户端初始化成功
2025-11-10 23:52:45,999 - INFO - root - LLMClientManager: switched to Gemini client
2025-11-10 23:52:45,999 - INFO - root - 已手动切换到 LLM 客户端: Gemini
2025-11-10 23:52:45,999 - INFO - root - 使用 LLM 模型: gemini-2.5-flash
2025-11-10 23:52:45,999 - INFO - root - 可用客户端: ['Gemini']
2025-11-10 23:52:46,000 - INFO - root - === 运行配置 ===
2025-11-10 23:52:46,000 - INFO - root - 处理模式: arxiv在线搜索
2025-11-10 23:52:46,000 - INFO - root - 关键词: QAT
2025-11-10 23:52:46,000 - INFO - root - 查询: CVPR 2026
2025-11-10 23:52:46,000 - INFO - root - 排序: None
2025-11-10 23:52:46,001 - INFO - root - 最近天数: 180
2025-11-10 23:52:46,001 - INFO - root - 最大处理数量: 2
2025-11-10 23:52:46,001 - INFO - root - 保存图片: 是
2025-11-10 23:52:46,001 - INFO - root - 输出语言: 中文
2025-11-10 23:52:46,002 - INFO - root - 强制重新处理: 否
2025-11-10 23:52:46,002 - INFO - root - ====================
2025-11-10 23:52:46,002 - INFO - root - 使用 arXiv 搜索模式（通过 chat_arxiv 模块获取）
2025-11-10 23:52:46,002 - INFO - root - Fetching page 1 with URL: https://arxiv.org/search/?query=CVPR+2026&searchtype=all&abstracts=show&order=-announced_date_first&size=50
2025-11-10 23:52:52,158 - INFO - root - get_all_titles_from_web 
2025-11-10 23:52:52,159 - INFO - root - Page:0, Index:0, Learning to Seek Evidence: A Verifiable Reasoning Agent with Causal Faithfulness Analysis, https://arxiv.org/pdf/2511.01425, 2025-11-03
2025-11-10 23:52:52,160 - INFO - root - Fetching page 2 with URL: https://arxiv.org/search/?query=CVPR+2026&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=50
2025-11-10 23:52:58,367 - INFO - root - ------------------------------------------------------------------------------------------------------------------------
2025-11-10 23:52:58,374 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\CVPR 2026\Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness.pdf
2025-11-10 23:52:58,406 - INFO - root - 正在总结论文 1/1: Learning to Seek Evidence: A Verifiable Reasoning Agent with Causal Faithfulness Analysis
2025-11-10 23:53:52,234 - INFO - root - LLMClient: rate limit reached, sleeping 6.2s
2025-11-10 23:54:51,191 - INFO - root - 正在提取论文图片...
2025-11-10 23:54:51,535 - INFO - root - 已保存图片 1/10：./export\QAT\images\figure_1_page2.jpeg
2025-11-10 23:54:51,570 - INFO - root - 已保存图片 2/10：./export\QAT\images\figure_2_page2.jpeg
2025-11-10 23:54:51,599 - INFO - root - 已保存图片 3/10：./export\QAT\images\figure_3_page2.jpeg
2025-11-10 23:54:51,617 - INFO - root - 已保存图片 4/10：./export\QAT\images\figure_4_page2.jpeg
2025-11-10 23:54:51,631 - INFO - root - 已保存图片 5/10：./export\QAT\images\figure_5_page2.jpeg
2025-11-10 23:54:51,647 - INFO - root - 已保存图片 6/10：./export\QAT\images\figure_6_page2.jpeg
2025-11-10 23:54:51,676 - INFO - root - 已保存图片 7/10：./export\QAT\images\figure_7_page2.jpeg
2025-11-10 23:54:51,702 - INFO - root - 已保存图片 8/10：./export\QAT\images\figure_8_page2.jpeg
2025-11-10 23:54:51,768 - INFO - root - 已保存图片 9/10：./export\QAT\images\figure_9_page2.jpeg
2025-11-10 23:54:51,790 - INFO - root - 已保存图片 10/10：./export\QAT\images\figure_10_page2.jpeg
2025-11-10 23:54:51,791 - INFO - root - 成功添加图片 1：./export\QAT\images\figure_1_page2.jpeg
2025-11-10 23:54:51,793 - INFO - root - 成功添加图片 2：./export\QAT\images\figure_2_page2.jpeg
2025-11-10 23:54:51,793 - INFO - root - 成功添加图片 3：./export\QAT\images\figure_3_page2.jpeg
2025-11-10 23:54:51,793 - INFO - root - 成功添加图片 4：./export\QAT\images\figure_4_page2.jpeg
2025-11-10 23:54:51,794 - INFO - root - 成功添加图片 5：./export\QAT\images\figure_5_page2.jpeg
2025-11-10 23:54:51,794 - INFO - root - 成功添加图片 6：./export\QAT\images\figure_6_page2.jpeg
2025-11-10 23:54:51,795 - INFO - root - 成功添加图片 7：./export\QAT\images\figure_7_page2.jpeg
2025-11-10 23:54:51,796 - INFO - root - 成功添加图片 8：./export\QAT\images\figure_8_page2.jpeg
2025-11-10 23:54:51,796 - INFO - root - 成功添加图片 9：./export\QAT\images\figure_9_page2.jpeg
2025-11-10 23:54:51,797 - INFO - root - 成功添加图片 10：./export\QAT\images\figure_10_page2.jpeg
2025-11-10 23:54:51,797 - INFO - root - 提取到arXiv ID: 2511.01425
2025-11-10 23:54:51,798 - INFO - root - 估算引用量: 5
2025-11-10 23:54:51,802 - WARNING - root - 图片文件不存在: images/figure_10_page2.jpeg
2025-11-10 23:54:51,803 - INFO - root - 图片存在于images目录: ./export\QAT\images\figure_10_page2.jpeg
2025-11-10 23:54:51,804 - WARNING - root - 图片文件不存在: images/figure_9_page2.jpeg
2025-11-10 23:54:51,804 - INFO - root - 图片存在于images目录: ./export\QAT\images\figure_9_page2.jpeg
2025-11-10 23:54:51,804 - WARNING - root - 图片文件不存在: images/figure_8_page2.jpeg
2025-11-10 23:54:51,805 - INFO - root - 图片存在于images目录: ./export\QAT\images\figure_8_page2.jpeg
2025-11-10 23:54:51,805 - WARNING - root - 图片文件不存在: images/figure_7_page2.jpeg
2025-11-10 23:54:51,805 - INFO - root - 图片存在于images目录: ./export\QAT\images\figure_7_page2.jpeg
2025-11-10 23:54:51,806 - WARNING - root - 图片文件不存在: images/figure_6_page2.jpeg
2025-11-10 23:54:51,806 - INFO - root - 图片存在于images目录: ./export\QAT\images\figure_6_page2.jpeg
2025-11-10 23:54:51,806 - WARNING - root - 图片文件不存在: images/figure_5_page2.jpeg
2025-11-10 23:54:51,807 - INFO - root - 图片存在于images目录: ./export\QAT\images\figure_5_page2.jpeg
2025-11-10 23:54:51,808 - WARNING - root - 图片文件不存在: images/figure_4_page2.jpeg
2025-11-10 23:54:51,809 - INFO - root - 图片存在于images目录: ./export\QAT\images\figure_4_page2.jpeg
2025-11-10 23:54:51,809 - WARNING - root - 图片文件不存在: images/figure_3_page2.jpeg
2025-11-10 23:54:51,809 - INFO - root - 图片存在于images目录: ./export\QAT\images\figure_3_page2.jpeg
2025-11-10 23:54:51,809 - WARNING - root - 图片文件不存在: images/figure_2_page2.jpeg
2025-11-10 23:54:51,811 - INFO - root - 图片存在于images目录: ./export\QAT\images\figure_2_page2.jpeg
2025-11-10 23:54:51,811 - WARNING - root - 图片文件不存在: images/figure_1_page2.jpeg
2025-11-10 23:54:51,811 - INFO - root - 图片存在于images目录: ./export\QAT\images\figure_1_page2.jpeg
2025-11-10 23:54:51,818 - INFO - root - 论文《Learning to Seek Evidence: A Verifiable Reasoning Agent with Causal Faithfulness Analysis》的分析已保存到 ./export\QAT\Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness.md
2025-11-10 23:54:51,824 - INFO - root - 提取到arXiv ID: 2511.01425
2025-11-10 23:54:51,824 - INFO - root - 估算引用量: 6
2025-11-10 23:54:52,184 - INFO - root - 已生成汇总Excel表格: ./export\QAT\论文汇总_QAT_20251110_235451.xlsx
2025-11-10 23:54:52,187 - INFO - root - 已生成汇总Excel表格: ./export\QAT\论文汇总_QAT_20251110_235451.xlsx
2025-11-10 23:54:52,187 - INFO - root - summary time: 142.81 seconds
2025-11-11 00:07:17,876 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-11 00:07:17,878 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-11 00:07:17,880 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-11 00:07:19,749 - INFO - root - LLMClientManager: 指定使用客户端: Gemini
2025-11-11 00:07:21,345 - INFO - root - GeminiClient: trying model models/gemini-2.5-flash
2025-11-11 00:07:26,101 - INFO - root - GeminiClient: initialized model gemini-2.5-flash
2025-11-11 00:07:26,102 - INFO - root - LLMClientManager: Gemini 客户端初始化成功
2025-11-11 00:07:26,102 - INFO - root - LLMClientManager: switched to Gemini client
2025-11-11 00:07:26,103 - INFO - root - 已手动切换到 LLM 客户端: Gemini
2025-11-11 00:07:26,103 - INFO - root - 使用 LLM 模型: gemini-2.5-flash
2025-11-11 00:07:26,103 - INFO - root - 可用客户端: ['Gemini']
2025-11-11 00:07:26,104 - INFO - root - === 运行配置 ===
2025-11-11 00:07:26,105 - INFO - root - 处理模式: arxiv在线搜索
2025-11-11 00:07:26,106 - INFO - root - 关键词: QAT
2025-11-11 00:07:26,106 - INFO - root - 查询: CVPR 2026
2025-11-11 00:07:26,106 - INFO - root - 排序: None
2025-11-11 00:07:26,107 - INFO - root - 最近天数: 180
2025-11-11 00:07:26,107 - INFO - root - 最大处理数量: 2
2025-11-11 00:07:26,107 - INFO - root - 保存图片: 是
2025-11-11 00:07:26,108 - INFO - root - 输出语言: 中文
2025-11-11 00:07:26,108 - INFO - root - 强制重新处理: 否
2025-11-11 00:07:26,109 - INFO - root - ====================
2025-11-11 00:07:26,110 - INFO - root - 使用 arXiv 搜索模式（通过 chat_arxiv 模块获取）
2025-11-11 00:07:26,110 - INFO - root - Fetching page 1 with URL: https://arxiv.org/search/?query=CVPR+2026&searchtype=all&abstracts=show&order=-announced_date_first&size=50
2025-11-11 00:07:32,188 - INFO - root - get_all_titles_from_web 
2025-11-11 00:07:32,189 - INFO - root - Page:0, Index:0, Learning to Seek Evidence: A Verifiable Reasoning Agent with Causal Faithfulness Analysis, https://arxiv.org/pdf/2511.01425, 2025-11-03
2025-11-11 00:07:32,190 - INFO - root - Fetching page 2 with URL: https://arxiv.org/search/?query=CVPR+2026&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=50
2025-11-11 00:07:38,463 - INFO - root - ------------------------------------------------------------------------------------------------------------------------
2025-11-11 00:07:38,469 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\CVPR 2026\Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness.pdf
2025-11-11 00:07:38,473 - INFO - root - 跳过已处理论文 Learning to Seek Evidence: A Verifiable Reasoning Agent with Causal Faithfulness Analysis：d:\ChatPaper\academic Papers\CVPR 2026\Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness.pdf
2025-11-11 00:07:38,475 - INFO - root - 提取到arXiv ID: 2511.01425
2025-11-11 00:07:38,480 - INFO - root - 调用arXiv API: https://export.arxiv.org/api/query?id=2511.01425
2025-11-11 00:07:44,397 - WARNING - root - 未找到entry元素: 2511.01425
2025-11-11 00:07:44,400 - WARNING - root - arXiv API请求失败: 200
2025-11-11 00:07:44,403 - INFO - root - 估算引用量: 12
2025-11-11 00:07:44,771 - INFO - root - 已生成汇总Excel表格: ./export\QAT\论文汇总_QAT_20251111_000744.xlsx
2025-11-11 00:07:44,773 - INFO - root - 已生成汇总Excel表格: ./export\QAT\论文汇总_QAT_20251111_000744.xlsx
2025-11-11 00:07:44,773 - INFO - root - summary time: 26.90 seconds
2025-11-11 00:15:27,194 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-11 00:15:27,199 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-11 00:15:27,201 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-11 00:15:29,228 - INFO - root - LLMClientManager: 指定使用客户端: Gemini
2025-11-11 00:15:30,523 - INFO - root - GeminiClient: trying model models/gemini-2.5-flash
2025-11-11 00:15:34,827 - INFO - root - GeminiClient: initialized model gemini-2.5-flash
2025-11-11 00:15:34,827 - INFO - root - LLMClientManager: Gemini 客户端初始化成功
2025-11-11 00:15:34,828 - INFO - root - LLMClientManager: switched to Gemini client
2025-11-11 00:15:34,828 - INFO - root - 已手动切换到 LLM 客户端: Gemini
2025-11-11 00:15:34,829 - INFO - root - 使用 LLM 模型: gemini-2.5-flash
2025-11-11 00:15:34,829 - INFO - root - 可用客户端: ['Gemini']
2025-11-11 00:15:34,829 - INFO - root - === 运行配置 ===
2025-11-11 00:15:34,830 - INFO - root - 处理模式: arxiv在线搜索
2025-11-11 00:15:34,830 - INFO - root - 关键词: QAT
2025-11-11 00:15:34,830 - INFO - root - 查询: CVPR 2026
2025-11-11 00:15:34,830 - INFO - root - 排序: None
2025-11-11 00:15:34,831 - INFO - root - 最近天数: 180
2025-11-11 00:15:34,832 - INFO - root - 最大处理数量: 2
2025-11-11 00:15:34,832 - INFO - root - 保存图片: 是
2025-11-11 00:15:34,833 - INFO - root - 输出语言: 中文
2025-11-11 00:15:34,833 - INFO - root - 强制重新处理: 否
2025-11-11 00:15:34,834 - INFO - root - ====================
2025-11-11 00:15:34,834 - INFO - root - 使用 arXiv 搜索模式（通过 chat_arxiv 模块获取）
2025-11-11 00:15:34,834 - INFO - root - Fetching page 1 with URL: https://arxiv.org/search/?query=CVPR+2026&searchtype=all&abstracts=show&order=-announced_date_first&size=50
2025-11-11 00:15:40,901 - INFO - root - get_all_titles_from_web 
2025-11-11 00:15:40,902 - INFO - root - Page:0, Index:0, Learning to Seek Evidence: A Verifiable Reasoning Agent with Causal Faithfulness Analysis, https://arxiv.org/pdf/2511.01425, 2025-11-03
2025-11-11 00:15:40,903 - INFO - root - Fetching page 2 with URL: https://arxiv.org/search/?query=CVPR+2026&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=50
2025-11-11 00:15:46,773 - INFO - root - ------------------------------------------------------------------------------------------------------------------------
2025-11-11 00:15:46,778 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\CVPR 2026\Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness.pdf
2025-11-11 00:15:46,782 - INFO - root - 正在总结论文 1/1: Learning to Seek Evidence: A Verifiable Reasoning Agent with Causal Faithfulness Analysis
2025-11-11 00:16:41,609 - INFO - root - LLMClient: rate limit reached, sleeping 5.2s
2025-11-11 00:17:46,190 - INFO - root - 正在提取论文图片...
2025-11-11 00:17:46,421 - INFO - root - 已保存图片 1/10：./export\QAT\images\figure_1_page2.jpeg
2025-11-11 00:17:46,430 - INFO - root - 已保存图片 2/10：./export\QAT\images\figure_2_page2.jpeg
2025-11-11 00:17:46,438 - INFO - root - 已保存图片 3/10：./export\QAT\images\figure_3_page2.jpeg
2025-11-11 00:17:46,453 - INFO - root - 已保存图片 4/10：./export\QAT\images\figure_4_page2.jpeg
2025-11-11 00:17:46,477 - INFO - root - 已保存图片 5/10：./export\QAT\images\figure_5_page2.jpeg
2025-11-11 00:17:46,491 - INFO - root - 已保存图片 6/10：./export\QAT\images\figure_6_page2.jpeg
2025-11-11 00:17:46,520 - INFO - root - 已保存图片 7/10：./export\QAT\images\figure_7_page2.jpeg
2025-11-11 00:17:46,543 - INFO - root - 已保存图片 8/10：./export\QAT\images\figure_8_page2.jpeg
2025-11-11 00:17:46,615 - INFO - root - 已保存图片 9/10：./export\QAT\images\figure_9_page2.jpeg
2025-11-11 00:17:46,631 - INFO - root - 已保存图片 10/10：./export\QAT\images\figure_10_page2.jpeg
2025-11-11 00:17:46,645 - INFO - root - 成功添加图片 1：./export\QAT\images\figure_1_page2.jpeg
2025-11-11 00:17:46,646 - INFO - root - 成功添加图片 2：./export\QAT\images\figure_2_page2.jpeg
2025-11-11 00:17:46,647 - INFO - root - 成功添加图片 3：./export\QAT\images\figure_3_page2.jpeg
2025-11-11 00:17:46,647 - INFO - root - 成功添加图片 4：./export\QAT\images\figure_4_page2.jpeg
2025-11-11 00:17:46,647 - INFO - root - 成功添加图片 5：./export\QAT\images\figure_5_page2.jpeg
2025-11-11 00:17:46,647 - INFO - root - 成功添加图片 6：./export\QAT\images\figure_6_page2.jpeg
2025-11-11 00:17:46,653 - INFO - root - 成功添加图片 7：./export\QAT\images\figure_7_page2.jpeg
2025-11-11 00:17:46,654 - INFO - root - 成功添加图片 8：./export\QAT\images\figure_8_page2.jpeg
2025-11-11 00:17:46,654 - INFO - root - 成功添加图片 9：./export\QAT\images\figure_9_page2.jpeg
2025-11-11 00:17:46,654 - INFO - root - 成功添加图片 10：./export\QAT\images\figure_10_page2.jpeg
2025-11-11 00:17:46,656 - INFO - root - 提取到arXiv ID: 2511.01425
2025-11-11 00:17:46,658 - INFO - root - 调用arXiv API: https://export.arxiv.org/api/query?id=2511.01425
2025-11-11 00:17:52,559 - WARNING - root - 未找到entry元素: 2511.01425
2025-11-11 00:17:52,559 - INFO - root - XML根元素标签: {http://www.w3.org/2005/Atom}feed
2025-11-11 00:17:52,559 - INFO - root - XML根元素属性: {}
2025-11-11 00:17:52,559 - INFO - root - 根元素的直接子元素:
2025-11-11 00:17:52,560 - INFO - root -   0. {http://www.w3.org/2005/Atom}link: None
2025-11-11 00:17:52,560 - INFO - root -   1. {http://www.w3.org/2005/Atom}title: ArXiv Query: search_query=&id_list=&start=0&max_results=10
2025-11-11 00:17:52,560 - INFO - root -   2. {http://www.w3.org/2005/Atom}id: http://arxiv.org/api/iQlyOhQ3W8t8kI903+StmrBZNWM
2025-11-11 00:17:52,560 - INFO - root -   3. {http://www.w3.org/2005/Atom}updated: 2025-11-10T00:00:00-05:00
2025-11-11 00:17:52,561 - INFO - root -   4. {http://a9.com/-/spec/opensearch/1.1/}totalResults: 0
2025-11-11 00:17:52,561 - INFO - root -   5. {http://a9.com/-/spec/opensearch/1.1/}startIndex: 0
2025-11-11 00:17:52,561 - INFO - root -   6. {http://a9.com/-/spec/opensearch/1.1/}itemsPerPage: 10
2025-11-11 00:17:52,561 - INFO - root - XML内容前500字符: <?xml version="1.0" encoding="UTF-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <link href="http://arxiv.org/api/query?search_query%3D%26id_list%3D%26start%3D0%26max_results%3D10" rel="self" type="application/atom+xml"/>
  <title type="html">ArXiv Query: search_query=&amp;id_list=&amp;start=0&amp;max_results=10</title>
  <id>http://arxiv.org/api/iQlyOhQ3W8t8kI903+StmrBZNWM</id>
  <updated>2025-11-10T00:00:00-05:00</updated>
  <opensearch:totalResults xmlns:opensearch="http://a9.com/-/spec/op
2025-11-11 00:17:52,564 - INFO - root - 估算引用量: 3
2025-11-11 00:17:52,566 - WARNING - root - 图片文件不存在: images/figure_10_page2.jpeg
2025-11-11 00:17:52,568 - INFO - root - 图片存在于images目录: ./export\QAT\images\figure_10_page2.jpeg
2025-11-11 00:17:52,568 - WARNING - root - 图片文件不存在: images/figure_9_page2.jpeg
2025-11-11 00:17:52,568 - INFO - root - 图片存在于images目录: ./export\QAT\images\figure_9_page2.jpeg
2025-11-11 00:17:52,569 - WARNING - root - 图片文件不存在: images/figure_8_page2.jpeg
2025-11-11 00:17:52,569 - INFO - root - 图片存在于images目录: ./export\QAT\images\figure_8_page2.jpeg
2025-11-11 00:17:52,570 - WARNING - root - 图片文件不存在: images/figure_7_page2.jpeg
2025-11-11 00:17:52,572 - INFO - root - 图片存在于images目录: ./export\QAT\images\figure_7_page2.jpeg
2025-11-11 00:17:52,574 - WARNING - root - 图片文件不存在: images/figure_6_page2.jpeg
2025-11-11 00:17:52,577 - INFO - root - 图片存在于images目录: ./export\QAT\images\figure_6_page2.jpeg
2025-11-11 00:17:52,579 - WARNING - root - 图片文件不存在: images/figure_5_page2.jpeg
2025-11-11 00:17:52,579 - INFO - root - 图片存在于images目录: ./export\QAT\images\figure_5_page2.jpeg
2025-11-11 00:17:52,579 - WARNING - root - 图片文件不存在: images/figure_4_page2.jpeg
2025-11-11 00:17:52,580 - INFO - root - 图片存在于images目录: ./export\QAT\images\figure_4_page2.jpeg
2025-11-11 00:17:52,580 - WARNING - root - 图片文件不存在: images/figure_3_page2.jpeg
2025-11-11 00:17:52,580 - INFO - root - 图片存在于images目录: ./export\QAT\images\figure_3_page2.jpeg
2025-11-11 00:17:52,581 - WARNING - root - 图片文件不存在: images/figure_2_page2.jpeg
2025-11-11 00:17:52,581 - INFO - root - 图片存在于images目录: ./export\QAT\images\figure_2_page2.jpeg
2025-11-11 00:17:52,581 - WARNING - root - 图片文件不存在: images/figure_1_page2.jpeg
2025-11-11 00:17:52,581 - INFO - root - 图片存在于images目录: ./export\QAT\images\figure_1_page2.jpeg
2025-11-11 00:17:52,584 - INFO - root - 论文《Learning to Seek Evidence: A Verifiable Reasoning Agent with Causal Faithfulness Analysis》的分析已保存到 ./export\QAT\Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness.md
2025-11-11 00:17:52,589 - INFO - root - 提取到arXiv ID: 2511.01425
2025-11-11 00:17:52,592 - INFO - root - 调用arXiv API: https://export.arxiv.org/api/query?id=2511.01425
2025-11-11 00:17:58,009 - WARNING - root - 未找到entry元素: 2511.01425
2025-11-11 00:17:58,010 - INFO - root - XML根元素标签: {http://www.w3.org/2005/Atom}feed
2025-11-11 00:17:58,011 - INFO - root - XML根元素属性: {}
2025-11-11 00:17:58,012 - INFO - root - 根元素的直接子元素:
2025-11-11 00:17:58,013 - INFO - root -   0. {http://www.w3.org/2005/Atom}link: None
2025-11-11 00:17:58,013 - INFO - root -   1. {http://www.w3.org/2005/Atom}title: ArXiv Query: search_query=&id_list=&start=0&max_results=10
2025-11-11 00:17:58,013 - INFO - root -   2. {http://www.w3.org/2005/Atom}id: http://arxiv.org/api/iQlyOhQ3W8t8kI903+StmrBZNWM
2025-11-11 00:17:58,013 - INFO - root -   3. {http://www.w3.org/2005/Atom}updated: 2025-11-10T00:00:00-05:00
2025-11-11 00:17:58,013 - INFO - root -   4. {http://a9.com/-/spec/opensearch/1.1/}totalResults: 0
2025-11-11 00:17:58,013 - INFO - root -   5. {http://a9.com/-/spec/opensearch/1.1/}startIndex: 0
2025-11-11 00:17:58,014 - INFO - root -   6. {http://a9.com/-/spec/opensearch/1.1/}itemsPerPage: 10
2025-11-11 00:17:58,014 - INFO - root - XML内容前500字符: <?xml version="1.0" encoding="UTF-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <link href="http://arxiv.org/api/query?search_query%3D%26id_list%3D%26start%3D0%26max_results%3D10" rel="self" type="application/atom+xml"/>
  <title type="html">ArXiv Query: search_query=&amp;id_list=&amp;start=0&amp;max_results=10</title>
  <id>http://arxiv.org/api/iQlyOhQ3W8t8kI903+StmrBZNWM</id>
  <updated>2025-11-10T00:00:00-05:00</updated>
  <opensearch:totalResults xmlns:opensearch="http://a9.com/-/spec/op
2025-11-11 00:17:58,018 - INFO - root - 估算引用量: 13
2025-11-11 00:17:58,370 - INFO - root - 已生成汇总Excel表格: ./export\QAT\论文汇总_QAT_20251111_001758.xlsx
2025-11-11 00:17:58,372 - INFO - root - 已生成汇总Excel表格: ./export\QAT\论文汇总_QAT_20251111_001758.xlsx
2025-11-11 00:17:58,373 - INFO - root - summary time: 151.18 seconds
2025-11-11 00:19:34,204 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-11 00:19:34,206 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-11 00:19:34,209 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-11 00:19:36,364 - INFO - root - LLMClientManager: 指定使用客户端: Gemini
2025-11-11 00:19:37,230 - INFO - root - GeminiClient: trying model models/gemini-2.5-flash
2025-11-11 00:19:44,898 - INFO - root - GeminiClient: initialized model gemini-2.5-flash
2025-11-11 00:19:44,900 - INFO - root - LLMClientManager: Gemini 客户端初始化成功
2025-11-11 00:19:44,902 - INFO - root - LLMClientManager: switched to Gemini client
2025-11-11 00:19:44,904 - INFO - root - 已手动切换到 LLM 客户端: Gemini
2025-11-11 00:19:44,905 - INFO - root - 使用 LLM 模型: gemini-2.5-flash
2025-11-11 00:19:44,906 - INFO - root - 可用客户端: ['Gemini']
2025-11-11 00:19:44,908 - INFO - root - === 运行配置 ===
2025-11-11 00:19:44,908 - INFO - root - 处理模式: arxiv在线搜索
2025-11-11 00:19:44,909 - INFO - root - 关键词: CVPR
2025-11-11 00:19:44,910 - INFO - root - 查询: CVPR 2025
2025-11-11 00:19:44,911 - INFO - root - 排序: None
2025-11-11 00:19:44,913 - INFO - root - 最近天数: 180
2025-11-11 00:19:44,915 - INFO - root - 最大处理数量: 5
2025-11-11 00:19:44,917 - INFO - root - 保存图片: 是
2025-11-11 00:19:44,920 - INFO - root - 输出语言: 中文
2025-11-11 00:19:44,921 - INFO - root - 强制重新处理: 否
2025-11-11 00:19:44,922 - INFO - root - ====================
2025-11-11 00:19:44,923 - INFO - root - 使用 arXiv 搜索模式（通过 chat_arxiv 模块获取）
2025-11-11 00:19:44,925 - INFO - root - Fetching page 1 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50
2025-11-11 00:19:52,377 - INFO - root - get_all_titles_from_web 
2025-11-11 00:19:52,378 - INFO - root - Page:0, Index:0, Learning to Seek Evidence: A Verifiable Reasoning Agent with Causal Faithfulness Analysis, https://arxiv.org/pdf/2511.01425, 2025-11-03
2025-11-11 00:19:52,378 - INFO - root - Page:0, Index:1, OmniTrack++: Omnidirectional Multi-Object Tracking by Learning Large-FoV Trajectory Feedback, https://arxiv.org/pdf/2511.00510, 2025-11-01
2025-11-11 00:19:52,379 - INFO - root - Page:0, Index:2, NeuCo-Bench: A Novel Benchmark Framework for Neural Embeddings in Earth Observation, https://arxiv.org/pdf/2510.17914, 2025-10-19
2025-11-11 00:19:52,379 - INFO - root - Page:0, Index:3, NTIRE 2025 Challenge on Low Light Image Enhancement: Methods and Results, https://arxiv.org/pdf/2510.13670, 2025-10-15
2025-11-11 00:19:52,379 - INFO - root - Page:0, Index:4, Class Prototypes based Contrastive Learning for Classifying Multi-Label and Fine-Grained Educational Videos, https://arxiv.org/pdf/2510.11204, 2025-10-13
2025-11-11 00:19:52,379 - INFO - root - Page:0, Index:5, MIMO: A medical vision language model with visual referring multimodal input and pixel grounding multimodal output, https://arxiv.org/pdf/2510.10011, 2025-10-11
2025-11-11 00:19:52,379 - INFO - root - Page:0, Index:6, Vision Language Models: A Survey of 26K Papers, https://arxiv.org/pdf/2510.09586, 2025-10-10
2025-11-11 00:19:52,380 - INFO - root - Page:0, Index:7, DiT-VTON: Diffusion Transformer Framework for Unified Multi-Category Virtual Try-On and Virtual Try-All with Integrated Image Editing, https://arxiv.org/pdf/2510.04797, 2025-10-03
2025-11-11 00:19:52,380 - INFO - root - Page:0, Index:8, PatchVSR: Breaking Video Diffusion Resolution Limits with Patch-wise Video Super-Resolution, https://arxiv.org/pdf/2509.26025, 2025-09-30
2025-11-11 00:19:52,380 - INFO - root - Page:0, Index:9, FreqDebias: Towards Generalizable Deepfake Detection via Consistency-Driven Frequency Debiasing, https://arxiv.org/pdf/2509.22412, 2025-09-26
2025-11-11 00:19:52,380 - INFO - root - Page:0, Index:10, A Mutual Learning Method for Salient Object Detection with intertwined Multi-Supervision--Revised, https://arxiv.org/pdf/2509.21363, 2025-09-21
2025-11-11 00:19:52,380 - INFO - root - Page:0, Index:11, InstructVTON: Optimal Auto-Masking and Natural-Language-Guided Interactive Style Control for Inpainting-Based Virtual Try-On, https://arxiv.org/pdf/2509.20524, 2025-09-24
2025-11-11 00:19:52,381 - INFO - root - Page:0, Index:12, Efficient Encoder-Free Pose Conditioning and Pose Control for Virtual Try-On, https://arxiv.org/pdf/2509.20343, 2025-09-24
2025-11-11 00:19:52,381 - INFO - root - Page:0, Index:13, The Photographer Eye: Teaching Multimodal Large Language Models to Understand Image Aesthetics like Photographers, https://arxiv.org/pdf/2509.18582, 2025-10-22
2025-11-11 00:19:52,381 - INFO - root - Page:0, Index:14, ENSAM: an efficient foundation model for interactive segmentation of 3D medical images, https://arxiv.org/pdf/2509.15874, 2025-09-19
2025-11-11 00:19:52,381 - INFO - root - Page:0, Index:15, DEFT-VTON: Efficient Virtual Try-On with Consistent Generalised H-Transform, https://arxiv.org/pdf/2509.13506, 2025-09-16
2025-11-11 00:19:52,381 - INFO - root - Page:0, Index:16, Weakly and Self-Supervised Class-Agnostic Motion Prediction for Autonomous Driving, https://arxiv.org/pdf/2509.13116, 2025-09-16
2025-11-11 00:19:52,381 - INFO - root - Page:0, Index:17, Domain-Adaptive Pretraining Improves Primate Behavior Recognition, https://arxiv.org/pdf/2509.12193, 2025-09-15
2025-11-11 00:19:52,381 - INFO - root - Page:0, Index:18, The System Description of CPS Team for Track on Driving with Language of CVPR 2024 Autonomous Grand Challenge, https://arxiv.org/pdf/2509.11071, 2025-09-13
2025-11-11 00:19:52,381 - INFO - root - Page:0, Index:19, An HMM-based framework for identity-aware long-term multi-object tracking from sparse and uncertain identification: use case on long-term tracking in livestock, https://arxiv.org/pdf/2509.09962, 2025-09-12
2025-11-11 00:19:52,383 - INFO - root - Page:0, Index:20, InterAct: Advancing Large-Scale Versatile 3D Human-Object Interaction Generation, https://arxiv.org/pdf/2509.09555, 2025-09-11
2025-11-11 00:19:52,384 - INFO - root - Page:0, Index:21, Geospatial Foundational Embedder: Top-1 Winning Solution on EarthVision Embed2Scale Challenge (CVPR 2025), https://arxiv.org/pdf/2509.06993, 2025-09-03
2025-11-11 00:19:52,385 - INFO - root - Page:0, Index:22, 2nd Place Solution for CVPR2024 E2E Challenge: End-to-End Autonomous Driving Using Vision Language Model, https://arxiv.org/pdf/2509.02659, 2025-09-02
2025-11-11 00:19:52,386 - INFO - root - Page:0, Index:23, Unsupervised Training of Vision Transformers with Synthetic Negatives, https://arxiv.org/pdf/2509.02024, 2025-09-02
2025-11-11 00:19:52,386 - INFO - root - Page:0, Index:24, MV-SSM: Multi-View State Space Modeling for 3D Human Pose Estimation, https://arxiv.org/pdf/2509.00649, 2025-08-30
2025-11-11 00:19:52,387 - INFO - root - Page:0, Index:25, CryptoFace: End-to-End Encrypted Face Recognition, https://arxiv.org/pdf/2509.00332, 2025-08-29
2025-11-11 00:19:52,389 - INFO - root - Page:0, Index:26, ControlEchoSynth: Boosting Ejection Fraction Estimation Models via Controlled Video Diffusion, https://arxiv.org/pdf/2508.17631, 2025-08-26
2025-11-11 00:19:52,390 - INFO - root - Page:0, Index:27, Explain Before You Answer: A Survey on Compositional Visual Reasoning, https://arxiv.org/pdf/2508.17298, 2025-08-27
2025-11-11 00:19:52,391 - INFO - root - Page:0, Index:28, Investigating Different Geo Priors for Image Classification, https://arxiv.org/pdf/2508.15946, 2025-08-21
2025-11-11 00:19:52,400 - INFO - root - Page:0, Index:29, Towards Source-Free Machine Unlearning, https://arxiv.org/pdf/2508.15127, 2025-08-20
2025-11-11 00:19:52,416 - INFO - root - Page:0, Index:30, MR6D: Benchmarking 6D Pose Estimation for Mobile Robots, https://arxiv.org/pdf/2508.13775, 2025-08-19
2025-11-11 00:19:52,419 - INFO - root - Page:0, Index:31, Calibrating Biased Distribution in VFM-derived Latent Space via Cross-Domain Geometric Consistency, https://arxiv.org/pdf/2508.13518, 2025-08-19
2025-11-11 00:19:52,420 - INFO - root - Page:0, Index:32, SIS-Challenge: Event-based Spatio-temporal Instance Segmentation Challenge at the CVPR 2025 Event-based Vision Workshop, https://arxiv.org/pdf/2508.12813, 2025-08-18
2025-11-11 00:19:52,421 - INFO - root - Page:0, Index:33, Multi-Level Knowledge Distillation and Dynamic Self-Supervised Learning for Continual Learning, https://arxiv.org/pdf/2508.12692, 2025-08-22
2025-11-11 00:19:52,424 - INFO - root - Page:0, Index:34, Stochastic-based Patch Filtering for Few-Shot Learning, https://arxiv.org/pdf/2508.10066, 2025-08-13
2025-11-11 00:19:52,433 - INFO - root - Page:0, Index:35, Slot Attention-based Feature Filtering for Few-Shot Learning, https://arxiv.org/pdf/2508.09699, 2025-08-13
2025-11-11 00:19:52,437 - INFO - root - Page:0, Index:36, Comparison Reveals Commonality: Customized Image Generation through Contrastive Inversion, https://arxiv.org/pdf/2508.07755, 2025-08-11
2025-11-11 00:19:52,439 - INFO - root - Page:0, Index:37, SLRTP2025 Sign Language Production Challenge: Methodology, Results, and Future Work, https://arxiv.org/pdf/2508.06951, 2025-08-09
2025-11-11 00:19:52,439 - INFO - root - Page:0, Index:38, Exploring Fairness across Fine-Grained Attributes in Large Vision-Language Models, https://arxiv.org/pdf/2508.03079, 2025-08-05
2025-11-11 00:19:52,441 - INFO - root - Page:0, Index:39, Devil is in the Detail: Towards Injecting Fine Details of Image Prompt in Image Generation via Conflict-free Guidance and Stratified Attention, https://arxiv.org/pdf/2508.02004, 2025-08-03
2025-11-11 00:19:52,444 - INFO - root - Page:0, Index:40, IAUNet: Instance-Aware U-Net, https://arxiv.org/pdf/2508.01928, 2025-08-03
2025-11-11 00:19:52,448 - INFO - root - Page:0, Index:41, Gaussian Splatting Feature Fields for Privacy-Preserving Visual Localization, https://arxiv.org/pdf/2507.23569, 2025-08-26
2025-11-11 00:19:52,452 - INFO - root - Page:0, Index:42, From Scan to Action: Leveraging Realistic Scans for Embodied Scene Understanding, https://arxiv.org/pdf/2507.17585, 2025-07-23
2025-11-11 00:19:52,457 - INFO - root - Page:0, Index:43, LEAD: Exploring Logit Space Evolution for Model Selection, https://arxiv.org/pdf/2507.14559, 2025-07-19
2025-11-11 00:19:52,464 - INFO - root - Page:0, Index:44, HeCoFuse: Cross-Modal Complementary V2X Cooperative Perception with Heterogeneous Sensors, https://arxiv.org/pdf/2507.13677, 2025-07-18
2025-11-11 00:19:52,467 - INFO - root - Page:0, Index:45, OmniVec2 -- A Novel Transformer based Network for Large Scale Multimodal and Multitask Learning, https://arxiv.org/pdf/2507.13364, 2025-07-06
2025-11-11 00:19:52,468 - INFO - root - Page:0, Index:46, A Training-Free, Task-Agnostic Framework for Enhancing MLLM Performance on High-Resolution Images, https://arxiv.org/pdf/2507.10202, 2025-07-14
2025-11-11 00:19:52,469 - INFO - root - Page:0, Index:47, Quantum Federated Learning for Multimodal Data: A Modality-Agnostic Approach, https://arxiv.org/pdf/2507.08217, 2025-07-10
2025-11-11 00:19:52,479 - INFO - root - Page:0, Index:48, CuriosAI Submission to the EgoExo4D Proficiency Estimation Challenge 2025, https://arxiv.org/pdf/2507.08022, 2025-07-08
2025-11-11 00:19:52,484 - INFO - root - Page:0, Index:49, Rethinking Query-based Transformer for Continual Image Segmentation, https://arxiv.org/pdf/2507.07831, 2025-07-10
2025-11-11 00:19:52,486 - INFO - root - Fetching page 2 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=50
2025-11-11 00:20:00,191 - INFO - root - get_all_titles_from_web 
2025-11-11 00:20:00,192 - INFO - root - Page:1, Index:0, Scalable and Realistic Virtual Try-on Application for Foundation Makeup with Kubelka-Munk Theory, https://arxiv.org/pdf/2507.07333, 2025-07-09
2025-11-11 00:20:00,192 - INFO - root - Page:1, Index:1, Free on the Fly: Enhancing Flexibility in Test-Time Adaptation with Online EM, https://arxiv.org/pdf/2507.06973, 2025-07-09
2025-11-11 00:20:00,192 - INFO - root - Page:1, Index:2, Adaptive Part Learning for Fine-Grained Generalized Category Discovery: A Plug-and-Play Enhancement, https://arxiv.org/pdf/2507.06928, 2025-07-09
2025-11-11 00:20:00,192 - INFO - root - Page:1, Index:3, Grounded Gesture Generation: Language, Motion, and Space, https://arxiv.org/pdf/2507.04522, 2025-07-06
2025-11-11 00:20:00,194 - INFO - root - Page:1, Index:4, Comprehensive Information Bottleneck for Unveiling Universal Attribution to Interpret Vision Transformers, https://arxiv.org/pdf/2507.04388, 2025-07-06
2025-11-11 00:20:00,194 - INFO - root - Page:1, Index:5, ZERO: Industry-ready Vision Foundation Model with Multi-modal Prompts, https://arxiv.org/pdf/2507.04270, 2025-11-07
2025-11-11 00:20:00,194 - INFO - root - Page:1, Index:6, Beyond Accuracy: Metrics that Uncover What Makes a 'Good' Visual Descriptor, https://arxiv.org/pdf/2507.03542, 2025-07-08
2025-11-11 00:20:00,195 - INFO - root - Page:1, Index:7, ConceptMix++: Leveling the Playing Field in Text-to-Image Benchmarking via Iterative Prompt Optimization, https://arxiv.org/pdf/2507.03275, 2025-07-03
2025-11-11 00:20:00,195 - INFO - root - Page:1, Index:8, APT: Adaptive Personalized Training for Diffusion Models with Limited Data, https://arxiv.org/pdf/2507.02687, 2025-07-03
2025-11-11 00:20:00,196 - INFO - root - Page:1, Index:9, DreamComposer++: Empowering Diffusion Models with Multi-View Conditions for 3D Content Generation, https://arxiv.org/pdf/2507.02299, 2025-07-03
2025-11-11 00:20:00,196 - INFO - root - Page:1, Index:10, Soft Self-labeling and Potts Relaxations for Weakly-Supervised Segmentation, https://arxiv.org/pdf/2507.01721, 2025-07-02
2025-11-11 00:20:00,196 - INFO - root - Page:1, Index:11, Interpolation-Based Event Visual Data Filtering Algorithms, https://arxiv.org/pdf/2507.01557, 2025-07-02
2025-11-11 00:20:00,196 - INFO - root - Page:1, Index:12, AVC-DPO: Aligned Video Captioning via Direct Preference Optimization, https://arxiv.org/pdf/2507.01492, 2025-07-02
2025-11-11 00:20:00,198 - INFO - root - Page:1, Index:13, NN-Former: Rethinking Graph Structure in Neural Architecture Representation, https://arxiv.org/pdf/2507.00880, 2025-07-01
2025-11-11 00:20:00,198 - INFO - root - Page:1, Index:14, Instant Particle Size Distribution Measurement Using CNNs Trained on Synthetic Data, https://arxiv.org/pdf/2507.00822, 2025-07-01
2025-11-11 00:20:00,200 - INFO - root - Page:1, Index:15, Moment Sampling in Video LLMs for Long-Form Video QA, https://arxiv.org/pdf/2507.00033, 2025-06-17
2025-11-11 00:20:00,200 - INFO - root - Page:1, Index:16, Revisiting Audio-Visual Segmentation with Vision-Centric Transformer, https://arxiv.org/pdf/2506.23623, 2025-06-30
2025-11-11 00:20:00,200 - INFO - root - Page:1, Index:17, MTADiffusion: Mask Text Alignment Diffusion Model for Object Inpainting, https://arxiv.org/pdf/2506.23482, 2025-06-29
2025-11-11 00:20:00,200 - INFO - root - Page:1, Index:18, Benchmarking Generalizable Bimanual Manipulation: RoboTwin Dual-Arm Collaboration Challenge at CVPR 2025 MEIS Workshop, https://arxiv.org/pdf/2506.23351, 2025-07-02
2025-11-11 00:20:00,200 - INFO - root - Page:1, Index:19, Prompting without Panic: Attribute-aware, Zero-shot, Test-Time Calibration, https://arxiv.org/pdf/2506.22819, 2025-06-28
2025-11-11 00:20:00,201 - INFO - root - Page:1, Index:20, Analyzing and Fine-Tuning Whisper Models for Multilingual Pilot Speech Transcription in the Cockpit, https://arxiv.org/pdf/2506.21990, 2025-06-27
2025-11-11 00:20:00,201 - INFO - root - Page:1, Index:21, SceneDiffuser++: City-Scale Traffic Simulation via a Generative World Model, https://arxiv.org/pdf/2506.21976, 2025-06-27
2025-11-11 00:20:00,201 - INFO - root - Page:1, Index:22, DIVE: Deep-search Iterative Video Exploration A Technical Report for the CVRR Challenge at CVPR 2025, https://arxiv.org/pdf/2506.21891, 2025-06-27
2025-11-11 00:20:00,201 - INFO - root - Page:1, Index:23, End-to-End RGB-IR Joint Image Compression With Channel-wise Cross-modality Entropy Model, https://arxiv.org/pdf/2506.21851, 2025-06-26
2025-11-11 00:20:00,201 - INFO - root - Page:1, Index:24, Distilling Normalizing Flows, https://arxiv.org/pdf/2506.21003, 2025-06-26
2025-11-11 00:20:00,201 - INFO - root - Page:1, Index:25, Joint attitude estimation and 3D neural reconstruction of non-cooperative space objects, https://arxiv.org/pdf/2506.20638, 2025-06-25
2025-11-11 00:20:00,202 - INFO - root - Page:1, Index:26, Accept More, Reject Less: Reducing up to 19% Unnecessary Desk-Rejections over 11 Years of ICLR Data, https://arxiv.org/pdf/2506.20141, 2025-06-25
2025-11-11 00:20:00,202 - INFO - root - Page:1, Index:27, SceneCrafter: Controllable Multi-View Driving Scene Editing, https://arxiv.org/pdf/2506.19488, 2025-06-24
2025-11-11 00:20:00,202 - INFO - root - Page:1, Index:28, Emergence of Text Readability in Vision Language Models, https://arxiv.org/pdf/2506.19389, 2025-06-24
2025-11-11 00:20:00,202 - INFO - root - Page:1, Index:29, MedErr-CT: A Visual Question Answering Benchmark for Identifying and Correcting Errors in CT Reports, https://arxiv.org/pdf/2506.19217, 2025-06-23
2025-11-11 00:20:00,204 - INFO - root - Page:1, Index:30, RareSpot: Spotting Small and Rare Wildlife in Aerial Imagery with Multi-Scale Consistency and Context-Aware Augmentation, https://arxiv.org/pdf/2506.19087, 2025-06-23
2025-11-11 00:20:00,204 - INFO - root - Page:1, Index:31, Object-aware Sound Source Localization via Audio-Visual Scene Understanding, https://arxiv.org/pdf/2506.18557, 2025-06-23
2025-11-11 00:20:00,205 - INFO - root - Page:1, Index:32, Rethinking Decoder Design: Improving Biomarker Segmentation Using Depth-to-Space Restoration and Residual Linear Attention, https://arxiv.org/pdf/2506.18335, 2025-06-23
2025-11-11 00:20:00,207 - INFO - root - Page:1, Index:33, Relation3D: Enhancing Relation Modeling for Point Cloud Instance Segmentation, https://arxiv.org/pdf/2506.17891, 2025-06-21
2025-11-11 00:20:00,207 - INFO - root - Page:1, Index:34, HIRE: Lightweight High-Resolution Image Feature Enrichment for Multimodal LLMs, https://arxiv.org/pdf/2506.17608, 2025-06-21
2025-11-11 00:20:00,207 - INFO - root - Page:1, Index:35, Spatially-Aware Evaluation of Segmentation Uncertainty, https://arxiv.org/pdf/2506.16589, 2025-06-19
2025-11-11 00:20:00,209 - INFO - root - Page:1, Index:36, Tripartite Weight-Space Ensemble for Few-Shot Class-Incremental Learning, https://arxiv.org/pdf/2506.15720, 2025-06-03
2025-11-11 00:20:00,210 - INFO - root - Page:1, Index:37, PARC: A Quantitative Framework Uncovering the Symmetries within Vision Language Models, https://arxiv.org/pdf/2506.14808, 2025-06-03
2025-11-11 00:20:00,211 - INFO - root - Page:1, Index:38, Self-supervised Representation Learning with Local Aggregation for Image-based Profiling, https://arxiv.org/pdf/2506.14265, 2025-10-27
2025-11-11 00:20:00,212 - INFO - root - Page:1, Index:39, Towards Robust Learning to Optimize with Theoretical Guarantees, https://arxiv.org/pdf/2506.14263, 2025-06-17
2025-11-11 00:20:00,213 - INFO - root - Page:1, Index:40, Hidden Bias in the Machine: Stereotypes in Text-to-Image Models, https://arxiv.org/pdf/2506.13780, 2025-06-09
2025-11-11 00:20:00,213 - INFO - root - Page:1, Index:41, SmartHome-Bench: A Comprehensive Benchmark for Video Anomaly Detection in Smart Homes Using Multi-Modal Large Language Models, https://arxiv.org/pdf/2506.12992, 2025-06-15
2025-11-11 00:20:00,214 - INFO - root - Page:1, Index:42, Generative 4D Scene Gaussian Splatting with Object View-Synthesis Priors, https://arxiv.org/pdf/2506.12716, 2025-06-15
2025-11-11 00:20:00,215 - INFO - root - Page:1, Index:43, DejaVid: Encoder-Agnostic Learned Temporal Matching for Video Classification, https://arxiv.org/pdf/2506.12585, 2025-06-14
2025-11-11 00:20:00,219 - INFO - root - Page:1, Index:44, Pushing the Limits of Safety: A Technical Report on the ATLAS Challenge 2025, https://arxiv.org/pdf/2506.12430, 2025-07-10
2025-11-11 00:20:00,220 - INFO - root - Page:1, Index:45, FIMA-Q: Post-Training Quantization for Vision Transformers by Fisher Information Matrix Approximation, https://arxiv.org/pdf/2506.11543, 2025-06-13
2025-11-11 00:20:00,222 - INFO - root - Page:1, Index:46, Stop learning it all to mitigate visual hallucination, Focus on the hallucination target, https://arxiv.org/pdf/2506.11417, 2025-06-12
2025-11-11 00:20:00,222 - INFO - root - Page:1, Index:47, EfficientQuant: An Efficient Post-Training Quantization for CNN-Transformer Hybrid Models on Edge Devices, https://arxiv.org/pdf/2506.11093, 2025-06-05
2025-11-11 00:20:00,222 - INFO - root - Page:1, Index:48, HalLoc: Token-level Localization of Hallucinations for Vision Language Models, https://arxiv.org/pdf/2506.10286, 2025-06-11
2025-11-11 00:20:00,223 - INFO - root - Page:1, Index:49, DySS: Dynamic Queries and State-Space Learning for Efficient 3D Object Detection from Multi-Camera Videos, https://arxiv.org/pdf/2506.10242, 2025-06-11
2025-11-11 00:20:00,224 - INFO - root - Fetching page 3 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=100
2025-11-11 00:20:08,109 - INFO - root - get_all_titles_from_web 
2025-11-11 00:20:08,110 - INFO - root - Page:2, Index:0, Improving Personalized Search with Regularized Low-Rank Parameter Updates, https://arxiv.org/pdf/2506.10182, 2025-06-11
2025-11-11 00:20:08,110 - INFO - root - Page:2, Index:1, Hearing Hands: Generating Sounds from Physical Interactions in 3D Scenes, https://arxiv.org/pdf/2506.09989, 2025-06-11
2025-11-11 00:20:08,111 - INFO - root - Page:2, Index:2, UniPre3D: Unified Pre-training of 3D Point Cloud Models with Cross-Modal Gaussian Splatting, https://arxiv.org/pdf/2506.09952, 2025-06-11
2025-11-11 00:20:08,111 - INFO - root - Page:2, Index:3, Provoking Multi-modal Few-Shot LVLM via Exploration-Exploitation In-Context Learning, https://arxiv.org/pdf/2506.09473, 2025-06-11
2025-11-11 00:20:08,111 - INFO - root - Page:2, Index:4, Synthetic Human Action Video Data Generation with Pose Transfer, https://arxiv.org/pdf/2506.09411, 2025-06-11
2025-11-11 00:20:08,112 - INFO - root - Page:2, Index:5, ScaleLSD: Scalable Deep Line Segment Detection Streamlined, https://arxiv.org/pdf/2506.09369, 2025-06-10
2025-11-11 00:20:08,112 - INFO - root - Page:2, Index:6, CheckManual: A New Challenge and Benchmark for Manual-based Appliance Manipulation, https://arxiv.org/pdf/2506.09343, 2025-06-10
2025-11-11 00:20:08,112 - INFO - root - Page:2, Index:7, PatchGuard: Adversarially Robust Anomaly Detection and Localization through Vision Transformers and Pseudo Anomalies, https://arxiv.org/pdf/2506.09237, 2025-10-24
2025-11-11 00:20:08,112 - INFO - root - Page:2, Index:8, SILK: Smooth InterpoLation frameworK for motion in-betweening A Simplified Computational Approach, https://arxiv.org/pdf/2506.09075, 2025-06-09
2025-11-11 00:20:08,112 - INFO - root - Page:2, Index:9, BG-HOP: A Bimanual Generative Hand-Object Prior, https://arxiv.org/pdf/2506.09068, 2025-06-08
2025-11-11 00:20:08,112 - INFO - root - Page:2, Index:10, ORIDa: Object-centric Real-world Image Composition Dataset, https://arxiv.org/pdf/2506.08964, 2025-06-10
2025-11-11 00:20:08,114 - INFO - root - Page:2, Index:11, DiscoVLA: Discrepancy Reduction in Vision, Language, and Alignment for Parameter-Efficient Video-Text Retrieval, https://arxiv.org/pdf/2506.08887, 2025-06-10
2025-11-11 00:20:08,114 - INFO - root - Page:2, Index:12, A Comprehensive Study of Decoder-Only LLMs for Text-to-Image Generation, https://arxiv.org/pdf/2506.08210, 2025-06-09
2025-11-11 00:20:08,114 - INFO - root - Page:2, Index:13, Open World Scene Graph Generation using Vision Language Models, https://arxiv.org/pdf/2506.08189, 2025-06-09
2025-11-11 00:20:08,115 - INFO - root - Page:2, Index:14, Aligning Proteins and Language: A Foundation Model for Protein Retrieval, https://arxiv.org/pdf/2506.08023, 2025-05-27
2025-11-11 00:20:08,115 - INFO - root - Page:2, Index:15, UA-Pose: Uncertainty-Aware 6D Object Pose Estimation and Online Object Completion with Partial References, https://arxiv.org/pdf/2506.07996, 2025-06-09
2025-11-11 00:20:08,115 - INFO - root - Page:2, Index:16, Speedy Deformable 3D Gaussian Splatting: Fast Rendering and Compression of Dynamic Scenes, https://arxiv.org/pdf/2506.07917, 2025-06-09
2025-11-11 00:20:08,116 - INFO - root - Page:2, Index:17, GaussianVAE: Adaptive Learning Dynamics of 3D Gaussians for High-Fidelity Super-Resolution, https://arxiv.org/pdf/2506.07897, 2025-06-09
2025-11-11 00:20:08,117 - INFO - root - Page:2, Index:18, Spatio-Temporal State Space Model For Efficient Event-Based Optical Flow, https://arxiv.org/pdf/2506.07878, 2025-06-09
2025-11-11 00:20:08,119 - INFO - root - Page:2, Index:19, FreeGave: 3D Physics Learning from Dynamic Videos by Gaussian Velocity, https://arxiv.org/pdf/2506.07865, 2025-06-09
2025-11-11 00:20:08,119 - INFO - root - Page:2, Index:20, LogoSP: Local-global Grouping of Superpoints for Unsupervised Semantic Segmentation of 3D Point Clouds, https://arxiv.org/pdf/2506.07857, 2025-06-09
2025-11-11 00:20:08,122 - INFO - root - Page:2, Index:21, Difference Inversion: Interpolate and Isolate the Difference with Token Consistency for Image Analogy Generation, https://arxiv.org/pdf/2506.07750, 2025-06-09
2025-11-11 00:20:08,122 - INFO - root - Page:2, Index:22, Synthetic Visual Genome, https://arxiv.org/pdf/2506.07643, 2025-06-09
2025-11-11 00:20:08,129 - INFO - root - Page:2, Index:23, Fractional Collisions: A Framework for Risk Estimation of Counterfactual Conflicts using Autonomous Driving Behavior Simulations, https://arxiv.org/pdf/2506.07540, 2025-06-09
2025-11-11 00:20:08,129 - INFO - root - Page:2, Index:24, Multi-Step Guided Diffusion for Image Restoration on Edge Devices: Toward Lightweight Perception in Embodied AI, https://arxiv.org/pdf/2506.07286, 2025-06-08
2025-11-11 00:20:08,130 - INFO - root - Page:2, Index:25, LLM-Enhanced Rapid-Reflex Async-Reflect Embodied Agent for Real-Time Decision-Making in Dynamically Changing Environments, https://arxiv.org/pdf/2506.07223, 2025-06-08
2025-11-11 00:20:08,130 - INFO - root - Page:2, Index:26, UCOD-DPL: Unsupervised Camouflaged Object Detection via Dynamic Pseudo-label Learning, https://arxiv.org/pdf/2506.07087, 2025-06-08
2025-11-11 00:20:08,130 - INFO - root - Page:2, Index:27, BePo: Leveraging Birds Eye View and Sparse Points for Efficient and Accurate 3D Occupancy Prediction, https://arxiv.org/pdf/2506.07002, 2025-06-08
2025-11-11 00:20:08,130 - INFO - root - Page:2, Index:28, Reading in the Dark with Foveated Event Vision, https://arxiv.org/pdf/2506.06918, 2025-06-07
2025-11-11 00:20:08,131 - INFO - root - Page:2, Index:29, NSD-Imagery: A benchmark dataset for extending fMRI vision decoding methods to mental imagery, https://arxiv.org/pdf/2506.06898, 2025-06-07
2025-11-11 00:20:08,131 - INFO - root - Page:2, Index:30, Continuous-Time SO(3) Forecasting with Savitzky--Golay Neural Controlled Differential Equations, https://arxiv.org/pdf/2506.06780, 2025-06-07
2025-11-11 00:20:08,131 - INFO - root - Page:2, Index:31, Generalized Trajectory Scoring for End-to-end Multimodal Planning, https://arxiv.org/pdf/2506.06664, 2025-06-07
2025-11-11 00:20:08,132 - INFO - root - Page:2, Index:32, EV-LayerSegNet: Self-supervised Motion Segmentation using Event Cameras, https://arxiv.org/pdf/2506.06596, 2025-06-06
2025-11-11 00:20:08,132 - INFO - root - Page:2, Index:33, Vid2Sim: Generalizable, Video-based Reconstruction of Appearance, Geometry and Physics for Mesh-free Simulation, https://arxiv.org/pdf/2506.06440, 2025-06-06
2025-11-11 00:20:08,133 - INFO - root - Page:2, Index:34, FADE: Frequency-Aware Diffusion Model Factorization for Video Editing, https://arxiv.org/pdf/2506.05934, 2025-06-06
2025-11-11 00:20:08,133 - INFO - root - Page:2, Index:35, Unleashing the Potential of Consistency Learning for Detecting and Grounding Multi-Modal Media Manipulation, https://arxiv.org/pdf/2506.05890, 2025-06-06
2025-11-11 00:20:08,134 - INFO - root - Page:2, Index:36, DeformCL: Learning Deformable Centerline Representation for Vessel Extraction in 3D Medical Image, https://arxiv.org/pdf/2506.05820, 2025-06-06
2025-11-11 00:20:08,138 - INFO - root - Page:2, Index:37, NTIRE 2025 Challenge on HR Depth from Images of Specular and Transparent Surfaces, https://arxiv.org/pdf/2506.05815, 2025-06-06
2025-11-11 00:20:08,143 - INFO - root - Page:2, Index:38, GazeNLQ @ Ego4D Natural Language Queries Challenge 2025, https://arxiv.org/pdf/2506.05782, 2025-06-06
2025-11-11 00:20:08,146 - INFO - root - Page:2, Index:39, Robust sensor fusion against on-vehicle sensor staleness, https://arxiv.org/pdf/2506.05780, 2025-06-06
2025-11-11 00:20:08,146 - INFO - root - Page:2, Index:40, Where Is The Ball: 3D Ball Trajectory Estimation From 2D Monocular Tracking, https://arxiv.org/pdf/2506.05763, 2025-06-06
2025-11-11 00:20:08,147 - INFO - root - Page:2, Index:41, VoxelSplat: Dynamic Gaussian Splatting as an Effective Loss for Occupancy and Flow Prediction, https://arxiv.org/pdf/2506.05563, 2025-06-05
2025-11-11 00:20:08,147 - INFO - root - Page:2, Index:42, Gen4D: Synthesizing Humans and Scenes in the Wild, https://arxiv.org/pdf/2506.05397, 2025-06-03
2025-11-11 00:20:08,149 - INFO - root - Page:2, Index:43, Attacking Attention of Foundation Models Disrupts Downstream Tasks, https://arxiv.org/pdf/2506.05394, 2025-09-12
2025-11-11 00:20:08,149 - INFO - root - Page:2, Index:44, FreeTimeGS: Free Gaussian Primitives at Anytime and Anywhere for Dynamic Scene Reconstruction, https://arxiv.org/pdf/2506.05348, 2025-06-06
2025-11-11 00:20:08,149 - INFO - root - Page:2, Index:45, LotusFilter: Fast Diverse Nearest Neighbor Search via a Learned Cutoff Table, https://arxiv.org/pdf/2506.04790, 2025-06-05
2025-11-11 00:20:08,151 - INFO - root - Page:2, Index:46, Towards Holistic Visual Quality Assessment of AI-Generated Videos: A LLM-Based Multi-Dimensional Evaluation Model, https://arxiv.org/pdf/2506.04715, 2025-06-11
2025-11-11 00:20:08,151 - INFO - root - Page:2, Index:47, Gradient Inversion Attacks on Parameter-Efficient Fine-Tuning, https://arxiv.org/pdf/2506.04453, 2025-06-04
2025-11-11 00:20:08,152 - INFO - root - Page:2, Index:48, HMAR: Efficient Hierarchical Masked Auto-Regressive Image Generation, https://arxiv.org/pdf/2506.04421, 2025-06-04
2025-11-11 00:20:08,152 - INFO - root - Page:2, Index:49, Visualizing and Controlling Cortical Responses Using Voxel-Weighted Activation Maximization, https://arxiv.org/pdf/2506.04379, 2025-06-04
2025-11-11 00:20:08,152 - INFO - root - Fetching page 4 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=150
2025-11-11 00:20:14,479 - INFO - root - get_all_titles_from_web 
2025-11-11 00:20:14,479 - INFO - root - Page:3, Index:0, FlexGS: Train Once, Deploy Everywhere with Many-in-One Flexible 3D Gaussian Splatting, https://arxiv.org/pdf/2506.04174, 2025-06-04
2025-11-11 00:20:14,479 - INFO - root - Page:3, Index:1, Multi-view Surface Reconstruction Using Normal and Reflectance Cues, https://arxiv.org/pdf/2506.04115, 2025-06-04
2025-11-11 00:20:14,481 - INFO - root - Page:3, Index:2, Vocabulary-free few-shot learning for Vision-Language Models, https://arxiv.org/pdf/2506.04005, 2025-06-04
2025-11-11 00:20:14,482 - INFO - root - Page:3, Index:3, Learning from Noise: Enhancing DNNs for Event-Based Vision through Controlled Noise Injection, https://arxiv.org/pdf/2506.03918, 2025-06-04
2025-11-11 00:20:14,482 - INFO - root - Page:3, Index:4, Video, How Do Your Tokens Merge?, https://arxiv.org/pdf/2506.03885, 2025-06-04
2025-11-11 00:20:14,483 - INFO - root - Page:3, Index:5, OSGNet @ Ego4D Episodic Memory Challenge 2025, https://arxiv.org/pdf/2506.03710, 2025-06-04
2025-11-11 00:20:14,483 - INFO - root - Page:3, Index:6, AetherVision-Bench: An Open-Vocabulary RGB-Infrared Benchmark for Multi-Angle Segmentation across Aerial and Ground Perspectives, https://arxiv.org/pdf/2506.03709, 2025-06-04
2025-11-11 00:20:14,483 - INFO - root - Page:3, Index:7, OV-COAST: Cost Aggregation with Optimal Transport for Open-Vocabulary Semantic Segmentation, https://arxiv.org/pdf/2506.03706, 2025-06-04
2025-11-11 00:20:14,484 - INFO - root - Page:3, Index:8, Generating 6DoF Object Manipulation Trajectories from Action Description in Egocentric Vision, https://arxiv.org/pdf/2506.03605, 2025-06-04
2025-11-11 00:20:14,484 - INFO - root - Page:3, Index:9, SemNav: A Model-Based Planner for Zero-Shot Object Goal Navigation Using Vision-Foundation Models, https://arxiv.org/pdf/2506.03516, 2025-06-03
2025-11-11 00:20:14,484 - INFO - root - Page:3, Index:10, Heterogeneous Skeleton-Based Action Representation Learning, https://arxiv.org/pdf/2506.03481, 2025-06-03
2025-11-11 00:20:14,484 - INFO - root - Page:3, Index:11, Hybrid Ensemble of Segmentation-Assisted Classification and GBDT for Skin Cancer Detection with Engineered Metadata and Synthetic Lesions from ISIC 2024 Non-Dermoscopic 3D-TBP Images, https://arxiv.org/pdf/2506.03420, 2025-06-03
2025-11-11 00:20:14,484 - INFO - root - Page:3, Index:12, Self-Supervised Spatial Correspondence Across Modalities, https://arxiv.org/pdf/2506.03148, 2025-06-03
2025-11-11 00:20:14,485 - INFO - root - Page:3, Index:13, Dense Match Summarization for Faster Two-view Estimation, https://arxiv.org/pdf/2506.02893, 2025-06-03
2025-11-11 00:20:14,485 - INFO - root - Page:3, Index:14, NTIRE 2025 XGC Quality Assessment Challenge: Methods and Results, https://arxiv.org/pdf/2506.02875, 2025-06-03
2025-11-11 00:20:14,485 - INFO - root - Page:3, Index:15, FreeScene: Mixed Graph Diffusion for 3D Scene Synthesis from Free Prompts, https://arxiv.org/pdf/2506.02781, 2025-06-03
2025-11-11 00:20:14,486 - INFO - root - Page:3, Index:16, Technical Report for Ego4D Long-Term Action Anticipation Challenge 2025, https://arxiv.org/pdf/2506.02550, 2025-06-11
2025-11-11 00:20:14,486 - INFO - root - Page:3, Index:17, Probabilistic Online Event Downsampling, https://arxiv.org/pdf/2506.02547, 2025-09-23
2025-11-11 00:20:14,486 - INFO - root - Page:3, Index:18, Towards In-the-wild 3D Plane Reconstruction from a Single Image, https://arxiv.org/pdf/2506.02493, 2025-06-03
2025-11-11 00:20:14,487 - INFO - root - Page:3, Index:19, Efficient Test-time Adaptive Object Detection via Sensitivity-Guided Pruning, https://arxiv.org/pdf/2506.02462, 2025-06-03
2025-11-11 00:20:14,487 - INFO - root - Page:3, Index:20, EgoVIS@CVPR: PAIR-Net: Enhancing Egocentric Speaker Detection via Pretrained Audio-Visual Fusion and Alignment Loss, https://arxiv.org/pdf/2506.02247, 2025-09-26
2025-11-11 00:20:14,488 - INFO - root - Page:3, Index:21, Diff2Flow: Training Flow Matching Models via Diffusion Model Alignment, https://arxiv.org/pdf/2506.02221, 2025-06-02
2025-11-11 00:20:14,488 - INFO - root - Page:3, Index:22, NTIRE 2025 Challenge on RAW Image Restoration and Super-Resolution, https://arxiv.org/pdf/2506.02197, 2025-06-04
2025-11-11 00:20:14,494 - INFO - root - Page:3, Index:23, RAW Image Reconstruction from RGB on Smartphones. NTIRE 2025 Challenge Report, https://arxiv.org/pdf/2506.01947, 2025-06-02
2025-11-11 00:20:14,499 - INFO - root - Page:3, Index:24, Silence is Golden: Leveraging Adversarial Examples to Nullify Audio Control in LDM-based Talking-Head Generation, https://arxiv.org/pdf/2506.01591, 2025-06-02
2025-11-11 00:20:14,502 - INFO - root - Page:3, Index:25, SAM2-LOVE: Segment Anything Model 2 in Language-aided Audio-Visual Scenes, https://arxiv.org/pdf/2506.01558, 2025-06-02
2025-11-11 00:20:14,502 - INFO - root - Page:3, Index:26, Neural shape reconstruction from multiple views with static pattern projection, https://arxiv.org/pdf/2506.01389, 2025-06-02
2025-11-11 00:20:14,504 - INFO - root - Page:3, Index:27, SAM-I2V: Upgrading SAM to Support Promptable Video Segmentation with Less than 0.2% Training Cost, https://arxiv.org/pdf/2506.01304, 2025-06-02
2025-11-11 00:20:14,504 - INFO - root - Page:3, Index:28, Perceptual Inductive Bias Is What You Need Before Contrastive Learning, https://arxiv.org/pdf/2506.01201, 2025-06-01
2025-11-11 00:20:14,505 - INFO - root - Page:3, Index:29, Test Automation for Interactive Scenarios via Promptable Traffic Simulation, https://arxiv.org/pdf/2506.01199, 2025-06-04
2025-11-11 00:20:14,505 - INFO - root - Page:3, Index:30, GraphPad: Inference-Time 3D Scene Graph Updates for Embodied Question Answering, https://arxiv.org/pdf/2506.01174, 2025-06-01
2025-11-11 00:20:14,505 - INFO - root - Page:3, Index:31, Aligned Contrastive Loss for Long-Tailed Recognition, https://arxiv.org/pdf/2506.01071, 2025-06-01
2025-11-11 00:20:14,506 - INFO - root - Page:3, Index:32, Self-supervised ControlNet with Spatio-Temporal Mamba for Real-world Video Super-resolution, https://arxiv.org/pdf/2506.01037, 2025-06-01
2025-11-11 00:20:14,507 - INFO - root - Page:3, Index:33, ArtiScene: Language-Driven Artistic 3D Scene Generation Through Image Intermediary, https://arxiv.org/pdf/2506.00742, 2025-05-31
2025-11-11 00:20:14,507 - INFO - root - Page:3, Index:34, 3D Gaussian Splat Vulnerabilities, https://arxiv.org/pdf/2506.00280, 2025-05-30
2025-11-11 00:20:14,507 - INFO - root - Page:3, Index:35, EgoVIS@CVPR: What Changed and What Could Have Changed? State-Change Counterfactuals for Procedure-Aware Video Representation Learning, https://arxiv.org/pdf/2506.00101, 2025-09-26
2025-11-11 00:20:14,511 - INFO - root - Page:3, Index:36, CL-LoRA: Continual Low-Rank Adaptation for Rehearsal-Free Class-Incremental Learning, https://arxiv.org/pdf/2505.24816, 2025-05-30
2025-11-11 00:20:14,512 - INFO - root - Page:3, Index:37, PatchDEMUX: A Certifiably Robust Framework for Multi-label Classifiers Against Adversarial Patches, https://arxiv.org/pdf/2505.24703, 2025-05-30
2025-11-11 00:20:14,512 - INFO - root - Page:3, Index:38, Conformal Prediction for Zero-Shot Models, https://arxiv.org/pdf/2505.24693, 2025-05-30
2025-11-11 00:20:14,519 - INFO - root - Page:3, Index:39, Learning reusable concepts across different egocentric video understanding tasks, https://arxiv.org/pdf/2505.24690, 2025-05-30
2025-11-11 00:20:14,520 - INFO - root - Page:3, Index:40, Period-LLM: Extending the Periodic Capability of Multimodal Large Language Model, https://arxiv.org/pdf/2505.24476, 2025-05-30
2025-11-11 00:20:14,522 - INFO - root - Page:3, Index:41, PCIE_Interaction Solution for Ego4D Social Interaction Challenge, https://arxiv.org/pdf/2505.24404, 2025-05-30
2025-11-11 00:20:14,522 - INFO - root - Page:3, Index:42, Leadership Assessment in Pediatric Intensive Care Unit Team Training, https://arxiv.org/pdf/2505.24389, 2025-08-28
2025-11-11 00:20:14,523 - INFO - root - Page:3, Index:43, Interpreting Large Text-to-Image Diffusion Models with Dictionary Learning, https://arxiv.org/pdf/2505.24360, 2025-07-10
2025-11-11 00:20:14,523 - INFO - root - Page:3, Index:44, InteractAnything: Zero-shot Human Object Interaction Synthesis via LLM Feedback and Object Affordance Parsing, https://arxiv.org/pdf/2505.24315, 2025-05-30
2025-11-11 00:20:14,524 - INFO - root - Page:3, Index:45, MaskAdapt: Unsupervised Geometry-Aware Domain Adaptation Using Multimodal Contextual Learning and RGB-Depth Masking, https://arxiv.org/pdf/2505.24026, 2025-05-29
2025-11-11 00:20:14,524 - INFO - root - Page:3, Index:46, Argus: Vision-Centric Reasoning with Grounded Chain-of-Thought, https://arxiv.org/pdf/2505.23766, 2025-05-29
2025-11-11 00:20:14,527 - INFO - root - Page:3, Index:47, Sketch Down the FLOPs: Towards Efficient Networks for Human Sketch, https://arxiv.org/pdf/2505.23763, 2025-05-29
2025-11-11 00:20:14,527 - INFO - root - Page:3, Index:48, Boosting Domain Incremental Learning: Selecting the Optimal Parameters is All You Need, https://arxiv.org/pdf/2505.23744, 2025-05-29
2025-11-11 00:20:14,527 - INFO - root - Page:3, Index:49, DA-VPT: Semantic-Guided Visual Prompt Tuning for Vision Transformers, https://arxiv.org/pdf/2505.23694, 2025-06-01
2025-11-11 00:20:14,527 - INFO - root - Fetching page 5 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=200
2025-11-11 00:20:21,165 - INFO - root - get_all_titles_from_web 
2025-11-11 00:20:21,166 - INFO - root - Page:4, Index:0, Bridging Classical and Modern Computer Vision: PerceptiveNet for Tree Crown Semantic Segmentation, https://arxiv.org/pdf/2505.23597, 2025-05-29
2025-11-11 00:20:21,166 - INFO - root - Page:4, Index:1, Synthetic Generation and Latent Projection Denoising of Rim Lesions in Multiple Sclerosis, https://arxiv.org/pdf/2505.23353, 2025-05-29
2025-11-11 00:20:21,166 - INFO - root - Page:4, Index:2, Wav2Sem: Plug-and-Play Audio Semantic Decoupling for 3D Speech-Driven Facial Animation, https://arxiv.org/pdf/2505.23290, 2025-05-29
2025-11-11 00:20:21,167 - INFO - root - Page:4, Index:3, Proximal Algorithm Unrolling: Flexible and Efficient Reconstruction Networks for Single-Pixel Imaging, https://arxiv.org/pdf/2505.23180, 2025-05-29
2025-11-11 00:20:21,167 - INFO - root - Page:4, Index:4, HMAD: Advancing E2E Driving with Anchored Offset Proposals and Simulation-Supervised Multi-target Scoring, https://arxiv.org/pdf/2505.23129, 2025-05-29
2025-11-11 00:20:21,167 - INFO - root - Page:4, Index:5, URWKV: Unified RWKV Model with Multi-state Perspective for Low-light Image Restoration, https://arxiv.org/pdf/2505.23068, 2025-05-29
2025-11-11 00:20:21,168 - INFO - root - Page:4, Index:6, 4DTAM: Non-Rigid Tracking and Mapping via Dynamic Surface Gaussians, https://arxiv.org/pdf/2505.22859, 2025-05-28
2025-11-11 00:20:21,168 - INFO - root - Page:4, Index:7, A Probabilistic Jump-Diffusion Framework for Open-World Egocentric Activity Recognition, https://arxiv.org/pdf/2505.22858, 2025-05-28
2025-11-11 00:20:21,168 - INFO - root - Page:4, Index:8, PS4PRO: Pixel-to-pixel Supervision for Photorealistic Rendering and Optimization, https://arxiv.org/pdf/2505.22616, 2025-05-28
2025-11-11 00:20:21,169 - INFO - root - Page:4, Index:9, Universal Domain Adaptation for Semantic Segmentation, https://arxiv.org/pdf/2505.22458, 2025-06-05
2025-11-11 00:20:21,169 - INFO - root - Page:4, Index:10, Zero-Shot 3D Visual Grounding from Vision-Language Models, https://arxiv.org/pdf/2505.22429, 2025-05-28
2025-11-11 00:20:21,170 - INFO - root - Page:4, Index:11, RC-AutoCalib: An End-to-End Radar-Camera Automatic Calibration Network, https://arxiv.org/pdf/2505.22427, 2025-05-28
2025-11-11 00:20:21,170 - INFO - root - Page:4, Index:12, Bringing CLIP to the Clinic: Dynamic Soft Labels and Negation-Aware Learning for Medical Analysis, https://arxiv.org/pdf/2505.22079, 2025-05-28
2025-11-11 00:20:21,170 - INFO - root - Page:4, Index:13, Point-to-Region Loss for Semi-Supervised Point-Based Crowd Counting, https://arxiv.org/pdf/2505.21943, 2025-05-27
2025-11-11 00:20:21,172 - INFO - root - Page:4, Index:14, FRAMES-VQA: Benchmarking Fine-Tuning Robustness across Multi-Modal Shifts in Visual Question Answering, https://arxiv.org/pdf/2505.21755, 2025-06-20
2025-11-11 00:20:21,173 - INFO - root - Page:4, Index:15, Knowledge Distillation Approach for SOS Fusion Staging: Towards Fully Automated Skeletal Maturity Assessment, https://arxiv.org/pdf/2505.21561, 2025-05-26
2025-11-11 00:20:21,173 - INFO - root - Page:4, Index:16, Enhancing Vision Transformer Explainability Using Artificial Astrocytes, https://arxiv.org/pdf/2505.21513, 2025-05-20
2025-11-11 00:20:21,173 - INFO - root - Page:4, Index:17, Empowering Vector Graphics with Consistently Arbitrary Viewing and View-dependent Visibility, https://arxiv.org/pdf/2505.21377, 2025-05-27
2025-11-11 00:20:21,174 - INFO - root - Page:4, Index:18, Structure from Collision, https://arxiv.org/pdf/2505.21335, 2025-05-27
2025-11-11 00:20:21,176 - INFO - root - Page:4, Index:19, Boosting Adversarial Transferability via High-Frequency Augmentation and Hierarchical-Gradient Fusion, https://arxiv.org/pdf/2505.21181, 2025-05-27
2025-11-11 00:20:21,178 - INFO - root - Page:4, Index:20, RefAV: Towards Planning-Centric Scenario Mining, https://arxiv.org/pdf/2505.20981, 2025-06-18
2025-11-11 00:20:21,178 - INFO - root - Page:4, Index:21, PMA: Towards Parameter-Efficient Point Cloud Understanding via Point Mamba Adapter, https://arxiv.org/pdf/2505.20941, 2025-05-27
2025-11-11 00:20:21,180 - INFO - root - Page:4, Index:22, HuMoCon: Concept Discovery for Human Motion Understanding, https://arxiv.org/pdf/2505.20920, 2025-05-27
2025-11-11 00:20:21,181 - INFO - root - Page:4, Index:23, Exploring Timeline Control for Facial Motion Generation, https://arxiv.org/pdf/2505.20861, 2025-05-27
2025-11-11 00:20:21,181 - INFO - root - Page:4, Index:24, ConText-CIR: Learning from Concepts in Text for Composed Image Retrieval, https://arxiv.org/pdf/2505.20764, 2025-05-27
2025-11-11 00:20:21,181 - INFO - root - Page:4, Index:25, HCQA-1.5 @ Ego4D EgoSchema Challenge 2025, https://arxiv.org/pdf/2505.20644, 2025-05-26
2025-11-11 00:20:21,183 - INFO - root - Page:4, Index:26, Roboflow100-VL: A Multi-Domain Object Detection Benchmark for Vision-Language Models, https://arxiv.org/pdf/2505.20612, 2025-10-22
2025-11-11 00:20:21,184 - INFO - root - Page:4, Index:27, MotionPro: A Precise Motion Controller for Image-to-Video Generation, https://arxiv.org/pdf/2505.20287, 2025-05-26
2025-11-11 00:20:21,185 - INFO - root - Page:4, Index:28, Category-Agnostic Neural Object Rigging, https://arxiv.org/pdf/2505.20283, 2025-05-26
2025-11-11 00:20:21,187 - INFO - root - Page:4, Index:29, Towards Video to Piano Music Generation with Chain-of-Perform Support Benchmarks, https://arxiv.org/pdf/2505.20038, 2025-05-26
2025-11-11 00:20:21,191 - INFO - root - Page:4, Index:30, Can Visual Encoder Learn to See Arrows?, https://arxiv.org/pdf/2505.19944, 2025-05-26
2025-11-11 00:20:21,191 - INFO - root - Page:4, Index:31, GoLF-NRT: Integrating Global Context and Local Geometry for Few-Shot View Synthesis, https://arxiv.org/pdf/2505.19813, 2025-05-26
2025-11-11 00:20:21,192 - INFO - root - Page:4, Index:32, Depth-Guided Bundle Sampling for Efficient Generalizable Neural Radiance Field Reconstruction, https://arxiv.org/pdf/2505.19793, 2025-05-26
2025-11-11 00:20:21,192 - INFO - root - Page:4, Index:33, SuperAD: A Training-free Anomaly Classification and Segmentation Method for CVPR 2025 VAND 3.0 Workshop Challenge Track 1: Adapt & Detect, https://arxiv.org/pdf/2505.19750, 2025-05-27
2025-11-11 00:20:21,194 - INFO - root - Page:4, Index:34, Knowledge-Aligned Counterfactual-Enhancement Diffusion Perception for Unsupervised Cross-Domain Visual Emotion Recognition, https://arxiv.org/pdf/2505.19694, 2025-05-26
2025-11-11 00:20:21,195 - INFO - root - Page:4, Index:35, Rotation-Equivariant Self-Supervised Method in Image Denoising, https://arxiv.org/pdf/2505.19618, 2025-05-26
2025-11-11 00:20:21,195 - INFO - root - Page:4, Index:36, NTIRE 2025 Challenge on Video Quality Enhancement for Video Conferencing: Datasets, Methods and Results, https://arxiv.org/pdf/2505.18988, 2025-05-25
2025-11-11 00:20:21,195 - INFO - root - Page:4, Index:37, Geometry-guided Online 3D Video Synthesis with Multi-View Temporal Consistency, https://arxiv.org/pdf/2505.18932, 2025-05-24
2025-11-11 00:20:21,196 - INFO - root - Page:4, Index:38, Digital Overconsumption and Waste: A Closer Look at the Impacts of Generative AI, https://arxiv.org/pdf/2505.18894, 2025-05-24
2025-11-11 00:20:21,196 - INFO - root - Page:4, Index:39, VISTA: Vision-Language Inference for Training-Free Stock Time-Series Analysis, https://arxiv.org/pdf/2505.18570, 2025-06-11
2025-11-11 00:20:21,197 - INFO - root - Page:4, Index:40, Syn3DTxt: Embedding 3D Cues for Scene Text Generation, https://arxiv.org/pdf/2505.18479, 2025-05-23
2025-11-11 00:20:21,198 - INFO - root - Page:4, Index:41, CTRL-GS: Cascaded Temporal Residue Learning for 4D Gaussian Splatting, https://arxiv.org/pdf/2505.18306, 2025-05-31
2025-11-11 00:20:21,198 - INFO - root - Page:4, Index:42, DualTalk: Dual-Speaker Interaction for 3D Talking Head Conversations, https://arxiv.org/pdf/2505.18096, 2025-05-26
2025-11-11 00:20:21,201 - INFO - root - Page:4, Index:43, SeaLion: Semantic Part-Aware Latent Point Diffusion Models for 3D Generation, https://arxiv.org/pdf/2505.17721, 2025-07-07
2025-11-11 00:20:21,201 - INFO - root - Page:4, Index:44, PoseBH: Prototypical Multi-Dataset Training Beyond Human Pose Estimation, https://arxiv.org/pdf/2505.17475, 2025-05-23
2025-11-11 00:20:21,202 - INFO - root - Page:4, Index:45, Pursuing Temporal-Consistent Video Virtual Try-On via Dynamic Pose Interaction, https://arxiv.org/pdf/2505.16980, 2025-05-22
2025-11-11 00:20:21,207 - INFO - root - Page:4, Index:46, UniPhy: Learning a Unified Constitutive Model for Inverse Physics Simulation, https://arxiv.org/pdf/2505.16971, 2025-05-22
2025-11-11 00:20:21,207 - INFO - root - Page:4, Index:47, Tracking the Flight: Exploring a Computational Framework for Analyzing Escape Responses in Plains Zebra (Equus quagga), https://arxiv.org/pdf/2505.16882, 2025-05-23
2025-11-11 00:20:21,210 - INFO - root - Page:4, Index:48, Semi-Supervised State-Space Model with Dynamic Stacking Filter for Real-World Video Deraining, https://arxiv.org/pdf/2505.16811, 2025-05-22
2025-11-11 00:20:21,210 - INFO - root - Page:4, Index:49, SOLVE: Synergy of Language-Vision and End-to-End Networks for Autonomous Driving, https://arxiv.org/pdf/2505.16805, 2025-05-22
2025-11-11 00:20:21,210 - INFO - root - Fetching page 6 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=250
2025-11-11 00:20:27,839 - INFO - root - get_all_titles_from_web 
2025-11-11 00:20:27,839 - INFO - root - Page:5, Index:0, Four Eyes Are Better Than Two: Harnessing the Collaborative Potential of Large Models via Differentiated Thinking and Complementary Ensembles, https://arxiv.org/pdf/2505.16784, 2025-06-07
2025-11-11 00:20:27,840 - INFO - root - Page:5, Index:1, Single Domain Generalization for Few-Shot Counting via Universal Representation Matching, https://arxiv.org/pdf/2505.16778, 2025-05-22
2025-11-11 00:20:27,840 - INFO - root - Page:5, Index:2, Seeing Far and Clearly: Mitigating Hallucinations in MLLMs with Attention Causal Decoding, https://arxiv.org/pdf/2505.16652, 2025-06-07
2025-11-11 00:20:27,840 - INFO - root - Page:5, Index:3, Sketchy Bounding-box Supervision for 3D Instance Segmentation, https://arxiv.org/pdf/2505.16399, 2025-05-22
2025-11-11 00:20:27,841 - INFO - root - Page:5, Index:4, DeCafNet: Delegate and Conquer for Efficient Temporal Grounding in Long Videos, https://arxiv.org/pdf/2505.16376, 2025-05-22
2025-11-11 00:20:27,841 - INFO - root - Page:5, Index:5, NTIRE 2025 challenge on Text to Image Generation Model Quality Assessment, https://arxiv.org/pdf/2505.16314, 2025-05-22
2025-11-11 00:20:27,841 - INFO - root - Page:5, Index:6, Analyzing Hierarchical Structure in Vision Models with Sparse Autoencoders, https://arxiv.org/pdf/2505.15970, 2025-05-21
2025-11-11 00:20:27,841 - INFO - root - Page:5, Index:7, Efficient Data Driven Mixture-of-Expert Extraction from Trained Networks, https://arxiv.org/pdf/2505.15414, 2025-05-21
2025-11-11 00:20:27,842 - INFO - root - Page:5, Index:8, Mouse Lockbox Dataset: Behavior Recognition for Mice Solving Lockboxes, https://arxiv.org/pdf/2505.15408, 2025-06-17
2025-11-11 00:20:27,842 - INFO - root - Page:5, Index:9, Zero-Shot Gaze-based Volumetric Medical Image Segmentation, https://arxiv.org/pdf/2505.15256, 2025-06-10
2025-11-11 00:20:27,842 - INFO - root - Page:5, Index:10, Dual Precision Quantization for Efficient and Accurate Deep Neural Networks Inference, https://arxiv.org/pdf/2505.14638, 2025-05-20
2025-11-11 00:20:27,842 - INFO - root - Page:5, Index:11, Neural Video Compression with Context Modulation, https://arxiv.org/pdf/2505.14541, 2025-05-20
2025-11-11 00:20:27,843 - INFO - root - Page:5, Index:12, Selective Structured State Space for Multispectral-fused Small Target Detection, https://arxiv.org/pdf/2505.14043, 2025-05-23
2025-11-11 00:20:27,844 - INFO - root - Page:5, Index:13, OmniStyle: Filtering High Quality Style Transfer Data at Scale, https://arxiv.org/pdf/2505.14028, 2025-05-20
2025-11-11 00:20:27,845 - INFO - root - Page:5, Index:14, Domain Adaptation of VLM for Soccer Video Understanding, https://arxiv.org/pdf/2505.13860, 2025-07-07
2025-11-11 00:20:27,846 - INFO - root - Page:5, Index:15, Ground-V: Teaching VLMs to Ground Complex Instructions in Pixels, https://arxiv.org/pdf/2505.13788, 2025-05-19
2025-11-11 00:20:27,847 - INFO - root - Page:5, Index:16, FinePhys: Fine-grained Human Action Generation by Explicitly Incorporating Physical Laws for Effective Skeletal Guidance, https://arxiv.org/pdf/2505.13437, 2025-05-19
2025-11-11 00:20:27,847 - INFO - root - Page:5, Index:17, The Way Up: A Dataset for Hold Usage Detection in Sport Climbing, https://arxiv.org/pdf/2505.12854, 2025-05-19
2025-11-11 00:20:27,849 - INFO - root - Page:5, Index:18, PEER pressure: Model-to-Model Regularization for Single Source Domain Generalization, https://arxiv.org/pdf/2505.12745, 2025-05-19
2025-11-11 00:20:27,849 - INFO - root - Page:5, Index:19, Mamba-Adaptor: State Space Model Adaptor for Visual Recognition, https://arxiv.org/pdf/2505.12685, 2025-05-19
2025-11-11 00:20:27,969 - INFO - root - Page:5, Index:20, Scalable Video-to-Dataset Generation for Cross-Platform Mobile Agents, https://arxiv.org/pdf/2505.12632, 2025-05-18
2025-11-11 00:20:28,033 - INFO - root - Page:5, Index:21, Degradation-Aware Feature Perturbation for All-in-One Image Restoration, https://arxiv.org/pdf/2505.12630, 2025-05-18
2025-11-11 00:20:28,040 - INFO - root - Page:5, Index:22, Guiding Diffusion with Deep Geometric Moments: Balancing Fidelity and Variation, https://arxiv.org/pdf/2505.12486, 2025-05-18
2025-11-11 00:20:28,046 - INFO - root - Page:5, Index:23, Learning to Highlight Audio by Watching Movies, https://arxiv.org/pdf/2505.12154, 2025-05-17
2025-11-11 00:20:28,051 - INFO - root - Page:5, Index:24, Understanding the Capabilities of Molecular Graph Neural Networks in Materials Science Through Multimodal Learning and Physical Context Encoding, https://arxiv.org/pdf/2505.12137, 2025-05-17
2025-11-11 00:20:28,099 - INFO - root - Page:5, Index:25, iSegMan: Interactive Segment-and-Manipulate 3D Gaussians, https://arxiv.org/pdf/2505.11934, 2025-05-17
2025-11-11 00:20:28,102 - INFO - root - Page:5, Index:26, Self-Learning Hyperspectral and Multispectral Image Fusion via Adaptive Residual Guided Subspace Diffusion Model, https://arxiv.org/pdf/2505.11800, 2025-05-16
2025-11-11 00:20:28,102 - INFO - root - Page:5, Index:27, X-Edit: Detecting and Localizing Edits in Images Altered by Text-Guided Diffusion Models, https://arxiv.org/pdf/2505.11753, 2025-05-16
2025-11-11 00:20:28,102 - INFO - root - Page:5, Index:28, MTevent: A Multi-Task Event Camera Dataset for 6D Pose Estimation and Moving Object Detection, https://arxiv.org/pdf/2505.11282, 2025-06-02
2025-11-11 00:20:28,103 - INFO - root - Page:5, Index:29, Imputation-free and Alignment-free: Incomplete Multi-view Clustering Driven by Consensus Semantic Learning, https://arxiv.org/pdf/2505.11182, 2025-05-16
2025-11-11 00:20:28,104 - INFO - root - Page:5, Index:30, MultiLink: Multi-class Structure Recovery via Agglomerative Clustering and Model Selection, https://arxiv.org/pdf/2505.10874, 2025-05-16
2025-11-11 00:20:28,104 - INFO - root - Page:5, Index:31, RefPose: Leveraging Reference Geometric Correspondences for Accurate 6D Pose Estimation of Unseen Objects, https://arxiv.org/pdf/2505.10841, 2025-05-16
2025-11-11 00:20:28,105 - INFO - root - Page:5, Index:32, MoCLIP: Motion-Aware Fine-Tuning and Distillation of CLIP for Human Motion Generation, https://arxiv.org/pdf/2505.10810, 2025-05-15
2025-11-11 00:20:28,107 - INFO - root - Page:5, Index:33, Automated Detection of Salvin's Albatrosses: Improving Deep Learning Tools for Aerial Wildlife Surveys, https://arxiv.org/pdf/2505.10737, 2025-05-15
2025-11-11 00:20:28,107 - INFO - root - Page:5, Index:34, Advancing Multiple Instance Learning with Continual Learning for Whole Slide Imaging, https://arxiv.org/pdf/2505.10649, 2025-05-15
2025-11-11 00:20:28,107 - INFO - root - Page:5, Index:35, Inferring Driving Maps by Deep Learning-based Trail Map Extraction, https://arxiv.org/pdf/2505.10258, 2025-05-15
2025-11-11 00:20:28,108 - INFO - root - Page:5, Index:36, Behind Maya: Building a Multilingual Vision Language Model, https://arxiv.org/pdf/2505.08910, 2025-05-15
2025-11-11 00:20:28,108 - INFO - root - Page:5, Index:37, PosterO: Structuring Layout Trees to Enable Language Models in Generalized Content-Aware Layout Generation, https://arxiv.org/pdf/2505.07843, 2025-05-26
2025-11-11 00:20:28,108 - INFO - root - Page:5, Index:38, Prototype Augmented Hypernetworks for Continual Learning, https://arxiv.org/pdf/2505.07450, 2025-05-16
2025-11-11 00:20:28,112 - INFO - root - Fetching page 7 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=300
2025-11-11 00:20:35,825 - INFO - root - get_all_titles_from_web 
2025-11-11 00:20:35,825 - INFO - root - Page:6, Index:0, Convex Relaxation for Robust Vanishing Point Estimation in Manhattan World, https://arxiv.org/pdf/2505.04788, 2025-06-05
2025-11-11 00:20:35,826 - INFO - root - Page:6, Index:1, S3D: Sketch-Driven 3D Model Generation, https://arxiv.org/pdf/2505.04185, 2025-06-03
2025-11-11 00:20:35,826 - INFO - root - Page:6, Index:2, Generating Synthetic Data via Augmentations for Improved Facial Resemblance in DreamBooth and InstantID, https://arxiv.org/pdf/2505.03557, 2025-07-17
2025-11-11 00:20:35,826 - INFO - root - Page:6, Index:3, CAV-MAE Sync: Improving Contrastive Audio-Visual Mask Autoencoders via Fine-Grained Alignment, https://arxiv.org/pdf/2505.01237, 2025-05-21
2025-11-11 00:20:35,826 - INFO - root - Fetching page 8 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=350
2025-11-11 00:20:43,715 - INFO - root - get_all_titles_from_web 
2025-11-11 00:20:43,716 - INFO - root - Page:7, Index:0, Where's the liability in the Generative Era? Recovery-based Black-Box Detection of AI-Generated Content, https://arxiv.org/pdf/2505.01008, 2025-08-25
2025-11-11 00:20:43,716 - INFO - root - Page:7, Index:1, SpatialLLM: A Compound 3D-Informed Design towards Spatially-Intelligent Large Multimodal Models, https://arxiv.org/pdf/2505.00788, 2025-06-10
2025-11-11 00:20:43,716 - INFO - root - Page:7, Index:2, Prisma: An Open Source Toolkit for Mechanistic Interpretability in Vision and Video, https://arxiv.org/pdf/2504.19475, 2025-06-03
2025-11-11 00:20:43,717 - INFO - root - Page:7, Index:3, SSL4Eco: A Global Seasonal Dataset for Geospatial Foundation Models in Ecology, https://arxiv.org/pdf/2504.18256, 2025-10-20
2025-11-11 00:20:43,717 - INFO - root - Page:7, Index:4, Vision-Language Models Are Not Pragmatically Competent in Referring Expression Generation, https://arxiv.org/pdf/2504.16060, 2025-07-30
2025-11-11 00:20:43,718 - INFO - root - Fetching page 9 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=400
2025-11-11 00:20:51,605 - INFO - root - get_all_titles_from_web 
2025-11-11 00:20:51,605 - INFO - root - Page:8, Index:0, Leveraging Automatic CAD Annotations for Supervised Learning in 3D Scene Understanding, https://arxiv.org/pdf/2504.13580, 2025-05-16
2025-11-11 00:20:51,606 - INFO - root - Page:8, Index:1, CAP-Net: A Unified Network for 6D Pose and Size Estimation of Categorical Articulated Parts from a Single RGB-D Image, https://arxiv.org/pdf/2504.11230, 2025-06-02
2025-11-11 00:20:51,606 - INFO - root - Page:8, Index:2, Video Summarization with Large Language Models, https://arxiv.org/pdf/2504.11199, 2025-06-05
2025-11-11 00:20:51,606 - INFO - root - Page:8, Index:3, R-TPT: Improving Adversarial Robustness of Vision-Language Models through Test-Time Prompt Tuning, https://arxiv.org/pdf/2504.11195, 2025-08-27
2025-11-11 00:20:51,606 - INFO - root - Page:8, Index:4, TerraMesh: A Planetary Mosaic of Multimodal Earth Observation Data, https://arxiv.org/pdf/2504.11172, 2025-08-01
2025-11-11 00:20:51,607 - INFO - root - Page:8, Index:5, Seeing like a Cephalopod: Colour Vision with a Monochrome Event Camera, https://arxiv.org/pdf/2504.10984, 2025-06-06
2025-11-11 00:20:51,607 - INFO - root - Page:8, Index:6, Hearing Anywhere in Any Environment, https://arxiv.org/pdf/2504.10746, 2025-06-04
2025-11-11 00:20:51,607 - INFO - root - Fetching page 10 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=450
2025-11-11 00:20:58,171 - INFO - root - get_all_titles_from_web 
2025-11-11 00:20:58,171 - INFO - root - Page:9, Index:0, Correlative and Discriminative Label Grouping for Multi-Label Visual Prompt Tuning, https://arxiv.org/pdf/2504.09990, 2025-07-09
2025-11-11 00:20:58,172 - INFO - root - Page:9, Index:1, SPICE: A Synergistic, Precise, Iterative, and Customizable Image Editing Workflow, https://arxiv.org/pdf/2504.09697, 2025-10-16
2025-11-11 00:20:58,172 - INFO - root - Page:9, Index:2, Mimic In-Context Learning for Multimodal Tasks, https://arxiv.org/pdf/2504.08851, 2025-05-17
2025-11-11 00:20:58,172 - INFO - root - Page:9, Index:3, Digital Twin Catalog: A Large-Scale Photorealistic 3D Object Digital Twin Dataset, https://arxiv.org/pdf/2504.08541, 2025-05-18
2025-11-11 00:20:58,172 - INFO - root - Page:9, Index:4, MMLA: Multi-Environment, Multi-Species, Low-Altitude Drone Dataset, https://arxiv.org/pdf/2504.07744, 2025-10-22
2025-11-11 00:20:58,172 - INFO - root - Fetching page 11 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=500
2025-11-11 00:21:06,578 - INFO - root - get_all_titles_from_web 
2025-11-11 00:21:06,579 - INFO - root - Page:10, Index:0, PromptHMR: Promptable Human Mesh Recovery, https://arxiv.org/pdf/2504.06397, 2025-05-23
2025-11-11 00:21:06,579 - INFO - root - Page:10, Index:1, SCAM: A Real-World Typographic Robustness Evaluation for Multimodal Foundation Models, https://arxiv.org/pdf/2504.04893, 2025-09-26
2025-11-11 00:21:06,580 - INFO - root - Fetching page 12 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=550
2025-11-11 00:21:13,544 - INFO - root - get_all_titles_from_web 
2025-11-11 00:21:13,545 - INFO - root - Page:11, Index:0, Charm: The Missing Piece in ViT fine-tuning for Image Aesthetic Assessment, https://arxiv.org/pdf/2504.02522, 2025-05-15
2025-11-11 00:21:13,545 - INFO - root - Page:11, Index:1, T*: Re-thinking Temporal Search for Long-Form Video Understanding, https://arxiv.org/pdf/2504.02259, 2025-08-24
2025-11-11 00:21:13,546 - INFO - root - Page:11, Index:2, CoMatcher: Multi-View Collaborative Feature Matching, https://arxiv.org/pdf/2504.01872, 2025-08-20
2025-11-11 00:21:13,546 - INFO - root - Page:11, Index:3, Think Small, Act Big: Primitive Prompt Learning for Lifelong Robot Manipulation, https://arxiv.org/pdf/2504.00420, 2025-06-01
2025-11-11 00:21:13,547 - INFO - root - Fetching page 13 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=600
2025-11-11 00:21:20,290 - INFO - root - get_all_titles_from_web 
2025-11-11 00:21:20,291 - INFO - root - Page:12, Index:0, It's a (Blind) Match! Towards Vision-Language Correspondence without Parallel Data, https://arxiv.org/pdf/2503.24129, 2025-05-29
2025-11-11 00:21:20,292 - INFO - root - Page:12, Index:1, ReferDINO-Plus: 2nd Solution for 4th PVUW MeViS Challenge at CVPR 2025, https://arxiv.org/pdf/2503.23509, 2025-05-29
2025-11-11 00:21:20,292 - INFO - root - Page:12, Index:2, A Unified Image-Dense Annotation Generation Model for Underwater Scenes, https://arxiv.org/pdf/2503.21771, 2025-07-27
2025-11-11 00:21:20,292 - INFO - root - Fetching page 14 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=650
2025-11-11 00:21:28,461 - INFO - root - get_all_titles_from_web 
2025-11-11 00:21:28,462 - INFO - root - Page:13, Index:0, Learning Class Prototypes for Unified Sparse Supervised 3D Object Detection, https://arxiv.org/pdf/2503.21099, 2025-06-13
2025-11-11 00:21:28,462 - INFO - root - Page:13, Index:1, LATTE-MV: Learning to Anticipate Table Tennis Hits from Monocular Videos, https://arxiv.org/pdf/2503.20936, 2025-09-01
2025-11-11 00:21:28,462 - INFO - root - Page:13, Index:2, BizGen: Advancing Article-level Visual Text Rendering for Infographics Generation, https://arxiv.org/pdf/2503.20672, 2025-07-02
2025-11-11 00:21:28,463 - INFO - root - Page:13, Index:3, ITA-MDT: Image-Timestep-Adaptive Masked Diffusion Transformer Framework for Image-Based Virtual Try-On, https://arxiv.org/pdf/2503.20418, 2025-06-01
2025-11-11 00:21:28,464 - INFO - root - Page:13, Index:4, Faster Parameter-Efficient Tuning with Token Redundancy Reduction, https://arxiv.org/pdf/2503.20282, 2025-08-26
2025-11-11 00:21:28,464 - INFO - root - Page:13, Index:5, DINeMo: Learning Neural Mesh Models with no 3D Annotations, https://arxiv.org/pdf/2503.20220, 2025-06-09
2025-11-11 00:21:28,465 - INFO - root - Page:13, Index:6, Scaling Vision Pre-Training to 4K Resolution, https://arxiv.org/pdf/2503.19903, 2025-08-03
2025-11-11 00:21:28,465 - INFO - root - Page:13, Index:7, GENIUS: A Generative Framework for Universal Multimodal Search, https://arxiv.org/pdf/2503.19868, 2025-06-05
2025-11-11 00:21:28,466 - INFO - root - Fetching page 15 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=700
2025-11-11 00:21:35,978 - INFO - root - get_all_titles_from_web 
2025-11-11 00:21:35,979 - INFO - root - Page:14, Index:0, Galaxy Walker: Geometry-aware VLMs For Galaxy-scale Understanding, https://arxiv.org/pdf/2503.18578, 2025-05-25
2025-11-11 00:21:35,980 - INFO - root - Page:14, Index:1, LookCloser: Frequency-aware Radiance Field for Tiny-Detail Scene, https://arxiv.org/pdf/2503.18513, 2025-07-29
2025-11-11 00:21:35,980 - INFO - root - Fetching page 16 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=750
2025-11-11 00:21:43,144 - INFO - root - get_all_titles_from_web 
2025-11-11 00:21:43,144 - INFO - root - Page:15, Index:0, LoTUS: Large-Scale Machine Unlearning with a Taste of Uncertainty, https://arxiv.org/pdf/2503.18314, 2025-05-29
2025-11-11 00:21:43,144 - INFO - root - Page:15, Index:1, MammAlps: A multi-view video behavior monitoring dataset of wild mammals in the Swiss Alps, https://arxiv.org/pdf/2503.18223, 2025-06-04
2025-11-11 00:21:43,145 - INFO - root - Page:15, Index:2, Progressive Prompt Detailing for Improved Alignment in Text-to-Image Generative Models, https://arxiv.org/pdf/2503.17794, 2025-05-30
2025-11-11 00:21:43,145 - INFO - root - Page:15, Index:3, CountLLM: Towards Generalizable Repetitive Action Counting via Large Language Model, https://arxiv.org/pdf/2503.17690, 2025-06-29
2025-11-11 00:21:43,145 - INFO - root - Page:15, Index:4, TaoAvatar: Real-Time Lifelike Full-Body Talking Avatars for Augmented Reality via 3D Gaussian Splatting, https://arxiv.org/pdf/2503.17032, 2025-07-23
2025-11-11 00:21:43,146 - INFO - root - Page:15, Index:5, Generalized Few-shot 3D Point Cloud Segmentation with Vision-Language Model, https://arxiv.org/pdf/2503.16282, 2025-05-20
2025-11-11 00:21:43,146 - INFO - root - Fetching page 17 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=800
2025-11-11 00:21:49,448 - INFO - root - get_all_titles_from_web 
2025-11-11 00:21:49,449 - INFO - root - Page:16, Index:0, High Temporal Consistency through Semantic Similarity Propagation in Semi-Supervised Video Semantic Segmentation for Autonomous Flight, https://arxiv.org/pdf/2503.15676, 2025-06-26
2025-11-11 00:21:49,449 - INFO - root - Page:16, Index:1, DPFlow: Adaptive Optical Flow Estimation with a Dual-Pyramid Framework, https://arxiv.org/pdf/2503.14880, 2025-09-29
2025-11-11 00:21:49,449 - INFO - root - Fetching page 18 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=850
2025-11-11 00:21:56,341 - INFO - root - get_all_titles_from_web 
2025-11-11 00:21:56,342 - INFO - root - Page:17, Index:0, From Head to Tail: Towards Balanced Representation in Large Vision-Language Models through Adaptive Data Calibration, https://arxiv.org/pdf/2503.12821, 2025-05-29
2025-11-11 00:21:56,342 - INFO - root - Page:17, Index:1, MambaIC: State Space Models for High-Performance Learned Image Compression, https://arxiv.org/pdf/2503.12461, 2025-08-22
2025-11-11 00:21:56,342 - INFO - root - Page:17, Index:2, Localized Concept Erasure for Text-to-Image Diffusion Models Using Training-Free Gated Low-Rank Adaptation, https://arxiv.org/pdf/2503.12356, 2025-07-09
2025-11-11 00:21:56,344 - INFO - root - Page:17, Index:3, TASTE-Rob: Advancing Video Generation of Task-Oriented Hand-Object Interaction for Generalizable Robotic Manipulation, https://arxiv.org/pdf/2503.11423, 2025-06-05
2025-11-11 00:21:56,344 - INFO - root - Page:17, Index:4, Panopticon: Advancing Any-Sensor Foundation Models for Earth Observation, https://arxiv.org/pdf/2503.10845, 2025-08-01
2025-11-11 00:21:56,344 - INFO - root - Page:17, Index:5, Transformers without Normalization, https://arxiv.org/pdf/2503.10622, 2025-06-14
2025-11-11 00:21:56,345 - INFO - root - Page:17, Index:6, dFLMoE: Decentralized Federated Learning via Mixture of Experts for Medical Data Analysis, https://arxiv.org/pdf/2503.10412, 2025-05-19
2025-11-11 00:21:56,345 - INFO - root - Fetching page 19 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=900
2025-11-11 00:22:03,280 - INFO - root - get_all_titles_from_web 
2025-11-11 00:22:03,280 - INFO - root - Page:18, Index:0, Project-Probe-Aggregate: Efficient Fine-Tuning for Group Robustness, https://arxiv.org/pdf/2503.09487, 2025-08-26
2025-11-11 00:22:03,280 - INFO - root - Page:18, Index:1, VLog: Video-Language Models by Generative Retrieval of Narration Vocabulary, https://arxiv.org/pdf/2503.09402, 2025-06-09
2025-11-11 00:22:03,282 - INFO - root - Fetching page 20 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=950
2025-11-11 00:22:11,506 - INFO - root - get_all_titles_from_web 
2025-11-11 00:22:11,506 - INFO - root - Page:19, Index:0, Escaping Plato's Cave: Towards the Alignment of 3D and Text Latent Spaces, https://arxiv.org/pdf/2503.05283, 2025-06-04
2025-11-11 00:22:11,508 - INFO - root - Page:19, Index:1, FluidNexus: 3D Fluid Reconstruction and Prediction from a Single Video, https://arxiv.org/pdf/2503.04720, 2025-07-09
2025-11-11 00:22:11,508 - INFO - root - Page:19, Index:2, Question-Aware Gaussian Experts for Audio-Visual Question Answering, https://arxiv.org/pdf/2503.04459, 2025-06-11
2025-11-11 00:22:11,508 - INFO - root - Page:19, Index:3, Q-Eval-100K: Evaluating Visual Quality and Alignment Level for Text-to-Vision Content, https://arxiv.org/pdf/2503.02357, 2025-06-15
2025-11-11 00:22:11,509 - INFO - root - Fetching page 21 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=1000
2025-11-11 00:22:18,399 - INFO - root - get_all_titles_from_web 
2025-11-11 00:22:18,399 - INFO - root - Page:20, Index:0, Data Distributional Properties As Inductive Bias for Systematic Generalization, https://arxiv.org/pdf/2502.20499, 2025-06-17
2025-11-11 00:22:18,400 - INFO - root - Page:20, Index:1, Knowledge Bridger: Towards Training-free Missing Modality Completion, https://arxiv.org/pdf/2502.19834, 2025-06-17
2025-11-11 00:22:18,400 - INFO - root - Fetching page 22 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=1050
2025-11-11 00:22:25,340 - INFO - root - get_all_titles_from_web 
2025-11-11 00:22:25,341 - INFO - root - Page:21, Index:0, MALT Diffusion: Memory-Augmented Latent Transformers for Any-Length Video Generation, https://arxiv.org/pdf/2502.12632, 2025-07-08
2025-11-11 00:22:25,341 - INFO - root - Page:21, Index:1, ILIAS: Instance-Level Image retrieval At Scale, https://arxiv.org/pdf/2502.11748, 2025-06-23
2025-11-11 00:22:25,341 - INFO - root - Page:21, Index:2, Distraction is All You Need for Multimodal Large Language Model Jailbreaking, https://arxiv.org/pdf/2502.10794, 2025-06-16
2025-11-11 00:22:25,342 - INFO - root - Page:21, Index:3, Spatial457: A Diagnostic Benchmark for 6D Spatial Reasoning of Large Multimodal Models, https://arxiv.org/pdf/2502.08636, 2025-06-08
2025-11-11 00:22:25,342 - INFO - root - Page:21, Index:4, TRAVEL: Training-Free Retrieval and Alignment for Vision-and-Language Navigation, https://arxiv.org/pdf/2502.07306, 2025-06-09
2025-11-11 00:22:25,342 - INFO - root - Page:21, Index:5, DiTASK: Multi-Task Fine-Tuning with Diffeomorphic Transformations, https://arxiv.org/pdf/2502.06029, 2025-06-01
2025-11-11 00:22:25,342 - INFO - root - Page:21, Index:6, ConceptAttention: Diffusion Transformers Learn Highly Interpretable Features, https://arxiv.org/pdf/2502.04320, 2025-07-01
2025-11-11 00:22:25,343 - INFO - root - Page:21, Index:7, GCE-Pose: Global Context Enhancement for Category-level Object Pose Estimation, https://arxiv.org/pdf/2502.04293, 2025-06-24
2025-11-11 00:22:25,343 - INFO - root - Page:21, Index:8, Calibrated Multi-Preference Optimization for Aligning Diffusion Models, https://arxiv.org/pdf/2502.02588, 2025-09-26
2025-11-11 00:22:25,343 - INFO - root - Page:21, Index:9, Instruct-4DGS: Efficient Dynamic Scene Editing via 4D Gaussian-based Static-Dynamic Separation, https://arxiv.org/pdf/2502.02091, 2025-07-01
2025-11-11 00:22:25,344 - INFO - root - Page:21, Index:10, Low-Resource Video Super-Resolution using Memory, Wavelets, and Deformable Convolutions, https://arxiv.org/pdf/2502.01816, 2025-06-19
2025-11-11 00:22:25,344 - INFO - root - Page:21, Index:11, Bridging Text and Crystal Structures: Literature-driven Contrastive Learning for Materials Science, https://arxiv.org/pdf/2501.12919, 2025-06-18
2025-11-11 00:22:25,346 - INFO - root - Page:21, Index:12, T2ISafety: Benchmark for Assessing Fairness, Toxicity, and Privacy in Image Generation, https://arxiv.org/pdf/2501.12612, 2025-07-25
2025-11-11 00:22:25,347 - INFO - root - Page:21, Index:13, Fine-Grained Image-Text Correspondence with Cost Aggregation for Open-Vocabulary Part Segmentation, https://arxiv.org/pdf/2501.09688, 2025-08-08
2025-11-11 00:22:25,348 - INFO - root - Fetching page 23 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=1100
2025-11-11 00:22:32,049 - INFO - root - get_all_titles_from_web 
2025-11-11 00:22:32,050 - INFO - root - Page:22, Index:0, Bias for Action: Video Implicit Neural Representations with Bias Modulation, https://arxiv.org/pdf/2501.09277, 2025-06-06
2025-11-11 00:22:32,050 - INFO - root - Page:22, Index:1, MonSter++: Unified Stereo Matching, Multi-view Stereo, and Real-time Stereo with Monodepth Priors, https://arxiv.org/pdf/2501.08643, 2025-09-25
2025-11-11 00:22:32,050 - INFO - root - Page:22, Index:2, Go-with-the-Flow: Motion-Controllable Video Diffusion Models Using Real-Time Warped Noise, https://arxiv.org/pdf/2501.08331, 2025-08-06
2025-11-11 00:22:32,052 - INFO - root - Page:22, Index:3, Nonisotropic Gaussian Diffusion for Realistic 3D Human Motion Prediction, https://arxiv.org/pdf/2501.06035, 2025-07-08
2025-11-11 00:22:32,052 - INFO - root - Page:22, Index:4, Discovering Hidden Visual Concepts Beyond Linguistic Input in Infant Learning, https://arxiv.org/pdf/2501.05205, 2025-06-13
2025-11-11 00:22:32,054 - INFO - root - Page:22, Index:5, PERSE: Personalized 3D Generative Avatars from A Single Portrait, https://arxiv.org/pdf/2412.21206, 2025-09-28
2025-11-11 00:22:32,054 - INFO - root - Page:22, Index:6, MaskGaussian: Adaptive 3D Gaussian Representation from Probabilistic Masks, https://arxiv.org/pdf/2412.20522, 2025-06-14
2025-11-11 00:22:32,055 - INFO - root - Page:22, Index:7, SimLTD: Simple Supervised and Semi-Supervised Long-Tailed Object Detection, https://arxiv.org/pdf/2412.20047, 2025-06-09
2025-11-11 00:22:32,055 - INFO - root - Page:22, Index:8, Conditional Balance: Improving Multi-Conditioning Trade-Offs in Image Generation, https://arxiv.org/pdf/2412.19853, 2025-08-03
2025-11-11 00:22:32,056 - INFO - root - Fetching page 24 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=1150
2025-11-11 00:22:38,677 - INFO - root - get_all_titles_from_web 
2025-11-11 00:22:38,678 - INFO - root - Page:23, Index:0, CoCoGaussian: Leveraging Circle of Confusion for Gaussian Splatting from Defocused Images, https://arxiv.org/pdf/2412.16028, 2025-05-15
2025-11-11 00:22:38,678 - INFO - root - Page:23, Index:1, EnergyMoGen: Compositional Human Motion Generation with Energy-Based Diffusion Model in Latent Space, https://arxiv.org/pdf/2412.14706, 2025-06-04
2025-11-11 00:22:38,679 - INFO - root - Page:23, Index:2, DarkIR: Robust Low-Light Image Restoration, https://arxiv.org/pdf/2412.13443, 2025-10-14
2025-11-11 00:22:38,679 - INFO - root - Page:23, Index:3, FastVLM: Efficient Vision Encoding for Vision Language Models, https://arxiv.org/pdf/2412.13303, 2025-05-15
2025-11-11 00:22:38,679 - INFO - root - Page:23, Index:4, Real-time Free-view Human Rendering from Sparse-view RGB Videos using Double Unprojected Textures, https://arxiv.org/pdf/2412.13183, 2025-06-20
2025-11-11 00:22:38,680 - INFO - root - Page:23, Index:5, CondiMen: Conditional Multi-Person Mesh Recovery, https://arxiv.org/pdf/2412.13058, 2025-06-04
2025-11-11 00:22:38,680 - INFO - root - Page:23, Index:6, MASt3R-SLAM: Real-Time Dense SLAM with 3D Reconstruction Priors, https://arxiv.org/pdf/2412.12392, 2025-06-02
2025-11-11 00:22:38,680 - INFO - root - Page:23, Index:7, DynamicScaler: Seamless and Scalable Video Generation for Panoramic Scenes, https://arxiv.org/pdf/2412.11100, 2025-10-04
2025-11-11 00:22:38,680 - INFO - root - Page:23, Index:8, SnapGen-V: Generating a Five-Second Video within Five Seconds on a Mobile Device, https://arxiv.org/pdf/2412.10494, 2025-06-09
2025-11-11 00:22:38,681 - INFO - root - Page:23, Index:9, Mr. DETR++: Instructive Multi-Route Training for Detection Transformers with Mixture-of-Experts, https://arxiv.org/pdf/2412.10028, 2025-06-26
2025-11-11 00:22:38,681 - INFO - root - Page:23, Index:10, LinGen: Towards High-Resolution Minute-Length Text-to-Video Generation with Linear Computational Complexity, https://arxiv.org/pdf/2412.09856, 2025-05-24
2025-11-11 00:22:38,681 - INFO - root - Page:23, Index:11, Gaze-LLE: Gaze Target Estimation via Large-Scale Learned Encoders, https://arxiv.org/pdf/2412.09586, 2025-06-03
2025-11-11 00:22:38,682 - INFO - root - Fetching page 25 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=1200
2025-11-11 00:22:46,139 - INFO - root - get_all_titles_from_web 
2025-11-11 00:22:46,140 - INFO - root - Page:24, Index:0, From Slow Bidirectional to Fast Autoregressive Video Diffusion Models, https://arxiv.org/pdf/2412.07772, 2025-09-23
2025-11-11 00:22:46,140 - INFO - root - Page:24, Index:1, Rate-In: Information-Driven Adaptive Dropout Rates for Improved Inference-Time Uncertainty Estimation, https://arxiv.org/pdf/2412.07169, 2025-06-03
2025-11-11 00:22:46,140 - INFO - root - Page:24, Index:2, FIRE: Robust Detection of Diffusion-Generated Images via Frequency-Guided Reconstruction Error, https://arxiv.org/pdf/2412.07140, 2025-11-03
2025-11-11 00:22:46,141 - INFO - root - Page:24, Index:3, Birth and Death of a Rose, https://arxiv.org/pdf/2412.05278, 2025-06-05
2025-11-11 00:22:46,141 - INFO - root - Page:24, Index:4, DualPM: Dual Posed-Canonical Point Maps for 3D Shape and Pose Reconstruction, https://arxiv.org/pdf/2412.04464, 2025-08-14
2025-11-11 00:22:46,143 - INFO - root - Page:24, Index:5, SeeGround: See and Ground for Zero-Shot Open-Vocabulary 3D Visual Grounding, https://arxiv.org/pdf/2412.04383, 2025-05-29
2025-11-11 00:22:46,143 - INFO - root - ------------------------------------------------------------------------------------------------------------------------
2025-11-11 00:22:46,148 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\CVPR 2025\Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness.pdf
2025-11-11 00:22:46,152 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\CVPR 2025\OmniTrack++_ Omnidirectional Multi-Object Tracking by Learning Large-FoV Traject.pdf
2025-11-11 00:23:24,076 - INFO - root - 正在总结论文 1/5: Learning to Seek Evidence: A Verifiable Reasoning Agent with Causal Faithfulness Analysis
2025-11-11 00:28:56,634 - INFO - root - 正在提取论文图片...
2025-11-11 00:28:57,079 - INFO - root - 已保存图片 1/10：./export\CVPR\images\figure_1_page2.jpeg
2025-11-11 00:28:57,090 - INFO - root - 已保存图片 2/10：./export\CVPR\images\figure_2_page2.jpeg
2025-11-11 00:28:57,110 - INFO - root - 已保存图片 3/10：./export\CVPR\images\figure_3_page2.jpeg
2025-11-11 00:28:57,133 - INFO - root - 已保存图片 4/10：./export\CVPR\images\figure_4_page2.jpeg
2025-11-11 00:28:57,151 - INFO - root - 已保存图片 5/10：./export\CVPR\images\figure_5_page2.jpeg
2025-11-11 00:28:57,163 - INFO - root - 已保存图片 6/10：./export\CVPR\images\figure_6_page2.jpeg
2025-11-11 00:28:57,174 - INFO - root - 已保存图片 7/10：./export\CVPR\images\figure_7_page2.jpeg
2025-11-11 00:28:57,181 - INFO - root - 已保存图片 8/10：./export\CVPR\images\figure_8_page2.jpeg
2025-11-11 00:28:57,224 - INFO - root - 已保存图片 9/10：./export\CVPR\images\figure_9_page2.jpeg
2025-11-11 00:28:57,233 - INFO - root - 已保存图片 10/10：./export\CVPR\images\figure_10_page2.jpeg
2025-11-11 00:28:57,234 - INFO - root - 成功添加图片 1：./export\CVPR\images\figure_1_page2.jpeg
2025-11-11 00:28:57,238 - INFO - root - 成功添加图片 2：./export\CVPR\images\figure_2_page2.jpeg
2025-11-11 00:28:57,239 - INFO - root - 成功添加图片 3：./export\CVPR\images\figure_3_page2.jpeg
2025-11-11 00:28:57,240 - INFO - root - 成功添加图片 4：./export\CVPR\images\figure_4_page2.jpeg
2025-11-11 00:28:57,241 - INFO - root - 成功添加图片 5：./export\CVPR\images\figure_5_page2.jpeg
2025-11-11 00:28:57,241 - INFO - root - 成功添加图片 6：./export\CVPR\images\figure_6_page2.jpeg
2025-11-11 00:28:57,242 - INFO - root - 成功添加图片 7：./export\CVPR\images\figure_7_page2.jpeg
2025-11-11 00:28:57,242 - INFO - root - 成功添加图片 8：./export\CVPR\images\figure_8_page2.jpeg
2025-11-11 00:28:57,243 - INFO - root - 成功添加图片 9：./export\CVPR\images\figure_9_page2.jpeg
2025-11-11 00:28:57,243 - INFO - root - 成功添加图片 10：./export\CVPR\images\figure_10_page2.jpeg
2025-11-11 00:28:57,244 - INFO - root - 提取到arXiv ID: 2511.01425
2025-11-11 00:28:57,245 - INFO - root - 调用arXiv API: https://export.arxiv.org/api/query?id=2511.01425
2025-11-11 00:29:02,662 - WARNING - root - 未找到entry元素: 2511.01425
2025-11-11 00:29:02,662 - INFO - root - XML根元素标签: {http://www.w3.org/2005/Atom}feed
2025-11-11 00:29:02,662 - INFO - root - XML根元素属性: {}
2025-11-11 00:29:02,662 - INFO - root - 根元素的直接子元素:
2025-11-11 00:29:02,663 - INFO - root -   0. {http://www.w3.org/2005/Atom}link: None
2025-11-11 00:29:02,663 - INFO - root -   1. {http://www.w3.org/2005/Atom}title: ArXiv Query: search_query=&id_list=&start=0&max_results=10
2025-11-11 00:29:02,663 - INFO - root -   2. {http://www.w3.org/2005/Atom}id: http://arxiv.org/api/iQlyOhQ3W8t8kI903+StmrBZNWM
2025-11-11 00:29:02,664 - INFO - root -   3. {http://www.w3.org/2005/Atom}updated: 2025-11-10T00:00:00-05:00
2025-11-11 00:29:02,664 - INFO - root -   4. {http://a9.com/-/spec/opensearch/1.1/}totalResults: 0
2025-11-11 00:29:02,665 - INFO - root -   5. {http://a9.com/-/spec/opensearch/1.1/}startIndex: 0
2025-11-11 00:29:02,665 - INFO - root -   6. {http://a9.com/-/spec/opensearch/1.1/}itemsPerPage: 10
2025-11-11 00:29:02,665 - INFO - root - XML内容前500字符: <?xml version="1.0" encoding="UTF-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <link href="http://arxiv.org/api/query?search_query%3D%26id_list%3D%26start%3D0%26max_results%3D10" rel="self" type="application/atom+xml"/>
  <title type="html">ArXiv Query: search_query=&amp;id_list=&amp;start=0&amp;max_results=10</title>
  <id>http://arxiv.org/api/iQlyOhQ3W8t8kI903+StmrBZNWM</id>
  <updated>2025-11-10T00:00:00-05:00</updated>
  <opensearch:totalResults xmlns:opensearch="http://a9.com/-/spec/op
2025-11-11 00:29:02,668 - INFO - root - 估算引用量: 8
2025-11-11 00:29:02,671 - WARNING - root - 图片文件不存在: images/figure_10_page2.jpeg
2025-11-11 00:29:02,672 - INFO - root - 图片存在于images目录: ./export\CVPR\images\figure_10_page2.jpeg
2025-11-11 00:29:02,679 - WARNING - root - 图片文件不存在: images/figure_9_page2.jpeg
2025-11-11 00:29:02,679 - INFO - root - 图片存在于images目录: ./export\CVPR\images\figure_9_page2.jpeg
2025-11-11 00:29:02,680 - WARNING - root - 图片文件不存在: images/figure_8_page2.jpeg
2025-11-11 00:29:02,681 - INFO - root - 图片存在于images目录: ./export\CVPR\images\figure_8_page2.jpeg
2025-11-11 00:29:02,686 - WARNING - root - 图片文件不存在: images/figure_7_page2.jpeg
2025-11-11 00:29:02,689 - INFO - root - 图片存在于images目录: ./export\CVPR\images\figure_7_page2.jpeg
2025-11-11 00:29:02,693 - WARNING - root - 图片文件不存在: images/figure_6_page2.jpeg
2025-11-11 00:29:02,695 - INFO - root - 图片存在于images目录: ./export\CVPR\images\figure_6_page2.jpeg
2025-11-11 00:29:02,697 - WARNING - root - 图片文件不存在: images/figure_5_page2.jpeg
2025-11-11 00:29:02,698 - INFO - root - 图片存在于images目录: ./export\CVPR\images\figure_5_page2.jpeg
2025-11-11 00:29:02,698 - WARNING - root - 图片文件不存在: images/figure_4_page2.jpeg
2025-11-11 00:29:02,699 - INFO - root - 图片存在于images目录: ./export\CVPR\images\figure_4_page2.jpeg
2025-11-11 00:29:02,699 - WARNING - root - 图片文件不存在: images/figure_3_page2.jpeg
2025-11-11 00:29:02,699 - INFO - root - 图片存在于images目录: ./export\CVPR\images\figure_3_page2.jpeg
2025-11-11 00:29:02,701 - WARNING - root - 图片文件不存在: images/figure_2_page2.jpeg
2025-11-11 00:29:02,701 - INFO - root - 图片存在于images目录: ./export\CVPR\images\figure_2_page2.jpeg
2025-11-11 00:29:02,705 - WARNING - root - 图片文件不存在: images/figure_1_page2.jpeg
2025-11-11 00:29:02,705 - INFO - root - 图片存在于images目录: ./export\CVPR\images\figure_1_page2.jpeg
2025-11-11 00:29:02,714 - INFO - root - 论文《Learning to Seek Evidence: A Verifiable Reasoning Agent with Causal Faithfulness Analysis》的分析已保存到 ./export\CVPR\Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness.md
2025-11-11 00:29:02,717 - INFO - root - 正在总结论文 2/5: OmniTrack++: Omnidirectional Multi-Object Tracking by Learning Large-FoV Trajectory Feedback
2025-11-11 00:30:54,714 - INFO - root - 正在提取论文图片...
2025-11-11 00:30:56,228 - INFO - root - 已保存图片 1/10：./export\CVPR\images\figure_1_page13.jpeg
2025-11-11 00:30:56,393 - INFO - root - 已保存图片 2/10：./export\CVPR\images\figure_2_page13.jpeg
2025-11-11 00:30:56,501 - INFO - root - 已保存图片 3/10：./export\CVPR\images\figure_3_page13.jpeg
2025-11-11 00:30:56,628 - INFO - root - 已保存图片 4/10：./export\CVPR\images\figure_4_page2.jpeg
2025-11-11 00:30:56,776 - INFO - root - 已保存图片 5/10：./export\CVPR\images\figure_5_page5.png
2025-11-11 00:30:56,843 - INFO - root - 已保存图片 6/10：./export\CVPR\images\figure_6_page13.jpeg
2025-11-11 00:30:56,897 - INFO - root - 已保存图片 7/10：./export\CVPR\images\figure_7_page2.jpeg
2025-11-11 00:30:56,969 - INFO - root - 已保存图片 8/10：./export\CVPR\images\figure_8_page8.jpeg
2025-11-11 00:30:57,019 - INFO - root - 已保存图片 9/10：./export\CVPR\images\figure_9_page1.jpeg
2025-11-11 00:30:57,060 - INFO - root - 已保存图片 10/10：./export\CVPR\images\figure_10_page1.png
2025-11-11 00:30:57,082 - INFO - root - 成功添加图片 1：./export\CVPR\images\figure_1_page13.jpeg
2025-11-11 00:30:57,083 - INFO - root - 成功添加图片 2：./export\CVPR\images\figure_2_page13.jpeg
2025-11-11 00:30:57,084 - INFO - root - 成功添加图片 3：./export\CVPR\images\figure_3_page13.jpeg
2025-11-11 00:30:57,085 - INFO - root - 成功添加图片 4：./export\CVPR\images\figure_4_page2.jpeg
2025-11-11 00:30:57,086 - INFO - root - 成功添加图片 5：./export\CVPR\images\figure_5_page5.png
2025-11-11 00:30:57,087 - INFO - root - 成功添加图片 6：./export\CVPR\images\figure_6_page13.jpeg
2025-11-11 00:30:57,088 - INFO - root - 成功添加图片 7：./export\CVPR\images\figure_7_page2.jpeg
2025-11-11 00:30:57,090 - INFO - root - 成功添加图片 8：./export\CVPR\images\figure_8_page8.jpeg
2025-11-11 00:30:57,092 - INFO - root - 成功添加图片 9：./export\CVPR\images\figure_9_page1.jpeg
2025-11-11 00:30:57,093 - INFO - root - 成功添加图片 10：./export\CVPR\images\figure_10_page1.png
2025-11-11 00:30:57,096 - INFO - root - 提取到arXiv ID: 2511.00510
2025-11-11 00:30:57,097 - INFO - root - 调用arXiv API: https://export.arxiv.org/api/query?id=2511.00510
2025-11-11 00:31:02,923 - WARNING - root - 未找到entry元素: 2511.00510
2025-11-11 00:31:02,923 - INFO - root - XML根元素标签: {http://www.w3.org/2005/Atom}feed
2025-11-11 00:31:02,924 - INFO - root - XML根元素属性: {}
2025-11-11 00:31:02,924 - INFO - root - 根元素的直接子元素:
2025-11-11 00:31:02,924 - INFO - root -   0. {http://www.w3.org/2005/Atom}link: None
2025-11-11 00:31:02,924 - INFO - root -   1. {http://www.w3.org/2005/Atom}title: ArXiv Query: search_query=&id_list=&start=0&max_results=10
2025-11-11 00:31:02,924 - INFO - root -   2. {http://www.w3.org/2005/Atom}id: http://arxiv.org/api/iQlyOhQ3W8t8kI903+StmrBZNWM
2025-11-11 00:31:02,924 - INFO - root -   3. {http://www.w3.org/2005/Atom}updated: 2025-11-10T00:00:00-05:00
2025-11-11 00:31:02,926 - INFO - root -   4. {http://a9.com/-/spec/opensearch/1.1/}totalResults: 0
2025-11-11 00:31:02,926 - INFO - root -   5. {http://a9.com/-/spec/opensearch/1.1/}startIndex: 0
2025-11-11 00:31:02,926 - INFO - root -   6. {http://a9.com/-/spec/opensearch/1.1/}itemsPerPage: 10
2025-11-11 00:31:02,926 - INFO - root - XML内容前500字符: <?xml version="1.0" encoding="UTF-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <link href="http://arxiv.org/api/query?search_query%3D%26id_list%3D%26start%3D0%26max_results%3D10" rel="self" type="application/atom+xml"/>
  <title type="html">ArXiv Query: search_query=&amp;id_list=&amp;start=0&amp;max_results=10</title>
  <id>http://arxiv.org/api/iQlyOhQ3W8t8kI903+StmrBZNWM</id>
  <updated>2025-11-10T00:00:00-05:00</updated>
  <opensearch:totalResults xmlns:opensearch="http://a9.com/-/spec/op
2025-11-11 00:31:02,931 - INFO - root - 估算引用量: 13
2025-11-11 00:31:02,933 - WARNING - root - 图片文件不存在: images/figure_10_page1.png
2025-11-11 00:31:02,933 - INFO - root - 图片存在于images目录: ./export\CVPR\images\figure_10_page1.png
2025-11-11 00:31:02,934 - WARNING - root - 图片文件不存在: images/figure_9_page1.jpeg
2025-11-11 00:31:02,934 - INFO - root - 图片存在于images目录: ./export\CVPR\images\figure_9_page1.jpeg
2025-11-11 00:31:02,935 - WARNING - root - 图片文件不存在: images/figure_8_page8.jpeg
2025-11-11 00:31:02,935 - INFO - root - 图片存在于images目录: ./export\CVPR\images\figure_8_page8.jpeg
2025-11-11 00:31:02,936 - WARNING - root - 图片文件不存在: images/figure_7_page2.jpeg
2025-11-11 00:31:02,936 - INFO - root - 图片存在于images目录: ./export\CVPR\images\figure_7_page2.jpeg
2025-11-11 00:31:02,936 - WARNING - root - 图片文件不存在: images/figure_6_page13.jpeg
2025-11-11 00:31:02,937 - INFO - root - 图片存在于images目录: ./export\CVPR\images\figure_6_page13.jpeg
2025-11-11 00:31:02,937 - WARNING - root - 图片文件不存在: images/figure_5_page5.png
2025-11-11 00:31:02,937 - INFO - root - 图片存在于images目录: ./export\CVPR\images\figure_5_page5.png
2025-11-11 00:31:02,937 - WARNING - root - 图片文件不存在: images/figure_4_page2.jpeg
2025-11-11 00:31:02,940 - INFO - root - 图片存在于images目录: ./export\CVPR\images\figure_4_page2.jpeg
2025-11-11 00:31:02,941 - WARNING - root - 图片文件不存在: images/figure_3_page13.jpeg
2025-11-11 00:31:02,941 - INFO - root - 图片存在于images目录: ./export\CVPR\images\figure_3_page13.jpeg
2025-11-11 00:31:02,942 - WARNING - root - 图片文件不存在: images/figure_2_page13.jpeg
2025-11-11 00:31:02,943 - INFO - root - 图片存在于images目录: ./export\CVPR\images\figure_2_page13.jpeg
2025-11-11 00:31:02,949 - WARNING - root - 图片文件不存在: images/figure_1_page13.jpeg
2025-11-11 00:31:02,950 - INFO - root - 图片存在于images目录: ./export\CVPR\images\figure_1_page13.jpeg
2025-11-11 00:31:02,953 - INFO - root - 论文《OmniTrack++: Omnidirectional Multi-Object Tracking by Learning Large-FoV Trajectory Feedback》的分析已保存到 ./export\CVPR\OmniTrack++_ Omnidirectional Multi-Object Tracking by Learning Large-FoV Traject.md
2025-11-11 00:31:02,966 - INFO - root - 正在总结论文 3/5: NeuCo-Bench: A Novel Benchmark Framework for Neural Embeddings in Earth Observation
2025-11-11 00:40:43,629 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-11 00:40:43,633 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-11 00:40:43,635 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-11 00:40:44,754 - INFO - root - LLMClientManager: 指定使用客户端: Gemini
2025-11-11 00:40:46,706 - INFO - root - GeminiClient: trying model models/gemini-2.5-flash
2025-11-11 00:40:48,552 - INFO - root - GeminiClient: initialized model gemini-2.5-flash
2025-11-11 00:40:48,552 - INFO - root - LLMClientManager: Gemini 客户端初始化成功
2025-11-11 00:40:48,552 - INFO - root - LLMClientManager: switched to Gemini client
2025-11-11 00:40:48,553 - INFO - root - 已手动切换到 LLM 客户端: Gemini
2025-11-11 00:40:48,553 - INFO - root - 使用 LLM 模型: gemini-2.5-flash
2025-11-11 00:40:48,554 - INFO - root - 可用客户端: ['Gemini']
2025-11-11 00:40:48,554 - INFO - root - === 运行配置 ===
2025-11-11 00:40:48,554 - INFO - root - 处理模式: arxiv在线搜索
2025-11-11 00:40:48,555 - INFO - root - 关键词: CVPR
2025-11-11 00:40:48,555 - INFO - root - 查询: CVPR 2025
2025-11-11 00:40:48,555 - INFO - root - 排序: None
2025-11-11 00:40:48,556 - INFO - root - 最近天数: 180
2025-11-11 00:40:48,556 - INFO - root - 最大处理数量: 5
2025-11-11 00:40:48,556 - INFO - root - 保存图片: 是
2025-11-11 00:40:48,556 - INFO - root - 输出语言: 中文
2025-11-11 00:40:48,557 - INFO - root - 强制重新处理: 否
2025-11-11 00:40:48,558 - INFO - root - ====================
2025-11-11 00:40:48,558 - INFO - root - 使用 arXiv 搜索模式（通过 chat_arxiv 模块获取）
2025-11-11 00:40:48,558 - INFO - root - Fetching page 1 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50
2025-11-11 00:40:55,229 - INFO - root - get_all_titles_from_web 
2025-11-11 00:40:55,229 - INFO - root - Page:0, Index:0, Learning to Seek Evidence: A Verifiable Reasoning Agent with Causal Faithfulness Analysis, https://arxiv.org/pdf/2511.01425, 2025-11-03
2025-11-11 00:40:55,230 - INFO - root - Page:0, Index:1, OmniTrack++: Omnidirectional Multi-Object Tracking by Learning Large-FoV Trajectory Feedback, https://arxiv.org/pdf/2511.00510, 2025-11-01
2025-11-11 00:40:55,230 - INFO - root - Page:0, Index:2, NeuCo-Bench: A Novel Benchmark Framework for Neural Embeddings in Earth Observation, https://arxiv.org/pdf/2510.17914, 2025-10-19
2025-11-11 00:40:55,230 - INFO - root - Page:0, Index:3, NTIRE 2025 Challenge on Low Light Image Enhancement: Methods and Results, https://arxiv.org/pdf/2510.13670, 2025-10-15
2025-11-11 00:40:55,232 - INFO - root - Page:0, Index:4, Class Prototypes based Contrastive Learning for Classifying Multi-Label and Fine-Grained Educational Videos, https://arxiv.org/pdf/2510.11204, 2025-10-13
2025-11-11 00:40:55,232 - INFO - root - Page:0, Index:5, MIMO: A medical vision language model with visual referring multimodal input and pixel grounding multimodal output, https://arxiv.org/pdf/2510.10011, 2025-10-11
2025-11-11 00:40:55,232 - INFO - root - Page:0, Index:6, Vision Language Models: A Survey of 26K Papers, https://arxiv.org/pdf/2510.09586, 2025-10-10
2025-11-11 00:40:55,233 - INFO - root - Page:0, Index:7, DiT-VTON: Diffusion Transformer Framework for Unified Multi-Category Virtual Try-On and Virtual Try-All with Integrated Image Editing, https://arxiv.org/pdf/2510.04797, 2025-10-03
2025-11-11 00:40:55,233 - INFO - root - Page:0, Index:8, PatchVSR: Breaking Video Diffusion Resolution Limits with Patch-wise Video Super-Resolution, https://arxiv.org/pdf/2509.26025, 2025-09-30
2025-11-11 00:40:55,233 - INFO - root - Page:0, Index:9, FreqDebias: Towards Generalizable Deepfake Detection via Consistency-Driven Frequency Debiasing, https://arxiv.org/pdf/2509.22412, 2025-09-26
2025-11-11 00:40:55,233 - INFO - root - Page:0, Index:10, A Mutual Learning Method for Salient Object Detection with intertwined Multi-Supervision--Revised, https://arxiv.org/pdf/2509.21363, 2025-09-21
2025-11-11 00:40:55,234 - INFO - root - Page:0, Index:11, InstructVTON: Optimal Auto-Masking and Natural-Language-Guided Interactive Style Control for Inpainting-Based Virtual Try-On, https://arxiv.org/pdf/2509.20524, 2025-09-24
2025-11-11 00:40:55,234 - INFO - root - Page:0, Index:12, Efficient Encoder-Free Pose Conditioning and Pose Control for Virtual Try-On, https://arxiv.org/pdf/2509.20343, 2025-09-24
2025-11-11 00:40:55,234 - INFO - root - Page:0, Index:13, The Photographer Eye: Teaching Multimodal Large Language Models to Understand Image Aesthetics like Photographers, https://arxiv.org/pdf/2509.18582, 2025-10-22
2025-11-11 00:40:55,234 - INFO - root - Page:0, Index:14, ENSAM: an efficient foundation model for interactive segmentation of 3D medical images, https://arxiv.org/pdf/2509.15874, 2025-09-19
2025-11-11 00:40:55,236 - INFO - root - Page:0, Index:15, DEFT-VTON: Efficient Virtual Try-On with Consistent Generalised H-Transform, https://arxiv.org/pdf/2509.13506, 2025-09-16
2025-11-11 00:40:55,237 - INFO - root - Page:0, Index:16, Weakly and Self-Supervised Class-Agnostic Motion Prediction for Autonomous Driving, https://arxiv.org/pdf/2509.13116, 2025-09-16
2025-11-11 00:40:55,238 - INFO - root - Page:0, Index:17, Domain-Adaptive Pretraining Improves Primate Behavior Recognition, https://arxiv.org/pdf/2509.12193, 2025-09-15
2025-11-11 00:40:55,238 - INFO - root - Page:0, Index:18, The System Description of CPS Team for Track on Driving with Language of CVPR 2024 Autonomous Grand Challenge, https://arxiv.org/pdf/2509.11071, 2025-09-13
2025-11-11 00:40:55,238 - INFO - root - Page:0, Index:19, An HMM-based framework for identity-aware long-term multi-object tracking from sparse and uncertain identification: use case on long-term tracking in livestock, https://arxiv.org/pdf/2509.09962, 2025-09-12
2025-11-11 00:40:55,239 - INFO - root - Page:0, Index:20, InterAct: Advancing Large-Scale Versatile 3D Human-Object Interaction Generation, https://arxiv.org/pdf/2509.09555, 2025-09-11
2025-11-11 00:40:55,239 - INFO - root - Page:0, Index:21, Geospatial Foundational Embedder: Top-1 Winning Solution on EarthVision Embed2Scale Challenge (CVPR 2025), https://arxiv.org/pdf/2509.06993, 2025-09-03
2025-11-11 00:40:55,240 - INFO - root - Page:0, Index:22, 2nd Place Solution for CVPR2024 E2E Challenge: End-to-End Autonomous Driving Using Vision Language Model, https://arxiv.org/pdf/2509.02659, 2025-09-02
2025-11-11 00:40:55,241 - INFO - root - Page:0, Index:23, Unsupervised Training of Vision Transformers with Synthetic Negatives, https://arxiv.org/pdf/2509.02024, 2025-09-02
2025-11-11 00:40:55,243 - INFO - root - Page:0, Index:24, MV-SSM: Multi-View State Space Modeling for 3D Human Pose Estimation, https://arxiv.org/pdf/2509.00649, 2025-08-30
2025-11-11 00:40:55,244 - INFO - root - Page:0, Index:25, CryptoFace: End-to-End Encrypted Face Recognition, https://arxiv.org/pdf/2509.00332, 2025-08-29
2025-11-11 00:40:55,244 - INFO - root - Page:0, Index:26, ControlEchoSynth: Boosting Ejection Fraction Estimation Models via Controlled Video Diffusion, https://arxiv.org/pdf/2508.17631, 2025-08-26
2025-11-11 00:40:55,244 - INFO - root - Page:0, Index:27, Explain Before You Answer: A Survey on Compositional Visual Reasoning, https://arxiv.org/pdf/2508.17298, 2025-08-27
2025-11-11 00:40:55,244 - INFO - root - Page:0, Index:28, Investigating Different Geo Priors for Image Classification, https://arxiv.org/pdf/2508.15946, 2025-08-21
2025-11-11 00:40:55,246 - INFO - root - Page:0, Index:29, Towards Source-Free Machine Unlearning, https://arxiv.org/pdf/2508.15127, 2025-08-20
2025-11-11 00:40:55,246 - INFO - root - Page:0, Index:30, MR6D: Benchmarking 6D Pose Estimation for Mobile Robots, https://arxiv.org/pdf/2508.13775, 2025-08-19
2025-11-11 00:40:55,246 - INFO - root - Page:0, Index:31, Calibrating Biased Distribution in VFM-derived Latent Space via Cross-Domain Geometric Consistency, https://arxiv.org/pdf/2508.13518, 2025-08-19
2025-11-11 00:40:55,246 - INFO - root - Page:0, Index:32, SIS-Challenge: Event-based Spatio-temporal Instance Segmentation Challenge at the CVPR 2025 Event-based Vision Workshop, https://arxiv.org/pdf/2508.12813, 2025-08-18
2025-11-11 00:40:55,248 - INFO - root - Page:0, Index:33, Multi-Level Knowledge Distillation and Dynamic Self-Supervised Learning for Continual Learning, https://arxiv.org/pdf/2508.12692, 2025-08-22
2025-11-11 00:40:55,248 - INFO - root - Page:0, Index:34, Stochastic-based Patch Filtering for Few-Shot Learning, https://arxiv.org/pdf/2508.10066, 2025-08-13
2025-11-11 00:40:55,248 - INFO - root - Page:0, Index:35, Slot Attention-based Feature Filtering for Few-Shot Learning, https://arxiv.org/pdf/2508.09699, 2025-08-13
2025-11-11 00:40:55,249 - INFO - root - Page:0, Index:36, Comparison Reveals Commonality: Customized Image Generation through Contrastive Inversion, https://arxiv.org/pdf/2508.07755, 2025-08-11
2025-11-11 00:40:55,249 - INFO - root - Page:0, Index:37, SLRTP2025 Sign Language Production Challenge: Methodology, Results, and Future Work, https://arxiv.org/pdf/2508.06951, 2025-08-09
2025-11-11 00:40:55,249 - INFO - root - Page:0, Index:38, Exploring Fairness across Fine-Grained Attributes in Large Vision-Language Models, https://arxiv.org/pdf/2508.03079, 2025-08-05
2025-11-11 00:40:55,250 - INFO - root - Page:0, Index:39, Devil is in the Detail: Towards Injecting Fine Details of Image Prompt in Image Generation via Conflict-free Guidance and Stratified Attention, https://arxiv.org/pdf/2508.02004, 2025-08-03
2025-11-11 00:40:55,250 - INFO - root - Page:0, Index:40, IAUNet: Instance-Aware U-Net, https://arxiv.org/pdf/2508.01928, 2025-08-03
2025-11-11 00:40:55,250 - INFO - root - Page:0, Index:41, Gaussian Splatting Feature Fields for Privacy-Preserving Visual Localization, https://arxiv.org/pdf/2507.23569, 2025-08-26
2025-11-11 00:40:55,253 - INFO - root - Page:0, Index:42, From Scan to Action: Leveraging Realistic Scans for Embodied Scene Understanding, https://arxiv.org/pdf/2507.17585, 2025-07-23
2025-11-11 00:40:55,254 - INFO - root - Page:0, Index:43, LEAD: Exploring Logit Space Evolution for Model Selection, https://arxiv.org/pdf/2507.14559, 2025-07-19
2025-11-11 00:40:55,255 - INFO - root - Page:0, Index:44, HeCoFuse: Cross-Modal Complementary V2X Cooperative Perception with Heterogeneous Sensors, https://arxiv.org/pdf/2507.13677, 2025-07-18
2025-11-11 00:40:55,258 - INFO - root - Page:0, Index:45, OmniVec2 -- A Novel Transformer based Network for Large Scale Multimodal and Multitask Learning, https://arxiv.org/pdf/2507.13364, 2025-07-06
2025-11-11 00:40:55,259 - INFO - root - Page:0, Index:46, A Training-Free, Task-Agnostic Framework for Enhancing MLLM Performance on High-Resolution Images, https://arxiv.org/pdf/2507.10202, 2025-07-14
2025-11-11 00:40:55,259 - INFO - root - Page:0, Index:47, Quantum Federated Learning for Multimodal Data: A Modality-Agnostic Approach, https://arxiv.org/pdf/2507.08217, 2025-07-10
2025-11-11 00:40:55,260 - INFO - root - Page:0, Index:48, CuriosAI Submission to the EgoExo4D Proficiency Estimation Challenge 2025, https://arxiv.org/pdf/2507.08022, 2025-07-08
2025-11-11 00:40:55,260 - INFO - root - Page:0, Index:49, Rethinking Query-based Transformer for Continual Image Segmentation, https://arxiv.org/pdf/2507.07831, 2025-07-10
2025-11-11 00:40:55,261 - INFO - root - Fetching page 2 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=50
2025-11-11 00:41:03,516 - INFO - root - get_all_titles_from_web 
2025-11-11 00:41:03,517 - INFO - root - Page:1, Index:0, Scalable and Realistic Virtual Try-on Application for Foundation Makeup with Kubelka-Munk Theory, https://arxiv.org/pdf/2507.07333, 2025-07-09
2025-11-11 00:41:03,517 - INFO - root - Page:1, Index:1, Free on the Fly: Enhancing Flexibility in Test-Time Adaptation with Online EM, https://arxiv.org/pdf/2507.06973, 2025-07-09
2025-11-11 00:41:03,517 - INFO - root - Page:1, Index:2, Adaptive Part Learning for Fine-Grained Generalized Category Discovery: A Plug-and-Play Enhancement, https://arxiv.org/pdf/2507.06928, 2025-07-09
2025-11-11 00:41:03,517 - INFO - root - Page:1, Index:3, Grounded Gesture Generation: Language, Motion, and Space, https://arxiv.org/pdf/2507.04522, 2025-07-06
2025-11-11 00:41:03,518 - INFO - root - Page:1, Index:4, Comprehensive Information Bottleneck for Unveiling Universal Attribution to Interpret Vision Transformers, https://arxiv.org/pdf/2507.04388, 2025-07-06
2025-11-11 00:41:03,518 - INFO - root - Page:1, Index:5, ZERO: Industry-ready Vision Foundation Model with Multi-modal Prompts, https://arxiv.org/pdf/2507.04270, 2025-11-07
2025-11-11 00:41:03,519 - INFO - root - Page:1, Index:6, Beyond Accuracy: Metrics that Uncover What Makes a 'Good' Visual Descriptor, https://arxiv.org/pdf/2507.03542, 2025-07-08
2025-11-11 00:41:03,520 - INFO - root - Page:1, Index:7, ConceptMix++: Leveling the Playing Field in Text-to-Image Benchmarking via Iterative Prompt Optimization, https://arxiv.org/pdf/2507.03275, 2025-07-03
2025-11-11 00:41:03,520 - INFO - root - Page:1, Index:8, APT: Adaptive Personalized Training for Diffusion Models with Limited Data, https://arxiv.org/pdf/2507.02687, 2025-07-03
2025-11-11 00:41:03,520 - INFO - root - Page:1, Index:9, DreamComposer++: Empowering Diffusion Models with Multi-View Conditions for 3D Content Generation, https://arxiv.org/pdf/2507.02299, 2025-07-03
2025-11-11 00:41:03,520 - INFO - root - Page:1, Index:10, Soft Self-labeling and Potts Relaxations for Weakly-Supervised Segmentation, https://arxiv.org/pdf/2507.01721, 2025-07-02
2025-11-11 00:41:03,520 - INFO - root - Page:1, Index:11, Interpolation-Based Event Visual Data Filtering Algorithms, https://arxiv.org/pdf/2507.01557, 2025-07-02
2025-11-11 00:41:03,520 - INFO - root - Page:1, Index:12, AVC-DPO: Aligned Video Captioning via Direct Preference Optimization, https://arxiv.org/pdf/2507.01492, 2025-07-02
2025-11-11 00:41:03,521 - INFO - root - Page:1, Index:13, NN-Former: Rethinking Graph Structure in Neural Architecture Representation, https://arxiv.org/pdf/2507.00880, 2025-07-01
2025-11-11 00:41:03,521 - INFO - root - Page:1, Index:14, Instant Particle Size Distribution Measurement Using CNNs Trained on Synthetic Data, https://arxiv.org/pdf/2507.00822, 2025-07-01
2025-11-11 00:41:03,521 - INFO - root - Page:1, Index:15, Moment Sampling in Video LLMs for Long-Form Video QA, https://arxiv.org/pdf/2507.00033, 2025-06-17
2025-11-11 00:41:03,522 - INFO - root - Page:1, Index:16, Revisiting Audio-Visual Segmentation with Vision-Centric Transformer, https://arxiv.org/pdf/2506.23623, 2025-06-30
2025-11-11 00:41:03,522 - INFO - root - Page:1, Index:17, MTADiffusion: Mask Text Alignment Diffusion Model for Object Inpainting, https://arxiv.org/pdf/2506.23482, 2025-06-29
2025-11-11 00:41:03,522 - INFO - root - Page:1, Index:18, Benchmarking Generalizable Bimanual Manipulation: RoboTwin Dual-Arm Collaboration Challenge at CVPR 2025 MEIS Workshop, https://arxiv.org/pdf/2506.23351, 2025-07-02
2025-11-11 00:41:03,524 - INFO - root - Page:1, Index:19, Prompting without Panic: Attribute-aware, Zero-shot, Test-Time Calibration, https://arxiv.org/pdf/2506.22819, 2025-06-28
2025-11-11 00:41:03,524 - INFO - root - Page:1, Index:20, Analyzing and Fine-Tuning Whisper Models for Multilingual Pilot Speech Transcription in the Cockpit, https://arxiv.org/pdf/2506.21990, 2025-06-27
2025-11-11 00:41:03,524 - INFO - root - Page:1, Index:21, SceneDiffuser++: City-Scale Traffic Simulation via a Generative World Model, https://arxiv.org/pdf/2506.21976, 2025-06-27
2025-11-11 00:41:03,525 - INFO - root - Page:1, Index:22, DIVE: Deep-search Iterative Video Exploration A Technical Report for the CVRR Challenge at CVPR 2025, https://arxiv.org/pdf/2506.21891, 2025-06-27
2025-11-11 00:41:03,525 - INFO - root - Page:1, Index:23, End-to-End RGB-IR Joint Image Compression With Channel-wise Cross-modality Entropy Model, https://arxiv.org/pdf/2506.21851, 2025-06-26
2025-11-11 00:41:03,525 - INFO - root - Page:1, Index:24, Distilling Normalizing Flows, https://arxiv.org/pdf/2506.21003, 2025-06-26
2025-11-11 00:41:03,526 - INFO - root - Page:1, Index:25, Joint attitude estimation and 3D neural reconstruction of non-cooperative space objects, https://arxiv.org/pdf/2506.20638, 2025-06-25
2025-11-11 00:41:03,530 - INFO - root - Page:1, Index:26, Accept More, Reject Less: Reducing up to 19% Unnecessary Desk-Rejections over 11 Years of ICLR Data, https://arxiv.org/pdf/2506.20141, 2025-06-25
2025-11-11 00:41:03,532 - INFO - root - Page:1, Index:27, SceneCrafter: Controllable Multi-View Driving Scene Editing, https://arxiv.org/pdf/2506.19488, 2025-06-24
2025-11-11 00:41:03,532 - INFO - root - Page:1, Index:28, Emergence of Text Readability in Vision Language Models, https://arxiv.org/pdf/2506.19389, 2025-06-24
2025-11-11 00:41:03,532 - INFO - root - Page:1, Index:29, MedErr-CT: A Visual Question Answering Benchmark for Identifying and Correcting Errors in CT Reports, https://arxiv.org/pdf/2506.19217, 2025-06-23
2025-11-11 00:41:03,532 - INFO - root - Page:1, Index:30, RareSpot: Spotting Small and Rare Wildlife in Aerial Imagery with Multi-Scale Consistency and Context-Aware Augmentation, https://arxiv.org/pdf/2506.19087, 2025-06-23
2025-11-11 00:41:03,532 - INFO - root - Page:1, Index:31, Object-aware Sound Source Localization via Audio-Visual Scene Understanding, https://arxiv.org/pdf/2506.18557, 2025-06-23
2025-11-11 00:41:03,532 - INFO - root - Page:1, Index:32, Rethinking Decoder Design: Improving Biomarker Segmentation Using Depth-to-Space Restoration and Residual Linear Attention, https://arxiv.org/pdf/2506.18335, 2025-06-23
2025-11-11 00:41:03,532 - INFO - root - Page:1, Index:33, Relation3D: Enhancing Relation Modeling for Point Cloud Instance Segmentation, https://arxiv.org/pdf/2506.17891, 2025-06-21
2025-11-11 00:41:03,533 - INFO - root - Page:1, Index:34, HIRE: Lightweight High-Resolution Image Feature Enrichment for Multimodal LLMs, https://arxiv.org/pdf/2506.17608, 2025-06-21
2025-11-11 00:41:03,533 - INFO - root - Page:1, Index:35, Spatially-Aware Evaluation of Segmentation Uncertainty, https://arxiv.org/pdf/2506.16589, 2025-06-19
2025-11-11 00:41:03,533 - INFO - root - Page:1, Index:36, Tripartite Weight-Space Ensemble for Few-Shot Class-Incremental Learning, https://arxiv.org/pdf/2506.15720, 2025-06-03
2025-11-11 00:41:03,535 - INFO - root - Page:1, Index:37, PARC: A Quantitative Framework Uncovering the Symmetries within Vision Language Models, https://arxiv.org/pdf/2506.14808, 2025-06-03
2025-11-11 00:41:03,535 - INFO - root - Page:1, Index:38, Self-supervised Representation Learning with Local Aggregation for Image-based Profiling, https://arxiv.org/pdf/2506.14265, 2025-10-27
2025-11-11 00:41:03,535 - INFO - root - Page:1, Index:39, Towards Robust Learning to Optimize with Theoretical Guarantees, https://arxiv.org/pdf/2506.14263, 2025-06-17
2025-11-11 00:41:03,535 - INFO - root - Page:1, Index:40, Hidden Bias in the Machine: Stereotypes in Text-to-Image Models, https://arxiv.org/pdf/2506.13780, 2025-06-09
2025-11-11 00:41:03,536 - INFO - root - Page:1, Index:41, SmartHome-Bench: A Comprehensive Benchmark for Video Anomaly Detection in Smart Homes Using Multi-Modal Large Language Models, https://arxiv.org/pdf/2506.12992, 2025-06-15
2025-11-11 00:41:03,536 - INFO - root - Page:1, Index:42, Generative 4D Scene Gaussian Splatting with Object View-Synthesis Priors, https://arxiv.org/pdf/2506.12716, 2025-06-15
2025-11-11 00:41:03,536 - INFO - root - Page:1, Index:43, DejaVid: Encoder-Agnostic Learned Temporal Matching for Video Classification, https://arxiv.org/pdf/2506.12585, 2025-06-14
2025-11-11 00:41:03,537 - INFO - root - Page:1, Index:44, Pushing the Limits of Safety: A Technical Report on the ATLAS Challenge 2025, https://arxiv.org/pdf/2506.12430, 2025-07-10
2025-11-11 00:41:03,537 - INFO - root - Page:1, Index:45, FIMA-Q: Post-Training Quantization for Vision Transformers by Fisher Information Matrix Approximation, https://arxiv.org/pdf/2506.11543, 2025-06-13
2025-11-11 00:41:03,537 - INFO - root - Page:1, Index:46, Stop learning it all to mitigate visual hallucination, Focus on the hallucination target, https://arxiv.org/pdf/2506.11417, 2025-06-12
2025-11-11 00:41:03,538 - INFO - root - Page:1, Index:47, EfficientQuant: An Efficient Post-Training Quantization for CNN-Transformer Hybrid Models on Edge Devices, https://arxiv.org/pdf/2506.11093, 2025-06-05
2025-11-11 00:41:03,538 - INFO - root - Page:1, Index:48, HalLoc: Token-level Localization of Hallucinations for Vision Language Models, https://arxiv.org/pdf/2506.10286, 2025-06-11
2025-11-11 00:41:03,538 - INFO - root - Page:1, Index:49, DySS: Dynamic Queries and State-Space Learning for Efficient 3D Object Detection from Multi-Camera Videos, https://arxiv.org/pdf/2506.10242, 2025-06-11
2025-11-11 00:41:03,538 - INFO - root - Fetching page 3 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=100
2025-11-11 00:41:10,712 - INFO - root - get_all_titles_from_web 
2025-11-11 00:41:10,712 - INFO - root - Page:2, Index:0, Improving Personalized Search with Regularized Low-Rank Parameter Updates, https://arxiv.org/pdf/2506.10182, 2025-06-11
2025-11-11 00:41:10,713 - INFO - root - Page:2, Index:1, Hearing Hands: Generating Sounds from Physical Interactions in 3D Scenes, https://arxiv.org/pdf/2506.09989, 2025-06-11
2025-11-11 00:41:10,713 - INFO - root - Page:2, Index:2, UniPre3D: Unified Pre-training of 3D Point Cloud Models with Cross-Modal Gaussian Splatting, https://arxiv.org/pdf/2506.09952, 2025-06-11
2025-11-11 00:41:10,713 - INFO - root - Page:2, Index:3, Provoking Multi-modal Few-Shot LVLM via Exploration-Exploitation In-Context Learning, https://arxiv.org/pdf/2506.09473, 2025-06-11
2025-11-11 00:41:10,714 - INFO - root - Page:2, Index:4, Synthetic Human Action Video Data Generation with Pose Transfer, https://arxiv.org/pdf/2506.09411, 2025-06-11
2025-11-11 00:41:10,714 - INFO - root - Page:2, Index:5, ScaleLSD: Scalable Deep Line Segment Detection Streamlined, https://arxiv.org/pdf/2506.09369, 2025-06-10
2025-11-11 00:41:10,714 - INFO - root - Page:2, Index:6, CheckManual: A New Challenge and Benchmark for Manual-based Appliance Manipulation, https://arxiv.org/pdf/2506.09343, 2025-06-10
2025-11-11 00:41:10,714 - INFO - root - Page:2, Index:7, PatchGuard: Adversarially Robust Anomaly Detection and Localization through Vision Transformers and Pseudo Anomalies, https://arxiv.org/pdf/2506.09237, 2025-10-24
2025-11-11 00:41:10,715 - INFO - root - Page:2, Index:8, SILK: Smooth InterpoLation frameworK for motion in-betweening A Simplified Computational Approach, https://arxiv.org/pdf/2506.09075, 2025-06-09
2025-11-11 00:41:10,715 - INFO - root - Page:2, Index:9, BG-HOP: A Bimanual Generative Hand-Object Prior, https://arxiv.org/pdf/2506.09068, 2025-06-08
2025-11-11 00:41:10,715 - INFO - root - Page:2, Index:10, ORIDa: Object-centric Real-world Image Composition Dataset, https://arxiv.org/pdf/2506.08964, 2025-06-10
2025-11-11 00:41:10,716 - INFO - root - Page:2, Index:11, DiscoVLA: Discrepancy Reduction in Vision, Language, and Alignment for Parameter-Efficient Video-Text Retrieval, https://arxiv.org/pdf/2506.08887, 2025-06-10
2025-11-11 00:41:10,716 - INFO - root - Page:2, Index:12, A Comprehensive Study of Decoder-Only LLMs for Text-to-Image Generation, https://arxiv.org/pdf/2506.08210, 2025-06-09
2025-11-11 00:41:10,716 - INFO - root - Page:2, Index:13, Open World Scene Graph Generation using Vision Language Models, https://arxiv.org/pdf/2506.08189, 2025-06-09
2025-11-11 00:41:10,718 - INFO - root - Page:2, Index:14, Aligning Proteins and Language: A Foundation Model for Protein Retrieval, https://arxiv.org/pdf/2506.08023, 2025-05-27
2025-11-11 00:41:10,718 - INFO - root - Page:2, Index:15, UA-Pose: Uncertainty-Aware 6D Object Pose Estimation and Online Object Completion with Partial References, https://arxiv.org/pdf/2506.07996, 2025-06-09
2025-11-11 00:41:10,718 - INFO - root - Page:2, Index:16, Speedy Deformable 3D Gaussian Splatting: Fast Rendering and Compression of Dynamic Scenes, https://arxiv.org/pdf/2506.07917, 2025-06-09
2025-11-11 00:41:10,719 - INFO - root - Page:2, Index:17, GaussianVAE: Adaptive Learning Dynamics of 3D Gaussians for High-Fidelity Super-Resolution, https://arxiv.org/pdf/2506.07897, 2025-06-09
2025-11-11 00:41:10,719 - INFO - root - Page:2, Index:18, Spatio-Temporal State Space Model For Efficient Event-Based Optical Flow, https://arxiv.org/pdf/2506.07878, 2025-06-09
2025-11-11 00:41:10,720 - INFO - root - Page:2, Index:19, FreeGave: 3D Physics Learning from Dynamic Videos by Gaussian Velocity, https://arxiv.org/pdf/2506.07865, 2025-06-09
2025-11-11 00:41:10,720 - INFO - root - Page:2, Index:20, LogoSP: Local-global Grouping of Superpoints for Unsupervised Semantic Segmentation of 3D Point Clouds, https://arxiv.org/pdf/2506.07857, 2025-06-09
2025-11-11 00:41:10,720 - INFO - root - Page:2, Index:21, Difference Inversion: Interpolate and Isolate the Difference with Token Consistency for Image Analogy Generation, https://arxiv.org/pdf/2506.07750, 2025-06-09
2025-11-11 00:41:10,721 - INFO - root - Page:2, Index:22, Synthetic Visual Genome, https://arxiv.org/pdf/2506.07643, 2025-06-09
2025-11-11 00:41:10,721 - INFO - root - Page:2, Index:23, Fractional Collisions: A Framework for Risk Estimation of Counterfactual Conflicts using Autonomous Driving Behavior Simulations, https://arxiv.org/pdf/2506.07540, 2025-06-09
2025-11-11 00:41:10,721 - INFO - root - Page:2, Index:24, Multi-Step Guided Diffusion for Image Restoration on Edge Devices: Toward Lightweight Perception in Embodied AI, https://arxiv.org/pdf/2506.07286, 2025-06-08
2025-11-11 00:41:10,721 - INFO - root - Page:2, Index:25, LLM-Enhanced Rapid-Reflex Async-Reflect Embodied Agent for Real-Time Decision-Making in Dynamically Changing Environments, https://arxiv.org/pdf/2506.07223, 2025-06-08
2025-11-11 00:41:10,722 - INFO - root - Page:2, Index:26, UCOD-DPL: Unsupervised Camouflaged Object Detection via Dynamic Pseudo-label Learning, https://arxiv.org/pdf/2506.07087, 2025-06-08
2025-11-11 00:41:10,722 - INFO - root - Page:2, Index:27, BePo: Leveraging Birds Eye View and Sparse Points for Efficient and Accurate 3D Occupancy Prediction, https://arxiv.org/pdf/2506.07002, 2025-06-08
2025-11-11 00:41:10,722 - INFO - root - Page:2, Index:28, Reading in the Dark with Foveated Event Vision, https://arxiv.org/pdf/2506.06918, 2025-06-07
2025-11-11 00:41:10,724 - INFO - root - Page:2, Index:29, NSD-Imagery: A benchmark dataset for extending fMRI vision decoding methods to mental imagery, https://arxiv.org/pdf/2506.06898, 2025-06-07
2025-11-11 00:41:10,724 - INFO - root - Page:2, Index:30, Continuous-Time SO(3) Forecasting with Savitzky--Golay Neural Controlled Differential Equations, https://arxiv.org/pdf/2506.06780, 2025-06-07
2025-11-11 00:41:10,725 - INFO - root - Page:2, Index:31, Generalized Trajectory Scoring for End-to-end Multimodal Planning, https://arxiv.org/pdf/2506.06664, 2025-06-07
2025-11-11 00:41:10,725 - INFO - root - Page:2, Index:32, EV-LayerSegNet: Self-supervised Motion Segmentation using Event Cameras, https://arxiv.org/pdf/2506.06596, 2025-06-06
2025-11-11 00:41:10,725 - INFO - root - Page:2, Index:33, Vid2Sim: Generalizable, Video-based Reconstruction of Appearance, Geometry and Physics for Mesh-free Simulation, https://arxiv.org/pdf/2506.06440, 2025-06-06
2025-11-11 00:41:10,725 - INFO - root - Page:2, Index:34, FADE: Frequency-Aware Diffusion Model Factorization for Video Editing, https://arxiv.org/pdf/2506.05934, 2025-06-06
2025-11-11 00:41:10,726 - INFO - root - Page:2, Index:35, Unleashing the Potential of Consistency Learning for Detecting and Grounding Multi-Modal Media Manipulation, https://arxiv.org/pdf/2506.05890, 2025-06-06
2025-11-11 00:41:10,726 - INFO - root - Page:2, Index:36, DeformCL: Learning Deformable Centerline Representation for Vessel Extraction in 3D Medical Image, https://arxiv.org/pdf/2506.05820, 2025-06-06
2025-11-11 00:41:10,726 - INFO - root - Page:2, Index:37, NTIRE 2025 Challenge on HR Depth from Images of Specular and Transparent Surfaces, https://arxiv.org/pdf/2506.05815, 2025-06-06
2025-11-11 00:41:10,726 - INFO - root - Page:2, Index:38, GazeNLQ @ Ego4D Natural Language Queries Challenge 2025, https://arxiv.org/pdf/2506.05782, 2025-06-06
2025-11-11 00:41:10,727 - INFO - root - Page:2, Index:39, Robust sensor fusion against on-vehicle sensor staleness, https://arxiv.org/pdf/2506.05780, 2025-06-06
2025-11-11 00:41:10,727 - INFO - root - Page:2, Index:40, Where Is The Ball: 3D Ball Trajectory Estimation From 2D Monocular Tracking, https://arxiv.org/pdf/2506.05763, 2025-06-06
2025-11-11 00:41:10,727 - INFO - root - Page:2, Index:41, VoxelSplat: Dynamic Gaussian Splatting as an Effective Loss for Occupancy and Flow Prediction, https://arxiv.org/pdf/2506.05563, 2025-06-05
2025-11-11 00:41:10,728 - INFO - root - Page:2, Index:42, Gen4D: Synthesizing Humans and Scenes in the Wild, https://arxiv.org/pdf/2506.05397, 2025-06-03
2025-11-11 00:41:10,728 - INFO - root - Page:2, Index:43, Attacking Attention of Foundation Models Disrupts Downstream Tasks, https://arxiv.org/pdf/2506.05394, 2025-09-12
2025-11-11 00:41:10,728 - INFO - root - Page:2, Index:44, FreeTimeGS: Free Gaussian Primitives at Anytime and Anywhere for Dynamic Scene Reconstruction, https://arxiv.org/pdf/2506.05348, 2025-06-06
2025-11-11 00:41:10,729 - INFO - root - Page:2, Index:45, LotusFilter: Fast Diverse Nearest Neighbor Search via a Learned Cutoff Table, https://arxiv.org/pdf/2506.04790, 2025-06-05
2025-11-11 00:41:10,729 - INFO - root - Page:2, Index:46, Towards Holistic Visual Quality Assessment of AI-Generated Videos: A LLM-Based Multi-Dimensional Evaluation Model, https://arxiv.org/pdf/2506.04715, 2025-06-11
2025-11-11 00:41:10,729 - INFO - root - Page:2, Index:47, Gradient Inversion Attacks on Parameter-Efficient Fine-Tuning, https://arxiv.org/pdf/2506.04453, 2025-06-04
2025-11-11 00:41:10,729 - INFO - root - Page:2, Index:48, HMAR: Efficient Hierarchical Masked Auto-Regressive Image Generation, https://arxiv.org/pdf/2506.04421, 2025-06-04
2025-11-11 00:41:10,730 - INFO - root - Page:2, Index:49, Visualizing and Controlling Cortical Responses Using Voxel-Weighted Activation Maximization, https://arxiv.org/pdf/2506.04379, 2025-06-04
2025-11-11 00:41:10,730 - INFO - root - Fetching page 4 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=150
2025-11-11 00:41:17,134 - INFO - root - get_all_titles_from_web 
2025-11-11 00:41:17,135 - INFO - root - Page:3, Index:0, FlexGS: Train Once, Deploy Everywhere with Many-in-One Flexible 3D Gaussian Splatting, https://arxiv.org/pdf/2506.04174, 2025-06-04
2025-11-11 00:41:17,135 - INFO - root - Page:3, Index:1, Multi-view Surface Reconstruction Using Normal and Reflectance Cues, https://arxiv.org/pdf/2506.04115, 2025-06-04
2025-11-11 00:41:17,136 - INFO - root - Page:3, Index:2, Vocabulary-free few-shot learning for Vision-Language Models, https://arxiv.org/pdf/2506.04005, 2025-06-04
2025-11-11 00:41:17,136 - INFO - root - Page:3, Index:3, Learning from Noise: Enhancing DNNs for Event-Based Vision through Controlled Noise Injection, https://arxiv.org/pdf/2506.03918, 2025-06-04
2025-11-11 00:41:17,137 - INFO - root - Page:3, Index:4, Video, How Do Your Tokens Merge?, https://arxiv.org/pdf/2506.03885, 2025-06-04
2025-11-11 00:41:17,137 - INFO - root - Page:3, Index:5, OSGNet @ Ego4D Episodic Memory Challenge 2025, https://arxiv.org/pdf/2506.03710, 2025-06-04
2025-11-11 00:41:17,137 - INFO - root - Page:3, Index:6, AetherVision-Bench: An Open-Vocabulary RGB-Infrared Benchmark for Multi-Angle Segmentation across Aerial and Ground Perspectives, https://arxiv.org/pdf/2506.03709, 2025-06-04
2025-11-11 00:41:17,138 - INFO - root - Page:3, Index:7, OV-COAST: Cost Aggregation with Optimal Transport for Open-Vocabulary Semantic Segmentation, https://arxiv.org/pdf/2506.03706, 2025-06-04
2025-11-11 00:41:17,138 - INFO - root - Page:3, Index:8, Generating 6DoF Object Manipulation Trajectories from Action Description in Egocentric Vision, https://arxiv.org/pdf/2506.03605, 2025-06-04
2025-11-11 00:41:17,138 - INFO - root - Page:3, Index:9, SemNav: A Model-Based Planner for Zero-Shot Object Goal Navigation Using Vision-Foundation Models, https://arxiv.org/pdf/2506.03516, 2025-06-03
2025-11-11 00:41:17,139 - INFO - root - Page:3, Index:10, Heterogeneous Skeleton-Based Action Representation Learning, https://arxiv.org/pdf/2506.03481, 2025-06-03
2025-11-11 00:41:17,139 - INFO - root - Page:3, Index:11, Hybrid Ensemble of Segmentation-Assisted Classification and GBDT for Skin Cancer Detection with Engineered Metadata and Synthetic Lesions from ISIC 2024 Non-Dermoscopic 3D-TBP Images, https://arxiv.org/pdf/2506.03420, 2025-06-03
2025-11-11 00:41:17,139 - INFO - root - Page:3, Index:12, Self-Supervised Spatial Correspondence Across Modalities, https://arxiv.org/pdf/2506.03148, 2025-06-03
2025-11-11 00:41:17,143 - INFO - root - Page:3, Index:13, Dense Match Summarization for Faster Two-view Estimation, https://arxiv.org/pdf/2506.02893, 2025-06-03
2025-11-11 00:41:17,144 - INFO - root - Page:3, Index:14, NTIRE 2025 XGC Quality Assessment Challenge: Methods and Results, https://arxiv.org/pdf/2506.02875, 2025-06-03
2025-11-11 00:41:17,146 - INFO - root - Page:3, Index:15, FreeScene: Mixed Graph Diffusion for 3D Scene Synthesis from Free Prompts, https://arxiv.org/pdf/2506.02781, 2025-06-03
2025-11-11 00:41:17,147 - INFO - root - Page:3, Index:16, Technical Report for Ego4D Long-Term Action Anticipation Challenge 2025, https://arxiv.org/pdf/2506.02550, 2025-06-11
2025-11-11 00:41:17,147 - INFO - root - Page:3, Index:17, Probabilistic Online Event Downsampling, https://arxiv.org/pdf/2506.02547, 2025-09-23
2025-11-11 00:41:17,148 - INFO - root - Page:3, Index:18, Towards In-the-wild 3D Plane Reconstruction from a Single Image, https://arxiv.org/pdf/2506.02493, 2025-06-03
2025-11-11 00:41:17,149 - INFO - root - Page:3, Index:19, Efficient Test-time Adaptive Object Detection via Sensitivity-Guided Pruning, https://arxiv.org/pdf/2506.02462, 2025-06-03
2025-11-11 00:41:17,149 - INFO - root - Page:3, Index:20, EgoVIS@CVPR: PAIR-Net: Enhancing Egocentric Speaker Detection via Pretrained Audio-Visual Fusion and Alignment Loss, https://arxiv.org/pdf/2506.02247, 2025-09-26
2025-11-11 00:41:17,150 - INFO - root - Page:3, Index:21, Diff2Flow: Training Flow Matching Models via Diffusion Model Alignment, https://arxiv.org/pdf/2506.02221, 2025-06-02
2025-11-11 00:41:17,150 - INFO - root - Page:3, Index:22, NTIRE 2025 Challenge on RAW Image Restoration and Super-Resolution, https://arxiv.org/pdf/2506.02197, 2025-06-04
2025-11-11 00:41:17,150 - INFO - root - Page:3, Index:23, RAW Image Reconstruction from RGB on Smartphones. NTIRE 2025 Challenge Report, https://arxiv.org/pdf/2506.01947, 2025-06-02
2025-11-11 00:41:17,152 - INFO - root - Page:3, Index:24, Silence is Golden: Leveraging Adversarial Examples to Nullify Audio Control in LDM-based Talking-Head Generation, https://arxiv.org/pdf/2506.01591, 2025-06-02
2025-11-11 00:41:17,152 - INFO - root - Page:3, Index:25, SAM2-LOVE: Segment Anything Model 2 in Language-aided Audio-Visual Scenes, https://arxiv.org/pdf/2506.01558, 2025-06-02
2025-11-11 00:41:17,152 - INFO - root - Page:3, Index:26, Neural shape reconstruction from multiple views with static pattern projection, https://arxiv.org/pdf/2506.01389, 2025-06-02
2025-11-11 00:41:17,152 - INFO - root - Page:3, Index:27, SAM-I2V: Upgrading SAM to Support Promptable Video Segmentation with Less than 0.2% Training Cost, https://arxiv.org/pdf/2506.01304, 2025-06-02
2025-11-11 00:41:17,152 - INFO - root - Page:3, Index:28, Perceptual Inductive Bias Is What You Need Before Contrastive Learning, https://arxiv.org/pdf/2506.01201, 2025-06-01
2025-11-11 00:41:17,153 - INFO - root - Page:3, Index:29, Test Automation for Interactive Scenarios via Promptable Traffic Simulation, https://arxiv.org/pdf/2506.01199, 2025-06-04
2025-11-11 00:41:17,153 - INFO - root - Page:3, Index:30, GraphPad: Inference-Time 3D Scene Graph Updates for Embodied Question Answering, https://arxiv.org/pdf/2506.01174, 2025-06-01
2025-11-11 00:41:17,153 - INFO - root - Page:3, Index:31, Aligned Contrastive Loss for Long-Tailed Recognition, https://arxiv.org/pdf/2506.01071, 2025-06-01
2025-11-11 00:41:17,153 - INFO - root - Page:3, Index:32, Self-supervised ControlNet with Spatio-Temporal Mamba for Real-world Video Super-resolution, https://arxiv.org/pdf/2506.01037, 2025-06-01
2025-11-11 00:41:17,154 - INFO - root - Page:3, Index:33, ArtiScene: Language-Driven Artistic 3D Scene Generation Through Image Intermediary, https://arxiv.org/pdf/2506.00742, 2025-05-31
2025-11-11 00:41:17,154 - INFO - root - Page:3, Index:34, 3D Gaussian Splat Vulnerabilities, https://arxiv.org/pdf/2506.00280, 2025-05-30
2025-11-11 00:41:17,154 - INFO - root - Page:3, Index:35, EgoVIS@CVPR: What Changed and What Could Have Changed? State-Change Counterfactuals for Procedure-Aware Video Representation Learning, https://arxiv.org/pdf/2506.00101, 2025-09-26
2025-11-11 00:41:17,154 - INFO - root - Page:3, Index:36, CL-LoRA: Continual Low-Rank Adaptation for Rehearsal-Free Class-Incremental Learning, https://arxiv.org/pdf/2505.24816, 2025-05-30
2025-11-11 00:41:17,155 - INFO - root - Page:3, Index:37, PatchDEMUX: A Certifiably Robust Framework for Multi-label Classifiers Against Adversarial Patches, https://arxiv.org/pdf/2505.24703, 2025-05-30
2025-11-11 00:41:17,155 - INFO - root - Page:3, Index:38, Conformal Prediction for Zero-Shot Models, https://arxiv.org/pdf/2505.24693, 2025-05-30
2025-11-11 00:41:17,155 - INFO - root - Page:3, Index:39, Learning reusable concepts across different egocentric video understanding tasks, https://arxiv.org/pdf/2505.24690, 2025-05-30
2025-11-11 00:41:17,158 - INFO - root - Page:3, Index:40, Period-LLM: Extending the Periodic Capability of Multimodal Large Language Model, https://arxiv.org/pdf/2505.24476, 2025-05-30
2025-11-11 00:41:17,159 - INFO - root - Page:3, Index:41, PCIE_Interaction Solution for Ego4D Social Interaction Challenge, https://arxiv.org/pdf/2505.24404, 2025-05-30
2025-11-11 00:41:17,159 - INFO - root - Page:3, Index:42, Leadership Assessment in Pediatric Intensive Care Unit Team Training, https://arxiv.org/pdf/2505.24389, 2025-08-28
2025-11-11 00:41:17,159 - INFO - root - Page:3, Index:43, Interpreting Large Text-to-Image Diffusion Models with Dictionary Learning, https://arxiv.org/pdf/2505.24360, 2025-07-10
2025-11-11 00:41:17,160 - INFO - root - Page:3, Index:44, InteractAnything: Zero-shot Human Object Interaction Synthesis via LLM Feedback and Object Affordance Parsing, https://arxiv.org/pdf/2505.24315, 2025-05-30
2025-11-11 00:41:17,161 - INFO - root - Page:3, Index:45, MaskAdapt: Unsupervised Geometry-Aware Domain Adaptation Using Multimodal Contextual Learning and RGB-Depth Masking, https://arxiv.org/pdf/2505.24026, 2025-05-29
2025-11-11 00:41:17,162 - INFO - root - Page:3, Index:46, Argus: Vision-Centric Reasoning with Grounded Chain-of-Thought, https://arxiv.org/pdf/2505.23766, 2025-05-29
2025-11-11 00:41:17,162 - INFO - root - Page:3, Index:47, Sketch Down the FLOPs: Towards Efficient Networks for Human Sketch, https://arxiv.org/pdf/2505.23763, 2025-05-29
2025-11-11 00:41:17,162 - INFO - root - Page:3, Index:48, Boosting Domain Incremental Learning: Selecting the Optimal Parameters is All You Need, https://arxiv.org/pdf/2505.23744, 2025-05-29
2025-11-11 00:41:17,163 - INFO - root - Page:3, Index:49, DA-VPT: Semantic-Guided Visual Prompt Tuning for Vision Transformers, https://arxiv.org/pdf/2505.23694, 2025-06-01
2025-11-11 00:41:17,164 - INFO - root - Fetching page 5 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=200
2025-11-11 00:41:23,349 - INFO - root - get_all_titles_from_web 
2025-11-11 00:41:23,350 - INFO - root - Page:4, Index:0, Bridging Classical and Modern Computer Vision: PerceptiveNet for Tree Crown Semantic Segmentation, https://arxiv.org/pdf/2505.23597, 2025-05-29
2025-11-11 00:41:23,350 - INFO - root - Page:4, Index:1, Synthetic Generation and Latent Projection Denoising of Rim Lesions in Multiple Sclerosis, https://arxiv.org/pdf/2505.23353, 2025-05-29
2025-11-11 00:41:23,350 - INFO - root - Page:4, Index:2, Wav2Sem: Plug-and-Play Audio Semantic Decoupling for 3D Speech-Driven Facial Animation, https://arxiv.org/pdf/2505.23290, 2025-05-29
2025-11-11 00:41:23,350 - INFO - root - Page:4, Index:3, Proximal Algorithm Unrolling: Flexible and Efficient Reconstruction Networks for Single-Pixel Imaging, https://arxiv.org/pdf/2505.23180, 2025-05-29
2025-11-11 00:41:23,351 - INFO - root - Page:4, Index:4, HMAD: Advancing E2E Driving with Anchored Offset Proposals and Simulation-Supervised Multi-target Scoring, https://arxiv.org/pdf/2505.23129, 2025-05-29
2025-11-11 00:41:23,351 - INFO - root - Page:4, Index:5, URWKV: Unified RWKV Model with Multi-state Perspective for Low-light Image Restoration, https://arxiv.org/pdf/2505.23068, 2025-05-29
2025-11-11 00:41:23,351 - INFO - root - Page:4, Index:6, 4DTAM: Non-Rigid Tracking and Mapping via Dynamic Surface Gaussians, https://arxiv.org/pdf/2505.22859, 2025-05-28
2025-11-11 00:41:23,352 - INFO - root - Page:4, Index:7, A Probabilistic Jump-Diffusion Framework for Open-World Egocentric Activity Recognition, https://arxiv.org/pdf/2505.22858, 2025-05-28
2025-11-11 00:41:23,352 - INFO - root - Page:4, Index:8, PS4PRO: Pixel-to-pixel Supervision for Photorealistic Rendering and Optimization, https://arxiv.org/pdf/2505.22616, 2025-05-28
2025-11-11 00:41:23,352 - INFO - root - Page:4, Index:9, Universal Domain Adaptation for Semantic Segmentation, https://arxiv.org/pdf/2505.22458, 2025-06-05
2025-11-11 00:41:23,353 - INFO - root - Page:4, Index:10, Zero-Shot 3D Visual Grounding from Vision-Language Models, https://arxiv.org/pdf/2505.22429, 2025-05-28
2025-11-11 00:41:23,353 - INFO - root - Page:4, Index:11, RC-AutoCalib: An End-to-End Radar-Camera Automatic Calibration Network, https://arxiv.org/pdf/2505.22427, 2025-05-28
2025-11-11 00:41:23,353 - INFO - root - Page:4, Index:12, Bringing CLIP to the Clinic: Dynamic Soft Labels and Negation-Aware Learning for Medical Analysis, https://arxiv.org/pdf/2505.22079, 2025-05-28
2025-11-11 00:41:23,353 - INFO - root - Page:4, Index:13, Point-to-Region Loss for Semi-Supervised Point-Based Crowd Counting, https://arxiv.org/pdf/2505.21943, 2025-05-27
2025-11-11 00:41:23,354 - INFO - root - Page:4, Index:14, FRAMES-VQA: Benchmarking Fine-Tuning Robustness across Multi-Modal Shifts in Visual Question Answering, https://arxiv.org/pdf/2505.21755, 2025-06-20
2025-11-11 00:41:23,354 - INFO - root - Page:4, Index:15, Knowledge Distillation Approach for SOS Fusion Staging: Towards Fully Automated Skeletal Maturity Assessment, https://arxiv.org/pdf/2505.21561, 2025-05-26
2025-11-11 00:41:23,355 - INFO - root - Page:4, Index:16, Enhancing Vision Transformer Explainability Using Artificial Astrocytes, https://arxiv.org/pdf/2505.21513, 2025-05-20
2025-11-11 00:41:23,355 - INFO - root - Page:4, Index:17, Empowering Vector Graphics with Consistently Arbitrary Viewing and View-dependent Visibility, https://arxiv.org/pdf/2505.21377, 2025-05-27
2025-11-11 00:41:23,355 - INFO - root - Page:4, Index:18, Structure from Collision, https://arxiv.org/pdf/2505.21335, 2025-05-27
2025-11-11 00:41:23,355 - INFO - root - Page:4, Index:19, Boosting Adversarial Transferability via High-Frequency Augmentation and Hierarchical-Gradient Fusion, https://arxiv.org/pdf/2505.21181, 2025-05-27
2025-11-11 00:41:23,356 - INFO - root - Page:4, Index:20, RefAV: Towards Planning-Centric Scenario Mining, https://arxiv.org/pdf/2505.20981, 2025-06-18
2025-11-11 00:41:23,356 - INFO - root - Page:4, Index:21, PMA: Towards Parameter-Efficient Point Cloud Understanding via Point Mamba Adapter, https://arxiv.org/pdf/2505.20941, 2025-05-27
2025-11-11 00:41:23,356 - INFO - root - Page:4, Index:22, HuMoCon: Concept Discovery for Human Motion Understanding, https://arxiv.org/pdf/2505.20920, 2025-05-27
2025-11-11 00:41:23,356 - INFO - root - Page:4, Index:23, Exploring Timeline Control for Facial Motion Generation, https://arxiv.org/pdf/2505.20861, 2025-05-27
2025-11-11 00:41:23,357 - INFO - root - Page:4, Index:24, ConText-CIR: Learning from Concepts in Text for Composed Image Retrieval, https://arxiv.org/pdf/2505.20764, 2025-05-27
2025-11-11 00:41:23,357 - INFO - root - Page:4, Index:25, HCQA-1.5 @ Ego4D EgoSchema Challenge 2025, https://arxiv.org/pdf/2505.20644, 2025-05-26
2025-11-11 00:41:23,357 - INFO - root - Page:4, Index:26, Roboflow100-VL: A Multi-Domain Object Detection Benchmark for Vision-Language Models, https://arxiv.org/pdf/2505.20612, 2025-10-22
2025-11-11 00:41:23,357 - INFO - root - Page:4, Index:27, MotionPro: A Precise Motion Controller for Image-to-Video Generation, https://arxiv.org/pdf/2505.20287, 2025-05-26
2025-11-11 00:41:23,357 - INFO - root - Page:4, Index:28, Category-Agnostic Neural Object Rigging, https://arxiv.org/pdf/2505.20283, 2025-05-26
2025-11-11 00:41:23,357 - INFO - root - Page:4, Index:29, Towards Video to Piano Music Generation with Chain-of-Perform Support Benchmarks, https://arxiv.org/pdf/2505.20038, 2025-05-26
2025-11-11 00:41:23,357 - INFO - root - Page:4, Index:30, Can Visual Encoder Learn to See Arrows?, https://arxiv.org/pdf/2505.19944, 2025-05-26
2025-11-11 00:41:23,357 - INFO - root - Page:4, Index:31, GoLF-NRT: Integrating Global Context and Local Geometry for Few-Shot View Synthesis, https://arxiv.org/pdf/2505.19813, 2025-05-26
2025-11-11 00:41:23,359 - INFO - root - Page:4, Index:32, Depth-Guided Bundle Sampling for Efficient Generalizable Neural Radiance Field Reconstruction, https://arxiv.org/pdf/2505.19793, 2025-05-26
2025-11-11 00:41:23,359 - INFO - root - Page:4, Index:33, SuperAD: A Training-free Anomaly Classification and Segmentation Method for CVPR 2025 VAND 3.0 Workshop Challenge Track 1: Adapt & Detect, https://arxiv.org/pdf/2505.19750, 2025-05-27
2025-11-11 00:41:23,359 - INFO - root - Page:4, Index:34, Knowledge-Aligned Counterfactual-Enhancement Diffusion Perception for Unsupervised Cross-Domain Visual Emotion Recognition, https://arxiv.org/pdf/2505.19694, 2025-05-26
2025-11-11 00:41:23,360 - INFO - root - Page:4, Index:35, Rotation-Equivariant Self-Supervised Method in Image Denoising, https://arxiv.org/pdf/2505.19618, 2025-05-26
2025-11-11 00:41:23,360 - INFO - root - Page:4, Index:36, NTIRE 2025 Challenge on Video Quality Enhancement for Video Conferencing: Datasets, Methods and Results, https://arxiv.org/pdf/2505.18988, 2025-05-25
2025-11-11 00:41:23,361 - INFO - root - Page:4, Index:37, Geometry-guided Online 3D Video Synthesis with Multi-View Temporal Consistency, https://arxiv.org/pdf/2505.18932, 2025-05-24
2025-11-11 00:41:23,362 - INFO - root - Page:4, Index:38, Digital Overconsumption and Waste: A Closer Look at the Impacts of Generative AI, https://arxiv.org/pdf/2505.18894, 2025-05-24
2025-11-11 00:41:23,363 - INFO - root - Page:4, Index:39, VISTA: Vision-Language Inference for Training-Free Stock Time-Series Analysis, https://arxiv.org/pdf/2505.18570, 2025-06-11
2025-11-11 00:41:23,366 - INFO - root - Page:4, Index:40, Syn3DTxt: Embedding 3D Cues for Scene Text Generation, https://arxiv.org/pdf/2505.18479, 2025-05-23
2025-11-11 00:41:23,367 - INFO - root - Page:4, Index:41, CTRL-GS: Cascaded Temporal Residue Learning for 4D Gaussian Splatting, https://arxiv.org/pdf/2505.18306, 2025-05-31
2025-11-11 00:41:23,368 - INFO - root - Page:4, Index:42, DualTalk: Dual-Speaker Interaction for 3D Talking Head Conversations, https://arxiv.org/pdf/2505.18096, 2025-05-26
2025-11-11 00:41:23,369 - INFO - root - Page:4, Index:43, SeaLion: Semantic Part-Aware Latent Point Diffusion Models for 3D Generation, https://arxiv.org/pdf/2505.17721, 2025-07-07
2025-11-11 00:41:23,369 - INFO - root - Page:4, Index:44, PoseBH: Prototypical Multi-Dataset Training Beyond Human Pose Estimation, https://arxiv.org/pdf/2505.17475, 2025-05-23
2025-11-11 00:41:23,369 - INFO - root - Page:4, Index:45, Pursuing Temporal-Consistent Video Virtual Try-On via Dynamic Pose Interaction, https://arxiv.org/pdf/2505.16980, 2025-05-22
2025-11-11 00:41:23,369 - INFO - root - Page:4, Index:46, UniPhy: Learning a Unified Constitutive Model for Inverse Physics Simulation, https://arxiv.org/pdf/2505.16971, 2025-05-22
2025-11-11 00:41:23,369 - INFO - root - Page:4, Index:47, Tracking the Flight: Exploring a Computational Framework for Analyzing Escape Responses in Plains Zebra (Equus quagga), https://arxiv.org/pdf/2505.16882, 2025-05-23
2025-11-11 00:41:23,370 - INFO - root - Page:4, Index:48, Semi-Supervised State-Space Model with Dynamic Stacking Filter for Real-World Video Deraining, https://arxiv.org/pdf/2505.16811, 2025-05-22
2025-11-11 00:41:23,370 - INFO - root - Page:4, Index:49, SOLVE: Synergy of Language-Vision and End-to-End Networks for Autonomous Driving, https://arxiv.org/pdf/2505.16805, 2025-05-22
2025-11-11 00:41:23,371 - INFO - root - Fetching page 6 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=250
2025-11-11 00:41:30,431 - INFO - root - get_all_titles_from_web 
2025-11-11 00:41:30,431 - INFO - root - Page:5, Index:0, Four Eyes Are Better Than Two: Harnessing the Collaborative Potential of Large Models via Differentiated Thinking and Complementary Ensembles, https://arxiv.org/pdf/2505.16784, 2025-06-07
2025-11-11 00:41:30,432 - INFO - root - Page:5, Index:1, Single Domain Generalization for Few-Shot Counting via Universal Representation Matching, https://arxiv.org/pdf/2505.16778, 2025-05-22
2025-11-11 00:41:30,432 - INFO - root - Page:5, Index:2, Seeing Far and Clearly: Mitigating Hallucinations in MLLMs with Attention Causal Decoding, https://arxiv.org/pdf/2505.16652, 2025-06-07
2025-11-11 00:41:30,432 - INFO - root - Page:5, Index:3, Sketchy Bounding-box Supervision for 3D Instance Segmentation, https://arxiv.org/pdf/2505.16399, 2025-05-22
2025-11-11 00:41:30,432 - INFO - root - Page:5, Index:4, DeCafNet: Delegate and Conquer for Efficient Temporal Grounding in Long Videos, https://arxiv.org/pdf/2505.16376, 2025-05-22
2025-11-11 00:41:30,432 - INFO - root - Page:5, Index:5, NTIRE 2025 challenge on Text to Image Generation Model Quality Assessment, https://arxiv.org/pdf/2505.16314, 2025-05-22
2025-11-11 00:41:30,433 - INFO - root - Page:5, Index:6, Analyzing Hierarchical Structure in Vision Models with Sparse Autoencoders, https://arxiv.org/pdf/2505.15970, 2025-05-21
2025-11-11 00:41:30,433 - INFO - root - Page:5, Index:7, Efficient Data Driven Mixture-of-Expert Extraction from Trained Networks, https://arxiv.org/pdf/2505.15414, 2025-05-21
2025-11-11 00:41:30,433 - INFO - root - Page:5, Index:8, Mouse Lockbox Dataset: Behavior Recognition for Mice Solving Lockboxes, https://arxiv.org/pdf/2505.15408, 2025-06-17
2025-11-11 00:41:30,433 - INFO - root - Page:5, Index:9, Zero-Shot Gaze-based Volumetric Medical Image Segmentation, https://arxiv.org/pdf/2505.15256, 2025-06-10
2025-11-11 00:41:30,434 - INFO - root - Page:5, Index:10, Dual Precision Quantization for Efficient and Accurate Deep Neural Networks Inference, https://arxiv.org/pdf/2505.14638, 2025-05-20
2025-11-11 00:41:30,434 - INFO - root - Page:5, Index:11, Neural Video Compression with Context Modulation, https://arxiv.org/pdf/2505.14541, 2025-05-20
2025-11-11 00:41:30,434 - INFO - root - Page:5, Index:12, Selective Structured State Space for Multispectral-fused Small Target Detection, https://arxiv.org/pdf/2505.14043, 2025-05-23
2025-11-11 00:41:30,434 - INFO - root - Page:5, Index:13, OmniStyle: Filtering High Quality Style Transfer Data at Scale, https://arxiv.org/pdf/2505.14028, 2025-05-20
2025-11-11 00:41:30,435 - INFO - root - Page:5, Index:14, Domain Adaptation of VLM for Soccer Video Understanding, https://arxiv.org/pdf/2505.13860, 2025-07-07
2025-11-11 00:41:30,435 - INFO - root - Page:5, Index:15, Ground-V: Teaching VLMs to Ground Complex Instructions in Pixels, https://arxiv.org/pdf/2505.13788, 2025-05-19
2025-11-11 00:41:30,435 - INFO - root - Page:5, Index:16, FinePhys: Fine-grained Human Action Generation by Explicitly Incorporating Physical Laws for Effective Skeletal Guidance, https://arxiv.org/pdf/2505.13437, 2025-05-19
2025-11-11 00:41:30,435 - INFO - root - Page:5, Index:17, The Way Up: A Dataset for Hold Usage Detection in Sport Climbing, https://arxiv.org/pdf/2505.12854, 2025-05-19
2025-11-11 00:41:30,436 - INFO - root - Page:5, Index:18, PEER pressure: Model-to-Model Regularization for Single Source Domain Generalization, https://arxiv.org/pdf/2505.12745, 2025-05-19
2025-11-11 00:41:30,437 - INFO - root - Page:5, Index:19, Mamba-Adaptor: State Space Model Adaptor for Visual Recognition, https://arxiv.org/pdf/2505.12685, 2025-05-19
2025-11-11 00:41:30,437 - INFO - root - Page:5, Index:20, Scalable Video-to-Dataset Generation for Cross-Platform Mobile Agents, https://arxiv.org/pdf/2505.12632, 2025-05-18
2025-11-11 00:41:30,437 - INFO - root - Page:5, Index:21, Degradation-Aware Feature Perturbation for All-in-One Image Restoration, https://arxiv.org/pdf/2505.12630, 2025-05-18
2025-11-11 00:41:30,439 - INFO - root - Page:5, Index:22, Guiding Diffusion with Deep Geometric Moments: Balancing Fidelity and Variation, https://arxiv.org/pdf/2505.12486, 2025-05-18
2025-11-11 00:41:30,440 - INFO - root - Page:5, Index:23, Learning to Highlight Audio by Watching Movies, https://arxiv.org/pdf/2505.12154, 2025-05-17
2025-11-11 00:41:30,441 - INFO - root - Page:5, Index:24, Understanding the Capabilities of Molecular Graph Neural Networks in Materials Science Through Multimodal Learning and Physical Context Encoding, https://arxiv.org/pdf/2505.12137, 2025-05-17
2025-11-11 00:41:30,441 - INFO - root - Page:5, Index:25, iSegMan: Interactive Segment-and-Manipulate 3D Gaussians, https://arxiv.org/pdf/2505.11934, 2025-05-17
2025-11-11 00:41:30,441 - INFO - root - Page:5, Index:26, Self-Learning Hyperspectral and Multispectral Image Fusion via Adaptive Residual Guided Subspace Diffusion Model, https://arxiv.org/pdf/2505.11800, 2025-05-16
2025-11-11 00:41:30,442 - INFO - root - Page:5, Index:27, X-Edit: Detecting and Localizing Edits in Images Altered by Text-Guided Diffusion Models, https://arxiv.org/pdf/2505.11753, 2025-05-16
2025-11-11 00:41:30,442 - INFO - root - Page:5, Index:28, MTevent: A Multi-Task Event Camera Dataset for 6D Pose Estimation and Moving Object Detection, https://arxiv.org/pdf/2505.11282, 2025-06-02
2025-11-11 00:41:30,442 - INFO - root - Page:5, Index:29, Imputation-free and Alignment-free: Incomplete Multi-view Clustering Driven by Consensus Semantic Learning, https://arxiv.org/pdf/2505.11182, 2025-05-16
2025-11-11 00:41:30,443 - INFO - root - Page:5, Index:30, MultiLink: Multi-class Structure Recovery via Agglomerative Clustering and Model Selection, https://arxiv.org/pdf/2505.10874, 2025-05-16
2025-11-11 00:41:30,445 - INFO - root - Page:5, Index:31, RefPose: Leveraging Reference Geometric Correspondences for Accurate 6D Pose Estimation of Unseen Objects, https://arxiv.org/pdf/2505.10841, 2025-05-16
2025-11-11 00:41:30,446 - INFO - root - Page:5, Index:32, MoCLIP: Motion-Aware Fine-Tuning and Distillation of CLIP for Human Motion Generation, https://arxiv.org/pdf/2505.10810, 2025-05-15
2025-11-11 00:41:30,446 - INFO - root - Page:5, Index:33, Automated Detection of Salvin's Albatrosses: Improving Deep Learning Tools for Aerial Wildlife Surveys, https://arxiv.org/pdf/2505.10737, 2025-05-15
2025-11-11 00:41:30,446 - INFO - root - Page:5, Index:34, Advancing Multiple Instance Learning with Continual Learning for Whole Slide Imaging, https://arxiv.org/pdf/2505.10649, 2025-05-15
2025-11-11 00:41:30,448 - INFO - root - Page:5, Index:35, Inferring Driving Maps by Deep Learning-based Trail Map Extraction, https://arxiv.org/pdf/2505.10258, 2025-05-15
2025-11-11 00:41:30,448 - INFO - root - Page:5, Index:36, Behind Maya: Building a Multilingual Vision Language Model, https://arxiv.org/pdf/2505.08910, 2025-05-15
2025-11-11 00:41:30,449 - INFO - root - Page:5, Index:37, PosterO: Structuring Layout Trees to Enable Language Models in Generalized Content-Aware Layout Generation, https://arxiv.org/pdf/2505.07843, 2025-05-26
2025-11-11 00:41:30,449 - INFO - root - Page:5, Index:38, Prototype Augmented Hypernetworks for Continual Learning, https://arxiv.org/pdf/2505.07450, 2025-05-16
2025-11-11 00:41:30,450 - INFO - root - Fetching page 7 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=300
2025-11-11 00:41:36,838 - INFO - root - get_all_titles_from_web 
2025-11-11 00:41:36,839 - INFO - root - Page:6, Index:0, Convex Relaxation for Robust Vanishing Point Estimation in Manhattan World, https://arxiv.org/pdf/2505.04788, 2025-06-05
2025-11-11 00:41:36,839 - INFO - root - Page:6, Index:1, S3D: Sketch-Driven 3D Model Generation, https://arxiv.org/pdf/2505.04185, 2025-06-03
2025-11-11 00:41:36,839 - INFO - root - Page:6, Index:2, Generating Synthetic Data via Augmentations for Improved Facial Resemblance in DreamBooth and InstantID, https://arxiv.org/pdf/2505.03557, 2025-07-17
2025-11-11 00:41:36,840 - INFO - root - Page:6, Index:3, CAV-MAE Sync: Improving Contrastive Audio-Visual Mask Autoencoders via Fine-Grained Alignment, https://arxiv.org/pdf/2505.01237, 2025-05-21
2025-11-11 00:41:36,840 - INFO - root - Fetching page 8 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=350
2025-11-11 00:41:43,255 - INFO - root - get_all_titles_from_web 
2025-11-11 00:41:43,256 - INFO - root - Page:7, Index:0, Where's the liability in the Generative Era? Recovery-based Black-Box Detection of AI-Generated Content, https://arxiv.org/pdf/2505.01008, 2025-08-25
2025-11-11 00:41:43,256 - INFO - root - Page:7, Index:1, SpatialLLM: A Compound 3D-Informed Design towards Spatially-Intelligent Large Multimodal Models, https://arxiv.org/pdf/2505.00788, 2025-06-10
2025-11-11 00:41:43,256 - INFO - root - Page:7, Index:2, Prisma: An Open Source Toolkit for Mechanistic Interpretability in Vision and Video, https://arxiv.org/pdf/2504.19475, 2025-06-03
2025-11-11 00:41:43,256 - INFO - root - Page:7, Index:3, SSL4Eco: A Global Seasonal Dataset for Geospatial Foundation Models in Ecology, https://arxiv.org/pdf/2504.18256, 2025-10-20
2025-11-11 00:41:43,258 - INFO - root - Page:7, Index:4, Vision-Language Models Are Not Pragmatically Competent in Referring Expression Generation, https://arxiv.org/pdf/2504.16060, 2025-07-30
2025-11-11 00:41:43,258 - INFO - root - Fetching page 9 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=400
2025-11-11 00:41:49,820 - INFO - root - get_all_titles_from_web 
2025-11-11 00:41:49,821 - INFO - root - Page:8, Index:0, Leveraging Automatic CAD Annotations for Supervised Learning in 3D Scene Understanding, https://arxiv.org/pdf/2504.13580, 2025-05-16
2025-11-11 00:41:49,821 - INFO - root - Page:8, Index:1, CAP-Net: A Unified Network for 6D Pose and Size Estimation of Categorical Articulated Parts from a Single RGB-D Image, https://arxiv.org/pdf/2504.11230, 2025-06-02
2025-11-11 00:41:49,821 - INFO - root - Page:8, Index:2, Video Summarization with Large Language Models, https://arxiv.org/pdf/2504.11199, 2025-06-05
2025-11-11 00:41:49,822 - INFO - root - Page:8, Index:3, R-TPT: Improving Adversarial Robustness of Vision-Language Models through Test-Time Prompt Tuning, https://arxiv.org/pdf/2504.11195, 2025-08-27
2025-11-11 00:41:49,823 - INFO - root - Page:8, Index:4, TerraMesh: A Planetary Mosaic of Multimodal Earth Observation Data, https://arxiv.org/pdf/2504.11172, 2025-08-01
2025-11-11 00:41:49,824 - INFO - root - Page:8, Index:5, Seeing like a Cephalopod: Colour Vision with a Monochrome Event Camera, https://arxiv.org/pdf/2504.10984, 2025-06-06
2025-11-11 00:41:49,824 - INFO - root - Page:8, Index:6, Hearing Anywhere in Any Environment, https://arxiv.org/pdf/2504.10746, 2025-06-04
2025-11-11 00:41:49,824 - INFO - root - Fetching page 10 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=450
2025-11-11 00:41:56,428 - INFO - root - get_all_titles_from_web 
2025-11-11 00:41:56,430 - INFO - root - Page:9, Index:0, Correlative and Discriminative Label Grouping for Multi-Label Visual Prompt Tuning, https://arxiv.org/pdf/2504.09990, 2025-07-09
2025-11-11 00:41:56,431 - INFO - root - Page:9, Index:1, SPICE: A Synergistic, Precise, Iterative, and Customizable Image Editing Workflow, https://arxiv.org/pdf/2504.09697, 2025-10-16
2025-11-11 00:41:56,432 - INFO - root - Page:9, Index:2, Mimic In-Context Learning for Multimodal Tasks, https://arxiv.org/pdf/2504.08851, 2025-05-17
2025-11-11 00:41:56,433 - INFO - root - Page:9, Index:3, Digital Twin Catalog: A Large-Scale Photorealistic 3D Object Digital Twin Dataset, https://arxiv.org/pdf/2504.08541, 2025-05-18
2025-11-11 00:41:56,433 - INFO - root - Page:9, Index:4, MMLA: Multi-Environment, Multi-Species, Low-Altitude Drone Dataset, https://arxiv.org/pdf/2504.07744, 2025-10-22
2025-11-11 00:41:56,434 - INFO - root - Fetching page 11 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=500
2025-11-11 00:42:02,681 - INFO - root - get_all_titles_from_web 
2025-11-11 00:42:02,681 - INFO - root - Page:10, Index:0, PromptHMR: Promptable Human Mesh Recovery, https://arxiv.org/pdf/2504.06397, 2025-05-23
2025-11-11 00:42:02,681 - INFO - root - Page:10, Index:1, SCAM: A Real-World Typographic Robustness Evaluation for Multimodal Foundation Models, https://arxiv.org/pdf/2504.04893, 2025-09-26
2025-11-11 00:42:02,682 - INFO - root - Fetching page 12 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=550
2025-11-11 00:42:09,214 - INFO - root - get_all_titles_from_web 
2025-11-11 00:42:09,214 - INFO - root - Page:11, Index:0, Charm: The Missing Piece in ViT fine-tuning for Image Aesthetic Assessment, https://arxiv.org/pdf/2504.02522, 2025-05-15
2025-11-11 00:42:09,215 - INFO - root - Page:11, Index:1, T*: Re-thinking Temporal Search for Long-Form Video Understanding, https://arxiv.org/pdf/2504.02259, 2025-08-24
2025-11-11 00:42:09,216 - INFO - root - Page:11, Index:2, CoMatcher: Multi-View Collaborative Feature Matching, https://arxiv.org/pdf/2504.01872, 2025-08-20
2025-11-11 00:42:09,216 - INFO - root - Page:11, Index:3, Think Small, Act Big: Primitive Prompt Learning for Lifelong Robot Manipulation, https://arxiv.org/pdf/2504.00420, 2025-06-01
2025-11-11 00:42:09,216 - INFO - root - Fetching page 13 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=600
2025-11-11 00:42:15,708 - INFO - root - get_all_titles_from_web 
2025-11-11 00:42:15,708 - INFO - root - Page:12, Index:0, It's a (Blind) Match! Towards Vision-Language Correspondence without Parallel Data, https://arxiv.org/pdf/2503.24129, 2025-05-29
2025-11-11 00:42:15,709 - INFO - root - Page:12, Index:1, ReferDINO-Plus: 2nd Solution for 4th PVUW MeViS Challenge at CVPR 2025, https://arxiv.org/pdf/2503.23509, 2025-05-29
2025-11-11 00:42:15,709 - INFO - root - Page:12, Index:2, A Unified Image-Dense Annotation Generation Model for Underwater Scenes, https://arxiv.org/pdf/2503.21771, 2025-07-27
2025-11-11 00:42:15,709 - INFO - root - Fetching page 14 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=650
2025-11-11 00:42:21,984 - INFO - root - get_all_titles_from_web 
2025-11-11 00:42:21,985 - INFO - root - Page:13, Index:0, Learning Class Prototypes for Unified Sparse Supervised 3D Object Detection, https://arxiv.org/pdf/2503.21099, 2025-06-13
2025-11-11 00:42:21,985 - INFO - root - Page:13, Index:1, LATTE-MV: Learning to Anticipate Table Tennis Hits from Monocular Videos, https://arxiv.org/pdf/2503.20936, 2025-09-01
2025-11-11 00:42:21,985 - INFO - root - Page:13, Index:2, BizGen: Advancing Article-level Visual Text Rendering for Infographics Generation, https://arxiv.org/pdf/2503.20672, 2025-07-02
2025-11-11 00:42:21,985 - INFO - root - Page:13, Index:3, ITA-MDT: Image-Timestep-Adaptive Masked Diffusion Transformer Framework for Image-Based Virtual Try-On, https://arxiv.org/pdf/2503.20418, 2025-06-01
2025-11-11 00:42:21,986 - INFO - root - Page:13, Index:4, Faster Parameter-Efficient Tuning with Token Redundancy Reduction, https://arxiv.org/pdf/2503.20282, 2025-08-26
2025-11-11 00:42:21,987 - INFO - root - Page:13, Index:5, DINeMo: Learning Neural Mesh Models with no 3D Annotations, https://arxiv.org/pdf/2503.20220, 2025-06-09
2025-11-11 00:42:21,987 - INFO - root - Page:13, Index:6, Scaling Vision Pre-Training to 4K Resolution, https://arxiv.org/pdf/2503.19903, 2025-08-03
2025-11-11 00:42:21,987 - INFO - root - Page:13, Index:7, GENIUS: A Generative Framework for Universal Multimodal Search, https://arxiv.org/pdf/2503.19868, 2025-06-05
2025-11-11 00:42:21,987 - INFO - root - Fetching page 15 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=700
2025-11-11 00:42:28,685 - INFO - root - get_all_titles_from_web 
2025-11-11 00:42:28,686 - INFO - root - Page:14, Index:0, Galaxy Walker: Geometry-aware VLMs For Galaxy-scale Understanding, https://arxiv.org/pdf/2503.18578, 2025-05-25
2025-11-11 00:42:28,686 - INFO - root - Page:14, Index:1, LookCloser: Frequency-aware Radiance Field for Tiny-Detail Scene, https://arxiv.org/pdf/2503.18513, 2025-07-29
2025-11-11 00:42:28,686 - INFO - root - Fetching page 16 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=750
2025-11-11 00:42:35,624 - INFO - root - get_all_titles_from_web 
2025-11-11 00:42:35,624 - INFO - root - Page:15, Index:0, LoTUS: Large-Scale Machine Unlearning with a Taste of Uncertainty, https://arxiv.org/pdf/2503.18314, 2025-05-29
2025-11-11 00:42:35,625 - INFO - root - Page:15, Index:1, MammAlps: A multi-view video behavior monitoring dataset of wild mammals in the Swiss Alps, https://arxiv.org/pdf/2503.18223, 2025-06-04
2025-11-11 00:42:35,625 - INFO - root - Page:15, Index:2, Progressive Prompt Detailing for Improved Alignment in Text-to-Image Generative Models, https://arxiv.org/pdf/2503.17794, 2025-05-30
2025-11-11 00:42:35,625 - INFO - root - Page:15, Index:3, CountLLM: Towards Generalizable Repetitive Action Counting via Large Language Model, https://arxiv.org/pdf/2503.17690, 2025-06-29
2025-11-11 00:42:35,625 - INFO - root - Page:15, Index:4, TaoAvatar: Real-Time Lifelike Full-Body Talking Avatars for Augmented Reality via 3D Gaussian Splatting, https://arxiv.org/pdf/2503.17032, 2025-07-23
2025-11-11 00:42:35,626 - INFO - root - Page:15, Index:5, Generalized Few-shot 3D Point Cloud Segmentation with Vision-Language Model, https://arxiv.org/pdf/2503.16282, 2025-05-20
2025-11-11 00:42:35,626 - INFO - root - Fetching page 17 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=800
2025-11-11 00:42:43,013 - INFO - root - get_all_titles_from_web 
2025-11-11 00:42:43,013 - INFO - root - Page:16, Index:0, High Temporal Consistency through Semantic Similarity Propagation in Semi-Supervised Video Semantic Segmentation for Autonomous Flight, https://arxiv.org/pdf/2503.15676, 2025-06-26
2025-11-11 00:42:43,014 - INFO - root - Page:16, Index:1, DPFlow: Adaptive Optical Flow Estimation with a Dual-Pyramid Framework, https://arxiv.org/pdf/2503.14880, 2025-09-29
2025-11-11 00:42:43,014 - INFO - root - Fetching page 18 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=850
2025-11-11 00:42:49,802 - INFO - root - get_all_titles_from_web 
2025-11-11 00:42:49,803 - INFO - root - Page:17, Index:0, From Head to Tail: Towards Balanced Representation in Large Vision-Language Models through Adaptive Data Calibration, https://arxiv.org/pdf/2503.12821, 2025-05-29
2025-11-11 00:42:49,803 - INFO - root - Page:17, Index:1, MambaIC: State Space Models for High-Performance Learned Image Compression, https://arxiv.org/pdf/2503.12461, 2025-08-22
2025-11-11 00:42:49,804 - INFO - root - Page:17, Index:2, Localized Concept Erasure for Text-to-Image Diffusion Models Using Training-Free Gated Low-Rank Adaptation, https://arxiv.org/pdf/2503.12356, 2025-07-09
2025-11-11 00:42:49,804 - INFO - root - Page:17, Index:3, TASTE-Rob: Advancing Video Generation of Task-Oriented Hand-Object Interaction for Generalizable Robotic Manipulation, https://arxiv.org/pdf/2503.11423, 2025-06-05
2025-11-11 00:42:49,804 - INFO - root - Page:17, Index:4, Panopticon: Advancing Any-Sensor Foundation Models for Earth Observation, https://arxiv.org/pdf/2503.10845, 2025-08-01
2025-11-11 00:42:49,804 - INFO - root - Page:17, Index:5, Transformers without Normalization, https://arxiv.org/pdf/2503.10622, 2025-06-14
2025-11-11 00:42:49,805 - INFO - root - Page:17, Index:6, dFLMoE: Decentralized Federated Learning via Mixture of Experts for Medical Data Analysis, https://arxiv.org/pdf/2503.10412, 2025-05-19
2025-11-11 00:42:49,805 - INFO - root - Fetching page 19 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=900
2025-11-11 00:42:57,013 - INFO - root - get_all_titles_from_web 
2025-11-11 00:42:57,014 - INFO - root - Page:18, Index:0, Project-Probe-Aggregate: Efficient Fine-Tuning for Group Robustness, https://arxiv.org/pdf/2503.09487, 2025-08-26
2025-11-11 00:42:57,014 - INFO - root - Page:18, Index:1, VLog: Video-Language Models by Generative Retrieval of Narration Vocabulary, https://arxiv.org/pdf/2503.09402, 2025-06-09
2025-11-11 00:42:57,014 - INFO - root - Fetching page 20 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=950
2025-11-11 00:43:03,218 - INFO - root - get_all_titles_from_web 
2025-11-11 00:43:03,219 - INFO - root - Page:19, Index:0, Escaping Plato's Cave: Towards the Alignment of 3D and Text Latent Spaces, https://arxiv.org/pdf/2503.05283, 2025-06-04
2025-11-11 00:43:03,219 - INFO - root - Page:19, Index:1, FluidNexus: 3D Fluid Reconstruction and Prediction from a Single Video, https://arxiv.org/pdf/2503.04720, 2025-07-09
2025-11-11 00:43:03,219 - INFO - root - Page:19, Index:2, Question-Aware Gaussian Experts for Audio-Visual Question Answering, https://arxiv.org/pdf/2503.04459, 2025-06-11
2025-11-11 00:43:03,219 - INFO - root - Page:19, Index:3, Q-Eval-100K: Evaluating Visual Quality and Alignment Level for Text-to-Vision Content, https://arxiv.org/pdf/2503.02357, 2025-06-15
2025-11-11 00:43:03,220 - INFO - root - Fetching page 21 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=1000
2025-11-11 00:43:09,628 - INFO - root - get_all_titles_from_web 
2025-11-11 00:43:09,628 - INFO - root - Page:20, Index:0, Data Distributional Properties As Inductive Bias for Systematic Generalization, https://arxiv.org/pdf/2502.20499, 2025-06-17
2025-11-11 00:43:09,629 - INFO - root - Page:20, Index:1, Knowledge Bridger: Towards Training-free Missing Modality Completion, https://arxiv.org/pdf/2502.19834, 2025-06-17
2025-11-11 00:43:09,629 - INFO - root - Fetching page 22 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=1050
2025-11-11 00:43:16,773 - INFO - root - get_all_titles_from_web 
2025-11-11 00:43:16,773 - INFO - root - Page:21, Index:0, MALT Diffusion: Memory-Augmented Latent Transformers for Any-Length Video Generation, https://arxiv.org/pdf/2502.12632, 2025-07-08
2025-11-11 00:43:16,774 - INFO - root - Page:21, Index:1, ILIAS: Instance-Level Image retrieval At Scale, https://arxiv.org/pdf/2502.11748, 2025-06-23
2025-11-11 00:43:16,774 - INFO - root - Page:21, Index:2, Distraction is All You Need for Multimodal Large Language Model Jailbreaking, https://arxiv.org/pdf/2502.10794, 2025-06-16
2025-11-11 00:43:16,774 - INFO - root - Page:21, Index:3, Spatial457: A Diagnostic Benchmark for 6D Spatial Reasoning of Large Multimodal Models, https://arxiv.org/pdf/2502.08636, 2025-06-08
2025-11-11 00:43:16,774 - INFO - root - Page:21, Index:4, TRAVEL: Training-Free Retrieval and Alignment for Vision-and-Language Navigation, https://arxiv.org/pdf/2502.07306, 2025-06-09
2025-11-11 00:43:16,775 - INFO - root - Page:21, Index:5, DiTASK: Multi-Task Fine-Tuning with Diffeomorphic Transformations, https://arxiv.org/pdf/2502.06029, 2025-06-01
2025-11-11 00:43:16,775 - INFO - root - Page:21, Index:6, ConceptAttention: Diffusion Transformers Learn Highly Interpretable Features, https://arxiv.org/pdf/2502.04320, 2025-07-01
2025-11-11 00:43:16,776 - INFO - root - Page:21, Index:7, GCE-Pose: Global Context Enhancement for Category-level Object Pose Estimation, https://arxiv.org/pdf/2502.04293, 2025-06-24
2025-11-11 00:43:16,776 - INFO - root - Page:21, Index:8, Calibrated Multi-Preference Optimization for Aligning Diffusion Models, https://arxiv.org/pdf/2502.02588, 2025-09-26
2025-11-11 00:43:16,777 - INFO - root - Page:21, Index:9, Instruct-4DGS: Efficient Dynamic Scene Editing via 4D Gaussian-based Static-Dynamic Separation, https://arxiv.org/pdf/2502.02091, 2025-07-01
2025-11-11 00:43:16,777 - INFO - root - Page:21, Index:10, Low-Resource Video Super-Resolution using Memory, Wavelets, and Deformable Convolutions, https://arxiv.org/pdf/2502.01816, 2025-06-19
2025-11-11 00:43:16,778 - INFO - root - Page:21, Index:11, Bridging Text and Crystal Structures: Literature-driven Contrastive Learning for Materials Science, https://arxiv.org/pdf/2501.12919, 2025-06-18
2025-11-11 00:43:16,778 - INFO - root - Page:21, Index:12, T2ISafety: Benchmark for Assessing Fairness, Toxicity, and Privacy in Image Generation, https://arxiv.org/pdf/2501.12612, 2025-07-25
2025-11-11 00:43:16,780 - INFO - root - Page:21, Index:13, Fine-Grained Image-Text Correspondence with Cost Aggregation for Open-Vocabulary Part Segmentation, https://arxiv.org/pdf/2501.09688, 2025-08-08
2025-11-11 00:43:16,780 - INFO - root - Fetching page 23 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=1100
2025-11-11 00:43:23,053 - INFO - root - get_all_titles_from_web 
2025-11-11 00:43:23,054 - INFO - root - Page:22, Index:0, Bias for Action: Video Implicit Neural Representations with Bias Modulation, https://arxiv.org/pdf/2501.09277, 2025-06-06
2025-11-11 00:43:23,054 - INFO - root - Page:22, Index:1, MonSter++: Unified Stereo Matching, Multi-view Stereo, and Real-time Stereo with Monodepth Priors, https://arxiv.org/pdf/2501.08643, 2025-09-25
2025-11-11 00:43:23,054 - INFO - root - Page:22, Index:2, Go-with-the-Flow: Motion-Controllable Video Diffusion Models Using Real-Time Warped Noise, https://arxiv.org/pdf/2501.08331, 2025-08-06
2025-11-11 00:43:23,054 - INFO - root - Page:22, Index:3, Nonisotropic Gaussian Diffusion for Realistic 3D Human Motion Prediction, https://arxiv.org/pdf/2501.06035, 2025-07-08
2025-11-11 00:43:23,055 - INFO - root - Page:22, Index:4, Discovering Hidden Visual Concepts Beyond Linguistic Input in Infant Learning, https://arxiv.org/pdf/2501.05205, 2025-06-13
2025-11-11 00:43:23,055 - INFO - root - Page:22, Index:5, PERSE: Personalized 3D Generative Avatars from A Single Portrait, https://arxiv.org/pdf/2412.21206, 2025-09-28
2025-11-11 00:43:23,055 - INFO - root - Page:22, Index:6, MaskGaussian: Adaptive 3D Gaussian Representation from Probabilistic Masks, https://arxiv.org/pdf/2412.20522, 2025-06-14
2025-11-11 00:43:23,056 - INFO - root - Page:22, Index:7, SimLTD: Simple Supervised and Semi-Supervised Long-Tailed Object Detection, https://arxiv.org/pdf/2412.20047, 2025-06-09
2025-11-11 00:43:23,056 - INFO - root - Page:22, Index:8, Conditional Balance: Improving Multi-Conditioning Trade-Offs in Image Generation, https://arxiv.org/pdf/2412.19853, 2025-08-03
2025-11-11 00:43:23,056 - INFO - root - Fetching page 24 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=1150
2025-11-11 00:43:29,695 - INFO - root - get_all_titles_from_web 
2025-11-11 00:43:29,696 - INFO - root - Page:23, Index:0, CoCoGaussian: Leveraging Circle of Confusion for Gaussian Splatting from Defocused Images, https://arxiv.org/pdf/2412.16028, 2025-05-15
2025-11-11 00:43:29,696 - INFO - root - Page:23, Index:1, EnergyMoGen: Compositional Human Motion Generation with Energy-Based Diffusion Model in Latent Space, https://arxiv.org/pdf/2412.14706, 2025-06-04
2025-11-11 00:43:29,696 - INFO - root - Page:23, Index:2, DarkIR: Robust Low-Light Image Restoration, https://arxiv.org/pdf/2412.13443, 2025-10-14
2025-11-11 00:43:29,697 - INFO - root - Page:23, Index:3, FastVLM: Efficient Vision Encoding for Vision Language Models, https://arxiv.org/pdf/2412.13303, 2025-05-15
2025-11-11 00:43:29,697 - INFO - root - Page:23, Index:4, Real-time Free-view Human Rendering from Sparse-view RGB Videos using Double Unprojected Textures, https://arxiv.org/pdf/2412.13183, 2025-06-20
2025-11-11 00:43:29,697 - INFO - root - Page:23, Index:5, CondiMen: Conditional Multi-Person Mesh Recovery, https://arxiv.org/pdf/2412.13058, 2025-06-04
2025-11-11 00:43:29,697 - INFO - root - Page:23, Index:6, MASt3R-SLAM: Real-Time Dense SLAM with 3D Reconstruction Priors, https://arxiv.org/pdf/2412.12392, 2025-06-02
2025-11-11 00:43:29,697 - INFO - root - Page:23, Index:7, DynamicScaler: Seamless and Scalable Video Generation for Panoramic Scenes, https://arxiv.org/pdf/2412.11100, 2025-10-04
2025-11-11 00:43:29,697 - INFO - root - Page:23, Index:8, SnapGen-V: Generating a Five-Second Video within Five Seconds on a Mobile Device, https://arxiv.org/pdf/2412.10494, 2025-06-09
2025-11-11 00:43:29,698 - INFO - root - Page:23, Index:9, Mr. DETR++: Instructive Multi-Route Training for Detection Transformers with Mixture-of-Experts, https://arxiv.org/pdf/2412.10028, 2025-06-26
2025-11-11 00:43:29,698 - INFO - root - Page:23, Index:10, LinGen: Towards High-Resolution Minute-Length Text-to-Video Generation with Linear Computational Complexity, https://arxiv.org/pdf/2412.09856, 2025-05-24
2025-11-11 00:43:29,698 - INFO - root - Page:23, Index:11, Gaze-LLE: Gaze Target Estimation via Large-Scale Learned Encoders, https://arxiv.org/pdf/2412.09586, 2025-06-03
2025-11-11 00:43:29,698 - INFO - root - Fetching page 25 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=1200
2025-11-11 00:43:36,519 - INFO - root - get_all_titles_from_web 
2025-11-11 00:43:36,519 - INFO - root - Page:24, Index:0, From Slow Bidirectional to Fast Autoregressive Video Diffusion Models, https://arxiv.org/pdf/2412.07772, 2025-09-23
2025-11-11 00:43:36,520 - INFO - root - Page:24, Index:1, Rate-In: Information-Driven Adaptive Dropout Rates for Improved Inference-Time Uncertainty Estimation, https://arxiv.org/pdf/2412.07169, 2025-06-03
2025-11-11 00:43:36,520 - INFO - root - Page:24, Index:2, FIRE: Robust Detection of Diffusion-Generated Images via Frequency-Guided Reconstruction Error, https://arxiv.org/pdf/2412.07140, 2025-11-03
2025-11-11 00:43:36,520 - INFO - root - Page:24, Index:3, Birth and Death of a Rose, https://arxiv.org/pdf/2412.05278, 2025-06-05
2025-11-11 00:43:36,520 - INFO - root - Page:24, Index:4, DualPM: Dual Posed-Canonical Point Maps for 3D Shape and Pose Reconstruction, https://arxiv.org/pdf/2412.04464, 2025-08-14
2025-11-11 00:43:36,521 - INFO - root - Page:24, Index:5, SeeGround: See and Ground for Zero-Shot Open-Vocabulary 3D Visual Grounding, https://arxiv.org/pdf/2412.04383, 2025-05-29
2025-11-11 00:43:36,521 - INFO - root - ------------------------------------------------------------------------------------------------------------------------
2025-11-11 00:43:36,526 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\CVPR 2025\Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness.pdf
2025-11-11 00:43:36,548 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\CVPR 2025\OmniTrack++_ Omnidirectional Multi-Object Tracking by Learning Large-FoV Traject.pdf
2025-11-11 00:43:36,550 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\CVPR 2025\NeuCo-Bench_ A Novel Benchmark Framework for Neural Embeddings in Earth Observat.pdf
2025-11-11 00:43:36,551 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\CVPR 2025\NTIRE 2025 Challenge on Low Light Image Enhancement_ Methods and Results.pdf
2025-11-11 00:43:36,551 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\CVPR 2025\Class Prototypes based Contrastive Learning for Classifying Multi-Label and Fine.pdf
2025-11-11 00:43:36,553 - INFO - root - 跳过已处理论文 Learning to Seek Evidence: A Verifiable Reasoning Agent with Causal Faithfulness Analysis：d:\ChatPaper\academic Papers\CVPR 2025\Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness.pdf
2025-11-11 00:43:36,553 - INFO - root - 跳过已处理论文 OmniTrack++: Omnidirectional Multi-Object Tracking by Learning Large-FoV Trajectory Feedback：d:\ChatPaper\academic Papers\CVPR 2025\OmniTrack++_ Omnidirectional Multi-Object Tracking by Learning Large-FoV Traject.pdf
2025-11-11 00:43:36,555 - INFO - root - 正在总结论文 3/5: NeuCo-Bench: A Novel Benchmark Framework for Neural Embeddings in Earth Observation
2025-11-11 00:44:19,194 - INFO - root - LLMClient: rate limit reached, sleeping 17.4s
2025-11-11 00:44:59,217 - INFO - root - 正在提取论文图片...
2025-11-11 00:45:01,118 - INFO - root - 已保存图片 1/10：./export\CVPR\images\figure_1_page30.png
2025-11-11 00:45:01,252 - INFO - root - 已保存图片 2/10：./export\CVPR\images\figure_2_page33.png
2025-11-11 00:45:01,373 - INFO - root - 已保存图片 3/10：./export\CVPR\images\figure_3_page33.png
2025-11-11 00:45:01,469 - INFO - root - 已保存图片 4/10：./export\CVPR\images\figure_4_page30.jpeg
2025-11-11 00:45:01,580 - INFO - root - 已保存图片 5/10：./export\CVPR\images\figure_5_page24.png
2025-11-11 00:45:01,654 - INFO - root - 已保存图片 6/10：./export\CVPR\images\figure_6_page34.png
2025-11-11 00:45:01,720 - INFO - root - 已保存图片 7/10：./export\CVPR\images\figure_7_page32.png
2025-11-11 00:45:01,753 - INFO - root - 已保存图片 8/10：./export\CVPR\images\figure_8_page29.jpeg
2025-11-11 00:45:01,788 - INFO - root - 已保存图片 9/10：./export\CVPR\images\figure_9_page29.jpeg
2025-11-11 00:45:01,819 - INFO - root - 已保存图片 10/10：./export\CVPR\images\figure_10_page29.jpeg
2025-11-11 00:45:01,835 - INFO - root - 成功添加图片 1：./export\CVPR\images\figure_1_page30.png
2025-11-11 00:45:01,835 - INFO - root - 成功添加图片 2：./export\CVPR\images\figure_2_page33.png
2025-11-11 00:45:01,836 - INFO - root - 成功添加图片 3：./export\CVPR\images\figure_3_page33.png
2025-11-11 00:45:01,836 - INFO - root - 成功添加图片 4：./export\CVPR\images\figure_4_page30.jpeg
2025-11-11 00:45:01,837 - INFO - root - 成功添加图片 5：./export\CVPR\images\figure_5_page24.png
2025-11-11 00:45:01,837 - INFO - root - 成功添加图片 6：./export\CVPR\images\figure_6_page34.png
2025-11-11 00:45:01,839 - INFO - root - 成功添加图片 7：./export\CVPR\images\figure_7_page32.png
2025-11-11 00:45:01,839 - INFO - root - 成功添加图片 8：./export\CVPR\images\figure_8_page29.jpeg
2025-11-11 00:45:01,839 - INFO - root - 成功添加图片 9：./export\CVPR\images\figure_9_page29.jpeg
2025-11-11 00:45:01,840 - INFO - root - 成功添加图片 10：./export\CVPR\images\figure_10_page29.jpeg
2025-11-11 00:45:01,843 - INFO - root - 论文《NeuCo-Bench: A Novel Benchmark Framework for Neural Embeddings in Earth Observation》的分析已保存到 ./export\CVPR\NeuCo-Bench_ A Novel Benchmark Framework for Neural Embeddings in Earth Observat.md
2025-11-11 00:45:01,847 - INFO - root - 正在总结论文 4/5: NTIRE 2025 Challenge on Low Light Image Enhancement: Methods and Results
2025-11-11 00:51:35,083 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-11 00:51:35,085 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-11 00:51:35,088 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-11 00:51:36,445 - INFO - root - LLMClientManager: 指定使用客户端: Gemini
2025-11-11 00:51:37,869 - INFO - root - GeminiClient: trying model models/gemini-2.5-flash
2025-11-11 00:51:45,253 - INFO - root - GeminiClient: initialized model gemini-2.5-flash
2025-11-11 00:51:45,394 - INFO - root - LLMClientManager: Gemini 客户端初始化成功
2025-11-11 00:51:45,475 - INFO - root - LLMClientManager: switched to Gemini client
2025-11-11 00:51:45,489 - INFO - root - 已手动切换到 LLM 客户端: Gemini
2025-11-11 00:51:45,493 - INFO - root - 使用 LLM 模型: gemini-2.5-flash
2025-11-11 00:51:45,504 - INFO - root - 可用客户端: ['Gemini']
2025-11-11 00:51:45,505 - INFO - root - === 运行配置 ===
2025-11-11 00:51:45,506 - INFO - root - 处理模式: arxiv在线搜索
2025-11-11 00:51:45,507 - INFO - root - 关键词: CVPR
2025-11-11 00:51:45,508 - INFO - root - 查询: CVPR 2025
2025-11-11 00:51:45,508 - INFO - root - 排序: None
2025-11-11 00:51:45,512 - INFO - root - 最近天数: 180
2025-11-11 00:51:45,513 - INFO - root - 最大处理数量: 5
2025-11-11 00:51:45,513 - INFO - root - 保存图片: 是
2025-11-11 00:51:45,514 - INFO - root - 输出语言: 中文
2025-11-11 00:51:45,522 - INFO - root - 强制重新处理: 否
2025-11-11 00:51:45,523 - INFO - root - ====================
2025-11-11 00:51:45,524 - INFO - root - 使用 arXiv 搜索模式（通过 chat_arxiv 模块获取）
2025-11-11 00:51:45,525 - INFO - root - Fetching page 1 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50
2025-11-11 00:51:55,470 - INFO - root - get_all_titles_from_web 
2025-11-11 00:51:55,470 - INFO - root - Page:0, Index:0, Learning to Seek Evidence: A Verifiable Reasoning Agent with Causal Faithfulness Analysis, https://arxiv.org/pdf/2511.01425, 2025-11-03
2025-11-11 00:51:55,472 - INFO - root - Page:0, Index:1, OmniTrack++: Omnidirectional Multi-Object Tracking by Learning Large-FoV Trajectory Feedback, https://arxiv.org/pdf/2511.00510, 2025-11-01
2025-11-11 00:51:55,472 - INFO - root - Page:0, Index:2, NeuCo-Bench: A Novel Benchmark Framework for Neural Embeddings in Earth Observation, https://arxiv.org/pdf/2510.17914, 2025-10-19
2025-11-11 00:51:55,472 - INFO - root - Page:0, Index:3, NTIRE 2025 Challenge on Low Light Image Enhancement: Methods and Results, https://arxiv.org/pdf/2510.13670, 2025-10-15
2025-11-11 00:51:55,472 - INFO - root - Page:0, Index:4, Class Prototypes based Contrastive Learning for Classifying Multi-Label and Fine-Grained Educational Videos, https://arxiv.org/pdf/2510.11204, 2025-10-13
2025-11-11 00:51:55,473 - INFO - root - Page:0, Index:5, MIMO: A medical vision language model with visual referring multimodal input and pixel grounding multimodal output, https://arxiv.org/pdf/2510.10011, 2025-10-11
2025-11-11 00:51:55,473 - INFO - root - Page:0, Index:6, Vision Language Models: A Survey of 26K Papers, https://arxiv.org/pdf/2510.09586, 2025-10-10
2025-11-11 00:51:55,473 - INFO - root - Page:0, Index:7, DiT-VTON: Diffusion Transformer Framework for Unified Multi-Category Virtual Try-On and Virtual Try-All with Integrated Image Editing, https://arxiv.org/pdf/2510.04797, 2025-10-03
2025-11-11 00:51:55,473 - INFO - root - Page:0, Index:8, PatchVSR: Breaking Video Diffusion Resolution Limits with Patch-wise Video Super-Resolution, https://arxiv.org/pdf/2509.26025, 2025-09-30
2025-11-11 00:51:55,474 - INFO - root - Page:0, Index:9, FreqDebias: Towards Generalizable Deepfake Detection via Consistency-Driven Frequency Debiasing, https://arxiv.org/pdf/2509.22412, 2025-09-26
2025-11-11 00:51:55,474 - INFO - root - Page:0, Index:10, A Mutual Learning Method for Salient Object Detection with intertwined Multi-Supervision--Revised, https://arxiv.org/pdf/2509.21363, 2025-09-21
2025-11-11 00:51:55,476 - INFO - root - Page:0, Index:11, InstructVTON: Optimal Auto-Masking and Natural-Language-Guided Interactive Style Control for Inpainting-Based Virtual Try-On, https://arxiv.org/pdf/2509.20524, 2025-09-24
2025-11-11 00:51:55,482 - INFO - root - Page:0, Index:12, Efficient Encoder-Free Pose Conditioning and Pose Control for Virtual Try-On, https://arxiv.org/pdf/2509.20343, 2025-09-24
2025-11-11 00:51:55,484 - INFO - root - Page:0, Index:13, The Photographer Eye: Teaching Multimodal Large Language Models to Understand Image Aesthetics like Photographers, https://arxiv.org/pdf/2509.18582, 2025-10-22
2025-11-11 00:51:55,484 - INFO - root - Page:0, Index:14, ENSAM: an efficient foundation model for interactive segmentation of 3D medical images, https://arxiv.org/pdf/2509.15874, 2025-09-19
2025-11-11 00:51:55,485 - INFO - root - Page:0, Index:15, DEFT-VTON: Efficient Virtual Try-On with Consistent Generalised H-Transform, https://arxiv.org/pdf/2509.13506, 2025-09-16
2025-11-11 00:51:55,486 - INFO - root - Page:0, Index:16, Weakly and Self-Supervised Class-Agnostic Motion Prediction for Autonomous Driving, https://arxiv.org/pdf/2509.13116, 2025-09-16
2025-11-11 00:51:55,486 - INFO - root - Page:0, Index:17, Domain-Adaptive Pretraining Improves Primate Behavior Recognition, https://arxiv.org/pdf/2509.12193, 2025-09-15
2025-11-11 00:51:55,486 - INFO - root - Page:0, Index:18, The System Description of CPS Team for Track on Driving with Language of CVPR 2024 Autonomous Grand Challenge, https://arxiv.org/pdf/2509.11071, 2025-09-13
2025-11-11 00:51:55,487 - INFO - root - Page:0, Index:19, An HMM-based framework for identity-aware long-term multi-object tracking from sparse and uncertain identification: use case on long-term tracking in livestock, https://arxiv.org/pdf/2509.09962, 2025-09-12
2025-11-11 00:51:55,490 - INFO - root - Page:0, Index:20, InterAct: Advancing Large-Scale Versatile 3D Human-Object Interaction Generation, https://arxiv.org/pdf/2509.09555, 2025-09-11
2025-11-11 00:51:55,491 - INFO - root - Page:0, Index:21, Geospatial Foundational Embedder: Top-1 Winning Solution on EarthVision Embed2Scale Challenge (CVPR 2025), https://arxiv.org/pdf/2509.06993, 2025-09-03
2025-11-11 00:51:55,493 - INFO - root - Page:0, Index:22, 2nd Place Solution for CVPR2024 E2E Challenge: End-to-End Autonomous Driving Using Vision Language Model, https://arxiv.org/pdf/2509.02659, 2025-09-02
2025-11-11 00:51:55,496 - INFO - root - Page:0, Index:23, Unsupervised Training of Vision Transformers with Synthetic Negatives, https://arxiv.org/pdf/2509.02024, 2025-09-02
2025-11-11 00:51:55,498 - INFO - root - Page:0, Index:24, MV-SSM: Multi-View State Space Modeling for 3D Human Pose Estimation, https://arxiv.org/pdf/2509.00649, 2025-08-30
2025-11-11 00:51:55,500 - INFO - root - Page:0, Index:25, CryptoFace: End-to-End Encrypted Face Recognition, https://arxiv.org/pdf/2509.00332, 2025-08-29
2025-11-11 00:51:55,501 - INFO - root - Page:0, Index:26, ControlEchoSynth: Boosting Ejection Fraction Estimation Models via Controlled Video Diffusion, https://arxiv.org/pdf/2508.17631, 2025-08-26
2025-11-11 00:51:55,502 - INFO - root - Page:0, Index:27, Explain Before You Answer: A Survey on Compositional Visual Reasoning, https://arxiv.org/pdf/2508.17298, 2025-08-27
2025-11-11 00:51:55,503 - INFO - root - Page:0, Index:28, Investigating Different Geo Priors for Image Classification, https://arxiv.org/pdf/2508.15946, 2025-08-21
2025-11-11 00:51:55,505 - INFO - root - Page:0, Index:29, Towards Source-Free Machine Unlearning, https://arxiv.org/pdf/2508.15127, 2025-08-20
2025-11-11 00:51:55,505 - INFO - root - Page:0, Index:30, MR6D: Benchmarking 6D Pose Estimation for Mobile Robots, https://arxiv.org/pdf/2508.13775, 2025-08-19
2025-11-11 00:51:55,509 - INFO - root - Page:0, Index:31, Calibrating Biased Distribution in VFM-derived Latent Space via Cross-Domain Geometric Consistency, https://arxiv.org/pdf/2508.13518, 2025-08-19
2025-11-11 00:51:55,523 - INFO - root - Page:0, Index:32, SIS-Challenge: Event-based Spatio-temporal Instance Segmentation Challenge at the CVPR 2025 Event-based Vision Workshop, https://arxiv.org/pdf/2508.12813, 2025-08-18
2025-11-11 00:51:55,525 - INFO - root - Page:0, Index:33, Multi-Level Knowledge Distillation and Dynamic Self-Supervised Learning for Continual Learning, https://arxiv.org/pdf/2508.12692, 2025-08-22
2025-11-11 00:51:55,526 - INFO - root - Page:0, Index:34, Stochastic-based Patch Filtering for Few-Shot Learning, https://arxiv.org/pdf/2508.10066, 2025-08-13
2025-11-11 00:51:55,528 - INFO - root - Page:0, Index:35, Slot Attention-based Feature Filtering for Few-Shot Learning, https://arxiv.org/pdf/2508.09699, 2025-08-13
2025-11-11 00:51:55,534 - INFO - root - Page:0, Index:36, Comparison Reveals Commonality: Customized Image Generation through Contrastive Inversion, https://arxiv.org/pdf/2508.07755, 2025-08-11
2025-11-11 00:51:55,535 - INFO - root - Page:0, Index:37, SLRTP2025 Sign Language Production Challenge: Methodology, Results, and Future Work, https://arxiv.org/pdf/2508.06951, 2025-08-09
2025-11-11 00:51:55,535 - INFO - root - Page:0, Index:38, Exploring Fairness across Fine-Grained Attributes in Large Vision-Language Models, https://arxiv.org/pdf/2508.03079, 2025-08-05
2025-11-11 00:51:55,535 - INFO - root - Page:0, Index:39, Devil is in the Detail: Towards Injecting Fine Details of Image Prompt in Image Generation via Conflict-free Guidance and Stratified Attention, https://arxiv.org/pdf/2508.02004, 2025-08-03
2025-11-11 00:51:55,538 - INFO - root - Page:0, Index:40, IAUNet: Instance-Aware U-Net, https://arxiv.org/pdf/2508.01928, 2025-08-03
2025-11-11 00:51:55,540 - INFO - root - Page:0, Index:41, Gaussian Splatting Feature Fields for Privacy-Preserving Visual Localization, https://arxiv.org/pdf/2507.23569, 2025-08-26
2025-11-11 00:51:55,540 - INFO - root - Page:0, Index:42, From Scan to Action: Leveraging Realistic Scans for Embodied Scene Understanding, https://arxiv.org/pdf/2507.17585, 2025-07-23
2025-11-11 00:51:55,543 - INFO - root - Page:0, Index:43, LEAD: Exploring Logit Space Evolution for Model Selection, https://arxiv.org/pdf/2507.14559, 2025-07-19
2025-11-11 00:51:55,545 - INFO - root - Page:0, Index:44, HeCoFuse: Cross-Modal Complementary V2X Cooperative Perception with Heterogeneous Sensors, https://arxiv.org/pdf/2507.13677, 2025-07-18
2025-11-11 00:51:55,554 - INFO - root - Page:0, Index:45, OmniVec2 -- A Novel Transformer based Network for Large Scale Multimodal and Multitask Learning, https://arxiv.org/pdf/2507.13364, 2025-07-06
2025-11-11 00:51:55,563 - INFO - root - Page:0, Index:46, A Training-Free, Task-Agnostic Framework for Enhancing MLLM Performance on High-Resolution Images, https://arxiv.org/pdf/2507.10202, 2025-07-14
2025-11-11 00:51:55,569 - INFO - root - Page:0, Index:47, Quantum Federated Learning for Multimodal Data: A Modality-Agnostic Approach, https://arxiv.org/pdf/2507.08217, 2025-07-10
2025-11-11 00:51:55,572 - INFO - root - Page:0, Index:48, CuriosAI Submission to the EgoExo4D Proficiency Estimation Challenge 2025, https://arxiv.org/pdf/2507.08022, 2025-07-08
2025-11-11 00:51:55,573 - INFO - root - Page:0, Index:49, Rethinking Query-based Transformer for Continual Image Segmentation, https://arxiv.org/pdf/2507.07831, 2025-07-10
2025-11-11 00:51:55,580 - INFO - root - Fetching page 2 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=50
2025-11-11 00:52:02,095 - INFO - root - get_all_titles_from_web 
2025-11-11 00:52:02,095 - INFO - root - Page:1, Index:0, Scalable and Realistic Virtual Try-on Application for Foundation Makeup with Kubelka-Munk Theory, https://arxiv.org/pdf/2507.07333, 2025-07-09
2025-11-11 00:52:02,096 - INFO - root - Page:1, Index:1, Free on the Fly: Enhancing Flexibility in Test-Time Adaptation with Online EM, https://arxiv.org/pdf/2507.06973, 2025-07-09
2025-11-11 00:52:02,096 - INFO - root - Page:1, Index:2, Adaptive Part Learning for Fine-Grained Generalized Category Discovery: A Plug-and-Play Enhancement, https://arxiv.org/pdf/2507.06928, 2025-07-09
2025-11-11 00:52:02,096 - INFO - root - Page:1, Index:3, Grounded Gesture Generation: Language, Motion, and Space, https://arxiv.org/pdf/2507.04522, 2025-07-06
2025-11-11 00:52:02,096 - INFO - root - Page:1, Index:4, Comprehensive Information Bottleneck for Unveiling Universal Attribution to Interpret Vision Transformers, https://arxiv.org/pdf/2507.04388, 2025-07-06
2025-11-11 00:52:02,097 - INFO - root - Page:1, Index:5, ZERO: Industry-ready Vision Foundation Model with Multi-modal Prompts, https://arxiv.org/pdf/2507.04270, 2025-11-07
2025-11-11 00:52:02,097 - INFO - root - Page:1, Index:6, Beyond Accuracy: Metrics that Uncover What Makes a 'Good' Visual Descriptor, https://arxiv.org/pdf/2507.03542, 2025-07-08
2025-11-11 00:52:02,098 - INFO - root - Page:1, Index:7, ConceptMix++: Leveling the Playing Field in Text-to-Image Benchmarking via Iterative Prompt Optimization, https://arxiv.org/pdf/2507.03275, 2025-07-03
2025-11-11 00:52:02,099 - INFO - root - Page:1, Index:8, APT: Adaptive Personalized Training for Diffusion Models with Limited Data, https://arxiv.org/pdf/2507.02687, 2025-07-03
2025-11-11 00:52:02,099 - INFO - root - Page:1, Index:9, DreamComposer++: Empowering Diffusion Models with Multi-View Conditions for 3D Content Generation, https://arxiv.org/pdf/2507.02299, 2025-07-03
2025-11-11 00:52:02,099 - INFO - root - Page:1, Index:10, Soft Self-labeling and Potts Relaxations for Weakly-Supervised Segmentation, https://arxiv.org/pdf/2507.01721, 2025-07-02
2025-11-11 00:52:02,101 - INFO - root - Page:1, Index:11, Interpolation-Based Event Visual Data Filtering Algorithms, https://arxiv.org/pdf/2507.01557, 2025-07-02
2025-11-11 00:52:02,102 - INFO - root - Page:1, Index:12, AVC-DPO: Aligned Video Captioning via Direct Preference Optimization, https://arxiv.org/pdf/2507.01492, 2025-07-02
2025-11-11 00:52:02,102 - INFO - root - Page:1, Index:13, NN-Former: Rethinking Graph Structure in Neural Architecture Representation, https://arxiv.org/pdf/2507.00880, 2025-07-01
2025-11-11 00:52:02,102 - INFO - root - Page:1, Index:14, Instant Particle Size Distribution Measurement Using CNNs Trained on Synthetic Data, https://arxiv.org/pdf/2507.00822, 2025-07-01
2025-11-11 00:52:02,103 - INFO - root - Page:1, Index:15, Moment Sampling in Video LLMs for Long-Form Video QA, https://arxiv.org/pdf/2507.00033, 2025-06-17
2025-11-11 00:52:02,103 - INFO - root - Page:1, Index:16, Revisiting Audio-Visual Segmentation with Vision-Centric Transformer, https://arxiv.org/pdf/2506.23623, 2025-06-30
2025-11-11 00:52:02,103 - INFO - root - Page:1, Index:17, MTADiffusion: Mask Text Alignment Diffusion Model for Object Inpainting, https://arxiv.org/pdf/2506.23482, 2025-06-29
2025-11-11 00:52:02,103 - INFO - root - Page:1, Index:18, Benchmarking Generalizable Bimanual Manipulation: RoboTwin Dual-Arm Collaboration Challenge at CVPR 2025 MEIS Workshop, https://arxiv.org/pdf/2506.23351, 2025-07-02
2025-11-11 00:52:02,104 - INFO - root - Page:1, Index:19, Prompting without Panic: Attribute-aware, Zero-shot, Test-Time Calibration, https://arxiv.org/pdf/2506.22819, 2025-06-28
2025-11-11 00:52:02,104 - INFO - root - Page:1, Index:20, Analyzing and Fine-Tuning Whisper Models for Multilingual Pilot Speech Transcription in the Cockpit, https://arxiv.org/pdf/2506.21990, 2025-06-27
2025-11-11 00:52:02,104 - INFO - root - Page:1, Index:21, SceneDiffuser++: City-Scale Traffic Simulation via a Generative World Model, https://arxiv.org/pdf/2506.21976, 2025-06-27
2025-11-11 00:52:02,104 - INFO - root - Page:1, Index:22, DIVE: Deep-search Iterative Video Exploration A Technical Report for the CVRR Challenge at CVPR 2025, https://arxiv.org/pdf/2506.21891, 2025-06-27
2025-11-11 00:52:02,105 - INFO - root - Page:1, Index:23, End-to-End RGB-IR Joint Image Compression With Channel-wise Cross-modality Entropy Model, https://arxiv.org/pdf/2506.21851, 2025-06-26
2025-11-11 00:52:02,106 - INFO - root - Page:1, Index:24, Distilling Normalizing Flows, https://arxiv.org/pdf/2506.21003, 2025-06-26
2025-11-11 00:52:02,106 - INFO - root - Page:1, Index:25, Joint attitude estimation and 3D neural reconstruction of non-cooperative space objects, https://arxiv.org/pdf/2506.20638, 2025-06-25
2025-11-11 00:52:02,106 - INFO - root - Page:1, Index:26, Accept More, Reject Less: Reducing up to 19% Unnecessary Desk-Rejections over 11 Years of ICLR Data, https://arxiv.org/pdf/2506.20141, 2025-06-25
2025-11-11 00:52:02,106 - INFO - root - Page:1, Index:27, SceneCrafter: Controllable Multi-View Driving Scene Editing, https://arxiv.org/pdf/2506.19488, 2025-06-24
2025-11-11 00:52:02,106 - INFO - root - Page:1, Index:28, Emergence of Text Readability in Vision Language Models, https://arxiv.org/pdf/2506.19389, 2025-06-24
2025-11-11 00:52:02,107 - INFO - root - Page:1, Index:29, MedErr-CT: A Visual Question Answering Benchmark for Identifying and Correcting Errors in CT Reports, https://arxiv.org/pdf/2506.19217, 2025-06-23
2025-11-11 00:52:02,107 - INFO - root - Page:1, Index:30, RareSpot: Spotting Small and Rare Wildlife in Aerial Imagery with Multi-Scale Consistency and Context-Aware Augmentation, https://arxiv.org/pdf/2506.19087, 2025-06-23
2025-11-11 00:52:02,107 - INFO - root - Page:1, Index:31, Object-aware Sound Source Localization via Audio-Visual Scene Understanding, https://arxiv.org/pdf/2506.18557, 2025-06-23
2025-11-11 00:52:02,108 - INFO - root - Page:1, Index:32, Rethinking Decoder Design: Improving Biomarker Segmentation Using Depth-to-Space Restoration and Residual Linear Attention, https://arxiv.org/pdf/2506.18335, 2025-06-23
2025-11-11 00:52:02,108 - INFO - root - Page:1, Index:33, Relation3D: Enhancing Relation Modeling for Point Cloud Instance Segmentation, https://arxiv.org/pdf/2506.17891, 2025-06-21
2025-11-11 00:52:02,108 - INFO - root - Page:1, Index:34, HIRE: Lightweight High-Resolution Image Feature Enrichment for Multimodal LLMs, https://arxiv.org/pdf/2506.17608, 2025-06-21
2025-11-11 00:52:02,109 - INFO - root - Page:1, Index:35, Spatially-Aware Evaluation of Segmentation Uncertainty, https://arxiv.org/pdf/2506.16589, 2025-06-19
2025-11-11 00:52:02,109 - INFO - root - Page:1, Index:36, Tripartite Weight-Space Ensemble for Few-Shot Class-Incremental Learning, https://arxiv.org/pdf/2506.15720, 2025-06-03
2025-11-11 00:52:02,109 - INFO - root - Page:1, Index:37, PARC: A Quantitative Framework Uncovering the Symmetries within Vision Language Models, https://arxiv.org/pdf/2506.14808, 2025-06-03
2025-11-11 00:52:02,109 - INFO - root - Page:1, Index:38, Self-supervised Representation Learning with Local Aggregation for Image-based Profiling, https://arxiv.org/pdf/2506.14265, 2025-10-27
2025-11-11 00:52:02,110 - INFO - root - Page:1, Index:39, Towards Robust Learning to Optimize with Theoretical Guarantees, https://arxiv.org/pdf/2506.14263, 2025-06-17
2025-11-11 00:52:02,110 - INFO - root - Page:1, Index:40, Hidden Bias in the Machine: Stereotypes in Text-to-Image Models, https://arxiv.org/pdf/2506.13780, 2025-06-09
2025-11-11 00:52:02,110 - INFO - root - Page:1, Index:41, SmartHome-Bench: A Comprehensive Benchmark for Video Anomaly Detection in Smart Homes Using Multi-Modal Large Language Models, https://arxiv.org/pdf/2506.12992, 2025-06-15
2025-11-11 00:52:02,110 - INFO - root - Page:1, Index:42, Generative 4D Scene Gaussian Splatting with Object View-Synthesis Priors, https://arxiv.org/pdf/2506.12716, 2025-06-15
2025-11-11 00:52:02,111 - INFO - root - Page:1, Index:43, DejaVid: Encoder-Agnostic Learned Temporal Matching for Video Classification, https://arxiv.org/pdf/2506.12585, 2025-06-14
2025-11-11 00:52:02,111 - INFO - root - Page:1, Index:44, Pushing the Limits of Safety: A Technical Report on the ATLAS Challenge 2025, https://arxiv.org/pdf/2506.12430, 2025-07-10
2025-11-11 00:52:02,111 - INFO - root - Page:1, Index:45, FIMA-Q: Post-Training Quantization for Vision Transformers by Fisher Information Matrix Approximation, https://arxiv.org/pdf/2506.11543, 2025-06-13
2025-11-11 00:52:02,112 - INFO - root - Page:1, Index:46, Stop learning it all to mitigate visual hallucination, Focus on the hallucination target, https://arxiv.org/pdf/2506.11417, 2025-06-12
2025-11-11 00:52:02,112 - INFO - root - Page:1, Index:47, EfficientQuant: An Efficient Post-Training Quantization for CNN-Transformer Hybrid Models on Edge Devices, https://arxiv.org/pdf/2506.11093, 2025-06-05
2025-11-11 00:52:02,112 - INFO - root - Page:1, Index:48, HalLoc: Token-level Localization of Hallucinations for Vision Language Models, https://arxiv.org/pdf/2506.10286, 2025-06-11
2025-11-11 00:52:02,112 - INFO - root - Page:1, Index:49, DySS: Dynamic Queries and State-Space Learning for Efficient 3D Object Detection from Multi-Camera Videos, https://arxiv.org/pdf/2506.10242, 2025-06-11
2025-11-11 00:52:02,113 - INFO - root - Fetching page 3 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=100
2025-11-11 00:52:08,601 - INFO - root - get_all_titles_from_web 
2025-11-11 00:52:08,602 - INFO - root - Page:2, Index:0, Improving Personalized Search with Regularized Low-Rank Parameter Updates, https://arxiv.org/pdf/2506.10182, 2025-06-11
2025-11-11 00:52:08,602 - INFO - root - Page:2, Index:1, Hearing Hands: Generating Sounds from Physical Interactions in 3D Scenes, https://arxiv.org/pdf/2506.09989, 2025-06-11
2025-11-11 00:52:08,602 - INFO - root - Page:2, Index:2, UniPre3D: Unified Pre-training of 3D Point Cloud Models with Cross-Modal Gaussian Splatting, https://arxiv.org/pdf/2506.09952, 2025-06-11
2025-11-11 00:52:08,604 - INFO - root - Page:2, Index:3, Provoking Multi-modal Few-Shot LVLM via Exploration-Exploitation In-Context Learning, https://arxiv.org/pdf/2506.09473, 2025-06-11
2025-11-11 00:52:08,604 - INFO - root - Page:2, Index:4, Synthetic Human Action Video Data Generation with Pose Transfer, https://arxiv.org/pdf/2506.09411, 2025-06-11
2025-11-11 00:52:08,604 - INFO - root - Page:2, Index:5, ScaleLSD: Scalable Deep Line Segment Detection Streamlined, https://arxiv.org/pdf/2506.09369, 2025-06-10
2025-11-11 00:52:08,606 - INFO - root - Page:2, Index:6, CheckManual: A New Challenge and Benchmark for Manual-based Appliance Manipulation, https://arxiv.org/pdf/2506.09343, 2025-06-10
2025-11-11 00:52:08,606 - INFO - root - Page:2, Index:7, PatchGuard: Adversarially Robust Anomaly Detection and Localization through Vision Transformers and Pseudo Anomalies, https://arxiv.org/pdf/2506.09237, 2025-10-24
2025-11-11 00:52:08,606 - INFO - root - Page:2, Index:8, SILK: Smooth InterpoLation frameworK for motion in-betweening A Simplified Computational Approach, https://arxiv.org/pdf/2506.09075, 2025-06-09
2025-11-11 00:52:08,608 - INFO - root - Page:2, Index:9, BG-HOP: A Bimanual Generative Hand-Object Prior, https://arxiv.org/pdf/2506.09068, 2025-06-08
2025-11-11 00:52:08,608 - INFO - root - Page:2, Index:10, ORIDa: Object-centric Real-world Image Composition Dataset, https://arxiv.org/pdf/2506.08964, 2025-06-10
2025-11-11 00:52:08,608 - INFO - root - Page:2, Index:11, DiscoVLA: Discrepancy Reduction in Vision, Language, and Alignment for Parameter-Efficient Video-Text Retrieval, https://arxiv.org/pdf/2506.08887, 2025-06-10
2025-11-11 00:52:08,608 - INFO - root - Page:2, Index:12, A Comprehensive Study of Decoder-Only LLMs for Text-to-Image Generation, https://arxiv.org/pdf/2506.08210, 2025-06-09
2025-11-11 00:52:08,608 - INFO - root - Page:2, Index:13, Open World Scene Graph Generation using Vision Language Models, https://arxiv.org/pdf/2506.08189, 2025-06-09
2025-11-11 00:52:08,608 - INFO - root - Page:2, Index:14, Aligning Proteins and Language: A Foundation Model for Protein Retrieval, https://arxiv.org/pdf/2506.08023, 2025-05-27
2025-11-11 00:52:08,608 - INFO - root - Page:2, Index:15, UA-Pose: Uncertainty-Aware 6D Object Pose Estimation and Online Object Completion with Partial References, https://arxiv.org/pdf/2506.07996, 2025-06-09
2025-11-11 00:52:08,609 - INFO - root - Page:2, Index:16, Speedy Deformable 3D Gaussian Splatting: Fast Rendering and Compression of Dynamic Scenes, https://arxiv.org/pdf/2506.07917, 2025-06-09
2025-11-11 00:52:08,610 - INFO - root - Page:2, Index:17, GaussianVAE: Adaptive Learning Dynamics of 3D Gaussians for High-Fidelity Super-Resolution, https://arxiv.org/pdf/2506.07897, 2025-06-09
2025-11-11 00:52:08,610 - INFO - root - Page:2, Index:18, Spatio-Temporal State Space Model For Efficient Event-Based Optical Flow, https://arxiv.org/pdf/2506.07878, 2025-06-09
2025-11-11 00:52:08,610 - INFO - root - Page:2, Index:19, FreeGave: 3D Physics Learning from Dynamic Videos by Gaussian Velocity, https://arxiv.org/pdf/2506.07865, 2025-06-09
2025-11-11 00:52:08,611 - INFO - root - Page:2, Index:20, LogoSP: Local-global Grouping of Superpoints for Unsupervised Semantic Segmentation of 3D Point Clouds, https://arxiv.org/pdf/2506.07857, 2025-06-09
2025-11-11 00:52:08,611 - INFO - root - Page:2, Index:21, Difference Inversion: Interpolate and Isolate the Difference with Token Consistency for Image Analogy Generation, https://arxiv.org/pdf/2506.07750, 2025-06-09
2025-11-11 00:52:08,611 - INFO - root - Page:2, Index:22, Synthetic Visual Genome, https://arxiv.org/pdf/2506.07643, 2025-06-09
2025-11-11 00:52:08,611 - INFO - root - Page:2, Index:23, Fractional Collisions: A Framework for Risk Estimation of Counterfactual Conflicts using Autonomous Driving Behavior Simulations, https://arxiv.org/pdf/2506.07540, 2025-06-09
2025-11-11 00:52:08,612 - INFO - root - Page:2, Index:24, Multi-Step Guided Diffusion for Image Restoration on Edge Devices: Toward Lightweight Perception in Embodied AI, https://arxiv.org/pdf/2506.07286, 2025-06-08
2025-11-11 00:52:08,612 - INFO - root - Page:2, Index:25, LLM-Enhanced Rapid-Reflex Async-Reflect Embodied Agent for Real-Time Decision-Making in Dynamically Changing Environments, https://arxiv.org/pdf/2506.07223, 2025-06-08
2025-11-11 00:52:08,612 - INFO - root - Page:2, Index:26, UCOD-DPL: Unsupervised Camouflaged Object Detection via Dynamic Pseudo-label Learning, https://arxiv.org/pdf/2506.07087, 2025-06-08
2025-11-11 00:52:08,612 - INFO - root - Page:2, Index:27, BePo: Leveraging Birds Eye View and Sparse Points for Efficient and Accurate 3D Occupancy Prediction, https://arxiv.org/pdf/2506.07002, 2025-06-08
2025-11-11 00:52:08,613 - INFO - root - Page:2, Index:28, Reading in the Dark with Foveated Event Vision, https://arxiv.org/pdf/2506.06918, 2025-06-07
2025-11-11 00:52:08,613 - INFO - root - Page:2, Index:29, NSD-Imagery: A benchmark dataset for extending fMRI vision decoding methods to mental imagery, https://arxiv.org/pdf/2506.06898, 2025-06-07
2025-11-11 00:52:08,613 - INFO - root - Page:2, Index:30, Continuous-Time SO(3) Forecasting with Savitzky--Golay Neural Controlled Differential Equations, https://arxiv.org/pdf/2506.06780, 2025-06-07
2025-11-11 00:52:08,613 - INFO - root - Page:2, Index:31, Generalized Trajectory Scoring for End-to-end Multimodal Planning, https://arxiv.org/pdf/2506.06664, 2025-06-07
2025-11-11 00:52:08,613 - INFO - root - Page:2, Index:32, EV-LayerSegNet: Self-supervised Motion Segmentation using Event Cameras, https://arxiv.org/pdf/2506.06596, 2025-06-06
2025-11-11 00:52:08,613 - INFO - root - Page:2, Index:33, Vid2Sim: Generalizable, Video-based Reconstruction of Appearance, Geometry and Physics for Mesh-free Simulation, https://arxiv.org/pdf/2506.06440, 2025-06-06
2025-11-11 00:52:08,614 - INFO - root - Page:2, Index:34, FADE: Frequency-Aware Diffusion Model Factorization for Video Editing, https://arxiv.org/pdf/2506.05934, 2025-06-06
2025-11-11 00:52:08,614 - INFO - root - Page:2, Index:35, Unleashing the Potential of Consistency Learning for Detecting and Grounding Multi-Modal Media Manipulation, https://arxiv.org/pdf/2506.05890, 2025-06-06
2025-11-11 00:52:08,614 - INFO - root - Page:2, Index:36, DeformCL: Learning Deformable Centerline Representation for Vessel Extraction in 3D Medical Image, https://arxiv.org/pdf/2506.05820, 2025-06-06
2025-11-11 00:52:08,614 - INFO - root - Page:2, Index:37, NTIRE 2025 Challenge on HR Depth from Images of Specular and Transparent Surfaces, https://arxiv.org/pdf/2506.05815, 2025-06-06
2025-11-11 00:52:08,614 - INFO - root - Page:2, Index:38, GazeNLQ @ Ego4D Natural Language Queries Challenge 2025, https://arxiv.org/pdf/2506.05782, 2025-06-06
2025-11-11 00:52:08,616 - INFO - root - Page:2, Index:39, Robust sensor fusion against on-vehicle sensor staleness, https://arxiv.org/pdf/2506.05780, 2025-06-06
2025-11-11 00:52:08,617 - INFO - root - Page:2, Index:40, Where Is The Ball: 3D Ball Trajectory Estimation From 2D Monocular Tracking, https://arxiv.org/pdf/2506.05763, 2025-06-06
2025-11-11 00:52:08,617 - INFO - root - Page:2, Index:41, VoxelSplat: Dynamic Gaussian Splatting as an Effective Loss for Occupancy and Flow Prediction, https://arxiv.org/pdf/2506.05563, 2025-06-05
2025-11-11 00:52:08,617 - INFO - root - Page:2, Index:42, Gen4D: Synthesizing Humans and Scenes in the Wild, https://arxiv.org/pdf/2506.05397, 2025-06-03
2025-11-11 00:52:08,618 - INFO - root - Page:2, Index:43, Attacking Attention of Foundation Models Disrupts Downstream Tasks, https://arxiv.org/pdf/2506.05394, 2025-09-12
2025-11-11 00:52:08,618 - INFO - root - Page:2, Index:44, FreeTimeGS: Free Gaussian Primitives at Anytime and Anywhere for Dynamic Scene Reconstruction, https://arxiv.org/pdf/2506.05348, 2025-06-06
2025-11-11 00:52:08,618 - INFO - root - Page:2, Index:45, LotusFilter: Fast Diverse Nearest Neighbor Search via a Learned Cutoff Table, https://arxiv.org/pdf/2506.04790, 2025-06-05
2025-11-11 00:52:08,618 - INFO - root - Page:2, Index:46, Towards Holistic Visual Quality Assessment of AI-Generated Videos: A LLM-Based Multi-Dimensional Evaluation Model, https://arxiv.org/pdf/2506.04715, 2025-06-11
2025-11-11 00:52:08,618 - INFO - root - Page:2, Index:47, Gradient Inversion Attacks on Parameter-Efficient Fine-Tuning, https://arxiv.org/pdf/2506.04453, 2025-06-04
2025-11-11 00:52:08,618 - INFO - root - Page:2, Index:48, HMAR: Efficient Hierarchical Masked Auto-Regressive Image Generation, https://arxiv.org/pdf/2506.04421, 2025-06-04
2025-11-11 00:52:08,619 - INFO - root - Page:2, Index:49, Visualizing and Controlling Cortical Responses Using Voxel-Weighted Activation Maximization, https://arxiv.org/pdf/2506.04379, 2025-06-04
2025-11-11 00:52:08,619 - INFO - root - Fetching page 4 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=150
2025-11-11 00:52:15,507 - INFO - root - get_all_titles_from_web 
2025-11-11 00:52:15,508 - INFO - root - Page:3, Index:0, FlexGS: Train Once, Deploy Everywhere with Many-in-One Flexible 3D Gaussian Splatting, https://arxiv.org/pdf/2506.04174, 2025-06-04
2025-11-11 00:52:15,508 - INFO - root - Page:3, Index:1, Multi-view Surface Reconstruction Using Normal and Reflectance Cues, https://arxiv.org/pdf/2506.04115, 2025-06-04
2025-11-11 00:52:15,508 - INFO - root - Page:3, Index:2, Vocabulary-free few-shot learning for Vision-Language Models, https://arxiv.org/pdf/2506.04005, 2025-06-04
2025-11-11 00:52:15,508 - INFO - root - Page:3, Index:3, Learning from Noise: Enhancing DNNs for Event-Based Vision through Controlled Noise Injection, https://arxiv.org/pdf/2506.03918, 2025-06-04
2025-11-11 00:52:15,509 - INFO - root - Page:3, Index:4, Video, How Do Your Tokens Merge?, https://arxiv.org/pdf/2506.03885, 2025-06-04
2025-11-11 00:52:15,509 - INFO - root - Page:3, Index:5, OSGNet @ Ego4D Episodic Memory Challenge 2025, https://arxiv.org/pdf/2506.03710, 2025-06-04
2025-11-11 00:52:15,510 - INFO - root - Page:3, Index:6, AetherVision-Bench: An Open-Vocabulary RGB-Infrared Benchmark for Multi-Angle Segmentation across Aerial and Ground Perspectives, https://arxiv.org/pdf/2506.03709, 2025-06-04
2025-11-11 00:52:15,510 - INFO - root - Page:3, Index:7, OV-COAST: Cost Aggregation with Optimal Transport for Open-Vocabulary Semantic Segmentation, https://arxiv.org/pdf/2506.03706, 2025-06-04
2025-11-11 00:52:15,517 - INFO - root - Page:3, Index:8, Generating 6DoF Object Manipulation Trajectories from Action Description in Egocentric Vision, https://arxiv.org/pdf/2506.03605, 2025-06-04
2025-11-11 00:52:15,519 - INFO - root - Page:3, Index:9, SemNav: A Model-Based Planner for Zero-Shot Object Goal Navigation Using Vision-Foundation Models, https://arxiv.org/pdf/2506.03516, 2025-06-03
2025-11-11 00:52:15,519 - INFO - root - Page:3, Index:10, Heterogeneous Skeleton-Based Action Representation Learning, https://arxiv.org/pdf/2506.03481, 2025-06-03
2025-11-11 00:52:15,519 - INFO - root - Page:3, Index:11, Hybrid Ensemble of Segmentation-Assisted Classification and GBDT for Skin Cancer Detection with Engineered Metadata and Synthetic Lesions from ISIC 2024 Non-Dermoscopic 3D-TBP Images, https://arxiv.org/pdf/2506.03420, 2025-06-03
2025-11-11 00:52:15,520 - INFO - root - Page:3, Index:12, Self-Supervised Spatial Correspondence Across Modalities, https://arxiv.org/pdf/2506.03148, 2025-06-03
2025-11-11 00:52:15,520 - INFO - root - Page:3, Index:13, Dense Match Summarization for Faster Two-view Estimation, https://arxiv.org/pdf/2506.02893, 2025-06-03
2025-11-11 00:52:15,521 - INFO - root - Page:3, Index:14, NTIRE 2025 XGC Quality Assessment Challenge: Methods and Results, https://arxiv.org/pdf/2506.02875, 2025-06-03
2025-11-11 00:52:15,521 - INFO - root - Page:3, Index:15, FreeScene: Mixed Graph Diffusion for 3D Scene Synthesis from Free Prompts, https://arxiv.org/pdf/2506.02781, 2025-06-03
2025-11-11 00:52:15,521 - INFO - root - Page:3, Index:16, Technical Report for Ego4D Long-Term Action Anticipation Challenge 2025, https://arxiv.org/pdf/2506.02550, 2025-06-11
2025-11-11 00:52:15,523 - INFO - root - Page:3, Index:17, Probabilistic Online Event Downsampling, https://arxiv.org/pdf/2506.02547, 2025-09-23
2025-11-11 00:52:15,523 - INFO - root - Page:3, Index:18, Towards In-the-wild 3D Plane Reconstruction from a Single Image, https://arxiv.org/pdf/2506.02493, 2025-06-03
2025-11-11 00:52:15,525 - INFO - root - Page:3, Index:19, Efficient Test-time Adaptive Object Detection via Sensitivity-Guided Pruning, https://arxiv.org/pdf/2506.02462, 2025-06-03
2025-11-11 00:52:15,525 - INFO - root - Page:3, Index:20, EgoVIS@CVPR: PAIR-Net: Enhancing Egocentric Speaker Detection via Pretrained Audio-Visual Fusion and Alignment Loss, https://arxiv.org/pdf/2506.02247, 2025-09-26
2025-11-11 00:52:15,525 - INFO - root - Page:3, Index:21, Diff2Flow: Training Flow Matching Models via Diffusion Model Alignment, https://arxiv.org/pdf/2506.02221, 2025-06-02
2025-11-11 00:52:15,526 - INFO - root - Page:3, Index:22, NTIRE 2025 Challenge on RAW Image Restoration and Super-Resolution, https://arxiv.org/pdf/2506.02197, 2025-06-04
2025-11-11 00:52:15,526 - INFO - root - Page:3, Index:23, RAW Image Reconstruction from RGB on Smartphones. NTIRE 2025 Challenge Report, https://arxiv.org/pdf/2506.01947, 2025-06-02
2025-11-11 00:52:15,526 - INFO - root - Page:3, Index:24, Silence is Golden: Leveraging Adversarial Examples to Nullify Audio Control in LDM-based Talking-Head Generation, https://arxiv.org/pdf/2506.01591, 2025-06-02
2025-11-11 00:52:15,527 - INFO - root - Page:3, Index:25, SAM2-LOVE: Segment Anything Model 2 in Language-aided Audio-Visual Scenes, https://arxiv.org/pdf/2506.01558, 2025-06-02
2025-11-11 00:52:15,527 - INFO - root - Page:3, Index:26, Neural shape reconstruction from multiple views with static pattern projection, https://arxiv.org/pdf/2506.01389, 2025-06-02
2025-11-11 00:52:15,537 - INFO - root - Page:3, Index:27, SAM-I2V: Upgrading SAM to Support Promptable Video Segmentation with Less than 0.2% Training Cost, https://arxiv.org/pdf/2506.01304, 2025-06-02
2025-11-11 00:52:15,537 - INFO - root - Page:3, Index:28, Perceptual Inductive Bias Is What You Need Before Contrastive Learning, https://arxiv.org/pdf/2506.01201, 2025-06-01
2025-11-11 00:52:15,537 - INFO - root - Page:3, Index:29, Test Automation for Interactive Scenarios via Promptable Traffic Simulation, https://arxiv.org/pdf/2506.01199, 2025-06-04
2025-11-11 00:52:15,539 - INFO - root - Page:3, Index:30, GraphPad: Inference-Time 3D Scene Graph Updates for Embodied Question Answering, https://arxiv.org/pdf/2506.01174, 2025-06-01
2025-11-11 00:52:15,539 - INFO - root - Page:3, Index:31, Aligned Contrastive Loss for Long-Tailed Recognition, https://arxiv.org/pdf/2506.01071, 2025-06-01
2025-11-11 00:52:15,540 - INFO - root - Page:3, Index:32, Self-supervised ControlNet with Spatio-Temporal Mamba for Real-world Video Super-resolution, https://arxiv.org/pdf/2506.01037, 2025-06-01
2025-11-11 00:52:15,540 - INFO - root - Page:3, Index:33, ArtiScene: Language-Driven Artistic 3D Scene Generation Through Image Intermediary, https://arxiv.org/pdf/2506.00742, 2025-05-31
2025-11-11 00:52:15,541 - INFO - root - Page:3, Index:34, 3D Gaussian Splat Vulnerabilities, https://arxiv.org/pdf/2506.00280, 2025-05-30
2025-11-11 00:52:15,542 - INFO - root - Page:3, Index:35, EgoVIS@CVPR: What Changed and What Could Have Changed? State-Change Counterfactuals for Procedure-Aware Video Representation Learning, https://arxiv.org/pdf/2506.00101, 2025-09-26
2025-11-11 00:52:15,542 - INFO - root - Page:3, Index:36, CL-LoRA: Continual Low-Rank Adaptation for Rehearsal-Free Class-Incremental Learning, https://arxiv.org/pdf/2505.24816, 2025-05-30
2025-11-11 00:52:15,543 - INFO - root - Page:3, Index:37, PatchDEMUX: A Certifiably Robust Framework for Multi-label Classifiers Against Adversarial Patches, https://arxiv.org/pdf/2505.24703, 2025-05-30
2025-11-11 00:52:15,543 - INFO - root - Page:3, Index:38, Conformal Prediction for Zero-Shot Models, https://arxiv.org/pdf/2505.24693, 2025-05-30
2025-11-11 00:52:15,544 - INFO - root - Page:3, Index:39, Learning reusable concepts across different egocentric video understanding tasks, https://arxiv.org/pdf/2505.24690, 2025-05-30
2025-11-11 00:52:15,544 - INFO - root - Page:3, Index:40, Period-LLM: Extending the Periodic Capability of Multimodal Large Language Model, https://arxiv.org/pdf/2505.24476, 2025-05-30
2025-11-11 00:52:15,549 - INFO - root - Page:3, Index:41, PCIE_Interaction Solution for Ego4D Social Interaction Challenge, https://arxiv.org/pdf/2505.24404, 2025-05-30
2025-11-11 00:52:15,550 - INFO - root - Page:3, Index:42, Leadership Assessment in Pediatric Intensive Care Unit Team Training, https://arxiv.org/pdf/2505.24389, 2025-08-28
2025-11-11 00:52:15,551 - INFO - root - Page:3, Index:43, Interpreting Large Text-to-Image Diffusion Models with Dictionary Learning, https://arxiv.org/pdf/2505.24360, 2025-07-10
2025-11-11 00:52:15,555 - INFO - root - Page:3, Index:44, InteractAnything: Zero-shot Human Object Interaction Synthesis via LLM Feedback and Object Affordance Parsing, https://arxiv.org/pdf/2505.24315, 2025-05-30
2025-11-11 00:52:15,557 - INFO - root - Page:3, Index:45, MaskAdapt: Unsupervised Geometry-Aware Domain Adaptation Using Multimodal Contextual Learning and RGB-Depth Masking, https://arxiv.org/pdf/2505.24026, 2025-05-29
2025-11-11 00:52:15,558 - INFO - root - Page:3, Index:46, Argus: Vision-Centric Reasoning with Grounded Chain-of-Thought, https://arxiv.org/pdf/2505.23766, 2025-05-29
2025-11-11 00:52:15,558 - INFO - root - Page:3, Index:47, Sketch Down the FLOPs: Towards Efficient Networks for Human Sketch, https://arxiv.org/pdf/2505.23763, 2025-05-29
2025-11-11 00:52:15,559 - INFO - root - Page:3, Index:48, Boosting Domain Incremental Learning: Selecting the Optimal Parameters is All You Need, https://arxiv.org/pdf/2505.23744, 2025-05-29
2025-11-11 00:52:15,559 - INFO - root - Page:3, Index:49, DA-VPT: Semantic-Guided Visual Prompt Tuning for Vision Transformers, https://arxiv.org/pdf/2505.23694, 2025-06-01
2025-11-11 00:52:15,559 - INFO - root - Fetching page 5 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=200
2025-11-11 00:52:21,895 - INFO - root - get_all_titles_from_web 
2025-11-11 00:52:21,896 - INFO - root - Page:4, Index:0, Bridging Classical and Modern Computer Vision: PerceptiveNet for Tree Crown Semantic Segmentation, https://arxiv.org/pdf/2505.23597, 2025-05-29
2025-11-11 00:52:21,896 - INFO - root - Page:4, Index:1, Synthetic Generation and Latent Projection Denoising of Rim Lesions in Multiple Sclerosis, https://arxiv.org/pdf/2505.23353, 2025-05-29
2025-11-11 00:52:21,896 - INFO - root - Page:4, Index:2, Wav2Sem: Plug-and-Play Audio Semantic Decoupling for 3D Speech-Driven Facial Animation, https://arxiv.org/pdf/2505.23290, 2025-05-29
2025-11-11 00:52:21,896 - INFO - root - Page:4, Index:3, Proximal Algorithm Unrolling: Flexible and Efficient Reconstruction Networks for Single-Pixel Imaging, https://arxiv.org/pdf/2505.23180, 2025-05-29
2025-11-11 00:52:21,897 - INFO - root - Page:4, Index:4, HMAD: Advancing E2E Driving with Anchored Offset Proposals and Simulation-Supervised Multi-target Scoring, https://arxiv.org/pdf/2505.23129, 2025-05-29
2025-11-11 00:52:21,897 - INFO - root - Page:4, Index:5, URWKV: Unified RWKV Model with Multi-state Perspective for Low-light Image Restoration, https://arxiv.org/pdf/2505.23068, 2025-05-29
2025-11-11 00:52:21,897 - INFO - root - Page:4, Index:6, 4DTAM: Non-Rigid Tracking and Mapping via Dynamic Surface Gaussians, https://arxiv.org/pdf/2505.22859, 2025-05-28
2025-11-11 00:52:21,897 - INFO - root - Page:4, Index:7, A Probabilistic Jump-Diffusion Framework for Open-World Egocentric Activity Recognition, https://arxiv.org/pdf/2505.22858, 2025-05-28
2025-11-11 00:52:21,897 - INFO - root - Page:4, Index:8, PS4PRO: Pixel-to-pixel Supervision for Photorealistic Rendering and Optimization, https://arxiv.org/pdf/2505.22616, 2025-05-28
2025-11-11 00:52:21,899 - INFO - root - Page:4, Index:9, Universal Domain Adaptation for Semantic Segmentation, https://arxiv.org/pdf/2505.22458, 2025-06-05
2025-11-11 00:52:21,899 - INFO - root - Page:4, Index:10, Zero-Shot 3D Visual Grounding from Vision-Language Models, https://arxiv.org/pdf/2505.22429, 2025-05-28
2025-11-11 00:52:21,899 - INFO - root - Page:4, Index:11, RC-AutoCalib: An End-to-End Radar-Camera Automatic Calibration Network, https://arxiv.org/pdf/2505.22427, 2025-05-28
2025-11-11 00:52:21,899 - INFO - root - Page:4, Index:12, Bringing CLIP to the Clinic: Dynamic Soft Labels and Negation-Aware Learning for Medical Analysis, https://arxiv.org/pdf/2505.22079, 2025-05-28
2025-11-11 00:52:21,900 - INFO - root - Page:4, Index:13, Point-to-Region Loss for Semi-Supervised Point-Based Crowd Counting, https://arxiv.org/pdf/2505.21943, 2025-05-27
2025-11-11 00:52:21,900 - INFO - root - Page:4, Index:14, FRAMES-VQA: Benchmarking Fine-Tuning Robustness across Multi-Modal Shifts in Visual Question Answering, https://arxiv.org/pdf/2505.21755, 2025-06-20
2025-11-11 00:52:21,902 - INFO - root - Page:4, Index:15, Knowledge Distillation Approach for SOS Fusion Staging: Towards Fully Automated Skeletal Maturity Assessment, https://arxiv.org/pdf/2505.21561, 2025-05-26
2025-11-11 00:52:21,905 - INFO - root - Page:4, Index:16, Enhancing Vision Transformer Explainability Using Artificial Astrocytes, https://arxiv.org/pdf/2505.21513, 2025-05-20
2025-11-11 00:52:21,907 - INFO - root - Page:4, Index:17, Empowering Vector Graphics with Consistently Arbitrary Viewing and View-dependent Visibility, https://arxiv.org/pdf/2505.21377, 2025-05-27
2025-11-11 00:52:21,908 - INFO - root - Page:4, Index:18, Structure from Collision, https://arxiv.org/pdf/2505.21335, 2025-05-27
2025-11-11 00:52:21,909 - INFO - root - Page:4, Index:19, Boosting Adversarial Transferability via High-Frequency Augmentation and Hierarchical-Gradient Fusion, https://arxiv.org/pdf/2505.21181, 2025-05-27
2025-11-11 00:52:21,911 - INFO - root - Page:4, Index:20, RefAV: Towards Planning-Centric Scenario Mining, https://arxiv.org/pdf/2505.20981, 2025-06-18
2025-11-11 00:52:21,911 - INFO - root - Page:4, Index:21, PMA: Towards Parameter-Efficient Point Cloud Understanding via Point Mamba Adapter, https://arxiv.org/pdf/2505.20941, 2025-05-27
2025-11-11 00:52:21,911 - INFO - root - Page:4, Index:22, HuMoCon: Concept Discovery for Human Motion Understanding, https://arxiv.org/pdf/2505.20920, 2025-05-27
2025-11-11 00:52:21,912 - INFO - root - Page:4, Index:23, Exploring Timeline Control for Facial Motion Generation, https://arxiv.org/pdf/2505.20861, 2025-05-27
2025-11-11 00:52:21,912 - INFO - root - Page:4, Index:24, ConText-CIR: Learning from Concepts in Text for Composed Image Retrieval, https://arxiv.org/pdf/2505.20764, 2025-05-27
2025-11-11 00:52:21,914 - INFO - root - Page:4, Index:25, HCQA-1.5 @ Ego4D EgoSchema Challenge 2025, https://arxiv.org/pdf/2505.20644, 2025-05-26
2025-11-11 00:52:21,914 - INFO - root - Page:4, Index:26, Roboflow100-VL: A Multi-Domain Object Detection Benchmark for Vision-Language Models, https://arxiv.org/pdf/2505.20612, 2025-10-22
2025-11-11 00:52:21,915 - INFO - root - Page:4, Index:27, MotionPro: A Precise Motion Controller for Image-to-Video Generation, https://arxiv.org/pdf/2505.20287, 2025-05-26
2025-11-11 00:52:21,916 - INFO - root - Page:4, Index:28, Category-Agnostic Neural Object Rigging, https://arxiv.org/pdf/2505.20283, 2025-05-26
2025-11-11 00:52:21,916 - INFO - root - Page:4, Index:29, Towards Video to Piano Music Generation with Chain-of-Perform Support Benchmarks, https://arxiv.org/pdf/2505.20038, 2025-05-26
2025-11-11 00:52:21,917 - INFO - root - Page:4, Index:30, Can Visual Encoder Learn to See Arrows?, https://arxiv.org/pdf/2505.19944, 2025-05-26
2025-11-11 00:52:21,917 - INFO - root - Page:4, Index:31, GoLF-NRT: Integrating Global Context and Local Geometry for Few-Shot View Synthesis, https://arxiv.org/pdf/2505.19813, 2025-05-26
2025-11-11 00:52:21,919 - INFO - root - Page:4, Index:32, Depth-Guided Bundle Sampling for Efficient Generalizable Neural Radiance Field Reconstruction, https://arxiv.org/pdf/2505.19793, 2025-05-26
2025-11-11 00:52:21,919 - INFO - root - Page:4, Index:33, SuperAD: A Training-free Anomaly Classification and Segmentation Method for CVPR 2025 VAND 3.0 Workshop Challenge Track 1: Adapt & Detect, https://arxiv.org/pdf/2505.19750, 2025-05-27
2025-11-11 00:52:21,923 - INFO - root - Page:4, Index:34, Knowledge-Aligned Counterfactual-Enhancement Diffusion Perception for Unsupervised Cross-Domain Visual Emotion Recognition, https://arxiv.org/pdf/2505.19694, 2025-05-26
2025-11-11 00:52:21,923 - INFO - root - Page:4, Index:35, Rotation-Equivariant Self-Supervised Method in Image Denoising, https://arxiv.org/pdf/2505.19618, 2025-05-26
2025-11-11 00:52:21,924 - INFO - root - Page:4, Index:36, NTIRE 2025 Challenge on Video Quality Enhancement for Video Conferencing: Datasets, Methods and Results, https://arxiv.org/pdf/2505.18988, 2025-05-25
2025-11-11 00:52:21,924 - INFO - root - Page:4, Index:37, Geometry-guided Online 3D Video Synthesis with Multi-View Temporal Consistency, https://arxiv.org/pdf/2505.18932, 2025-05-24
2025-11-11 00:52:21,924 - INFO - root - Page:4, Index:38, Digital Overconsumption and Waste: A Closer Look at the Impacts of Generative AI, https://arxiv.org/pdf/2505.18894, 2025-05-24
2025-11-11 00:52:21,925 - INFO - root - Page:4, Index:39, VISTA: Vision-Language Inference for Training-Free Stock Time-Series Analysis, https://arxiv.org/pdf/2505.18570, 2025-06-11
2025-11-11 00:52:21,925 - INFO - root - Page:4, Index:40, Syn3DTxt: Embedding 3D Cues for Scene Text Generation, https://arxiv.org/pdf/2505.18479, 2025-05-23
2025-11-11 00:52:21,926 - INFO - root - Page:4, Index:41, CTRL-GS: Cascaded Temporal Residue Learning for 4D Gaussian Splatting, https://arxiv.org/pdf/2505.18306, 2025-05-31
2025-11-11 00:52:21,926 - INFO - root - Page:4, Index:42, DualTalk: Dual-Speaker Interaction for 3D Talking Head Conversations, https://arxiv.org/pdf/2505.18096, 2025-05-26
2025-11-11 00:52:21,926 - INFO - root - Page:4, Index:43, SeaLion: Semantic Part-Aware Latent Point Diffusion Models for 3D Generation, https://arxiv.org/pdf/2505.17721, 2025-07-07
2025-11-11 00:52:21,927 - INFO - root - Page:4, Index:44, PoseBH: Prototypical Multi-Dataset Training Beyond Human Pose Estimation, https://arxiv.org/pdf/2505.17475, 2025-05-23
2025-11-11 00:52:21,927 - INFO - root - Page:4, Index:45, Pursuing Temporal-Consistent Video Virtual Try-On via Dynamic Pose Interaction, https://arxiv.org/pdf/2505.16980, 2025-05-22
2025-11-11 00:52:21,927 - INFO - root - Page:4, Index:46, UniPhy: Learning a Unified Constitutive Model for Inverse Physics Simulation, https://arxiv.org/pdf/2505.16971, 2025-05-22
2025-11-11 00:52:21,928 - INFO - root - Page:4, Index:47, Tracking the Flight: Exploring a Computational Framework for Analyzing Escape Responses in Plains Zebra (Equus quagga), https://arxiv.org/pdf/2505.16882, 2025-05-23
2025-11-11 00:52:21,929 - INFO - root - Page:4, Index:48, Semi-Supervised State-Space Model with Dynamic Stacking Filter for Real-World Video Deraining, https://arxiv.org/pdf/2505.16811, 2025-05-22
2025-11-11 00:52:21,929 - INFO - root - Page:4, Index:49, SOLVE: Synergy of Language-Vision and End-to-End Networks for Autonomous Driving, https://arxiv.org/pdf/2505.16805, 2025-05-22
2025-11-11 00:52:21,929 - INFO - root - Fetching page 6 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=250
2025-11-11 00:52:29,618 - INFO - root - get_all_titles_from_web 
2025-11-11 00:52:29,618 - INFO - root - Page:5, Index:0, Four Eyes Are Better Than Two: Harnessing the Collaborative Potential of Large Models via Differentiated Thinking and Complementary Ensembles, https://arxiv.org/pdf/2505.16784, 2025-06-07
2025-11-11 00:52:29,619 - INFO - root - Page:5, Index:1, Single Domain Generalization for Few-Shot Counting via Universal Representation Matching, https://arxiv.org/pdf/2505.16778, 2025-05-22
2025-11-11 00:52:29,619 - INFO - root - Page:5, Index:2, Seeing Far and Clearly: Mitigating Hallucinations in MLLMs with Attention Causal Decoding, https://arxiv.org/pdf/2505.16652, 2025-06-07
2025-11-11 00:52:29,620 - INFO - root - Page:5, Index:3, Sketchy Bounding-box Supervision for 3D Instance Segmentation, https://arxiv.org/pdf/2505.16399, 2025-05-22
2025-11-11 00:52:29,620 - INFO - root - Page:5, Index:4, DeCafNet: Delegate and Conquer for Efficient Temporal Grounding in Long Videos, https://arxiv.org/pdf/2505.16376, 2025-05-22
2025-11-11 00:52:29,620 - INFO - root - Page:5, Index:5, NTIRE 2025 challenge on Text to Image Generation Model Quality Assessment, https://arxiv.org/pdf/2505.16314, 2025-05-22
2025-11-11 00:52:29,622 - INFO - root - Page:5, Index:6, Analyzing Hierarchical Structure in Vision Models with Sparse Autoencoders, https://arxiv.org/pdf/2505.15970, 2025-05-21
2025-11-11 00:52:29,622 - INFO - root - Page:5, Index:7, Efficient Data Driven Mixture-of-Expert Extraction from Trained Networks, https://arxiv.org/pdf/2505.15414, 2025-05-21
2025-11-11 00:52:29,622 - INFO - root - Page:5, Index:8, Mouse Lockbox Dataset: Behavior Recognition for Mice Solving Lockboxes, https://arxiv.org/pdf/2505.15408, 2025-06-17
2025-11-11 00:52:29,624 - INFO - root - Page:5, Index:9, Zero-Shot Gaze-based Volumetric Medical Image Segmentation, https://arxiv.org/pdf/2505.15256, 2025-06-10
2025-11-11 00:52:29,625 - INFO - root - Page:5, Index:10, Dual Precision Quantization for Efficient and Accurate Deep Neural Networks Inference, https://arxiv.org/pdf/2505.14638, 2025-05-20
2025-11-11 00:52:29,626 - INFO - root - Page:5, Index:11, Neural Video Compression with Context Modulation, https://arxiv.org/pdf/2505.14541, 2025-05-20
2025-11-11 00:52:29,626 - INFO - root - Page:5, Index:12, Selective Structured State Space for Multispectral-fused Small Target Detection, https://arxiv.org/pdf/2505.14043, 2025-05-23
2025-11-11 00:52:29,626 - INFO - root - Page:5, Index:13, OmniStyle: Filtering High Quality Style Transfer Data at Scale, https://arxiv.org/pdf/2505.14028, 2025-05-20
2025-11-11 00:52:29,628 - INFO - root - Page:5, Index:14, Domain Adaptation of VLM for Soccer Video Understanding, https://arxiv.org/pdf/2505.13860, 2025-07-07
2025-11-11 00:52:29,628 - INFO - root - Page:5, Index:15, Ground-V: Teaching VLMs to Ground Complex Instructions in Pixels, https://arxiv.org/pdf/2505.13788, 2025-05-19
2025-11-11 00:52:29,628 - INFO - root - Page:5, Index:16, FinePhys: Fine-grained Human Action Generation by Explicitly Incorporating Physical Laws for Effective Skeletal Guidance, https://arxiv.org/pdf/2505.13437, 2025-05-19
2025-11-11 00:52:29,628 - INFO - root - Page:5, Index:17, The Way Up: A Dataset for Hold Usage Detection in Sport Climbing, https://arxiv.org/pdf/2505.12854, 2025-05-19
2025-11-11 00:52:29,629 - INFO - root - Page:5, Index:18, PEER pressure: Model-to-Model Regularization for Single Source Domain Generalization, https://arxiv.org/pdf/2505.12745, 2025-05-19
2025-11-11 00:52:29,630 - INFO - root - Page:5, Index:19, Mamba-Adaptor: State Space Model Adaptor for Visual Recognition, https://arxiv.org/pdf/2505.12685, 2025-05-19
2025-11-11 00:52:29,631 - INFO - root - Page:5, Index:20, Scalable Video-to-Dataset Generation for Cross-Platform Mobile Agents, https://arxiv.org/pdf/2505.12632, 2025-05-18
2025-11-11 00:52:29,631 - INFO - root - Page:5, Index:21, Degradation-Aware Feature Perturbation for All-in-One Image Restoration, https://arxiv.org/pdf/2505.12630, 2025-05-18
2025-11-11 00:52:29,632 - INFO - root - Page:5, Index:22, Guiding Diffusion with Deep Geometric Moments: Balancing Fidelity and Variation, https://arxiv.org/pdf/2505.12486, 2025-05-18
2025-11-11 00:52:29,632 - INFO - root - Page:5, Index:23, Learning to Highlight Audio by Watching Movies, https://arxiv.org/pdf/2505.12154, 2025-05-17
2025-11-11 00:52:29,632 - INFO - root - Page:5, Index:24, Understanding the Capabilities of Molecular Graph Neural Networks in Materials Science Through Multimodal Learning and Physical Context Encoding, https://arxiv.org/pdf/2505.12137, 2025-05-17
2025-11-11 00:52:29,632 - INFO - root - Page:5, Index:25, iSegMan: Interactive Segment-and-Manipulate 3D Gaussians, https://arxiv.org/pdf/2505.11934, 2025-05-17
2025-11-11 00:52:29,634 - INFO - root - Page:5, Index:26, Self-Learning Hyperspectral and Multispectral Image Fusion via Adaptive Residual Guided Subspace Diffusion Model, https://arxiv.org/pdf/2505.11800, 2025-05-16
2025-11-11 00:52:29,634 - INFO - root - Page:5, Index:27, X-Edit: Detecting and Localizing Edits in Images Altered by Text-Guided Diffusion Models, https://arxiv.org/pdf/2505.11753, 2025-05-16
2025-11-11 00:52:29,635 - INFO - root - Page:5, Index:28, MTevent: A Multi-Task Event Camera Dataset for 6D Pose Estimation and Moving Object Detection, https://arxiv.org/pdf/2505.11282, 2025-06-02
2025-11-11 00:52:29,637 - INFO - root - Page:5, Index:29, Imputation-free and Alignment-free: Incomplete Multi-view Clustering Driven by Consensus Semantic Learning, https://arxiv.org/pdf/2505.11182, 2025-05-16
2025-11-11 00:52:29,637 - INFO - root - Page:5, Index:30, MultiLink: Multi-class Structure Recovery via Agglomerative Clustering and Model Selection, https://arxiv.org/pdf/2505.10874, 2025-05-16
2025-11-11 00:52:29,637 - INFO - root - Page:5, Index:31, RefPose: Leveraging Reference Geometric Correspondences for Accurate 6D Pose Estimation of Unseen Objects, https://arxiv.org/pdf/2505.10841, 2025-05-16
2025-11-11 00:52:29,637 - INFO - root - Page:5, Index:32, MoCLIP: Motion-Aware Fine-Tuning and Distillation of CLIP for Human Motion Generation, https://arxiv.org/pdf/2505.10810, 2025-05-15
2025-11-11 00:52:29,639 - INFO - root - Page:5, Index:33, Automated Detection of Salvin's Albatrosses: Improving Deep Learning Tools for Aerial Wildlife Surveys, https://arxiv.org/pdf/2505.10737, 2025-05-15
2025-11-11 00:52:29,641 - INFO - root - Page:5, Index:34, Advancing Multiple Instance Learning with Continual Learning for Whole Slide Imaging, https://arxiv.org/pdf/2505.10649, 2025-05-15
2025-11-11 00:52:29,641 - INFO - root - Page:5, Index:35, Inferring Driving Maps by Deep Learning-based Trail Map Extraction, https://arxiv.org/pdf/2505.10258, 2025-05-15
2025-11-11 00:52:29,643 - INFO - root - Page:5, Index:36, Behind Maya: Building a Multilingual Vision Language Model, https://arxiv.org/pdf/2505.08910, 2025-05-15
2025-11-11 00:52:29,646 - INFO - root - Page:5, Index:37, PosterO: Structuring Layout Trees to Enable Language Models in Generalized Content-Aware Layout Generation, https://arxiv.org/pdf/2505.07843, 2025-05-26
2025-11-11 00:52:29,649 - INFO - root - Page:5, Index:38, Prototype Augmented Hypernetworks for Continual Learning, https://arxiv.org/pdf/2505.07450, 2025-05-16
2025-11-11 00:52:29,652 - INFO - root - Fetching page 7 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=300
2025-11-11 00:52:36,246 - INFO - root - get_all_titles_from_web 
2025-11-11 00:52:36,246 - INFO - root - Page:6, Index:0, Convex Relaxation for Robust Vanishing Point Estimation in Manhattan World, https://arxiv.org/pdf/2505.04788, 2025-06-05
2025-11-11 00:52:36,248 - INFO - root - Page:6, Index:1, S3D: Sketch-Driven 3D Model Generation, https://arxiv.org/pdf/2505.04185, 2025-06-03
2025-11-11 00:52:36,252 - INFO - root - Page:6, Index:2, Generating Synthetic Data via Augmentations for Improved Facial Resemblance in DreamBooth and InstantID, https://arxiv.org/pdf/2505.03557, 2025-07-17
2025-11-11 00:52:36,252 - INFO - root - Page:6, Index:3, CAV-MAE Sync: Improving Contrastive Audio-Visual Mask Autoencoders via Fine-Grained Alignment, https://arxiv.org/pdf/2505.01237, 2025-05-21
2025-11-11 00:52:36,256 - INFO - root - Fetching page 8 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=350
2025-11-11 00:52:42,951 - INFO - root - get_all_titles_from_web 
2025-11-11 00:52:42,951 - INFO - root - Page:7, Index:0, Where's the liability in the Generative Era? Recovery-based Black-Box Detection of AI-Generated Content, https://arxiv.org/pdf/2505.01008, 2025-08-25
2025-11-11 00:52:42,952 - INFO - root - Page:7, Index:1, SpatialLLM: A Compound 3D-Informed Design towards Spatially-Intelligent Large Multimodal Models, https://arxiv.org/pdf/2505.00788, 2025-06-10
2025-11-11 00:52:42,953 - INFO - root - Page:7, Index:2, Prisma: An Open Source Toolkit for Mechanistic Interpretability in Vision and Video, https://arxiv.org/pdf/2504.19475, 2025-06-03
2025-11-11 00:52:42,954 - INFO - root - Page:7, Index:3, SSL4Eco: A Global Seasonal Dataset for Geospatial Foundation Models in Ecology, https://arxiv.org/pdf/2504.18256, 2025-10-20
2025-11-11 00:52:42,954 - INFO - root - Page:7, Index:4, Vision-Language Models Are Not Pragmatically Competent in Referring Expression Generation, https://arxiv.org/pdf/2504.16060, 2025-07-30
2025-11-11 00:52:42,961 - INFO - root - Fetching page 9 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=400
2025-11-11 00:52:49,900 - INFO - root - get_all_titles_from_web 
2025-11-11 00:52:49,909 - INFO - root - Page:8, Index:0, Leveraging Automatic CAD Annotations for Supervised Learning in 3D Scene Understanding, https://arxiv.org/pdf/2504.13580, 2025-05-16
2025-11-11 00:52:49,919 - INFO - root - Page:8, Index:1, CAP-Net: A Unified Network for 6D Pose and Size Estimation of Categorical Articulated Parts from a Single RGB-D Image, https://arxiv.org/pdf/2504.11230, 2025-06-02
2025-11-11 00:52:49,936 - INFO - root - Page:8, Index:2, Video Summarization with Large Language Models, https://arxiv.org/pdf/2504.11199, 2025-06-05
2025-11-11 00:52:49,957 - INFO - root - Page:8, Index:3, R-TPT: Improving Adversarial Robustness of Vision-Language Models through Test-Time Prompt Tuning, https://arxiv.org/pdf/2504.11195, 2025-08-27
2025-11-11 00:52:49,973 - INFO - root - Page:8, Index:4, TerraMesh: A Planetary Mosaic of Multimodal Earth Observation Data, https://arxiv.org/pdf/2504.11172, 2025-08-01
2025-11-11 00:52:49,986 - INFO - root - Page:8, Index:5, Seeing like a Cephalopod: Colour Vision with a Monochrome Event Camera, https://arxiv.org/pdf/2504.10984, 2025-06-06
2025-11-11 00:52:49,994 - INFO - root - Page:8, Index:6, Hearing Anywhere in Any Environment, https://arxiv.org/pdf/2504.10746, 2025-06-04
2025-11-11 00:52:50,007 - INFO - root - Fetching page 10 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=450
2025-11-11 00:52:56,382 - INFO - root - get_all_titles_from_web 
2025-11-11 00:52:56,383 - INFO - root - Page:9, Index:0, Correlative and Discriminative Label Grouping for Multi-Label Visual Prompt Tuning, https://arxiv.org/pdf/2504.09990, 2025-07-09
2025-11-11 00:52:56,383 - INFO - root - Page:9, Index:1, SPICE: A Synergistic, Precise, Iterative, and Customizable Image Editing Workflow, https://arxiv.org/pdf/2504.09697, 2025-10-16
2025-11-11 00:52:56,383 - INFO - root - Page:9, Index:2, Mimic In-Context Learning for Multimodal Tasks, https://arxiv.org/pdf/2504.08851, 2025-05-17
2025-11-11 00:52:56,383 - INFO - root - Page:9, Index:3, Digital Twin Catalog: A Large-Scale Photorealistic 3D Object Digital Twin Dataset, https://arxiv.org/pdf/2504.08541, 2025-05-18
2025-11-11 00:52:56,384 - INFO - root - Page:9, Index:4, MMLA: Multi-Environment, Multi-Species, Low-Altitude Drone Dataset, https://arxiv.org/pdf/2504.07744, 2025-10-22
2025-11-11 00:52:56,384 - INFO - root - Fetching page 11 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=500
2025-11-11 00:53:02,604 - INFO - root - get_all_titles_from_web 
2025-11-11 00:53:02,605 - INFO - root - Page:10, Index:0, PromptHMR: Promptable Human Mesh Recovery, https://arxiv.org/pdf/2504.06397, 2025-05-23
2025-11-11 00:53:02,605 - INFO - root - Page:10, Index:1, SCAM: A Real-World Typographic Robustness Evaluation for Multimodal Foundation Models, https://arxiv.org/pdf/2504.04893, 2025-09-26
2025-11-11 00:53:02,606 - INFO - root - Fetching page 12 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=550
2025-11-11 00:53:09,285 - INFO - root - get_all_titles_from_web 
2025-11-11 00:53:09,286 - INFO - root - Page:11, Index:0, Charm: The Missing Piece in ViT fine-tuning for Image Aesthetic Assessment, https://arxiv.org/pdf/2504.02522, 2025-05-15
2025-11-11 00:53:09,286 - INFO - root - Page:11, Index:1, T*: Re-thinking Temporal Search for Long-Form Video Understanding, https://arxiv.org/pdf/2504.02259, 2025-08-24
2025-11-11 00:53:09,287 - INFO - root - Page:11, Index:2, CoMatcher: Multi-View Collaborative Feature Matching, https://arxiv.org/pdf/2504.01872, 2025-08-20
2025-11-11 00:53:09,287 - INFO - root - Page:11, Index:3, Think Small, Act Big: Primitive Prompt Learning for Lifelong Robot Manipulation, https://arxiv.org/pdf/2504.00420, 2025-06-01
2025-11-11 00:53:09,287 - INFO - root - Fetching page 13 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=600
2025-11-11 00:53:16,159 - INFO - root - get_all_titles_from_web 
2025-11-11 00:53:16,159 - INFO - root - Page:12, Index:0, It's a (Blind) Match! Towards Vision-Language Correspondence without Parallel Data, https://arxiv.org/pdf/2503.24129, 2025-05-29
2025-11-11 00:53:16,159 - INFO - root - Page:12, Index:1, ReferDINO-Plus: 2nd Solution for 4th PVUW MeViS Challenge at CVPR 2025, https://arxiv.org/pdf/2503.23509, 2025-05-29
2025-11-11 00:53:16,161 - INFO - root - Page:12, Index:2, A Unified Image-Dense Annotation Generation Model for Underwater Scenes, https://arxiv.org/pdf/2503.21771, 2025-07-27
2025-11-11 00:53:16,161 - INFO - root - Fetching page 14 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=650
2025-11-11 00:53:22,725 - INFO - root - get_all_titles_from_web 
2025-11-11 00:53:22,726 - INFO - root - Page:13, Index:0, Learning Class Prototypes for Unified Sparse Supervised 3D Object Detection, https://arxiv.org/pdf/2503.21099, 2025-06-13
2025-11-11 00:53:22,727 - INFO - root - Page:13, Index:1, LATTE-MV: Learning to Anticipate Table Tennis Hits from Monocular Videos, https://arxiv.org/pdf/2503.20936, 2025-09-01
2025-11-11 00:53:22,731 - INFO - root - Page:13, Index:2, BizGen: Advancing Article-level Visual Text Rendering for Infographics Generation, https://arxiv.org/pdf/2503.20672, 2025-07-02
2025-11-11 00:53:22,732 - INFO - root - Page:13, Index:3, ITA-MDT: Image-Timestep-Adaptive Masked Diffusion Transformer Framework for Image-Based Virtual Try-On, https://arxiv.org/pdf/2503.20418, 2025-06-01
2025-11-11 00:53:22,734 - INFO - root - Page:13, Index:4, Faster Parameter-Efficient Tuning with Token Redundancy Reduction, https://arxiv.org/pdf/2503.20282, 2025-08-26
2025-11-11 00:53:22,734 - INFO - root - Page:13, Index:5, DINeMo: Learning Neural Mesh Models with no 3D Annotations, https://arxiv.org/pdf/2503.20220, 2025-06-09
2025-11-11 00:53:22,736 - INFO - root - Page:13, Index:6, Scaling Vision Pre-Training to 4K Resolution, https://arxiv.org/pdf/2503.19903, 2025-08-03
2025-11-11 00:53:22,737 - INFO - root - Page:13, Index:7, GENIUS: A Generative Framework for Universal Multimodal Search, https://arxiv.org/pdf/2503.19868, 2025-06-05
2025-11-11 00:53:22,738 - INFO - root - Fetching page 15 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=700
2025-11-11 00:53:29,330 - INFO - root - get_all_titles_from_web 
2025-11-11 00:53:29,330 - INFO - root - Page:14, Index:0, Galaxy Walker: Geometry-aware VLMs For Galaxy-scale Understanding, https://arxiv.org/pdf/2503.18578, 2025-05-25
2025-11-11 00:53:29,331 - INFO - root - Page:14, Index:1, LookCloser: Frequency-aware Radiance Field for Tiny-Detail Scene, https://arxiv.org/pdf/2503.18513, 2025-07-29
2025-11-11 00:53:29,331 - INFO - root - Fetching page 16 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=750
2025-11-11 00:53:35,662 - INFO - root - get_all_titles_from_web 
2025-11-11 00:53:35,662 - INFO - root - Page:15, Index:0, LoTUS: Large-Scale Machine Unlearning with a Taste of Uncertainty, https://arxiv.org/pdf/2503.18314, 2025-05-29
2025-11-11 00:53:35,662 - INFO - root - Page:15, Index:1, MammAlps: A multi-view video behavior monitoring dataset of wild mammals in the Swiss Alps, https://arxiv.org/pdf/2503.18223, 2025-06-04
2025-11-11 00:53:35,663 - INFO - root - Page:15, Index:2, Progressive Prompt Detailing for Improved Alignment in Text-to-Image Generative Models, https://arxiv.org/pdf/2503.17794, 2025-05-30
2025-11-11 00:53:35,663 - INFO - root - Page:15, Index:3, CountLLM: Towards Generalizable Repetitive Action Counting via Large Language Model, https://arxiv.org/pdf/2503.17690, 2025-06-29
2025-11-11 00:53:35,663 - INFO - root - Page:15, Index:4, TaoAvatar: Real-Time Lifelike Full-Body Talking Avatars for Augmented Reality via 3D Gaussian Splatting, https://arxiv.org/pdf/2503.17032, 2025-07-23
2025-11-11 00:53:35,663 - INFO - root - Page:15, Index:5, Generalized Few-shot 3D Point Cloud Segmentation with Vision-Language Model, https://arxiv.org/pdf/2503.16282, 2025-05-20
2025-11-11 00:53:35,664 - INFO - root - Fetching page 17 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=800
2025-11-11 00:53:43,084 - INFO - root - get_all_titles_from_web 
2025-11-11 00:53:43,085 - INFO - root - Page:16, Index:0, High Temporal Consistency through Semantic Similarity Propagation in Semi-Supervised Video Semantic Segmentation for Autonomous Flight, https://arxiv.org/pdf/2503.15676, 2025-06-26
2025-11-11 00:53:43,086 - INFO - root - Page:16, Index:1, DPFlow: Adaptive Optical Flow Estimation with a Dual-Pyramid Framework, https://arxiv.org/pdf/2503.14880, 2025-09-29
2025-11-11 00:53:43,086 - INFO - root - Fetching page 18 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=850
2025-11-11 00:53:50,096 - INFO - root - get_all_titles_from_web 
2025-11-11 00:53:50,115 - INFO - root - Page:17, Index:0, From Head to Tail: Towards Balanced Representation in Large Vision-Language Models through Adaptive Data Calibration, https://arxiv.org/pdf/2503.12821, 2025-05-29
2025-11-11 00:53:50,116 - INFO - root - Page:17, Index:1, MambaIC: State Space Models for High-Performance Learned Image Compression, https://arxiv.org/pdf/2503.12461, 2025-08-22
2025-11-11 00:53:50,117 - INFO - root - Page:17, Index:2, Localized Concept Erasure for Text-to-Image Diffusion Models Using Training-Free Gated Low-Rank Adaptation, https://arxiv.org/pdf/2503.12356, 2025-07-09
2025-11-11 00:53:50,117 - INFO - root - Page:17, Index:3, TASTE-Rob: Advancing Video Generation of Task-Oriented Hand-Object Interaction for Generalizable Robotic Manipulation, https://arxiv.org/pdf/2503.11423, 2025-06-05
2025-11-11 00:53:50,118 - INFO - root - Page:17, Index:4, Panopticon: Advancing Any-Sensor Foundation Models for Earth Observation, https://arxiv.org/pdf/2503.10845, 2025-08-01
2025-11-11 00:53:50,119 - INFO - root - Page:17, Index:5, Transformers without Normalization, https://arxiv.org/pdf/2503.10622, 2025-06-14
2025-11-11 00:53:50,119 - INFO - root - Page:17, Index:6, dFLMoE: Decentralized Federated Learning via Mixture of Experts for Medical Data Analysis, https://arxiv.org/pdf/2503.10412, 2025-05-19
2025-11-11 00:53:50,120 - INFO - root - Fetching page 19 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=900
2025-11-11 00:53:56,899 - INFO - root - get_all_titles_from_web 
2025-11-11 00:53:56,900 - INFO - root - Page:18, Index:0, Project-Probe-Aggregate: Efficient Fine-Tuning for Group Robustness, https://arxiv.org/pdf/2503.09487, 2025-08-26
2025-11-11 00:53:56,900 - INFO - root - Page:18, Index:1, VLog: Video-Language Models by Generative Retrieval of Narration Vocabulary, https://arxiv.org/pdf/2503.09402, 2025-06-09
2025-11-11 00:53:56,900 - INFO - root - Fetching page 20 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=950
2025-11-11 00:54:04,043 - INFO - root - get_all_titles_from_web 
2025-11-11 00:54:04,044 - INFO - root - Page:19, Index:0, Escaping Plato's Cave: Towards the Alignment of 3D and Text Latent Spaces, https://arxiv.org/pdf/2503.05283, 2025-06-04
2025-11-11 00:54:04,044 - INFO - root - Page:19, Index:1, FluidNexus: 3D Fluid Reconstruction and Prediction from a Single Video, https://arxiv.org/pdf/2503.04720, 2025-07-09
2025-11-11 00:54:04,044 - INFO - root - Page:19, Index:2, Question-Aware Gaussian Experts for Audio-Visual Question Answering, https://arxiv.org/pdf/2503.04459, 2025-06-11
2025-11-11 00:54:04,045 - INFO - root - Page:19, Index:3, Q-Eval-100K: Evaluating Visual Quality and Alignment Level for Text-to-Vision Content, https://arxiv.org/pdf/2503.02357, 2025-06-15
2025-11-11 00:54:04,045 - INFO - root - Fetching page 21 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=1000
2025-11-11 00:54:11,758 - INFO - root - get_all_titles_from_web 
2025-11-11 00:54:11,758 - INFO - root - Page:20, Index:0, Data Distributional Properties As Inductive Bias for Systematic Generalization, https://arxiv.org/pdf/2502.20499, 2025-06-17
2025-11-11 00:54:11,758 - INFO - root - Page:20, Index:1, Knowledge Bridger: Towards Training-free Missing Modality Completion, https://arxiv.org/pdf/2502.19834, 2025-06-17
2025-11-11 00:54:11,758 - INFO - root - Fetching page 22 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=1050
2025-11-11 00:54:18,063 - INFO - root - get_all_titles_from_web 
2025-11-11 00:54:18,064 - INFO - root - Page:21, Index:0, MALT Diffusion: Memory-Augmented Latent Transformers for Any-Length Video Generation, https://arxiv.org/pdf/2502.12632, 2025-07-08
2025-11-11 00:54:18,064 - INFO - root - Page:21, Index:1, ILIAS: Instance-Level Image retrieval At Scale, https://arxiv.org/pdf/2502.11748, 2025-06-23
2025-11-11 00:54:18,065 - INFO - root - Page:21, Index:2, Distraction is All You Need for Multimodal Large Language Model Jailbreaking, https://arxiv.org/pdf/2502.10794, 2025-06-16
2025-11-11 00:54:18,065 - INFO - root - Page:21, Index:3, Spatial457: A Diagnostic Benchmark for 6D Spatial Reasoning of Large Multimodal Models, https://arxiv.org/pdf/2502.08636, 2025-06-08
2025-11-11 00:54:18,065 - INFO - root - Page:21, Index:4, TRAVEL: Training-Free Retrieval and Alignment for Vision-and-Language Navigation, https://arxiv.org/pdf/2502.07306, 2025-06-09
2025-11-11 00:54:18,066 - INFO - root - Page:21, Index:5, DiTASK: Multi-Task Fine-Tuning with Diffeomorphic Transformations, https://arxiv.org/pdf/2502.06029, 2025-06-01
2025-11-11 00:54:18,066 - INFO - root - Page:21, Index:6, ConceptAttention: Diffusion Transformers Learn Highly Interpretable Features, https://arxiv.org/pdf/2502.04320, 2025-07-01
2025-11-11 00:54:18,071 - INFO - root - Page:21, Index:7, GCE-Pose: Global Context Enhancement for Category-level Object Pose Estimation, https://arxiv.org/pdf/2502.04293, 2025-06-24
2025-11-11 00:54:18,072 - INFO - root - Page:21, Index:8, Calibrated Multi-Preference Optimization for Aligning Diffusion Models, https://arxiv.org/pdf/2502.02588, 2025-09-26
2025-11-11 00:54:18,074 - INFO - root - Page:21, Index:9, Instruct-4DGS: Efficient Dynamic Scene Editing via 4D Gaussian-based Static-Dynamic Separation, https://arxiv.org/pdf/2502.02091, 2025-07-01
2025-11-11 00:54:18,074 - INFO - root - Page:21, Index:10, Low-Resource Video Super-Resolution using Memory, Wavelets, and Deformable Convolutions, https://arxiv.org/pdf/2502.01816, 2025-06-19
2025-11-11 00:54:18,075 - INFO - root - Page:21, Index:11, Bridging Text and Crystal Structures: Literature-driven Contrastive Learning for Materials Science, https://arxiv.org/pdf/2501.12919, 2025-06-18
2025-11-11 00:54:18,075 - INFO - root - Page:21, Index:12, T2ISafety: Benchmark for Assessing Fairness, Toxicity, and Privacy in Image Generation, https://arxiv.org/pdf/2501.12612, 2025-07-25
2025-11-11 00:54:18,076 - INFO - root - Page:21, Index:13, Fine-Grained Image-Text Correspondence with Cost Aggregation for Open-Vocabulary Part Segmentation, https://arxiv.org/pdf/2501.09688, 2025-08-08
2025-11-11 00:54:18,076 - INFO - root - Fetching page 23 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=1100
2025-11-11 00:54:24,555 - INFO - root - get_all_titles_from_web 
2025-11-11 00:54:24,557 - INFO - root - Page:22, Index:0, Bias for Action: Video Implicit Neural Representations with Bias Modulation, https://arxiv.org/pdf/2501.09277, 2025-06-06
2025-11-11 00:54:24,559 - INFO - root - Page:22, Index:1, MonSter++: Unified Stereo Matching, Multi-view Stereo, and Real-time Stereo with Monodepth Priors, https://arxiv.org/pdf/2501.08643, 2025-09-25
2025-11-11 00:54:24,559 - INFO - root - Page:22, Index:2, Go-with-the-Flow: Motion-Controllable Video Diffusion Models Using Real-Time Warped Noise, https://arxiv.org/pdf/2501.08331, 2025-08-06
2025-11-11 00:54:24,559 - INFO - root - Page:22, Index:3, Nonisotropic Gaussian Diffusion for Realistic 3D Human Motion Prediction, https://arxiv.org/pdf/2501.06035, 2025-07-08
2025-11-11 00:54:24,559 - INFO - root - Page:22, Index:4, Discovering Hidden Visual Concepts Beyond Linguistic Input in Infant Learning, https://arxiv.org/pdf/2501.05205, 2025-06-13
2025-11-11 00:54:24,560 - INFO - root - Page:22, Index:5, PERSE: Personalized 3D Generative Avatars from A Single Portrait, https://arxiv.org/pdf/2412.21206, 2025-09-28
2025-11-11 00:54:24,560 - INFO - root - Page:22, Index:6, MaskGaussian: Adaptive 3D Gaussian Representation from Probabilistic Masks, https://arxiv.org/pdf/2412.20522, 2025-06-14
2025-11-11 00:54:24,560 - INFO - root - Page:22, Index:7, SimLTD: Simple Supervised and Semi-Supervised Long-Tailed Object Detection, https://arxiv.org/pdf/2412.20047, 2025-06-09
2025-11-11 00:54:24,560 - INFO - root - Page:22, Index:8, Conditional Balance: Improving Multi-Conditioning Trade-Offs in Image Generation, https://arxiv.org/pdf/2412.19853, 2025-08-03
2025-11-11 00:54:24,560 - INFO - root - Fetching page 24 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=1150
2025-11-11 00:54:31,036 - INFO - root - get_all_titles_from_web 
2025-11-11 00:54:31,037 - INFO - root - Page:23, Index:0, CoCoGaussian: Leveraging Circle of Confusion for Gaussian Splatting from Defocused Images, https://arxiv.org/pdf/2412.16028, 2025-05-15
2025-11-11 00:54:31,037 - INFO - root - Page:23, Index:1, EnergyMoGen: Compositional Human Motion Generation with Energy-Based Diffusion Model in Latent Space, https://arxiv.org/pdf/2412.14706, 2025-06-04
2025-11-11 00:54:31,038 - INFO - root - Page:23, Index:2, DarkIR: Robust Low-Light Image Restoration, https://arxiv.org/pdf/2412.13443, 2025-10-14
2025-11-11 00:54:31,038 - INFO - root - Page:23, Index:3, FastVLM: Efficient Vision Encoding for Vision Language Models, https://arxiv.org/pdf/2412.13303, 2025-05-15
2025-11-11 00:54:31,038 - INFO - root - Page:23, Index:4, Real-time Free-view Human Rendering from Sparse-view RGB Videos using Double Unprojected Textures, https://arxiv.org/pdf/2412.13183, 2025-06-20
2025-11-11 00:54:31,038 - INFO - root - Page:23, Index:5, CondiMen: Conditional Multi-Person Mesh Recovery, https://arxiv.org/pdf/2412.13058, 2025-06-04
2025-11-11 00:54:31,039 - INFO - root - Page:23, Index:6, MASt3R-SLAM: Real-Time Dense SLAM with 3D Reconstruction Priors, https://arxiv.org/pdf/2412.12392, 2025-06-02
2025-11-11 00:54:31,040 - INFO - root - Page:23, Index:7, DynamicScaler: Seamless and Scalable Video Generation for Panoramic Scenes, https://arxiv.org/pdf/2412.11100, 2025-10-04
2025-11-11 00:54:31,040 - INFO - root - Page:23, Index:8, SnapGen-V: Generating a Five-Second Video within Five Seconds on a Mobile Device, https://arxiv.org/pdf/2412.10494, 2025-06-09
2025-11-11 00:54:31,040 - INFO - root - Page:23, Index:9, Mr. DETR++: Instructive Multi-Route Training for Detection Transformers with Mixture-of-Experts, https://arxiv.org/pdf/2412.10028, 2025-06-26
2025-11-11 00:54:31,041 - INFO - root - Page:23, Index:10, LinGen: Towards High-Resolution Minute-Length Text-to-Video Generation with Linear Computational Complexity, https://arxiv.org/pdf/2412.09856, 2025-05-24
2025-11-11 00:54:31,041 - INFO - root - Page:23, Index:11, Gaze-LLE: Gaze Target Estimation via Large-Scale Learned Encoders, https://arxiv.org/pdf/2412.09586, 2025-06-03
2025-11-11 00:54:31,041 - INFO - root - Fetching page 25 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=1200
2025-11-11 00:54:38,876 - INFO - root - get_all_titles_from_web 
2025-11-11 00:54:38,877 - INFO - root - Page:24, Index:0, From Slow Bidirectional to Fast Autoregressive Video Diffusion Models, https://arxiv.org/pdf/2412.07772, 2025-09-23
2025-11-11 00:54:38,878 - INFO - root - Page:24, Index:1, Rate-In: Information-Driven Adaptive Dropout Rates for Improved Inference-Time Uncertainty Estimation, https://arxiv.org/pdf/2412.07169, 2025-06-03
2025-11-11 00:54:38,878 - INFO - root - Page:24, Index:2, FIRE: Robust Detection of Diffusion-Generated Images via Frequency-Guided Reconstruction Error, https://arxiv.org/pdf/2412.07140, 2025-11-03
2025-11-11 00:54:38,878 - INFO - root - Page:24, Index:3, Birth and Death of a Rose, https://arxiv.org/pdf/2412.05278, 2025-06-05
2025-11-11 00:54:38,879 - INFO - root - Page:24, Index:4, DualPM: Dual Posed-Canonical Point Maps for 3D Shape and Pose Reconstruction, https://arxiv.org/pdf/2412.04464, 2025-08-14
2025-11-11 00:54:38,879 - INFO - root - Page:24, Index:5, SeeGround: See and Ground for Zero-Shot Open-Vocabulary 3D Visual Grounding, https://arxiv.org/pdf/2412.04383, 2025-05-29
2025-11-11 00:54:38,879 - INFO - root - ------------------------------------------------------------------------------------------------------------------------
2025-11-11 00:54:38,899 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\CVPR 2025\Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness.pdf
2025-11-11 00:54:38,907 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\CVPR 2025\OmniTrack++_ Omnidirectional Multi-Object Tracking by Learning Large-FoV Traject.pdf
2025-11-11 00:54:38,909 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\CVPR 2025\NeuCo-Bench_ A Novel Benchmark Framework for Neural Embeddings in Earth Observat.pdf
2025-11-11 00:54:38,910 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\CVPR 2025\NTIRE 2025 Challenge on Low Light Image Enhancement_ Methods and Results.pdf
2025-11-11 00:54:38,911 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\CVPR 2025\Class Prototypes based Contrastive Learning for Classifying Multi-Label and Fine.pdf
2025-11-11 00:54:38,913 - INFO - root - 跳过已处理论文 Learning to Seek Evidence: A Verifiable Reasoning Agent with Causal Faithfulness Analysis：d:\ChatPaper\academic Papers\CVPR 2025\Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness.pdf
2025-11-11 00:54:38,914 - INFO - root - 跳过已处理论文 OmniTrack++: Omnidirectional Multi-Object Tracking by Learning Large-FoV Trajectory Feedback：d:\ChatPaper\academic Papers\CVPR 2025\OmniTrack++_ Omnidirectional Multi-Object Tracking by Learning Large-FoV Traject.pdf
2025-11-11 00:54:38,914 - INFO - root - 跳过已处理论文 NeuCo-Bench: A Novel Benchmark Framework for Neural Embeddings in Earth Observation：d:\ChatPaper\academic Papers\CVPR 2025\NeuCo-Bench_ A Novel Benchmark Framework for Neural Embeddings in Earth Observat.pdf
2025-11-11 00:54:38,915 - INFO - root - 正在总结论文 4/5: NTIRE 2025 Challenge on Low Light Image Enhancement: Methods and Results
2025-11-11 00:57:12,888 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-11 00:57:12,891 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-11 00:57:12,893 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-11 00:57:13,950 - INFO - root - LLMClientManager: 指定使用客户端: Gemini
2025-11-11 00:57:14,646 - INFO - root - GeminiClient: trying model models/gemini-2.5-flash
2025-11-11 00:57:19,087 - INFO - root - GeminiClient: initialized model gemini-2.5-flash
2025-11-11 00:57:19,087 - INFO - root - LLMClientManager: Gemini 客户端初始化成功
2025-11-11 00:57:19,087 - INFO - root - LLMClientManager: switched to Gemini client
2025-11-11 00:57:19,088 - INFO - root - 已手动切换到 LLM 客户端: Gemini
2025-11-11 00:57:19,088 - INFO - root - 使用 LLM 模型: gemini-2.5-flash
2025-11-11 00:57:19,090 - INFO - root - 可用客户端: ['Gemini']
2025-11-11 00:57:19,091 - INFO - root - === 运行配置 ===
2025-11-11 00:57:19,091 - INFO - root - 处理模式: arxiv在线搜索
2025-11-11 00:57:19,092 - INFO - root - 关键词: CVPR
2025-11-11 00:57:19,093 - INFO - root - 查询: CVPR 2025
2025-11-11 00:57:19,095 - INFO - root - 排序: None
2025-11-11 00:57:19,097 - INFO - root - 最近天数: 180
2025-11-11 00:57:19,105 - INFO - root - 最大处理数量: 5
2025-11-11 00:57:19,106 - INFO - root - 保存图片: 是
2025-11-11 00:57:19,108 - INFO - root - 输出语言: 中文
2025-11-11 00:57:19,108 - INFO - root - 强制重新处理: 否
2025-11-11 00:57:19,109 - INFO - root - ====================
2025-11-11 00:57:19,109 - INFO - root - 使用 arXiv 搜索模式（通过 chat_arxiv 模块获取）
2025-11-11 00:57:19,111 - INFO - root - Fetching page 1 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50
2025-11-11 00:57:25,835 - INFO - root - get_all_titles_from_web 
2025-11-11 00:57:25,836 - INFO - root - Page:0, Index:0, Learning to Seek Evidence: A Verifiable Reasoning Agent with Causal Faithfulness Analysis, https://arxiv.org/pdf/2511.01425, 2025-11-03
2025-11-11 00:57:25,836 - INFO - root - Page:0, Index:1, OmniTrack++: Omnidirectional Multi-Object Tracking by Learning Large-FoV Trajectory Feedback, https://arxiv.org/pdf/2511.00510, 2025-11-01
2025-11-11 00:57:25,838 - INFO - root - Page:0, Index:2, NeuCo-Bench: A Novel Benchmark Framework for Neural Embeddings in Earth Observation, https://arxiv.org/pdf/2510.17914, 2025-10-19
2025-11-11 00:57:25,838 - INFO - root - Page:0, Index:3, NTIRE 2025 Challenge on Low Light Image Enhancement: Methods and Results, https://arxiv.org/pdf/2510.13670, 2025-10-15
2025-11-11 00:57:25,838 - INFO - root - Page:0, Index:4, Class Prototypes based Contrastive Learning for Classifying Multi-Label and Fine-Grained Educational Videos, https://arxiv.org/pdf/2510.11204, 2025-10-13
2025-11-11 00:57:25,839 - INFO - root - Page:0, Index:5, MIMO: A medical vision language model with visual referring multimodal input and pixel grounding multimodal output, https://arxiv.org/pdf/2510.10011, 2025-10-11
2025-11-11 00:57:25,839 - INFO - root - Page:0, Index:6, Vision Language Models: A Survey of 26K Papers, https://arxiv.org/pdf/2510.09586, 2025-10-10
2025-11-11 00:57:25,839 - INFO - root - Page:0, Index:7, DiT-VTON: Diffusion Transformer Framework for Unified Multi-Category Virtual Try-On and Virtual Try-All with Integrated Image Editing, https://arxiv.org/pdf/2510.04797, 2025-10-03
2025-11-11 00:57:25,841 - INFO - root - Page:0, Index:8, PatchVSR: Breaking Video Diffusion Resolution Limits with Patch-wise Video Super-Resolution, https://arxiv.org/pdf/2509.26025, 2025-09-30
2025-11-11 00:57:25,841 - INFO - root - Page:0, Index:9, FreqDebias: Towards Generalizable Deepfake Detection via Consistency-Driven Frequency Debiasing, https://arxiv.org/pdf/2509.22412, 2025-09-26
2025-11-11 00:57:25,841 - INFO - root - Page:0, Index:10, A Mutual Learning Method for Salient Object Detection with intertwined Multi-Supervision--Revised, https://arxiv.org/pdf/2509.21363, 2025-09-21
2025-11-11 00:57:25,842 - INFO - root - Page:0, Index:11, InstructVTON: Optimal Auto-Masking and Natural-Language-Guided Interactive Style Control for Inpainting-Based Virtual Try-On, https://arxiv.org/pdf/2509.20524, 2025-09-24
2025-11-11 00:57:25,843 - INFO - root - Page:0, Index:12, Efficient Encoder-Free Pose Conditioning and Pose Control for Virtual Try-On, https://arxiv.org/pdf/2509.20343, 2025-09-24
2025-11-11 00:57:25,844 - INFO - root - Page:0, Index:13, The Photographer Eye: Teaching Multimodal Large Language Models to Understand Image Aesthetics like Photographers, https://arxiv.org/pdf/2509.18582, 2025-10-22
2025-11-11 00:57:25,846 - INFO - root - Page:0, Index:14, ENSAM: an efficient foundation model for interactive segmentation of 3D medical images, https://arxiv.org/pdf/2509.15874, 2025-09-19
2025-11-11 00:57:25,846 - INFO - root - Page:0, Index:15, DEFT-VTON: Efficient Virtual Try-On with Consistent Generalised H-Transform, https://arxiv.org/pdf/2509.13506, 2025-09-16
2025-11-11 00:57:25,847 - INFO - root - Page:0, Index:16, Weakly and Self-Supervised Class-Agnostic Motion Prediction for Autonomous Driving, https://arxiv.org/pdf/2509.13116, 2025-09-16
2025-11-11 00:57:25,850 - INFO - root - Page:0, Index:17, Domain-Adaptive Pretraining Improves Primate Behavior Recognition, https://arxiv.org/pdf/2509.12193, 2025-09-15
2025-11-11 00:57:25,850 - INFO - root - Page:0, Index:18, The System Description of CPS Team for Track on Driving with Language of CVPR 2024 Autonomous Grand Challenge, https://arxiv.org/pdf/2509.11071, 2025-09-13
2025-11-11 00:57:25,850 - INFO - root - Page:0, Index:19, An HMM-based framework for identity-aware long-term multi-object tracking from sparse and uncertain identification: use case on long-term tracking in livestock, https://arxiv.org/pdf/2509.09962, 2025-09-12
2025-11-11 00:57:25,852 - INFO - root - Page:0, Index:20, InterAct: Advancing Large-Scale Versatile 3D Human-Object Interaction Generation, https://arxiv.org/pdf/2509.09555, 2025-09-11
2025-11-11 00:57:25,852 - INFO - root - Page:0, Index:21, Geospatial Foundational Embedder: Top-1 Winning Solution on EarthVision Embed2Scale Challenge (CVPR 2025), https://arxiv.org/pdf/2509.06993, 2025-09-03
2025-11-11 00:57:25,853 - INFO - root - Page:0, Index:22, 2nd Place Solution for CVPR2024 E2E Challenge: End-to-End Autonomous Driving Using Vision Language Model, https://arxiv.org/pdf/2509.02659, 2025-09-02
2025-11-11 00:57:25,855 - INFO - root - Page:0, Index:23, Unsupervised Training of Vision Transformers with Synthetic Negatives, https://arxiv.org/pdf/2509.02024, 2025-09-02
2025-11-11 00:57:25,860 - INFO - root - Page:0, Index:24, MV-SSM: Multi-View State Space Modeling for 3D Human Pose Estimation, https://arxiv.org/pdf/2509.00649, 2025-08-30
2025-11-11 00:57:25,860 - INFO - root - Page:0, Index:25, CryptoFace: End-to-End Encrypted Face Recognition, https://arxiv.org/pdf/2509.00332, 2025-08-29
2025-11-11 00:57:25,860 - INFO - root - Page:0, Index:26, ControlEchoSynth: Boosting Ejection Fraction Estimation Models via Controlled Video Diffusion, https://arxiv.org/pdf/2508.17631, 2025-08-26
2025-11-11 00:57:25,860 - INFO - root - Page:0, Index:27, Explain Before You Answer: A Survey on Compositional Visual Reasoning, https://arxiv.org/pdf/2508.17298, 2025-08-27
2025-11-11 00:57:25,861 - INFO - root - Page:0, Index:28, Investigating Different Geo Priors for Image Classification, https://arxiv.org/pdf/2508.15946, 2025-08-21
2025-11-11 00:57:25,861 - INFO - root - Page:0, Index:29, Towards Source-Free Machine Unlearning, https://arxiv.org/pdf/2508.15127, 2025-08-20
2025-11-11 00:57:25,861 - INFO - root - Page:0, Index:30, MR6D: Benchmarking 6D Pose Estimation for Mobile Robots, https://arxiv.org/pdf/2508.13775, 2025-08-19
2025-11-11 00:57:25,862 - INFO - root - Page:0, Index:31, Calibrating Biased Distribution in VFM-derived Latent Space via Cross-Domain Geometric Consistency, https://arxiv.org/pdf/2508.13518, 2025-08-19
2025-11-11 00:57:25,862 - INFO - root - Page:0, Index:32, SIS-Challenge: Event-based Spatio-temporal Instance Segmentation Challenge at the CVPR 2025 Event-based Vision Workshop, https://arxiv.org/pdf/2508.12813, 2025-08-18
2025-11-11 00:57:25,862 - INFO - root - Page:0, Index:33, Multi-Level Knowledge Distillation and Dynamic Self-Supervised Learning for Continual Learning, https://arxiv.org/pdf/2508.12692, 2025-08-22
2025-11-11 00:57:25,862 - INFO - root - Page:0, Index:34, Stochastic-based Patch Filtering for Few-Shot Learning, https://arxiv.org/pdf/2508.10066, 2025-08-13
2025-11-11 00:57:25,863 - INFO - root - Page:0, Index:35, Slot Attention-based Feature Filtering for Few-Shot Learning, https://arxiv.org/pdf/2508.09699, 2025-08-13
2025-11-11 00:57:25,863 - INFO - root - Page:0, Index:36, Comparison Reveals Commonality: Customized Image Generation through Contrastive Inversion, https://arxiv.org/pdf/2508.07755, 2025-08-11
2025-11-11 00:57:25,864 - INFO - root - Page:0, Index:37, SLRTP2025 Sign Language Production Challenge: Methodology, Results, and Future Work, https://arxiv.org/pdf/2508.06951, 2025-08-09
2025-11-11 00:57:25,864 - INFO - root - Page:0, Index:38, Exploring Fairness across Fine-Grained Attributes in Large Vision-Language Models, https://arxiv.org/pdf/2508.03079, 2025-08-05
2025-11-11 00:57:25,864 - INFO - root - Page:0, Index:39, Devil is in the Detail: Towards Injecting Fine Details of Image Prompt in Image Generation via Conflict-free Guidance and Stratified Attention, https://arxiv.org/pdf/2508.02004, 2025-08-03
2025-11-11 00:57:25,865 - INFO - root - Page:0, Index:40, IAUNet: Instance-Aware U-Net, https://arxiv.org/pdf/2508.01928, 2025-08-03
2025-11-11 00:57:25,865 - INFO - root - Page:0, Index:41, Gaussian Splatting Feature Fields for Privacy-Preserving Visual Localization, https://arxiv.org/pdf/2507.23569, 2025-08-26
2025-11-11 00:57:25,867 - INFO - root - Page:0, Index:42, From Scan to Action: Leveraging Realistic Scans for Embodied Scene Understanding, https://arxiv.org/pdf/2507.17585, 2025-07-23
2025-11-11 00:57:25,867 - INFO - root - Page:0, Index:43, LEAD: Exploring Logit Space Evolution for Model Selection, https://arxiv.org/pdf/2507.14559, 2025-07-19
2025-11-11 00:57:25,867 - INFO - root - Page:0, Index:44, HeCoFuse: Cross-Modal Complementary V2X Cooperative Perception with Heterogeneous Sensors, https://arxiv.org/pdf/2507.13677, 2025-07-18
2025-11-11 00:57:25,868 - INFO - root - Page:0, Index:45, OmniVec2 -- A Novel Transformer based Network for Large Scale Multimodal and Multitask Learning, https://arxiv.org/pdf/2507.13364, 2025-07-06
2025-11-11 00:57:25,868 - INFO - root - Page:0, Index:46, A Training-Free, Task-Agnostic Framework for Enhancing MLLM Performance on High-Resolution Images, https://arxiv.org/pdf/2507.10202, 2025-07-14
2025-11-11 00:57:25,868 - INFO - root - Page:0, Index:47, Quantum Federated Learning for Multimodal Data: A Modality-Agnostic Approach, https://arxiv.org/pdf/2507.08217, 2025-07-10
2025-11-11 00:57:25,869 - INFO - root - Page:0, Index:48, CuriosAI Submission to the EgoExo4D Proficiency Estimation Challenge 2025, https://arxiv.org/pdf/2507.08022, 2025-07-08
2025-11-11 00:57:25,869 - INFO - root - Page:0, Index:49, Rethinking Query-based Transformer for Continual Image Segmentation, https://arxiv.org/pdf/2507.07831, 2025-07-10
2025-11-11 00:57:25,869 - INFO - root - Fetching page 2 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=50
2025-11-11 00:57:32,170 - INFO - root - get_all_titles_from_web 
2025-11-11 00:57:32,170 - INFO - root - Page:1, Index:0, Scalable and Realistic Virtual Try-on Application for Foundation Makeup with Kubelka-Munk Theory, https://arxiv.org/pdf/2507.07333, 2025-07-09
2025-11-11 00:57:32,171 - INFO - root - Page:1, Index:1, Free on the Fly: Enhancing Flexibility in Test-Time Adaptation with Online EM, https://arxiv.org/pdf/2507.06973, 2025-07-09
2025-11-11 00:57:32,171 - INFO - root - Page:1, Index:2, Adaptive Part Learning for Fine-Grained Generalized Category Discovery: A Plug-and-Play Enhancement, https://arxiv.org/pdf/2507.06928, 2025-07-09
2025-11-11 00:57:32,171 - INFO - root - Page:1, Index:3, Grounded Gesture Generation: Language, Motion, and Space, https://arxiv.org/pdf/2507.04522, 2025-07-06
2025-11-11 00:57:32,172 - INFO - root - Page:1, Index:4, Comprehensive Information Bottleneck for Unveiling Universal Attribution to Interpret Vision Transformers, https://arxiv.org/pdf/2507.04388, 2025-07-06
2025-11-11 00:57:32,172 - INFO - root - Page:1, Index:5, ZERO: Industry-ready Vision Foundation Model with Multi-modal Prompts, https://arxiv.org/pdf/2507.04270, 2025-11-07
2025-11-11 00:57:32,172 - INFO - root - Page:1, Index:6, Beyond Accuracy: Metrics that Uncover What Makes a 'Good' Visual Descriptor, https://arxiv.org/pdf/2507.03542, 2025-07-08
2025-11-11 00:57:32,172 - INFO - root - Page:1, Index:7, ConceptMix++: Leveling the Playing Field in Text-to-Image Benchmarking via Iterative Prompt Optimization, https://arxiv.org/pdf/2507.03275, 2025-07-03
2025-11-11 00:57:32,173 - INFO - root - Page:1, Index:8, APT: Adaptive Personalized Training for Diffusion Models with Limited Data, https://arxiv.org/pdf/2507.02687, 2025-07-03
2025-11-11 00:57:32,173 - INFO - root - Page:1, Index:9, DreamComposer++: Empowering Diffusion Models with Multi-View Conditions for 3D Content Generation, https://arxiv.org/pdf/2507.02299, 2025-07-03
2025-11-11 00:57:32,173 - INFO - root - Page:1, Index:10, Soft Self-labeling and Potts Relaxations for Weakly-Supervised Segmentation, https://arxiv.org/pdf/2507.01721, 2025-07-02
2025-11-11 00:57:32,173 - INFO - root - Page:1, Index:11, Interpolation-Based Event Visual Data Filtering Algorithms, https://arxiv.org/pdf/2507.01557, 2025-07-02
2025-11-11 00:57:32,174 - INFO - root - Page:1, Index:12, AVC-DPO: Aligned Video Captioning via Direct Preference Optimization, https://arxiv.org/pdf/2507.01492, 2025-07-02
2025-11-11 00:57:32,174 - INFO - root - Page:1, Index:13, NN-Former: Rethinking Graph Structure in Neural Architecture Representation, https://arxiv.org/pdf/2507.00880, 2025-07-01
2025-11-11 00:57:32,174 - INFO - root - Page:1, Index:14, Instant Particle Size Distribution Measurement Using CNNs Trained on Synthetic Data, https://arxiv.org/pdf/2507.00822, 2025-07-01
2025-11-11 00:57:32,175 - INFO - root - Page:1, Index:15, Moment Sampling in Video LLMs for Long-Form Video QA, https://arxiv.org/pdf/2507.00033, 2025-06-17
2025-11-11 00:57:32,175 - INFO - root - Page:1, Index:16, Revisiting Audio-Visual Segmentation with Vision-Centric Transformer, https://arxiv.org/pdf/2506.23623, 2025-06-30
2025-11-11 00:57:32,175 - INFO - root - Page:1, Index:17, MTADiffusion: Mask Text Alignment Diffusion Model for Object Inpainting, https://arxiv.org/pdf/2506.23482, 2025-06-29
2025-11-11 00:57:32,176 - INFO - root - Page:1, Index:18, Benchmarking Generalizable Bimanual Manipulation: RoboTwin Dual-Arm Collaboration Challenge at CVPR 2025 MEIS Workshop, https://arxiv.org/pdf/2506.23351, 2025-07-02
2025-11-11 00:57:32,177 - INFO - root - Page:1, Index:19, Prompting without Panic: Attribute-aware, Zero-shot, Test-Time Calibration, https://arxiv.org/pdf/2506.22819, 2025-06-28
2025-11-11 00:57:32,177 - INFO - root - Page:1, Index:20, Analyzing and Fine-Tuning Whisper Models for Multilingual Pilot Speech Transcription in the Cockpit, https://arxiv.org/pdf/2506.21990, 2025-06-27
2025-11-11 00:57:32,177 - INFO - root - Page:1, Index:21, SceneDiffuser++: City-Scale Traffic Simulation via a Generative World Model, https://arxiv.org/pdf/2506.21976, 2025-06-27
2025-11-11 00:57:32,178 - INFO - root - Page:1, Index:22, DIVE: Deep-search Iterative Video Exploration A Technical Report for the CVRR Challenge at CVPR 2025, https://arxiv.org/pdf/2506.21891, 2025-06-27
2025-11-11 00:57:32,178 - INFO - root - Page:1, Index:23, End-to-End RGB-IR Joint Image Compression With Channel-wise Cross-modality Entropy Model, https://arxiv.org/pdf/2506.21851, 2025-06-26
2025-11-11 00:57:32,178 - INFO - root - Page:1, Index:24, Distilling Normalizing Flows, https://arxiv.org/pdf/2506.21003, 2025-06-26
2025-11-11 00:57:32,179 - INFO - root - Page:1, Index:25, Joint attitude estimation and 3D neural reconstruction of non-cooperative space objects, https://arxiv.org/pdf/2506.20638, 2025-06-25
2025-11-11 00:57:32,179 - INFO - root - Page:1, Index:26, Accept More, Reject Less: Reducing up to 19% Unnecessary Desk-Rejections over 11 Years of ICLR Data, https://arxiv.org/pdf/2506.20141, 2025-06-25
2025-11-11 00:57:32,179 - INFO - root - Page:1, Index:27, SceneCrafter: Controllable Multi-View Driving Scene Editing, https://arxiv.org/pdf/2506.19488, 2025-06-24
2025-11-11 00:57:32,179 - INFO - root - Page:1, Index:28, Emergence of Text Readability in Vision Language Models, https://arxiv.org/pdf/2506.19389, 2025-06-24
2025-11-11 00:57:32,180 - INFO - root - Page:1, Index:29, MedErr-CT: A Visual Question Answering Benchmark for Identifying and Correcting Errors in CT Reports, https://arxiv.org/pdf/2506.19217, 2025-06-23
2025-11-11 00:57:32,180 - INFO - root - Page:1, Index:30, RareSpot: Spotting Small and Rare Wildlife in Aerial Imagery with Multi-Scale Consistency and Context-Aware Augmentation, https://arxiv.org/pdf/2506.19087, 2025-06-23
2025-11-11 00:57:32,181 - INFO - root - Page:1, Index:31, Object-aware Sound Source Localization via Audio-Visual Scene Understanding, https://arxiv.org/pdf/2506.18557, 2025-06-23
2025-11-11 00:57:32,181 - INFO - root - Page:1, Index:32, Rethinking Decoder Design: Improving Biomarker Segmentation Using Depth-to-Space Restoration and Residual Linear Attention, https://arxiv.org/pdf/2506.18335, 2025-06-23
2025-11-11 00:57:32,181 - INFO - root - Page:1, Index:33, Relation3D: Enhancing Relation Modeling for Point Cloud Instance Segmentation, https://arxiv.org/pdf/2506.17891, 2025-06-21
2025-11-11 00:57:32,181 - INFO - root - Page:1, Index:34, HIRE: Lightweight High-Resolution Image Feature Enrichment for Multimodal LLMs, https://arxiv.org/pdf/2506.17608, 2025-06-21
2025-11-11 00:57:32,181 - INFO - root - Page:1, Index:35, Spatially-Aware Evaluation of Segmentation Uncertainty, https://arxiv.org/pdf/2506.16589, 2025-06-19
2025-11-11 00:57:32,183 - INFO - root - Page:1, Index:36, Tripartite Weight-Space Ensemble for Few-Shot Class-Incremental Learning, https://arxiv.org/pdf/2506.15720, 2025-06-03
2025-11-11 00:57:32,183 - INFO - root - Page:1, Index:37, PARC: A Quantitative Framework Uncovering the Symmetries within Vision Language Models, https://arxiv.org/pdf/2506.14808, 2025-06-03
2025-11-11 00:57:32,183 - INFO - root - Page:1, Index:38, Self-supervised Representation Learning with Local Aggregation for Image-based Profiling, https://arxiv.org/pdf/2506.14265, 2025-10-27
2025-11-11 00:57:32,183 - INFO - root - Page:1, Index:39, Towards Robust Learning to Optimize with Theoretical Guarantees, https://arxiv.org/pdf/2506.14263, 2025-06-17
2025-11-11 00:57:32,184 - INFO - root - Page:1, Index:40, Hidden Bias in the Machine: Stereotypes in Text-to-Image Models, https://arxiv.org/pdf/2506.13780, 2025-06-09
2025-11-11 00:57:32,184 - INFO - root - Page:1, Index:41, SmartHome-Bench: A Comprehensive Benchmark for Video Anomaly Detection in Smart Homes Using Multi-Modal Large Language Models, https://arxiv.org/pdf/2506.12992, 2025-06-15
2025-11-11 00:57:32,184 - INFO - root - Page:1, Index:42, Generative 4D Scene Gaussian Splatting with Object View-Synthesis Priors, https://arxiv.org/pdf/2506.12716, 2025-06-15
2025-11-11 00:57:32,184 - INFO - root - Page:1, Index:43, DejaVid: Encoder-Agnostic Learned Temporal Matching for Video Classification, https://arxiv.org/pdf/2506.12585, 2025-06-14
2025-11-11 00:57:32,185 - INFO - root - Page:1, Index:44, Pushing the Limits of Safety: A Technical Report on the ATLAS Challenge 2025, https://arxiv.org/pdf/2506.12430, 2025-07-10
2025-11-11 00:57:32,185 - INFO - root - Page:1, Index:45, FIMA-Q: Post-Training Quantization for Vision Transformers by Fisher Information Matrix Approximation, https://arxiv.org/pdf/2506.11543, 2025-06-13
2025-11-11 00:57:32,185 - INFO - root - Page:1, Index:46, Stop learning it all to mitigate visual hallucination, Focus on the hallucination target, https://arxiv.org/pdf/2506.11417, 2025-06-12
2025-11-11 00:57:32,185 - INFO - root - Page:1, Index:47, EfficientQuant: An Efficient Post-Training Quantization for CNN-Transformer Hybrid Models on Edge Devices, https://arxiv.org/pdf/2506.11093, 2025-06-05
2025-11-11 00:57:32,186 - INFO - root - Page:1, Index:48, HalLoc: Token-level Localization of Hallucinations for Vision Language Models, https://arxiv.org/pdf/2506.10286, 2025-06-11
2025-11-11 00:57:32,186 - INFO - root - Page:1, Index:49, DySS: Dynamic Queries and State-Space Learning for Efficient 3D Object Detection from Multi-Camera Videos, https://arxiv.org/pdf/2506.10242, 2025-06-11
2025-11-11 00:57:32,187 - INFO - root - Fetching page 3 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=100
2025-11-11 00:57:38,712 - INFO - root - get_all_titles_from_web 
2025-11-11 00:57:38,712 - INFO - root - Page:2, Index:0, Improving Personalized Search with Regularized Low-Rank Parameter Updates, https://arxiv.org/pdf/2506.10182, 2025-06-11
2025-11-11 00:57:38,713 - INFO - root - Page:2, Index:1, Hearing Hands: Generating Sounds from Physical Interactions in 3D Scenes, https://arxiv.org/pdf/2506.09989, 2025-06-11
2025-11-11 00:57:38,713 - INFO - root - Page:2, Index:2, UniPre3D: Unified Pre-training of 3D Point Cloud Models with Cross-Modal Gaussian Splatting, https://arxiv.org/pdf/2506.09952, 2025-06-11
2025-11-11 00:57:38,713 - INFO - root - Page:2, Index:3, Provoking Multi-modal Few-Shot LVLM via Exploration-Exploitation In-Context Learning, https://arxiv.org/pdf/2506.09473, 2025-06-11
2025-11-11 00:57:38,714 - INFO - root - Page:2, Index:4, Synthetic Human Action Video Data Generation with Pose Transfer, https://arxiv.org/pdf/2506.09411, 2025-06-11
2025-11-11 00:57:38,714 - INFO - root - Page:2, Index:5, ScaleLSD: Scalable Deep Line Segment Detection Streamlined, https://arxiv.org/pdf/2506.09369, 2025-06-10
2025-11-11 00:57:38,714 - INFO - root - Page:2, Index:6, CheckManual: A New Challenge and Benchmark for Manual-based Appliance Manipulation, https://arxiv.org/pdf/2506.09343, 2025-06-10
2025-11-11 00:57:38,714 - INFO - root - Page:2, Index:7, PatchGuard: Adversarially Robust Anomaly Detection and Localization through Vision Transformers and Pseudo Anomalies, https://arxiv.org/pdf/2506.09237, 2025-10-24
2025-11-11 00:57:38,715 - INFO - root - Page:2, Index:8, SILK: Smooth InterpoLation frameworK for motion in-betweening A Simplified Computational Approach, https://arxiv.org/pdf/2506.09075, 2025-06-09
2025-11-11 00:57:38,715 - INFO - root - Page:2, Index:9, BG-HOP: A Bimanual Generative Hand-Object Prior, https://arxiv.org/pdf/2506.09068, 2025-06-08
2025-11-11 00:57:38,715 - INFO - root - Page:2, Index:10, ORIDa: Object-centric Real-world Image Composition Dataset, https://arxiv.org/pdf/2506.08964, 2025-06-10
2025-11-11 00:57:38,715 - INFO - root - Page:2, Index:11, DiscoVLA: Discrepancy Reduction in Vision, Language, and Alignment for Parameter-Efficient Video-Text Retrieval, https://arxiv.org/pdf/2506.08887, 2025-06-10
2025-11-11 00:57:38,718 - INFO - root - Page:2, Index:12, A Comprehensive Study of Decoder-Only LLMs for Text-to-Image Generation, https://arxiv.org/pdf/2506.08210, 2025-06-09
2025-11-11 00:57:38,718 - INFO - root - Page:2, Index:13, Open World Scene Graph Generation using Vision Language Models, https://arxiv.org/pdf/2506.08189, 2025-06-09
2025-11-11 00:57:38,719 - INFO - root - Page:2, Index:14, Aligning Proteins and Language: A Foundation Model for Protein Retrieval, https://arxiv.org/pdf/2506.08023, 2025-05-27
2025-11-11 00:57:38,719 - INFO - root - Page:2, Index:15, UA-Pose: Uncertainty-Aware 6D Object Pose Estimation and Online Object Completion with Partial References, https://arxiv.org/pdf/2506.07996, 2025-06-09
2025-11-11 00:57:38,719 - INFO - root - Page:2, Index:16, Speedy Deformable 3D Gaussian Splatting: Fast Rendering and Compression of Dynamic Scenes, https://arxiv.org/pdf/2506.07917, 2025-06-09
2025-11-11 00:57:38,720 - INFO - root - Page:2, Index:17, GaussianVAE: Adaptive Learning Dynamics of 3D Gaussians for High-Fidelity Super-Resolution, https://arxiv.org/pdf/2506.07897, 2025-06-09
2025-11-11 00:57:38,720 - INFO - root - Page:2, Index:18, Spatio-Temporal State Space Model For Efficient Event-Based Optical Flow, https://arxiv.org/pdf/2506.07878, 2025-06-09
2025-11-11 00:57:38,720 - INFO - root - Page:2, Index:19, FreeGave: 3D Physics Learning from Dynamic Videos by Gaussian Velocity, https://arxiv.org/pdf/2506.07865, 2025-06-09
2025-11-11 00:57:38,721 - INFO - root - Page:2, Index:20, LogoSP: Local-global Grouping of Superpoints for Unsupervised Semantic Segmentation of 3D Point Clouds, https://arxiv.org/pdf/2506.07857, 2025-06-09
2025-11-11 00:57:38,721 - INFO - root - Page:2, Index:21, Difference Inversion: Interpolate and Isolate the Difference with Token Consistency for Image Analogy Generation, https://arxiv.org/pdf/2506.07750, 2025-06-09
2025-11-11 00:57:38,721 - INFO - root - Page:2, Index:22, Synthetic Visual Genome, https://arxiv.org/pdf/2506.07643, 2025-06-09
2025-11-11 00:57:38,721 - INFO - root - Page:2, Index:23, Fractional Collisions: A Framework for Risk Estimation of Counterfactual Conflicts using Autonomous Driving Behavior Simulations, https://arxiv.org/pdf/2506.07540, 2025-06-09
2025-11-11 00:57:38,722 - INFO - root - Page:2, Index:24, Multi-Step Guided Diffusion for Image Restoration on Edge Devices: Toward Lightweight Perception in Embodied AI, https://arxiv.org/pdf/2506.07286, 2025-06-08
2025-11-11 00:57:38,722 - INFO - root - Page:2, Index:25, LLM-Enhanced Rapid-Reflex Async-Reflect Embodied Agent for Real-Time Decision-Making in Dynamically Changing Environments, https://arxiv.org/pdf/2506.07223, 2025-06-08
2025-11-11 00:57:38,722 - INFO - root - Page:2, Index:26, UCOD-DPL: Unsupervised Camouflaged Object Detection via Dynamic Pseudo-label Learning, https://arxiv.org/pdf/2506.07087, 2025-06-08
2025-11-11 00:57:38,722 - INFO - root - Page:2, Index:27, BePo: Leveraging Birds Eye View and Sparse Points for Efficient and Accurate 3D Occupancy Prediction, https://arxiv.org/pdf/2506.07002, 2025-06-08
2025-11-11 00:57:38,723 - INFO - root - Page:2, Index:28, Reading in the Dark with Foveated Event Vision, https://arxiv.org/pdf/2506.06918, 2025-06-07
2025-11-11 00:57:38,725 - INFO - root - Page:2, Index:29, NSD-Imagery: A benchmark dataset for extending fMRI vision decoding methods to mental imagery, https://arxiv.org/pdf/2506.06898, 2025-06-07
2025-11-11 00:57:38,725 - INFO - root - Page:2, Index:30, Continuous-Time SO(3) Forecasting with Savitzky--Golay Neural Controlled Differential Equations, https://arxiv.org/pdf/2506.06780, 2025-06-07
2025-11-11 00:57:38,725 - INFO - root - Page:2, Index:31, Generalized Trajectory Scoring for End-to-end Multimodal Planning, https://arxiv.org/pdf/2506.06664, 2025-06-07
2025-11-11 00:57:38,727 - INFO - root - Page:2, Index:32, EV-LayerSegNet: Self-supervised Motion Segmentation using Event Cameras, https://arxiv.org/pdf/2506.06596, 2025-06-06
2025-11-11 00:57:38,727 - INFO - root - Page:2, Index:33, Vid2Sim: Generalizable, Video-based Reconstruction of Appearance, Geometry and Physics for Mesh-free Simulation, https://arxiv.org/pdf/2506.06440, 2025-06-06
2025-11-11 00:57:38,727 - INFO - root - Page:2, Index:34, FADE: Frequency-Aware Diffusion Model Factorization for Video Editing, https://arxiv.org/pdf/2506.05934, 2025-06-06
2025-11-11 00:57:38,728 - INFO - root - Page:2, Index:35, Unleashing the Potential of Consistency Learning for Detecting and Grounding Multi-Modal Media Manipulation, https://arxiv.org/pdf/2506.05890, 2025-06-06
2025-11-11 00:57:38,728 - INFO - root - Page:2, Index:36, DeformCL: Learning Deformable Centerline Representation for Vessel Extraction in 3D Medical Image, https://arxiv.org/pdf/2506.05820, 2025-06-06
2025-11-11 00:57:38,728 - INFO - root - Page:2, Index:37, NTIRE 2025 Challenge on HR Depth from Images of Specular and Transparent Surfaces, https://arxiv.org/pdf/2506.05815, 2025-06-06
2025-11-11 00:57:38,728 - INFO - root - Page:2, Index:38, GazeNLQ @ Ego4D Natural Language Queries Challenge 2025, https://arxiv.org/pdf/2506.05782, 2025-06-06
2025-11-11 00:57:38,730 - INFO - root - Page:2, Index:39, Robust sensor fusion against on-vehicle sensor staleness, https://arxiv.org/pdf/2506.05780, 2025-06-06
2025-11-11 00:57:38,730 - INFO - root - Page:2, Index:40, Where Is The Ball: 3D Ball Trajectory Estimation From 2D Monocular Tracking, https://arxiv.org/pdf/2506.05763, 2025-06-06
2025-11-11 00:57:38,730 - INFO - root - Page:2, Index:41, VoxelSplat: Dynamic Gaussian Splatting as an Effective Loss for Occupancy and Flow Prediction, https://arxiv.org/pdf/2506.05563, 2025-06-05
2025-11-11 00:57:38,730 - INFO - root - Page:2, Index:42, Gen4D: Synthesizing Humans and Scenes in the Wild, https://arxiv.org/pdf/2506.05397, 2025-06-03
2025-11-11 00:57:38,731 - INFO - root - Page:2, Index:43, Attacking Attention of Foundation Models Disrupts Downstream Tasks, https://arxiv.org/pdf/2506.05394, 2025-09-12
2025-11-11 00:57:38,731 - INFO - root - Page:2, Index:44, FreeTimeGS: Free Gaussian Primitives at Anytime and Anywhere for Dynamic Scene Reconstruction, https://arxiv.org/pdf/2506.05348, 2025-06-06
2025-11-11 00:57:38,731 - INFO - root - Page:2, Index:45, LotusFilter: Fast Diverse Nearest Neighbor Search via a Learned Cutoff Table, https://arxiv.org/pdf/2506.04790, 2025-06-05
2025-11-11 00:57:38,732 - INFO - root - Page:2, Index:46, Towards Holistic Visual Quality Assessment of AI-Generated Videos: A LLM-Based Multi-Dimensional Evaluation Model, https://arxiv.org/pdf/2506.04715, 2025-06-11
2025-11-11 00:57:38,732 - INFO - root - Page:2, Index:47, Gradient Inversion Attacks on Parameter-Efficient Fine-Tuning, https://arxiv.org/pdf/2506.04453, 2025-06-04
2025-11-11 00:57:38,732 - INFO - root - Page:2, Index:48, HMAR: Efficient Hierarchical Masked Auto-Regressive Image Generation, https://arxiv.org/pdf/2506.04421, 2025-06-04
2025-11-11 00:57:38,732 - INFO - root - Page:2, Index:49, Visualizing and Controlling Cortical Responses Using Voxel-Weighted Activation Maximization, https://arxiv.org/pdf/2506.04379, 2025-06-04
2025-11-11 00:57:38,733 - INFO - root - Fetching page 4 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=150
2025-11-11 00:57:45,581 - INFO - root - get_all_titles_from_web 
2025-11-11 00:57:45,601 - INFO - root - Page:3, Index:0, FlexGS: Train Once, Deploy Everywhere with Many-in-One Flexible 3D Gaussian Splatting, https://arxiv.org/pdf/2506.04174, 2025-06-04
2025-11-11 00:57:45,629 - INFO - root - Page:3, Index:1, Multi-view Surface Reconstruction Using Normal and Reflectance Cues, https://arxiv.org/pdf/2506.04115, 2025-06-04
2025-11-11 00:57:45,630 - INFO - root - Page:3, Index:2, Vocabulary-free few-shot learning for Vision-Language Models, https://arxiv.org/pdf/2506.04005, 2025-06-04
2025-11-11 00:57:45,631 - INFO - root - Page:3, Index:3, Learning from Noise: Enhancing DNNs for Event-Based Vision through Controlled Noise Injection, https://arxiv.org/pdf/2506.03918, 2025-06-04
2025-11-11 00:57:45,631 - INFO - root - Page:3, Index:4, Video, How Do Your Tokens Merge?, https://arxiv.org/pdf/2506.03885, 2025-06-04
2025-11-11 00:57:45,631 - INFO - root - Page:3, Index:5, OSGNet @ Ego4D Episodic Memory Challenge 2025, https://arxiv.org/pdf/2506.03710, 2025-06-04
2025-11-11 00:57:45,631 - INFO - root - Page:3, Index:6, AetherVision-Bench: An Open-Vocabulary RGB-Infrared Benchmark for Multi-Angle Segmentation across Aerial and Ground Perspectives, https://arxiv.org/pdf/2506.03709, 2025-06-04
2025-11-11 00:57:45,631 - INFO - root - Page:3, Index:7, OV-COAST: Cost Aggregation with Optimal Transport for Open-Vocabulary Semantic Segmentation, https://arxiv.org/pdf/2506.03706, 2025-06-04
2025-11-11 00:57:45,632 - INFO - root - Page:3, Index:8, Generating 6DoF Object Manipulation Trajectories from Action Description in Egocentric Vision, https://arxiv.org/pdf/2506.03605, 2025-06-04
2025-11-11 00:57:45,632 - INFO - root - Page:3, Index:9, SemNav: A Model-Based Planner for Zero-Shot Object Goal Navigation Using Vision-Foundation Models, https://arxiv.org/pdf/2506.03516, 2025-06-03
2025-11-11 00:57:45,632 - INFO - root - Page:3, Index:10, Heterogeneous Skeleton-Based Action Representation Learning, https://arxiv.org/pdf/2506.03481, 2025-06-03
2025-11-11 00:57:45,632 - INFO - root - Page:3, Index:11, Hybrid Ensemble of Segmentation-Assisted Classification and GBDT for Skin Cancer Detection with Engineered Metadata and Synthetic Lesions from ISIC 2024 Non-Dermoscopic 3D-TBP Images, https://arxiv.org/pdf/2506.03420, 2025-06-03
2025-11-11 00:57:45,634 - INFO - root - Page:3, Index:12, Self-Supervised Spatial Correspondence Across Modalities, https://arxiv.org/pdf/2506.03148, 2025-06-03
2025-11-11 00:57:45,635 - INFO - root - Page:3, Index:13, Dense Match Summarization for Faster Two-view Estimation, https://arxiv.org/pdf/2506.02893, 2025-06-03
2025-11-11 00:57:45,635 - INFO - root - Page:3, Index:14, NTIRE 2025 XGC Quality Assessment Challenge: Methods and Results, https://arxiv.org/pdf/2506.02875, 2025-06-03
2025-11-11 00:57:45,637 - INFO - root - Page:3, Index:15, FreeScene: Mixed Graph Diffusion for 3D Scene Synthesis from Free Prompts, https://arxiv.org/pdf/2506.02781, 2025-06-03
2025-11-11 00:57:45,639 - INFO - root - Page:3, Index:16, Technical Report for Ego4D Long-Term Action Anticipation Challenge 2025, https://arxiv.org/pdf/2506.02550, 2025-06-11
2025-11-11 00:57:45,641 - INFO - root - Page:3, Index:17, Probabilistic Online Event Downsampling, https://arxiv.org/pdf/2506.02547, 2025-09-23
2025-11-11 00:57:45,642 - INFO - root - Page:3, Index:18, Towards In-the-wild 3D Plane Reconstruction from a Single Image, https://arxiv.org/pdf/2506.02493, 2025-06-03
2025-11-11 00:57:45,644 - INFO - root - Page:3, Index:19, Efficient Test-time Adaptive Object Detection via Sensitivity-Guided Pruning, https://arxiv.org/pdf/2506.02462, 2025-06-03
2025-11-11 00:57:45,644 - INFO - root - Page:3, Index:20, EgoVIS@CVPR: PAIR-Net: Enhancing Egocentric Speaker Detection via Pretrained Audio-Visual Fusion and Alignment Loss, https://arxiv.org/pdf/2506.02247, 2025-09-26
2025-11-11 00:57:45,644 - INFO - root - Page:3, Index:21, Diff2Flow: Training Flow Matching Models via Diffusion Model Alignment, https://arxiv.org/pdf/2506.02221, 2025-06-02
2025-11-11 00:57:45,644 - INFO - root - Page:3, Index:22, NTIRE 2025 Challenge on RAW Image Restoration and Super-Resolution, https://arxiv.org/pdf/2506.02197, 2025-06-04
2025-11-11 00:57:45,646 - INFO - root - Page:3, Index:23, RAW Image Reconstruction from RGB on Smartphones. NTIRE 2025 Challenge Report, https://arxiv.org/pdf/2506.01947, 2025-06-02
2025-11-11 00:57:45,646 - INFO - root - Page:3, Index:24, Silence is Golden: Leveraging Adversarial Examples to Nullify Audio Control in LDM-based Talking-Head Generation, https://arxiv.org/pdf/2506.01591, 2025-06-02
2025-11-11 00:57:45,646 - INFO - root - Page:3, Index:25, SAM2-LOVE: Segment Anything Model 2 in Language-aided Audio-Visual Scenes, https://arxiv.org/pdf/2506.01558, 2025-06-02
2025-11-11 00:57:45,647 - INFO - root - Page:3, Index:26, Neural shape reconstruction from multiple views with static pattern projection, https://arxiv.org/pdf/2506.01389, 2025-06-02
2025-11-11 00:57:45,647 - INFO - root - Page:3, Index:27, SAM-I2V: Upgrading SAM to Support Promptable Video Segmentation with Less than 0.2% Training Cost, https://arxiv.org/pdf/2506.01304, 2025-06-02
2025-11-11 00:57:45,647 - INFO - root - Page:3, Index:28, Perceptual Inductive Bias Is What You Need Before Contrastive Learning, https://arxiv.org/pdf/2506.01201, 2025-06-01
2025-11-11 00:57:45,647 - INFO - root - Page:3, Index:29, Test Automation for Interactive Scenarios via Promptable Traffic Simulation, https://arxiv.org/pdf/2506.01199, 2025-06-04
2025-11-11 00:57:45,648 - INFO - root - Page:3, Index:30, GraphPad: Inference-Time 3D Scene Graph Updates for Embodied Question Answering, https://arxiv.org/pdf/2506.01174, 2025-06-01
2025-11-11 00:57:45,648 - INFO - root - Page:3, Index:31, Aligned Contrastive Loss for Long-Tailed Recognition, https://arxiv.org/pdf/2506.01071, 2025-06-01
2025-11-11 00:57:45,648 - INFO - root - Page:3, Index:32, Self-supervised ControlNet with Spatio-Temporal Mamba for Real-world Video Super-resolution, https://arxiv.org/pdf/2506.01037, 2025-06-01
2025-11-11 00:57:45,648 - INFO - root - Page:3, Index:33, ArtiScene: Language-Driven Artistic 3D Scene Generation Through Image Intermediary, https://arxiv.org/pdf/2506.00742, 2025-05-31
2025-11-11 00:57:45,653 - INFO - root - Page:3, Index:34, 3D Gaussian Splat Vulnerabilities, https://arxiv.org/pdf/2506.00280, 2025-05-30
2025-11-11 00:57:45,653 - INFO - root - Page:3, Index:35, EgoVIS@CVPR: What Changed and What Could Have Changed? State-Change Counterfactuals for Procedure-Aware Video Representation Learning, https://arxiv.org/pdf/2506.00101, 2025-09-26
2025-11-11 00:57:45,653 - INFO - root - Page:3, Index:36, CL-LoRA: Continual Low-Rank Adaptation for Rehearsal-Free Class-Incremental Learning, https://arxiv.org/pdf/2505.24816, 2025-05-30
2025-11-11 00:57:45,653 - INFO - root - Page:3, Index:37, PatchDEMUX: A Certifiably Robust Framework for Multi-label Classifiers Against Adversarial Patches, https://arxiv.org/pdf/2505.24703, 2025-05-30
2025-11-11 00:57:45,655 - INFO - root - Page:3, Index:38, Conformal Prediction for Zero-Shot Models, https://arxiv.org/pdf/2505.24693, 2025-05-30
2025-11-11 00:57:45,655 - INFO - root - Page:3, Index:39, Learning reusable concepts across different egocentric video understanding tasks, https://arxiv.org/pdf/2505.24690, 2025-05-30
2025-11-11 00:57:45,655 - INFO - root - Page:3, Index:40, Period-LLM: Extending the Periodic Capability of Multimodal Large Language Model, https://arxiv.org/pdf/2505.24476, 2025-05-30
2025-11-11 00:57:45,656 - INFO - root - Page:3, Index:41, PCIE_Interaction Solution for Ego4D Social Interaction Challenge, https://arxiv.org/pdf/2505.24404, 2025-05-30
2025-11-11 00:57:45,656 - INFO - root - Page:3, Index:42, Leadership Assessment in Pediatric Intensive Care Unit Team Training, https://arxiv.org/pdf/2505.24389, 2025-08-28
2025-11-11 00:57:45,656 - INFO - root - Page:3, Index:43, Interpreting Large Text-to-Image Diffusion Models with Dictionary Learning, https://arxiv.org/pdf/2505.24360, 2025-07-10
2025-11-11 00:57:45,656 - INFO - root - Page:3, Index:44, InteractAnything: Zero-shot Human Object Interaction Synthesis via LLM Feedback and Object Affordance Parsing, https://arxiv.org/pdf/2505.24315, 2025-05-30
2025-11-11 00:57:45,660 - INFO - root - Page:3, Index:45, MaskAdapt: Unsupervised Geometry-Aware Domain Adaptation Using Multimodal Contextual Learning and RGB-Depth Masking, https://arxiv.org/pdf/2505.24026, 2025-05-29
2025-11-11 00:57:45,662 - INFO - root - Page:3, Index:46, Argus: Vision-Centric Reasoning with Grounded Chain-of-Thought, https://arxiv.org/pdf/2505.23766, 2025-05-29
2025-11-11 00:57:45,662 - INFO - root - Page:3, Index:47, Sketch Down the FLOPs: Towards Efficient Networks for Human Sketch, https://arxiv.org/pdf/2505.23763, 2025-05-29
2025-11-11 00:57:45,664 - INFO - root - Page:3, Index:48, Boosting Domain Incremental Learning: Selecting the Optimal Parameters is All You Need, https://arxiv.org/pdf/2505.23744, 2025-05-29
2025-11-11 00:57:45,664 - INFO - root - Page:3, Index:49, DA-VPT: Semantic-Guided Visual Prompt Tuning for Vision Transformers, https://arxiv.org/pdf/2505.23694, 2025-06-01
2025-11-11 00:57:45,664 - INFO - root - Fetching page 5 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=200
2025-11-11 00:57:52,075 - INFO - root - get_all_titles_from_web 
2025-11-11 00:57:52,076 - INFO - root - Page:4, Index:0, Bridging Classical and Modern Computer Vision: PerceptiveNet for Tree Crown Semantic Segmentation, https://arxiv.org/pdf/2505.23597, 2025-05-29
2025-11-11 00:57:52,076 - INFO - root - Page:4, Index:1, Synthetic Generation and Latent Projection Denoising of Rim Lesions in Multiple Sclerosis, https://arxiv.org/pdf/2505.23353, 2025-05-29
2025-11-11 00:57:52,077 - INFO - root - Page:4, Index:2, Wav2Sem: Plug-and-Play Audio Semantic Decoupling for 3D Speech-Driven Facial Animation, https://arxiv.org/pdf/2505.23290, 2025-05-29
2025-11-11 00:57:52,077 - INFO - root - Page:4, Index:3, Proximal Algorithm Unrolling: Flexible and Efficient Reconstruction Networks for Single-Pixel Imaging, https://arxiv.org/pdf/2505.23180, 2025-05-29
2025-11-11 00:57:52,077 - INFO - root - Page:4, Index:4, HMAD: Advancing E2E Driving with Anchored Offset Proposals and Simulation-Supervised Multi-target Scoring, https://arxiv.org/pdf/2505.23129, 2025-05-29
2025-11-11 00:57:52,078 - INFO - root - Page:4, Index:5, URWKV: Unified RWKV Model with Multi-state Perspective for Low-light Image Restoration, https://arxiv.org/pdf/2505.23068, 2025-05-29
2025-11-11 00:57:52,078 - INFO - root - Page:4, Index:6, 4DTAM: Non-Rigid Tracking and Mapping via Dynamic Surface Gaussians, https://arxiv.org/pdf/2505.22859, 2025-05-28
2025-11-11 00:57:52,078 - INFO - root - Page:4, Index:7, A Probabilistic Jump-Diffusion Framework for Open-World Egocentric Activity Recognition, https://arxiv.org/pdf/2505.22858, 2025-05-28
2025-11-11 00:57:52,079 - INFO - root - Page:4, Index:8, PS4PRO: Pixel-to-pixel Supervision for Photorealistic Rendering and Optimization, https://arxiv.org/pdf/2505.22616, 2025-05-28
2025-11-11 00:57:52,080 - INFO - root - Page:4, Index:9, Universal Domain Adaptation for Semantic Segmentation, https://arxiv.org/pdf/2505.22458, 2025-06-05
2025-11-11 00:57:52,083 - INFO - root - Page:4, Index:10, Zero-Shot 3D Visual Grounding from Vision-Language Models, https://arxiv.org/pdf/2505.22429, 2025-05-28
2025-11-11 00:57:52,084 - INFO - root - Page:4, Index:11, RC-AutoCalib: An End-to-End Radar-Camera Automatic Calibration Network, https://arxiv.org/pdf/2505.22427, 2025-05-28
2025-11-11 00:57:52,084 - INFO - root - Page:4, Index:12, Bringing CLIP to the Clinic: Dynamic Soft Labels and Negation-Aware Learning for Medical Analysis, https://arxiv.org/pdf/2505.22079, 2025-05-28
2025-11-11 00:57:52,085 - INFO - root - Page:4, Index:13, Point-to-Region Loss for Semi-Supervised Point-Based Crowd Counting, https://arxiv.org/pdf/2505.21943, 2025-05-27
2025-11-11 00:57:52,086 - INFO - root - Page:4, Index:14, FRAMES-VQA: Benchmarking Fine-Tuning Robustness across Multi-Modal Shifts in Visual Question Answering, https://arxiv.org/pdf/2505.21755, 2025-06-20
2025-11-11 00:57:52,086 - INFO - root - Page:4, Index:15, Knowledge Distillation Approach for SOS Fusion Staging: Towards Fully Automated Skeletal Maturity Assessment, https://arxiv.org/pdf/2505.21561, 2025-05-26
2025-11-11 00:57:52,086 - INFO - root - Page:4, Index:16, Enhancing Vision Transformer Explainability Using Artificial Astrocytes, https://arxiv.org/pdf/2505.21513, 2025-05-20
2025-11-11 00:57:52,086 - INFO - root - Page:4, Index:17, Empowering Vector Graphics with Consistently Arbitrary Viewing and View-dependent Visibility, https://arxiv.org/pdf/2505.21377, 2025-05-27
2025-11-11 00:57:52,087 - INFO - root - Page:4, Index:18, Structure from Collision, https://arxiv.org/pdf/2505.21335, 2025-05-27
2025-11-11 00:57:52,087 - INFO - root - Page:4, Index:19, Boosting Adversarial Transferability via High-Frequency Augmentation and Hierarchical-Gradient Fusion, https://arxiv.org/pdf/2505.21181, 2025-05-27
2025-11-11 00:57:52,087 - INFO - root - Page:4, Index:20, RefAV: Towards Planning-Centric Scenario Mining, https://arxiv.org/pdf/2505.20981, 2025-06-18
2025-11-11 00:57:52,088 - INFO - root - Page:4, Index:21, PMA: Towards Parameter-Efficient Point Cloud Understanding via Point Mamba Adapter, https://arxiv.org/pdf/2505.20941, 2025-05-27
2025-11-11 00:57:52,090 - INFO - root - Page:4, Index:22, HuMoCon: Concept Discovery for Human Motion Understanding, https://arxiv.org/pdf/2505.20920, 2025-05-27
2025-11-11 00:57:52,090 - INFO - root - Page:4, Index:23, Exploring Timeline Control for Facial Motion Generation, https://arxiv.org/pdf/2505.20861, 2025-05-27
2025-11-11 00:57:52,091 - INFO - root - Page:4, Index:24, ConText-CIR: Learning from Concepts in Text for Composed Image Retrieval, https://arxiv.org/pdf/2505.20764, 2025-05-27
2025-11-11 00:57:52,091 - INFO - root - Page:4, Index:25, HCQA-1.5 @ Ego4D EgoSchema Challenge 2025, https://arxiv.org/pdf/2505.20644, 2025-05-26
2025-11-11 00:57:52,091 - INFO - root - Page:4, Index:26, Roboflow100-VL: A Multi-Domain Object Detection Benchmark for Vision-Language Models, https://arxiv.org/pdf/2505.20612, 2025-10-22
2025-11-11 00:57:52,091 - INFO - root - Page:4, Index:27, MotionPro: A Precise Motion Controller for Image-to-Video Generation, https://arxiv.org/pdf/2505.20287, 2025-05-26
2025-11-11 00:57:52,092 - INFO - root - Page:4, Index:28, Category-Agnostic Neural Object Rigging, https://arxiv.org/pdf/2505.20283, 2025-05-26
2025-11-11 00:57:52,093 - INFO - root - Page:4, Index:29, Towards Video to Piano Music Generation with Chain-of-Perform Support Benchmarks, https://arxiv.org/pdf/2505.20038, 2025-05-26
2025-11-11 00:57:52,094 - INFO - root - Page:4, Index:30, Can Visual Encoder Learn to See Arrows?, https://arxiv.org/pdf/2505.19944, 2025-05-26
2025-11-11 00:57:52,098 - INFO - root - Page:4, Index:31, GoLF-NRT: Integrating Global Context and Local Geometry for Few-Shot View Synthesis, https://arxiv.org/pdf/2505.19813, 2025-05-26
2025-11-11 00:57:52,099 - INFO - root - Page:4, Index:32, Depth-Guided Bundle Sampling for Efficient Generalizable Neural Radiance Field Reconstruction, https://arxiv.org/pdf/2505.19793, 2025-05-26
2025-11-11 00:57:52,100 - INFO - root - Page:4, Index:33, SuperAD: A Training-free Anomaly Classification and Segmentation Method for CVPR 2025 VAND 3.0 Workshop Challenge Track 1: Adapt & Detect, https://arxiv.org/pdf/2505.19750, 2025-05-27
2025-11-11 00:57:52,101 - INFO - root - Page:4, Index:34, Knowledge-Aligned Counterfactual-Enhancement Diffusion Perception for Unsupervised Cross-Domain Visual Emotion Recognition, https://arxiv.org/pdf/2505.19694, 2025-05-26
2025-11-11 00:57:52,102 - INFO - root - Page:4, Index:35, Rotation-Equivariant Self-Supervised Method in Image Denoising, https://arxiv.org/pdf/2505.19618, 2025-05-26
2025-11-11 00:57:52,104 - INFO - root - Page:4, Index:36, NTIRE 2025 Challenge on Video Quality Enhancement for Video Conferencing: Datasets, Methods and Results, https://arxiv.org/pdf/2505.18988, 2025-05-25
2025-11-11 00:57:52,105 - INFO - root - Page:4, Index:37, Geometry-guided Online 3D Video Synthesis with Multi-View Temporal Consistency, https://arxiv.org/pdf/2505.18932, 2025-05-24
2025-11-11 00:57:52,106 - INFO - root - Page:4, Index:38, Digital Overconsumption and Waste: A Closer Look at the Impacts of Generative AI, https://arxiv.org/pdf/2505.18894, 2025-05-24
2025-11-11 00:57:52,106 - INFO - root - Page:4, Index:39, VISTA: Vision-Language Inference for Training-Free Stock Time-Series Analysis, https://arxiv.org/pdf/2505.18570, 2025-06-11
2025-11-11 00:57:52,106 - INFO - root - Page:4, Index:40, Syn3DTxt: Embedding 3D Cues for Scene Text Generation, https://arxiv.org/pdf/2505.18479, 2025-05-23
2025-11-11 00:57:52,107 - INFO - root - Page:4, Index:41, CTRL-GS: Cascaded Temporal Residue Learning for 4D Gaussian Splatting, https://arxiv.org/pdf/2505.18306, 2025-05-31
2025-11-11 00:57:52,107 - INFO - root - Page:4, Index:42, DualTalk: Dual-Speaker Interaction for 3D Talking Head Conversations, https://arxiv.org/pdf/2505.18096, 2025-05-26
2025-11-11 00:57:52,108 - INFO - root - Page:4, Index:43, SeaLion: Semantic Part-Aware Latent Point Diffusion Models for 3D Generation, https://arxiv.org/pdf/2505.17721, 2025-07-07
2025-11-11 00:57:52,110 - INFO - root - Page:4, Index:44, PoseBH: Prototypical Multi-Dataset Training Beyond Human Pose Estimation, https://arxiv.org/pdf/2505.17475, 2025-05-23
2025-11-11 00:57:52,110 - INFO - root - Page:4, Index:45, Pursuing Temporal-Consistent Video Virtual Try-On via Dynamic Pose Interaction, https://arxiv.org/pdf/2505.16980, 2025-05-22
2025-11-11 00:57:52,111 - INFO - root - Page:4, Index:46, UniPhy: Learning a Unified Constitutive Model for Inverse Physics Simulation, https://arxiv.org/pdf/2505.16971, 2025-05-22
2025-11-11 00:57:52,112 - INFO - root - Page:4, Index:47, Tracking the Flight: Exploring a Computational Framework for Analyzing Escape Responses in Plains Zebra (Equus quagga), https://arxiv.org/pdf/2505.16882, 2025-05-23
2025-11-11 00:57:52,112 - INFO - root - Page:4, Index:48, Semi-Supervised State-Space Model with Dynamic Stacking Filter for Real-World Video Deraining, https://arxiv.org/pdf/2505.16811, 2025-05-22
2025-11-11 00:57:52,117 - INFO - root - Page:4, Index:49, SOLVE: Synergy of Language-Vision and End-to-End Networks for Autonomous Driving, https://arxiv.org/pdf/2505.16805, 2025-05-22
2025-11-11 00:57:52,120 - INFO - root - Fetching page 6 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=250
2025-11-11 00:58:00,047 - INFO - root - get_all_titles_from_web 
2025-11-11 00:58:00,059 - INFO - root - Page:5, Index:0, Four Eyes Are Better Than Two: Harnessing the Collaborative Potential of Large Models via Differentiated Thinking and Complementary Ensembles, https://arxiv.org/pdf/2505.16784, 2025-06-07
2025-11-11 00:58:00,067 - INFO - root - Page:5, Index:1, Single Domain Generalization for Few-Shot Counting via Universal Representation Matching, https://arxiv.org/pdf/2505.16778, 2025-05-22
2025-11-11 00:58:00,098 - INFO - root - Page:5, Index:2, Seeing Far and Clearly: Mitigating Hallucinations in MLLMs with Attention Causal Decoding, https://arxiv.org/pdf/2505.16652, 2025-06-07
2025-11-11 00:58:00,111 - INFO - root - Page:5, Index:3, Sketchy Bounding-box Supervision for 3D Instance Segmentation, https://arxiv.org/pdf/2505.16399, 2025-05-22
2025-11-11 00:58:00,114 - INFO - root - Page:5, Index:4, DeCafNet: Delegate and Conquer for Efficient Temporal Grounding in Long Videos, https://arxiv.org/pdf/2505.16376, 2025-05-22
2025-11-11 00:58:00,115 - INFO - root - Page:5, Index:5, NTIRE 2025 challenge on Text to Image Generation Model Quality Assessment, https://arxiv.org/pdf/2505.16314, 2025-05-22
2025-11-11 00:58:00,116 - INFO - root - Page:5, Index:6, Analyzing Hierarchical Structure in Vision Models with Sparse Autoencoders, https://arxiv.org/pdf/2505.15970, 2025-05-21
2025-11-11 00:58:00,117 - INFO - root - Page:5, Index:7, Efficient Data Driven Mixture-of-Expert Extraction from Trained Networks, https://arxiv.org/pdf/2505.15414, 2025-05-21
2025-11-11 00:58:00,118 - INFO - root - Page:5, Index:8, Mouse Lockbox Dataset: Behavior Recognition for Mice Solving Lockboxes, https://arxiv.org/pdf/2505.15408, 2025-06-17
2025-11-11 00:58:00,119 - INFO - root - Page:5, Index:9, Zero-Shot Gaze-based Volumetric Medical Image Segmentation, https://arxiv.org/pdf/2505.15256, 2025-06-10
2025-11-11 00:58:00,120 - INFO - root - Page:5, Index:10, Dual Precision Quantization for Efficient and Accurate Deep Neural Networks Inference, https://arxiv.org/pdf/2505.14638, 2025-05-20
2025-11-11 00:58:00,123 - INFO - root - Page:5, Index:11, Neural Video Compression with Context Modulation, https://arxiv.org/pdf/2505.14541, 2025-05-20
2025-11-11 00:58:00,129 - INFO - root - Page:5, Index:12, Selective Structured State Space for Multispectral-fused Small Target Detection, https://arxiv.org/pdf/2505.14043, 2025-05-23
2025-11-11 00:58:00,130 - INFO - root - Page:5, Index:13, OmniStyle: Filtering High Quality Style Transfer Data at Scale, https://arxiv.org/pdf/2505.14028, 2025-05-20
2025-11-11 00:58:00,131 - INFO - root - Page:5, Index:14, Domain Adaptation of VLM for Soccer Video Understanding, https://arxiv.org/pdf/2505.13860, 2025-07-07
2025-11-11 00:58:00,132 - INFO - root - Page:5, Index:15, Ground-V: Teaching VLMs to Ground Complex Instructions in Pixels, https://arxiv.org/pdf/2505.13788, 2025-05-19
2025-11-11 00:58:00,133 - INFO - root - Page:5, Index:16, FinePhys: Fine-grained Human Action Generation by Explicitly Incorporating Physical Laws for Effective Skeletal Guidance, https://arxiv.org/pdf/2505.13437, 2025-05-19
2025-11-11 00:58:00,134 - INFO - root - Page:5, Index:17, The Way Up: A Dataset for Hold Usage Detection in Sport Climbing, https://arxiv.org/pdf/2505.12854, 2025-05-19
2025-11-11 00:58:00,134 - INFO - root - Page:5, Index:18, PEER pressure: Model-to-Model Regularization for Single Source Domain Generalization, https://arxiv.org/pdf/2505.12745, 2025-05-19
2025-11-11 00:58:00,135 - INFO - root - Page:5, Index:19, Mamba-Adaptor: State Space Model Adaptor for Visual Recognition, https://arxiv.org/pdf/2505.12685, 2025-05-19
2025-11-11 00:58:00,136 - INFO - root - Page:5, Index:20, Scalable Video-to-Dataset Generation for Cross-Platform Mobile Agents, https://arxiv.org/pdf/2505.12632, 2025-05-18
2025-11-11 00:58:00,136 - INFO - root - Page:5, Index:21, Degradation-Aware Feature Perturbation for All-in-One Image Restoration, https://arxiv.org/pdf/2505.12630, 2025-05-18
2025-11-11 00:58:00,136 - INFO - root - Page:5, Index:22, Guiding Diffusion with Deep Geometric Moments: Balancing Fidelity and Variation, https://arxiv.org/pdf/2505.12486, 2025-05-18
2025-11-11 00:58:00,138 - INFO - root - Page:5, Index:23, Learning to Highlight Audio by Watching Movies, https://arxiv.org/pdf/2505.12154, 2025-05-17
2025-11-11 00:58:00,145 - INFO - root - Page:5, Index:24, Understanding the Capabilities of Molecular Graph Neural Networks in Materials Science Through Multimodal Learning and Physical Context Encoding, https://arxiv.org/pdf/2505.12137, 2025-05-17
2025-11-11 00:58:00,146 - INFO - root - Page:5, Index:25, iSegMan: Interactive Segment-and-Manipulate 3D Gaussians, https://arxiv.org/pdf/2505.11934, 2025-05-17
2025-11-11 00:58:00,146 - INFO - root - Page:5, Index:26, Self-Learning Hyperspectral and Multispectral Image Fusion via Adaptive Residual Guided Subspace Diffusion Model, https://arxiv.org/pdf/2505.11800, 2025-05-16
2025-11-11 00:58:00,146 - INFO - root - Page:5, Index:27, X-Edit: Detecting and Localizing Edits in Images Altered by Text-Guided Diffusion Models, https://arxiv.org/pdf/2505.11753, 2025-05-16
2025-11-11 00:58:00,147 - INFO - root - Page:5, Index:28, MTevent: A Multi-Task Event Camera Dataset for 6D Pose Estimation and Moving Object Detection, https://arxiv.org/pdf/2505.11282, 2025-06-02
2025-11-11 00:58:00,147 - INFO - root - Page:5, Index:29, Imputation-free and Alignment-free: Incomplete Multi-view Clustering Driven by Consensus Semantic Learning, https://arxiv.org/pdf/2505.11182, 2025-05-16
2025-11-11 00:58:00,148 - INFO - root - Page:5, Index:30, MultiLink: Multi-class Structure Recovery via Agglomerative Clustering and Model Selection, https://arxiv.org/pdf/2505.10874, 2025-05-16
2025-11-11 00:58:00,151 - INFO - root - Page:5, Index:31, RefPose: Leveraging Reference Geometric Correspondences for Accurate 6D Pose Estimation of Unseen Objects, https://arxiv.org/pdf/2505.10841, 2025-05-16
2025-11-11 00:58:00,151 - INFO - root - Page:5, Index:32, MoCLIP: Motion-Aware Fine-Tuning and Distillation of CLIP for Human Motion Generation, https://arxiv.org/pdf/2505.10810, 2025-05-15
2025-11-11 00:58:00,151 - INFO - root - Page:5, Index:33, Automated Detection of Salvin's Albatrosses: Improving Deep Learning Tools for Aerial Wildlife Surveys, https://arxiv.org/pdf/2505.10737, 2025-05-15
2025-11-11 00:58:00,152 - INFO - root - Page:5, Index:34, Advancing Multiple Instance Learning with Continual Learning for Whole Slide Imaging, https://arxiv.org/pdf/2505.10649, 2025-05-15
2025-11-11 00:58:00,152 - INFO - root - Page:5, Index:35, Inferring Driving Maps by Deep Learning-based Trail Map Extraction, https://arxiv.org/pdf/2505.10258, 2025-05-15
2025-11-11 00:58:00,152 - INFO - root - Page:5, Index:36, Behind Maya: Building a Multilingual Vision Language Model, https://arxiv.org/pdf/2505.08910, 2025-05-15
2025-11-11 00:58:00,152 - INFO - root - Page:5, Index:37, PosterO: Structuring Layout Trees to Enable Language Models in Generalized Content-Aware Layout Generation, https://arxiv.org/pdf/2505.07843, 2025-05-26
2025-11-11 00:58:00,153 - INFO - root - Page:5, Index:38, Prototype Augmented Hypernetworks for Continual Learning, https://arxiv.org/pdf/2505.07450, 2025-05-16
2025-11-11 00:58:00,153 - INFO - root - Fetching page 7 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=300
2025-11-11 00:58:06,842 - INFO - root - get_all_titles_from_web 
2025-11-11 00:58:06,842 - INFO - root - Page:6, Index:0, Convex Relaxation for Robust Vanishing Point Estimation in Manhattan World, https://arxiv.org/pdf/2505.04788, 2025-06-05
2025-11-11 00:58:06,843 - INFO - root - Page:6, Index:1, S3D: Sketch-Driven 3D Model Generation, https://arxiv.org/pdf/2505.04185, 2025-06-03
2025-11-11 00:58:06,843 - INFO - root - Page:6, Index:2, Generating Synthetic Data via Augmentations for Improved Facial Resemblance in DreamBooth and InstantID, https://arxiv.org/pdf/2505.03557, 2025-07-17
2025-11-11 00:58:06,843 - INFO - root - Page:6, Index:3, CAV-MAE Sync: Improving Contrastive Audio-Visual Mask Autoencoders via Fine-Grained Alignment, https://arxiv.org/pdf/2505.01237, 2025-05-21
2025-11-11 00:58:06,843 - INFO - root - Fetching page 8 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=350
2025-11-11 00:58:13,679 - INFO - root - get_all_titles_from_web 
2025-11-11 00:58:13,679 - INFO - root - Page:7, Index:0, Where's the liability in the Generative Era? Recovery-based Black-Box Detection of AI-Generated Content, https://arxiv.org/pdf/2505.01008, 2025-08-25
2025-11-11 00:58:13,681 - INFO - root - Page:7, Index:1, SpatialLLM: A Compound 3D-Informed Design towards Spatially-Intelligent Large Multimodal Models, https://arxiv.org/pdf/2505.00788, 2025-06-10
2025-11-11 00:58:13,681 - INFO - root - Page:7, Index:2, Prisma: An Open Source Toolkit for Mechanistic Interpretability in Vision and Video, https://arxiv.org/pdf/2504.19475, 2025-06-03
2025-11-11 00:58:13,681 - INFO - root - Page:7, Index:3, SSL4Eco: A Global Seasonal Dataset for Geospatial Foundation Models in Ecology, https://arxiv.org/pdf/2504.18256, 2025-10-20
2025-11-11 00:58:13,682 - INFO - root - Page:7, Index:4, Vision-Language Models Are Not Pragmatically Competent in Referring Expression Generation, https://arxiv.org/pdf/2504.16060, 2025-07-30
2025-11-11 00:58:13,682 - INFO - root - Fetching page 9 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=400
2025-11-11 00:58:20,387 - INFO - root - get_all_titles_from_web 
2025-11-11 00:58:20,388 - INFO - root - Page:8, Index:0, Leveraging Automatic CAD Annotations for Supervised Learning in 3D Scene Understanding, https://arxiv.org/pdf/2504.13580, 2025-05-16
2025-11-11 00:58:20,388 - INFO - root - Page:8, Index:1, CAP-Net: A Unified Network for 6D Pose and Size Estimation of Categorical Articulated Parts from a Single RGB-D Image, https://arxiv.org/pdf/2504.11230, 2025-06-02
2025-11-11 00:58:20,388 - INFO - root - Page:8, Index:2, Video Summarization with Large Language Models, https://arxiv.org/pdf/2504.11199, 2025-06-05
2025-11-11 00:58:20,389 - INFO - root - Page:8, Index:3, R-TPT: Improving Adversarial Robustness of Vision-Language Models through Test-Time Prompt Tuning, https://arxiv.org/pdf/2504.11195, 2025-08-27
2025-11-11 00:58:20,389 - INFO - root - Page:8, Index:4, TerraMesh: A Planetary Mosaic of Multimodal Earth Observation Data, https://arxiv.org/pdf/2504.11172, 2025-08-01
2025-11-11 00:58:20,389 - INFO - root - Page:8, Index:5, Seeing like a Cephalopod: Colour Vision with a Monochrome Event Camera, https://arxiv.org/pdf/2504.10984, 2025-06-06
2025-11-11 00:58:20,390 - INFO - root - Page:8, Index:6, Hearing Anywhere in Any Environment, https://arxiv.org/pdf/2504.10746, 2025-06-04
2025-11-11 00:58:20,390 - INFO - root - Fetching page 10 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=450
2025-11-11 00:58:26,634 - INFO - root - get_all_titles_from_web 
2025-11-11 00:58:26,634 - INFO - root - Page:9, Index:0, Correlative and Discriminative Label Grouping for Multi-Label Visual Prompt Tuning, https://arxiv.org/pdf/2504.09990, 2025-07-09
2025-11-11 00:58:26,635 - INFO - root - Page:9, Index:1, SPICE: A Synergistic, Precise, Iterative, and Customizable Image Editing Workflow, https://arxiv.org/pdf/2504.09697, 2025-10-16
2025-11-11 00:58:26,635 - INFO - root - Page:9, Index:2, Mimic In-Context Learning for Multimodal Tasks, https://arxiv.org/pdf/2504.08851, 2025-05-17
2025-11-11 00:58:26,635 - INFO - root - Page:9, Index:3, Digital Twin Catalog: A Large-Scale Photorealistic 3D Object Digital Twin Dataset, https://arxiv.org/pdf/2504.08541, 2025-05-18
2025-11-11 00:58:26,636 - INFO - root - Page:9, Index:4, MMLA: Multi-Environment, Multi-Species, Low-Altitude Drone Dataset, https://arxiv.org/pdf/2504.07744, 2025-10-22
2025-11-11 00:58:26,636 - INFO - root - Fetching page 11 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=500
2025-11-11 00:58:33,326 - INFO - root - get_all_titles_from_web 
2025-11-11 00:58:33,326 - INFO - root - Page:10, Index:0, PromptHMR: Promptable Human Mesh Recovery, https://arxiv.org/pdf/2504.06397, 2025-05-23
2025-11-11 00:58:33,327 - INFO - root - Page:10, Index:1, SCAM: A Real-World Typographic Robustness Evaluation for Multimodal Foundation Models, https://arxiv.org/pdf/2504.04893, 2025-09-26
2025-11-11 00:58:33,327 - INFO - root - Fetching page 12 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=550
2025-11-11 00:58:39,492 - INFO - root - get_all_titles_from_web 
2025-11-11 00:58:39,492 - INFO - root - Page:11, Index:0, Charm: The Missing Piece in ViT fine-tuning for Image Aesthetic Assessment, https://arxiv.org/pdf/2504.02522, 2025-05-15
2025-11-11 00:58:39,493 - INFO - root - Page:11, Index:1, T*: Re-thinking Temporal Search for Long-Form Video Understanding, https://arxiv.org/pdf/2504.02259, 2025-08-24
2025-11-11 00:58:39,495 - INFO - root - Page:11, Index:2, CoMatcher: Multi-View Collaborative Feature Matching, https://arxiv.org/pdf/2504.01872, 2025-08-20
2025-11-11 00:58:39,495 - INFO - root - Page:11, Index:3, Think Small, Act Big: Primitive Prompt Learning for Lifelong Robot Manipulation, https://arxiv.org/pdf/2504.00420, 2025-06-01
2025-11-11 00:58:39,496 - INFO - root - Fetching page 13 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=600
2025-11-11 00:58:45,898 - INFO - root - get_all_titles_from_web 
2025-11-11 00:58:45,900 - INFO - root - Page:12, Index:0, It's a (Blind) Match! Towards Vision-Language Correspondence without Parallel Data, https://arxiv.org/pdf/2503.24129, 2025-05-29
2025-11-11 00:58:45,902 - INFO - root - Page:12, Index:1, ReferDINO-Plus: 2nd Solution for 4th PVUW MeViS Challenge at CVPR 2025, https://arxiv.org/pdf/2503.23509, 2025-05-29
2025-11-11 00:58:45,903 - INFO - root - Page:12, Index:2, A Unified Image-Dense Annotation Generation Model for Underwater Scenes, https://arxiv.org/pdf/2503.21771, 2025-07-27
2025-11-11 00:58:45,904 - INFO - root - Fetching page 14 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=650
2025-11-11 00:58:52,615 - INFO - root - get_all_titles_from_web 
2025-11-11 00:58:52,615 - INFO - root - Page:13, Index:0, Learning Class Prototypes for Unified Sparse Supervised 3D Object Detection, https://arxiv.org/pdf/2503.21099, 2025-06-13
2025-11-11 00:58:52,616 - INFO - root - Page:13, Index:1, LATTE-MV: Learning to Anticipate Table Tennis Hits from Monocular Videos, https://arxiv.org/pdf/2503.20936, 2025-09-01
2025-11-11 00:58:52,616 - INFO - root - Page:13, Index:2, BizGen: Advancing Article-level Visual Text Rendering for Infographics Generation, https://arxiv.org/pdf/2503.20672, 2025-07-02
2025-11-11 00:58:52,616 - INFO - root - Page:13, Index:3, ITA-MDT: Image-Timestep-Adaptive Masked Diffusion Transformer Framework for Image-Based Virtual Try-On, https://arxiv.org/pdf/2503.20418, 2025-06-01
2025-11-11 00:58:52,616 - INFO - root - Page:13, Index:4, Faster Parameter-Efficient Tuning with Token Redundancy Reduction, https://arxiv.org/pdf/2503.20282, 2025-08-26
2025-11-11 00:58:52,616 - INFO - root - Page:13, Index:5, DINeMo: Learning Neural Mesh Models with no 3D Annotations, https://arxiv.org/pdf/2503.20220, 2025-06-09
2025-11-11 00:58:52,618 - INFO - root - Page:13, Index:6, Scaling Vision Pre-Training to 4K Resolution, https://arxiv.org/pdf/2503.19903, 2025-08-03
2025-11-11 00:58:52,618 - INFO - root - Page:13, Index:7, GENIUS: A Generative Framework for Universal Multimodal Search, https://arxiv.org/pdf/2503.19868, 2025-06-05
2025-11-11 00:58:52,618 - INFO - root - Fetching page 15 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=700
2025-11-11 00:58:58,870 - INFO - root - get_all_titles_from_web 
2025-11-11 00:58:58,870 - INFO - root - Page:14, Index:0, Galaxy Walker: Geometry-aware VLMs For Galaxy-scale Understanding, https://arxiv.org/pdf/2503.18578, 2025-05-25
2025-11-11 00:58:58,871 - INFO - root - Page:14, Index:1, LookCloser: Frequency-aware Radiance Field for Tiny-Detail Scene, https://arxiv.org/pdf/2503.18513, 2025-07-29
2025-11-11 00:58:58,871 - INFO - root - Fetching page 16 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=750
2025-11-11 00:59:05,345 - INFO - root - get_all_titles_from_web 
2025-11-11 00:59:05,345 - INFO - root - Page:15, Index:0, LoTUS: Large-Scale Machine Unlearning with a Taste of Uncertainty, https://arxiv.org/pdf/2503.18314, 2025-05-29
2025-11-11 00:59:05,346 - INFO - root - Page:15, Index:1, MammAlps: A multi-view video behavior monitoring dataset of wild mammals in the Swiss Alps, https://arxiv.org/pdf/2503.18223, 2025-06-04
2025-11-11 00:59:05,346 - INFO - root - Page:15, Index:2, Progressive Prompt Detailing for Improved Alignment in Text-to-Image Generative Models, https://arxiv.org/pdf/2503.17794, 2025-05-30
2025-11-11 00:59:05,346 - INFO - root - Page:15, Index:3, CountLLM: Towards Generalizable Repetitive Action Counting via Large Language Model, https://arxiv.org/pdf/2503.17690, 2025-06-29
2025-11-11 00:59:05,346 - INFO - root - Page:15, Index:4, TaoAvatar: Real-Time Lifelike Full-Body Talking Avatars for Augmented Reality via 3D Gaussian Splatting, https://arxiv.org/pdf/2503.17032, 2025-07-23
2025-11-11 00:59:05,346 - INFO - root - Page:15, Index:5, Generalized Few-shot 3D Point Cloud Segmentation with Vision-Language Model, https://arxiv.org/pdf/2503.16282, 2025-05-20
2025-11-11 00:59:05,347 - INFO - root - Fetching page 17 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=800
2025-11-11 00:59:11,615 - INFO - root - get_all_titles_from_web 
2025-11-11 00:59:11,616 - INFO - root - Page:16, Index:0, High Temporal Consistency through Semantic Similarity Propagation in Semi-Supervised Video Semantic Segmentation for Autonomous Flight, https://arxiv.org/pdf/2503.15676, 2025-06-26
2025-11-11 00:59:11,616 - INFO - root - Page:16, Index:1, DPFlow: Adaptive Optical Flow Estimation with a Dual-Pyramid Framework, https://arxiv.org/pdf/2503.14880, 2025-09-29
2025-11-11 00:59:11,616 - INFO - root - Fetching page 18 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=850
2025-11-11 00:59:18,054 - INFO - root - get_all_titles_from_web 
2025-11-11 00:59:18,054 - INFO - root - Page:17, Index:0, From Head to Tail: Towards Balanced Representation in Large Vision-Language Models through Adaptive Data Calibration, https://arxiv.org/pdf/2503.12821, 2025-05-29
2025-11-11 00:59:18,055 - INFO - root - Page:17, Index:1, MambaIC: State Space Models for High-Performance Learned Image Compression, https://arxiv.org/pdf/2503.12461, 2025-08-22
2025-11-11 00:59:18,055 - INFO - root - Page:17, Index:2, Localized Concept Erasure for Text-to-Image Diffusion Models Using Training-Free Gated Low-Rank Adaptation, https://arxiv.org/pdf/2503.12356, 2025-07-09
2025-11-11 00:59:18,055 - INFO - root - Page:17, Index:3, TASTE-Rob: Advancing Video Generation of Task-Oriented Hand-Object Interaction for Generalizable Robotic Manipulation, https://arxiv.org/pdf/2503.11423, 2025-06-05
2025-11-11 00:59:18,056 - INFO - root - Page:17, Index:4, Panopticon: Advancing Any-Sensor Foundation Models for Earth Observation, https://arxiv.org/pdf/2503.10845, 2025-08-01
2025-11-11 00:59:18,056 - INFO - root - Page:17, Index:5, Transformers without Normalization, https://arxiv.org/pdf/2503.10622, 2025-06-14
2025-11-11 00:59:18,056 - INFO - root - Page:17, Index:6, dFLMoE: Decentralized Federated Learning via Mixture of Experts for Medical Data Analysis, https://arxiv.org/pdf/2503.10412, 2025-05-19
2025-11-11 00:59:18,056 - INFO - root - Fetching page 19 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=900
2025-11-11 00:59:25,452 - INFO - root - get_all_titles_from_web 
2025-11-11 00:59:25,452 - INFO - root - Page:18, Index:0, Project-Probe-Aggregate: Efficient Fine-Tuning for Group Robustness, https://arxiv.org/pdf/2503.09487, 2025-08-26
2025-11-11 00:59:25,453 - INFO - root - Page:18, Index:1, VLog: Video-Language Models by Generative Retrieval of Narration Vocabulary, https://arxiv.org/pdf/2503.09402, 2025-06-09
2025-11-11 00:59:25,453 - INFO - root - Fetching page 20 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=950
2025-11-11 00:59:32,206 - INFO - root - get_all_titles_from_web 
2025-11-11 00:59:32,207 - INFO - root - Page:19, Index:0, Escaping Plato's Cave: Towards the Alignment of 3D and Text Latent Spaces, https://arxiv.org/pdf/2503.05283, 2025-06-04
2025-11-11 00:59:32,207 - INFO - root - Page:19, Index:1, FluidNexus: 3D Fluid Reconstruction and Prediction from a Single Video, https://arxiv.org/pdf/2503.04720, 2025-07-09
2025-11-11 00:59:32,207 - INFO - root - Page:19, Index:2, Question-Aware Gaussian Experts for Audio-Visual Question Answering, https://arxiv.org/pdf/2503.04459, 2025-06-11
2025-11-11 00:59:32,209 - INFO - root - Page:19, Index:3, Q-Eval-100K: Evaluating Visual Quality and Alignment Level for Text-to-Vision Content, https://arxiv.org/pdf/2503.02357, 2025-06-15
2025-11-11 00:59:32,209 - INFO - root - Fetching page 21 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=1000
2025-11-11 00:59:38,894 - INFO - root - get_all_titles_from_web 
2025-11-11 00:59:38,895 - INFO - root - Page:20, Index:0, Data Distributional Properties As Inductive Bias for Systematic Generalization, https://arxiv.org/pdf/2502.20499, 2025-06-17
2025-11-11 00:59:38,895 - INFO - root - Page:20, Index:1, Knowledge Bridger: Towards Training-free Missing Modality Completion, https://arxiv.org/pdf/2502.19834, 2025-06-17
2025-11-11 00:59:38,896 - INFO - root - Fetching page 22 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=1050
2025-11-11 00:59:45,487 - INFO - root - get_all_titles_from_web 
2025-11-11 00:59:45,488 - INFO - root - Page:21, Index:0, MALT Diffusion: Memory-Augmented Latent Transformers for Any-Length Video Generation, https://arxiv.org/pdf/2502.12632, 2025-07-08
2025-11-11 00:59:45,488 - INFO - root - Page:21, Index:1, ILIAS: Instance-Level Image retrieval At Scale, https://arxiv.org/pdf/2502.11748, 2025-06-23
2025-11-11 00:59:45,489 - INFO - root - Page:21, Index:2, Distraction is All You Need for Multimodal Large Language Model Jailbreaking, https://arxiv.org/pdf/2502.10794, 2025-06-16
2025-11-11 00:59:45,489 - INFO - root - Page:21, Index:3, Spatial457: A Diagnostic Benchmark for 6D Spatial Reasoning of Large Multimodal Models, https://arxiv.org/pdf/2502.08636, 2025-06-08
2025-11-11 00:59:45,489 - INFO - root - Page:21, Index:4, TRAVEL: Training-Free Retrieval and Alignment for Vision-and-Language Navigation, https://arxiv.org/pdf/2502.07306, 2025-06-09
2025-11-11 00:59:45,490 - INFO - root - Page:21, Index:5, DiTASK: Multi-Task Fine-Tuning with Diffeomorphic Transformations, https://arxiv.org/pdf/2502.06029, 2025-06-01
2025-11-11 00:59:45,490 - INFO - root - Page:21, Index:6, ConceptAttention: Diffusion Transformers Learn Highly Interpretable Features, https://arxiv.org/pdf/2502.04320, 2025-07-01
2025-11-11 00:59:45,490 - INFO - root - Page:21, Index:7, GCE-Pose: Global Context Enhancement for Category-level Object Pose Estimation, https://arxiv.org/pdf/2502.04293, 2025-06-24
2025-11-11 00:59:45,491 - INFO - root - Page:21, Index:8, Calibrated Multi-Preference Optimization for Aligning Diffusion Models, https://arxiv.org/pdf/2502.02588, 2025-09-26
2025-11-11 00:59:45,491 - INFO - root - Page:21, Index:9, Instruct-4DGS: Efficient Dynamic Scene Editing via 4D Gaussian-based Static-Dynamic Separation, https://arxiv.org/pdf/2502.02091, 2025-07-01
2025-11-11 00:59:45,494 - INFO - root - Page:21, Index:10, Low-Resource Video Super-Resolution using Memory, Wavelets, and Deformable Convolutions, https://arxiv.org/pdf/2502.01816, 2025-06-19
2025-11-11 00:59:45,494 - INFO - root - Page:21, Index:11, Bridging Text and Crystal Structures: Literature-driven Contrastive Learning for Materials Science, https://arxiv.org/pdf/2501.12919, 2025-06-18
2025-11-11 00:59:45,495 - INFO - root - Page:21, Index:12, T2ISafety: Benchmark for Assessing Fairness, Toxicity, and Privacy in Image Generation, https://arxiv.org/pdf/2501.12612, 2025-07-25
2025-11-11 00:59:45,495 - INFO - root - Page:21, Index:13, Fine-Grained Image-Text Correspondence with Cost Aggregation for Open-Vocabulary Part Segmentation, https://arxiv.org/pdf/2501.09688, 2025-08-08
2025-11-11 00:59:45,496 - INFO - root - Fetching page 23 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=1100
2025-11-11 00:59:52,080 - INFO - root - get_all_titles_from_web 
2025-11-11 00:59:52,081 - INFO - root - Page:22, Index:0, Bias for Action: Video Implicit Neural Representations with Bias Modulation, https://arxiv.org/pdf/2501.09277, 2025-06-06
2025-11-11 00:59:52,081 - INFO - root - Page:22, Index:1, MonSter++: Unified Stereo Matching, Multi-view Stereo, and Real-time Stereo with Monodepth Priors, https://arxiv.org/pdf/2501.08643, 2025-09-25
2025-11-11 00:59:52,081 - INFO - root - Page:22, Index:2, Go-with-the-Flow: Motion-Controllable Video Diffusion Models Using Real-Time Warped Noise, https://arxiv.org/pdf/2501.08331, 2025-08-06
2025-11-11 00:59:52,081 - INFO - root - Page:22, Index:3, Nonisotropic Gaussian Diffusion for Realistic 3D Human Motion Prediction, https://arxiv.org/pdf/2501.06035, 2025-07-08
2025-11-11 00:59:52,082 - INFO - root - Page:22, Index:4, Discovering Hidden Visual Concepts Beyond Linguistic Input in Infant Learning, https://arxiv.org/pdf/2501.05205, 2025-06-13
2025-11-11 00:59:52,082 - INFO - root - Page:22, Index:5, PERSE: Personalized 3D Generative Avatars from A Single Portrait, https://arxiv.org/pdf/2412.21206, 2025-09-28
2025-11-11 00:59:52,083 - INFO - root - Page:22, Index:6, MaskGaussian: Adaptive 3D Gaussian Representation from Probabilistic Masks, https://arxiv.org/pdf/2412.20522, 2025-06-14
2025-11-11 00:59:52,083 - INFO - root - Page:22, Index:7, SimLTD: Simple Supervised and Semi-Supervised Long-Tailed Object Detection, https://arxiv.org/pdf/2412.20047, 2025-06-09
2025-11-11 00:59:52,084 - INFO - root - Page:22, Index:8, Conditional Balance: Improving Multi-Conditioning Trade-Offs in Image Generation, https://arxiv.org/pdf/2412.19853, 2025-08-03
2025-11-11 00:59:52,084 - INFO - root - Fetching page 24 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=1150
2025-11-11 00:59:58,480 - INFO - root - get_all_titles_from_web 
2025-11-11 00:59:58,481 - INFO - root - Page:23, Index:0, CoCoGaussian: Leveraging Circle of Confusion for Gaussian Splatting from Defocused Images, https://arxiv.org/pdf/2412.16028, 2025-05-15
2025-11-11 00:59:58,481 - INFO - root - Page:23, Index:1, EnergyMoGen: Compositional Human Motion Generation with Energy-Based Diffusion Model in Latent Space, https://arxiv.org/pdf/2412.14706, 2025-06-04
2025-11-11 00:59:58,481 - INFO - root - Page:23, Index:2, DarkIR: Robust Low-Light Image Restoration, https://arxiv.org/pdf/2412.13443, 2025-10-14
2025-11-11 00:59:58,482 - INFO - root - Page:23, Index:3, FastVLM: Efficient Vision Encoding for Vision Language Models, https://arxiv.org/pdf/2412.13303, 2025-05-15
2025-11-11 00:59:58,482 - INFO - root - Page:23, Index:4, Real-time Free-view Human Rendering from Sparse-view RGB Videos using Double Unprojected Textures, https://arxiv.org/pdf/2412.13183, 2025-06-20
2025-11-11 00:59:58,482 - INFO - root - Page:23, Index:5, CondiMen: Conditional Multi-Person Mesh Recovery, https://arxiv.org/pdf/2412.13058, 2025-06-04
2025-11-11 00:59:58,483 - INFO - root - Page:23, Index:6, MASt3R-SLAM: Real-Time Dense SLAM with 3D Reconstruction Priors, https://arxiv.org/pdf/2412.12392, 2025-06-02
2025-11-11 00:59:58,483 - INFO - root - Page:23, Index:7, DynamicScaler: Seamless and Scalable Video Generation for Panoramic Scenes, https://arxiv.org/pdf/2412.11100, 2025-10-04
2025-11-11 00:59:58,483 - INFO - root - Page:23, Index:8, SnapGen-V: Generating a Five-Second Video within Five Seconds on a Mobile Device, https://arxiv.org/pdf/2412.10494, 2025-06-09
2025-11-11 00:59:58,485 - INFO - root - Page:23, Index:9, Mr. DETR++: Instructive Multi-Route Training for Detection Transformers with Mixture-of-Experts, https://arxiv.org/pdf/2412.10028, 2025-06-26
2025-11-11 00:59:58,485 - INFO - root - Page:23, Index:10, LinGen: Towards High-Resolution Minute-Length Text-to-Video Generation with Linear Computational Complexity, https://arxiv.org/pdf/2412.09856, 2025-05-24
2025-11-11 00:59:58,485 - INFO - root - Page:23, Index:11, Gaze-LLE: Gaze Target Estimation via Large-Scale Learned Encoders, https://arxiv.org/pdf/2412.09586, 2025-06-03
2025-11-11 00:59:58,486 - INFO - root - Fetching page 25 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=1200
2025-11-11 01:00:05,427 - INFO - root - get_all_titles_from_web 
2025-11-11 01:00:05,427 - INFO - root - Page:24, Index:0, From Slow Bidirectional to Fast Autoregressive Video Diffusion Models, https://arxiv.org/pdf/2412.07772, 2025-09-23
2025-11-11 01:00:05,428 - INFO - root - Page:24, Index:1, Rate-In: Information-Driven Adaptive Dropout Rates for Improved Inference-Time Uncertainty Estimation, https://arxiv.org/pdf/2412.07169, 2025-06-03
2025-11-11 01:00:05,428 - INFO - root - Page:24, Index:2, FIRE: Robust Detection of Diffusion-Generated Images via Frequency-Guided Reconstruction Error, https://arxiv.org/pdf/2412.07140, 2025-11-03
2025-11-11 01:00:05,430 - INFO - root - Page:24, Index:3, Birth and Death of a Rose, https://arxiv.org/pdf/2412.05278, 2025-06-05
2025-11-11 01:00:05,430 - INFO - root - Page:24, Index:4, DualPM: Dual Posed-Canonical Point Maps for 3D Shape and Pose Reconstruction, https://arxiv.org/pdf/2412.04464, 2025-08-14
2025-11-11 01:00:05,431 - INFO - root - Page:24, Index:5, SeeGround: See and Ground for Zero-Shot Open-Vocabulary 3D Visual Grounding, https://arxiv.org/pdf/2412.04383, 2025-05-29
2025-11-11 01:00:05,431 - INFO - root - ------------------------------------------------------------------------------------------------------------------------
2025-11-11 01:00:05,432 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\CVPR 2025\Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness.pdf
2025-11-11 01:00:05,458 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\CVPR 2025\OmniTrack++_ Omnidirectional Multi-Object Tracking by Learning Large-FoV Traject.pdf
2025-11-11 01:00:05,459 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\CVPR 2025\NeuCo-Bench_ A Novel Benchmark Framework for Neural Embeddings in Earth Observat.pdf
2025-11-11 01:00:05,460 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\CVPR 2025\NTIRE 2025 Challenge on Low Light Image Enhancement_ Methods and Results.pdf
2025-11-11 01:00:05,462 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\CVPR 2025\Class Prototypes based Contrastive Learning for Classifying Multi-Label and Fine.pdf
2025-11-11 01:00:05,466 - INFO - root - 正在总结论文 1/5: Learning to Seek Evidence: A Verifiable Reasoning Agent with Causal Faithfulness Analysis
2025-11-11 01:05:44,477 - INFO - root - 正在提取论文图片...
2025-11-11 01:05:44,633 - INFO - root - 已保存图片 1/10：./export\CVPR\images\figure_1_page2.jpeg
2025-11-11 01:05:44,640 - INFO - root - 已保存图片 2/10：./export\CVPR\images\figure_2_page2.jpeg
2025-11-11 01:05:44,647 - INFO - root - 已保存图片 3/10：./export\CVPR\images\figure_3_page2.jpeg
2025-11-11 01:05:44,657 - INFO - root - 已保存图片 4/10：./export\CVPR\images\figure_4_page2.jpeg
2025-11-11 01:05:44,663 - INFO - root - 已保存图片 5/10：./export\CVPR\images\figure_5_page2.jpeg
2025-11-11 01:05:44,673 - INFO - root - 已保存图片 6/10：./export\CVPR\images\figure_6_page2.jpeg
2025-11-11 01:05:44,688 - INFO - root - 已保存图片 7/10：./export\CVPR\images\figure_7_page2.jpeg
2025-11-11 01:05:44,696 - INFO - root - 已保存图片 8/10：./export\CVPR\images\figure_8_page2.jpeg
2025-11-11 01:05:44,727 - INFO - root - 已保存图片 9/10：./export\CVPR\images\figure_9_page2.jpeg
2025-11-11 01:05:44,738 - INFO - root - 已保存图片 10/10：./export\CVPR\images\figure_10_page2.jpeg
2025-11-11 01:05:44,739 - INFO - root - 成功添加图片 1：./export\CVPR\images\figure_1_page2.jpeg
2025-11-11 01:05:44,740 - INFO - root - 成功添加图片 2：./export\CVPR\images\figure_2_page2.jpeg
2025-11-11 01:05:44,740 - INFO - root - 成功添加图片 3：./export\CVPR\images\figure_3_page2.jpeg
2025-11-11 01:05:44,741 - INFO - root - 成功添加图片 4：./export\CVPR\images\figure_4_page2.jpeg
2025-11-11 01:05:44,741 - INFO - root - 成功添加图片 5：./export\CVPR\images\figure_5_page2.jpeg
2025-11-11 01:05:44,741 - INFO - root - 成功添加图片 6：./export\CVPR\images\figure_6_page2.jpeg
2025-11-11 01:05:44,741 - INFO - root - 成功添加图片 7：./export\CVPR\images\figure_7_page2.jpeg
2025-11-11 01:05:44,743 - INFO - root - 成功添加图片 8：./export\CVPR\images\figure_8_page2.jpeg
2025-11-11 01:05:44,743 - INFO - root - 成功添加图片 9：./export\CVPR\images\figure_9_page2.jpeg
2025-11-11 01:05:44,744 - INFO - root - 成功添加图片 10：./export\CVPR\images\figure_10_page2.jpeg
2025-11-11 01:05:44,745 - INFO - root - 论文《Learning to Seek Evidence: A Verifiable Reasoning Agent with Causal Faithfulness Analysis》的分析已保存到 ./export\CVPR\Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness.md
2025-11-11 01:05:44,748 - INFO - root - 正在总结论文 2/5: OmniTrack++: Omnidirectional Multi-Object Tracking by Learning Large-FoV Trajectory Feedback
2025-11-11 01:08:13,804 - INFO - root - 正在提取论文图片...
2025-11-11 01:08:14,324 - INFO - root - 已保存图片 1/10：./export\CVPR\images\figure_1_page13.jpeg
2025-11-11 01:08:14,403 - INFO - root - 已保存图片 2/10：./export\CVPR\images\figure_2_page13.jpeg
2025-11-11 01:08:14,460 - INFO - root - 已保存图片 3/10：./export\CVPR\images\figure_3_page13.jpeg
2025-11-11 01:08:14,525 - INFO - root - 已保存图片 4/10：./export\CVPR\images\figure_4_page2.jpeg
2025-11-11 01:08:14,586 - INFO - root - 已保存图片 5/10：./export\CVPR\images\figure_5_page5.png
2025-11-11 01:08:14,630 - INFO - root - 已保存图片 6/10：./export\CVPR\images\figure_6_page13.jpeg
2025-11-11 01:08:14,694 - INFO - root - 已保存图片 7/10：./export\CVPR\images\figure_7_page2.jpeg
2025-11-11 01:08:14,733 - INFO - root - 已保存图片 8/10：./export\CVPR\images\figure_8_page8.jpeg
2025-11-11 01:08:14,752 - INFO - root - 已保存图片 9/10：./export\CVPR\images\figure_9_page1.jpeg
2025-11-11 01:08:14,772 - INFO - root - 已保存图片 10/10：./export\CVPR\images\figure_10_page1.png
2025-11-11 01:08:14,779 - INFO - root - 成功添加图片 1：./export\CVPR\images\figure_1_page13.jpeg
2025-11-11 01:08:14,779 - INFO - root - 成功添加图片 2：./export\CVPR\images\figure_2_page13.jpeg
2025-11-11 01:08:14,780 - INFO - root - 成功添加图片 3：./export\CVPR\images\figure_3_page13.jpeg
2025-11-11 01:08:14,785 - INFO - root - 成功添加图片 4：./export\CVPR\images\figure_4_page2.jpeg
2025-11-11 01:08:14,786 - INFO - root - 成功添加图片 5：./export\CVPR\images\figure_5_page5.png
2025-11-11 01:08:14,787 - INFO - root - 成功添加图片 6：./export\CVPR\images\figure_6_page13.jpeg
2025-11-11 01:08:14,787 - INFO - root - 成功添加图片 7：./export\CVPR\images\figure_7_page2.jpeg
2025-11-11 01:08:14,787 - INFO - root - 成功添加图片 8：./export\CVPR\images\figure_8_page8.jpeg
2025-11-11 01:08:14,789 - INFO - root - 成功添加图片 9：./export\CVPR\images\figure_9_page1.jpeg
2025-11-11 01:08:14,789 - INFO - root - 成功添加图片 10：./export\CVPR\images\figure_10_page1.png
2025-11-11 01:08:14,792 - INFO - root - 论文《OmniTrack++: Omnidirectional Multi-Object Tracking by Learning Large-FoV Trajectory Feedback》的分析已保存到 ./export\CVPR\OmniTrack++_ Omnidirectional Multi-Object Tracking by Learning Large-FoV Traject.md
2025-11-11 01:08:14,796 - INFO - root - 正在总结论文 3/5: NeuCo-Bench: A Novel Benchmark Framework for Neural Embeddings in Earth Observation
2025-11-11 01:08:26,361 - INFO - root - LLMClient: rate limit reached, sleeping 20.0s
2025-11-11 01:10:01,803 - INFO - root - 尝试使用 utf-8 编码读取配置文件...
2025-11-11 01:10:01,804 - INFO - root - 成功使用 utf-8 编码读取配置文件
2025-11-11 01:10:01,807 - INFO - root - 已将配置文件转换为 UTF-8 编码
2025-11-11 01:10:04,399 - INFO - root - LLMClientManager: 指定使用客户端: Gemini
2025-11-11 01:10:05,827 - INFO - root - GeminiClient: trying model models/gemini-2.5-flash
2025-11-11 01:10:09,206 - INFO - root - GeminiClient: initialized model gemini-2.5-flash
2025-11-11 01:10:09,207 - INFO - root - LLMClientManager: Gemini 客户端初始化成功
2025-11-11 01:10:09,208 - INFO - root - LLMClientManager: switched to Gemini client
2025-11-11 01:10:09,208 - INFO - root - 已手动切换到 LLM 客户端: Gemini
2025-11-11 01:10:09,208 - INFO - root - 使用 LLM 模型: gemini-2.5-flash
2025-11-11 01:10:09,209 - INFO - root - 可用客户端: ['Gemini']
2025-11-11 01:10:09,209 - INFO - root - === 运行配置 ===
2025-11-11 01:10:09,210 - INFO - root - 处理模式: arxiv在线搜索
2025-11-11 01:10:09,211 - INFO - root - 关键词: CVPR
2025-11-11 01:10:09,211 - INFO - root - 查询: CVPR 2025
2025-11-11 01:10:09,211 - INFO - root - 排序: None
2025-11-11 01:10:09,217 - INFO - root - 最近天数: 180
2025-11-11 01:10:09,217 - INFO - root - 最大处理数量: 50
2025-11-11 01:10:09,219 - INFO - root - 保存图片: 是
2025-11-11 01:10:09,219 - INFO - root - 输出语言: 中文
2025-11-11 01:10:09,221 - INFO - root - 强制重新处理: 否
2025-11-11 01:10:09,222 - INFO - root - ====================
2025-11-11 01:10:09,222 - INFO - root - 使用 arXiv 搜索模式（通过 chat_arxiv 模块获取）
2025-11-11 01:10:09,222 - INFO - root - Fetching page 1 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50
2025-11-11 01:10:20,191 - INFO - root - get_all_titles_from_web 
2025-11-11 01:10:20,193 - INFO - root - Page:0, Index:0, Learning to Seek Evidence: A Verifiable Reasoning Agent with Causal Faithfulness Analysis, https://arxiv.org/pdf/2511.01425, 2025-11-03
2025-11-11 01:10:20,193 - INFO - root - Page:0, Index:1, OmniTrack++: Omnidirectional Multi-Object Tracking by Learning Large-FoV Trajectory Feedback, https://arxiv.org/pdf/2511.00510, 2025-11-01
2025-11-11 01:10:20,193 - INFO - root - Page:0, Index:2, NeuCo-Bench: A Novel Benchmark Framework for Neural Embeddings in Earth Observation, https://arxiv.org/pdf/2510.17914, 2025-10-19
2025-11-11 01:10:20,194 - INFO - root - Page:0, Index:3, NTIRE 2025 Challenge on Low Light Image Enhancement: Methods and Results, https://arxiv.org/pdf/2510.13670, 2025-10-15
2025-11-11 01:10:20,194 - INFO - root - Page:0, Index:4, Class Prototypes based Contrastive Learning for Classifying Multi-Label and Fine-Grained Educational Videos, https://arxiv.org/pdf/2510.11204, 2025-10-13
2025-11-11 01:10:20,194 - INFO - root - Page:0, Index:5, MIMO: A medical vision language model with visual referring multimodal input and pixel grounding multimodal output, https://arxiv.org/pdf/2510.10011, 2025-10-11
2025-11-11 01:10:20,194 - INFO - root - Page:0, Index:6, Vision Language Models: A Survey of 26K Papers, https://arxiv.org/pdf/2510.09586, 2025-10-10
2025-11-11 01:10:20,195 - INFO - root - Page:0, Index:7, DiT-VTON: Diffusion Transformer Framework for Unified Multi-Category Virtual Try-On and Virtual Try-All with Integrated Image Editing, https://arxiv.org/pdf/2510.04797, 2025-10-03
2025-11-11 01:10:20,195 - INFO - root - Page:0, Index:8, PatchVSR: Breaking Video Diffusion Resolution Limits with Patch-wise Video Super-Resolution, https://arxiv.org/pdf/2509.26025, 2025-09-30
2025-11-11 01:10:20,195 - INFO - root - Page:0, Index:9, FreqDebias: Towards Generalizable Deepfake Detection via Consistency-Driven Frequency Debiasing, https://arxiv.org/pdf/2509.22412, 2025-09-26
2025-11-11 01:10:20,195 - INFO - root - Page:0, Index:10, A Mutual Learning Method for Salient Object Detection with intertwined Multi-Supervision--Revised, https://arxiv.org/pdf/2509.21363, 2025-09-21
2025-11-11 01:10:20,195 - INFO - root - Page:0, Index:11, InstructVTON: Optimal Auto-Masking and Natural-Language-Guided Interactive Style Control for Inpainting-Based Virtual Try-On, https://arxiv.org/pdf/2509.20524, 2025-09-24
2025-11-11 01:10:20,196 - INFO - root - Page:0, Index:12, Efficient Encoder-Free Pose Conditioning and Pose Control for Virtual Try-On, https://arxiv.org/pdf/2509.20343, 2025-09-24
2025-11-11 01:10:20,196 - INFO - root - Page:0, Index:13, The Photographer Eye: Teaching Multimodal Large Language Models to Understand Image Aesthetics like Photographers, https://arxiv.org/pdf/2509.18582, 2025-10-22
2025-11-11 01:10:20,196 - INFO - root - Page:0, Index:14, ENSAM: an efficient foundation model for interactive segmentation of 3D medical images, https://arxiv.org/pdf/2509.15874, 2025-09-19
2025-11-11 01:10:20,196 - INFO - root - Page:0, Index:15, DEFT-VTON: Efficient Virtual Try-On with Consistent Generalised H-Transform, https://arxiv.org/pdf/2509.13506, 2025-09-16
2025-11-11 01:10:20,197 - INFO - root - Page:0, Index:16, Weakly and Self-Supervised Class-Agnostic Motion Prediction for Autonomous Driving, https://arxiv.org/pdf/2509.13116, 2025-09-16
2025-11-11 01:10:20,197 - INFO - root - Page:0, Index:17, Domain-Adaptive Pretraining Improves Primate Behavior Recognition, https://arxiv.org/pdf/2509.12193, 2025-09-15
2025-11-11 01:10:20,197 - INFO - root - Page:0, Index:18, The System Description of CPS Team for Track on Driving with Language of CVPR 2024 Autonomous Grand Challenge, https://arxiv.org/pdf/2509.11071, 2025-09-13
2025-11-11 01:10:20,197 - INFO - root - Page:0, Index:19, An HMM-based framework for identity-aware long-term multi-object tracking from sparse and uncertain identification: use case on long-term tracking in livestock, https://arxiv.org/pdf/2509.09962, 2025-09-12
2025-11-11 01:10:20,198 - INFO - root - Page:0, Index:20, InterAct: Advancing Large-Scale Versatile 3D Human-Object Interaction Generation, https://arxiv.org/pdf/2509.09555, 2025-09-11
2025-11-11 01:10:20,198 - INFO - root - Page:0, Index:21, Geospatial Foundational Embedder: Top-1 Winning Solution on EarthVision Embed2Scale Challenge (CVPR 2025), https://arxiv.org/pdf/2509.06993, 2025-09-03
2025-11-11 01:10:20,198 - INFO - root - Page:0, Index:22, 2nd Place Solution for CVPR2024 E2E Challenge: End-to-End Autonomous Driving Using Vision Language Model, https://arxiv.org/pdf/2509.02659, 2025-09-02
2025-11-11 01:10:20,198 - INFO - root - Page:0, Index:23, Unsupervised Training of Vision Transformers with Synthetic Negatives, https://arxiv.org/pdf/2509.02024, 2025-09-02
2025-11-11 01:10:20,198 - INFO - root - Page:0, Index:24, MV-SSM: Multi-View State Space Modeling for 3D Human Pose Estimation, https://arxiv.org/pdf/2509.00649, 2025-08-30
2025-11-11 01:10:20,198 - INFO - root - Page:0, Index:25, CryptoFace: End-to-End Encrypted Face Recognition, https://arxiv.org/pdf/2509.00332, 2025-08-29
2025-11-11 01:10:20,199 - INFO - root - Page:0, Index:26, ControlEchoSynth: Boosting Ejection Fraction Estimation Models via Controlled Video Diffusion, https://arxiv.org/pdf/2508.17631, 2025-08-26
2025-11-11 01:10:20,199 - INFO - root - Page:0, Index:27, Explain Before You Answer: A Survey on Compositional Visual Reasoning, https://arxiv.org/pdf/2508.17298, 2025-08-27
2025-11-11 01:10:20,199 - INFO - root - Page:0, Index:28, Investigating Different Geo Priors for Image Classification, https://arxiv.org/pdf/2508.15946, 2025-08-21
2025-11-11 01:10:20,199 - INFO - root - Page:0, Index:29, Towards Source-Free Machine Unlearning, https://arxiv.org/pdf/2508.15127, 2025-08-20
2025-11-11 01:10:20,199 - INFO - root - Page:0, Index:30, MR6D: Benchmarking 6D Pose Estimation for Mobile Robots, https://arxiv.org/pdf/2508.13775, 2025-08-19
2025-11-11 01:10:20,199 - INFO - root - Page:0, Index:31, Calibrating Biased Distribution in VFM-derived Latent Space via Cross-Domain Geometric Consistency, https://arxiv.org/pdf/2508.13518, 2025-08-19
2025-11-11 01:10:20,199 - INFO - root - Page:0, Index:32, SIS-Challenge: Event-based Spatio-temporal Instance Segmentation Challenge at the CVPR 2025 Event-based Vision Workshop, https://arxiv.org/pdf/2508.12813, 2025-08-18
2025-11-11 01:10:20,200 - INFO - root - Page:0, Index:33, Multi-Level Knowledge Distillation and Dynamic Self-Supervised Learning for Continual Learning, https://arxiv.org/pdf/2508.12692, 2025-08-22
2025-11-11 01:10:20,201 - INFO - root - Page:0, Index:34, Stochastic-based Patch Filtering for Few-Shot Learning, https://arxiv.org/pdf/2508.10066, 2025-08-13
2025-11-11 01:10:20,202 - INFO - root - Page:0, Index:35, Slot Attention-based Feature Filtering for Few-Shot Learning, https://arxiv.org/pdf/2508.09699, 2025-08-13
2025-11-11 01:10:20,204 - INFO - root - Page:0, Index:36, Comparison Reveals Commonality: Customized Image Generation through Contrastive Inversion, https://arxiv.org/pdf/2508.07755, 2025-08-11
2025-11-11 01:10:20,204 - INFO - root - Page:0, Index:37, SLRTP2025 Sign Language Production Challenge: Methodology, Results, and Future Work, https://arxiv.org/pdf/2508.06951, 2025-08-09
2025-11-11 01:10:20,205 - INFO - root - Page:0, Index:38, Exploring Fairness across Fine-Grained Attributes in Large Vision-Language Models, https://arxiv.org/pdf/2508.03079, 2025-08-05
2025-11-11 01:10:20,205 - INFO - root - Page:0, Index:39, Devil is in the Detail: Towards Injecting Fine Details of Image Prompt in Image Generation via Conflict-free Guidance and Stratified Attention, https://arxiv.org/pdf/2508.02004, 2025-08-03
2025-11-11 01:10:20,205 - INFO - root - Page:0, Index:40, IAUNet: Instance-Aware U-Net, https://arxiv.org/pdf/2508.01928, 2025-08-03
2025-11-11 01:10:20,208 - INFO - root - Page:0, Index:41, Gaussian Splatting Feature Fields for Privacy-Preserving Visual Localization, https://arxiv.org/pdf/2507.23569, 2025-08-26
2025-11-11 01:10:20,208 - INFO - root - Page:0, Index:42, From Scan to Action: Leveraging Realistic Scans for Embodied Scene Understanding, https://arxiv.org/pdf/2507.17585, 2025-07-23
2025-11-11 01:10:20,210 - INFO - root - Page:0, Index:43, LEAD: Exploring Logit Space Evolution for Model Selection, https://arxiv.org/pdf/2507.14559, 2025-07-19
2025-11-11 01:10:20,211 - INFO - root - Page:0, Index:44, HeCoFuse: Cross-Modal Complementary V2X Cooperative Perception with Heterogeneous Sensors, https://arxiv.org/pdf/2507.13677, 2025-07-18
2025-11-11 01:10:20,211 - INFO - root - Page:0, Index:45, OmniVec2 -- A Novel Transformer based Network for Large Scale Multimodal and Multitask Learning, https://arxiv.org/pdf/2507.13364, 2025-07-06
2025-11-11 01:10:20,211 - INFO - root - Page:0, Index:46, A Training-Free, Task-Agnostic Framework for Enhancing MLLM Performance on High-Resolution Images, https://arxiv.org/pdf/2507.10202, 2025-07-14
2025-11-11 01:10:20,212 - INFO - root - Page:0, Index:47, Quantum Federated Learning for Multimodal Data: A Modality-Agnostic Approach, https://arxiv.org/pdf/2507.08217, 2025-07-10
2025-11-11 01:10:20,212 - INFO - root - Page:0, Index:48, CuriosAI Submission to the EgoExo4D Proficiency Estimation Challenge 2025, https://arxiv.org/pdf/2507.08022, 2025-07-08
2025-11-11 01:10:20,212 - INFO - root - Page:0, Index:49, Rethinking Query-based Transformer for Continual Image Segmentation, https://arxiv.org/pdf/2507.07831, 2025-07-10
2025-11-11 01:10:20,212 - INFO - root - Fetching page 2 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=50
2025-11-11 01:10:30,495 - INFO - root - get_all_titles_from_web 
2025-11-11 01:10:30,495 - INFO - root - Page:1, Index:0, Scalable and Realistic Virtual Try-on Application for Foundation Makeup with Kubelka-Munk Theory, https://arxiv.org/pdf/2507.07333, 2025-07-09
2025-11-11 01:10:30,496 - INFO - root - Page:1, Index:1, Free on the Fly: Enhancing Flexibility in Test-Time Adaptation with Online EM, https://arxiv.org/pdf/2507.06973, 2025-07-09
2025-11-11 01:10:30,496 - INFO - root - Page:1, Index:2, Adaptive Part Learning for Fine-Grained Generalized Category Discovery: A Plug-and-Play Enhancement, https://arxiv.org/pdf/2507.06928, 2025-07-09
2025-11-11 01:10:30,496 - INFO - root - Page:1, Index:3, Grounded Gesture Generation: Language, Motion, and Space, https://arxiv.org/pdf/2507.04522, 2025-07-06
2025-11-11 01:10:30,497 - INFO - root - Page:1, Index:4, Comprehensive Information Bottleneck for Unveiling Universal Attribution to Interpret Vision Transformers, https://arxiv.org/pdf/2507.04388, 2025-07-06
2025-11-11 01:10:30,497 - INFO - root - Page:1, Index:5, ZERO: Industry-ready Vision Foundation Model with Multi-modal Prompts, https://arxiv.org/pdf/2507.04270, 2025-11-07
2025-11-11 01:10:30,498 - INFO - root - Page:1, Index:6, Beyond Accuracy: Metrics that Uncover What Makes a 'Good' Visual Descriptor, https://arxiv.org/pdf/2507.03542, 2025-07-08
2025-11-11 01:10:30,498 - INFO - root - Page:1, Index:7, ConceptMix++: Leveling the Playing Field in Text-to-Image Benchmarking via Iterative Prompt Optimization, https://arxiv.org/pdf/2507.03275, 2025-07-03
2025-11-11 01:10:30,498 - INFO - root - Page:1, Index:8, APT: Adaptive Personalized Training for Diffusion Models with Limited Data, https://arxiv.org/pdf/2507.02687, 2025-07-03
2025-11-11 01:10:30,498 - INFO - root - Page:1, Index:9, DreamComposer++: Empowering Diffusion Models with Multi-View Conditions for 3D Content Generation, https://arxiv.org/pdf/2507.02299, 2025-07-03
2025-11-11 01:10:30,499 - INFO - root - Page:1, Index:10, Soft Self-labeling and Potts Relaxations for Weakly-Supervised Segmentation, https://arxiv.org/pdf/2507.01721, 2025-07-02
2025-11-11 01:10:30,499 - INFO - root - Page:1, Index:11, Interpolation-Based Event Visual Data Filtering Algorithms, https://arxiv.org/pdf/2507.01557, 2025-07-02
2025-11-11 01:10:30,499 - INFO - root - Page:1, Index:12, AVC-DPO: Aligned Video Captioning via Direct Preference Optimization, https://arxiv.org/pdf/2507.01492, 2025-07-02
2025-11-11 01:10:30,499 - INFO - root - Page:1, Index:13, NN-Former: Rethinking Graph Structure in Neural Architecture Representation, https://arxiv.org/pdf/2507.00880, 2025-07-01
2025-11-11 01:10:30,499 - INFO - root - Page:1, Index:14, Instant Particle Size Distribution Measurement Using CNNs Trained on Synthetic Data, https://arxiv.org/pdf/2507.00822, 2025-07-01
2025-11-11 01:10:30,500 - INFO - root - Page:1, Index:15, Moment Sampling in Video LLMs for Long-Form Video QA, https://arxiv.org/pdf/2507.00033, 2025-06-17
2025-11-11 01:10:30,502 - INFO - root - Page:1, Index:16, Revisiting Audio-Visual Segmentation with Vision-Centric Transformer, https://arxiv.org/pdf/2506.23623, 2025-06-30
2025-11-11 01:10:30,502 - INFO - root - Page:1, Index:17, MTADiffusion: Mask Text Alignment Diffusion Model for Object Inpainting, https://arxiv.org/pdf/2506.23482, 2025-06-29
2025-11-11 01:10:30,502 - INFO - root - Page:1, Index:18, Benchmarking Generalizable Bimanual Manipulation: RoboTwin Dual-Arm Collaboration Challenge at CVPR 2025 MEIS Workshop, https://arxiv.org/pdf/2506.23351, 2025-07-02
2025-11-11 01:10:30,502 - INFO - root - Page:1, Index:19, Prompting without Panic: Attribute-aware, Zero-shot, Test-Time Calibration, https://arxiv.org/pdf/2506.22819, 2025-06-28
2025-11-11 01:10:30,503 - INFO - root - Page:1, Index:20, Analyzing and Fine-Tuning Whisper Models for Multilingual Pilot Speech Transcription in the Cockpit, https://arxiv.org/pdf/2506.21990, 2025-06-27
2025-11-11 01:10:30,503 - INFO - root - Page:1, Index:21, SceneDiffuser++: City-Scale Traffic Simulation via a Generative World Model, https://arxiv.org/pdf/2506.21976, 2025-06-27
2025-11-11 01:10:30,504 - INFO - root - Page:1, Index:22, DIVE: Deep-search Iterative Video Exploration A Technical Report for the CVRR Challenge at CVPR 2025, https://arxiv.org/pdf/2506.21891, 2025-06-27
2025-11-11 01:10:30,504 - INFO - root - Page:1, Index:23, End-to-End RGB-IR Joint Image Compression With Channel-wise Cross-modality Entropy Model, https://arxiv.org/pdf/2506.21851, 2025-06-26
2025-11-11 01:10:30,505 - INFO - root - Page:1, Index:24, Distilling Normalizing Flows, https://arxiv.org/pdf/2506.21003, 2025-06-26
2025-11-11 01:10:30,508 - INFO - root - Page:1, Index:25, Joint attitude estimation and 3D neural reconstruction of non-cooperative space objects, https://arxiv.org/pdf/2506.20638, 2025-06-25
2025-11-11 01:10:30,508 - INFO - root - Page:1, Index:26, Accept More, Reject Less: Reducing up to 19% Unnecessary Desk-Rejections over 11 Years of ICLR Data, https://arxiv.org/pdf/2506.20141, 2025-06-25
2025-11-11 01:10:30,509 - INFO - root - Page:1, Index:27, SceneCrafter: Controllable Multi-View Driving Scene Editing, https://arxiv.org/pdf/2506.19488, 2025-06-24
2025-11-11 01:10:30,509 - INFO - root - Page:1, Index:28, Emergence of Text Readability in Vision Language Models, https://arxiv.org/pdf/2506.19389, 2025-06-24
2025-11-11 01:10:30,509 - INFO - root - Page:1, Index:29, MedErr-CT: A Visual Question Answering Benchmark for Identifying and Correcting Errors in CT Reports, https://arxiv.org/pdf/2506.19217, 2025-06-23
2025-11-11 01:10:30,510 - INFO - root - Page:1, Index:30, RareSpot: Spotting Small and Rare Wildlife in Aerial Imagery with Multi-Scale Consistency and Context-Aware Augmentation, https://arxiv.org/pdf/2506.19087, 2025-06-23
2025-11-11 01:10:30,510 - INFO - root - Page:1, Index:31, Object-aware Sound Source Localization via Audio-Visual Scene Understanding, https://arxiv.org/pdf/2506.18557, 2025-06-23
2025-11-11 01:10:30,510 - INFO - root - Page:1, Index:32, Rethinking Decoder Design: Improving Biomarker Segmentation Using Depth-to-Space Restoration and Residual Linear Attention, https://arxiv.org/pdf/2506.18335, 2025-06-23
2025-11-11 01:10:30,511 - INFO - root - Page:1, Index:33, Relation3D: Enhancing Relation Modeling for Point Cloud Instance Segmentation, https://arxiv.org/pdf/2506.17891, 2025-06-21
2025-11-11 01:10:30,511 - INFO - root - Page:1, Index:34, HIRE: Lightweight High-Resolution Image Feature Enrichment for Multimodal LLMs, https://arxiv.org/pdf/2506.17608, 2025-06-21
2025-11-11 01:10:30,511 - INFO - root - Page:1, Index:35, Spatially-Aware Evaluation of Segmentation Uncertainty, https://arxiv.org/pdf/2506.16589, 2025-06-19
2025-11-11 01:10:30,511 - INFO - root - Page:1, Index:36, Tripartite Weight-Space Ensemble for Few-Shot Class-Incremental Learning, https://arxiv.org/pdf/2506.15720, 2025-06-03
2025-11-11 01:10:30,512 - INFO - root - Page:1, Index:37, PARC: A Quantitative Framework Uncovering the Symmetries within Vision Language Models, https://arxiv.org/pdf/2506.14808, 2025-06-03
2025-11-11 01:10:30,512 - INFO - root - Page:1, Index:38, Self-supervised Representation Learning with Local Aggregation for Image-based Profiling, https://arxiv.org/pdf/2506.14265, 2025-10-27
2025-11-11 01:10:30,512 - INFO - root - Page:1, Index:39, Towards Robust Learning to Optimize with Theoretical Guarantees, https://arxiv.org/pdf/2506.14263, 2025-06-17
2025-11-11 01:10:30,513 - INFO - root - Page:1, Index:40, Hidden Bias in the Machine: Stereotypes in Text-to-Image Models, https://arxiv.org/pdf/2506.13780, 2025-06-09
2025-11-11 01:10:30,513 - INFO - root - Page:1, Index:41, SmartHome-Bench: A Comprehensive Benchmark for Video Anomaly Detection in Smart Homes Using Multi-Modal Large Language Models, https://arxiv.org/pdf/2506.12992, 2025-06-15
2025-11-11 01:10:30,513 - INFO - root - Page:1, Index:42, Generative 4D Scene Gaussian Splatting with Object View-Synthesis Priors, https://arxiv.org/pdf/2506.12716, 2025-06-15
2025-11-11 01:10:30,514 - INFO - root - Page:1, Index:43, DejaVid: Encoder-Agnostic Learned Temporal Matching for Video Classification, https://arxiv.org/pdf/2506.12585, 2025-06-14
2025-11-11 01:10:30,514 - INFO - root - Page:1, Index:44, Pushing the Limits of Safety: A Technical Report on the ATLAS Challenge 2025, https://arxiv.org/pdf/2506.12430, 2025-07-10
2025-11-11 01:10:30,514 - INFO - root - Page:1, Index:45, FIMA-Q: Post-Training Quantization for Vision Transformers by Fisher Information Matrix Approximation, https://arxiv.org/pdf/2506.11543, 2025-06-13
2025-11-11 01:10:30,515 - INFO - root - Page:1, Index:46, Stop learning it all to mitigate visual hallucination, Focus on the hallucination target, https://arxiv.org/pdf/2506.11417, 2025-06-12
2025-11-11 01:10:30,515 - INFO - root - Page:1, Index:47, EfficientQuant: An Efficient Post-Training Quantization for CNN-Transformer Hybrid Models on Edge Devices, https://arxiv.org/pdf/2506.11093, 2025-06-05
2025-11-11 01:10:30,516 - INFO - root - Page:1, Index:48, HalLoc: Token-level Localization of Hallucinations for Vision Language Models, https://arxiv.org/pdf/2506.10286, 2025-06-11
2025-11-11 01:10:30,523 - INFO - root - Page:1, Index:49, DySS: Dynamic Queries and State-Space Learning for Efficient 3D Object Detection from Multi-Camera Videos, https://arxiv.org/pdf/2506.10242, 2025-06-11
2025-11-11 01:10:30,524 - INFO - root - Fetching page 3 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=100
2025-11-11 01:10:41,785 - INFO - root - get_all_titles_from_web 
2025-11-11 01:10:41,786 - INFO - root - Page:2, Index:0, Improving Personalized Search with Regularized Low-Rank Parameter Updates, https://arxiv.org/pdf/2506.10182, 2025-06-11
2025-11-11 01:10:41,786 - INFO - root - Page:2, Index:1, Hearing Hands: Generating Sounds from Physical Interactions in 3D Scenes, https://arxiv.org/pdf/2506.09989, 2025-06-11
2025-11-11 01:10:41,786 - INFO - root - Page:2, Index:2, UniPre3D: Unified Pre-training of 3D Point Cloud Models with Cross-Modal Gaussian Splatting, https://arxiv.org/pdf/2506.09952, 2025-06-11
2025-11-11 01:10:41,786 - INFO - root - Page:2, Index:3, Provoking Multi-modal Few-Shot LVLM via Exploration-Exploitation In-Context Learning, https://arxiv.org/pdf/2506.09473, 2025-06-11
2025-11-11 01:10:41,788 - INFO - root - Page:2, Index:4, Synthetic Human Action Video Data Generation with Pose Transfer, https://arxiv.org/pdf/2506.09411, 2025-06-11
2025-11-11 01:10:41,788 - INFO - root - Page:2, Index:5, ScaleLSD: Scalable Deep Line Segment Detection Streamlined, https://arxiv.org/pdf/2506.09369, 2025-06-10
2025-11-11 01:10:41,788 - INFO - root - Page:2, Index:6, CheckManual: A New Challenge and Benchmark for Manual-based Appliance Manipulation, https://arxiv.org/pdf/2506.09343, 2025-06-10
2025-11-11 01:10:41,788 - INFO - root - Page:2, Index:7, PatchGuard: Adversarially Robust Anomaly Detection and Localization through Vision Transformers and Pseudo Anomalies, https://arxiv.org/pdf/2506.09237, 2025-10-24
2025-11-11 01:10:41,789 - INFO - root - Page:2, Index:8, SILK: Smooth InterpoLation frameworK for motion in-betweening A Simplified Computational Approach, https://arxiv.org/pdf/2506.09075, 2025-06-09
2025-11-11 01:10:41,789 - INFO - root - Page:2, Index:9, BG-HOP: A Bimanual Generative Hand-Object Prior, https://arxiv.org/pdf/2506.09068, 2025-06-08
2025-11-11 01:10:41,789 - INFO - root - Page:2, Index:10, ORIDa: Object-centric Real-world Image Composition Dataset, https://arxiv.org/pdf/2506.08964, 2025-06-10
2025-11-11 01:10:41,790 - INFO - root - Page:2, Index:11, DiscoVLA: Discrepancy Reduction in Vision, Language, and Alignment for Parameter-Efficient Video-Text Retrieval, https://arxiv.org/pdf/2506.08887, 2025-06-10
2025-11-11 01:10:41,790 - INFO - root - Page:2, Index:12, A Comprehensive Study of Decoder-Only LLMs for Text-to-Image Generation, https://arxiv.org/pdf/2506.08210, 2025-06-09
2025-11-11 01:10:41,790 - INFO - root - Page:2, Index:13, Open World Scene Graph Generation using Vision Language Models, https://arxiv.org/pdf/2506.08189, 2025-06-09
2025-11-11 01:10:41,791 - INFO - root - Page:2, Index:14, Aligning Proteins and Language: A Foundation Model for Protein Retrieval, https://arxiv.org/pdf/2506.08023, 2025-05-27
2025-11-11 01:10:41,791 - INFO - root - Page:2, Index:15, UA-Pose: Uncertainty-Aware 6D Object Pose Estimation and Online Object Completion with Partial References, https://arxiv.org/pdf/2506.07996, 2025-06-09
2025-11-11 01:10:41,791 - INFO - root - Page:2, Index:16, Speedy Deformable 3D Gaussian Splatting: Fast Rendering and Compression of Dynamic Scenes, https://arxiv.org/pdf/2506.07917, 2025-06-09
2025-11-11 01:10:41,791 - INFO - root - Page:2, Index:17, GaussianVAE: Adaptive Learning Dynamics of 3D Gaussians for High-Fidelity Super-Resolution, https://arxiv.org/pdf/2506.07897, 2025-06-09
2025-11-11 01:10:41,792 - INFO - root - Page:2, Index:18, Spatio-Temporal State Space Model For Efficient Event-Based Optical Flow, https://arxiv.org/pdf/2506.07878, 2025-06-09
2025-11-11 01:10:41,792 - INFO - root - Page:2, Index:19, FreeGave: 3D Physics Learning from Dynamic Videos by Gaussian Velocity, https://arxiv.org/pdf/2506.07865, 2025-06-09
2025-11-11 01:10:41,793 - INFO - root - Page:2, Index:20, LogoSP: Local-global Grouping of Superpoints for Unsupervised Semantic Segmentation of 3D Point Clouds, https://arxiv.org/pdf/2506.07857, 2025-06-09
2025-11-11 01:10:41,793 - INFO - root - Page:2, Index:21, Difference Inversion: Interpolate and Isolate the Difference with Token Consistency for Image Analogy Generation, https://arxiv.org/pdf/2506.07750, 2025-06-09
2025-11-11 01:10:41,793 - INFO - root - Page:2, Index:22, Synthetic Visual Genome, https://arxiv.org/pdf/2506.07643, 2025-06-09
2025-11-11 01:10:41,794 - INFO - root - Page:2, Index:23, Fractional Collisions: A Framework for Risk Estimation of Counterfactual Conflicts using Autonomous Driving Behavior Simulations, https://arxiv.org/pdf/2506.07540, 2025-06-09
2025-11-11 01:10:41,794 - INFO - root - Page:2, Index:24, Multi-Step Guided Diffusion for Image Restoration on Edge Devices: Toward Lightweight Perception in Embodied AI, https://arxiv.org/pdf/2506.07286, 2025-06-08
2025-11-11 01:10:41,795 - INFO - root - Page:2, Index:25, LLM-Enhanced Rapid-Reflex Async-Reflect Embodied Agent for Real-Time Decision-Making in Dynamically Changing Environments, https://arxiv.org/pdf/2506.07223, 2025-06-08
2025-11-11 01:10:41,795 - INFO - root - Page:2, Index:26, UCOD-DPL: Unsupervised Camouflaged Object Detection via Dynamic Pseudo-label Learning, https://arxiv.org/pdf/2506.07087, 2025-06-08
2025-11-11 01:10:41,796 - INFO - root - Page:2, Index:27, BePo: Leveraging Birds Eye View and Sparse Points for Efficient and Accurate 3D Occupancy Prediction, https://arxiv.org/pdf/2506.07002, 2025-06-08
2025-11-11 01:10:41,796 - INFO - root - Page:2, Index:28, Reading in the Dark with Foveated Event Vision, https://arxiv.org/pdf/2506.06918, 2025-06-07
2025-11-11 01:10:41,799 - INFO - root - Page:2, Index:29, NSD-Imagery: A benchmark dataset for extending fMRI vision decoding methods to mental imagery, https://arxiv.org/pdf/2506.06898, 2025-06-07
2025-11-11 01:10:41,801 - INFO - root - Page:2, Index:30, Continuous-Time SO(3) Forecasting with Savitzky--Golay Neural Controlled Differential Equations, https://arxiv.org/pdf/2506.06780, 2025-06-07
2025-11-11 01:10:41,801 - INFO - root - Page:2, Index:31, Generalized Trajectory Scoring for End-to-end Multimodal Planning, https://arxiv.org/pdf/2506.06664, 2025-06-07
2025-11-11 01:10:41,801 - INFO - root - Page:2, Index:32, EV-LayerSegNet: Self-supervised Motion Segmentation using Event Cameras, https://arxiv.org/pdf/2506.06596, 2025-06-06
2025-11-11 01:10:41,801 - INFO - root - Page:2, Index:33, Vid2Sim: Generalizable, Video-based Reconstruction of Appearance, Geometry and Physics for Mesh-free Simulation, https://arxiv.org/pdf/2506.06440, 2025-06-06
2025-11-11 01:10:41,801 - INFO - root - Page:2, Index:34, FADE: Frequency-Aware Diffusion Model Factorization for Video Editing, https://arxiv.org/pdf/2506.05934, 2025-06-06
2025-11-11 01:10:41,803 - INFO - root - Page:2, Index:35, Unleashing the Potential of Consistency Learning for Detecting and Grounding Multi-Modal Media Manipulation, https://arxiv.org/pdf/2506.05890, 2025-06-06
2025-11-11 01:10:41,803 - INFO - root - Page:2, Index:36, DeformCL: Learning Deformable Centerline Representation for Vessel Extraction in 3D Medical Image, https://arxiv.org/pdf/2506.05820, 2025-06-06
2025-11-11 01:10:41,803 - INFO - root - Page:2, Index:37, NTIRE 2025 Challenge on HR Depth from Images of Specular and Transparent Surfaces, https://arxiv.org/pdf/2506.05815, 2025-06-06
2025-11-11 01:10:41,804 - INFO - root - Page:2, Index:38, GazeNLQ @ Ego4D Natural Language Queries Challenge 2025, https://arxiv.org/pdf/2506.05782, 2025-06-06
2025-11-11 01:10:41,804 - INFO - root - Page:2, Index:39, Robust sensor fusion against on-vehicle sensor staleness, https://arxiv.org/pdf/2506.05780, 2025-06-06
2025-11-11 01:10:41,804 - INFO - root - Page:2, Index:40, Where Is The Ball: 3D Ball Trajectory Estimation From 2D Monocular Tracking, https://arxiv.org/pdf/2506.05763, 2025-06-06
2025-11-11 01:10:41,804 - INFO - root - Page:2, Index:41, VoxelSplat: Dynamic Gaussian Splatting as an Effective Loss for Occupancy and Flow Prediction, https://arxiv.org/pdf/2506.05563, 2025-06-05
2025-11-11 01:10:41,806 - INFO - root - Page:2, Index:42, Gen4D: Synthesizing Humans and Scenes in the Wild, https://arxiv.org/pdf/2506.05397, 2025-06-03
2025-11-11 01:10:41,806 - INFO - root - Page:2, Index:43, Attacking Attention of Foundation Models Disrupts Downstream Tasks, https://arxiv.org/pdf/2506.05394, 2025-09-12
2025-11-11 01:10:41,829 - INFO - root - Page:2, Index:44, FreeTimeGS: Free Gaussian Primitives at Anytime and Anywhere for Dynamic Scene Reconstruction, https://arxiv.org/pdf/2506.05348, 2025-06-06
2025-11-11 01:10:41,830 - INFO - root - Page:2, Index:45, LotusFilter: Fast Diverse Nearest Neighbor Search via a Learned Cutoff Table, https://arxiv.org/pdf/2506.04790, 2025-06-05
2025-11-11 01:10:41,831 - INFO - root - Page:2, Index:46, Towards Holistic Visual Quality Assessment of AI-Generated Videos: A LLM-Based Multi-Dimensional Evaluation Model, https://arxiv.org/pdf/2506.04715, 2025-06-11
2025-11-11 01:10:41,832 - INFO - root - Page:2, Index:47, Gradient Inversion Attacks on Parameter-Efficient Fine-Tuning, https://arxiv.org/pdf/2506.04453, 2025-06-04
2025-11-11 01:10:41,832 - INFO - root - Page:2, Index:48, HMAR: Efficient Hierarchical Masked Auto-Regressive Image Generation, https://arxiv.org/pdf/2506.04421, 2025-06-04
2025-11-11 01:10:41,834 - INFO - root - Page:2, Index:49, Visualizing and Controlling Cortical Responses Using Voxel-Weighted Activation Maximization, https://arxiv.org/pdf/2506.04379, 2025-06-04
2025-11-11 01:10:41,834 - INFO - root - Fetching page 4 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=150
2025-11-11 01:10:48,226 - INFO - root - get_all_titles_from_web 
2025-11-11 01:10:48,226 - INFO - root - Page:3, Index:0, FlexGS: Train Once, Deploy Everywhere with Many-in-One Flexible 3D Gaussian Splatting, https://arxiv.org/pdf/2506.04174, 2025-06-04
2025-11-11 01:10:48,226 - INFO - root - Page:3, Index:1, Multi-view Surface Reconstruction Using Normal and Reflectance Cues, https://arxiv.org/pdf/2506.04115, 2025-06-04
2025-11-11 01:10:48,226 - INFO - root - Page:3, Index:2, Vocabulary-free few-shot learning for Vision-Language Models, https://arxiv.org/pdf/2506.04005, 2025-06-04
2025-11-11 01:10:48,228 - INFO - root - Page:3, Index:3, Learning from Noise: Enhancing DNNs for Event-Based Vision through Controlled Noise Injection, https://arxiv.org/pdf/2506.03918, 2025-06-04
2025-11-11 01:10:48,228 - INFO - root - Page:3, Index:4, Video, How Do Your Tokens Merge?, https://arxiv.org/pdf/2506.03885, 2025-06-04
2025-11-11 01:10:48,228 - INFO - root - Page:3, Index:5, OSGNet @ Ego4D Episodic Memory Challenge 2025, https://arxiv.org/pdf/2506.03710, 2025-06-04
2025-11-11 01:10:48,228 - INFO - root - Page:3, Index:6, AetherVision-Bench: An Open-Vocabulary RGB-Infrared Benchmark for Multi-Angle Segmentation across Aerial and Ground Perspectives, https://arxiv.org/pdf/2506.03709, 2025-06-04
2025-11-11 01:10:48,229 - INFO - root - Page:3, Index:7, OV-COAST: Cost Aggregation with Optimal Transport for Open-Vocabulary Semantic Segmentation, https://arxiv.org/pdf/2506.03706, 2025-06-04
2025-11-11 01:10:48,229 - INFO - root - Page:3, Index:8, Generating 6DoF Object Manipulation Trajectories from Action Description in Egocentric Vision, https://arxiv.org/pdf/2506.03605, 2025-06-04
2025-11-11 01:10:48,229 - INFO - root - Page:3, Index:9, SemNav: A Model-Based Planner for Zero-Shot Object Goal Navigation Using Vision-Foundation Models, https://arxiv.org/pdf/2506.03516, 2025-06-03
2025-11-11 01:10:48,230 - INFO - root - Page:3, Index:10, Heterogeneous Skeleton-Based Action Representation Learning, https://arxiv.org/pdf/2506.03481, 2025-06-03
2025-11-11 01:10:48,230 - INFO - root - Page:3, Index:11, Hybrid Ensemble of Segmentation-Assisted Classification and GBDT for Skin Cancer Detection with Engineered Metadata and Synthetic Lesions from ISIC 2024 Non-Dermoscopic 3D-TBP Images, https://arxiv.org/pdf/2506.03420, 2025-06-03
2025-11-11 01:10:48,230 - INFO - root - Page:3, Index:12, Self-Supervised Spatial Correspondence Across Modalities, https://arxiv.org/pdf/2506.03148, 2025-06-03
2025-11-11 01:10:48,230 - INFO - root - Page:3, Index:13, Dense Match Summarization for Faster Two-view Estimation, https://arxiv.org/pdf/2506.02893, 2025-06-03
2025-11-11 01:10:48,231 - INFO - root - Page:3, Index:14, NTIRE 2025 XGC Quality Assessment Challenge: Methods and Results, https://arxiv.org/pdf/2506.02875, 2025-06-03
2025-11-11 01:10:48,231 - INFO - root - Page:3, Index:15, FreeScene: Mixed Graph Diffusion for 3D Scene Synthesis from Free Prompts, https://arxiv.org/pdf/2506.02781, 2025-06-03
2025-11-11 01:10:48,231 - INFO - root - Page:3, Index:16, Technical Report for Ego4D Long-Term Action Anticipation Challenge 2025, https://arxiv.org/pdf/2506.02550, 2025-06-11
2025-11-11 01:10:48,231 - INFO - root - Page:3, Index:17, Probabilistic Online Event Downsampling, https://arxiv.org/pdf/2506.02547, 2025-09-23
2025-11-11 01:10:48,232 - INFO - root - Page:3, Index:18, Towards In-the-wild 3D Plane Reconstruction from a Single Image, https://arxiv.org/pdf/2506.02493, 2025-06-03
2025-11-11 01:10:48,232 - INFO - root - Page:3, Index:19, Efficient Test-time Adaptive Object Detection via Sensitivity-Guided Pruning, https://arxiv.org/pdf/2506.02462, 2025-06-03
2025-11-11 01:10:48,232 - INFO - root - Page:3, Index:20, EgoVIS@CVPR: PAIR-Net: Enhancing Egocentric Speaker Detection via Pretrained Audio-Visual Fusion and Alignment Loss, https://arxiv.org/pdf/2506.02247, 2025-09-26
2025-11-11 01:10:48,233 - INFO - root - Page:3, Index:21, Diff2Flow: Training Flow Matching Models via Diffusion Model Alignment, https://arxiv.org/pdf/2506.02221, 2025-06-02
2025-11-11 01:10:48,233 - INFO - root - Page:3, Index:22, NTIRE 2025 Challenge on RAW Image Restoration and Super-Resolution, https://arxiv.org/pdf/2506.02197, 2025-06-04
2025-11-11 01:10:48,233 - INFO - root - Page:3, Index:23, RAW Image Reconstruction from RGB on Smartphones. NTIRE 2025 Challenge Report, https://arxiv.org/pdf/2506.01947, 2025-06-02
2025-11-11 01:10:48,234 - INFO - root - Page:3, Index:24, Silence is Golden: Leveraging Adversarial Examples to Nullify Audio Control in LDM-based Talking-Head Generation, https://arxiv.org/pdf/2506.01591, 2025-06-02
2025-11-11 01:10:48,234 - INFO - root - Page:3, Index:25, SAM2-LOVE: Segment Anything Model 2 in Language-aided Audio-Visual Scenes, https://arxiv.org/pdf/2506.01558, 2025-06-02
2025-11-11 01:10:48,235 - INFO - root - Page:3, Index:26, Neural shape reconstruction from multiple views with static pattern projection, https://arxiv.org/pdf/2506.01389, 2025-06-02
2025-11-11 01:10:48,235 - INFO - root - Page:3, Index:27, SAM-I2V: Upgrading SAM to Support Promptable Video Segmentation with Less than 0.2% Training Cost, https://arxiv.org/pdf/2506.01304, 2025-06-02
2025-11-11 01:10:48,235 - INFO - root - Page:3, Index:28, Perceptual Inductive Bias Is What You Need Before Contrastive Learning, https://arxiv.org/pdf/2506.01201, 2025-06-01
2025-11-11 01:10:48,236 - INFO - root - Page:3, Index:29, Test Automation for Interactive Scenarios via Promptable Traffic Simulation, https://arxiv.org/pdf/2506.01199, 2025-06-04
2025-11-11 01:10:48,236 - INFO - root - Page:3, Index:30, GraphPad: Inference-Time 3D Scene Graph Updates for Embodied Question Answering, https://arxiv.org/pdf/2506.01174, 2025-06-01
2025-11-11 01:10:48,236 - INFO - root - Page:3, Index:31, Aligned Contrastive Loss for Long-Tailed Recognition, https://arxiv.org/pdf/2506.01071, 2025-06-01
2025-11-11 01:10:48,237 - INFO - root - Page:3, Index:32, Self-supervised ControlNet with Spatio-Temporal Mamba for Real-world Video Super-resolution, https://arxiv.org/pdf/2506.01037, 2025-06-01
2025-11-11 01:10:48,237 - INFO - root - Page:3, Index:33, ArtiScene: Language-Driven Artistic 3D Scene Generation Through Image Intermediary, https://arxiv.org/pdf/2506.00742, 2025-05-31
2025-11-11 01:10:48,237 - INFO - root - Page:3, Index:34, 3D Gaussian Splat Vulnerabilities, https://arxiv.org/pdf/2506.00280, 2025-05-30
2025-11-11 01:10:48,238 - INFO - root - Page:3, Index:35, EgoVIS@CVPR: What Changed and What Could Have Changed? State-Change Counterfactuals for Procedure-Aware Video Representation Learning, https://arxiv.org/pdf/2506.00101, 2025-09-26
2025-11-11 01:10:48,240 - INFO - root - Page:3, Index:36, CL-LoRA: Continual Low-Rank Adaptation for Rehearsal-Free Class-Incremental Learning, https://arxiv.org/pdf/2505.24816, 2025-05-30
2025-11-11 01:10:48,241 - INFO - root - Page:3, Index:37, PatchDEMUX: A Certifiably Robust Framework for Multi-label Classifiers Against Adversarial Patches, https://arxiv.org/pdf/2505.24703, 2025-05-30
2025-11-11 01:10:48,242 - INFO - root - Page:3, Index:38, Conformal Prediction for Zero-Shot Models, https://arxiv.org/pdf/2505.24693, 2025-05-30
2025-11-11 01:10:48,244 - INFO - root - Page:3, Index:39, Learning reusable concepts across different egocentric video understanding tasks, https://arxiv.org/pdf/2505.24690, 2025-05-30
2025-11-11 01:10:48,244 - INFO - root - Page:3, Index:40, Period-LLM: Extending the Periodic Capability of Multimodal Large Language Model, https://arxiv.org/pdf/2505.24476, 2025-05-30
2025-11-11 01:10:48,244 - INFO - root - Page:3, Index:41, PCIE_Interaction Solution for Ego4D Social Interaction Challenge, https://arxiv.org/pdf/2505.24404, 2025-05-30
2025-11-11 01:10:48,244 - INFO - root - Page:3, Index:42, Leadership Assessment in Pediatric Intensive Care Unit Team Training, https://arxiv.org/pdf/2505.24389, 2025-08-28
2025-11-11 01:10:48,245 - INFO - root - Page:3, Index:43, Interpreting Large Text-to-Image Diffusion Models with Dictionary Learning, https://arxiv.org/pdf/2505.24360, 2025-07-10
2025-11-11 01:10:48,245 - INFO - root - Page:3, Index:44, InteractAnything: Zero-shot Human Object Interaction Synthesis via LLM Feedback and Object Affordance Parsing, https://arxiv.org/pdf/2505.24315, 2025-05-30
2025-11-11 01:10:48,245 - INFO - root - Page:3, Index:45, MaskAdapt: Unsupervised Geometry-Aware Domain Adaptation Using Multimodal Contextual Learning and RGB-Depth Masking, https://arxiv.org/pdf/2505.24026, 2025-05-29
2025-11-11 01:10:48,246 - INFO - root - Page:3, Index:46, Argus: Vision-Centric Reasoning with Grounded Chain-of-Thought, https://arxiv.org/pdf/2505.23766, 2025-05-29
2025-11-11 01:10:48,246 - INFO - root - Page:3, Index:47, Sketch Down the FLOPs: Towards Efficient Networks for Human Sketch, https://arxiv.org/pdf/2505.23763, 2025-05-29
2025-11-11 01:10:48,246 - INFO - root - Page:3, Index:48, Boosting Domain Incremental Learning: Selecting the Optimal Parameters is All You Need, https://arxiv.org/pdf/2505.23744, 2025-05-29
2025-11-11 01:10:48,246 - INFO - root - Page:3, Index:49, DA-VPT: Semantic-Guided Visual Prompt Tuning for Vision Transformers, https://arxiv.org/pdf/2505.23694, 2025-06-01
2025-11-11 01:10:48,246 - INFO - root - Fetching page 5 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=200
2025-11-11 01:10:54,742 - INFO - root - get_all_titles_from_web 
2025-11-11 01:10:54,742 - INFO - root - Page:4, Index:0, Bridging Classical and Modern Computer Vision: PerceptiveNet for Tree Crown Semantic Segmentation, https://arxiv.org/pdf/2505.23597, 2025-05-29
2025-11-11 01:10:54,744 - INFO - root - Page:4, Index:1, Synthetic Generation and Latent Projection Denoising of Rim Lesions in Multiple Sclerosis, https://arxiv.org/pdf/2505.23353, 2025-05-29
2025-11-11 01:10:54,744 - INFO - root - Page:4, Index:2, Wav2Sem: Plug-and-Play Audio Semantic Decoupling for 3D Speech-Driven Facial Animation, https://arxiv.org/pdf/2505.23290, 2025-05-29
2025-11-11 01:10:54,744 - INFO - root - Page:4, Index:3, Proximal Algorithm Unrolling: Flexible and Efficient Reconstruction Networks for Single-Pixel Imaging, https://arxiv.org/pdf/2505.23180, 2025-05-29
2025-11-11 01:10:54,745 - INFO - root - Page:4, Index:4, HMAD: Advancing E2E Driving with Anchored Offset Proposals and Simulation-Supervised Multi-target Scoring, https://arxiv.org/pdf/2505.23129, 2025-05-29
2025-11-11 01:10:54,745 - INFO - root - Page:4, Index:5, URWKV: Unified RWKV Model with Multi-state Perspective for Low-light Image Restoration, https://arxiv.org/pdf/2505.23068, 2025-05-29
2025-11-11 01:10:54,745 - INFO - root - Page:4, Index:6, 4DTAM: Non-Rigid Tracking and Mapping via Dynamic Surface Gaussians, https://arxiv.org/pdf/2505.22859, 2025-05-28
2025-11-11 01:10:54,745 - INFO - root - Page:4, Index:7, A Probabilistic Jump-Diffusion Framework for Open-World Egocentric Activity Recognition, https://arxiv.org/pdf/2505.22858, 2025-05-28
2025-11-11 01:10:54,746 - INFO - root - Page:4, Index:8, PS4PRO: Pixel-to-pixel Supervision for Photorealistic Rendering and Optimization, https://arxiv.org/pdf/2505.22616, 2025-05-28
2025-11-11 01:10:54,746 - INFO - root - Page:4, Index:9, Universal Domain Adaptation for Semantic Segmentation, https://arxiv.org/pdf/2505.22458, 2025-06-05
2025-11-11 01:10:54,746 - INFO - root - Page:4, Index:10, Zero-Shot 3D Visual Grounding from Vision-Language Models, https://arxiv.org/pdf/2505.22429, 2025-05-28
2025-11-11 01:10:54,746 - INFO - root - Page:4, Index:11, RC-AutoCalib: An End-to-End Radar-Camera Automatic Calibration Network, https://arxiv.org/pdf/2505.22427, 2025-05-28
2025-11-11 01:10:54,747 - INFO - root - Page:4, Index:12, Bringing CLIP to the Clinic: Dynamic Soft Labels and Negation-Aware Learning for Medical Analysis, https://arxiv.org/pdf/2505.22079, 2025-05-28
2025-11-11 01:10:54,747 - INFO - root - Page:4, Index:13, Point-to-Region Loss for Semi-Supervised Point-Based Crowd Counting, https://arxiv.org/pdf/2505.21943, 2025-05-27
2025-11-11 01:10:54,747 - INFO - root - Page:4, Index:14, FRAMES-VQA: Benchmarking Fine-Tuning Robustness across Multi-Modal Shifts in Visual Question Answering, https://arxiv.org/pdf/2505.21755, 2025-06-20
2025-11-11 01:10:54,747 - INFO - root - Page:4, Index:15, Knowledge Distillation Approach for SOS Fusion Staging: Towards Fully Automated Skeletal Maturity Assessment, https://arxiv.org/pdf/2505.21561, 2025-05-26
2025-11-11 01:10:54,747 - INFO - root - Page:4, Index:16, Enhancing Vision Transformer Explainability Using Artificial Astrocytes, https://arxiv.org/pdf/2505.21513, 2025-05-20
2025-11-11 01:10:54,748 - INFO - root - Page:4, Index:17, Empowering Vector Graphics with Consistently Arbitrary Viewing and View-dependent Visibility, https://arxiv.org/pdf/2505.21377, 2025-05-27
2025-11-11 01:10:54,748 - INFO - root - Page:4, Index:18, Structure from Collision, https://arxiv.org/pdf/2505.21335, 2025-05-27
2025-11-11 01:10:54,750 - INFO - root - Page:4, Index:19, Boosting Adversarial Transferability via High-Frequency Augmentation and Hierarchical-Gradient Fusion, https://arxiv.org/pdf/2505.21181, 2025-05-27
2025-11-11 01:10:54,750 - INFO - root - Page:4, Index:20, RefAV: Towards Planning-Centric Scenario Mining, https://arxiv.org/pdf/2505.20981, 2025-06-18
2025-11-11 01:10:54,751 - INFO - root - Page:4, Index:21, PMA: Towards Parameter-Efficient Point Cloud Understanding via Point Mamba Adapter, https://arxiv.org/pdf/2505.20941, 2025-05-27
2025-11-11 01:10:54,751 - INFO - root - Page:4, Index:22, HuMoCon: Concept Discovery for Human Motion Understanding, https://arxiv.org/pdf/2505.20920, 2025-05-27
2025-11-11 01:10:54,752 - INFO - root - Page:4, Index:23, Exploring Timeline Control for Facial Motion Generation, https://arxiv.org/pdf/2505.20861, 2025-05-27
2025-11-11 01:10:54,752 - INFO - root - Page:4, Index:24, ConText-CIR: Learning from Concepts in Text for Composed Image Retrieval, https://arxiv.org/pdf/2505.20764, 2025-05-27
2025-11-11 01:10:54,754 - INFO - root - Page:4, Index:25, HCQA-1.5 @ Ego4D EgoSchema Challenge 2025, https://arxiv.org/pdf/2505.20644, 2025-05-26
2025-11-11 01:10:54,757 - INFO - root - Page:4, Index:26, Roboflow100-VL: A Multi-Domain Object Detection Benchmark for Vision-Language Models, https://arxiv.org/pdf/2505.20612, 2025-10-22
2025-11-11 01:10:54,757 - INFO - root - Page:4, Index:27, MotionPro: A Precise Motion Controller for Image-to-Video Generation, https://arxiv.org/pdf/2505.20287, 2025-05-26
2025-11-11 01:10:54,757 - INFO - root - Page:4, Index:28, Category-Agnostic Neural Object Rigging, https://arxiv.org/pdf/2505.20283, 2025-05-26
2025-11-11 01:10:54,759 - INFO - root - Page:4, Index:29, Towards Video to Piano Music Generation with Chain-of-Perform Support Benchmarks, https://arxiv.org/pdf/2505.20038, 2025-05-26
2025-11-11 01:10:54,760 - INFO - root - Page:4, Index:30, Can Visual Encoder Learn to See Arrows?, https://arxiv.org/pdf/2505.19944, 2025-05-26
2025-11-11 01:10:54,761 - INFO - root - Page:4, Index:31, GoLF-NRT: Integrating Global Context and Local Geometry for Few-Shot View Synthesis, https://arxiv.org/pdf/2505.19813, 2025-05-26
2025-11-11 01:10:54,761 - INFO - root - Page:4, Index:32, Depth-Guided Bundle Sampling for Efficient Generalizable Neural Radiance Field Reconstruction, https://arxiv.org/pdf/2505.19793, 2025-05-26
2025-11-11 01:10:54,762 - INFO - root - Page:4, Index:33, SuperAD: A Training-free Anomaly Classification and Segmentation Method for CVPR 2025 VAND 3.0 Workshop Challenge Track 1: Adapt & Detect, https://arxiv.org/pdf/2505.19750, 2025-05-27
2025-11-11 01:10:54,764 - INFO - root - Page:4, Index:34, Knowledge-Aligned Counterfactual-Enhancement Diffusion Perception for Unsupervised Cross-Domain Visual Emotion Recognition, https://arxiv.org/pdf/2505.19694, 2025-05-26
2025-11-11 01:10:54,764 - INFO - root - Page:4, Index:35, Rotation-Equivariant Self-Supervised Method in Image Denoising, https://arxiv.org/pdf/2505.19618, 2025-05-26
2025-11-11 01:10:54,765 - INFO - root - Page:4, Index:36, NTIRE 2025 Challenge on Video Quality Enhancement for Video Conferencing: Datasets, Methods and Results, https://arxiv.org/pdf/2505.18988, 2025-05-25
2025-11-11 01:10:54,765 - INFO - root - Page:4, Index:37, Geometry-guided Online 3D Video Synthesis with Multi-View Temporal Consistency, https://arxiv.org/pdf/2505.18932, 2025-05-24
2025-11-11 01:10:54,766 - INFO - root - Page:4, Index:38, Digital Overconsumption and Waste: A Closer Look at the Impacts of Generative AI, https://arxiv.org/pdf/2505.18894, 2025-05-24
2025-11-11 01:10:54,766 - INFO - root - Page:4, Index:39, VISTA: Vision-Language Inference for Training-Free Stock Time-Series Analysis, https://arxiv.org/pdf/2505.18570, 2025-06-11
2025-11-11 01:10:54,766 - INFO - root - Page:4, Index:40, Syn3DTxt: Embedding 3D Cues for Scene Text Generation, https://arxiv.org/pdf/2505.18479, 2025-05-23
2025-11-11 01:10:54,766 - INFO - root - Page:4, Index:41, CTRL-GS: Cascaded Temporal Residue Learning for 4D Gaussian Splatting, https://arxiv.org/pdf/2505.18306, 2025-05-31
2025-11-11 01:10:54,767 - INFO - root - Page:4, Index:42, DualTalk: Dual-Speaker Interaction for 3D Talking Head Conversations, https://arxiv.org/pdf/2505.18096, 2025-05-26
2025-11-11 01:10:54,767 - INFO - root - Page:4, Index:43, SeaLion: Semantic Part-Aware Latent Point Diffusion Models for 3D Generation, https://arxiv.org/pdf/2505.17721, 2025-07-07
2025-11-11 01:10:54,767 - INFO - root - Page:4, Index:44, PoseBH: Prototypical Multi-Dataset Training Beyond Human Pose Estimation, https://arxiv.org/pdf/2505.17475, 2025-05-23
2025-11-11 01:10:54,767 - INFO - root - Page:4, Index:45, Pursuing Temporal-Consistent Video Virtual Try-On via Dynamic Pose Interaction, https://arxiv.org/pdf/2505.16980, 2025-05-22
2025-11-11 01:10:54,768 - INFO - root - Page:4, Index:46, UniPhy: Learning a Unified Constitutive Model for Inverse Physics Simulation, https://arxiv.org/pdf/2505.16971, 2025-05-22
2025-11-11 01:10:54,768 - INFO - root - Page:4, Index:47, Tracking the Flight: Exploring a Computational Framework for Analyzing Escape Responses in Plains Zebra (Equus quagga), https://arxiv.org/pdf/2505.16882, 2025-05-23
2025-11-11 01:10:54,769 - INFO - root - Page:4, Index:48, Semi-Supervised State-Space Model with Dynamic Stacking Filter for Real-World Video Deraining, https://arxiv.org/pdf/2505.16811, 2025-05-22
2025-11-11 01:10:54,769 - INFO - root - Page:4, Index:49, SOLVE: Synergy of Language-Vision and End-to-End Networks for Autonomous Driving, https://arxiv.org/pdf/2505.16805, 2025-05-22
2025-11-11 01:10:54,771 - INFO - root - Fetching page 6 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=250
2025-11-11 01:11:02,085 - INFO - root - get_all_titles_from_web 
2025-11-11 01:11:02,086 - INFO - root - Page:5, Index:0, Four Eyes Are Better Than Two: Harnessing the Collaborative Potential of Large Models via Differentiated Thinking and Complementary Ensembles, https://arxiv.org/pdf/2505.16784, 2025-06-07
2025-11-11 01:11:02,086 - INFO - root - Page:5, Index:1, Single Domain Generalization for Few-Shot Counting via Universal Representation Matching, https://arxiv.org/pdf/2505.16778, 2025-05-22
2025-11-11 01:11:02,086 - INFO - root - Page:5, Index:2, Seeing Far and Clearly: Mitigating Hallucinations in MLLMs with Attention Causal Decoding, https://arxiv.org/pdf/2505.16652, 2025-06-07
2025-11-11 01:11:02,086 - INFO - root - Page:5, Index:3, Sketchy Bounding-box Supervision for 3D Instance Segmentation, https://arxiv.org/pdf/2505.16399, 2025-05-22
2025-11-11 01:11:02,087 - INFO - root - Page:5, Index:4, DeCafNet: Delegate and Conquer for Efficient Temporal Grounding in Long Videos, https://arxiv.org/pdf/2505.16376, 2025-05-22
2025-11-11 01:11:02,087 - INFO - root - Page:5, Index:5, NTIRE 2025 challenge on Text to Image Generation Model Quality Assessment, https://arxiv.org/pdf/2505.16314, 2025-05-22
2025-11-11 01:11:02,088 - INFO - root - Page:5, Index:6, Analyzing Hierarchical Structure in Vision Models with Sparse Autoencoders, https://arxiv.org/pdf/2505.15970, 2025-05-21
2025-11-11 01:11:02,088 - INFO - root - Page:5, Index:7, Efficient Data Driven Mixture-of-Expert Extraction from Trained Networks, https://arxiv.org/pdf/2505.15414, 2025-05-21
2025-11-11 01:11:02,088 - INFO - root - Page:5, Index:8, Mouse Lockbox Dataset: Behavior Recognition for Mice Solving Lockboxes, https://arxiv.org/pdf/2505.15408, 2025-06-17
2025-11-11 01:11:02,088 - INFO - root - Page:5, Index:9, Zero-Shot Gaze-based Volumetric Medical Image Segmentation, https://arxiv.org/pdf/2505.15256, 2025-06-10
2025-11-11 01:11:02,090 - INFO - root - Page:5, Index:10, Dual Precision Quantization for Efficient and Accurate Deep Neural Networks Inference, https://arxiv.org/pdf/2505.14638, 2025-05-20
2025-11-11 01:11:02,090 - INFO - root - Page:5, Index:11, Neural Video Compression with Context Modulation, https://arxiv.org/pdf/2505.14541, 2025-05-20
2025-11-11 01:11:02,090 - INFO - root - Page:5, Index:12, Selective Structured State Space for Multispectral-fused Small Target Detection, https://arxiv.org/pdf/2505.14043, 2025-05-23
2025-11-11 01:11:02,090 - INFO - root - Page:5, Index:13, OmniStyle: Filtering High Quality Style Transfer Data at Scale, https://arxiv.org/pdf/2505.14028, 2025-05-20
2025-11-11 01:11:02,091 - INFO - root - Page:5, Index:14, Domain Adaptation of VLM for Soccer Video Understanding, https://arxiv.org/pdf/2505.13860, 2025-07-07
2025-11-11 01:11:02,091 - INFO - root - Page:5, Index:15, Ground-V: Teaching VLMs to Ground Complex Instructions in Pixels, https://arxiv.org/pdf/2505.13788, 2025-05-19
2025-11-11 01:11:02,091 - INFO - root - Page:5, Index:16, FinePhys: Fine-grained Human Action Generation by Explicitly Incorporating Physical Laws for Effective Skeletal Guidance, https://arxiv.org/pdf/2505.13437, 2025-05-19
2025-11-11 01:11:02,092 - INFO - root - Page:5, Index:17, The Way Up: A Dataset for Hold Usage Detection in Sport Climbing, https://arxiv.org/pdf/2505.12854, 2025-05-19
2025-11-11 01:11:02,092 - INFO - root - Page:5, Index:18, PEER pressure: Model-to-Model Regularization for Single Source Domain Generalization, https://arxiv.org/pdf/2505.12745, 2025-05-19
2025-11-11 01:11:02,092 - INFO - root - Page:5, Index:19, Mamba-Adaptor: State Space Model Adaptor for Visual Recognition, https://arxiv.org/pdf/2505.12685, 2025-05-19
2025-11-11 01:11:02,092 - INFO - root - Page:5, Index:20, Scalable Video-to-Dataset Generation for Cross-Platform Mobile Agents, https://arxiv.org/pdf/2505.12632, 2025-05-18
2025-11-11 01:11:02,092 - INFO - root - Page:5, Index:21, Degradation-Aware Feature Perturbation for All-in-One Image Restoration, https://arxiv.org/pdf/2505.12630, 2025-05-18
2025-11-11 01:11:02,094 - INFO - root - Page:5, Index:22, Guiding Diffusion with Deep Geometric Moments: Balancing Fidelity and Variation, https://arxiv.org/pdf/2505.12486, 2025-05-18
2025-11-11 01:11:02,094 - INFO - root - Page:5, Index:23, Learning to Highlight Audio by Watching Movies, https://arxiv.org/pdf/2505.12154, 2025-05-17
2025-11-11 01:11:02,094 - INFO - root - Page:5, Index:24, Understanding the Capabilities of Molecular Graph Neural Networks in Materials Science Through Multimodal Learning and Physical Context Encoding, https://arxiv.org/pdf/2505.12137, 2025-05-17
2025-11-11 01:11:02,095 - INFO - root - Page:5, Index:25, iSegMan: Interactive Segment-and-Manipulate 3D Gaussians, https://arxiv.org/pdf/2505.11934, 2025-05-17
2025-11-11 01:11:02,095 - INFO - root - Page:5, Index:26, Self-Learning Hyperspectral and Multispectral Image Fusion via Adaptive Residual Guided Subspace Diffusion Model, https://arxiv.org/pdf/2505.11800, 2025-05-16
2025-11-11 01:11:02,096 - INFO - root - Page:5, Index:27, X-Edit: Detecting and Localizing Edits in Images Altered by Text-Guided Diffusion Models, https://arxiv.org/pdf/2505.11753, 2025-05-16
2025-11-11 01:11:02,096 - INFO - root - Page:5, Index:28, MTevent: A Multi-Task Event Camera Dataset for 6D Pose Estimation and Moving Object Detection, https://arxiv.org/pdf/2505.11282, 2025-06-02
2025-11-11 01:11:02,096 - INFO - root - Page:5, Index:29, Imputation-free and Alignment-free: Incomplete Multi-view Clustering Driven by Consensus Semantic Learning, https://arxiv.org/pdf/2505.11182, 2025-05-16
2025-11-11 01:11:02,098 - INFO - root - Page:5, Index:30, MultiLink: Multi-class Structure Recovery via Agglomerative Clustering and Model Selection, https://arxiv.org/pdf/2505.10874, 2025-05-16
2025-11-11 01:11:02,101 - INFO - root - Page:5, Index:31, RefPose: Leveraging Reference Geometric Correspondences for Accurate 6D Pose Estimation of Unseen Objects, https://arxiv.org/pdf/2505.10841, 2025-05-16
2025-11-11 01:11:02,104 - INFO - root - Page:5, Index:32, MoCLIP: Motion-Aware Fine-Tuning and Distillation of CLIP for Human Motion Generation, https://arxiv.org/pdf/2505.10810, 2025-05-15
2025-11-11 01:11:02,104 - INFO - root - Page:5, Index:33, Automated Detection of Salvin's Albatrosses: Improving Deep Learning Tools for Aerial Wildlife Surveys, https://arxiv.org/pdf/2505.10737, 2025-05-15
2025-11-11 01:11:02,106 - INFO - root - Page:5, Index:34, Advancing Multiple Instance Learning with Continual Learning for Whole Slide Imaging, https://arxiv.org/pdf/2505.10649, 2025-05-15
2025-11-11 01:11:02,106 - INFO - root - Page:5, Index:35, Inferring Driving Maps by Deep Learning-based Trail Map Extraction, https://arxiv.org/pdf/2505.10258, 2025-05-15
2025-11-11 01:11:02,106 - INFO - root - Page:5, Index:36, Behind Maya: Building a Multilingual Vision Language Model, https://arxiv.org/pdf/2505.08910, 2025-05-15
2025-11-11 01:11:02,107 - INFO - root - Page:5, Index:37, PosterO: Structuring Layout Trees to Enable Language Models in Generalized Content-Aware Layout Generation, https://arxiv.org/pdf/2505.07843, 2025-05-26
2025-11-11 01:11:02,107 - INFO - root - Page:5, Index:38, Prototype Augmented Hypernetworks for Continual Learning, https://arxiv.org/pdf/2505.07450, 2025-05-16
2025-11-11 01:11:02,107 - INFO - root - Fetching page 7 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=300
2025-11-11 01:11:08,917 - INFO - root - get_all_titles_from_web 
2025-11-11 01:11:08,917 - INFO - root - Page:6, Index:0, Convex Relaxation for Robust Vanishing Point Estimation in Manhattan World, https://arxiv.org/pdf/2505.04788, 2025-06-05
2025-11-11 01:11:08,918 - INFO - root - Page:6, Index:1, S3D: Sketch-Driven 3D Model Generation, https://arxiv.org/pdf/2505.04185, 2025-06-03
2025-11-11 01:11:08,918 - INFO - root - Page:6, Index:2, Generating Synthetic Data via Augmentations for Improved Facial Resemblance in DreamBooth and InstantID, https://arxiv.org/pdf/2505.03557, 2025-07-17
2025-11-11 01:11:08,918 - INFO - root - Page:6, Index:3, CAV-MAE Sync: Improving Contrastive Audio-Visual Mask Autoencoders via Fine-Grained Alignment, https://arxiv.org/pdf/2505.01237, 2025-05-21
2025-11-11 01:11:08,919 - INFO - root - Fetching page 8 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=350
2025-11-11 01:11:15,576 - INFO - root - get_all_titles_from_web 
2025-11-11 01:11:15,577 - INFO - root - Page:7, Index:0, Where's the liability in the Generative Era? Recovery-based Black-Box Detection of AI-Generated Content, https://arxiv.org/pdf/2505.01008, 2025-08-25
2025-11-11 01:11:15,577 - INFO - root - Page:7, Index:1, SpatialLLM: A Compound 3D-Informed Design towards Spatially-Intelligent Large Multimodal Models, https://arxiv.org/pdf/2505.00788, 2025-06-10
2025-11-11 01:11:15,580 - INFO - root - Page:7, Index:2, Prisma: An Open Source Toolkit for Mechanistic Interpretability in Vision and Video, https://arxiv.org/pdf/2504.19475, 2025-06-03
2025-11-11 01:11:15,580 - INFO - root - Page:7, Index:3, SSL4Eco: A Global Seasonal Dataset for Geospatial Foundation Models in Ecology, https://arxiv.org/pdf/2504.18256, 2025-10-20
2025-11-11 01:11:15,581 - INFO - root - Page:7, Index:4, Vision-Language Models Are Not Pragmatically Competent in Referring Expression Generation, https://arxiv.org/pdf/2504.16060, 2025-07-30
2025-11-11 01:11:15,582 - INFO - root - Fetching page 9 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=400
2025-11-11 01:11:21,875 - INFO - root - get_all_titles_from_web 
2025-11-11 01:11:21,875 - INFO - root - Page:8, Index:0, Leveraging Automatic CAD Annotations for Supervised Learning in 3D Scene Understanding, https://arxiv.org/pdf/2504.13580, 2025-05-16
2025-11-11 01:11:21,876 - INFO - root - Page:8, Index:1, CAP-Net: A Unified Network for 6D Pose and Size Estimation of Categorical Articulated Parts from a Single RGB-D Image, https://arxiv.org/pdf/2504.11230, 2025-06-02
2025-11-11 01:11:21,876 - INFO - root - Page:8, Index:2, Video Summarization with Large Language Models, https://arxiv.org/pdf/2504.11199, 2025-06-05
2025-11-11 01:11:21,876 - INFO - root - Page:8, Index:3, R-TPT: Improving Adversarial Robustness of Vision-Language Models through Test-Time Prompt Tuning, https://arxiv.org/pdf/2504.11195, 2025-08-27
2025-11-11 01:11:21,876 - INFO - root - Page:8, Index:4, TerraMesh: A Planetary Mosaic of Multimodal Earth Observation Data, https://arxiv.org/pdf/2504.11172, 2025-08-01
2025-11-11 01:11:21,877 - INFO - root - Page:8, Index:5, Seeing like a Cephalopod: Colour Vision with a Monochrome Event Camera, https://arxiv.org/pdf/2504.10984, 2025-06-06
2025-11-11 01:11:21,877 - INFO - root - Page:8, Index:6, Hearing Anywhere in Any Environment, https://arxiv.org/pdf/2504.10746, 2025-06-04
2025-11-11 01:11:21,877 - INFO - root - Fetching page 10 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=450
2025-11-11 01:11:28,785 - INFO - root - get_all_titles_from_web 
2025-11-11 01:11:28,785 - INFO - root - Page:9, Index:0, Correlative and Discriminative Label Grouping for Multi-Label Visual Prompt Tuning, https://arxiv.org/pdf/2504.09990, 2025-07-09
2025-11-11 01:11:28,785 - INFO - root - Page:9, Index:1, SPICE: A Synergistic, Precise, Iterative, and Customizable Image Editing Workflow, https://arxiv.org/pdf/2504.09697, 2025-10-16
2025-11-11 01:11:28,785 - INFO - root - Page:9, Index:2, Mimic In-Context Learning for Multimodal Tasks, https://arxiv.org/pdf/2504.08851, 2025-05-17
2025-11-11 01:11:28,786 - INFO - root - Page:9, Index:3, Digital Twin Catalog: A Large-Scale Photorealistic 3D Object Digital Twin Dataset, https://arxiv.org/pdf/2504.08541, 2025-05-18
2025-11-11 01:11:28,786 - INFO - root - Page:9, Index:4, MMLA: Multi-Environment, Multi-Species, Low-Altitude Drone Dataset, https://arxiv.org/pdf/2504.07744, 2025-10-22
2025-11-11 01:11:28,786 - INFO - root - Fetching page 11 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=500
2025-11-11 01:11:35,559 - INFO - root - get_all_titles_from_web 
2025-11-11 01:11:35,559 - INFO - root - Page:10, Index:0, PromptHMR: Promptable Human Mesh Recovery, https://arxiv.org/pdf/2504.06397, 2025-05-23
2025-11-11 01:11:35,560 - INFO - root - Page:10, Index:1, SCAM: A Real-World Typographic Robustness Evaluation for Multimodal Foundation Models, https://arxiv.org/pdf/2504.04893, 2025-09-26
2025-11-11 01:11:35,560 - INFO - root - Fetching page 12 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=550
2025-11-11 01:11:42,367 - INFO - root - get_all_titles_from_web 
2025-11-11 01:11:42,367 - INFO - root - Page:11, Index:0, Charm: The Missing Piece in ViT fine-tuning for Image Aesthetic Assessment, https://arxiv.org/pdf/2504.02522, 2025-05-15
2025-11-11 01:11:42,368 - INFO - root - Page:11, Index:1, T*: Re-thinking Temporal Search for Long-Form Video Understanding, https://arxiv.org/pdf/2504.02259, 2025-08-24
2025-11-11 01:11:42,368 - INFO - root - Page:11, Index:2, CoMatcher: Multi-View Collaborative Feature Matching, https://arxiv.org/pdf/2504.01872, 2025-08-20
2025-11-11 01:11:42,368 - INFO - root - Page:11, Index:3, Think Small, Act Big: Primitive Prompt Learning for Lifelong Robot Manipulation, https://arxiv.org/pdf/2504.00420, 2025-06-01
2025-11-11 01:11:42,369 - INFO - root - Fetching page 13 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=600
2025-11-11 01:11:48,637 - INFO - root - get_all_titles_from_web 
2025-11-11 01:11:48,638 - INFO - root - Page:12, Index:0, It's a (Blind) Match! Towards Vision-Language Correspondence without Parallel Data, https://arxiv.org/pdf/2503.24129, 2025-05-29
2025-11-11 01:11:48,638 - INFO - root - Page:12, Index:1, ReferDINO-Plus: 2nd Solution for 4th PVUW MeViS Challenge at CVPR 2025, https://arxiv.org/pdf/2503.23509, 2025-05-29
2025-11-11 01:11:48,638 - INFO - root - Page:12, Index:2, A Unified Image-Dense Annotation Generation Model for Underwater Scenes, https://arxiv.org/pdf/2503.21771, 2025-07-27
2025-11-11 01:11:48,638 - INFO - root - Fetching page 14 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=650
2025-11-11 01:11:55,657 - INFO - root - get_all_titles_from_web 
2025-11-11 01:11:55,658 - INFO - root - Page:13, Index:0, Learning Class Prototypes for Unified Sparse Supervised 3D Object Detection, https://arxiv.org/pdf/2503.21099, 2025-06-13
2025-11-11 01:11:55,658 - INFO - root - Page:13, Index:1, LATTE-MV: Learning to Anticipate Table Tennis Hits from Monocular Videos, https://arxiv.org/pdf/2503.20936, 2025-09-01
2025-11-11 01:11:55,658 - INFO - root - Page:13, Index:2, BizGen: Advancing Article-level Visual Text Rendering for Infographics Generation, https://arxiv.org/pdf/2503.20672, 2025-07-02
2025-11-11 01:11:55,658 - INFO - root - Page:13, Index:3, ITA-MDT: Image-Timestep-Adaptive Masked Diffusion Transformer Framework for Image-Based Virtual Try-On, https://arxiv.org/pdf/2503.20418, 2025-06-01
2025-11-11 01:11:55,659 - INFO - root - Page:13, Index:4, Faster Parameter-Efficient Tuning with Token Redundancy Reduction, https://arxiv.org/pdf/2503.20282, 2025-08-26
2025-11-11 01:11:55,659 - INFO - root - Page:13, Index:5, DINeMo: Learning Neural Mesh Models with no 3D Annotations, https://arxiv.org/pdf/2503.20220, 2025-06-09
2025-11-11 01:11:55,659 - INFO - root - Page:13, Index:6, Scaling Vision Pre-Training to 4K Resolution, https://arxiv.org/pdf/2503.19903, 2025-08-03
2025-11-11 01:11:55,660 - INFO - root - Page:13, Index:7, GENIUS: A Generative Framework for Universal Multimodal Search, https://arxiv.org/pdf/2503.19868, 2025-06-05
2025-11-11 01:11:55,660 - INFO - root - Fetching page 15 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=700
2025-11-11 01:12:02,084 - INFO - root - get_all_titles_from_web 
2025-11-11 01:12:02,084 - INFO - root - Page:14, Index:0, Galaxy Walker: Geometry-aware VLMs For Galaxy-scale Understanding, https://arxiv.org/pdf/2503.18578, 2025-05-25
2025-11-11 01:12:02,084 - INFO - root - Page:14, Index:1, LookCloser: Frequency-aware Radiance Field for Tiny-Detail Scene, https://arxiv.org/pdf/2503.18513, 2025-07-29
2025-11-11 01:12:02,085 - INFO - root - Fetching page 16 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=750
2025-11-11 01:12:08,341 - INFO - root - get_all_titles_from_web 
2025-11-11 01:12:08,342 - INFO - root - Page:15, Index:0, LoTUS: Large-Scale Machine Unlearning with a Taste of Uncertainty, https://arxiv.org/pdf/2503.18314, 2025-05-29
2025-11-11 01:12:08,342 - INFO - root - Page:15, Index:1, MammAlps: A multi-view video behavior monitoring dataset of wild mammals in the Swiss Alps, https://arxiv.org/pdf/2503.18223, 2025-06-04
2025-11-11 01:12:08,342 - INFO - root - Page:15, Index:2, Progressive Prompt Detailing for Improved Alignment in Text-to-Image Generative Models, https://arxiv.org/pdf/2503.17794, 2025-05-30
2025-11-11 01:12:08,342 - INFO - root - Page:15, Index:3, CountLLM: Towards Generalizable Repetitive Action Counting via Large Language Model, https://arxiv.org/pdf/2503.17690, 2025-06-29
2025-11-11 01:12:08,343 - INFO - root - Page:15, Index:4, TaoAvatar: Real-Time Lifelike Full-Body Talking Avatars for Augmented Reality via 3D Gaussian Splatting, https://arxiv.org/pdf/2503.17032, 2025-07-23
2025-11-11 01:12:08,343 - INFO - root - Page:15, Index:5, Generalized Few-shot 3D Point Cloud Segmentation with Vision-Language Model, https://arxiv.org/pdf/2503.16282, 2025-05-20
2025-11-11 01:12:08,344 - INFO - root - Fetching page 17 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=800
2025-11-11 01:12:15,159 - INFO - root - get_all_titles_from_web 
2025-11-11 01:12:15,161 - INFO - root - Page:16, Index:0, High Temporal Consistency through Semantic Similarity Propagation in Semi-Supervised Video Semantic Segmentation for Autonomous Flight, https://arxiv.org/pdf/2503.15676, 2025-06-26
2025-11-11 01:12:15,161 - INFO - root - Page:16, Index:1, DPFlow: Adaptive Optical Flow Estimation with a Dual-Pyramid Framework, https://arxiv.org/pdf/2503.14880, 2025-09-29
2025-11-11 01:12:15,161 - INFO - root - Fetching page 18 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=850
2025-11-11 01:12:21,840 - INFO - root - get_all_titles_from_web 
2025-11-11 01:12:21,841 - INFO - root - Page:17, Index:0, From Head to Tail: Towards Balanced Representation in Large Vision-Language Models through Adaptive Data Calibration, https://arxiv.org/pdf/2503.12821, 2025-05-29
2025-11-11 01:12:21,841 - INFO - root - Page:17, Index:1, MambaIC: State Space Models for High-Performance Learned Image Compression, https://arxiv.org/pdf/2503.12461, 2025-08-22
2025-11-11 01:12:21,841 - INFO - root - Page:17, Index:2, Localized Concept Erasure for Text-to-Image Diffusion Models Using Training-Free Gated Low-Rank Adaptation, https://arxiv.org/pdf/2503.12356, 2025-07-09
2025-11-11 01:12:21,841 - INFO - root - Page:17, Index:3, TASTE-Rob: Advancing Video Generation of Task-Oriented Hand-Object Interaction for Generalizable Robotic Manipulation, https://arxiv.org/pdf/2503.11423, 2025-06-05
2025-11-11 01:12:21,842 - INFO - root - Page:17, Index:4, Panopticon: Advancing Any-Sensor Foundation Models for Earth Observation, https://arxiv.org/pdf/2503.10845, 2025-08-01
2025-11-11 01:12:21,842 - INFO - root - Page:17, Index:5, Transformers without Normalization, https://arxiv.org/pdf/2503.10622, 2025-06-14
2025-11-11 01:12:21,842 - INFO - root - Page:17, Index:6, dFLMoE: Decentralized Federated Learning via Mixture of Experts for Medical Data Analysis, https://arxiv.org/pdf/2503.10412, 2025-05-19
2025-11-11 01:12:21,842 - INFO - root - Fetching page 19 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=900
2025-11-11 01:12:28,848 - INFO - root - get_all_titles_from_web 
2025-11-11 01:12:28,848 - INFO - root - Page:18, Index:0, Project-Probe-Aggregate: Efficient Fine-Tuning for Group Robustness, https://arxiv.org/pdf/2503.09487, 2025-08-26
2025-11-11 01:12:28,848 - INFO - root - Page:18, Index:1, VLog: Video-Language Models by Generative Retrieval of Narration Vocabulary, https://arxiv.org/pdf/2503.09402, 2025-06-09
2025-11-11 01:12:28,848 - INFO - root - Fetching page 20 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=950
2025-11-11 01:12:35,427 - INFO - root - get_all_titles_from_web 
2025-11-11 01:12:35,429 - INFO - root - Page:19, Index:0, Escaping Plato's Cave: Towards the Alignment of 3D and Text Latent Spaces, https://arxiv.org/pdf/2503.05283, 2025-06-04
2025-11-11 01:12:35,429 - INFO - root - Page:19, Index:1, FluidNexus: 3D Fluid Reconstruction and Prediction from a Single Video, https://arxiv.org/pdf/2503.04720, 2025-07-09
2025-11-11 01:12:35,429 - INFO - root - Page:19, Index:2, Question-Aware Gaussian Experts for Audio-Visual Question Answering, https://arxiv.org/pdf/2503.04459, 2025-06-11
2025-11-11 01:12:35,430 - INFO - root - Page:19, Index:3, Q-Eval-100K: Evaluating Visual Quality and Alignment Level for Text-to-Vision Content, https://arxiv.org/pdf/2503.02357, 2025-06-15
2025-11-11 01:12:35,430 - INFO - root - Fetching page 21 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=1000
2025-11-11 01:12:41,998 - INFO - root - get_all_titles_from_web 
2025-11-11 01:12:41,999 - INFO - root - Page:20, Index:0, Data Distributional Properties As Inductive Bias for Systematic Generalization, https://arxiv.org/pdf/2502.20499, 2025-06-17
2025-11-11 01:12:41,999 - INFO - root - Page:20, Index:1, Knowledge Bridger: Towards Training-free Missing Modality Completion, https://arxiv.org/pdf/2502.19834, 2025-06-17
2025-11-11 01:12:41,999 - INFO - root - Fetching page 22 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=1050
2025-11-11 01:12:48,247 - INFO - root - get_all_titles_from_web 
2025-11-11 01:12:48,247 - INFO - root - Page:21, Index:0, MALT Diffusion: Memory-Augmented Latent Transformers for Any-Length Video Generation, https://arxiv.org/pdf/2502.12632, 2025-07-08
2025-11-11 01:12:48,248 - INFO - root - Page:21, Index:1, ILIAS: Instance-Level Image retrieval At Scale, https://arxiv.org/pdf/2502.11748, 2025-06-23
2025-11-11 01:12:48,248 - INFO - root - Page:21, Index:2, Distraction is All You Need for Multimodal Large Language Model Jailbreaking, https://arxiv.org/pdf/2502.10794, 2025-06-16
2025-11-11 01:12:48,248 - INFO - root - Page:21, Index:3, Spatial457: A Diagnostic Benchmark for 6D Spatial Reasoning of Large Multimodal Models, https://arxiv.org/pdf/2502.08636, 2025-06-08
2025-11-11 01:12:48,248 - INFO - root - Page:21, Index:4, TRAVEL: Training-Free Retrieval and Alignment for Vision-and-Language Navigation, https://arxiv.org/pdf/2502.07306, 2025-06-09
2025-11-11 01:12:48,249 - INFO - root - Page:21, Index:5, DiTASK: Multi-Task Fine-Tuning with Diffeomorphic Transformations, https://arxiv.org/pdf/2502.06029, 2025-06-01
2025-11-11 01:12:48,249 - INFO - root - Page:21, Index:6, ConceptAttention: Diffusion Transformers Learn Highly Interpretable Features, https://arxiv.org/pdf/2502.04320, 2025-07-01
2025-11-11 01:12:48,251 - INFO - root - Page:21, Index:7, GCE-Pose: Global Context Enhancement for Category-level Object Pose Estimation, https://arxiv.org/pdf/2502.04293, 2025-06-24
2025-11-11 01:12:48,251 - INFO - root - Page:21, Index:8, Calibrated Multi-Preference Optimization for Aligning Diffusion Models, https://arxiv.org/pdf/2502.02588, 2025-09-26
2025-11-11 01:12:48,251 - INFO - root - Page:21, Index:9, Instruct-4DGS: Efficient Dynamic Scene Editing via 4D Gaussian-based Static-Dynamic Separation, https://arxiv.org/pdf/2502.02091, 2025-07-01
2025-11-11 01:12:48,252 - INFO - root - Page:21, Index:10, Low-Resource Video Super-Resolution using Memory, Wavelets, and Deformable Convolutions, https://arxiv.org/pdf/2502.01816, 2025-06-19
2025-11-11 01:12:48,252 - INFO - root - Page:21, Index:11, Bridging Text and Crystal Structures: Literature-driven Contrastive Learning for Materials Science, https://arxiv.org/pdf/2501.12919, 2025-06-18
2025-11-11 01:12:48,252 - INFO - root - Page:21, Index:12, T2ISafety: Benchmark for Assessing Fairness, Toxicity, and Privacy in Image Generation, https://arxiv.org/pdf/2501.12612, 2025-07-25
2025-11-11 01:12:48,252 - INFO - root - Page:21, Index:13, Fine-Grained Image-Text Correspondence with Cost Aggregation for Open-Vocabulary Part Segmentation, https://arxiv.org/pdf/2501.09688, 2025-08-08
2025-11-11 01:12:48,252 - INFO - root - Fetching page 23 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=1100
2025-11-11 01:12:54,464 - INFO - root - get_all_titles_from_web 
2025-11-11 01:12:54,464 - INFO - root - Page:22, Index:0, Bias for Action: Video Implicit Neural Representations with Bias Modulation, https://arxiv.org/pdf/2501.09277, 2025-06-06
2025-11-11 01:12:54,465 - INFO - root - Page:22, Index:1, MonSter++: Unified Stereo Matching, Multi-view Stereo, and Real-time Stereo with Monodepth Priors, https://arxiv.org/pdf/2501.08643, 2025-09-25
2025-11-11 01:12:54,466 - INFO - root - Page:22, Index:2, Go-with-the-Flow: Motion-Controllable Video Diffusion Models Using Real-Time Warped Noise, https://arxiv.org/pdf/2501.08331, 2025-08-06
2025-11-11 01:12:54,466 - INFO - root - Page:22, Index:3, Nonisotropic Gaussian Diffusion for Realistic 3D Human Motion Prediction, https://arxiv.org/pdf/2501.06035, 2025-07-08
2025-11-11 01:12:54,466 - INFO - root - Page:22, Index:4, Discovering Hidden Visual Concepts Beyond Linguistic Input in Infant Learning, https://arxiv.org/pdf/2501.05205, 2025-06-13
2025-11-11 01:12:54,467 - INFO - root - Page:22, Index:5, PERSE: Personalized 3D Generative Avatars from A Single Portrait, https://arxiv.org/pdf/2412.21206, 2025-09-28
2025-11-11 01:12:54,467 - INFO - root - Page:22, Index:6, MaskGaussian: Adaptive 3D Gaussian Representation from Probabilistic Masks, https://arxiv.org/pdf/2412.20522, 2025-06-14
2025-11-11 01:12:54,467 - INFO - root - Page:22, Index:7, SimLTD: Simple Supervised and Semi-Supervised Long-Tailed Object Detection, https://arxiv.org/pdf/2412.20047, 2025-06-09
2025-11-11 01:12:54,467 - INFO - root - Page:22, Index:8, Conditional Balance: Improving Multi-Conditioning Trade-Offs in Image Generation, https://arxiv.org/pdf/2412.19853, 2025-08-03
2025-11-11 01:12:54,468 - INFO - root - Fetching page 24 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=1150
2025-11-11 01:13:01,429 - INFO - root - get_all_titles_from_web 
2025-11-11 01:13:01,430 - INFO - root - Page:23, Index:0, CoCoGaussian: Leveraging Circle of Confusion for Gaussian Splatting from Defocused Images, https://arxiv.org/pdf/2412.16028, 2025-05-15
2025-11-11 01:13:01,430 - INFO - root - Page:23, Index:1, EnergyMoGen: Compositional Human Motion Generation with Energy-Based Diffusion Model in Latent Space, https://arxiv.org/pdf/2412.14706, 2025-06-04
2025-11-11 01:13:01,430 - INFO - root - Page:23, Index:2, DarkIR: Robust Low-Light Image Restoration, https://arxiv.org/pdf/2412.13443, 2025-10-14
2025-11-11 01:13:01,430 - INFO - root - Page:23, Index:3, FastVLM: Efficient Vision Encoding for Vision Language Models, https://arxiv.org/pdf/2412.13303, 2025-05-15
2025-11-11 01:13:01,430 - INFO - root - Page:23, Index:4, Real-time Free-view Human Rendering from Sparse-view RGB Videos using Double Unprojected Textures, https://arxiv.org/pdf/2412.13183, 2025-06-20
2025-11-11 01:13:01,432 - INFO - root - Page:23, Index:5, CondiMen: Conditional Multi-Person Mesh Recovery, https://arxiv.org/pdf/2412.13058, 2025-06-04
2025-11-11 01:13:01,432 - INFO - root - Page:23, Index:6, MASt3R-SLAM: Real-Time Dense SLAM with 3D Reconstruction Priors, https://arxiv.org/pdf/2412.12392, 2025-06-02
2025-11-11 01:13:01,432 - INFO - root - Page:23, Index:7, DynamicScaler: Seamless and Scalable Video Generation for Panoramic Scenes, https://arxiv.org/pdf/2412.11100, 2025-10-04
2025-11-11 01:13:01,432 - INFO - root - Page:23, Index:8, SnapGen-V: Generating a Five-Second Video within Five Seconds on a Mobile Device, https://arxiv.org/pdf/2412.10494, 2025-06-09
2025-11-11 01:13:01,432 - INFO - root - Page:23, Index:9, Mr. DETR++: Instructive Multi-Route Training for Detection Transformers with Mixture-of-Experts, https://arxiv.org/pdf/2412.10028, 2025-06-26
2025-11-11 01:13:01,433 - INFO - root - Page:23, Index:10, LinGen: Towards High-Resolution Minute-Length Text-to-Video Generation with Linear Computational Complexity, https://arxiv.org/pdf/2412.09856, 2025-05-24
2025-11-11 01:13:01,434 - INFO - root - Page:23, Index:11, Gaze-LLE: Gaze Target Estimation via Large-Scale Learned Encoders, https://arxiv.org/pdf/2412.09586, 2025-06-03
2025-11-11 01:13:01,434 - INFO - root - Fetching page 25 with URL: https://arxiv.org/search/?query=CVPR+2025&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start=1200
2025-11-11 01:13:08,050 - INFO - root - get_all_titles_from_web 
2025-11-11 01:13:08,050 - INFO - root - Page:24, Index:0, From Slow Bidirectional to Fast Autoregressive Video Diffusion Models, https://arxiv.org/pdf/2412.07772, 2025-09-23
2025-11-11 01:13:08,051 - INFO - root - Page:24, Index:1, Rate-In: Information-Driven Adaptive Dropout Rates for Improved Inference-Time Uncertainty Estimation, https://arxiv.org/pdf/2412.07169, 2025-06-03
2025-11-11 01:13:08,051 - INFO - root - Page:24, Index:2, FIRE: Robust Detection of Diffusion-Generated Images via Frequency-Guided Reconstruction Error, https://arxiv.org/pdf/2412.07140, 2025-11-03
2025-11-11 01:13:08,052 - INFO - root - Page:24, Index:3, Birth and Death of a Rose, https://arxiv.org/pdf/2412.05278, 2025-06-05
2025-11-11 01:13:08,052 - INFO - root - Page:24, Index:4, DualPM: Dual Posed-Canonical Point Maps for 3D Shape and Pose Reconstruction, https://arxiv.org/pdf/2412.04464, 2025-08-14
2025-11-11 01:13:08,052 - INFO - root - Page:24, Index:5, SeeGround: See and Ground for Zero-Shot Open-Vocabulary 3D Visual Grounding, https://arxiv.org/pdf/2412.04383, 2025-05-29
2025-11-11 01:13:08,052 - INFO - root - ------------------------------------------------------------------------------------------------------------------------
2025-11-11 01:13:08,054 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\CVPR 2025\Learning to Seek Evidence_ A Verifiable Reasoning Agent with Causal Faithfulness.pdf
2025-11-11 01:13:08,101 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\CVPR 2025\OmniTrack++_ Omnidirectional Multi-Object Tracking by Learning Large-FoV Traject.pdf
2025-11-11 01:13:08,104 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\CVPR 2025\NeuCo-Bench_ A Novel Benchmark Framework for Neural Embeddings in Earth Observat.pdf
2025-11-11 01:13:08,106 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\CVPR 2025\NTIRE 2025 Challenge on Low Light Image Enhancement_ Methods and Results.pdf
2025-11-11 01:13:08,111 - INFO - root - File already exists, skipping download: d:\ChatPaper\academic Papers\CVPR 2025\Class Prototypes based Contrastive Learning for Classifying Multi-Label and Fine.pdf
