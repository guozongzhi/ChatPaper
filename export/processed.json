{
  "d:\\ChatPaper\\academic Papers\\Quantization-Aware-Training\\A Quantized VAE-MLP Botnet Detection Model_ A Systematic Evaluation of Quantizat.pdf": {
    "title": "A Quantized VAE-MLP Botnet Detection Model: A Systematic Evaluation of Quantization-Aware Training and Post-Training Quantization Strategies",
    "output": "D:\\ChatPaper\\export\\A Quantized VAE-MLP Botnet Detection Model_ A Systematic Evaluation of Quantizat.md",
    "time": "2025-11-09 21:06:35.030394"
  },
  "d:\\ChatPaper\\academic Papers\\Quantization-Aware-Training\\FP8-Flow-MoE_ A Casting-Free FP8 Recipe without Double Quantization Error.pdf": {
    "title": "FP8-Flow-MoE: A Casting-Free FP8 Recipe without Double Quantization Error",
    "output": "D:\\ChatPaper\\export\\FP8-Flow-MoE_ A Casting-Free FP8 Recipe without Double Quantization Error.md",
    "time": "2025-11-09 21:08:06.993173"
  },
  "d:\\ChatPaper\\academic Papers\\Quantization-Aware-Training\\Outlier-Aware Post-Training Quantization for Image Super-Resolution.pdf": {
    "title": "Outlier-Aware Post-Training Quantization for Image Super-Resolution",
    "output": "D:\\ChatPaper\\export\\Outlier-Aware Post-Training Quantization for Image Super-Resolution.md",
    "time": "2025-11-09 21:09:32.132184"
  },
  "d:\\ChatPaper\\academic Papers\\Quantization-Aware-Training\\Evaluation of Wafer-Scale SOT-MRAM for Analog Crossbar Array Applications.pdf": {
    "title": "Evaluation of Wafer-Scale SOT-MRAM for Analog Crossbar Array Applications",
    "output": "D:\\ChatPaper\\export\\Evaluation of Wafer-Scale SOT-MRAM for Analog Crossbar Array Applications.md",
    "time": "2025-11-09 21:11:10.185130"
  },
  "d:\\ChatPaper\\academic Papers\\Quantization-Aware-Training\\Improving the Straight-Through Estimator with Zeroth-Order Information.pdf": {
    "title": "Improving the Straight-Through Estimator with Zeroth-Order Information",
    "output": "D:\\ChatPaper\\export\\Improving the Straight-Through Estimator with Zeroth-Order Information.md",
    "time": "2025-11-09 21:12:34.732785"
  },
  "d:\\ChatPaper\\academic Papers\\Quantization-Aware-Training\\Real-Time Semantic Segmentation on FPGA for Autonomous Vehicles Using LMIINet wi.pdf": {
    "title": "Real-Time Semantic Segmentation on FPGA for Autonomous Vehicles Using LMIINet with the CGRA4ML Framework",
    "output": "D:\\ChatPaper\\export\\Real-Time Semantic Segmentation on FPGA for Autonomous Vehicles Using LMIINet wi.md",
    "time": "2025-11-09 21:14:12.250338"
  },
  "d:\\ChatPaper\\academic Papers\\Quantization-Aware-Training\\TernaryCLIP_ Efficiently Compressing Vision-Language Models with Ternary Weights.pdf": {
    "title": "TernaryCLIP: Efficiently Compressing Vision-Language Models with Ternary Weights and Distilled Knowledge",
    "output": "D:\\ChatPaper\\export\\TernaryCLIP_ Efficiently Compressing Vision-Language Models with Ternary Weights.md",
    "time": "2025-11-09 21:15:40.171673"
  },
  "d:\\ChatPaper\\academic Papers\\Quantization-Aware-Training\\KARIPAP_ Quantum-Inspired Tensor Network Compression of Large Language Models Us.pdf": {
    "title": "KARIPAP: Quantum-Inspired Tensor Network Compression of Large Language Models Using Infinite Projected Entangled Pair States and Tensor Renormalization Group",
    "output": "D:\\ChatPaper\\export\\KARIPAP_ Quantum-Inspired Tensor Network Compression of Large Language Models Us.md",
    "time": "2025-11-09 21:20:21.555976"
  },
  "d:\\ChatPaper\\academic Papers\\Quantization-Aware-Training\\A Convergence Analysis of Adaptive Optimizers under Floating-point Quantization.pdf": {
    "title": "A Convergence Analysis of Adaptive Optimizers under Floating-point Quantization",
    "output": "D:\\ChatPaper\\export\\A Convergence Analysis of Adaptive Optimizers under Floating-point Quantization.md",
    "time": "2025-11-09 21:21:50.459402"
  },
  "d:\\ChatPaper\\academic Papers\\Quantization-Aware-Training\\Adaptive Distribution-aware Quantization for Mixed-Precision Neural Networks.pdf": {
    "title": "Adaptive Distribution-aware Quantization for Mixed-Precision Neural Networks",
    "output": "D:\\ChatPaper\\export\\Adaptive Distribution-aware Quantization for Mixed-Precision Neural Networks.md",
    "time": "2025-11-09 21:23:20.270464"
  },
  "d:\\ChatPaper\\academic Papers\\Quantization-Aware-Training\\CAGE_ Curvature-Aware Gradient Estimation For Accurate Quantization-Aware Traini.pdf": {
    "title": "CAGE: Curvature-Aware Gradient Estimation For Accurate Quantization-Aware Training",
    "output": "D:\\ChatPaper\\export\\CAGE_ Curvature-Aware Gradient Estimation For Accurate Quantization-Aware Traini.md",
    "time": "2025-11-09 21:25:27.284070"
  },
  "d:\\ChatPaper\\academic Papers\\Quantization-Aware-Training\\Mixed-Precision Quantization for Language Models_ Techniques and Prospects.pdf": {
    "title": "Mixed-Precision Quantization for Language Models: Techniques and Prospects",
    "output": "D:\\ChatPaper\\export\\Mixed-Precision Quantization for Language Models_ Techniques and Prospects.md",
    "time": "2025-11-09 21:26:52.080220"
  },
  "d:\\ChatPaper\\academic Papers\\Quantization-Aware-Training\\SPLite Hand_ Sparsity-Aware Lightweight 3D Hand Pose Estimation.pdf": {
    "title": "SPLite Hand: Sparsity-Aware Lightweight 3D Hand Pose Estimation",
    "output": "D:\\ChatPaper\\export\\SPLite Hand_ Sparsity-Aware Lightweight 3D Hand Pose Estimation.md",
    "time": "2025-11-09 21:28:25.381791"
  },
  "d:\\ChatPaper\\academic Papers\\Quantization-Aware-Training\\CTR-LoRA_ Curvature-Aware and Trust-Region Guided Low-Rank Adaptation for Large.pdf": {
    "title": "CTR-LoRA: Curvature-Aware and Trust-Region Guided Low-Rank Adaptation for Large Language Models",
    "output": "D:\\ChatPaper\\export\\CTR-LoRA_ Curvature-Aware and Trust-Region Guided Low-Rank Adaptation for Large.md",
    "time": "2025-11-09 21:29:51.169807"
  },
  "d:\\ChatPaper\\academic Papers\\Quantization-Aware-Training\\SANR_ Scene-Aware Neural Representation for Light Field Image Compression with R.pdf": {
    "title": "SANR: Scene-Aware Neural Representation for Light Field Image Compression with Rate-Distortion Optimization",
    "output": "D:\\ChatPaper\\export\\SANR_ Scene-Aware Neural Representation for Light Field Image Compression with R.md",
    "time": "2025-11-09 21:34:34.955725"
  },
  "d:\\ChatPaper\\academic Papers\\Quantization-Aware-Training\\SpikeFit_ Towards Optimal Deployment of Spiking Networks on Neuromorphic Hardwar.pdf": {
    "title": "SpikeFit: Towards Optimal Deployment of Spiking Networks on Neuromorphic Hardware",
    "output": "D:\\ChatPaper\\export\\SpikeFit_ Towards Optimal Deployment of Spiking Networks on Neuromorphic Hardwar.md",
    "time": "2025-11-09 21:36:00.709937"
  },
  "d:\\ChatPaper\\academic Papers\\Quantization-Aware-Training\\GRank_ Towards Target-Aware and Streamlined Industrial Retrieval with a Generate.pdf": {
    "title": "GRank: Towards Target-Aware and Streamlined Industrial Retrieval with a Generate-Rank Framework",
    "output": "D:\\ChatPaper\\export\\GRank_ Towards Target-Aware and Streamlined Industrial Retrieval with a Generate.md",
    "time": "2025-11-09 21:38:10.293793"
  },
  "d:\\ChatPaper\\academic Papers\\Quantization-Aware-Training\\SaLon3R_ Structure-aware Long-term Generalizable 3D Reconstruction from Unposed.pdf": {
    "title": "SaLon3R: Structure-aware Long-term Generalizable 3D Reconstruction from Unposed Images",
    "output": "D:\\ChatPaper\\export\\SaLon3R_ Structure-aware Long-term Generalizable 3D Reconstruction from Unposed.md",
    "time": "2025-11-09 21:39:42.603277"
  },
  "d:\\ChatPaper\\academic Papers\\Quantization-Aware-Training\\FraQAT_ Quantization Aware Training with Fractional bits.pdf": {
    "title": "FraQAT: Quantization Aware Training with Fractional bits",
    "output": "D:\\ChatPaper\\export\\FraQAT_ Quantization Aware Training with Fractional bits.md",
    "time": "2025-11-09 21:41:17.209966"
  },
  "d:\\ChatPaper\\academic Papers\\Quantization-Aware-Training\\Computing-In-Memory Aware Model Adaption For Edge Devices.pdf": {
    "title": "Computing-In-Memory Aware Model Adaption For Edge Devices",
    "output": "D:\\ChatPaper\\export\\Computing-In-Memory Aware Model Adaption For Edge Devices.md",
    "time": "2025-11-09 21:42:39.695275"
  },
  "d:\\ChatPaper\\academic Papers\\Quantization-Aware-Training\\Invited Paper_ BitMedViT_ Ternary-Quantized Vision Transformer for Medical AI As.pdf": {
    "title": "Invited Paper: BitMedViT: Ternary-Quantized Vision Transformer for Medical AI Assistants on the Edge",
    "output": "D:\\ChatPaper\\export\\Invited Paper_ BitMedViT_ Ternary-Quantized Vision Transformer for Medical AI As.md",
    "time": "2025-11-09 21:44:16.198725"
  },
  "d:\\ChatPaper\\academic Papers\\Quantization-Aware-Training\\NeuroRVQ_ Multi-Scale EEG Tokenization for Generative Large Brainwave Models.pdf": {
    "title": "NeuroRVQ: Multi-Scale EEG Tokenization for Generative Large Brainwave Models",
    "output": "D:\\ChatPaper\\export\\NeuroRVQ_ Multi-Scale EEG Tokenization for Generative Large Brainwave Models.md",
    "time": "2025-11-09 21:45:46.793182"
  },
  "d:\\ChatPaper\\academic Papers\\Quantization-Aware-Training\\Detect Anything via Next Point Prediction.pdf": {
    "title": "Detect Anything via Next Point Prediction",
    "output": "D:\\ChatPaper\\export\\Detect Anything via Next Point Prediction.md",
    "time": "2025-11-09 21:47:16.014646"
  },
  "d:\\ChatPaper\\academic Papers\\Quantization-Aware-Training\\AndesVL Technical Report_ An Efficient Mobile-side Multimodal Large Language Mod.pdf": {
    "title": "AndesVL Technical Report: An Efficient Mobile-side Multimodal Large Language Model",
    "output": "D:\\ChatPaper\\export\\AndesVL Technical Report_ An Efficient Mobile-side Multimodal Large Language Mod.md",
    "time": "2025-11-09 21:48:45.419515"
  },
  "d:\\ChatPaper\\academic Papers\\Quantization-Aware-Training\\Rescaling-Aware Training for Efficient Deployment of Deep Learning Models on Ful.pdf": {
    "title": "Rescaling-Aware Training for Efficient Deployment of Deep Learning Models on Full-Integer Hardware",
    "output": "D:\\ChatPaper\\export\\Rescaling-Aware Training for Efficient Deployment of Deep Learning Models on Ful.md",
    "time": "2025-11-09 21:50:12.649599"
  },
  "d:\\ChatPaper\\academic Papers\\Quantization-Aware-Training\\SASER_ Stego attacks on open-source LLMs.pdf": {
    "title": "SASER: Stego attacks on open-source LLMs",
    "output": "D:\\ChatPaper\\export\\SASER_ Stego attacks on open-source LLMs.md",
    "time": "2025-11-09 21:51:52.691226"
  },
  "d:\\ChatPaper\\academic Papers\\Quantization-Aware-Training\\Ultralytics YOLO Evolution_ An Overview of YOLO26, YOLO11, YOLOv8 and YOLOv5 Obj.pdf": {
    "title": "Ultralytics YOLO Evolution: An Overview of YOLO26, YOLO11, YOLOv8 and YOLOv5 Object Detectors for Computer Vision and Pattern Recognition",
    "output": "D:\\ChatPaper\\export\\Ultralytics YOLO Evolution_ An Overview of YOLO26, YOLO11, YOLOv8 and YOLOv5 Obj.md",
    "time": "2025-11-09 21:53:20.994779"
  },
  "d:\\ChatPaper\\academic Papers\\Quantization-Aware-Training\\A Theoretically-Grounded Codebook for Digital Semantic Communications.pdf": {
    "title": "A Theoretically-Grounded Codebook for Digital Semantic Communications",
    "output": "D:\\ChatPaper\\export\\A Theoretically-Grounded Codebook for Digital Semantic Communications.md",
    "time": "2025-11-09 21:54:49.503754"
  },
  "d:\\ChatPaper\\academic Papers\\Quantization-Aware-Training\\QuantDemoire_ Quantization with Outlier Aware for Image Demoiréing.pdf": {
    "title": "QuantDemoire: Quantization with Outlier Aware for Image Demoiréing",
    "output": "D:\\ChatPaper\\export\\QuantDemoire_ Quantization with Outlier Aware for Image Demoiréing.md",
    "time": "2025-11-09 21:56:32.233794"
  },
  "d:\\ChatPaper\\academic Papers\\Quantization-Aware-Training\\Adaptively Sampling-Reusing-Mixing Decomposed Gradients to Speed Up Sharpness Aw.pdf": {
    "title": "Adaptively Sampling-Reusing-Mixing Decomposed Gradients to Speed Up Sharpness Aware Minimization",
    "output": "D:\\ChatPaper\\export\\Adaptively Sampling-Reusing-Mixing Decomposed Gradients to Speed Up Sharpness Aw.md",
    "time": "2025-11-09 21:58:02.659967"
  },
  "d:\\ChatPaper\\academic Papers\\Quantization-Aware-Training\\Quant-dLLM_ Post-Training Extreme Low-Bit Quantization for Diffusion Large Langu.pdf": {
    "title": "Quant-dLLM: Post-Training Extreme Low-Bit Quantization for Diffusion Large Language Models",
    "output": "D:\\ChatPaper\\export\\Quant-dLLM_ Post-Training Extreme Low-Bit Quantization for Diffusion Large Langu.md",
    "time": "2025-11-09 21:59:34.177859"
  },
  "d:\\ChatPaper\\academic Papers\\Quantization-Aware-Training\\PT$^2$-LLM_ Post-Training Ternarization for Large Language Models.pdf": {
    "title": "PT$^2$-LLM: Post-Training Ternarization for Large Language Models",
    "output": "D:\\ChatPaper\\export\\PT$^2$-LLM_ Post-Training Ternarization for Large Language Models.md",
    "time": "2025-11-09 22:01:40.198020"
  },
  "d:\\ChatPaper\\academic Papers\\Quantization-Aware-Training\\Purrception_ Variational Flow Matching for Vector-Quantized Image Generation.pdf": {
    "title": "Purrception: Variational Flow Matching for Vector-Quantized Image Generation",
    "output": "D:\\ChatPaper\\export\\Purrception_ Variational Flow Matching for Vector-Quantized Image Generation.md",
    "time": "2025-11-09 22:03:23.891900"
  },
  "d:\\ChatPaper\\academic Papers\\Quantization-Aware-Training\\Post-Training Quantization for Audio Diffusion Transformers.pdf": {
    "title": "Post-Training Quantization for Audio Diffusion Transformers",
    "output": "D:\\ChatPaper\\export\\Post-Training Quantization for Audio Diffusion Transformers.md",
    "time": "2025-11-09 22:04:50.422582"
  },
  "d:\\ChatPaper\\academic Papers\\Quantization-Aware-Training\\Rethinking RoPE Scaling in Quantized LLM_ Theory, Outlier, and Channel-Band Anal.pdf": {
    "title": "Rethinking RoPE Scaling in Quantized LLM: Theory, Outlier, and Channel-Band Analysis with Weight Rescaling",
    "output": "D:\\ChatPaper\\export\\Rethinking RoPE Scaling in Quantized LLM_ Theory, Outlier, and Channel-Band Anal.md",
    "time": "2025-11-09 22:06:20.099151"
  },
  "d:\\ChatPaper\\academic Papers\\Quantization-Aware-Training\\Post-Training Quantization via Residual Truncation and Zero Suppression for Diff.pdf": {
    "title": "Post-Training Quantization via Residual Truncation and Zero Suppression for Diffusion Models",
    "output": "D:\\ChatPaper\\export\\Post-Training Quantization via Residual Truncation and Zero Suppression for Diff.md",
    "time": "2025-11-09 22:07:52.734991"
  },
  "d:\\ChatPaper\\academic Papers\\Quantization-Aware-Training\\Cat_ Post-Training Quantization Error Reduction via Cluster-based Affine Transfo.pdf": {
    "title": "Cat: Post-Training Quantization Error Reduction via Cluster-based Affine Transformation",
    "output": "D:\\ChatPaper\\export\\Cat_ Post-Training Quantization Error Reduction via Cluster-based Affine Transfo.md",
    "time": "2025-11-09 22:09:29.410053"
  },
  "d:\\ChatPaper\\academic Papers\\Quantization-Aware-Training\\CAST_ Continuous and Differentiable Semi-Structured Sparsity-Aware Training for.pdf": {
    "title": "CAST: Continuous and Differentiable Semi-Structured Sparsity-Aware Training for Large Language Models",
    "output": "D:\\ChatPaper\\export\\CAST_ Continuous and Differentiable Semi-Structured Sparsity-Aware Training for.md",
    "time": "2025-11-09 22:10:55.374223"
  },
  "d:\\ChatPaper\\academic Papers\\Quantization-Aware-Training\\Norm-Q_ Effective Compression Method for Hidden Markov Models in Neuro-Symbolic.pdf": {
    "title": "Norm-Q: Effective Compression Method for Hidden Markov Models in Neuro-Symbolic Applications",
    "output": "D:\\ChatPaper\\export\\Norm-Q_ Effective Compression Method for Hidden Markov Models in Neuro-Symbolic.md",
    "time": "2025-11-09 22:12:21.588955"
  },
  "d:\\ChatPaper\\academic Papers\\Quantization-Aware-Training\\On-the-Fly Adaptation to Quantization_ Configuration-Aware LoRA for Efficient Fi.pdf": {
    "title": "On-the-Fly Adaptation to Quantization: Configuration-Aware LoRA for Efficient Fine-Tuning of Quantized LLMs",
    "output": "D:\\ChatPaper\\export\\On-the-Fly Adaptation to Quantization_ Configuration-Aware LoRA for Efficient Fi.md",
    "time": "2025-11-09 22:14:01.095528"
  },
  "d:\\ChatPaper\\academic Papers\\Quantization-Aware-Training\\VoxCPM_ Tokenizer-Free TTS for Context-Aware Speech Generation and True-to-Life.pdf": {
    "title": "VoxCPM: Tokenizer-Free TTS for Context-Aware Speech Generation and True-to-Life Voice Cloning",
    "output": "D:\\ChatPaper\\export\\VoxCPM_ Tokenizer-Free TTS for Context-Aware Speech Generation and True-to-Life.md",
    "time": "2025-11-09 22:37:55.083651"
  },
  "d:\\ChatPaper\\academic Papers\\Quantization-Aware-Training\\S$^2$NN_ Sub-bit Spiking Neural Networks.pdf": {
    "title": "S$^2$NN: Sub-bit Spiking Neural Networks",
    "output": "D:\\ChatPaper\\export\\S$^2$NN_ Sub-bit Spiking Neural Networks.md",
    "time": "2025-11-09 22:39:42.724963"
  },
  "d:\\ChatPaper\\academic Papers\\Quantization-Aware-Training\\Tequila_ Trapping-free Ternary Quantization for Large Language Models.pdf": {
    "title": "Tequila: Trapping-free Ternary Quantization for Large Language Models",
    "output": "D:\\ChatPaper\\export\\Tequila_ Trapping-free Ternary Quantization for Large Language Models.md",
    "time": "2025-11-09 22:41:51.802640"
  },
  "d:\\ChatPaper\\academic Papers\\Quantization-Aware-Training\\Texture Vector-Quantization and Reconstruction Aware Prediction for Generative S.pdf": {
    "title": "Texture Vector-Quantization and Reconstruction Aware Prediction for Generative Super-Resolution",
    "output": "D:\\ChatPaper\\export\\Texture Vector-Quantization and Reconstruction Aware Prediction for Generative S.md",
    "time": "2025-11-09 22:44:01.011257"
  },
  "d:\\ChatPaper\\academic Papers\\Quantization-Aware-Training\\RobuQ_ Pushing DiTs to W1.58A2 via Robust Activation Quantization.pdf": {
    "title": "RobuQ: Pushing DiTs to W1.58A2 via Robust Activation Quantization",
    "output": "D:\\ChatPaper\\export\\RobuQ_ Pushing DiTs to W1.58A2 via Robust Activation Quantization.md",
    "time": "2025-11-09 22:46:00.875269"
  },
  "d:\\ChatPaper\\academic Papers\\Quantization-Aware-Training\\Beyond Outliers_ A Study of Optimizers Under Quantization.pdf": {
    "title": "Beyond Outliers: A Study of Optimizers Under Quantization",
    "output": "D:\\ChatPaper\\export\\Beyond Outliers_ A Study of Optimizers Under Quantization.md",
    "time": "2025-11-09 22:48:11.519489"
  },
  "d:\\ChatPaper\\academic Papers\\Quantization-Aware-Training\\Compute-Optimal Quantization-Aware Training.pdf": {
    "title": "Compute-Optimal Quantization-Aware Training",
    "output": "D:\\ChatPaper\\export\\Compute-Optimal Quantization-Aware Training.md",
    "time": "2025-11-09 22:50:20.403013"
  },
  "d:\\ChatPaper\\academic Papers\\Quantization-Aware-Training\\COSPADI_ Compressing LLMs via Calibration-Guided Sparse Dictionary Learning.pdf": {
    "title": "COSPADI: Compressing LLMs via Calibration-Guided Sparse Dictionary Learning",
    "output": "D:\\ChatPaper\\export\\COSPADI_ Compressing LLMs via Calibration-Guided Sparse Dictionary Learning.md",
    "time": "2025-11-09 22:51:58.852648"
  },
  "d:\\ChatPaper\\academic Papers\\Quantization-Aware-Training\\SlimDiff_ Training-Free, Activation-Guided Hands-free Slimming of Diffusion Mode.pdf": {
    "title": "SlimDiff: Training-Free, Activation-Guided Hands-free Slimming of Diffusion Models",
    "output": "D:\\ChatPaper\\export\\SlimDiff_ Training-Free, Activation-Guided Hands-free Slimming of Diffusion Mode.md",
    "time": "2025-11-09 22:53:58.137632"
  },
  "d:\\ChatPaper\\academic Papers\\Quantization-Aware-Training\\Quantized Visual Geometry Grounded Transformer.pdf": {
    "title": "Quantized Visual Geometry Grounded Transformer",
    "output": "D:\\ChatPaper\\export\\Quantized Visual Geometry Grounded Transformer.md",
    "time": "2025-11-09 22:55:38.096992"
  },
  "d:\\ChatPaper\\academic Papers\\Quantization-Aware-Training\\Can Less Precise Be More Reliable_ A Systematic Evaluation of Quantization's Imp.pdf": {
    "title": "Can Less Precise Be More Reliable? A Systematic Evaluation of Quantization's Impact on CLIP Beyond Accuracy",
    "output": "D:\\ChatPaper\\export\\Can Less Precise Be More Reliable_ A Systematic Evaluation of Quantization's Imp.md",
    "time": "2025-11-09 22:57:26.118103"
  },
  "d:\\ChatPaper\\academic Papers\\Quantization-Aware-Training\\Punching Above Precision_ Small Quantized Model Distillation with Learnable Regu.pdf": {
    "title": "Punching Above Precision: Small Quantized Model Distillation with Learnable Regularizer",
    "output": "D:\\ChatPaper\\export\\Punching Above Precision_ Small Quantized Model Distillation with Learnable Regu.md",
    "time": "2025-11-09 22:59:26.098282"
  },
  "d:\\ChatPaper\\academic Papers\\Quantization-Aware-Training\\TinyEcoWeedNet_ Edge Efficient Real-Time Aerial Agricultural Weed Detection.pdf": {
    "title": "TinyEcoWeedNet: Edge Efficient Real-Time Aerial Agricultural Weed Detection",
    "output": "D:\\ChatPaper\\export\\TinyEcoWeedNet_ Edge Efficient Real-Time Aerial Agricultural Weed Detection.md",
    "time": "2025-11-09 23:01:21.519566"
  },
  "d:\\ChatPaper\\academic Papers\\Quantization-Aware-Training\\SBVR_ Summation of BitVector Representation for Efficient LLM Quantization.pdf": {
    "title": "SBVR: Summation of BitVector Representation for Efficient LLM Quantization",
    "output": "D:\\ChatPaper\\export\\SBVR_ Summation of BitVector Representation for Efficient LLM Quantization.md",
    "time": "2025-11-09 23:03:27.996987"
  },
  "d:\\ChatPaper\\academic Papers\\Quantization-Aware-Training\\QWHA_ Quantization-Aware Walsh-Hadamard Adaptation for Parameter-Efficient Fine-.pdf": {
    "title": "QWHA: Quantization-Aware Walsh-Hadamard Adaptation for Parameter-Efficient Fine-Tuning on Large Language Models",
    "output": "D:\\ChatPaper\\export\\QWHA_ Quantization-Aware Walsh-Hadamard Adaptation for Parameter-Efficient Fine-.md",
    "time": "2025-11-09 23:05:31.395962"
  },
  "d:\\ChatPaper\\academic Papers\\Quantization-Aware-Training\\PTQTP_ Post-Training Quantization to Trit-Planes for Large Language Models.pdf": {
    "title": "PTQTP: Post-Training Quantization to Trit-Planes for Large Language Models",
    "output": "D:\\ChatPaper\\export\\PTQTP_ Post-Training Quantization to Trit-Planes for Large Language Models.md",
    "time": "2025-11-09 23:07:40.743887"
  },
  "d:\\ChatPaper\\academic Papers\\Quantization-Aware-Training\\MEC-Quant_ Maximum Entropy Coding for Extremely Low Bit Quantization-Aware Train.pdf": {
    "title": "MEC-Quant: Maximum Entropy Coding for Extremely Low Bit Quantization-Aware Training",
    "output": "D:\\ChatPaper\\export\\MEC-Quant_ Maximum Entropy Coding for Extremely Low Bit Quantization-Aware Train.md",
    "time": "2025-11-09 23:09:31.798254"
  },
  "d:\\ChatPaper\\academic Papers\\Quantization-Aware-Training\\Q-ROAR_ Outlier-Aware Rescaling for RoPE Position Interpolation in Quantized Lon.pdf": {
    "title": "Q-ROAR: Outlier-Aware Rescaling for RoPE Position Interpolation in Quantized Long-Context LLMs",
    "output": "D:\\ChatPaper\\export\\Q-ROAR_ Outlier-Aware Rescaling for RoPE Position Interpolation in Quantized Lon.md",
    "time": "2025-11-09 23:11:26.251851"
  },
  "d:\\ChatPaper\\academic Papers\\Quantization-Aware-Training\\Efficient Quantization-Aware Neural Receivers_ Beyond Post-Training Quantization.pdf": {
    "title": "Efficient Quantization-Aware Neural Receivers: Beyond Post-Training Quantization",
    "output": "D:\\ChatPaper\\export\\Efficient Quantization-Aware Neural Receivers_ Beyond Post-Training Quantization.md",
    "time": "2025-11-09 23:13:19.465366"
  },
  "d:\\ChatPaper\\academic Papers\\Quantization-Aware-Training\\Rate-Distortion Limits for Multimodal Retrieval_ Theory, Optimal Codes, and Fini.pdf": {
    "title": "Rate-Distortion Limits for Multimodal Retrieval: Theory, Optimal Codes, and Finite-Sample Guarantees",
    "output": "D:\\ChatPaper\\export\\Rate-Distortion Limits for Multimodal Retrieval_ Theory, Optimal Codes, and Fini.md",
    "time": "2025-11-09 23:15:12.115261"
  },
  "d:\\ChatPaper\\academic Papers\\Quantization-Aware-Training\\SQAP-VLA_ A Synergistic Quantization-Aware Pruning Framework for High-Performanc.pdf": {
    "title": "SQAP-VLA: A Synergistic Quantization-Aware Pruning Framework for High-Performance Vision-Language-Action Models",
    "output": "D:\\ChatPaper\\export\\SQAP-VLA_ A Synergistic Quantization-Aware Pruning Framework for High-Performanc.md",
    "time": "2025-11-09 23:17:10.701298"
  },
  "d:\\ChatPaper\\academic Papers\\Quantization-Aware-Training\\CSI Compression Beyond Latents_ End-to-End Hybrid Attention-CNN Networks with En.pdf": {
    "title": "CSI Compression Beyond Latents: End-to-End Hybrid Attention-CNN Networks with Entropy Regularization",
    "output": "D:\\ChatPaper\\export\\CSI Compression Beyond Latents_ End-to-End Hybrid Attention-CNN Networks with En.md",
    "time": "2025-11-09 23:18:56.475672"
  },
  "d:\\ChatPaper\\academic Papers\\Quantization-Aware-Training\\Explaining How Quantization Disparately Skews a Model.pdf": {
    "title": "Explaining How Quantization Disparately Skews a Model",
    "output": "D:\\ChatPaper\\export\\Explaining How Quantization Disparately Skews a Model.md",
    "time": "2025-11-09 23:20:54.904788"
  },
  "d:\\ChatPaper\\academic Papers\\Quantization-Aware-Training\\LoaQ_ Layer-wise Output Approximation Quantization.pdf": {
    "title": "LoaQ: Layer-wise Output Approximation Quantization",
    "output": "D:\\ChatPaper\\export\\LoaQ_ Layer-wise Output Approximation Quantization.md",
    "time": "2025-11-09 23:22:39.132532"
  },
  "d:\\ChatPaper\\academic Papers\\Quantization-Aware-Training\\FineServe_ Precision-Aware KV Slab and Two-Level Scheduling for Heterogeneous Pr.pdf": {
    "title": "FineServe: Precision-Aware KV Slab and Two-Level Scheduling for Heterogeneous Precision LLM Serving",
    "output": "D:\\ChatPaper\\export\\FineServe_ Precision-Aware KV Slab and Two-Level Scheduling for Heterogeneous Pr.md",
    "time": "2025-11-09 23:24:26.105021"
  },
  "d:\\ChatPaper\\academic Papers\\Quantization-Aware-Training\\Sensitivity-Aware Post-Training Quantization for Deep Neural Networks.pdf": {
    "title": "Sensitivity-Aware Post-Training Quantization for Deep Neural Networks",
    "output": "D:\\ChatPaper\\export\\Sensitivity-Aware Post-Training Quantization for Deep Neural Networks.md",
    "time": "2025-11-09 23:26:22.551494"
  },
  "d:\\ChatPaper\\academic Papers\\Quantization-Aware-Training\\SuperSNN_ A Hardware-Aware Framework for Physically Realizable, High-Performance.pdf": {
    "title": "SuperSNN: A Hardware-Aware Framework for Physically Realizable, High-Performance Superconducting Spiking Neural Network Chips",
    "output": "D:\\ChatPaper\\export\\SuperSNN_ A Hardware-Aware Framework for Physically Realizable, High-Performance.md",
    "time": "2025-11-09 23:28:16.911313"
  },
  "d:\\ChatPaper\\academic Papers\\Quantization-Aware-Training\\Data-Augmented Quantization-Aware Knowledge Distillation.pdf": {
    "title": "Data-Augmented Quantization-Aware Knowledge Distillation",
    "output": "D:\\ChatPaper\\export\\Data-Augmented Quantization-Aware Knowledge Distillation.md",
    "time": "2025-11-09 23:29:52.809957"
  },
  "d:\\ChatPaper\\academic Papers\\Quantization-Aware-Training\\DPQuant_ Efficient and Differentially-Private Model Training via Dynamic Quantiz.pdf": {
    "title": "DPQuant: Efficient and Differentially-Private Model Training via Dynamic Quantization Scheduling",
    "output": "D:\\ChatPaper\\export\\DPQuant_ Efficient and Differentially-Private Model Training via Dynamic Quantiz.md",
    "time": "2025-11-09 23:31:53.501988"
  },
  "d:\\ChatPaper\\academic Papers\\Quantization-Aware-Training\\Empowering Large Language Model for Sequential Recommendation via Multimodal Emb.pdf": {
    "title": "Empowering Large Language Model for Sequential Recommendation via Multimodal Embeddings and Semantic IDs",
    "output": "D:\\ChatPaper\\export\\Empowering Large Language Model for Sequential Recommendation via Multimodal Emb.md",
    "time": "2025-11-09 23:33:55.624022"
  },
  "d:\\ChatPaper\\academic Papers\\Quantization-Aware-Training\\Q-Sched_ Pushing the Boundaries of Few-Step Diffusion Models with Quantization-A.pdf": {
    "title": "Q-Sched: Pushing the Boundaries of Few-Step Diffusion Models with Quantization-Aware Scheduling",
    "output": "D:\\ChatPaper\\export\\Q-Sched_ Pushing the Boundaries of Few-Step Diffusion Models with Quantization-A.md",
    "time": "2025-11-09 23:35:49.937696"
  },
  "d:\\ChatPaper\\academic Papers\\Quantization-Aware-Training\\Quantization Meets OOD_ Generalizable Quantization-aware Training from a Flatnes.pdf": {
    "title": "Quantization Meets OOD: Generalizable Quantization-aware Training from a Flatness Perspective",
    "output": "D:\\ChatPaper\\export\\Quantization Meets OOD_ Generalizable Quantization-aware Training from a Flatnes.md",
    "time": "2025-11-09 23:37:48.182166"
  },
  "d:\\ChatPaper\\academic Papers\\Quantization-Aware-Training\\Progressive Element-wise Gradient Estimation for Neural Network Quantization.pdf": {
    "title": "Progressive Element-wise Gradient Estimation for Neural Network Quantization",
    "output": "D:\\ChatPaper\\export\\Progressive Element-wise Gradient Estimation for Neural Network Quantization.md",
    "time": "2025-11-09 23:39:44.879859"
  },
  "d:\\ChatPaper\\academic Papers\\Quantization-Aware-Training\\End-to-End On-Device Quantization-Aware Training for LLMs at Inference Cost.pdf": {
    "title": "End-to-End On-Device Quantization-Aware Training for LLMs at Inference Cost",
    "output": "D:\\ChatPaper\\export\\End-to-End On-Device Quantization-Aware Training for LLMs at Inference Cost.md",
    "time": "2025-11-09 23:41:52.224869"
  },
  "d:\\ChatPaper\\academic Papers\\Quantization-Aware-Training\\Quantization Robustness to Input Degradations for Object Detection.pdf": {
    "title": "Quantization Robustness to Input Degradations for Object Detection",
    "output": "D:\\ChatPaper\\export\\Quantization Robustness to Input Degradations for Object Detection.md",
    "time": "2025-11-09 23:43:48.064700"
  },
  "d:\\ChatPaper\\academic Papers\\Quantization-Aware-Training\\Scaling Laws for Task-Stratified Knowledge in Post-Training Quantized Large Lang.pdf": {
    "title": "Scaling Laws for Task-Stratified Knowledge in Post-Training Quantized Large Language Models",
    "output": "D:\\ChatPaper\\export\\Scaling Laws for Task-Stratified Knowledge in Post-Training Quantized Large Lang.md",
    "time": "2025-11-09 23:45:37.622093"
  },
  "d:\\ChatPaper\\academic Papers\\Quantization-Aware-Training\\AQ-PCDSys_ An Adaptive Quantized Planetary Crater Detection System for Autonomou.pdf": {
    "title": "AQ-PCDSys: An Adaptive Quantized Planetary Crater Detection System for Autonomous Space Exploration",
    "output": "D:\\ChatPaper\\export\\AQ-PCDSys_ An Adaptive Quantized Planetary Crater Detection System for Autonomou.md",
    "time": "2025-11-09 23:47:30.433033"
  },
  "d:\\ChatPaper\\academic Papers\\Quantization-Aware-Training\\TaDiCodec_ Text-aware Diffusion Speech Tokenizer for Speech Language Modeling.pdf": {
    "title": "TaDiCodec: Text-aware Diffusion Speech Tokenizer for Speech Language Modeling",
    "output": "D:\\ChatPaper\\export\\TaDiCodec_ Text-aware Diffusion Speech Tokenizer for Speech Language Modeling.md",
    "time": "2025-11-09 23:49:22.760685"
  },
  "d:\\ChatPaper\\academic Papers\\Quantization-Aware-Training\\A Node-Aware Dynamic Quantization Approach for Graph Collaborative Filtering.pdf": {
    "title": "A Node-Aware Dynamic Quantization Approach for Graph Collaborative Filtering",
    "output": "D:\\ChatPaper\\export\\A Node-Aware Dynamic Quantization Approach for Graph Collaborative Filtering.md",
    "time": "2025-11-09 23:51:31.955895"
  },
  "d:\\ChatPaper\\academic Papers\\Quantization-Aware-Training\\JEDI-linear_ Fast and Efficient Graph Neural Networks for Jet Tagging on FPGAs.pdf": {
    "title": "JEDI-linear: Fast and Efficient Graph Neural Networks for Jet Tagging on FPGAs",
    "output": "D:\\ChatPaper\\export\\JEDI-linear_ Fast and Efficient Graph Neural Networks for Jet Tagging on FPGAs.md",
    "time": "2025-11-09 23:53:05.066119"
  }
}